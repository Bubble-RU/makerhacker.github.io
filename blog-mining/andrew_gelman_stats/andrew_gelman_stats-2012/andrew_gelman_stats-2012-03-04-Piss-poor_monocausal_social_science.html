<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1196" href="#">andrew_gelman_stats-2012-1196</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1196-html" href="http://andrewgelman.com/2012/03/04/piss-poor-monocausal-social-science/">html</a></p><p>Introduction: Dan Kahan writes: 
  
  
Okay, have done due diligence here & can’t find the reference. It was in recent blog — and was more or less an aside — but you ripped into researchers (pretty sure econometricians, but this could be my memory adding to your account recollections it conjured from my own experience) who purport to make estimates or predictions based on multivariate regression in which the value of particular predictor is set at some level while others “held constant” etc., on ground that variance in that particular predictor independent of covariance in other model predictors is unrealistic.  You made it sound, too, as if this were one of the pet peeves in your menagerie — leading me to think you had blasted into it before.


Know what I’m talking about?


Also — isn’t this really just a way of saying that the model is misspecified — at least if the goal is to try to make a valid & unbiased estimate of the impact of that particular predictor? The problem can’t be that one is usin</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Dan Kahan writes:        Okay, have done due diligence here & can’t find the reference. [sent-1, score-0.122]
</p><p>2 , on ground that variance in that particular predictor independent of covariance in other model predictors is unrealistic. [sent-3, score-1.138]
</p><p>3 You made it sound, too, as if this were one of the pet peeves in your menagerie — leading me to think you had blasted into it before. [sent-4, score-0.273]
</p><p>4 Also — isn’t this really just a way of saying that the model is misspecified — at least if the goal is to try to make a valid & unbiased estimate of the impact of that particular predictor? [sent-6, score-0.766]
</p><p>5 In any case, I’m reminded of the advice I often give that each causal inference typically requires its own analysis. [sent-13, score-0.176]
</p><p>6 I’m generally skeptical of an analysis where someone picks out one coefficient to address Hypothesis 1, another to address Hypothesis 2a, and so forth. [sent-14, score-0.428]
</p><p>7 If a causal inference can be framed via a natural experiment on some variable x, you want to control for things that come before x and not what comes after (I’m thinking of logical order, which is related to but is not identical to time order). [sent-15, score-0.479]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('predictor', 0.421), ('covariate', 0.279), ('collinear', 0.245), ('impact', 0.234), ('variance', 0.166), ('covariance', 0.162), ('estimate', 0.152), ('constant', 0.149), ('address', 0.127), ('diligence', 0.122), ('posits', 0.122), ('purport', 0.122), ('independent', 0.118), ('regression', 0.118), ('invalid', 0.115), ('peeves', 0.11), ('try', 0.108), ('ripped', 0.107), ('picks', 0.101), ('omitted', 0.101), ('hypothesis', 0.099), ('okay', 0.098), ('causal', 0.098), ('model', 0.097), ('affairs', 0.096), ('particular', 0.096), ('commonplace', 0.095), ('order', 0.095), ('influences', 0.091), ('econometricians', 0.091), ('pet', 0.09), ('interest', 0.084), ('framed', 0.083), ('holding', 0.083), ('memory', 0.08), ('kahan', 0.08), ('combine', 0.08), ('unbiased', 0.079), ('ground', 0.078), ('inference', 0.078), ('thinking', 0.074), ('phenomenon', 0.073), ('identical', 0.073), ('index', 0.073), ('logical', 0.073), ('yield', 0.073), ('one', 0.073), ('multivariate', 0.072), ('biased', 0.072), ('member', 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1196-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>Introduction: Dan Kahan writes: 
  
  
Okay, have done due diligence here & can’t find the reference. It was in recent blog — and was more or less an aside — but you ripped into researchers (pretty sure econometricians, but this could be my memory adding to your account recollections it conjured from my own experience) who purport to make estimates or predictions based on multivariate regression in which the value of particular predictor is set at some level while others “held constant” etc., on ground that variance in that particular predictor independent of covariance in other model predictors is unrealistic.  You made it sound, too, as if this were one of the pet peeves in your menagerie — leading me to think you had blasted into it before.


Know what I’m talking about?


Also — isn’t this really just a way of saying that the model is misspecified — at least if the goal is to try to make a valid & unbiased estimate of the impact of that particular predictor? The problem can’t be that one is usin</p><p>2 0.21333627 <a title="1196-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-05-Question_26_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1367 andrew gelman stats-2012-06-05-Question 26 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>Introduction: 26. You have just graded an an exam with 28 questions and 15 students. You fit a logistic item- response model estimating ability, difficulty, and discrimination parameters. Which of the following statements are basically true? (Indicate all that apply.)
 
(a) If a question is answered correctly by students with very low and very high ability, but is missed by students in the middle, it will have a high value for its discrimination parameter.
 
(b) It is not possible to fit an item-response model when you have more questions than students. In order to fit the model, you either need to reduce the number of questions (for example, by discarding some questions or by putting together some questions into a combined score) or increase the number of students in the dataset.
 
(c) To keep the model identified, you can set one of the difficulty parameters or one of the ability parameters to zero and set one of the discrimination parameters to 1.
 
(d) If two students answer the same number of q</p><p>3 0.20137441 <a title="1196-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-04-Question_25_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1365 andrew gelman stats-2012-06-04-Question 25 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>Introduction: 25. You are using multilevel regression and poststratification (MRP) to a survey of 1500 people to estimate support for the space program, by state. The model is fit using, as a state- level predictor, the Republican presidential vote in the state, which turns out to have a low correlation with support for the space program. Which of the following statements are basically true? (Indicate all that apply.)
 
(a) For small states, the MRP estimates will be determined almost entirely by the demo- graphic characteristics of the respondents in the sample from that state.
 
(b) For small states, the MRP estimates will be determined almost entirely by the demographic characteristics of the population in that state.
 
(c) Adding a predictor specifically for this model (for example, a measure of per-capita space-program spending in the state) could dramatically improve the estimates of state-level opinion.
 
(d) It would not be appropriate to add a predictor such as per-capita space-program spen</p><p>4 0.17846112 <a title="1196-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>Introduction: David Hoaglin writes:
  
After seeing it cited, I just read  your paper  in Technometrics.  The home radon levels provide an interesting and instructive example.


I [Hoaglin] have a different take on the difficulty of interpreting the estimated coefficient of the county-level basement proportion (gamma-sub-2) on page 434.  An important part of the difficulty involves “other things being equal.”  That sounds like the widespread interpretation of a regression coefficient as telling how the dependent variable responds to change in that predictor when the other predictors are held constant.  Unfortunately, as a general interpretation, that language is oversimplified; it doesn’t reflect how regression actually works.  The appropriate general interpretation is that the coefficient tells how the dependent variable responds to change in that predictor after allowing for simultaneous change in the other predictors in the data at hand.  Thus, in the county-level regression gamma-sub-2 summarize</p><p>5 0.1577712 <a title="1196-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>Introduction: Joshua Vogelstein asks for my thoughts as  a Bayesian on the above topic.  So here they are (briefly):
 
The concept of the bias-variance tradeoff can be useful if you don’t take it too seriously.  The basic idea is as follows:  if you’re estimating something, you can slice your data finer and finer, or perform more and more adjustments, each time getting a purer—and less biased—estimate.  But each subdivision or each adjustment reduces your sample size or increases potential estimation error, hence the variance of your estimate goes up.
 
That story is real.  In lots and lots of examples, there’s a continuum between a completely unadjusted general estimate (high bias, low variance) and a specific, focused, adjusted estimate (low bias, high variance).
 
Suppose, for example, you’re using data from a large experiment to estimate the effect of a treatment on a fairly narrow group, say, white men between the ages of 45 and 50.  At one extreme, you could just take the estimated treatment e</p><p>6 0.15221897 <a title="1196-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>7 0.14623556 <a title="1196-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-02-Covariate_Adjustment_in_RCT_-_Model_Overfitting_in_Multilevel_Regression.html">936 andrew gelman stats-2011-10-02-Covariate Adjustment in RCT - Model Overfitting in Multilevel Regression</a></p>
<p>8 0.13259037 <a title="1196-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-13-Checking_your_model_using_fake_data.html">852 andrew gelman stats-2011-08-13-Checking your model using fake data</a></p>
<p>9 0.12238123 <a title="1196-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>10 0.11925094 <a title="1196-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-24-A_new_efficient_lossless_compression_algorithm.html">228 andrew gelman stats-2010-08-24-A new efficient lossless compression algorithm</a></p>
<p>11 0.11779374 <a title="1196-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Adding_more_information_can_make_the_variance_go_up_%28depending_on_your_model%29.html">810 andrew gelman stats-2011-07-20-Adding more information can make the variance go up (depending on your model)</a></p>
<p>12 0.11760513 <a title="1196-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>13 0.11207137 <a title="1196-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-01-When_should_you_worry_about_imputed_data%3F.html">935 andrew gelman stats-2011-10-01-When should you worry about imputed data?</a></p>
<p>14 0.11116601 <a title="1196-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>15 0.10862479 <a title="1196-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>16 0.10750476 <a title="1196-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>17 0.1074052 <a title="1196-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>18 0.10736363 <a title="1196-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-28-%E2%80%9CGenomics%E2%80%9D_vs._genetics.html">303 andrew gelman stats-2010-09-28-“Genomics” vs. genetics</a></p>
<p>19 0.10733156 <a title="1196-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-07-Prior_distributions_for_regression_coefficients.html">1486 andrew gelman stats-2012-09-07-Prior distributions for regression coefficients</a></p>
<p>20 0.10617535 <a title="1196-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-Displaying_a_fitted_multilevel_model.html">328 andrew gelman stats-2010-10-08-Displaying a fitted multilevel model</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.189), (1, 0.101), (2, 0.085), (3, -0.045), (4, 0.053), (5, 0.016), (6, 0.02), (7, -0.037), (8, 0.076), (9, 0.069), (10, 0.019), (11, 0.038), (12, 0.025), (13, 0.003), (14, 0.001), (15, 0.014), (16, -0.024), (17, -0.013), (18, -0.025), (19, 0.028), (20, -0.008), (21, -0.022), (22, 0.055), (23, 0.017), (24, 0.048), (25, 0.023), (26, 0.04), (27, -0.039), (28, -0.04), (29, -0.008), (30, 0.074), (31, -0.053), (32, 0.009), (33, -0.032), (34, -0.018), (35, -0.046), (36, 0.055), (37, -0.017), (38, 0.047), (39, -0.009), (40, -0.042), (41, -0.055), (42, -0.07), (43, 0.032), (44, 0.027), (45, 0.044), (46, -0.012), (47, 0.044), (48, 0.03), (49, -0.009)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96374261 <a title="1196-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>Introduction: Dan Kahan writes: 
  
  
Okay, have done due diligence here & can’t find the reference. It was in recent blog — and was more or less an aside — but you ripped into researchers (pretty sure econometricians, but this could be my memory adding to your account recollections it conjured from my own experience) who purport to make estimates or predictions based on multivariate regression in which the value of particular predictor is set at some level while others “held constant” etc., on ground that variance in that particular predictor independent of covariance in other model predictors is unrealistic.  You made it sound, too, as if this were one of the pet peeves in your menagerie — leading me to think you had blasted into it before.


Know what I’m talking about?


Also — isn’t this really just a way of saying that the model is misspecified — at least if the goal is to try to make a valid & unbiased estimate of the impact of that particular predictor? The problem can’t be that one is usin</p><p>2 0.78884494 <a title="1196-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>Introduction: David Hoaglin writes:
  
After seeing it cited, I just read  your paper  in Technometrics.  The home radon levels provide an interesting and instructive example.


I [Hoaglin] have a different take on the difficulty of interpreting the estimated coefficient of the county-level basement proportion (gamma-sub-2) on page 434.  An important part of the difficulty involves “other things being equal.”  That sounds like the widespread interpretation of a regression coefficient as telling how the dependent variable responds to change in that predictor when the other predictors are held constant.  Unfortunately, as a general interpretation, that language is oversimplified; it doesn’t reflect how regression actually works.  The appropriate general interpretation is that the coefficient tells how the dependent variable responds to change in that predictor after allowing for simultaneous change in the other predictors in the data at hand.  Thus, in the county-level regression gamma-sub-2 summarize</p><p>3 0.76660246 <a title="1196-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-15-Still_more_Mr._P_in_public_health.html">770 andrew gelman stats-2011-06-15-Still more Mr. P in public health</a></p>
<p>Introduction: When it  rains  it pours . . .
 
John Transue writes:
  
I saw  a post  on Andrew Sullivan’s blog today about life expectancy in different US counties. With a bunch of the worst counties being in Mississippi, I thought that it might be another case of analysts getting extreme values from small counties.


However, the paper (see  here ) includes a pretty interesting methods section. This is from page 5, “Specifically, we used a mixed-effects Poisson regression with time, geospatial, and covariate components. Poisson regression fits count outcome variables, e.g., death counts, and is preferable to a logistic model because the latter is biased when an outcome is rare (occurring in less than 1% of observations).”


They have downloadable data. I believe that the data are predicted values from the model. A web appendix also gives 90% CIs for their estimates.


Do you think they solved the small county problem and that the worst counties really are where their spreadsheet suggests?
  
My re</p><p>4 0.73613065 <a title="1196-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>Introduction: Andy Cooper writes:
  
A link to an  article , “Four Assumptions Of Multiple Regression That Researchers Should Always Test”, has been making  the rounds  on Twitter.  Their first rule is “Variables are Normally distributed.”  And they seem to be talking about the independent variables – but then later bring in tests on the residuals (while admitting that the normally-distributed error assumption is a weak assumption).  


I thought we had long-since moved away from transforming our independent variables to make them normally distributed for statistical reasons (as opposed to standardizing them for interpretability, etc.)  Am I missing something?  I agree that leverage in a influence is important, but normality of the variables? The article is from 2002, so it might be dated, but given the popularity of the tweet, I thought I’d ask your opinion.
  
My response:  There’s some useful advice on that page but overall I think the advice was dated even in 2002.  In section 3.6 of my book wit</p><p>5 0.70790631 <a title="1196-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>Introduction: Andreas Graefe writes (see  here   here   here ):
  
The usual procedure for developing linear models to predict any kind of target variable is to identify a subset of most important predictors and to estimate weights that provide the best possible solution for a given sample. The resulting “optimally” weighted linear composite is then used when predicting new data. This approach is useful in situations with large and reliable datasets and few predictor variables. However, a large body of analytical and empirical evidence since the 1970s shows that the weighting of variables is of little, if any, value in situations with small and noisy datasets and a large number of predictor variables. In such situations, including all relevant variables is more important than their weighting. These findings have yet to impact many fields. This study uses data from nine established U.S. election-forecasting models whose forecasts are regularly published in academic journals to demonstrate the value o</p><p>6 0.70784354 <a title="1196-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>7 0.70241785 <a title="1196-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-04-Estimating_the_effect_of_A_on_B%2C_and_also_the_effect_of_B_on_A.html">393 andrew gelman stats-2010-11-04-Estimating the effect of A on B, and also the effect of B on A</a></p>
<p>8 0.70237345 <a title="1196-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>9 0.69155931 <a title="1196-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Modeling_y_%3D_a_%2B_b_%2B_c.html">1294 andrew gelman stats-2012-05-01-Modeling y = a + b + c</a></p>
<p>10 0.68846262 <a title="1196-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>11 0.68468022 <a title="1196-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-02-An_IV_won%E2%80%99t_save_your_life_if_the_line_is_tangled.html">550 andrew gelman stats-2011-02-02-An IV won’t save your life if the line is tangled</a></p>
<p>12 0.68053108 <a title="1196-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>13 0.68038827 <a title="1196-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-03-is_it_possible_to_%E2%80%9Coverstratify%E2%80%9D_when_assigning_a_treatment_in_a_randomized_control_trial%3F.html">553 andrew gelman stats-2011-02-03-is it possible to “overstratify” when assigning a treatment in a randomized control trial?</a></p>
<p>14 0.67759955 <a title="1196-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-31-Using_factor_analysis_or_principal_components_analysis_or_measurement-error_models_for_biological_measurements_in_archaeology%3F.html">1094 andrew gelman stats-2011-12-31-Using factor analysis or principal components analysis or measurement-error models for biological measurements in archaeology?</a></p>
<p>15 0.67631084 <a title="1196-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Matching_and_regression%3A__two_great_tastes_etc_etc.html">796 andrew gelman stats-2011-07-10-Matching and regression:  two great tastes etc etc</a></p>
<p>16 0.67167634 <a title="1196-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-28-Correlation%2C_prediction%2C_variation%2C_etc..html">301 andrew gelman stats-2010-09-28-Correlation, prediction, variation, etc.</a></p>
<p>17 0.66989112 <a title="1196-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-08-Regression_and_causality_and_variable_ordering.html">2364 andrew gelman stats-2014-06-08-Regression and causality and variable ordering</a></p>
<p>18 0.66837054 <a title="1196-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Is_instrumental_variables_analysis_particularly_susceptible_to_Type_M_errors%3F.html">368 andrew gelman stats-2010-10-25-Is instrumental variables analysis particularly susceptible to Type M errors?</a></p>
<p>19 0.66480041 <a title="1196-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-02-%E2%80%9CBased_on_my_experiences%2C_I_think_you_could_make_general_progress_by_constructing_a_solution_to_your_specific_problem.%E2%80%9D.html">1441 andrew gelman stats-2012-08-02-“Based on my experiences, I think you could make general progress by constructing a solution to your specific problem.”</a></p>
<p>20 0.66148841 <a title="1196-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-Why_we_hate_stepwise_regression.html">2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.223), (15, 0.03), (16, 0.055), (21, 0.035), (22, 0.014), (24, 0.163), (45, 0.016), (56, 0.011), (82, 0.021), (86, 0.028), (89, 0.038), (99, 0.27)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97720867 <a title="1196-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-01-%E2%80%9CRoughly_90%25_of_the_increase_in_._._.%E2%80%9D__Hey%2C_wait_a_minute%21.html">549 andrew gelman stats-2011-02-01-“Roughly 90% of the increase in . . .”  Hey, wait a minute!</a></p>
<p>Introduction: Matthew Yglesias  links  approvingly to the following  statement  by Michael Mandel:
  
Homeland Security accounts for roughly 90% of the increase in federal regulatory employment over the past ten years.
  
Roughly 90%, huh?  That sounds pretty impressive.  But wait a minute . . . what if total federal regulatory employment had increased a bit less.  Then Homeland Security could’ve accounted for 105% of the increase, or 500% of the increase, or whatever.  The point is the change in total employment is the sum of a bunch of pluses and minuses.  It happens that, if you don’t count Homeland Security, the total hasn’t changed much–I’m assuming Mandel’s numbers are correct here–and that could be interesting.
 
The “roughly 90%” figure is misleading because, when written as a percent of the total increase, it’s natural to quickly envision it as a percentage that is bounded by 100%. There is a total increase in regulatory employment that the individual agencies sum to, but some margins are p</p><p>2 0.97482121 <a title="1196-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-05-Taking_philosophical_arguments_literally.html">17 andrew gelman stats-2010-05-05-Taking philosophical arguments literally</a></p>
<p>Introduction: Aaron Swartz  writes  the following, as a lead-in to an argument in favor of vegetarianism:
  
 
Imagine you were an early settler of what is now the United States. It seems likely you would have killed native Americans. After all, your parents killed them, your siblings killed them, your friends killed them, the leaders of the community killed them, the President killed them. Chances are, you would have killed them too . . .


Or if you see nothing wrong with killing native Americans, take the example of slavery. Again, everyone had slaves and probably didn’t think too much about the morality of it. . . .
 

 
Are these statements true, though?  It’s hard for me to believe that most early settlers (from the context, it looks like Swartz is discussing the 1500s-1700s here) killed native Americans.  That is, if N is the number of early settlers, and Y is the number of these settlers who killed at least one Indian, I suspect Y/N is much closer to 0 than to 1.  Similarly, it’s not even cl</p><p>3 0.97294515 <a title="1196-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-28-Those_darn_physicists.html">1189 andrew gelman stats-2012-02-28-Those darn physicists</a></p>
<p>Introduction: X pointed me to  this  atrocity:
  
The data on obesity are pretty unequivocal: we’re fat, and we’re getting fatter. Explanations for this trend, however, vary widely, with the blame alternately pinned on individual behaviour, genetics and the environment. In other words, it’s a race between “we eat too much”, “we’re born that way” and “it’s society’s fault”. 
Now, research by Lazaros Gallos has come down strongly in favour of the third option. Gallos and his colleagues at City College of New York treated the obesity rates in some 3000 US counties as “particles” in a physical system, and calculated the correlation between pairs of “particles” as a function of the distance between them. . . . the data indicated that the size of the “obesity cities” – geographic regions with correlated obesity rates – was huge, up to 1000 km. . . .
  
Just to be clear:  I have no problem with people calculating spatial autocorrelations (or even with them using quaint terminology such as referring to coun</p><p>4 0.97028768 <a title="1196-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-18-Economic_Disparities_and_Life_Satisfaction_in_European_Regions.html">97 andrew gelman stats-2010-06-18-Economic Disparities and Life Satisfaction in European Regions</a></p>
<p>Introduction: Grazia Pittau, Roberto Zelli, and I came out with  a paper  investigating the role of economic variables in predicting regional disparities in reported life satisfaction of European Union citizens.  We use multilevel modeling to explicitly account for the hierarchical nature of our data, respondents within regions and countries, and for understanding patterns of variation within and between regions.  Here’s what we found:
 
- Personal income matters more in poor regions than in rich regions, a pattern that still holds for regions within the same country.
 
- Being unemployed is negatively associated with life satisfaction even after controlled for income variation. Living in high unemployment regions does not alleviate the unhappiness of being out of work.
 
- After controlling for individual characteristics and modeling interactions, regional differences in life satisfaction still remain.
 
Here’s a quick graph; there’s more in the article:</p><p>5 0.9691931 <a title="1196-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-18-Lack_of_complete_overlap.html">1017 andrew gelman stats-2011-11-18-Lack of complete overlap</a></p>
<p>Introduction: Evens Salies writes:
  
I have a question regarding a randomizing constraint in my current funded electricity experiment. 


After elimination of missing data we have 110 voluntary households from a larger population (resource constraints do not allow us to have more households!). I randomly assign them to threated and non treated where the treatment variable is some ICT that allows the treated to track their electricity consumption in real tim. The ICT is made of two devices, one that is plugged on the household’s modem and the other on the electric meter. A necessary condition for being treated is that the distance between the box and the meter be below some threshold (d), the value of which is 20 meters approximately. 


50 ICTs can be installed. 
60 households will be in the control group.


But, I can only assign 6 households in the control group for whom d is less than 20. Therefore, I have only 6 households in the control group who have a counterfactual in the group of treated.</p><p>6 0.9685728 <a title="1196-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-30-The_spam_just_gets_weirder_and_weirder.html">1698 andrew gelman stats-2013-01-30-The spam just gets weirder and weirder</a></p>
<p>7 0.96839577 <a title="1196-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-09-The_effects_of_fiscal_consolidation.html">1663 andrew gelman stats-2013-01-09-The effects of fiscal consolidation</a></p>
<p>8 0.96310169 <a title="1196-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-28-Brow_inflation.html">489 andrew gelman stats-2010-12-28-Brow inflation</a></p>
<p>9 0.94764578 <a title="1196-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-01-Needed%3A__A_Billionaire_Candidate_for_President_Who_Shares_the_Views_of_a_Washington_Post_Columnist.html">885 andrew gelman stats-2011-09-01-Needed:  A Billionaire Candidate for President Who Shares the Views of a Washington Post Columnist</a></p>
<p>10 0.94315839 <a title="1196-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-06-Bayesian_Anova_found_useful_in_ecology.html">1102 andrew gelman stats-2012-01-06-Bayesian Anova found useful in ecology</a></p>
<p>11 0.94299507 <a title="1196-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-23-Speaking_frankly.html">1508 andrew gelman stats-2012-09-23-Speaking frankly</a></p>
<p>12 0.94069672 <a title="1196-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-27-More_spam%21.html">1872 andrew gelman stats-2013-05-27-More spam!</a></p>
<p>13 0.93592435 <a title="1196-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-11-Folic_acid_and_autism.html">1893 andrew gelman stats-2013-06-11-Folic acid and autism</a></p>
<p>14 0.92587405 <a title="1196-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-24-Too_Good_To_Be_True%3A__The_Scientific_Mass_Production_of_Spurious_Statistical_Significance.html">1954 andrew gelman stats-2013-07-24-Too Good To Be True:  The Scientific Mass Production of Spurious Statistical Significance</a></p>
<p>15 0.92198718 <a title="1196-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-09-In_the_future%2C_everyone_will_publish_everything..html">1254 andrew gelman stats-2012-04-09-In the future, everyone will publish everything.</a></p>
<p>same-blog 16 0.91349864 <a title="1196-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>17 0.91228598 <a title="1196-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-07-Election_reports.html">1567 andrew gelman stats-2012-11-07-Election reports</a></p>
<p>18 0.91160798 <a title="1196-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-16-%E2%80%9CFalse-positive_psychology%E2%80%9D.html">1171 andrew gelman stats-2012-02-16-“False-positive psychology”</a></p>
<p>19 0.90601385 <a title="1196-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Happy_tax_day%21.html">663 andrew gelman stats-2011-04-15-Happy tax day!</a></p>
<p>20 0.89934164 <a title="1196-lda-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-05-Identifying_pathways_for_managing_multiple_disturbances_to_limit_plant_invasions.html">2360 andrew gelman stats-2014-06-05-Identifying pathways for managing multiple disturbances to limit plant invasions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
