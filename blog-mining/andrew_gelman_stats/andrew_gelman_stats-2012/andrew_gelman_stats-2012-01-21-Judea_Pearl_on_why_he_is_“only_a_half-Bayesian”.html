<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1133 andrew gelman stats-2012-01-21-Judea Pearl on why he is “only a half-Bayesian”</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1133" href="#">andrew_gelman_stats-2012-1133</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1133 andrew gelman stats-2012-01-21-Judea Pearl on why he is “only a half-Bayesian”</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1133-html" href="http://andrewgelman.com/2012/01/21/judea-pearl-on-why-he-is-only-a-half-bayesian/">html</a></p><p>Introduction: In  an article  published in 2001, Pearl wrote:
  
I [Pearl] turned Bayesian in 1971, as soon as I began reading Savage’s monograph The Foundations of Statistical Inference [Savage, 1962]. The arguments were unassailable: (i) It is plain silly to ignore what we know, (ii) It is natural and useful to cast what we know in the language of probabilities, and (iii) If our subjective probabilities are erroneous, their impact will get washed out in due time, as the number of observations increases.


Thirty years later, I [Pearl] am still a devout Bayesian in the sense of (i), but I now doubt the wisdom of (ii) and I know that, in general, (iii) is false.
  
He elaborates:
  
The bulk of human knowledge is organized around causal, not probabilistic relationships, and the grammar of probability calculus is insufficient for capturing those relationships. Specifically, the building blocks of our scientific and everyday knowledge are elementary facts such as “mud does not cause rain” and “symptom</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In  an article  published in 2001, Pearl wrote:    I [Pearl] turned Bayesian in 1971, as soon as I began reading Savage’s monograph The Foundations of Statistical Inference [Savage, 1962]. [sent-1, score-0.179]
</p><p>2 Thirty years later, I [Pearl] am still a devout Bayesian in the sense of (i), but I now doubt the wisdom of (ii) and I know that, in general, (iii) is false. [sent-3, score-0.185]
</p><p>3 He elaborates:    The bulk of human knowledge is organized around causal, not probabilistic relationships, and the grammar of probability calculus is insufficient for capturing those relationships. [sent-4, score-0.871]
</p><p>4 Specifically, the building blocks of our scientific and everyday knowledge are elementary facts such as “mud does not cause rain” and “symptoms do not cause disease” and those facts, strangely enough, cannot be expressed in the vocabulary of probability calculus. [sent-5, score-1.115]
</p><p>5 The Neyman-Rubin framework of potential outcomes does allow for casual reasoning within a probabilistic structure, but indeed it does not allow for statements such as “mud does not cause rain. [sent-8, score-1.028]
</p><p>6 ”  In the potential outcomes notation, one could define a random variable y=1 for rain or 0 for no rain, and define y^1 to be the outcome under treatment and y^2 to be the outcome under control. [sent-9, score-1.048]
</p><p>7 But it would not make sense for “mud” to be a treatment:  in the potential-outcomes framework, a treatment is something that you do, not something such as “mud” that you observe. [sent-10, score-0.142]
</p><p>8 I’m not saying here that Pearl’s framework is a good or bad idea; my point here is that I’m agreeing that he indeed seems to be asking questions that cannot be addressed by probability models. [sent-11, score-0.511]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mud', 0.402), ('pearl', 0.384), ('rain', 0.275), ('cause', 0.172), ('framework', 0.171), ('savage', 0.169), ('iii', 0.166), ('ii', 0.143), ('treatment', 0.142), ('probabilistic', 0.14), ('facts', 0.123), ('define', 0.114), ('probabilities', 0.112), ('washed', 0.111), ('devout', 0.111), ('monograph', 0.111), ('symptoms', 0.111), ('outcomes', 0.106), ('probability', 0.106), ('vocabulary', 0.105), ('strangely', 0.105), ('grammar', 0.105), ('outcome', 0.104), ('allow', 0.104), ('elaborates', 0.097), ('bulk', 0.097), ('knowledge', 0.093), ('erroneous', 0.092), ('cast', 0.092), ('capturing', 0.09), ('potential', 0.089), ('insufficient', 0.086), ('elementary', 0.083), ('agreeing', 0.083), ('notation', 0.083), ('calculus', 0.082), ('thirty', 0.082), ('blocks', 0.081), ('addressed', 0.079), ('plain', 0.076), ('everyday', 0.075), ('wisdom', 0.074), ('organized', 0.072), ('foundations', 0.072), ('indeed', 0.072), ('relationships', 0.07), ('casual', 0.07), ('began', 0.068), ('disease', 0.067), ('ignore', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1133-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Judea_Pearl_on_why_he_is_%E2%80%9Conly_a_half-Bayesian%E2%80%9D.html">1133 andrew gelman stats-2012-01-21-Judea Pearl on why he is “only a half-Bayesian”</a></p>
<p>Introduction: In  an article  published in 2001, Pearl wrote:
  
I [Pearl] turned Bayesian in 1971, as soon as I began reading Savage’s monograph The Foundations of Statistical Inference [Savage, 1962]. The arguments were unassailable: (i) It is plain silly to ignore what we know, (ii) It is natural and useful to cast what we know in the language of probabilities, and (iii) If our subjective probabilities are erroneous, their impact will get washed out in due time, as the number of observations increases.


Thirty years later, I [Pearl] am still a devout Bayesian in the sense of (i), but I now doubt the wisdom of (ii) and I know that, in general, (iii) is false.
  
He elaborates:
  
The bulk of human knowledge is organized around causal, not probabilistic relationships, and the grammar of probability calculus is insufficient for capturing those relationships. Specifically, the building blocks of our scientific and everyday knowledge are elementary facts such as “mud does not cause rain” and “symptom</p><p>2 0.24798152 <a title="1133-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-08-New_Judea_Pearl_journal_of_causal_inference.html">1888 andrew gelman stats-2013-06-08-New Judea Pearl journal of causal inference</a></p>
<p>Introduction: Pearl reports that his Journal of Causal Inference has just posted its  first issue , which contains a mix of theoretical and applied papers.  Pearl writes that they welcome submissions on all aspects of causal inference.</p><p>3 0.19898522 <a title="1133-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-13-Judea_Pearl_overview_on_causal_inference%2C_and_more_general_thoughts_on_the_reexpression_of_existing_methods_by_considering_their_implicit_assumptions.html">2170 andrew gelman stats-2014-01-13-Judea Pearl overview on causal inference, and more general thoughts on the reexpression of existing methods by considering their implicit assumptions</a></p>
<p>Introduction: This  material should be familiar to many of you but could be helpful to newcomers.  Pearl writes:
  
ALL causal conclusions in nonexperimental settings must be based on untested, judgmental assumptions that investigators are prepared to defend on scientific grounds. . . .


To understand what the world should be like for a given procedure to work is of no lesser scientific value than seeking evidence for how the world works . . .


Assumptions are self-destructive in their honesty. The more explicit the assumption, the more criticism it invites . . . causal diagrams invite the harshest criticism because they make assumptions more explicit and more transparent than other representation schemes.
  
As regular readers know (for example, search this blog for “Pearl”), I have not got much out of the causal-diagrams approach myself, but in general I think that when there are multiple, mathematically equivalent methods of getting the same answer, we tend to go with the framework we are used</p><p>4 0.15868697 <a title="1133-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>Introduction: Elias Bareinboim asked what I thought about  his comment  on selection bias in which he referred to a  paper  by himself and Judea Pearl, “Controlling Selection Bias in Causal Inference.”
 
I replied that I have no problem with what he wrote, but that from my perspective I find it easier to conceptualize such problems in terms of multilevel models. I elaborated on that point in a  recent post , “Hierarchical modeling as a framework for extrapolation,” which I think was read by only a few people (I say this because it received only two comments).
 
I don’t think Bareinboim objected to anything I wrote, but like me he is comfortable working within his own framework.  He wrote the following to me: 
  
  
In some sense, “not ad hoc” could mean logically consistent. In other words, if one agrees with the assumptions encoded in the model, one must also agree with the conclusions entailed by these assumptions. I am not aware of any other way of doing mathematics. As it turns out, to get causa</p><p>5 0.15010597 <a title="1133-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-23-Fight%21__%28also_a_bit_of_reminiscence_at_the_end%29.html">1136 andrew gelman stats-2012-01-23-Fight!  (also a bit of reminiscence at the end)</a></p>
<p>Introduction: Martin Lindquist and Michael Sobel published a  fun little article  in Neuroimage on models and assumptions for causal inference with intermediate outcomes. As their subtitle indicates (“A response to the comments on our comment”), this is a topic of some controversy. Lindquist and Sobel write:
  
Our original comment (Lindquist and Sobel, 2011) made explicit the types of assumptions neuroimaging researchers are making when directed graphical models (DGMs), which include certain types of structural equation models (SEMs), are used to estimate causal effects. When these assumptions, which many researchers are not aware of, are not met, parameters of these models should not be interpreted as effects. . . . [Judea] Pearl does not disagree with anything we stated. However, he takes exception to our use of potential outcomes notation, which is the standard notation used in the statistical literature on causal inference, and his comment is devoted to promoting his alternative conventions. [C</p><p>6 0.14610684 <a title="1133-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-15-New_prize_on_causality_in_statstistics_education.html">1624 andrew gelman stats-2012-12-15-New prize on causality in statstistics education</a></p>
<p>7 0.11754167 <a title="1133-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-New_journal_on_causal_inference.html">879 andrew gelman stats-2011-08-29-New journal on causal inference</a></p>
<p>8 0.10463364 <a title="1133-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-30-The_Roy_causal_model%3F.html">1962 andrew gelman stats-2013-07-30-The Roy causal model?</a></p>
<p>9 0.094521523 <a title="1133-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-15-%E2%80%9C10_Things_You_Need_to_Know_About_Causal_Effects%E2%80%9D.html">1675 andrew gelman stats-2013-01-15-“10 Things You Need to Know About Causal Effects”</a></p>
<p>10 0.092505738 <a title="1133-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>11 0.0885977 <a title="1133-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-11-How_do_we_evaluate_a_new_and_wacky_claim%3F.html">797 andrew gelman stats-2011-07-11-How do we evaluate a new and wacky claim?</a></p>
<p>12 0.085910723 <a title="1133-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-23-Combining_survey_data_obtained_using_different_modes_of_sampling.html">777 andrew gelman stats-2011-06-23-Combining survey data obtained using different modes of sampling</a></p>
<p>13 0.082149774 <a title="1133-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-03-is_it_possible_to_%E2%80%9Coverstratify%E2%80%9D_when_assigning_a_treatment_in_a_randomized_control_trial%3F.html">553 andrew gelman stats-2011-02-03-is it possible to “overstratify” when assigning a treatment in a randomized control trial?</a></p>
<p>14 0.081803642 <a title="1133-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-30-David_Hogg_on_statistics.html">1401 andrew gelman stats-2012-06-30-David Hogg on statistics</a></p>
<p>15 0.075899608 <a title="1133-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-30-Query_from_a_textbook_author_%E2%80%93_looking_for_stories_to_tell_to_undergrads_about_significance.html">2044 andrew gelman stats-2013-09-30-Query from a textbook author – looking for stories to tell to undergrads about significance</a></p>
<p>16 0.075465567 <a title="1133-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-22-Battle_of_the_Repo_Man_quotes%3A__Reid_Hastie%E2%80%99s_turn.html">1336 andrew gelman stats-2012-05-22-Battle of the Repo Man quotes:  Reid Hastie’s turn</a></p>
<p>17 0.075437307 <a title="1133-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Toward_a_framework_for_automatic_model_building.html">1718 andrew gelman stats-2013-02-11-Toward a framework for automatic model building</a></p>
<p>18 0.075018764 <a title="1133-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-01-Martin_and_Liu%3A__Probabilistic_inference_based_on_consistency_of_model_with_data.html">1095 andrew gelman stats-2012-01-01-Martin and Liu:  Probabilistic inference based on consistency of model with data</a></p>
<p>19 0.073871359 <a title="1133-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-15-Forward_causal_reasoning_statements_are_about_estimation%3B_reverse_causal_questions_are_about_model_checking_and_hypothesis_generation.html">1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</a></p>
<p>20 0.073643245 <a title="1133-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.116), (1, 0.043), (2, -0.012), (3, -0.024), (4, -0.051), (5, 0.006), (6, -0.015), (7, 0.019), (8, 0.064), (9, -0.026), (10, -0.04), (11, 0.0), (12, 0.016), (13, 0.003), (14, 0.01), (15, 0.027), (16, 0.036), (17, 0.015), (18, -0.045), (19, 0.064), (20, -0.039), (21, -0.02), (22, 0.035), (23, 0.027), (24, 0.07), (25, 0.14), (26, 0.022), (27, -0.017), (28, -0.042), (29, 0.017), (30, -0.005), (31, -0.04), (32, -0.05), (33, 0.034), (34, -0.057), (35, -0.043), (36, 0.025), (37, -0.011), (38, 0.005), (39, -0.001), (40, -0.031), (41, -0.017), (42, 0.027), (43, -0.061), (44, -0.042), (45, 0.035), (46, 0.001), (47, 0.048), (48, -0.06), (49, -0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96442598 <a title="1133-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Judea_Pearl_on_why_he_is_%E2%80%9Conly_a_half-Bayesian%E2%80%9D.html">1133 andrew gelman stats-2012-01-21-Judea Pearl on why he is “only a half-Bayesian”</a></p>
<p>Introduction: In  an article  published in 2001, Pearl wrote:
  
I [Pearl] turned Bayesian in 1971, as soon as I began reading Savage’s monograph The Foundations of Statistical Inference [Savage, 1962]. The arguments were unassailable: (i) It is plain silly to ignore what we know, (ii) It is natural and useful to cast what we know in the language of probabilities, and (iii) If our subjective probabilities are erroneous, their impact will get washed out in due time, as the number of observations increases.


Thirty years later, I [Pearl] am still a devout Bayesian in the sense of (i), but I now doubt the wisdom of (ii) and I know that, in general, (iii) is false.
  
He elaborates:
  
The bulk of human knowledge is organized around causal, not probabilistic relationships, and the grammar of probability calculus is insufficient for capturing those relationships. Specifically, the building blocks of our scientific and everyday knowledge are elementary facts such as “mud does not cause rain” and “symptom</p><p>2 0.78474051 <a title="1133-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-15-%E2%80%9C10_Things_You_Need_to_Know_About_Causal_Effects%E2%80%9D.html">1675 andrew gelman stats-2013-01-15-“10 Things You Need to Know About Causal Effects”</a></p>
<p>Introduction: Macartan Humphreys pointed me to  this excellent guide .
 
Here are the 10 items:
  
1. A causal claim is a statement about what didn’t happen. 
2. There is a fundamental problem of causal inference. 
3. You can estimate average causal effects even if you cannot observe any individual causal effects. 
4. If you know that, on average, A causes B and that B causes C, this does not mean that you know that A causes C. 
5. The counterfactual model is all about contribution, not attribution. 
6. X can cause Y even if there is no “causal path” connecting X and Y. 
7. Correlation is not causation. 
8. X can cause Y even if X is not a necessary condition or a sufficient condition for Y. 
9. Estimating average causal effects does not require that treatment and control groups are identical. 
10. There is no causation without manipulation.
  
The  article  follows with crisp discussions of each point.  My favorite is item #6, not because it’s the most important but because it brings in some real s</p><p>3 0.7570945 <a title="1133-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-08-New_Judea_Pearl_journal_of_causal_inference.html">1888 andrew gelman stats-2013-06-08-New Judea Pearl journal of causal inference</a></p>
<p>Introduction: Pearl reports that his Journal of Causal Inference has just posted its  first issue , which contains a mix of theoretical and applied papers.  Pearl writes that they welcome submissions on all aspects of causal inference.</p><p>4 0.74091828 <a title="1133-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-22-Battle_of_the_Repo_Man_quotes%3A__Reid_Hastie%E2%80%99s_turn.html">1336 andrew gelman stats-2012-05-22-Battle of the Repo Man quotes:  Reid Hastie’s turn</a></p>
<p>Introduction: In response to my comments on his recent opinion article on the the human tendency to overvalue information presented as stories, Reid Hastie  writes :
  
Andrew (and Commenters) … I’d like to try to clarify some of the statements and implications in my Bloomberg article on “Our Gift for Good Stories …”  The essay is what it is, but some of the implications that I intended to convey do not seem to have been communicated effectively.  So, let me take a shot at clarification here.  (Of course I am not assuming that, once clarified, my statements are necessarily correct or that you will agree with them.)


1.  What I meant in the sections of the paper that claimed the brain is naturally good at visual and causal (narrative) thinking, is that that the brain was probably selected, through evolutionary processes to be adaptively successful at those capacities.  I don’t have good evidence for this claim … but, we do a lot of those kinds of thinking, we’re distinctive as a species in the ways</p><p>5 0.73236263 <a title="1133-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-23-Fight%21__%28also_a_bit_of_reminiscence_at_the_end%29.html">1136 andrew gelman stats-2012-01-23-Fight!  (also a bit of reminiscence at the end)</a></p>
<p>Introduction: Martin Lindquist and Michael Sobel published a  fun little article  in Neuroimage on models and assumptions for causal inference with intermediate outcomes. As their subtitle indicates (“A response to the comments on our comment”), this is a topic of some controversy. Lindquist and Sobel write:
  
Our original comment (Lindquist and Sobel, 2011) made explicit the types of assumptions neuroimaging researchers are making when directed graphical models (DGMs), which include certain types of structural equation models (SEMs), are used to estimate causal effects. When these assumptions, which many researchers are not aware of, are not met, parameters of these models should not be interpreted as effects. . . . [Judea] Pearl does not disagree with anything we stated. However, he takes exception to our use of potential outcomes notation, which is the standard notation used in the statistical literature on causal inference, and his comment is devoted to promoting his alternative conventions. [C</p><p>6 0.72448391 <a title="1133-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>7 0.71109426 <a title="1133-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-11-Using_the_%E2%80%9Cinstrumental_variables%E2%80%9D_or_%E2%80%9Cpotential_outcomes%E2%80%9D_approach_to_clarify_causal_thinking.html">1492 andrew gelman stats-2012-09-11-Using the “instrumental variables” or “potential outcomes” approach to clarify causal thinking</a></p>
<p>8 0.70692474 <a title="1133-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-15-Forward_causal_reasoning_statements_are_about_estimation%3B_reverse_causal_questions_are_about_model_checking_and_hypothesis_generation.html">1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</a></p>
<p>9 0.69812495 <a title="1133-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-All_inference_is_about_generalizing_from_sample_to_population.html">1996 andrew gelman stats-2013-08-24-All inference is about generalizing from sample to population</a></p>
<p>10 0.68680596 <a title="1133-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-New_journal_on_causal_inference.html">879 andrew gelman stats-2011-08-29-New journal on causal inference</a></p>
<p>11 0.6670832 <a title="1133-lsi-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-13-Judea_Pearl_overview_on_causal_inference%2C_and_more_general_thoughts_on_the_reexpression_of_existing_methods_by_considering_their_implicit_assumptions.html">2170 andrew gelman stats-2014-01-13-Judea Pearl overview on causal inference, and more general thoughts on the reexpression of existing methods by considering their implicit assumptions</a></p>
<p>12 0.66664833 <a title="1133-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-08-Understanding_Simpson%E2%80%99s_paradox_using_a_graph.html">2286 andrew gelman stats-2014-04-08-Understanding Simpson’s paradox using a graph</a></p>
<p>13 0.65464097 <a title="1133-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-15-New_prize_on_causality_in_statstistics_education.html">1624 andrew gelman stats-2012-12-15-New prize on causality in statstistics education</a></p>
<p>14 0.6426062 <a title="1133-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-13-Randomized_experiments%2C_non-randomized_experiments%2C_and_observational_studies.html">340 andrew gelman stats-2010-10-13-Randomized experiments, non-randomized experiments, and observational studies</a></p>
<p>15 0.63643503 <a title="1133-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-04-Estimating_the_effect_of_A_on_B%2C_and_also_the_effect_of_B_on_A.html">393 andrew gelman stats-2010-11-04-Estimating the effect of A on B, and also the effect of B on A</a></p>
<p>16 0.6333937 <a title="1133-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-17-Macro_causality.html">807 andrew gelman stats-2011-07-17-Macro causality</a></p>
<p>17 0.62949383 <a title="1133-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-20-Paul_Rosenbaum_on_those_annoying_pre-treatment_variables_that_are_sort-of_instruments_and_sort-of_covariates.html">287 andrew gelman stats-2010-09-20-Paul Rosenbaum on those annoying pre-treatment variables that are sort-of instruments and sort-of covariates</a></p>
<p>18 0.6119439 <a title="1133-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-02-An_IV_won%E2%80%99t_save_your_life_if_the_line_is_tangled.html">550 andrew gelman stats-2011-02-02-An IV won’t save your life if the line is tangled</a></p>
<p>19 0.60985303 <a title="1133-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-22-Evaluating_the_impacts_of_welfare_reform%3F.html">1732 andrew gelman stats-2013-02-22-Evaluating the impacts of welfare reform?</a></p>
<p>20 0.60934985 <a title="1133-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-11-Why_ask_why%3F_Forward_causal_inference_and_reverse_causal_questions.html">2097 andrew gelman stats-2013-11-11-Why ask why? Forward causal inference and reverse causal questions</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(8, 0.203), (15, 0.079), (16, 0.063), (21, 0.058), (22, 0.011), (24, 0.202), (40, 0.01), (43, 0.021), (59, 0.021), (81, 0.013), (84, 0.01), (86, 0.027), (89, 0.024), (99, 0.148)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93507415 <a title="1133-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-24-Samurai_sword-wielding_Mormon_bishop_pharmaceutical_statistician_stops_mugger.html">1822 andrew gelman stats-2013-04-24-Samurai sword-wielding Mormon bishop pharmaceutical statistician stops mugger</a></p>
<p>Introduction: Brett Keller points us to  this  feel-good story of the day:
  
A Samurai sword-wielding Mormon bishop helped a neighbor woman escape a Tuesday morning attack by a man who had been stalking her.


Kent Hendrix woke up Tuesday to his teenage son pounding on his bedroom door and telling him somebody was being mugged in front of their house. The 47-year-old father of six rushed out the door and grabbed the weapon closest to him — a 29-inch high carbon steel Samurai sword. . . .


Hendrix, a pharmaceutical statistician, was one of several neighbors who came to the woman’s aid after she began yelling for help . . .
  
Too bad the whole “statistician” thing got buried in the middle of the article.  Fair enough, though:  I don’t know what it takes to become a Mormon bishop, but I assume it’s more effort than what it takes to learn statistics.</p><p>same-blog 2 0.89278984 <a title="1133-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Judea_Pearl_on_why_he_is_%E2%80%9Conly_a_half-Bayesian%E2%80%9D.html">1133 andrew gelman stats-2012-01-21-Judea Pearl on why he is “only a half-Bayesian”</a></p>
<p>Introduction: In  an article  published in 2001, Pearl wrote:
  
I [Pearl] turned Bayesian in 1971, as soon as I began reading Savage’s monograph The Foundations of Statistical Inference [Savage, 1962]. The arguments were unassailable: (i) It is plain silly to ignore what we know, (ii) It is natural and useful to cast what we know in the language of probabilities, and (iii) If our subjective probabilities are erroneous, their impact will get washed out in due time, as the number of observations increases.


Thirty years later, I [Pearl] am still a devout Bayesian in the sense of (i), but I now doubt the wisdom of (ii) and I know that, in general, (iii) is false.
  
He elaborates:
  
The bulk of human knowledge is organized around causal, not probabilistic relationships, and the grammar of probability calculus is insufficient for capturing those relationships. Specifically, the building blocks of our scientific and everyday knowledge are elementary facts such as “mud does not cause rain” and “symptom</p><p>3 0.79928839 <a title="1133-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-18-Multimodality_in_hierarchical_models.html">916 andrew gelman stats-2011-09-18-Multimodality in hierarchical models</a></p>
<p>Introduction: Jim Hodges posted a note to the Bugs mailing list that I thought could be of more general interest: 
  
  
Is multi-modality a common experience?  I [Hodges] think the answer is “nobody knows in any generality”.  Here are some examples of bimodality that certainly do *not* involve the kind of labeling problems that arise in mixture models.


The only systematic study of multimodality I know of is 


Liu J, Hodges JS (2003).  Posterior bimodality in the balanced one-way random effects model.  J.~Royal Stat.~Soc., Ser.~B, 65:247-255.


The surprise of this paper is that in the simplest possible hierarchical model (analyzed using the standard inverse-gamma priors for the two variances), bimodality occurs quite readily, although it is much less common to have two modes that are big enough so that you’d actually get a noticeable fraction of MCMC draws from both of them.  Because the restricted likelihood (= the marginal posterior for the two variances, if you’ve put flat priors on them) is</p><p>4 0.79849648 <a title="1133-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-19-Whassup_with_deviance_having_a_high_posterior_correlation_with_a_parameter_in_the_model%3F.html">1221 andrew gelman stats-2012-03-19-Whassup with deviance having a high posterior correlation with a parameter in the model?</a></p>
<p>Introduction: Jean Richardson writes: 
  
  
Do you know what might lead to a large negative cross-correlation (-0.95) between deviance and one of the model parameters?


Here’s the (brief) background:


I [Richardson] have written a Bayesian hierarchical site occupancy model for presence of disease on individual amphibians. The response variable is therefore binary (disease present/absent) and the probability of disease being present in an individual (psi) depends on various covariates (species of amphibian, location sampled, etc.) paramaterized using a logit link function.  Replicates are individuals sampled (tested for presence of disease) together.  The possibility of imperfect detection is included as p = (prob. disease detected given disease is present).


Posterior distributions were estimated using WinBUGS via R2WinBUGS. 
Simulated data from the model fit the real data very well and posterior distribution densities seem robust to any changes in the model (different priors, etc.)  All autocor</p><p>5 0.79776728 <a title="1133-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-06-Josh_Tenenbaum_presents_._._._a_model_of_folk_physics%21.html">994 andrew gelman stats-2011-11-06-Josh Tenenbaum presents . . . a model of folk physics!</a></p>
<p>Introduction: Josh Tenenbaum describes some new work modeling people’s physical reasoning as probabilistic inferences over intuitive theories of mechanics. 
  
A general-purpose capacity for “physical intelligence”—inferring physical properties of objects and predicting future states in complex dynamical scenes—is central to how humans interpret their environment and plan safe and effective actions.  The computations and representations underlying physical intelligence remain unclear, however. Cognitive studies have focused on mapping out judgment biases and errors, or on testing simple heuristic models suitable only for highly specific cases; they have not attempted to give general-purpose unifying models.  In computer science, artificial intelligence and robotics researchers have long sought to formalize common-sense physical reasoning but without success in approaching human-level competence.  Here we show that a wide range of human physical judgments can be explained by positing an “intuitive me</p><p>6 0.79543191 <a title="1133-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>7 0.79432023 <a title="1133-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-14-Prior_distribution_for_design_effects.html">85 andrew gelman stats-2010-06-14-Prior distribution for design effects</a></p>
<p>8 0.79332328 <a title="1133-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-19-Sharon_Begley%3A__Worse_than_Stephen_Jay_Gould%3F.html">1128 andrew gelman stats-2012-01-19-Sharon Begley:  Worse than Stephen Jay Gould?</a></p>
<p>9 0.77935612 <a title="1133-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-27-One_way_that_psychology_research_is_different_than_medical_research.html">433 andrew gelman stats-2010-11-27-One way that psychology research is different than medical research</a></p>
<p>10 0.76988387 <a title="1133-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-Rob_Kass_on_statistical_pragmatism%2C_and_my_reactions.html">317 andrew gelman stats-2010-10-04-Rob Kass on statistical pragmatism, and my reactions</a></p>
<p>11 0.76941788 <a title="1133-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-22-The_kluges_of_today_are_the_textbook_solutions_of_tomorrow..html">2143 andrew gelman stats-2013-12-22-The kluges of today are the textbook solutions of tomorrow.</a></p>
<p>12 0.76449001 <a title="1133-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>13 0.76392996 <a title="1133-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-What_are_the_trickiest_models_to_fit%3F.html">575 andrew gelman stats-2011-02-15-What are the trickiest models to fit?</a></p>
<p>14 0.75506318 <a title="1133-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-19-Tradeoffs_in_information_graphics.html">1584 andrew gelman stats-2012-11-19-Tradeoffs in information graphics</a></p>
<p>15 0.75180137 <a title="1133-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-12-Too_tired_to_mock.html">1800 andrew gelman stats-2013-04-12-Too tired to mock</a></p>
<p>16 0.74959779 <a title="1133-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-13-Economists_._._..html">1378 andrew gelman stats-2012-06-13-Economists . . .</a></p>
<p>17 0.74827027 <a title="1133-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-04-Too_many_MC%E2%80%99s_not_enough_MIC%E2%80%99s%2C_or_What_principles_should_govern_attempts_to_summarize_bivariate_associations_in_large_multivariate_datasets%3F.html">1706 andrew gelman stats-2013-02-04-Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets?</a></p>
<p>18 0.74818122 <a title="1133-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-24-Latest_in_blog_advertising.html">1080 andrew gelman stats-2011-12-24-Latest in blog advertising</a></p>
<p>19 0.74772441 <a title="1133-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-13-Stan_at_NIPS_2012_Workshop_on_Probabilistic_Programming.html">1576 andrew gelman stats-2012-11-13-Stan at NIPS 2012 Workshop on Probabilistic Programming</a></p>
<p>20 0.74591184 <a title="1133-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
