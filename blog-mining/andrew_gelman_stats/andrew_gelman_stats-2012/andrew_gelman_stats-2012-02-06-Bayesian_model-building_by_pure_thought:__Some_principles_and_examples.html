<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1156 andrew gelman stats-2012-02-06-Bayesian model-building by pure thought:  Some principles and examples</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1156" href="#">andrew_gelman_stats-2012-1156</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1156 andrew gelman stats-2012-02-06-Bayesian model-building by pure thought:  Some principles and examples</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1156-html" href="http://andrewgelman.com/2012/02/06/bayesian-model-building-by-pure-thought-some-principles-and-examples/">html</a></p><p>Introduction: This  is one of my favorite papers:
  
In applications, statistical models are often restricted to what produces reasonable estimates based on the data at hand. In many cases, however, the principles that allow a model to be restricted can be derived theoretically, in the absence of any data and with minimal applied context. We illustrate this point with three well-known theoretical examples from spatial statistics and time series. First, we show that an autoregressive model for local averages violates a principle of invariance under scaling. Second, we show how the Bayesian estimate of a strictly-increasing time series, using a uniform prior distribution, depends on the scale of estimation. Third, we interpret local smoothing of spatial lattice data as Bayesian estimation and show why uniform local smoothing does not make sense. In various forms, the results presented here have been derived in previous work; our contribution is to draw out some principles that can be derived theoretic</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This  is one of my favorite papers:    In applications, statistical models are often restricted to what produces reasonable estimates based on the data at hand. [sent-1, score-0.5]
</p><p>2 In many cases, however, the principles that allow a model to be restricted can be derived theoretically, in the absence of any data and with minimal applied context. [sent-2, score-1.102]
</p><p>3 We illustrate this point with three well-known theoretical examples from spatial statistics and time series. [sent-3, score-0.505]
</p><p>4 First, we show that an autoregressive model for local averages violates a principle of invariance under scaling. [sent-4, score-1.044]
</p><p>5 Second, we show how the Bayesian estimate of a strictly-increasing time series, using a uniform prior distribution, depends on the scale of estimation. [sent-5, score-0.537]
</p><p>6 Third, we interpret local smoothing of spatial lattice data as Bayesian estimation and show why uniform local smoothing does not make sense. [sent-6, score-1.981]
</p><p>7 In various forms, the results presented here have been derived in previous work; our contribution is to draw out some principles that can be derived theoretically, even though in the past they may have been presented in detail in the context of specific examples. [sent-7, score-1.613]
</p><p>8 But itâ&euro;&trade;s only been cited 17 times (and four of those were by me), so I must have done something wrong. [sent-9, score-0.169]
</p><p>9 In retrospect I think it wouldâ&euro;&trade;ve made more sense to write it as three separate papers; then each might have had its own impact. [sent-10, score-0.297]
</p><p>10 In any case, I hope the article provides some enjoyment and insight to those of you who click through. [sent-11, score-0.413]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('derived', 0.322), ('smoothing', 0.254), ('theoretically', 0.25), ('local', 0.242), ('restricted', 0.237), ('spatial', 0.227), ('uniform', 0.201), ('show', 0.176), ('principles', 0.173), ('invariance', 0.16), ('presented', 0.157), ('autoregressive', 0.153), ('lattice', 0.148), ('enjoyment', 0.14), ('violates', 0.129), ('papers', 0.115), ('absence', 0.115), ('three', 0.11), ('produces', 0.109), ('minimal', 0.107), ('retrospect', 0.105), ('averages', 0.104), ('insight', 0.101), ('forms', 0.097), ('illustrate', 0.096), ('contribution', 0.095), ('cited', 0.094), ('click', 0.09), ('bayesian', 0.088), ('interpret', 0.088), ('detail', 0.088), ('depends', 0.087), ('draw', 0.086), ('favorite', 0.085), ('provides', 0.082), ('separate', 0.082), ('third', 0.081), ('principle', 0.08), ('applications', 0.08), ('estimation', 0.08), ('allow', 0.079), ('four', 0.075), ('previous', 0.075), ('scale', 0.073), ('theoretical', 0.072), ('series', 0.072), ('specific', 0.071), ('love', 0.069), ('data', 0.069), ('context', 0.067)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="1156-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-06-Bayesian_model-building_by_pure_thought%3A__Some_principles_and_examples.html">1156 andrew gelman stats-2012-02-06-Bayesian model-building by pure thought:  Some principles and examples</a></p>
<p>Introduction: This  is one of my favorite papers:
  
In applications, statistical models are often restricted to what produces reasonable estimates based on the data at hand. In many cases, however, the principles that allow a model to be restricted can be derived theoretically, in the absence of any data and with minimal applied context. We illustrate this point with three well-known theoretical examples from spatial statistics and time series. First, we show that an autoregressive model for local averages violates a principle of invariance under scaling. Second, we show how the Bayesian estimate of a strictly-increasing time series, using a uniform prior distribution, depends on the scale of estimation. Third, we interpret local smoothing of spatial lattice data as Bayesian estimation and show why uniform local smoothing does not make sense. In various forms, the results presented here have been derived in previous work; our contribution is to draw out some principles that can be derived theoretic</p><p>2 0.13600442 <a title="1156-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-06-Bootstrap_averaging%3A_Examples_where_it_works_and_where_it_doesn%E2%80%99t_work.html">2201 andrew gelman stats-2014-02-06-Bootstrap averaging: Examples where it works and where it doesn’t work</a></p>
<p>Introduction: Aki and I  write :
  
The very generality of the boostrap creates both opportunity and peril, allowing researchers to solve otherwise intractable problems but also sometimes leading to an answer with an inappropriately high level of certainty.


We demonstrate with two examples from our own research:  one problem where bootstrap smoothing was effective and led us to an improved method, and another case where bootstrap smoothing would not solve the underlying problem.  Our point in these examples is not to disparage bootstrapping but rather to gain insight into where it will be more or less effective as a smoothing tool.


 An example where bootstrap smoothing works well 


Bayesian posterior distributions are commonly summarized using Monte Carlo simulations, and inferences for scalar parameters or quantities of interest can be summarized using 50% or 95% intervals.  A   interval for a continuous quantity is typically constructed either as a central probability interval (with probabili</p><p>3 0.12337342 <a title="1156-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-17-How_to_map_geographically-detailed_survey_responses%3F.html">1124 andrew gelman stats-2012-01-17-How to map geographically-detailed survey responses?</a></p>
<p>Introduction: David Sparks writes:
  
I am experimenting with the mapping/visualization of survey response data, with a particular focus on using transparency to convey uncertainty. See some examples  here .


Do you think the examples are successful at communicating both local values of the variable of interest, as well as the lack of information in certain places? Also, do you have any general advice for choosing an approach to spatially smoothing the data in a way that preserves local features, but prevents individual respondents from standing out? I have experimented a lot with smoothing in these maps, and the cost of preventing the Midwest and West from looking “spotty” is the oversmoothing of the Northeast.
  
My quick impression is that the graphs are more pretty than they are informative.  But “pretty” is not such a bad thing!  The conveying-information part is more difficult:  to me, the graphs seem to be displaying a somewhat confusing mix of opinion level and population density.  Consider</p><p>4 0.10928909 <a title="1156-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-Another_reason_why_you_can_get_good_inferences_from_a_bad_model.html">1527 andrew gelman stats-2012-10-10-Another reason why you can get good inferences from a bad model</a></p>
<p>Introduction: John Cook  considers  how people justify probability distribution assumptions:
  
Sometimes distribution assumptions are not justified.


Sometimes distributions can be derived from fundamental principles [or] . . . on theoretical grounds. For example, large samples and the central limit theorem together may justify assuming that something is normally distributed.


Often the choice of distribution is somewhat arbitrary, chosen by intuition or for convenience, and then empirically shown to work well enough.


Sometimes a distribution can be a bad fit and still work well, depending on what you’re asking of it.
  
Cook continues:
  
The last point is particularly interesting. It’s not hard to imagine that a poor fit would produce poor results. It’s surprising when a poor fit produces good results.
  
And then he gives an example of an effective but inaccurate model used to model survival times in a clinical trial.  Cook explains:
  
The [poorly-fitting] method works well because of the q</p><p>5 0.10870104 <a title="1156-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-29-More_on_scaled-inverse_Wishart_and_prior_independence.html">1474 andrew gelman stats-2012-08-29-More on scaled-inverse Wishart and prior independence</a></p>
<p>Introduction: I’ve had a couple of email conversations in the past couple days on dependence in multivariate prior distributions.
 
 Modeling the degrees of freedom and scale parameters in the t distribution 
 
First, in our Stan group we’ve been discussing the choice of priors for the degrees-of-freedom parameter in the t distribution.  I wrote that also there’s the question of parameterization.  It does not necessarily make sense to have independent priors on the df and scale parameters.  In some sense, the meaning of the scale parameter changes with the df.
 
 Prior dependence between correlation and scale parameters in the scaled inverse-Wishart model 
 
The second case of parameterization in prior distribution arose from an email I received from Chris Chatham pointing me to  this exploration  by Matt Simpson of the scaled inverse-Wishart prior distribution for hierarchical covariance matrices.  Simpson writes:
  
A popular prior for Σ is the inverse-Wishart distribution [ not  the same as the</p><p>6 0.10660194 <a title="1156-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>7 0.1061359 <a title="1156-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>8 0.10239626 <a title="1156-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>9 0.10217573 <a title="1156-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-05-Watership_Down%2C_thick_description%2C_applied_statistics%2C_immutability_of_stories%2C_and_playing_tennis_with_a_net.html">1750 andrew gelman stats-2013-03-05-Watership Down, thick description, applied statistics, immutability of stories, and playing tennis with a net</a></p>
<p>10 0.096708991 <a title="1156-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-08-More_evidence_of_growing_nationalization_of_congressional_elections.html">508 andrew gelman stats-2011-01-08-More evidence of growing nationalization of congressional elections</a></p>
<p>11 0.096209683 <a title="1156-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>12 0.095188826 <a title="1156-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>13 0.095095649 <a title="1156-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>14 0.093591049 <a title="1156-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>15 0.092088118 <a title="1156-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-09-Besag.html">193 andrew gelman stats-2010-08-09-Besag</a></p>
<p>16 0.091606274 <a title="1156-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-27-Overfitting.html">1431 andrew gelman stats-2012-07-27-Overfitting</a></p>
<p>17 0.091589533 <a title="1156-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>18 0.089394137 <a title="1156-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>19 0.088350296 <a title="1156-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-05-Prior_distribution_for_a_predicted_probability.html">2200 andrew gelman stats-2014-02-05-Prior distribution for a predicted probability</a></p>
<p>20 0.088334456 <a title="1156-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-17-Somebody%E2%80%99s_looking_for_a_book_on_time_series_analysis_in_the_style_of_Angrist_and_Pischke%2C_or_Gelman_and_Hill.html">1986 andrew gelman stats-2013-08-17-Somebody’s looking for a book on time series analysis in the style of Angrist and Pischke, or Gelman and Hill</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.176), (1, 0.1), (2, -0.019), (3, 0.027), (4, -0.013), (5, -0.024), (6, -0.021), (7, 0.014), (8, -0.016), (9, 0.014), (10, 0.045), (11, -0.014), (12, -0.028), (13, 0.012), (14, -0.018), (15, 0.007), (16, 0.038), (17, -0.002), (18, -0.009), (19, -0.015), (20, 0.002), (21, 0.021), (22, -0.012), (23, 0.018), (24, 0.029), (25, 0.016), (26, -0.015), (27, -0.022), (28, 0.013), (29, 0.013), (30, 0.004), (31, -0.029), (32, -0.028), (33, -0.024), (34, 0.02), (35, 0.002), (36, -0.032), (37, -0.006), (38, 0.027), (39, 0.012), (40, 0.026), (41, 0.031), (42, -0.069), (43, -0.009), (44, -0.013), (45, -0.012), (46, 0.022), (47, -0.04), (48, 0.009), (49, 0.021)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96741086 <a title="1156-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-06-Bayesian_model-building_by_pure_thought%3A__Some_principles_and_examples.html">1156 andrew gelman stats-2012-02-06-Bayesian model-building by pure thought:  Some principles and examples</a></p>
<p>Introduction: This  is one of my favorite papers:
  
In applications, statistical models are often restricted to what produces reasonable estimates based on the data at hand. In many cases, however, the principles that allow a model to be restricted can be derived theoretically, in the absence of any data and with minimal applied context. We illustrate this point with three well-known theoretical examples from spatial statistics and time series. First, we show that an autoregressive model for local averages violates a principle of invariance under scaling. Second, we show how the Bayesian estimate of a strictly-increasing time series, using a uniform prior distribution, depends on the scale of estimation. Third, we interpret local smoothing of spatial lattice data as Bayesian estimation and show why uniform local smoothing does not make sense. In various forms, the results presented here have been derived in previous work; our contribution is to draw out some principles that can be derived theoretic</p><p>2 0.79085392 <a title="1156-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<p>Introduction: Deborah Mayo pointed me to  this discussion  by Christian Hennig of my recent  article  on Induction and Deduction in Bayesian Data Analysis.
 
A couple days ago I  responded  to comments by Mayo, Stephen Senn, and Larry Wasserman.  I will respond to Hennig by pulling out paragraphs from his discussion and then replying.
 
Hennig:
  
for me the terms “frequentist” and “subjective Bayes” point to interpretations of probability, and not to specific methods of inference. The frequentist one refers to the idea that there is an underlying data generating process that repeatedly throws out data and would approximate the assumed distribution if one could only repeat it infinitely often.
  
Hennig makes the good point that, if this is the way you would define “frequentist” (it’s not how I’d define the term myself, but I’ll use Hennig’s definition here), then it makes sense to be a frequentist in some settings but not others.  Dice really can be rolled over and over again; a sample survey of 15</p><p>3 0.78824145 <a title="1156-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>Introduction: I sent a copy of my paper (coauthored with Cosma Shalizi) on  Philosophy and the practice of Bayesian statistics in the social sciences  to  Richard Berk , who wrote:
  
I read your paper this morning. I think we are pretty much on the same page about all models being wrong. I like very much the way you handle this in the paper. Yes, Newton’s work is wrong, but surely useful. I also like your twist on Bayesian methods. Makes good sense to me. Perhaps most important, your paper raises some difficult issues I have been trying to think more carefully about.


1. If the goal of a model is to be useful, surely we need to explore that “useful” means. At the very least, usefulness will depend on use. So a model that is useful for forecasting may or may not be useful for causal inference.


2. Usefulness will be a matter of degree. So that for each use we will need one or more metrics to represent how useful the model is. In what looks at first to be simple example, if the use is forecasting,</p><p>4 0.77408701 <a title="1156-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>Introduction: Robert Bell pointed me to  this post  by Brad De Long on Bayesian statistics, and then I also noticed  this  from Noah Smith, who wrote:
  
My impression is that although the Bayesian/Frequentist debate is interesting and intellectually fun, there’s really not much “there” there… despite being so-hip-right-now, Bayesian is not the Statistical Jesus.
  
I’m happy to see the discussion going in this direction.  Twenty-five years ago or so, when I got into this biz, there were some serious anti-Bayesian attitudes floating around in mainstream statistics.  Discussions in the journals sometimes devolved into debates of the form, “Bayesians:  knaves or fools?”.  You’d get all sorts of free-floating skepticism about any prior distribution at all, even while people were accepting without question (and doing theory on) logistic regressions, proportional hazards models, and all sorts of strong strong models.  (In the subfield of survey sampling, various prominent researchers would refuse to mode</p><p>5 0.76862109 <a title="1156-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-Transformations_for_non-normal_data.html">2176 andrew gelman stats-2014-01-19-Transformations for non-normal data</a></p>
<p>Introduction: Steve Peterson writes:
  
I recently submitted a proposal on applying a Bayesian analysis to gender comparisons on motivational constructs. I had an idea on how to improve the model I used and was hoping you could give me some feedback.


The data come from a survey based on 5-point Likert scales. Different constructs are measured for each student as scores derived from averaging a student’s responses on particular subsets of survey questions. (I suppose it is not uncontroversial to treat these scores as interval measures and would be interested to hear if you have any objections.) I am comparing genders on each construct. Researchers typically use t-tests to do so.


To use a Bayesian approach I applied the programs written in R and JAGS by John Kruschke for estimating the difference of means:


http://www.indiana.edu/~kruschke/BEST/


An issue in that analysis is that the distributions of student scores are not normal. There was skewness in some of the distributions and not always in</p><p>6 0.76619649 <a title="1156-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-15-The_UN_Plot_to_Force_Bayesianism_on_Unsuspecting_Americans_%28penalized_B-Spline_edition%29.html">2135 andrew gelman stats-2013-12-15-The UN Plot to Force Bayesianism on Unsuspecting Americans (penalized B-Spline edition)</a></p>
<p>7 0.76480901 <a title="1156-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-28-Understanding_simulations_in_terms_of_predictive_inference%3F.html">1287 andrew gelman stats-2012-04-28-Understanding simulations in terms of predictive inference?</a></p>
<p>8 0.76382536 <a title="1156-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<p>9 0.75724167 <a title="1156-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-17-Death%21.html">962 andrew gelman stats-2011-10-17-Death!</a></p>
<p>10 0.75724155 <a title="1156-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-27-Sampling_rate_of_human-scaled_time_series.html">112 andrew gelman stats-2010-06-27-Sampling rate of human-scaled time series</a></p>
<p>11 0.75566918 <a title="1156-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-Philosophy_of_Bayesian_statistics%3A_my_reactions_to_Hendry.html">1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</a></p>
<p>12 0.75452471 <a title="1156-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-11-Convergence_Monitoring_for_Non-Identifiable_and_Non-Parametric_Models.html">1374 andrew gelman stats-2012-06-11-Convergence Monitoring for Non-Identifiable and Non-Parametric Models</a></p>
<p>13 0.75334185 <a title="1156-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-23-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1868 andrew gelman stats-2013-05-23-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>14 0.75229496 <a title="1156-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>15 0.7518847 <a title="1156-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>16 0.75106549 <a title="1156-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-01-Peter_Huber%E2%80%99s_reflections_on_data_analysis.html">690 andrew gelman stats-2011-05-01-Peter Huber’s reflections on data analysis</a></p>
<p>17 0.75049919 <a title="1156-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>18 0.7482208 <a title="1156-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-Bayes_in_astronomy.html">1091 andrew gelman stats-2011-12-29-Bayes in astronomy</a></p>
<p>19 0.74798453 <a title="1156-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-07-Bayesian_hierarchical_model_for_the_prediction_of_soccer_results.html">20 andrew gelman stats-2010-05-07-Bayesian hierarchical model for the prediction of soccer results</a></p>
<p>20 0.74479651 <a title="1156-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-21-Everything_I_need_to_know_about_Bayesian_statistics%2C_I_learned_in_eight_schools..html">2180 andrew gelman stats-2014-01-21-Everything I need to know about Bayesian statistics, I learned in eight schools.</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.518), (24, 0.046), (79, 0.015), (89, 0.018), (98, 0.013), (99, 0.278)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99566931 <a title="1156-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-12-Where_are_the_larger-than-life_athletes%3F.html">1115 andrew gelman stats-2012-01-12-Where are the larger-than-life athletes?</a></p>
<p>Introduction: Jonathan Cantor  points  to this  poll  estimating rifle-armed QB Tim Tebow as America’s favorite pro athlete:
  
In an ESPN survey of 1,502 Americans age 12 or older, three percent identified Tebow as their favorite professional athlete.  Tebow finished in front of Kobe Bryant (2 percent), Aaron Rodgers (1.9 percent), Peyton Manning (1.8 percent), and Tom Brady (1.5 percent).
  
Amusing.  What this survey says to me is that there are no super-popular athletes who are active in America today.  Which actually sounds about right.  No Tiger Woods, no Magic Johnson, Muhammed Ali, John Elway, Pete Rose, Billie Jean King, etc etc.  Tebow is an amusing choice, people might as well pick him now while he’s still on top.  As a sports celeb, he’s like Bill Lee or the Refrigerator:  colorful and a solid pro athlete, but no superstar.
 
When you think about all the colorful superstar athletes of times gone by, it’s perhaps surprising that there’s nobody out there right now to play the role.  I supp</p><p>2 0.99394673 <a title="1156-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-16-Visualizations_of_NYPD_stop-and-frisk_data.html">1014 andrew gelman stats-2011-11-16-Visualizations of NYPD stop-and-frisk data</a></p>
<p>Introduction: Cathy O’Neil  organized  this visualization project  with NYPD stop-and-frisk data.  It’s part of the Data Without Borders project.  Unfortunately, because of legal restrictions I couldn’t send them the data Jeff, Alex, and I used in  our project  several years ago.</p><p>3 0.9931981 <a title="1156-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-21-Elevator_shame_is_a_two-way_street.html">528 andrew gelman stats-2011-01-21-Elevator shame is a two-way street</a></p>
<p>Introduction: Tyler Cowen  links  a  blog  by Samuel Arbesman mocking people who are so lazy that they take the elevator from 1 to 2.  This reminds me of my own annoyance about a guy who worked in my building and did  not  take the elevator.  (For the full story, go  here  and search on “elevator.”)</p><p>4 0.98885989 <a title="1156-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-07-Some_silly_things_you_%28didn%E2%80%99t%29_miss_by_not_reading_the_sister_blog.html">1659 andrew gelman stats-2013-01-07-Some silly things you (didn’t) miss by not reading the sister blog</a></p>
<p>Introduction: 1.   I have the least stressful job in America (duh) 
 
2.   B-school prof in a parody of short-term thinking 
 
3.   The academic clock 
 
4.   I guessed wrong 
 
5.   2012 Conceptual Development Lab Newsletter</p><p>5 0.98849022 <a title="1156-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-14-Desecration_of_valuable_real_estate.html">572 andrew gelman stats-2011-02-14-Desecration of valuable real estate</a></p>
<p>Introduction: Malecki asks:
  
Is  this  the worst infographic ever to appear in NYT?  USA Today is not something to aspire to.
  
To connect to some of our recent  themes , I agree this is a pretty horrible data display.  But it’s not bad as a series of images.  Considering the competition to be a cartoon or series of photos, these images aren’t so bad.
 
One issue, I think, is that designers get credit for creativity and originality (unusual color combinations!  Histogram bars shaped like mosques!) , which is often the opposite of what we want in a clear graph.  It’s Martin Amis vs. George Orwell all over again.</p><p>6 0.98816913 <a title="1156-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-06-Picking_on_Stephen_Wolfram.html">1304 andrew gelman stats-2012-05-06-Picking on Stephen Wolfram</a></p>
<p>7 0.98327589 <a title="1156-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-22-I%E2%80%99m_officially_no_longer_a_%E2%80%9Crogue%E2%80%9D.html">1180 andrew gelman stats-2012-02-22-I’m officially no longer a “rogue”</a></p>
<p>8 0.97730958 <a title="1156-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-05-How_do_segregation_measures_change_when_you_change_the_level_of_aggregation%3F.html">1366 andrew gelman stats-2012-06-05-How do segregation measures change when you change the level of aggregation?</a></p>
<p>9 0.97304261 <a title="1156-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-24-ESPN_is_looking_to_hire_a_research_analyst.html">1279 andrew gelman stats-2012-04-24-ESPN is looking to hire a research analyst</a></p>
<p>10 0.97085905 <a title="1156-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-08-Animated_drought_maps.html">1487 andrew gelman stats-2012-09-08-Animated drought maps</a></p>
<p>11 0.96377981 <a title="1156-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-19-Cross-validation_to_check_missing-data_imputation.html">1330 andrew gelman stats-2012-05-19-Cross-validation to check missing-data imputation</a></p>
<p>12 0.95297968 <a title="1156-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-30-A_graphics_talk_with_no_visuals%21.html">1598 andrew gelman stats-2012-11-30-A graphics talk with no visuals!</a></p>
<p>13 0.95293838 <a title="1156-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-24-Always_check_your_evidence.html">1025 andrew gelman stats-2011-11-24-Always check your evidence</a></p>
<p>14 0.9505055 <a title="1156-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-03-Getting_a_job_in_pro_sports%E2%80%A6_as_a_statistician.html">445 andrew gelman stats-2010-12-03-Getting a job in pro sports… as a statistician</a></p>
<p>15 0.93792325 <a title="1156-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Quote_of_the_day.html">398 andrew gelman stats-2010-11-06-Quote of the day</a></p>
<p>16 0.93728703 <a title="1156-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-06-Suspicious_pattern_of_too-strong_replications_of_medical_research.html">700 andrew gelman stats-2011-05-06-Suspicious pattern of too-strong replications of medical research</a></p>
<p>17 0.93507427 <a title="1156-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-25-Bayes_wikipedia_update.html">1026 andrew gelman stats-2011-11-25-Bayes wikipedia update</a></p>
<p>same-blog 18 0.92898536 <a title="1156-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-06-Bayesian_model-building_by_pure_thought%3A__Some_principles_and_examples.html">1156 andrew gelman stats-2012-02-06-Bayesian model-building by pure thought:  Some principles and examples</a></p>
<p>19 0.92442513 <a title="1156-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-14-The_tabloids_strike_again.html">1168 andrew gelman stats-2012-02-14-The tabloids strike again</a></p>
<p>20 0.92162591 <a title="1156-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-01-Do_you_own_anything_that_was_manufactured_in_the_1950s_and_still_is_in_regular%2C_active_use_in_your_life%3F.html">387 andrew gelman stats-2010-11-01-Do you own anything that was manufactured in the 1950s and still is in regular, active use in your life?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
