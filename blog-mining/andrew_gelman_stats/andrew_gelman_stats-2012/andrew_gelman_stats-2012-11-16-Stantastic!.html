<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1580 andrew gelman stats-2012-11-16-Stantastic!</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1580" href="#">andrew_gelman_stats-2012-1580</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1580 andrew gelman stats-2012-11-16-Stantastic!</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1580-html" href="http://andrewgelman.com/2012/11/16/stantastic/">html</a></p><p>Introduction: Richard McElreath writes:
  
I’ve been translating a few ongoing data analysis projects into  Stan  code, mostly with success. The most important for me right now has been a hierarchical zero-inflated gamma problem. This a “hurdle” model, in which a bernoulli GLM produces zeros/nonzeros, and then a gamma GLM produces the nonzero values, using varying effects correlated with those in the bernoulli process.


The data are 20 years of human foraging returns from a subsistence hunting population in Paraguay (the Ache), comprising about 15k hunts in total (Hill & Kintigh. 2009. Current Anthropology 50:369-377). Observed values are kilograms of meat returned to camp. The more complex models contain a 147-by-9 matrix of varying effects (147 unique hunters), as well as imputation of missing values.


Originally, I had written the sampler myself in raw R code. It was very slow, but I knew what it was doing at least. Just before Stan version 1.0 was released, I had managed to get JAGS to do it a</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The most important for me right now has been a hierarchical zero-inflated gamma problem. [sent-2, score-0.13]
</p><p>2 This a “hurdle” model, in which a bernoulli GLM produces zeros/nonzeros, and then a gamma GLM produces the nonzero values, using varying effects correlated with those in the bernoulli process. [sent-3, score-0.989]
</p><p>3 The data are 20 years of human foraging returns from a subsistence hunting population in Paraguay (the Ache), comprising about 15k hunts in total (Hill & Kintigh. [sent-4, score-0.342]
</p><p>4 Observed values are kilograms of meat returned to camp. [sent-7, score-0.138]
</p><p>5 The more complex models contain a 147-by-9 matrix of varying effects (147 unique hunters), as well as imputation of missing values. [sent-8, score-0.225]
</p><p>6 Originally, I had written the sampler myself in raw R code. [sent-9, score-0.119]
</p><p>7 0 was released, I had managed to get JAGS to do it all quite reliably. [sent-12, score-0.12]
</p><p>8 Stan produces the same inferences as my JAGS code does, but with 8 hour runs (no thinning needed) instead of 30 hour runs (with massive thinning). [sent-16, score-0.82]
</p><p>9 In the future, I should be getting similar data for about a dozen other foraging populations, so will want to scale this up to a meta-analytic level, with partial pooling across societies. [sent-17, score-0.293]
</p><p>10 On the horizon, I have a harder project I’d like to port into Stan, involving cumulative multi-normal likelihoods. [sent-19, score-0.161]
</p><p>11 I wrote my own sampler, using likelihoods from pmvnorm in the mvtnorm package, but it mixes very slowly, once all the varying effects are included. [sent-20, score-0.79]
</p><p>12 Is there a clever way to get the same likelihoods in Stan yet? [sent-21, score-0.128]
</p><p>13 If not, once you have a guide prepared for how to compile in new distributions, I can probably use that to hack mvtnorm’s pmvnorm into Stan. [sent-22, score-0.258]
</p><p>14 I’m pretty sure that with some vectorization and other steps, he can get his model to run in much less than 8 hours in Stan. [sent-23, score-0.143]
</p><p>15 And Lucas Leeman writes:    I just wanted to say thank you for Stan! [sent-25, score-0.164]
</p><p>16 I had this problem with a very slow mixing chain and I have finally managed to get Stan to do what I want. [sent-27, score-0.224]
</p><p>17 With the mock example I am playing Stan drastically outperforms the software I was using before. [sent-28, score-0.148]
</p><p>18 A few years ago, I had the attitude that I could fit a model in Bugs, and if that didn’t work I could program it myself. [sent-31, score-0.145]
</p><p>19 Fitting a model in Stan is essentially the same as programming it myself, except that the program has already been optimized and debugged, thus combining the convenience of Bugs with the efficiency of compiled code. [sent-33, score-0.394]
</p><p>20 Also, again we thank the Department of Energy, Institute for Education Sciences, and National Science Foundation for partial support of this project. [sent-34, score-0.265]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('stan', 0.418), ('foraging', 0.192), ('pmvnorm', 0.192), ('jags', 0.19), ('mvtnorm', 0.175), ('thinning', 0.175), ('produces', 0.169), ('thank', 0.164), ('bugs', 0.157), ('bernoulli', 0.148), ('varying', 0.144), ('gamma', 0.13), ('glm', 0.13), ('likelihoods', 0.128), ('managed', 0.12), ('sampler', 0.119), ('efficiency', 0.105), ('slow', 0.104), ('runs', 0.101), ('partial', 0.101), ('hour', 0.099), ('port', 0.087), ('hunters', 0.087), ('mcelreath', 0.087), ('debugged', 0.087), ('horizon', 0.082), ('leeman', 0.082), ('effects', 0.081), ('translating', 0.079), ('drastically', 0.079), ('code', 0.076), ('comprising', 0.076), ('hurdle', 0.076), ('anthropology', 0.076), ('program', 0.076), ('project', 0.074), ('announcing', 0.074), ('vectorization', 0.074), ('optimized', 0.074), ('hunting', 0.074), ('lucas', 0.074), ('values', 0.072), ('compiled', 0.07), ('mixes', 0.07), ('model', 0.069), ('outperforms', 0.069), ('compile', 0.066), ('converge', 0.066), ('meat', 0.066), ('inefficient', 0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="1580-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-16-Stantastic%21.html">1580 andrew gelman stats-2012-11-16-Stantastic!</a></p>
<p>Introduction: Richard McElreath writes:
  
I’ve been translating a few ongoing data analysis projects into  Stan  code, mostly with success. The most important for me right now has been a hierarchical zero-inflated gamma problem. This a “hurdle” model, in which a bernoulli GLM produces zeros/nonzeros, and then a gamma GLM produces the nonzero values, using varying effects correlated with those in the bernoulli process.


The data are 20 years of human foraging returns from a subsistence hunting population in Paraguay (the Ache), comprising about 15k hunts in total (Hill & Kintigh. 2009. Current Anthropology 50:369-377). Observed values are kilograms of meat returned to camp. The more complex models contain a 147-by-9 matrix of varying effects (147 unique hunters), as well as imputation of missing values.


Originally, I had written the sampler myself in raw R code. It was very slow, but I knew what it was doing at least. Just before Stan version 1.0 was released, I had managed to get JAGS to do it a</p><p>2 0.32029936 <a title="1580-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-A_Stan_is_Born.html">1475 andrew gelman stats-2012-08-30-A Stan is Born</a></p>
<p>Introduction: Stan 1.0.0 and RStan 1.0.0 
 
It’s official.  The Stan Development Team is happy to announce the first stable versions of Stan and RStan.  
 
 What is (R)Stan? 
 
Stan is an open-source package for obtaining Bayesian inference using the No-U-Turn sampler, a variant of Hamiltonian Monte Carlo.  It’s sort of like BUGS, but with a different language for expressing models and a different sampler for sampling from their posteriors. 
 
RStan is the R interface to Stan.  
 
 Stan Home Page 
 
Stan’s home page is:     http://mc-stan.org/    
 
It links everything you need to get started running Stan from the command line, from R, or from C++, including full step-by-step install instructions, a detailed user’s guide and reference manual for the modeling language, and tested ports of most of the BUGS examples.
 
 Peruse the Manual 
 
If you’d like to learn more, the   Stan User’s Guide and Reference Manual   is the place to start.</p><p>3 0.25857335 <a title="1580-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-14-Transitioning_to_Stan.html">2291 andrew gelman stats-2014-04-14-Transitioning to Stan</a></p>
<p>Introduction: Kevin Cartier writes:
  
I’ve been happily using R for a number of years now and recently came across Stan. Looks big and powerful, so I’d like to pick an appropriate project and try it out. I wondered if you could point me to a link or document that goes into the motivation for this tool (aside from the Stan user doc)?  What I’d like to understand is, at what point might you look at an emergent R project and advise, “You know, that thing you’re trying to do would be a whole lot easier/simpler/more straightforward to implement with Stan.” (or words to that effect).
  
My reply:  For my collaborators in political science, Stan has been most useful for models where the data set is not huge (e.g., we might have 10,000 data points or 50,000 data points but not 10 million) but where the model is somewhat complex (for example, a model with latent time series structure).  The point is that the model has enough parameters and uncertainty that you’ll want to do full Bayes (rather than some sort</p><p>4 0.23778529 <a title="1580-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-04-PyStan%21.html">1748 andrew gelman stats-2013-03-04-PyStan!</a></p>
<p>Introduction: Stan  is written in C++ and can be run from the command line and from R.  We’d like for  Python  users to be able to run Stan as well.  If anyone is interested in doing this, please let us know and we’d be happy to work with you on it.
 
Stan, like Python, is completely free and open-source.
 
P.S.  Because Stan is open-source, it of course would also be possible for people to translate Stan into Python, or to take whatever features they like from Stan and incorporate them into a Python package.  That’s fine too.  But we think it would make sense in addition for users to be able to run Stan directly from Python, in the same way that it can be run from R.</p><p>5 0.2181382 <a title="1580-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-22-My_talks_that_were_scheduled_for_Tues_at_the_Data_Skeptics_meetup_and_Wed_at_the_Open_Statistical_Programming_meetup.html">1950 andrew gelman stats-2013-07-22-My talks that were scheduled for Tues at the Data Skeptics meetup and Wed at the Open Statistical Programming meetup</a></p>
<p>Introduction: Statistical Methods and Data Skepticism 
  
Data analysis today is dominated by three paradigms:  null hypothesis significance testing, Bayesian inference, and exploratory data analysis.  There is concern that all these methods lead to overconfidence on the part of researchers and the general public, and this concern has led to the new “data skepticism” movement.


But the history of statistics is already in some sense a history of data skepticism.  Concepts of bias, variance, sampling and measurement error, least-squares regression, and statistical significance can all be viewed as formalizations of data skepticism.  All these methods address the concern that patterns in observed data might not generalize to the population of interest.


We discuss the challenge of attaining data skepticism while avoiding data nihilism, and consider some proposed future directions.
  
 Stan 
  
Stan (mc-stan.org) is an open-source package for obtaining Bayesian inference using the No-U-Turn sampler, a</p><p>6 0.21699868 <a title="1580-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-07-My_recent_debugging_experience.html">2161 andrew gelman stats-2014-01-07-My recent debugging experience</a></p>
<p>7 0.21559866 <a title="1580-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-13-Stan%21.html">1855 andrew gelman stats-2013-05-13-Stan!</a></p>
<p>8 0.18721765 <a title="1580-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-27-%28R-Py-Cmd%29Stan_2.1.0.html">2150 andrew gelman stats-2013-12-27-(R-Py-Cmd)Stan 2.1.0</a></p>
<p>9 0.18330847 <a title="1580-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-17-Stan_and_RStan_1.1.0.html">1627 andrew gelman stats-2012-12-17-Stan and RStan 1.1.0</a></p>
<p>10 0.1738185 <a title="1580-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-07-Robust_logistic_regression.html">1886 andrew gelman stats-2013-06-07-Robust logistic regression</a></p>
<p>11 0.16606307 <a title="1580-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-My_talk_at_MIT_on_Thurs_11_Oct.html">1528 andrew gelman stats-2012-10-10-My talk at MIT on Thurs 11 Oct</a></p>
<p>12 0.15755974 <a title="1580-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-04-Stan_%28%26_JAGS%29_Tutorial_on_Linear_Mixed_Models.html">2318 andrew gelman stats-2014-05-04-Stan (& JAGS) Tutorial on Linear Mixed Models</a></p>
<p>13 0.1534185 <a title="1580-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-27-In_Linux%2C_use_jags%28%29_to_call_Jags_instead_of_using_bugs%28%29_to_call_OpenBugs.html">55 andrew gelman stats-2010-05-27-In Linux, use jags() to call Jags instead of using bugs() to call OpenBugs</a></p>
<p>14 0.15188004 <a title="1580-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-07-Martyn_Plummer%E2%80%99s_Secret_JAGS_Blog.html">1045 andrew gelman stats-2011-12-07-Martyn Plummer’s Secret JAGS Blog</a></p>
<p>15 0.14812312 <a title="1580-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-10-Schiminovich_is_on_The_Simpsons.html">2096 andrew gelman stats-2013-11-10-Schiminovich is on The Simpsons</a></p>
<p>16 0.14698091 <a title="1580-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-05-Stan_%28quietly%29_passes_512_people_on_the_users_list.html">2124 andrew gelman stats-2013-12-05-Stan (quietly) passes 512 people on the users list</a></p>
<p>17 0.14692231 <a title="1580-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-13-CmdStan%2C_RStan%2C_PyStan_v2.2.0.html">2209 andrew gelman stats-2014-02-13-CmdStan, RStan, PyStan v2.2.0</a></p>
<p>18 0.14237456 <a title="1580-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-21-Stan_Model_of_the_Week%3A_Hierarchical_Modeling_of_Supernovas.html">2299 andrew gelman stats-2014-04-21-Stan Model of the Week: Hierarchical Modeling of Supernovas</a></p>
<p>19 0.14078894 <a title="1580-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-30-Stan_uses_Nuts%21.html">1036 andrew gelman stats-2011-11-30-Stan uses Nuts!</a></p>
<p>20 0.13435419 <a title="1580-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-Scalable_Stan.html">2035 andrew gelman stats-2013-09-23-Scalable Stan</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.157), (1, 0.085), (2, -0.026), (3, 0.077), (4, 0.128), (5, 0.12), (6, 0.001), (7, -0.269), (8, -0.084), (9, -0.092), (10, -0.164), (11, -0.001), (12, -0.1), (13, -0.075), (14, 0.095), (15, -0.014), (16, -0.028), (17, 0.06), (18, -0.031), (19, 0.008), (20, -0.028), (21, 0.005), (22, -0.086), (23, -0.013), (24, -0.015), (25, -0.032), (26, 0.004), (27, -0.033), (28, -0.075), (29, 0.006), (30, -0.006), (31, -0.016), (32, 0.003), (33, -0.002), (34, -0.003), (35, 0.06), (36, 0.023), (37, 0.039), (38, 0.011), (39, -0.01), (40, -0.001), (41, 0.014), (42, -0.007), (43, -0.028), (44, -0.005), (45, -0.045), (46, 0.001), (47, -0.019), (48, -0.017), (49, 0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97198957 <a title="1580-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-16-Stantastic%21.html">1580 andrew gelman stats-2012-11-16-Stantastic!</a></p>
<p>Introduction: Richard McElreath writes:
  
I’ve been translating a few ongoing data analysis projects into  Stan  code, mostly with success. The most important for me right now has been a hierarchical zero-inflated gamma problem. This a “hurdle” model, in which a bernoulli GLM produces zeros/nonzeros, and then a gamma GLM produces the nonzero values, using varying effects correlated with those in the bernoulli process.


The data are 20 years of human foraging returns from a subsistence hunting population in Paraguay (the Ache), comprising about 15k hunts in total (Hill & Kintigh. 2009. Current Anthropology 50:369-377). Observed values are kilograms of meat returned to camp. The more complex models contain a 147-by-9 matrix of varying effects (147 unique hunters), as well as imputation of missing values.


Originally, I had written the sampler myself in raw R code. It was very slow, but I knew what it was doing at least. Just before Stan version 1.0 was released, I had managed to get JAGS to do it a</p><p>2 0.93857598 <a title="1580-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-A_Stan_is_Born.html">1475 andrew gelman stats-2012-08-30-A Stan is Born</a></p>
<p>Introduction: Stan 1.0.0 and RStan 1.0.0 
 
It’s official.  The Stan Development Team is happy to announce the first stable versions of Stan and RStan.  
 
 What is (R)Stan? 
 
Stan is an open-source package for obtaining Bayesian inference using the No-U-Turn sampler, a variant of Hamiltonian Monte Carlo.  It’s sort of like BUGS, but with a different language for expressing models and a different sampler for sampling from their posteriors. 
 
RStan is the R interface to Stan.  
 
 Stan Home Page 
 
Stan’s home page is:     http://mc-stan.org/    
 
It links everything you need to get started running Stan from the command line, from R, or from C++, including full step-by-step install instructions, a detailed user’s guide and reference manual for the modeling language, and tested ports of most of the BUGS examples.
 
 Peruse the Manual 
 
If you’d like to learn more, the   Stan User’s Guide and Reference Manual   is the place to start.</p><p>3 0.93784791 <a title="1580-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-27-%28R-Py-Cmd%29Stan_2.1.0.html">2150 andrew gelman stats-2013-12-27-(R-Py-Cmd)Stan 2.1.0</a></p>
<p>Introduction: We’re happy to announce the release of Stan C++, CmdStan, 
RStan, and PyStan 2.1.0.  This is a minor feature release, 
but it is also an important bug fix release.  As always, the 
place to start is the (all new) Stan web pages:
 
 http://mc-stan.org 
 
 
 
 Major Bug in 2.0.0, 2.0.1 
 
Stan 2.0.0 and Stan 2.0.1 introduced a bug in the implementation 
of the NUTS criterion that led to poor tail exploration and 
thus biased the posterior uncertainty downward.  There was no 
bug in NUTS in Stan 1.3 or earlier, and 2.1 has been extensively tested 
and tests put in place so this problem will not recur.
 
If you are using Stan 2.0.0 or 2.0.1, you should switch to 2.1.0 as 
soon as possible and rerun any models you care about.
 
 
 
 New Target Acceptance Rate Default for Stan 2.1.0 
  Another big change aimed at reducing posterior estimation bias 
was an increase in the target acceptance rate during adaptation 
from 0.65 to 0.80.  The bad news is that iterations will take 
around 50% longer</p><p>4 0.92419088 <a title="1580-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-04-PyStan%21.html">1748 andrew gelman stats-2013-03-04-PyStan!</a></p>
<p>Introduction: Stan  is written in C++ and can be run from the command line and from R.  We’d like for  Python  users to be able to run Stan as well.  If anyone is interested in doing this, please let us know and we’d be happy to work with you on it.
 
Stan, like Python, is completely free and open-source.
 
P.S.  Because Stan is open-source, it of course would also be possible for people to translate Stan into Python, or to take whatever features they like from Stan and incorporate them into a Python package.  That’s fine too.  But we think it would make sense in addition for users to be able to run Stan directly from Python, in the same way that it can be run from R.</p><p>5 0.91687042 <a title="1580-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-14-The_joys_of_working_in_the_public_domain.html">712 andrew gelman stats-2011-05-14-The joys of working in the public domain</a></p>
<p>Introduction: Stan will make a total lifetime profit of $0, so we canâ&euro;&trade;t be  sued !</p><p>6 0.91171318 <a title="1580-lsi-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-13-CmdStan%2C_RStan%2C_PyStan_v2.2.0.html">2209 andrew gelman stats-2014-02-13-CmdStan, RStan, PyStan v2.2.0</a></p>
<p>7 0.882819 <a title="1580-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-05-Stan_%28quietly%29_passes_512_people_on_the_users_list.html">2124 andrew gelman stats-2013-12-05-Stan (quietly) passes 512 people on the users list</a></p>
<p>8 0.87615609 <a title="1580-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-17-Stan_and_RStan_1.1.0.html">1627 andrew gelman stats-2012-12-17-Stan and RStan 1.1.0</a></p>
<p>9 0.87303072 <a title="1580-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-07-My_recent_debugging_experience.html">2161 andrew gelman stats-2014-01-07-My recent debugging experience</a></p>
<p>10 0.87296563 <a title="1580-lsi-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-14-Transitioning_to_Stan.html">2291 andrew gelman stats-2014-04-14-Transitioning to Stan</a></p>
<p>11 0.86756265 <a title="1580-lsi-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-04-Stan_%28%26_JAGS%29_Tutorial_on_Linear_Mixed_Models.html">2318 andrew gelman stats-2014-05-04-Stan (& JAGS) Tutorial on Linear Mixed Models</a></p>
<p>12 0.84933013 <a title="1580-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-30-Stan_uses_Nuts%21.html">1036 andrew gelman stats-2011-11-30-Stan uses Nuts!</a></p>
<p>13 0.83476835 <a title="1580-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-07-Stan_users_meetup_next_week.html">2325 andrew gelman stats-2014-05-07-Stan users meetup next week</a></p>
<p>14 0.83129025 <a title="1580-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-13-Stan_at_NIPS_2012_Workshop_on_Probabilistic_Programming.html">1576 andrew gelman stats-2012-11-13-Stan at NIPS 2012 Workshop on Probabilistic Programming</a></p>
<p>15 0.82935506 <a title="1580-lsi-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-10-Stan_Model_of_the_Week%3A__PK_Calculation_of_IV_and_Oral_Dosing.html">2242 andrew gelman stats-2014-03-10-Stan Model of the Week:  PK Calculation of IV and Oral Dosing</a></p>
<p>16 0.82196683 <a title="1580-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-13-Stan%21.html">1855 andrew gelman stats-2013-05-13-Stan!</a></p>
<p>17 0.81503904 <a title="1580-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-10-Schiminovich_is_on_The_Simpsons.html">2096 andrew gelman stats-2013-11-10-Schiminovich is on The Simpsons</a></p>
<p>18 0.80010051 <a title="1580-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-28-Migrating_from_dot_to_underscore.html">1472 andrew gelman stats-2012-08-28-Migrating from dot to underscore</a></p>
<p>19 0.77762389 <a title="1580-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-30-Stan_Project%3A__Continuous_Relaxations_for_Discrete_MRFs.html">2003 andrew gelman stats-2013-08-30-Stan Project:  Continuous Relaxations for Discrete MRFs</a></p>
<p>20 0.76624846 <a title="1580-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-12-Samplers_for_Big_Science%3A__emcee_and_BAT.html">2020 andrew gelman stats-2013-09-12-Samplers for Big Science:  emcee and BAT</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.02), (15, 0.011), (16, 0.064), (21, 0.038), (24, 0.164), (27, 0.021), (36, 0.042), (40, 0.018), (44, 0.02), (45, 0.02), (54, 0.012), (64, 0.015), (78, 0.117), (86, 0.026), (89, 0.071), (99, 0.203)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93614352 <a title="1580-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-16-Stantastic%21.html">1580 andrew gelman stats-2012-11-16-Stantastic!</a></p>
<p>Introduction: Richard McElreath writes:
  
I’ve been translating a few ongoing data analysis projects into  Stan  code, mostly with success. The most important for me right now has been a hierarchical zero-inflated gamma problem. This a “hurdle” model, in which a bernoulli GLM produces zeros/nonzeros, and then a gamma GLM produces the nonzero values, using varying effects correlated with those in the bernoulli process.


The data are 20 years of human foraging returns from a subsistence hunting population in Paraguay (the Ache), comprising about 15k hunts in total (Hill & Kintigh. 2009. Current Anthropology 50:369-377). Observed values are kilograms of meat returned to camp. The more complex models contain a 147-by-9 matrix of varying effects (147 unique hunters), as well as imputation of missing values.


Originally, I had written the sampler myself in raw R code. It was very slow, but I knew what it was doing at least. Just before Stan version 1.0 was released, I had managed to get JAGS to do it a</p><p>2 0.89966762 <a title="1580-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-15-The_it-gets-me-so-angry-I-can%E2%80%99t-deal-with-it_threshold.html">2025 andrew gelman stats-2013-09-15-The it-gets-me-so-angry-I-can’t-deal-with-it threshold</a></p>
<p>Introduction: I happened to be looking at Slate (I know, I know, but I’d already browsed Gawker and I was desperately avoiding doing real work) and came across this  article  by Alice Gregory entitled, “I Read Everything Janet Malcolm Ever Published. I’m in awe of her.”
 
I too think Malcolm is an excellent writer, but (a) I’m not happy that she gets off the hook for  faking quotes , and (b) I’m really really not happy with her  apparent attempt  to try to force a mistrial for a convicted killer.
 
I just can’t get over that, for some reason.  I can appreciate Picasso’s genius even though he beat his wives or whatever it was he did, I can enjoy the music of Jackson Browne, etc.  But for some reason this Malcolm stuff sticks in my craw.  There’s no deep meaning to this—I recognize it is a somewhat irrational attitude on my part, I just wanted to share it with you.</p><p>3 0.88920856 <a title="1580-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-03-Boot.html">1881 andrew gelman stats-2013-06-03-Boot</a></p>
<p>Introduction: Joshua Hartshorne writes: 
  
  
I ran several large-N experiments (separate participants) and looked at performance against age. What we want to do is compare age-of-peak-performance across the different tasks (again, different participants).


We bootstrapped age-of-peak-performance. On each iteration, we sampled (with replacement) the X scores at each age, where X=num of participants at that age, and recorded the age at which performance peaked on that task. We then recorded the age at which performance was at peak and repeated. Once we had distributions of age-of-peak-performance, we used the means and SDs to calculate t-statistics to compare the results across different tasks. For graphical presentation, we used medians, interquartile ranges, and 95% confidence intervals (based on the distributions: the range within which 75% and 95% of the bootstrapped peaks appeared). 


While a number of people we consulted with thought this made a lot of sense, one reviewer of the paper insist</p><p>4 0.88892227 <a title="1580-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-10-I_don%E2%80%99t_like_this_cartoon.html">1572 andrew gelman stats-2012-11-10-I don’t like this cartoon</a></p>
<p>Introduction: Some people pointed me to  this :
 
 
 
I am happy to see statistical theory and methods be a topic in popular culture, and of course I’m glad that, contra  Feller , the Bayesian is presented as the hero this time, but . . . . I think the lower-left panel of the cartoon unfairly misrepresents frequentist statisticians.
 
Frequentist statisticians recognize many statistical goals.  Point estimates trade off bias and variance.  Interval estimates have the goal of achieving nominal coverage and the goal of being informative.  Tests have the goals of calibration and power.  Frequentists know that no single principle applies in all settings, and this is a setting where this particular method is clearly inappropriate.  All statisticians use prior information in their statistical analysis.  Non-Bayesians express their prior information not through a probability distribution on parameters but rather through their choice of methods.  I think this non-Bayesian attitude is too restrictive, but in</p><p>5 0.88718218 <a title="1580-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-14-Pourquoi_Google_search_est_devenu_plus_raisonnable%3F.html">207 andrew gelman stats-2010-08-14-Pourquoi Google search est devenu plus raisonnable?</a></p>
<p>Introduction: A few months ago  I questioned Dan Ariely’s belief that Google is the voice of the people by reporting the following bizarre options that Google gave to complete the simplest search I could think of:
  

 
   
 
Several commenters gave informed discussions about what was going on in Google’s program.
 
Maybe things are better now, though?  The latest version seems much more reasonable:
 
 
 
(Aleks sent this to me, then I checked on my own computer and got the same thing.)</p><p>6 0.88495392 <a title="1580-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-01-Don%E2%80%99t_let_your_standard_errors_drive_your_research_agenda.html">1702 andrew gelman stats-2013-02-01-Don’t let your standard errors drive your research agenda</a></p>
<p>7 0.88304448 <a title="1580-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-11-Using_the_%E2%80%9Cinstrumental_variables%E2%80%9D_or_%E2%80%9Cpotential_outcomes%E2%80%9D_approach_to_clarify_causal_thinking.html">1492 andrew gelman stats-2012-09-11-Using the “instrumental variables” or “potential outcomes” approach to clarify causal thinking</a></p>
<p>8 0.88131225 <a title="1580-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<p>9 0.8803941 <a title="1580-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>10 0.87807703 <a title="1580-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-26-Impersonators.html">1639 andrew gelman stats-2012-12-26-Impersonators</a></p>
<p>11 0.87731302 <a title="1580-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>12 0.87606454 <a title="1580-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-31-Bayes%3A_radical%2C_liberal%2C_or_conservative%3F.html">639 andrew gelman stats-2011-03-31-Bayes: radical, liberal, or conservative?</a></p>
<p>13 0.87591439 <a title="1580-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-23-Traditionalist_claims_that_modern_art_could_just_as_well_be_replaced_by_a_%E2%80%9Cpaint-throwing_chimp%E2%80%9D.html">1390 andrew gelman stats-2012-06-23-Traditionalist claims that modern art could just as well be replaced by a “paint-throwing chimp”</a></p>
<p>14 0.87552059 <a title="1580-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-28-Turing_chess_run_update.html">1473 andrew gelman stats-2012-08-28-Turing chess run update</a></p>
<p>15 0.87398696 <a title="1580-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-04-Shlemiel_the_Software_Developer_and_Unknown_Unknowns.html">2089 andrew gelman stats-2013-11-04-Shlemiel the Software Developer and Unknown Unknowns</a></p>
<p>16 0.87373364 <a title="1580-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-29-More_on_scaled-inverse_Wishart_and_prior_independence.html">1474 andrew gelman stats-2012-08-29-More on scaled-inverse Wishart and prior independence</a></p>
<p>17 0.87282014 <a title="1580-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-11-Data_Visualization_vs._Statistical_Graphics.html">407 andrew gelman stats-2010-11-11-Data Visualization vs. Statistical Graphics</a></p>
<p>18 0.87171042 <a title="1580-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-17-Macro_causality.html">807 andrew gelman stats-2011-07-17-Macro causality</a></p>
<p>19 0.86981261 <a title="1580-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-Cash_in%2C_cash_out_graph.html">502 andrew gelman stats-2011-01-04-Cash in, cash out graph</a></p>
<p>20 0.86927116 <a title="1580-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-18-Understanding_posterior_p-values.html">2029 andrew gelman stats-2013-09-18-Understanding posterior p-values</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
