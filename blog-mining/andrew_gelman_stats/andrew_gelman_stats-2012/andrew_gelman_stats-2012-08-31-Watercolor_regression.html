<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1478 andrew gelman stats-2012-08-31-Watercolor regression</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1478" href="#">andrew_gelman_stats-2012-1478</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1478 andrew gelman stats-2012-08-31-Watercolor regression</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1478-html" href="http://andrewgelman.com/2012/08/31/watercolor-regression/">html</a></p><p>Introduction: Solomon Hsiang writes:
  
Two small follow-ups based on the  discussion  (the second/bigger one is to address your comment about the 95% CI edges).


1. I realized that if we plot the confidence intervals as a solid color that fades (eg. using the “fixed ink” scheme from before) we can make sure the regression line also has heightened visual weight where confidence is high by plotting the line white. This makes the contrast (and thus visual weight) between the regression line and the CI highest when the CI is narrow and dark. As the CI fade near the edges, so does the contrast with the regression line. This is a small adjustment, but I like it because it is so simple and it makes the graph much nicer. (see “visually_weighted_fill_reverse” attached). My posted code has been updated to do this automatically.


2. You and your readers didn’t like that the edges of the filled CI were so sharp and arbitrary. But I didn’t like that the contrast between the spaghetti lines and the background</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I realized that if we plot the confidence intervals as a solid color that fades (eg. [sent-3, score-0.398]
</p><p>2 using the “fixed ink” scheme from before) we can make sure the regression line also has heightened visual weight where confidence is high by plotting the line white. [sent-4, score-0.899]
</p><p>3 This makes the contrast (and thus visual weight) between the regression line and the CI highest when the CI is narrow and dark. [sent-5, score-0.498]
</p><p>4 As the CI fade near the edges, so does the contrast with the regression line. [sent-6, score-0.326]
</p><p>5 My posted code has been updated to do this automatically. [sent-9, score-0.275]
</p><p>6 You and your readers didn’t like that the edges of the filled CI were so sharp and arbitrary. [sent-11, score-0.353]
</p><p>7 But I didn’t like that the contrast between the spaghetti lines and the background had so much visual weight. [sent-12, score-0.604]
</p><p>8 So to meet in the middle, I smoothed the spaghetti plot to get a nonparametric estimate of the probability that the conditional mean is at a given value (see “visually_weighted_fixed_ink_smoothed_spaghetti” attached). [sent-13, score-0.716]
</p><p>9 To do this, after generating the spaghetti through bootstrapping, I estimate a kernel density of the spaghetti in the Y dimension for each value of X. [sent-14, score-1.095]
</p><p>10 I set the visual-weighting scheme so it still “preserves ink” along a vertical line-integral, so the distribution dims where it widens since the ink is being “stretched out”. [sent-15, score-0.593]
</p><p>11 To me, it kind of looks like a watercolor painting — maybe we should call it a “watercolor regression” or something like that. [sent-16, score-0.324]
</p><p>12 The watercolor regression turned out to be more of a coding challenge than I expected, because the bandwidth for the kernel smoothing has to adjust to the width of the CI. [sent-17, score-0.872]
</p><p>13 And since several people seem to like R better than Matlab, I attached 2 figs to show them how I did this. [sent-18, score-0.218]
</p><p>14 jpg), I defined a new coordinate system that spanned the range of bootstrapped estimates for each value in X (step2. [sent-20, score-0.367]
</p><p>15 The kernel smoothing is then executed along the vertical columns of this new coordinate system. [sent-22, score-0.706]
</p><p>16 I’ve updated  the code posted online  to include this new option. [sent-23, score-0.275]
</p><p>17 This Matlab code will generate a similar plot using my vwregress function:    x = randn(100,1);  e = randn(100,1);  y = 2*x+x. [sent-24, score-0.448]
</p><p>18 Thanks to you and your readers for all the feedback. [sent-28, score-0.056]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('spaghetti', 0.371), ('ci', 0.299), ('watercolor', 0.259), ('ink', 0.213), ('kernel', 0.206), ('plot', 0.188), ('edges', 0.183), ('bw', 0.173), ('resamples', 0.173), ('randn', 0.157), ('vwregress', 0.157), ('regression', 0.151), ('bootstrapped', 0.148), ('attached', 0.139), ('bins', 0.137), ('color', 0.135), ('coordinate', 0.133), ('matlab', 0.13), ('visual', 0.129), ('vertical', 0.124), ('smoothing', 0.118), ('line', 0.114), ('contrast', 0.104), ('updated', 0.103), ('scheme', 0.103), ('code', 0.103), ('value', 0.086), ('weight', 0.086), ('widens', 0.079), ('preserves', 0.079), ('bandwidth', 0.079), ('figs', 0.079), ('confidence', 0.075), ('dims', 0.074), ('smoothed', 0.071), ('fade', 0.071), ('heightened', 0.071), ('posted', 0.069), ('executed', 0.069), ('painting', 0.065), ('hsiang', 0.065), ('bootstrapping', 0.062), ('generating', 0.061), ('solomon', 0.061), ('width', 0.059), ('filled', 0.057), ('sharp', 0.057), ('readers', 0.056), ('plotting', 0.056), ('columns', 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1478-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-31-Watercolor_regression.html">1478 andrew gelman stats-2012-08-31-Watercolor regression</a></p>
<p>Introduction: Solomon Hsiang writes:
  
Two small follow-ups based on the  discussion  (the second/bigger one is to address your comment about the 95% CI edges).


1. I realized that if we plot the confidence intervals as a solid color that fades (eg. using the “fixed ink” scheme from before) we can make sure the regression line also has heightened visual weight where confidence is high by plotting the line white. This makes the contrast (and thus visual weight) between the regression line and the CI highest when the CI is narrow and dark. As the CI fade near the edges, so does the contrast with the regression line. This is a small adjustment, but I like it because it is so simple and it makes the graph much nicer. (see “visually_weighted_fill_reverse” attached). My posted code has been updated to do this automatically.


2. You and your readers didn’t like that the edges of the filled CI were so sharp and arbitrary. But I didn’t like that the contrast between the spaghetti lines and the background</p><p>2 0.50713634 <a title="1478-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>Introduction: After  our discussion  of visual displays of regression uncertainty, I asked Solomon Hsiang and Lucas Leeman to send me their code.  Both of them replied.
 
Solomon wrote: 
  
  
The matlab and stata functions I wrote, as well as the script that replicates my figures, are all posted on  my website .


Also, I just added options to the main matlab function (vwregress.m) to make it display the spaghetti plot (similar to what Lucas did, but a simple bootstrap) and the shaded CI that you suggested (see figs below). They’re good suggestions.


   


   


Personally, I [Hsiang] like the shaded CI better, since I think that all the visual activity in the spaghetti plot is a little distracting and sometimes adds visual weight in places where I wouldn’t want it.  But the option is there in case people like it.
  
Solomon then followed up with:
  
I just thought of this small adjustment to your filled CI idea that seems neat. Cartographers like map projections that conserve area.  We can do som</p><p>3 0.1830143 <a title="1478-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-09-Visually_weighting_regression_displays.html">1452 andrew gelman stats-2012-08-09-Visually weighting regression displays</a></p>
<p>Introduction: Solomon Hsiang  writes :
  
One of my colleagues suggested that I send you  this very short note  that I wrote on a new approach for displaying regression result uncertainty (attached). It’s very simple, and I’ve found it effective in one of my papers where I actually use it, but if you have a chance to glance over it and have any ideas for how to sell the approach or make it better, I’d be very interested to hear them. (Also, if you’ve seen that someone else has already made this point, I’d appreciate knowing that too.)
  
Here’s an example:
 
   
 
Hsiang writes:
  
In Panel A, our eyes are drawn outward, away from the center of the display and toward the swirling confidence intervals at the edges. But in Panel B, our eyes are attracted to the middle of the regression line, where the high contrast between the line and the background is sharp and visually heavy. By using visual-weighting, we focus our readers’s attention on those portions of the regression that contain the most inform</p><p>4 0.12377623 <a title="1478-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-14-How_do_you_think_about_the_values_in_a_confidence_interval%3F.html">1672 andrew gelman stats-2013-01-14-How do you think about the values in a confidence interval?</a></p>
<p>Introduction: Philip Jones writes:
  
As an interested reader of your blog, I wondered if you might consider a blog entry sometime on the following  question  I posed on CrossValidated (StackExchange).


I originally posed the question based on my uncertainty about 95% CIs: “Are all values within the 95% CI equally likely (probable), or are the values at the “tails” of the 95% CI less likely than those in the middle of the CI closer to the point estimate?”


I posed this question based on discordant information I found at a couple of different web sources (I posted these sources in the body of the question).


I received some interesting replies, and the replies were not unanimous, in fact there is some serious disagreement there! After seeing this disagreement, I naturally thought of you, and whether you might be able to clear this up.


Please note I am not referring to credible intervals, but rather to the common medical journal reporting standard of confidence intervals.
  
My response:
 
First</p><p>5 0.12020929 <a title="1478-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-17-Graphs_showing_uncertainty_using_lighter_intensities_for_the_lines_that_go_further_from_the_center%2C_to_de-emphasize_the_edges.html">1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</a></p>
<p>Introduction: Following up on our  recent discussion  of visually-weighted displays of uncertainty in regression curves, Lucas Leeman sent in the following two graphs:
 
First, the basic spaghetti-style plot showing inferential uncertainty in the E(y|x) curve:
 
   
 
Then, a version using even lighter intensities for the lines that go further from the center, to further de-emphasize the edges:
 
   
 
P.S.  More (including code!)  here .</p><p>6 0.11371411 <a title="1478-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-12-%E2%80%9CThe_results_%28not_shown%29_._._.%E2%80%9D.html">2332 andrew gelman stats-2014-05-12-“The results (not shown) . . .”</a></p>
<p>7 0.11145091 <a title="1478-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-15-Problematic_interpretations_of_confidence_intervals.html">2248 andrew gelman stats-2014-03-15-Problematic interpretations of confidence intervals</a></p>
<p>8 0.10176376 <a title="1478-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>9 0.096773908 <a title="1478-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-06-Bootstrap_averaging%3A_Examples_where_it_works_and_where_it_doesn%E2%80%99t_work.html">2201 andrew gelman stats-2014-02-06-Bootstrap averaging: Examples where it works and where it doesn’t work</a></p>
<p>10 0.090225734 <a title="1478-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-Cash_in%2C_cash_out_graph.html">502 andrew gelman stats-2011-01-04-Cash in, cash out graph</a></p>
<p>11 0.089943595 <a title="1478-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-13-Hey%21__Here%E2%80%99s_a_referee_report_for_you%21.html">144 andrew gelman stats-2010-07-13-Hey!  Here’s a referee report for you!</a></p>
<p>12 0.086983785 <a title="1478-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-27-White_stripes_and_dead_armadillos.html">2308 andrew gelman stats-2014-04-27-White stripes and dead armadillos</a></p>
<p>13 0.079707816 <a title="1478-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-16-EdLab_at_Columbia%E2%80%99s_Teachers%E2%80%99_College.html">209 andrew gelman stats-2010-08-16-EdLab at Columbia’s Teachers’ College</a></p>
<p>14 0.077468134 <a title="1478-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-28-Difficulties_of_using_statistical_significance_%28or_lack_thereof%29_to_sift_through_and_compare_research_hypotheses.html">2042 andrew gelman stats-2013-09-28-Difficulties of using statistical significance (or lack thereof) to sift through and compare research hypotheses</a></p>
<p>15 0.074385583 <a title="1478-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-16-Choices_in_graphing_parallel_time_series.html">1498 andrew gelman stats-2012-09-16-Choices in graphing parallel time series</a></p>
<p>16 0.07373219 <a title="1478-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-10-Why_display_6_years_instead_of_30%3F.html">1258 andrew gelman stats-2012-04-10-Why display 6 years instead of 30?</a></p>
<p>17 0.073421799 <a title="1478-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-I_like_lineplots.html">800 andrew gelman stats-2011-07-13-I like lineplots</a></p>
<p>18 0.07244125 <a title="1478-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-05-Evidence_on_the_impact_of_sustained_use_of_polynomial_regression_on_causal_inference_%28a_claim_that_coal_heating_is_reducing_lifespan_by_5_years_for_half_a_billion_people%29.html">1968 andrew gelman stats-2013-08-05-Evidence on the impact of sustained use of polynomial regression on causal inference (a claim that coal heating is reducing lifespan by 5 years for half a billion people)</a></p>
<p>19 0.070583642 <a title="1478-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-27-Visual_diagnostics_for_discrete-data_regressions.html">929 andrew gelman stats-2011-09-27-Visual diagnostics for discrete-data regressions</a></p>
<p>20 0.068956666 <a title="1478-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-13-And_now%2C_here%E2%80%99s_something_that_would_make_Ed_Tufte_spin_in_his_._._._ummm%2C_Tufte%E2%80%99s_still_around%2C_actually%2C_so_let%E2%80%99s_just_say_I_don%E2%80%99t_think_he%E2%80%99d_like_it%21.html">2132 andrew gelman stats-2013-12-13-And now, here’s something that would make Ed Tufte spin in his . . . ummm, Tufte’s still around, actually, so let’s just say I don’t think he’d like it!</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.105), (1, 0.022), (2, 0.029), (3, 0.016), (4, 0.104), (5, -0.059), (6, 0.004), (7, -0.0), (8, -0.003), (9, -0.024), (10, -0.005), (11, -0.017), (12, 0.01), (13, 0.003), (14, -0.009), (15, 0.026), (16, 0.024), (17, -0.002), (18, -0.004), (19, -0.038), (20, 0.066), (21, 0.091), (22, 0.019), (23, -0.029), (24, 0.087), (25, -0.016), (26, 0.03), (27, -0.083), (28, -0.03), (29, 0.031), (30, 0.051), (31, -0.002), (32, -0.062), (33, -0.048), (34, 0.007), (35, -0.055), (36, -0.015), (37, 0.055), (38, 0.016), (39, -0.022), (40, 0.012), (41, 0.028), (42, 0.049), (43, -0.011), (44, 0.037), (45, 0.038), (46, -0.032), (47, 0.078), (48, 0.01), (49, -0.032)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96176332 <a title="1478-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-31-Watercolor_regression.html">1478 andrew gelman stats-2012-08-31-Watercolor regression</a></p>
<p>Introduction: Solomon Hsiang writes:
  
Two small follow-ups based on the  discussion  (the second/bigger one is to address your comment about the 95% CI edges).


1. I realized that if we plot the confidence intervals as a solid color that fades (eg. using the “fixed ink” scheme from before) we can make sure the regression line also has heightened visual weight where confidence is high by plotting the line white. This makes the contrast (and thus visual weight) between the regression line and the CI highest when the CI is narrow and dark. As the CI fade near the edges, so does the contrast with the regression line. This is a small adjustment, but I like it because it is so simple and it makes the graph much nicer. (see “visually_weighted_fill_reverse” attached). My posted code has been updated to do this automatically.


2. You and your readers didn’t like that the edges of the filled CI were so sharp and arbitrary. But I didn’t like that the contrast between the spaghetti lines and the background</p><p>2 0.86529601 <a title="1478-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>Introduction: After  our discussion  of visual displays of regression uncertainty, I asked Solomon Hsiang and Lucas Leeman to send me their code.  Both of them replied.
 
Solomon wrote: 
  
  
The matlab and stata functions I wrote, as well as the script that replicates my figures, are all posted on  my website .


Also, I just added options to the main matlab function (vwregress.m) to make it display the spaghetti plot (similar to what Lucas did, but a simple bootstrap) and the shaded CI that you suggested (see figs below). They’re good suggestions.


   


   


Personally, I [Hsiang] like the shaded CI better, since I think that all the visual activity in the spaghetti plot is a little distracting and sometimes adds visual weight in places where I wouldn’t want it.  But the option is there in case people like it.
  
Solomon then followed up with:
  
I just thought of this small adjustment to your filled CI idea that seems neat. Cartographers like map projections that conserve area.  We can do som</p><p>3 0.8643555 <a title="1478-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-09-Visually_weighting_regression_displays.html">1452 andrew gelman stats-2012-08-09-Visually weighting regression displays</a></p>
<p>Introduction: Solomon Hsiang  writes :
  
One of my colleagues suggested that I send you  this very short note  that I wrote on a new approach for displaying regression result uncertainty (attached). It’s very simple, and I’ve found it effective in one of my papers where I actually use it, but if you have a chance to glance over it and have any ideas for how to sell the approach or make it better, I’d be very interested to hear them. (Also, if you’ve seen that someone else has already made this point, I’d appreciate knowing that too.)
  
Here’s an example:
 
   
 
Hsiang writes:
  
In Panel A, our eyes are drawn outward, away from the center of the display and toward the swirling confidence intervals at the edges. But in Panel B, our eyes are attracted to the middle of the regression line, where the high contrast between the line and the background is sharp and visually heavy. By using visual-weighting, we focus our readers’s attention on those portions of the regression that contain the most inform</p><p>4 0.85901493 <a title="1478-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-17-Graphs_showing_uncertainty_using_lighter_intensities_for_the_lines_that_go_further_from_the_center%2C_to_de-emphasize_the_edges.html">1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</a></p>
<p>Introduction: Following up on our  recent discussion  of visually-weighted displays of uncertainty in regression curves, Lucas Leeman sent in the following two graphs:
 
First, the basic spaghetti-style plot showing inferential uncertainty in the E(y|x) curve:
 
   
 
Then, a version using even lighter intensities for the lines that go further from the center, to further de-emphasize the edges:
 
   
 
P.S.  More (including code!)  here .</p><p>5 0.71167576 <a title="1478-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Let%E2%80%99s_play_%E2%80%9CGuess_the_smoother%E2%80%9D%21.html">1283 andrew gelman stats-2012-04-26-Let’s play “Guess the smoother”!</a></p>
<p>Introduction: Andre de Boer writes:
  
In my profession as a risk manager I encountered this graph:


   


I can’t figure out what kind of regression this is, would you be so kind to enlighten me? 
The points represent (maturity,yield) of bonds.
  
My reply:  That’s a fun problem, reverse-engineering a curve fit!  My first guess is lowess, although it seems too flat and asympoty on the right side of the graph to be lowess.  Maybe a Gaussian process?  Looks too smooth to be a spline.  I guess I’ll go with my original guess, on the theory that lowess is the most accessible smoother out there, and if someone fit something much more complicated they’d make more of a big deal about it.  On the other hand, if the curve is an automatic output of some software (Excel? Stata?) then it could be just about anything.
 
Does anyone have any ideas?</p><p>6 0.68017381 <a title="1478-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-29-I%E2%80%99m_looking_for_a_quadrille_notebook_with_faint_lines.html">1235 andrew gelman stats-2012-03-29-I’m looking for a quadrille notebook with faint lines</a></p>
<p>7 0.67036438 <a title="1478-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-The_R_code_for_those_time-use_graphs.html">672 andrew gelman stats-2011-04-20-The R code for those time-use graphs</a></p>
<p>8 0.63467389 <a title="1478-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-16-Choices_in_graphing_parallel_time_series.html">1498 andrew gelman stats-2012-09-16-Choices in graphing parallel time series</a></p>
<p>9 0.61652845 <a title="1478-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-23-Lowess_is_great.html">293 andrew gelman stats-2010-09-23-Lowess is great</a></p>
<p>10 0.58535886 <a title="1478-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-10-Why_display_6_years_instead_of_30%3F.html">1258 andrew gelman stats-2012-04-10-Why display 6 years instead of 30?</a></p>
<p>11 0.57666016 <a title="1478-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-14-How_do_you_think_about_the_values_in_a_confidence_interval%3F.html">1672 andrew gelman stats-2013-01-14-How do you think about the values in a confidence interval?</a></p>
<p>12 0.57520884 <a title="1478-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-08-%E2%80%9CWhat_do_you_think_about_curved_lines_connecting_discrete_data-points%3F%E2%80%9D.html">134 andrew gelman stats-2010-07-08-“What do you think about curved lines connecting discrete data-points?”</a></p>
<p>13 0.56555897 <a title="1478-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-13-Hey%21__Here%E2%80%99s_a_referee_report_for_you%21.html">144 andrew gelman stats-2010-07-13-Hey!  Here’s a referee report for you!</a></p>
<p>14 0.56064504 <a title="1478-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-21-Instead_of_%E2%80%9Cconfidence_interval%2C%E2%80%9D_let%E2%80%99s_say_%E2%80%9Cuncertainty_interval%E2%80%9D.html">480 andrew gelman stats-2010-12-21-Instead of “confidence interval,” let’s say “uncertainty interval”</a></p>
<p>15 0.54716069 <a title="1478-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>16 0.54456604 <a title="1478-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-18-Course_proposal%3A_Bayesian_and_advanced_likelihood_statistical_methods_for_zombies..html">96 andrew gelman stats-2010-06-18-Course proposal: Bayesian and advanced likelihood statistical methods for zombies.</a></p>
<p>17 0.54270655 <a title="1478-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-09-iPython_Notebook.html">1716 andrew gelman stats-2013-02-09-iPython Notebook</a></p>
<p>18 0.54267478 <a title="1478-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-26-A_simple_semigraphic_display.html">296 andrew gelman stats-2010-09-26-A simple semigraphic display</a></p>
<p>19 0.54075986 <a title="1478-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-23-Thinking_outside_the_%28graphical%29_box%3A__Instead_of_arguing_about_how_best_to_fix_a_bar_chart%2C_graph_it_as_a_time_series_lineplot_instead.html">294 andrew gelman stats-2010-09-23-Thinking outside the (graphical) box:  Instead of arguing about how best to fix a bar chart, graph it as a time series lineplot instead</a></p>
<p>20 0.53912377 <a title="1478-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-15-World_record_running_times_vs._distance.html">1011 andrew gelman stats-2011-11-15-World record running times vs. distance</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(13, 0.021), (16, 0.035), (24, 0.088), (27, 0.013), (34, 0.018), (36, 0.36), (53, 0.016), (59, 0.028), (61, 0.033), (62, 0.017), (72, 0.012), (77, 0.026), (84, 0.029), (95, 0.022), (99, 0.157)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96040821 <a title="1478-lda-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-10-Stan_Model_of_the_Week%3A__PK_Calculation_of_IV_and_Oral_Dosing.html">2242 andrew gelman stats-2014-03-10-Stan Model of the Week:  PK Calculation of IV and Oral Dosing</a></p>
<p>Introduction: [Update: Revised given comments from Wingfeet, Andrew and germo.  Thanks!  I'd mistakenly translated the dlnorm priors in the first version --- amazing what a difference the priors make.  I also escaped the less-than and greater-than signs in the constraints in the model so they're visible.  I also updated to match the thin=2 output of JAGS.]
 
We’re going to be starting a Stan “model of the P” (for some time period P) column, so I thought I’d kick things off with one of my own.  I’ve been following the  Wingvoet blog , the author of which is identified only by the Blogger handle  Wingfeet ;  a couple of days ago this lovely post came out:
  
  PK calculation of IV and oral dosing in JAGS 
   
Wingfeet’s post implemented an answer to question 6 from chapter 6 of problem from Rowland and Tozer’s 2010 book,   Clinical Pharmacokinetics and Pharmacodynamics  , Fourth edition, Lippincott, Williams & Wilkins.   
 
So in the grand tradition of using this blog to procrastinate, I thought I’d t</p><p>2 0.82757878 <a title="1478-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-10-%E2%80%9CProposition_and_experiment%E2%80%9D.html">1797 andrew gelman stats-2013-04-10-“Proposition and experiment”</a></p>
<p>Introduction: Anna Lena Phillips  writes :
  
I. Many people will not, of their own accord, look at a poem.


II. Millions of people will, of their own accord, spend lots and lots of time looking at photographs of cats.


III. Therefore, earlier this year, I concluded that the best strategy for increasing the number of viewers for poems would be to print them on top of photographs of cats.


IV. I happen to like looking at both poems and cats.


V. So this is, for me, a win-win situation.


VI. Fortunately, my own cat is a patient model, and (if I am to be believed) quite photogenic.


VII. The aforementioned cat is Tisko Tansi, small hero.


VII. Thus I present to you (albeit in digital rather than physical form) an Endearments broadside, featuring a poem that originally appeared in BlazeVOX spring 2011.


VIII. If you want to share a copy of this image, please ask first. If you want a real copy, you can ask about that too.
  
She follows up with an image of a cat, on which is superimposed a short</p><p>3 0.82081252 <a title="1478-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-02-Information_is_good.html">176 andrew gelman stats-2010-08-02-Information is good</a></p>
<p>Introduction: Washington Post and Slate reporter Anne Applebaum wrote a  dismissive  column about Wikileaks, saying that they “offer nothing more than raw data.”
 
Applebaum argues that “The notion that the Internet can replace traditional news-gathering has just been revealed to be a myth. . . . without more journalism, more investigation, more work, these documents just don’t matter that much.”
 
Fine.  But don’t undervalue the role of mere data!  The usual story is that we  don’t  get to see the raw data underlying newspaper stories.  Wikileaks and other crowdsourced data can be extremely useful, whether or not they replace “traditional news-gathering.”</p><p>4 0.80814087 <a title="1478-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Stan_is_fast.html">1476 andrew gelman stats-2012-08-30-Stan is fast</a></p>
<p>Introduction: 10,000 iterations for 4 chains on the (precompiled) efficiently-parameterized 8-schools model: 
   
 > date () 
[1] "Thu Aug 30 22:12:53 2012" 
> fit3 <- stan (fit=fit2, data = schools_dat, iter = 1e4, n_chains = 4) 
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). 
Iteration: 10000 / 10000 [100%]  (Sampling) 
 
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). 
Iteration: 10000 / 10000 [100%]  (Sampling)
 
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). 
Iteration: 10000 / 10000 [100%]  (Sampling)
 
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). 
Iteration: 10000 / 10000 [100%]  (Sampling)
 
> date () 
[1] "Thu Aug 30 22:12:55 2012" 
> print (fit3) 
Inference for Stan model: anon_model. 
4 chains: each with iter=10000; warmup=5000; thin=1; 10000 iterations saved.
 
         mean se_mean  sd  2.5%  25%  50%  75% 97.5% n_eff Rhat 
mu        8.0     0.1 5.1  -2.0  4.7  8.0 11.3  18.4  4032    1 
tau       6.7     0.1 5.6   0.3  2.5  5.4  9.3  21.2  2958    1 
eta[1]    0.4     0.0 0.9  -1.5 -0</p><p>same-blog 5 0.80405122 <a title="1478-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-31-Watercolor_regression.html">1478 andrew gelman stats-2012-08-31-Watercolor regression</a></p>
<p>Introduction: Solomon Hsiang writes:
  
Two small follow-ups based on the  discussion  (the second/bigger one is to address your comment about the 95% CI edges).


1. I realized that if we plot the confidence intervals as a solid color that fades (eg. using the “fixed ink” scheme from before) we can make sure the regression line also has heightened visual weight where confidence is high by plotting the line white. This makes the contrast (and thus visual weight) between the regression line and the CI highest when the CI is narrow and dark. As the CI fade near the edges, so does the contrast with the regression line. This is a small adjustment, but I like it because it is so simple and it makes the graph much nicer. (see “visually_weighted_fill_reverse” attached). My posted code has been updated to do this automatically.


2. You and your readers didn’t like that the edges of the filled CI were so sharp and arbitrary. But I didn’t like that the contrast between the spaghetti lines and the background</p><p>6 0.72443688 <a title="1478-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-02-Obama_and_Reagan%2C_sitting_in_a_tree%2C_etc..html">551 andrew gelman stats-2011-02-02-Obama and Reagan, sitting in a tree, etc.</a></p>
<p>7 0.6589098 <a title="1478-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Who_gets_wedding_announcements_in_the_Times%3F.html">370 andrew gelman stats-2010-10-25-Who gets wedding announcements in the Times?</a></p>
<p>8 0.65454066 <a title="1478-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>9 0.65342516 <a title="1478-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-27-In_Linux%2C_use_jags%28%29_to_call_Jags_instead_of_using_bugs%28%29_to_call_OpenBugs.html">55 andrew gelman stats-2010-05-27-In Linux, use jags() to call Jags instead of using bugs() to call OpenBugs</a></p>
<p>10 0.64510226 <a title="1478-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-01-Arrow%E2%80%99s_theorem_update.html">883 andrew gelman stats-2011-09-01-Arrow’s theorem update</a></p>
<p>11 0.64287364 <a title="1478-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-20-%E2%80%9CPeople_with_an_itch_to_scratch%E2%80%9D.html">101 andrew gelman stats-2010-06-20-“People with an itch to scratch”</a></p>
<p>12 0.64080501 <a title="1478-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-17-NSF_program_%E2%80%9Cto_support_analytic_and_methodological_research_in_support_of_its_surveys%E2%80%9D.html">1217 andrew gelman stats-2012-03-17-NSF program “to support analytic and methodological research in support of its surveys”</a></p>
<p>13 0.6348387 <a title="1478-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-08-Of_parsing_and_chess.html">1847 andrew gelman stats-2013-05-08-Of parsing and chess</a></p>
<p>14 0.62148565 <a title="1478-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-18-What%E2%80%99s_my_Kasparov_number%3F.html">2105 andrew gelman stats-2013-11-18-What’s my Kasparov number?</a></p>
<p>15 0.60365701 <a title="1478-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-14-Progress%21__%28on_the_understanding_of_the_role_of_randomization_in_Bayesian_inference%29.html">1898 andrew gelman stats-2013-06-14-Progress!  (on the understanding of the role of randomization in Bayesian inference)</a></p>
<p>16 0.59933066 <a title="1478-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-15-The_two_faces_of_Erving_Goffman%3A__Subtle_observer_of_human_interactions%2C_and_Smug_organzation_man.html">415 andrew gelman stats-2010-11-15-The two faces of Erving Goffman:  Subtle observer of human interactions, and Smug organzation man</a></p>
<p>17 0.57261205 <a title="1478-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-11-Actually%2C_I_have_no_problem_with_this_graph.html">1851 andrew gelman stats-2013-05-11-Actually, I have no problem with this graph</a></p>
<p>18 0.56967455 <a title="1478-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-10-They%E2%80%99d_rather_be_rigorous_than_right.html">1666 andrew gelman stats-2013-01-10-They’d rather be rigorous than right</a></p>
<p>19 0.55869102 <a title="1478-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-08-Bayes-Godel.html">998 andrew gelman stats-2011-11-08-Bayes-Godel</a></p>
<p>20 0.54898083 <a title="1478-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-19-If_a_comment_is_flagged_as_spam%2C_it_will_disappear_forever.html">619 andrew gelman stats-2011-03-19-If a comment is flagged as spam, it will disappear forever</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
