<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1273" href="#">andrew_gelman_stats-2012-1273</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1273-html" href="http://andrewgelman.com/2012/04/20/proposals-for-alternative-review-systems-for-scientific-work/">html</a></p><p>Introduction: I recently became aware of two new entries in the ever-popular genre of, Our Peer-Review System is in Trouble; How Can We Fix It?
 
Political scientist Brendan Nyhan,  commenting  on experimental and empirical sciences more generally, focuses on the selection problem that positive rather then negative findings tend to get published, leading via the  statistical significance filter  to an overestimation of effect sizes.  Nyhan recommends that data-collection protocols be published ahead of time, with the commitment to publish the eventual results:
  
In the case of experimental data, a better practice would be for journals to accept articles before the study was conducted. The article should be written up to the point of the results section, which would then be populated using a pre-specified analysis plan submitted by the author. The journal would then allow for post-hoc analysis and interpretation by the author that would be labeled as such and distinguished from the previously submit</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Nyhan recommends that data-collection protocols be published ahead of time, with the commitment to publish the eventual results:    In the case of experimental data, a better practice would be for journals to accept articles before the study was conducted. [sent-3, score-0.861]
</p><p>2 The article should be written up to the point of the results section, which would then be populated using a pre-specified analysis plan submitted by the author. [sent-4, score-0.437]
</p><p>3 The journal would then allow for post-hoc analysis and interpretation by the author that would be labeled as such and distinguished from the previously submitted material. [sent-5, score-0.496]
</p><p>4 By offering such an option, journals would create a positive incentive for preregistration that would avoid file drawer bias. [sent-6, score-0.606]
</p><p>5 More published articles would have null findings (at least 5%! [sent-7, score-0.343]
</p><p>6 Quality control could be maintained by “replication audits of a random subset of published articles. [sent-9, score-0.245]
</p><p>7 At a minimum, these audits would verify that all the results in an article could be replicated. [sent-10, score-0.369]
</p><p>8 They could conceivably go further in some cases and try to recreate the author’s data and results from publicly available sources, re-run lab experiments, etc. [sent-11, score-0.226]
</p><p>9 ”   Coming from a completely different direction, theoretical statistician Larry Wasserman ( link  from Xian)  suggests  abandoning peer-reviewed journals entirely and replacing them by the Arxiv, a system run by physicists where people can upload their own articles. [sent-13, score-0.414]
</p><p>10 Arxiv is somewhat restricted (you have to be connected in some way to post an article, and they do enough screening so that, for example, they at first refused to publish my  zombies paper  (and, even when they did publish it, they removed George A. [sent-14, score-0.26]
</p><p>11 Larry’s suggestion of daily scanning of the Arxiv daily is not so practical—and it would be even much less so if his plan kicked in and the Arxiv suddenly started including the tens of thousands of papers outside of math and physics that are daily submitted to journals. [sent-31, score-0.825]
</p><p>12 Currently, journals serve as a filter for busy researchers and evaluators of research. [sent-32, score-0.355]
</p><p>13 I think Larry would respond to this criticism by arguing that a no-journals system would create an incentive for groups of scholars to manage a filtering service. [sent-33, score-0.743]
</p><p>14 , and maintaining a separate editorial staff for each (representing a huge amount of volunteer service on the part of editors and referees), they could run a set of filtering services. [sent-35, score-0.427]
</p><p>15 The editors of each filter would be expected to scan the literature and handle submissions (which in this case would be pointers to articles already published on the web). [sent-36, score-0.97]
</p><p>16 The editorial boards would have the responsibility to come up with monthly (say) recommended reading material. [sent-37, score-0.394]
</p><p>17 The main concern I see would be to keep the editors focused on solid research rather than getting tabloidlike. [sent-39, score-0.275]
</p><p>18 It would be tempting for an aggregator to give pointers to “pathological science” such as the Bible Code and silly sex-ratio analyses and ESP studies, in order to grab more attention. [sent-40, score-0.281]
</p><p>19 Nyhan recommends a more rigorous system, where to publish an article you have to supply data and other replication materials, whereas Wasserman would place no restrictions at all. [sent-44, score-0.479]
</p><p>20 I can well imagine someone reading Nyhan’s suggestions and saying Yeah, then reading Wasserman’s suggestions and agreeing to those too, without even fully realizing their different directions. [sent-46, score-0.296]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nyhan', 0.273), ('arxiv', 0.247), ('wasserman', 0.216), ('larry', 0.212), ('would', 0.15), ('filter', 0.15), ('system', 0.143), ('journals', 0.137), ('audits', 0.136), ('submitted', 0.132), ('daily', 0.132), ('filtering', 0.131), ('pointers', 0.131), ('publish', 0.13), ('editors', 0.125), ('recommends', 0.113), ('xian', 0.113), ('published', 0.109), ('editorial', 0.105), ('directions', 0.102), ('referees', 0.1), ('incentive', 0.097), ('replication', 0.086), ('articles', 0.084), ('results', 0.083), ('scanning', 0.075), ('aggregators', 0.075), ('recreate', 0.075), ('technometrics', 0.075), ('suggestions', 0.075), ('ideas', 0.074), ('reading', 0.073), ('create', 0.072), ('plan', 0.072), ('scan', 0.071), ('romero', 0.071), ('experimental', 0.07), ('refereeing', 0.068), ('evaluators', 0.068), ('conceivably', 0.068), ('upload', 0.068), ('eventual', 0.068), ('pathological', 0.068), ('boards', 0.066), ('abandoning', 0.066), ('maintaining', 0.066), ('author', 0.064), ('consuming', 0.064), ('reforms', 0.064), ('marketplace', 0.064)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999964 <a title="1273-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<p>Introduction: I recently became aware of two new entries in the ever-popular genre of, Our Peer-Review System is in Trouble; How Can We Fix It?
 
Political scientist Brendan Nyhan,  commenting  on experimental and empirical sciences more generally, focuses on the selection problem that positive rather then negative findings tend to get published, leading via the  statistical significance filter  to an overestimation of effect sizes.  Nyhan recommends that data-collection protocols be published ahead of time, with the commitment to publish the eventual results:
  
In the case of experimental data, a better practice would be for journals to accept articles before the study was conducted. The article should be written up to the point of the results section, which would then be populated using a pre-specified analysis plan submitted by the author. The journal would then allow for post-hoc analysis and interpretation by the author that would be labeled as such and distinguished from the previously submit</p><p>2 0.21762681 <a title="1273-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-23-Larry_Wasserman%E2%80%99s_statistics_blog.html">1389 andrew gelman stats-2012-06-23-Larry Wasserman’s statistics blog</a></p>
<p>Introduction: Larry Wasserman, a leading theoretical statistician and generally thoughtful guy, has started  a blog  on . . . theoretical statistics!  Good stuff, and readers of this blog should enjoy the different perspective that Larry offers.
 
 Here  are some earlier references to Larry on this blog, and  here’s  a discussion that gives a sense of our different (but not extremely different) attitudes about statistical methods.</p><p>3 0.20288521 <a title="1273-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-12-More_on_publishing_in_journals.html">2245 andrew gelman stats-2014-03-12-More on publishing in journals</a></p>
<p>Introduction: I’m postponing today’s scheduled post (“Empirical implications of Empirical Implications of Theoretical Models”) to continue the lively discussion from yesterday,  What if I were to stop publishing in journals? . 
   
 An example:  my papers with Basbøll 
 
Thomas Basbøll and I got into a long discussion on our blogs about business school professor Karl Weick and other cases of  plagiarism  copying text without attribution.  We felt it useful to take our ideas to the next level and write them up as a manuscript, which ended up being logical to split into two papers.  At that point I put some effort into getting these papers published, which I eventually did:   To throw away data: Plagiarism as a statistical crime  went into American Scientist and  When do stories work? Evidence and illustration in the social sciences  will appear in Sociological Methods and Research.  The second paper, in particular, took some effort to place; I got some advice from colleagues in sociology as to where</p><p>4 0.19298291 <a title="1273-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-13-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Wasserman.html">1165 andrew gelman stats-2012-02-13-Philosophy of Bayesian statistics:  my reactions to Wasserman</a></p>
<p>Introduction: Continuing with  my discussion of the articles in the special issue  of the journal Rationality, Markets and Morals on the philosophy of Bayesian statistics:
 
   
 
Larry Wasserman, “Low Assumptions, High Dimensions”:
 
This article was refreshing to me because it was so different from anything I’ve seen before.  Larry works in a statistics department and I work in a statistics department but there’s so little overlap in what we do.  Larry and I both work in high dimesions (maybe his dimensions are higher than mine, but a few thousand dimensions seems like a lot to me!), but there the similarity ends.  His article is all about using few to no assumptions, while I use assumptions all the time.  Here’s an example.  Larry writes:
  
P. Laurie Davies (and his co-workers) have written several interesting papers where probability models, at least in the sense that we usually use them, are eliminated. Data are treated as deterministic. One then looks for adequate models rather than true mode</p><p>5 0.18797503 <a title="1273-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-05-Related_to_z-statistics.html">1301 andrew gelman stats-2012-05-05-Related to z-statistics</a></p>
<p>Introduction: Pawel Sobkowicz writes:
  
How many zombies do you know?â&euro;&trade; Using indirect survey methods to measure alien attacks and outbreaks of the undead, Arxiv preprint arXiv:1003.6087, 2010 
I hope you would find interesting the following paper, recently posted on arXiv: 
Aliens on Earth. Are reports of close encounters correct?, arXiv:1203.6805
  
This is soooooo much better than getting links to bad graphs or to papers on sex ratios!</p><p>6 0.18531604 <a title="1273-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>7 0.16081759 <a title="1273-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-More_proposals_to_reform_the_peer-review_system.html">1272 andrew gelman stats-2012-04-20-More proposals to reform the peer-review system</a></p>
<p>8 0.15732288 <a title="1273-tfidf-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>9 0.15129846 <a title="1273-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-06-How_to_think_about_papers_published_in_low-grade_journals%3F.html">1928 andrew gelman stats-2013-07-06-How to think about papers published in low-grade journals?</a></p>
<p>10 0.15046348 <a title="1273-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>11 0.14877182 <a title="1273-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>12 0.14813195 <a title="1273-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>13 0.14779817 <a title="1273-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-26-Musical_chairs_in_econ_journals.html">371 andrew gelman stats-2010-10-26-Musical chairs in econ journals</a></p>
<p>14 0.14160736 <a title="1273-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>15 0.14132658 <a title="1273-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>16 0.13505214 <a title="1273-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-14-Progress%21__%28on_the_understanding_of_the_role_of_randomization_in_Bayesian_inference%29.html">1898 andrew gelman stats-2013-06-14-Progress!  (on the understanding of the role of randomization in Bayesian inference)</a></p>
<p>17 0.13060793 <a title="1273-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>18 0.13027954 <a title="1273-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>19 0.12909678 <a title="1273-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-The_reverse-journal-submission_system.html">1393 andrew gelman stats-2012-06-26-The reverse-journal-submission system</a></p>
<p>20 0.12905306 <a title="1273-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-30-You_can%E2%80%99t_put_Pandora_back_in_the_box.html">120 andrew gelman stats-2010-06-30-You can’t put Pandora back in the box</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.226), (1, -0.058), (2, -0.066), (3, -0.127), (4, -0.064), (5, -0.044), (6, 0.006), (7, -0.094), (8, -0.021), (9, -0.03), (10, 0.087), (11, 0.002), (12, -0.048), (13, -0.011), (14, -0.003), (15, -0.043), (16, -0.015), (17, 0.014), (18, -0.032), (19, 0.002), (20, 0.042), (21, 0.053), (22, 0.009), (23, 0.055), (24, -0.03), (25, -0.012), (26, -0.021), (27, 0.035), (28, 0.018), (29, 0.053), (30, -0.039), (31, -0.058), (32, 0.034), (33, 0.001), (34, -0.01), (35, 0.009), (36, -0.051), (37, 0.035), (38, -0.03), (39, 0.024), (40, 0.039), (41, 0.014), (42, -0.006), (43, 0.028), (44, -0.002), (45, 0.011), (46, 0.032), (47, 0.03), (48, -0.042), (49, 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96136636 <a title="1273-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<p>Introduction: I recently became aware of two new entries in the ever-popular genre of, Our Peer-Review System is in Trouble; How Can We Fix It?
 
Political scientist Brendan Nyhan,  commenting  on experimental and empirical sciences more generally, focuses on the selection problem that positive rather then negative findings tend to get published, leading via the  statistical significance filter  to an overestimation of effect sizes.  Nyhan recommends that data-collection protocols be published ahead of time, with the commitment to publish the eventual results:
  
In the case of experimental data, a better practice would be for journals to accept articles before the study was conducted. The article should be written up to the point of the results section, which would then be populated using a pre-specified analysis plan submitted by the author. The journal would then allow for post-hoc analysis and interpretation by the author that would be labeled as such and distinguished from the previously submit</p><p>2 0.89462668 <a title="1273-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>Introduction: Jeff Leek  points to  a post by Alex Holcombe, who disputes the idea that science is self-correcting.  Holcombe  writes  [scroll down to get to his part]:
  
The pace of scientific production has quickened, and self-correction has suffered. Findings that might correct old results are considered less interesting than results from more original research questions. Potential corrections are also more contested. As the competition for space in prestigious journals has become increasingly frenzied, doing and publishing studies that would confirm the rapidly accumulating new discoveries, or would correct them, became a losing proposition.
  
Holcombe picks up on some points that we’ve discussed a lot here in the past year.  Here’s Holcombe:
  
In certain subfields, almost all new work appears in only a very few journals, all associated with a single professional society. There is then no way around the senior gatekeepers, who may then suppress corrections with impunity. . . .


The bias agai</p><p>3 0.89074051 <a title="1273-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>Introduction: Dan Kahan  writes :
  
The basic idea . . . is to promote identification of study designs that scholars who disagree about a proposition would agree would generate evidence relevant to their competing conjectures—regardless of what studies based on such designs actually find. Articles proposing designs of this sort would be selected for publication and only then be carried out, by the proposing researchers with funding from the journal, which would publish the results too.


Now I [Kahan] am aware of a set of real journals that have a similar motivation.


One is the  Journal of Articles in Support of the Null Hypothesis, which as its title implies publishes papers reporting studies that fail to “reject” the null. Like JASNH, LR ≠1J would try to offset the “file drawer” bias and like bad consequences associated with the convention of publishing only findings that are “significant at p < 0.05."


But it would try to do more. By publishing studies that are deemed to have valid designs an</p><p>4 0.88921946 <a title="1273-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>Introduction: I discussed two problems:
 
1.  An artificial scarcity applied to journal publication, a scarcity which I believe is being enforced based on a monetary principle of not wanting to reduce the value of publication.  The problem is that journals don’t just spread information and improve communication, they also represent chits for hiring and promotion.  I’d prefer to separate these two aspects of publication. To keep these functions tied together seems to me like a terrible mistake.  It would be as if, instead of using dollar bills as currency, we were to just use  paper , and then if the government kept paper artificially scarce to retain the value of money, so that we were reduced to scratching notes to each other on walls and tables.
 
2.  The discontinuous way in which unpublished papers and submissions to journals are taken as highly suspect and requiring a strong justification of all methods and assumptions, but once a paper becomes published its conclusions are taken as true unless</p><p>5 0.87137735 <a title="1273-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>Introduction: The other day we  discussed  that paper on ovulation and voting (you may recall that the authors reported a scattered bunch of comparisons, significance tests, and p-values, and I recommended that they would’ve done better to simply report complete summaries of their data, so that readers could see the comparisons of interest in full context), and I was thinking a bit more about why I was so bothered that it was published in Psychological Science, which I’d thought of as a serious research journal. 
   
My concern isn’t just that that the paper is bad—after all, lots of bad papers get published—but rather that it had nothing really going for it,  except  that it was headline bait.  It was a survey done on Mechanical Turk, that’s it.  No clever design, no clever questions, no care in dealing with nonresponse problems, no innovative data analysis, no nothing.  The paper had nothing to offer, except that it had no obvious flaws.  Psychology is a huge field full of brilliant researchers.</p><p>6 0.86296511 <a title="1273-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-05-Against_double-blind_reviewing%3A__Political_science_and_statistics_are_not_like_biology_and_physics.html">601 andrew gelman stats-2011-03-05-Against double-blind reviewing:  Political science and statistics are not like biology and physics</a></p>
<p>7 0.86209822 <a title="1273-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>8 0.86177993 <a title="1273-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>9 0.85834152 <a title="1273-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>10 0.85421282 <a title="1273-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-24-Difficulties_in_publishing_non-replications_of_implausible_findings.html">1137 andrew gelman stats-2012-01-24-Difficulties in publishing non-replications of implausible findings</a></p>
<p>11 0.85379249 <a title="1273-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<p>12 0.84862065 <a title="1273-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-04-Literal_vs._rhetorical.html">2233 andrew gelman stats-2014-03-04-Literal vs. rhetorical</a></p>
<p>13 0.8405751 <a title="1273-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>14 0.83996922 <a title="1273-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-15-A_statistical_research_project%3A__Weeding_out_the_fraudulent_citations.html">1321 andrew gelman stats-2012-05-15-A statistical research project:  Weeding out the fraudulent citations</a></p>
<p>15 0.83923072 <a title="1273-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-16-%E2%80%9CGroundbreaking_or_Definitive%3F_Journals_Need_to_Pick_One%E2%80%9D.html">1122 andrew gelman stats-2012-01-16-“Groundbreaking or Definitive? Journals Need to Pick One”</a></p>
<p>16 0.83387548 <a title="1273-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>17 0.83334309 <a title="1273-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-06-How_to_think_about_papers_published_in_low-grade_journals%3F.html">1928 andrew gelman stats-2013-07-06-How to think about papers published in low-grade journals?</a></p>
<p>18 0.83245701 <a title="1273-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-01-I_owe_it_all_to_the_haters.html">834 andrew gelman stats-2011-08-01-I owe it all to the haters</a></p>
<p>19 0.82676774 <a title="1273-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-More_proposals_to_reform_the_peer-review_system.html">1272 andrew gelman stats-2012-04-20-More proposals to reform the peer-review system</a></p>
<p>20 0.81721425 <a title="1273-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-06-Against_optimism_about_social_science.html">1844 andrew gelman stats-2013-05-06-Against optimism about social science</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.017), (9, 0.019), (15, 0.097), (16, 0.081), (21, 0.014), (24, 0.125), (42, 0.019), (47, 0.112), (65, 0.024), (76, 0.011), (84, 0.021), (86, 0.052), (99, 0.256)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9565028 <a title="1273-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<p>Introduction: I recently became aware of two new entries in the ever-popular genre of, Our Peer-Review System is in Trouble; How Can We Fix It?
 
Political scientist Brendan Nyhan,  commenting  on experimental and empirical sciences more generally, focuses on the selection problem that positive rather then negative findings tend to get published, leading via the  statistical significance filter  to an overestimation of effect sizes.  Nyhan recommends that data-collection protocols be published ahead of time, with the commitment to publish the eventual results:
  
In the case of experimental data, a better practice would be for journals to accept articles before the study was conducted. The article should be written up to the point of the results section, which would then be populated using a pre-specified analysis plan submitted by the author. The journal would then allow for post-hoc analysis and interpretation by the author that would be labeled as such and distinguished from the previously submit</p><p>2 0.95551795 <a title="1273-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-14-Data_visualization_at_the_American_Evaluation_Association.html">275 andrew gelman stats-2010-09-14-Data visualization at the American Evaluation Association</a></p>
<p>Introduction: Stephanie Evergreen writes:
  
 
Media, web design, and marketing have all created an environment where stakeholders – clients, program participants, funders – all expect high quality graphics and reporting that effectively conveys the valuable insights from evaluation work. Some in statistics and mathematics have used data visualization strategies to support more useful reporting of complex ideas. Global growing interest in improving communications has begun to take root in the evaluation field as well. But as anyone who has sat through a day’s worth of a conference or had to endure a dissertation-worthy evaluation report knows, evaluators still have a long way to go. To support the development of researchers and evaluators, some members of the American Evaluation Association are proposing a new TIG (Topical Interest Group) on Data Visualization and Reporting.  If you are a member of AEA (or want to be) and you are interested in joining this TIG,  contact  Stephanie Evergreen.</p><p>3 0.95418108 <a title="1273-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-17-%E2%80%9CRewarding_Strivers%3A__Helping_Low-Income_Students_Succeed_in_College%E2%80%9D.html">95 andrew gelman stats-2010-06-17-“Rewarding Strivers:  Helping Low-Income Students Succeed in College”</a></p>
<p>Introduction: Several years ago, I heard about a project at the Educational Testing Service to  identify “strivers”:  students from disadvantaged backgrounds who did unexpectedly well on the SAT (the college admissions exam formerly known as the “Scholastic Aptitude Test” but apparently now just “the SAT,” in the same way that Exxon is just “Exxon” and that Harry Truman’s middle name is just “S”), at least 200 points above a predicted score based on demographic and neighborhood information.  My ETS colleague and I agreed that this was a silly idea:  From a statistical point of view, if student A is expected ahead of time to do better than student B, and then they get identical test scores, then you’d expect student A (the non-”striver”) to do better than student B (the “striver”) later on.  Just basic statistics:  if a student does much better than expected, then probably some of that improvement is noise.  The idea of identifying these “strivers” seemed misguided and not the best use of the SAT.</p><p>4 0.95102751 <a title="1273-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-13-Data_sharing_update.html">1055 andrew gelman stats-2011-12-13-Data sharing update</a></p>
<p>Introduction: Fred Oswald reports that Sian Beilock sent him sufficient amounts of raw data from  her research study  so allow him to answer his questions about the large effects that were observed.  This sort of collegiality is central to the collective scientific enterprise.
 
The bad news is that IRB’s are still getting in the way.  Beilock was very helpful but she had to work within the constraints of her IRB, which apparently advised her not to share data—even if de-identified—without getting lots more permissions.
 
Oswald writes:
  
It is a little concerning that the IRB bars the sharing of de-identified data, particularly in light of the  specific guidelines  of the journal Science, which appears to say that when you submit a study to the journal for publication, you are allowing for the sharing of de-identified data — unless you expressly say otherwise at the point that you submit the paper for consideration.
  
Again, I don’t blame Beilock and Ramirez—they appear to have been as helpful as</p><p>5 0.94739807 <a title="1273-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-27-%E2%80%9CHow_to_Lie_with_Statistics%E2%80%9D_guy_worked_for_the_tobacco_industry_to_mock_studies_of_the_risks_of_smoking_statistics.html">1285 andrew gelman stats-2012-04-27-“How to Lie with Statistics” guy worked for the tobacco industry to mock studies of the risks of smoking statistics</a></p>
<p>Introduction: Remember How to Lie With Statistics?  It turns out that the author worked for the cigarette companies.  John Mashey  points  to this, from Robert Proctor’s book, “Golden Holocaust: Origins of the Cigarette Catastrophe and the Case for Abolition”:
  
Darrell Huff, author of the wildly popular (and aptly named) How to Lie With Statistics, was paid to testify before Congress in the 1950s and then again in the 1960s, with the assigned task of ridiculing any notion of a cigarette-disease link. On March 22, 1965, Huff testified at hearings on cigarette labeling and advertising, accusing the recent Surgeon General’s report of myriad failures and “fallacies.” Huff peppered his attack with with amusing asides and anecdotes, lampooning spurious correlations like that between the size of Dutch families and the number of storks nesting on rooftops–which proves not that storks bring babies but rather that people with large families tend to have larger houses (which therefore attract more storks).</p><p>6 0.94448698 <a title="1273-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-04-%E2%80%9CDon%E2%80%99t_think_of_it_as_duplication._Think_of_it_as_a_single_paper_in_a_superposition_of_two_quantum_journals.%E2%80%9D.html">1654 andrew gelman stats-2013-01-04-“Don’t think of it as duplication. Think of it as a single paper in a superposition of two quantum journals.”</a></p>
<p>7 0.93328726 <a title="1273-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-12-The_Naval_Research_Lab.html">1261 andrew gelman stats-2012-04-12-The Naval Research Lab</a></p>
<p>8 0.92730349 <a title="1273-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-18-Check_your_missing-data_imputations_using_cross-validation.html">1218 andrew gelman stats-2012-03-18-Check your missing-data imputations using cross-validation</a></p>
<p>9 0.92526662 <a title="1273-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-G%2B_%3E_Skype.html">1143 andrew gelman stats-2012-01-29-G+ > Skype</a></p>
<p>10 0.92312831 <a title="1273-lda-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>11 0.92230833 <a title="1273-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-20-Unz_on_Unz.html">1730 andrew gelman stats-2013-02-20-Unz on Unz</a></p>
<p>12 0.9208473 <a title="1273-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-01-What_goes_around_._._..html">548 andrew gelman stats-2011-02-01-What goes around . . .</a></p>
<p>13 0.92026567 <a title="1273-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-30-I_just_skyped_in_from_Kentucky%2C_and_boy_are_my_arms_tired.html">438 andrew gelman stats-2010-11-30-I just skyped in from Kentucky, and boy are my arms tired</a></p>
<p>14 0.91910392 <a title="1273-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-11-My_talk_at_the_NY_data_visualization_meetup_this_Monday%21.html">1668 andrew gelman stats-2013-01-11-My talk at the NY data visualization meetup this Monday!</a></p>
<p>15 0.91808665 <a title="1273-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-Just_gave_a_talk.html">2275 andrew gelman stats-2014-03-31-Just gave a talk</a></p>
<p>16 0.91789848 <a title="1273-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>17 0.91789651 <a title="1273-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>18 0.91719913 <a title="1273-lda-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>19 0.91645896 <a title="1273-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-17-SAT_stories.html">94 andrew gelman stats-2010-06-17-SAT stories</a></p>
<p>20 0.91576636 <a title="1273-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-The_importance_of_style_in_academic_writing.html">902 andrew gelman stats-2011-09-12-The importance of style in academic writing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
