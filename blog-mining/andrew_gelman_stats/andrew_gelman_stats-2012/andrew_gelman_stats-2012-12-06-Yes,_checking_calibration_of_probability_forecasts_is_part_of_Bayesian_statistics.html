<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1610" href="#">andrew_gelman_stats-2012-1610</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1610-html" href="http://andrewgelman.com/2012/12/06/yes-checking-calibration-of-probability-forecasts-is-part-of-bayesian-statistics/">html</a></p><p>Introduction: Yes, checking calibration of probability forecasts is part of Bayesian statistics.  At the end of this post are three figures from Chapter 1 of Bayesian Data Analysis illustrating empirical evaluation of forecasts.
 
But first the background.  Why am I bringing this up now?  It’s because of something Larry Wasserman  wrote the other day : 
  
  
One of the striking facts about [baseball/political forecaster Nate Silver's recent] book is the emphasis the Silver places on frequency calibration. . . . Have no doubt about it: Nate Silver is a frequentist. For example, he says:

 
One of the most important tests of a forecast — I would argue that it is the single most important one — is called calibration. Out of all the times you said there was a 40 percent chance of rain, how often did rain actually occur? If over the long run, it really did rain about 40 percent of the time, that means your forecasts were well calibrated.
 
  
I had some discussion with Larry in the comments section of h</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Yes, checking calibration of probability forecasts is part of Bayesian statistics. [sent-1, score-0.657]
</p><p>2 It’s because of something Larry Wasserman  wrote the other day :        One of the striking facts about [baseball/political forecaster Nate Silver's recent] book is the emphasis the Silver places on frequency calibration. [sent-5, score-0.362]
</p><p>3 If over the long run, it really did rain about 40 percent of the time, that means your forecasts were well calibrated. [sent-12, score-0.309]
</p><p>4 I had some discussion with Larry in the comments section of his blog and raised the following point: There is such a thing as Bayesian calibration of probability forecasts. [sent-13, score-0.493]
</p><p>5 This isn’t the whole story (as always, calibration matters but so does precision). [sent-23, score-0.418]
</p><p>6 The last time I took (or taught) a theoretical statistics course was almost thirty years ago, but I recall frequentist coverage to be defined with the expectation taken conditional on the value of the unknown parameters theta in the model. [sent-24, score-1.159]
</p><p>7 The calibration Larry describes above (for another example, see  here  and scroll down) is unconditional on theta, thus Bayesian. [sent-25, score-0.638]
</p><p>8 Just about any purely data-based calibration will be Bayesian, as we never know theta. [sent-28, score-0.418]
</p><p>9 I don’t completely understand his reply, but I think he says that that unconditional coverage calculations are frequentist also. [sent-30, score-0.784]
</p><p>10 In that case, maybe we can divide up the coverage calculations as follows:  Unconditional coverage (E(y. [sent-31, score-0.69]
</p><p>11 (For both modes of inference, unconditional coverage will occur if all the assumptions are true. [sent-34, score-0.659]
</p><p>12 They’d rather develop methods with good average coverage properties under minimal assumptions. [sent-47, score-0.363]
</p><p>13 When it comes to frequency evaluation, the point is that Bayesian inference is supposed to be calibrated conditional on any aspect of the data. [sent-50, score-0.577]
</p><p>14 To return to the title of this post, yes, checking calibration of probability forecasts is part of Bayesian statistics. [sent-51, score-0.657]
</p><p>15 We have two examples of this calibration in  the very first chapter  of Bayesian Data Analysis. [sent-52, score-0.518]
</p><p>16 I think it’s fair enough to agree with Larry that these are frequency calculations. [sent-56, score-0.26]
</p><p>17 But they are  Bayesian  frequency calculations by virtue of being conditional on data, not on unknown parameters. [sent-57, score-0.676]
</p><p>18 I think this should make Larry happy, that frequency evaluation (albeit conditional on y, not theta) is central to modern Bayesian statistics. [sent-59, score-0.605]
</p><p>19 I think Nate’s doing them in the Bayesian way but I’ll accept Larry’s statement that Nate and I and other applied Bayesians are frequentists too (of the sort that perform our frequency evaluations conditional on observed data rather than unknown parameters). [sent-62, score-0.811]
</p><p>20 And I do see the conceptual (and, at times, practical) appeal of frequentist methods that allow fewer probability statements but make correspondingly fewer assumptions, even if I don’t usually go that way myself. [sent-63, score-0.491]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('calibration', 0.418), ('bayesian', 0.307), ('coverage', 0.294), ('larry', 0.266), ('frequency', 0.26), ('nate', 0.224), ('theta', 0.216), ('conditional', 0.194), ('unconditional', 0.177), ('frequentist', 0.167), ('rain', 0.146), ('unknown', 0.12), ('silver', 0.115), ('forecasts', 0.109), ('frequentists', 0.103), ('calculations', 0.102), ('chapter', 0.1), ('evaluation', 0.098), ('evaluations', 0.086), ('assumptions', 0.077), ('expectation', 0.077), ('inference', 0.075), ('probability', 0.075), ('occur', 0.07), ('methods', 0.069), ('bayesians', 0.067), ('fewer', 0.065), ('important', 0.06), ('justifiably', 0.059), ('calibrations', 0.056), ('forecaster', 0.056), ('checking', 0.055), ('empirical', 0.054), ('percent', 0.054), ('central', 0.053), ('illustrating', 0.05), ('correspondingly', 0.05), ('data', 0.048), ('calibrated', 0.048), ('parameters', 0.048), ('wary', 0.047), ('book', 0.046), ('albeit', 0.045), ('says', 0.044), ('thirty', 0.043), ('scroll', 0.043), ('tens', 0.042), ('wasserman', 0.042), ('modes', 0.041), ('responsibility', 0.04)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1610-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>Introduction: Yes, checking calibration of probability forecasts is part of Bayesian statistics.  At the end of this post are three figures from Chapter 1 of Bayesian Data Analysis illustrating empirical evaluation of forecasts.
 
But first the background.  Why am I bringing this up now?  It’s because of something Larry Wasserman  wrote the other day : 
  
  
One of the striking facts about [baseball/political forecaster Nate Silver's recent] book is the emphasis the Silver places on frequency calibration. . . . Have no doubt about it: Nate Silver is a frequentist. For example, he says:

 
One of the most important tests of a forecast — I would argue that it is the single most important one — is called calibration. Out of all the times you said there was a 40 percent chance of rain, how often did rain actually occur? If over the long run, it really did rain about 40 percent of the time, that means your forecasts were well calibrated.
 
  
I had some discussion with Larry in the comments section of h</p><p>2 0.26843494 <a title="1610-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-03-Some_thoughts_on_election_forecasting.html">391 andrew gelman stats-2010-11-03-Some thoughts on election forecasting</a></p>
<p>Introduction: I’ve written a lot on polls and elections (“a poll is a snapshot, not a forecast,” etc., or see here for a  more technical paper  with Kari Lock) but had a few things to add in light of Sam Wang’s  recent efforts . As a biologist with a physics degree, Wang brings an outsider’s perspective to political forecasting, which can be a good thing.  (I’m a bit of an outsider to political science myself, as is my sometime collaborator Nate Silver, who’s done a lot of good work in the past few years.)
 
But there are two places where Wang misses the point, I think.
  

 
He refers to his method as a “transparent, low-assumption calculation” and compares it favorably to “fancy modeling” and “assumption-laden models.”  Assumptions are a bad thing, right?  Well, no, I don’t think so.   Bad  assumptions are a bad thing.  Good assumptions are just fine.  Similarly for fancy modeling.  I don’t see why a model should get credit for  not  including a factor that might be important.
 
Let me clarify.  I</p><p>3 0.2618759 <a title="1610-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>Introduction: I sent Deborah Mayo a link to  my paper  with Cosma Shalizi on the philosophy of statistics, and she sent me the link to this conference which unfortunately already occurred.  (It’s too bad, because I’d have liked to have been there.)  I summarized my philosophy as follows:
  
I am highly sympathetic to the approach of Lakatos (or of Popper, if you consider Lakatos’s “Popper_2″ to be a reasonable simulation of the true Popperism), in that (a) I view statistical models as being built within theoretical structures, and (b) I see the checking and refutation of models to be a key part of scientific progress.  A big problem I have with mainstream Bayesianism is its “inductivist” view that science can operate completely smoothly with posterior updates:  the idea that new data causes us to increase the posterior probability of good models and decrease the posterior probability of bad models.  I don’t buy that:  I see models as ever-changing entities that are flexible and can be patched and ex</p><p>4 0.24512257 <a title="1610-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>Introduction: Bayesian inference, conditional on the model and data, conforms to the likelihood principle. But there is more to Bayesian methods than Bayesian inference. See chapters 6 and 7 of Bayesian Data Analysis for much discussion of this point.
 
It saddens me to see that people are still  confused  on this issue.</p><p>5 0.23884897 <a title="1610-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-23-A_statistical_version_of_Arrow%E2%80%99s_paradox.html">586 andrew gelman stats-2011-02-23-A statistical version of Arrow’s paradox</a></p>
<p>Introduction: Unfortunately, when we deal with scientists, statisticians are often put in a setting reminiscent of Arrow’s paradox, where we are asked to provide estimates that are informative and unbiased and confidence statements that are correct conditional on the data and also on the underlying true parameter. [It's not generally possible for an estimate to do all these things at the same time -- ed.]  Larry Wasserman feels that scientists are truly frequentist, and Don Rubin has told me how he feels that scientists interpret all statistical estimates Bayesianly. I have no doubt that both Larry and Don are correct. Voters want lower taxes and more services, and scientists want both Bayesian and frequency coverage; as the saying goes, everybody wants to go to heaven but nobody wants to die.</p><p>6 0.23678666 <a title="1610-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>7 0.23525733 <a title="1610-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-23-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1868 andrew gelman stats-2013-05-23-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>8 0.22002678 <a title="1610-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-14-Progress%21__%28on_the_understanding_of_the_role_of_randomization_in_Bayesian_inference%29.html">1898 andrew gelman stats-2013-06-14-Progress!  (on the understanding of the role of randomization in Bayesian inference)</a></p>
<p>9 0.21691212 <a title="1610-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-03-Statistical_methods_that_work_in_some_settings_but_not_others.html">1560 andrew gelman stats-2012-11-03-Statistical methods that work in some settings but not others</a></p>
<p>10 0.21231055 <a title="1610-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-21-Two_reviews_of_Nate_Silver%E2%80%99s_new_book%2C_from_Kaiser_Fung_and_Cathy_O%E2%80%99Neil.html">1634 andrew gelman stats-2012-12-21-Two reviews of Nate Silver’s new book, from Kaiser Fung and Cathy O’Neil</a></p>
<p>11 0.20450707 <a title="1610-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-Rob_Kass_on_statistical_pragmatism%2C_and_my_reactions.html">317 andrew gelman stats-2010-10-04-Rob Kass on statistical pragmatism, and my reactions</a></p>
<p>12 0.20041789 <a title="1610-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>13 0.19689071 <a title="1610-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-23-Larry_Wasserman%E2%80%99s_statistics_blog.html">1389 andrew gelman stats-2012-06-23-Larry Wasserman’s statistics blog</a></p>
<p>14 0.19328116 <a title="1610-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-10-I_don%E2%80%99t_like_this_cartoon.html">1572 andrew gelman stats-2012-11-10-I don’t like this cartoon</a></p>
<p>15 0.19305407 <a title="1610-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>16 0.1912387 <a title="1610-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>17 0.18308637 <a title="1610-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-16-The_%E2%80%9CWashington_read%E2%80%9D_and_the_algebra_of_conditional_distributions.html">961 andrew gelman stats-2011-10-16-The “Washington read” and the algebra of conditional distributions</a></p>
<p>18 0.18306805 <a title="1610-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<p>19 0.17955868 <a title="1610-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>20 0.1787506 <a title="1610-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.209), (1, 0.171), (2, -0.089), (3, 0.1), (4, -0.174), (5, 0.013), (6, -0.06), (7, 0.102), (8, 0.062), (9, -0.163), (10, 0.004), (11, -0.041), (12, 0.022), (13, 0.003), (14, 0.025), (15, 0.05), (16, 0.022), (17, 0.045), (18, -0.001), (19, 0.007), (20, 0.024), (21, 0.149), (22, -0.0), (23, 0.056), (24, 0.071), (25, -0.009), (26, -0.003), (27, 0.025), (28, 0.024), (29, 0.064), (30, -0.029), (31, 0.042), (32, -0.021), (33, -0.034), (34, 0.043), (35, 0.033), (36, -0.018), (37, 0.011), (38, -0.007), (39, -0.019), (40, 0.038), (41, 0.075), (42, -0.057), (43, -0.066), (44, -0.07), (45, -0.021), (46, 0.086), (47, 0.068), (48, -0.046), (49, 0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97090489 <a title="1610-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>Introduction: Yes, checking calibration of probability forecasts is part of Bayesian statistics.  At the end of this post are three figures from Chapter 1 of Bayesian Data Analysis illustrating empirical evaluation of forecasts.
 
But first the background.  Why am I bringing this up now?  It’s because of something Larry Wasserman  wrote the other day : 
  
  
One of the striking facts about [baseball/political forecaster Nate Silver's recent] book is the emphasis the Silver places on frequency calibration. . . . Have no doubt about it: Nate Silver is a frequentist. For example, he says:

 
One of the most important tests of a forecast — I would argue that it is the single most important one — is called calibration. Out of all the times you said there was a 40 percent chance of rain, how often did rain actually occur? If over the long run, it really did rain about 40 percent of the time, that means your forecasts were well calibrated.
 
  
I had some discussion with Larry in the comments section of h</p><p>2 0.8128913 <a title="1610-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>Introduction: Deborah Mayo recommended that I consider coming up with a new name for the statistical methods that I used, given that the term “Bayesian” has all sorts of associations that I dislike (as discussed, for example, in section 1 of  this article ).
 
I replied that I agree on Bayesian, I never liked the term and always wanted something better, but I couldn’t think of any convenient alternative.  Also, I was finding that Bayesians (even the Bayesians I disagreed with) were reading my research articles, while non-Bayesians were simply ignoring them.  So I thought it was best to identify with, and communicate with, those people who were willing to engage with me.
 
More formally, I’m happy defining “Bayesian” as “using inference from the posterior distribution, p(theta|y)”.  This says nothing about where the probability distributions come from (thus, no requirement to be “subjective” or “objective”) and it says nothing about the models (thus, no requirement to use the discrete models that hav</p><p>3 0.78068048 <a title="1610-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-04-Generalized_Method_of_Moments%2C_whatever_that_is.html">449 andrew gelman stats-2010-12-04-Generalized Method of Moments, whatever that is</a></p>
<p>Introduction: Xuequn Hu writes:
  
I am an econ doctoral student, trying to do some empirical work using Bayesian methods.  Recently I read a paper(and its discussion) that pitches Bayesian methods against GMM (Generalized Method of Moments), which is quite popular in econometrics for frequentists. I am wondering if you can, here or on your blog, give some insights about these two methods, from the perspective of a Bayesian statistician. I know GMM does not conform to likelihood principle, but Bayesian are often charged with strong distribution assumptions.  
  
I can’t actually help on this, since I don’t know what GMM is.  My guess is that, like other methods that don’t explicitly use prior estimation, this method will work well if sufficient information is included as data.  Which would imply a hierarchical structure.</p><p>4 0.77932715 <a title="1610-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-12-%E2%80%9CNot_only_defended_but_also_applied%E2%80%9D%3A_The_perceived_absurdity_of_Bayesian_inference.html">1262 andrew gelman stats-2012-04-12-“Not only defended but also applied”: The perceived absurdity of Bayesian inference</a></p>
<p>Introduction: Updated version  of my paper with Xian:
  
The missionary zeal of many Bayesians of old has been matched, in the other direction, by an attitude among some theoreticians that Bayesian methods are absurd—not merely misguided but obviously wrong in principle. We consider several examples, beginning with Feller’s classic text on probability theory and continuing with more recent cases such as the perceived Bayesian nature of the so-called doomsday argument. We analyze in this note the intellectual background behind various misconceptions about Bayesian statistics, without aiming at a complete historical coverage of the reasons for this dismissal.
  
I love this stuff.</p><p>5 0.77815545 <a title="1610-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-14-Progress%21__%28on_the_understanding_of_the_role_of_randomization_in_Bayesian_inference%29.html">1898 andrew gelman stats-2013-06-14-Progress!  (on the understanding of the role of randomization in Bayesian inference)</a></p>
<p>Introduction: Leading theoretical statistician Larry Wassserman  in 2008 :  
  
Some of the greatest contributions of statistics to science involve adding additional randomness and leveraging that randomness. Examples are randomized experiments, permutation tests, cross-validation and data-splitting. These are unabashedly frequentist ideas and, while one can strain to fit them into a Bayesian framework, they don’t really have a place in Bayesian inference. The fact that Bayesian methods do not naturally accommodate such a powerful set of statistical ideas seems like a serious deficiency.
  
To which I responded on the second-to-last paragraph of page 8  here .
 
Larry Wasserman in  2013 :
  
Some people say that there is no role for randomization in Bayesian inference. In other words, the randomization mechanism plays no role in Bayes’ theorem. But this is not really true. Without randomization, we can indeed derive a posterior for theta but it is highly sensitive to the prior. This is just a restat</p><p>6 0.7766881 <a title="1610-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>7 0.77404362 <a title="1610-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>8 0.77342921 <a title="1610-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>9 0.77031815 <a title="1610-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-03-Statistical_methods_that_work_in_some_settings_but_not_others.html">1560 andrew gelman stats-2012-11-03-Statistical methods that work in some settings but not others</a></p>
<p>10 0.76945287 <a title="1610-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>11 0.7665785 <a title="1610-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>12 0.764902 <a title="1610-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>13 0.75982559 <a title="1610-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>14 0.75826895 <a title="1610-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-28-Why_during_the_1950-1960%E2%80%B2s_did_Jerry_Cornfield_become_a_Bayesian%3F.html">2000 andrew gelman stats-2013-08-28-Why during the 1950-1960′s did Jerry Cornfield become a Bayesian?</a></p>
<p>15 0.7568329 <a title="1610-lsi-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>16 0.75288159 <a title="1610-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-Bayesian_models_for_simultaneous_equation_systems%3F.html">183 andrew gelman stats-2010-08-04-Bayesian models for simultaneous equation systems?</a></p>
<p>17 0.74754232 <a title="1610-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-29-Another_Feller_theory.html">1781 andrew gelman stats-2013-03-29-Another Feller theory</a></p>
<p>18 0.74029732 <a title="1610-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>19 0.73890644 <a title="1610-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-23-A_statistical_version_of_Arrow%E2%80%99s_paradox.html">586 andrew gelman stats-2011-02-23-A statistical version of Arrow’s paradox</a></p>
<p>20 0.73623747 <a title="1610-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-16-Looking_for_Bayesian_expertise_in_India%2C_for_the_purpose_of_analysis_of_sarcoma_trials.html">2293 andrew gelman stats-2014-04-16-Looking for Bayesian expertise in India, for the purpose of analysis of sarcoma trials</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.021), (5, 0.064), (8, 0.022), (11, 0.06), (15, 0.057), (16, 0.078), (20, 0.012), (24, 0.167), (36, 0.016), (42, 0.013), (68, 0.01), (76, 0.015), (85, 0.018), (86, 0.021), (95, 0.016), (99, 0.285)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96777511 <a title="1610-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>Introduction: Yes, checking calibration of probability forecasts is part of Bayesian statistics.  At the end of this post are three figures from Chapter 1 of Bayesian Data Analysis illustrating empirical evaluation of forecasts.
 
But first the background.  Why am I bringing this up now?  It’s because of something Larry Wasserman  wrote the other day : 
  
  
One of the striking facts about [baseball/political forecaster Nate Silver's recent] book is the emphasis the Silver places on frequency calibration. . . . Have no doubt about it: Nate Silver is a frequentist. For example, he says:

 
One of the most important tests of a forecast — I would argue that it is the single most important one — is called calibration. Out of all the times you said there was a 40 percent chance of rain, how often did rain actually occur? If over the long run, it really did rain about 40 percent of the time, that means your forecasts were well calibrated.
 
  
I had some discussion with Larry in the comments section of h</p><p>2 0.9631018 <a title="1610-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-08-P-values_and_statistical_practice.html">1713 andrew gelman stats-2013-02-08-P-values and statistical practice</a></p>
<p>Introduction: From  my new article  in the journal Epidemiology:
  
Sander Greenland and Charles Poole accept that P values are here to stay but recognize that some of their most common interpretations have problems. The casual view of the P value as posterior probability of the truth of the null hypothesis is false and not even close to valid under any reasonable model, yet this misunderstanding persists even in high-stakes settings (as discussed, for example, by Greenland in 2011). The formal view of the P value as a probability conditional on the null is mathematically correct but typically irrelevant to research goals (hence, the popularity of alternative—if wrong—interpretations). A Bayesian interpretation based on a spike-and-slab model makes little sense in applied contexts in epidemiology, political science, and other fields in which true effects are typically nonzero and bounded (thus violating both the “spike” and the “slab” parts of the model).


I find Greenland and Poole’s perspective t</p><p>3 0.95889068 <a title="1610-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-03-Some_thoughts_on_election_forecasting.html">391 andrew gelman stats-2010-11-03-Some thoughts on election forecasting</a></p>
<p>Introduction: I’ve written a lot on polls and elections (“a poll is a snapshot, not a forecast,” etc., or see here for a  more technical paper  with Kari Lock) but had a few things to add in light of Sam Wang’s  recent efforts . As a biologist with a physics degree, Wang brings an outsider’s perspective to political forecasting, which can be a good thing.  (I’m a bit of an outsider to political science myself, as is my sometime collaborator Nate Silver, who’s done a lot of good work in the past few years.)
 
But there are two places where Wang misses the point, I think.
  

 
He refers to his method as a “transparent, low-assumption calculation” and compares it favorably to “fancy modeling” and “assumption-laden models.”  Assumptions are a bad thing, right?  Well, no, I don’t think so.   Bad  assumptions are a bad thing.  Good assumptions are just fine.  Similarly for fancy modeling.  I don’t see why a model should get credit for  not  including a factor that might be important.
 
Let me clarify.  I</p><p>4 0.95848668 <a title="1610-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-24-Textbook_for_data_visualization%3F.html">1637 andrew gelman stats-2012-12-24-Textbook for data visualization?</a></p>
<p>Introduction: Dave Choi writes:
  
I’m building a course called “Exploring and visualizing data,” for Heinz college in Carnegie Mellon (public policy and information systems). Do you know any books that might be good for such a course? I’m hoping to get non-statisticians to appreciate the statistician’s point of view on this subject.
  
I immediately thought of Bill Cleveland’s 1985 classic, The Elements of Graphing Data, but I wasn’t sure of what comes next.  There are a lot of books on how to make graphics in R, but I’m not quite sure that’s the point.  And I’m loath to recommend Tufte since it would be kinda scary if a student were to take all of his ideas too seriously.
 
Any suggestions?</p><p>5 0.95788813 <a title="1610-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-21-Will_Tiger_Woods_catch_Jack_Nicklaus%3F__And_a_discussion_of_the_virtues_of_using_continuous_data_even_if_your_goal_is_discrete_prediction.html">1387 andrew gelman stats-2012-06-21-Will Tiger Woods catch Jack Nicklaus?  And a discussion of the virtues of using continuous data even if your goal is discrete prediction</a></p>
<p>Introduction: I know next to nothing about golf.  My mini-golf scores typically approach the maximum of 7 per hole, and I’ve never actually played macro-golf.  I did publish a paper on golf once ( A Probability Model for Golf Putting , with Deb Nolan), but it’s not so rare for people to publish papers on topics they know nothing about.  Those who can’t, research.
 
But I certainly have the ability to post other people’s ideas.  Charles Murray writes:
  
I [Murray] am playing around with the likelihood of Tiger Woods breaking Nicklaus’s record in the Majors. I’ve already gone on record  two years ago  with the reason why he won’t, but now I’m looking at it from a non-psychological perspective. Given the history of the majors, what how far above the average _for other great golfers_ does Tiger have to perform?


Here’s the procedure I’ve been working on:


1. For all golfers who have won at at least one major since 1934 (the year the Masters began), create 120 lines: one for each Major for each year f</p><p>6 0.95617843 <a title="1610-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-25-Is_there_too_much_coauthorship_in_economics_%28and_science_more_generally%29%3F__Or_too_little%3F.html">1914 andrew gelman stats-2013-06-25-Is there too much coauthorship in economics (and science more generally)?  Or too little?</a></p>
<p>7 0.95580065 <a title="1610-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-21-Belief_in_hell_is_associated_with_lower_crime_rates.html">1386 andrew gelman stats-2012-06-21-Belief in hell is associated with lower crime rates</a></p>
<p>8 0.9529742 <a title="1610-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-15-Outta_control_political_incorrectness.html">1578 andrew gelman stats-2012-11-15-Outta control political incorrectness</a></p>
<p>9 0.9520123 <a title="1610-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-27-Why_don%E2%80%99t_more_medical_discoveries_become_cures%3F.html">167 andrew gelman stats-2010-07-27-Why don’t more medical discoveries become cures?</a></p>
<p>10 0.951877 <a title="1610-lda-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>11 0.95177495 <a title="1610-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-28-Writing_for_free.html">2080 andrew gelman stats-2013-10-28-Writing for free</a></p>
<p>12 0.95110083 <a title="1610-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-08-A_Bayesian_approach_for_peer-review_panels%3F__and_a_speculation_about_Bruno_Frey.html">2055 andrew gelman stats-2013-10-08-A Bayesian approach for peer-review panels?  and a speculation about Bruno Frey</a></p>
<p>13 0.95090127 <a title="1610-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-12-How_to_best_graph_the_Beveridge_curve%2C_relating_the_vacancy_rate_in_jobs_to_the_unemployment_rate%3F.html">1894 andrew gelman stats-2013-06-12-How to best graph the Beveridge curve, relating the vacancy rate in jobs to the unemployment rate?</a></p>
<p>14 0.95052981 <a title="1610-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-22-Procrastination_as_a_positive_productivity_strategy.html">1225 andrew gelman stats-2012-03-22-Procrastination as a positive productivity strategy</a></p>
<p>15 0.95036685 <a title="1610-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>16 0.94999611 <a title="1610-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-03-Reinventing_the_wheel%2C_only_more_so..html">447 andrew gelman stats-2010-12-03-Reinventing the wheel, only more so.</a></p>
<p>17 0.94960523 <a title="1610-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>18 0.94959688 <a title="1610-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-The_importance_of_style_in_academic_writing.html">902 andrew gelman stats-2011-09-12-The importance of style in academic writing</a></p>
<p>19 0.94912159 <a title="1610-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-23-A_statistical_version_of_Arrow%E2%80%99s_paradox.html">586 andrew gelman stats-2011-02-23-A statistical version of Arrow’s paradox</a></p>
<p>20 0.9483875 <a title="1610-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-Infovis%2C_infographics%2C_and_data_visualization%3A__Where_I%E2%80%99m_coming_from%2C_and_where_I%E2%80%99d_like_to_go.html">878 andrew gelman stats-2011-08-29-Infovis, infographics, and data visualization:  Where I’m coming from, and where I’d like to go</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
