<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1209" href="#">andrew_gelman_stats-2012-1209</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1209-html" href="http://andrewgelman.com/2012/03/12/as-a-bayesian-i-want-scientists-to-report-their-data-non-bayesianly/">html</a></p><p>Introduction: Philipp Doebler writes: 
  
  
I was quite happy that recently you shared some thoughts of yours and others on meta-analysis. I especially liked the  slides by Chris Schmid  that you linked from your blog. A large portion of my work deals with meta-analysis and I am also fond of using Bayesian methods (actually two of the projects I am working on are very Bayesian), though I can not say I have opinions with respect to the underlying philosophy. I would say though, that I do share your view that there are good reasons to use informative priors.


The reason I am writing to you is that this leads to the following dilemma, which is puzzling me. Say a number of scientists conduct similar studies over the years and all of them did this in a Bayesian fashion. If each of the groups used informative priors based on the research of existing groups the priors could become more and more informative over the years, since more and more is known over the subject. At least in smallish studies these p</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Philipp Doebler writes:        I was quite happy that recently you shared some thoughts of yours and others on meta-analysis. [sent-1, score-0.079]
</p><p>2 I especially liked the  slides by Chris Schmid  that you linked from your blog. [sent-2, score-0.219]
</p><p>3 A large portion of my work deals with meta-analysis and I am also fond of using Bayesian methods (actually two of the projects I am working on are very Bayesian), though I can not say I have opinions with respect to the underlying philosophy. [sent-3, score-0.716]
</p><p>4 I would say though, that I do share your view that there are good reasons to use informative priors. [sent-4, score-0.425]
</p><p>5 The reason I am writing to you is that this leads to the following dilemma, which is puzzling me. [sent-5, score-0.232]
</p><p>6 Say a number of scientists conduct similar studies over the years and all of them did this in a Bayesian fashion. [sent-6, score-0.586]
</p><p>7 If each of the groups used informative priors based on the research of existing groups the priors could become more and more informative over the years, since more and more is known over the subject. [sent-7, score-1.382]
</p><p>8 At least in smallish studies these priors will have an impact on the conclusion, and the impact will increase with time. [sent-8, score-1.011]
</p><p>9 The worst case might be, that a) there is a form of regression to the mean of outcomes the individual studies and b) the variance of the effect sizes are smaller due to the highly informative priors. [sent-9, score-1.159]
</p><p>10 In some sense each of the primary studies is boosting its sample size by using informative priors. [sent-10, score-1.239]
</p><p>11 While this all makes perfect sense on the level of the primary studies, on the meta-analytic level the studies look as if they had achieved more precise estimates then they actually have and also there might be less heterogeneity observed than there really is. [sent-11, score-1.553]
</p><p>12 One could even say, that the newer studies are forstalling the meta-analysis. [sent-12, score-0.507]
</p><p>13 I am not sure if the above leads to the advice to use non-informative priors on the primary study level, so that primary study level outcomes are not influenced by other studies, or if the above only underlines the need to report outcomes in primary studies for more than one prior. [sent-13, score-2.724]
</p><p>14 It is difficult to combine posterior distributions as there is the risk of counting some information multiple times. [sent-16, score-0.168]
</p><p>15 Sometimes I say, As a Bayesian I want scientists to report their data non-Bayesianly. [sent-17, score-0.191]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('studies', 0.402), ('primary', 0.357), ('informative', 0.3), ('priors', 0.245), ('outcomes', 0.187), ('level', 0.171), ('bayesian', 0.136), ('leads', 0.132), ('say', 0.125), ('impact', 0.125), ('boosting', 0.118), ('fond', 0.118), ('schmid', 0.118), ('dilemma', 0.118), ('smallish', 0.114), ('groups', 0.113), ('newer', 0.105), ('deals', 0.101), ('puzzling', 0.1), ('scientists', 0.099), ('heterogeneity', 0.098), ('portion', 0.096), ('achieved', 0.093), ('report', 0.092), ('influenced', 0.091), ('combine', 0.086), ('conduct', 0.085), ('welcome', 0.085), ('counting', 0.082), ('shared', 0.079), ('slides', 0.078), ('worst', 0.075), ('projects', 0.075), ('precise', 0.073), ('study', 0.073), ('liked', 0.073), ('opinions', 0.07), ('linked', 0.068), ('though', 0.068), ('sizes', 0.067), ('smaller', 0.067), ('existing', 0.066), ('views', 0.066), ('conclusion', 0.066), ('perfect', 0.065), ('chris', 0.065), ('respect', 0.063), ('sense', 0.062), ('observed', 0.061), ('due', 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1209-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-12-As_a_Bayesian_I_want_scientists_to_report_their_data_non-Bayesianly.html">1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</a></p>
<p>Introduction: Philipp Doebler writes: 
  
  
I was quite happy that recently you shared some thoughts of yours and others on meta-analysis. I especially liked the  slides by Chris Schmid  that you linked from your blog. A large portion of my work deals with meta-analysis and I am also fond of using Bayesian methods (actually two of the projects I am working on are very Bayesian), though I can not say I have opinions with respect to the underlying philosophy. I would say though, that I do share your view that there are good reasons to use informative priors.


The reason I am writing to you is that this leads to the following dilemma, which is puzzling me. Say a number of scientists conduct similar studies over the years and all of them did this in a Bayesian fashion. If each of the groups used informative priors based on the research of existing groups the priors could become more and more informative over the years, since more and more is known over the subject. At least in smallish studies these p</p><p>2 0.26875666 <a title="1209-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-05-More_plain_old_everyday_Bayesianism.html">1926 andrew gelman stats-2013-07-05-More plain old everyday Bayesianism</a></p>
<p>Introduction: Following up on  this story , Bob Goodman writes:
  
A most recent issue of the New England Journal of Medicine published a study entitled  “Biventricular Pacing for Atrioventricular Block and Systolic Dysfunction,” (N Engl J Med 2013; 368:1585-1593), whereby “A hierarchical Bayesian proportional-hazards model was used for analysis of the primary outcome.” It is the first study I can recall in this journal that has reported on Table 2 (primary outcomes) “The Posterior Probability of Hazard Ratio < 1" (which in this case was .9978).
  
This is ok, but to be really picky I will say that there’s typically not so much reason to care about the posterior probability that the effect is greater than 1; I’d rather have an estimate of the effect.  Also we  should  be using informative priors.</p><p>3 0.2216128 <a title="1209-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<p>Introduction: A couple days ago we  discussed  some remarks by Tony O’Hagan and Jim Berger on weakly informative priors.  Jim  followed up  on Deborah Mayo’s blog with this:
  
Objective Bayesian priors are often improper (i.e., have infinite total mass), but this is not a problem when they are developed correctly. But not every improper prior is satisfactory. For instance, the constant prior is known to be unsatisfactory in many situations. The ‘solution’ pseudo-Bayesians often use is to choose a constant prior over a large but bounded set (a ‘weakly informative’ prior), saying it is now proper and so all is well. This is not true; if the constant prior on the whole parameter space is bad, so will be the constant prior over the bounded set. The problem is, in part, that some people confuse proper priors with subjective priors and, having learned that true subjective priors are fine, incorrectly presume that weakly informative proper priors are fine.
  
I have a few reactions to this:
 
1.  I agree</p><p>4 0.21087085 <a title="1209-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-27-%E2%80%9CKeeping_things_unridiculous%E2%80%9D%3A__Berger%2C_O%E2%80%99Hagan%2C_and_me_on_weakly_informative_priors.html">1087 andrew gelman stats-2011-12-27-“Keeping things unridiculous”:  Berger, O’Hagan, and me on weakly informative priors</a></p>
<p>Introduction: Deborah Mayo sent me  this quote  from Jim Berger:
  
Too often I see people pretending to be subjectivists, and then using “weakly informative” priors that the objective Bayesian community knows are terrible and will give ridiculous answers; subjectivism is then being used as a shield to hide ignorance. . . . In my own more provocative moments, I claim that the only true subjectivists are the objective Bayesians, because they refuse to use subjectivism as a shield against criticism of sloppy pseudo-Bayesian practice.
  
This caught my attention because I’ve become more and more convinced that weakly informative priors are  the right way to go  in many different situations.  I don’t think Berger was talking about  me , though, as the above quote came from a publication in 2006, at which time I’d only started writing about weakly informative priors.
 
Going back to Berger’s  article , I see that his “weakly informative priors” remark was aimed at  this article  by Anthony O’Hagan, who w</p><p>5 0.20022213 <a title="1209-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-Understanding_how_estimates_change_when_you_move_to_a_multilevel_model.html">850 andrew gelman stats-2011-08-11-Understanding how estimates change when you move to a multilevel model</a></p>
<p>Introduction: Ramu Sudhagoni writes:
  
 
I am working on combining three longitudinal studies using Bayesian hierarchical technique.  In each study, I have at least 70 subjects follow up on 5 different visit months. My model consists of 10 different covariates including longitudinal and cross-sectional effects. Mixed models are used to fit the three studies individually using Bayesian approach and I noticed that few covariates were significant. When I combined using three level hierarchical approach, all the covariates became non-significant at the population level,  and large estimates were found for variance parameters at the population level. I am struggling to understand why I am getting large variances at population level and wider credible intervals. I assumed non-informative normal priors for all my cross sectional and longitudinal effects, and non-informative inverse-gamma priors for variance parameters. I followed the approach explained by Inoue et al. (Title: Combining Longitudinal Studie</p><p>6 0.16792339 <a title="1209-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<p>7 0.16754998 <a title="1209-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<p>8 0.16682845 <a title="1209-tfidf-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>9 0.15763602 <a title="1209-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-26-New_research_journal_on_observational_studies.html">2268 andrew gelman stats-2014-03-26-New research journal on observational studies</a></p>
<p>10 0.14714783 <a title="1209-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<p>11 0.13842729 <a title="1209-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-15-Reputations_changeable%2C_situations_tolerable.html">1858 andrew gelman stats-2013-05-15-Reputations changeable, situations tolerable</a></p>
<p>12 0.13689649 <a title="1209-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-21-D._Buggin.html">1465 andrew gelman stats-2012-08-21-D. Buggin</a></p>
<p>13 0.13679364 <a title="1209-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>14 0.13664505 <a title="1209-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-27-%E2%80%9CWhat_Can_we_Learn_from_the_Many_Labs_Replication_Project%3F%E2%80%9D.html">2227 andrew gelman stats-2014-02-27-“What Can we Learn from the Many Labs Replication Project?”</a></p>
<p>15 0.13657875 <a title="1209-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-30-Infill_asymptotics_and_sprawl_asymptotics.html">1877 andrew gelman stats-2013-05-30-Infill asymptotics and sprawl asymptotics</a></p>
<p>16 0.1347907 <a title="1209-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-11-Weakly_informative_priors_for_Bayesian_nonparametric_models%3F.html">1454 andrew gelman stats-2012-08-11-Weakly informative priors for Bayesian nonparametric models?</a></p>
<p>17 0.13326757 <a title="1209-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-07-Neutral_noninformative_and_informative_conjugate_beta_and_gamma_prior_distributions.html">1046 andrew gelman stats-2011-12-07-Neutral noninformative and informative conjugate beta and gamma prior distributions</a></p>
<p>18 0.13156863 <a title="1209-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>19 0.12985267 <a title="1209-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-06-Comparing_people_from_two_surveys%2C_one_of_which_is_a_simple_random_sample_and_one_of_which_is_not.html">1523 andrew gelman stats-2012-10-06-Comparing people from two surveys, one of which is a simple random sample and one of which is not</a></p>
<p>20 0.12629497 <a title="1209-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-15-Weakly_informative_priors_and_imprecise_probabilities.html">468 andrew gelman stats-2010-12-15-Weakly informative priors and imprecise probabilities</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.217), (1, 0.112), (2, 0.028), (3, -0.054), (4, -0.052), (5, -0.033), (6, 0.044), (7, 0.026), (8, -0.119), (9, 0.048), (10, 0.018), (11, -0.006), (12, 0.095), (13, 0.025), (14, 0.078), (15, 0.022), (16, 0.023), (17, 0.031), (18, -0.01), (19, 0.062), (20, -0.088), (21, 0.038), (22, -0.029), (23, 0.051), (24, -0.033), (25, -0.01), (26, 0.03), (27, -0.005), (28, -0.009), (29, 0.047), (30, -0.041), (31, -0.062), (32, 0.014), (33, -0.009), (34, 0.041), (35, 0.059), (36, -0.017), (37, 0.006), (38, 0.08), (39, 0.007), (40, -0.008), (41, -0.009), (42, 0.097), (43, -0.002), (44, 0.044), (45, -0.057), (46, -0.048), (47, 0.056), (48, 0.013), (49, 0.006)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97339052 <a title="1209-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-12-As_a_Bayesian_I_want_scientists_to_report_their_data_non-Bayesianly.html">1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</a></p>
<p>Introduction: Philipp Doebler writes: 
  
  
I was quite happy that recently you shared some thoughts of yours and others on meta-analysis. I especially liked the  slides by Chris Schmid  that you linked from your blog. A large portion of my work deals with meta-analysis and I am also fond of using Bayesian methods (actually two of the projects I am working on are very Bayesian), though I can not say I have opinions with respect to the underlying philosophy. I would say though, that I do share your view that there are good reasons to use informative priors.


The reason I am writing to you is that this leads to the following dilemma, which is puzzling me. Say a number of scientists conduct similar studies over the years and all of them did this in a Bayesian fashion. If each of the groups used informative priors based on the research of existing groups the priors could become more and more informative over the years, since more and more is known over the subject. At least in smallish studies these p</p><p>2 0.77137166 <a title="1209-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-15-Weakly_informative_priors_and_imprecise_probabilities.html">468 andrew gelman stats-2010-12-15-Weakly informative priors and imprecise probabilities</a></p>
<p>Introduction: Giorgio Corani writes:
  
Your work on weakly informative priors is close to some research I [Corani] did (together with Prof. Zaffalon) in the last years using the so-called imprecise probabilities. The idea is to work with a set of priors (containing  even very different priors); to update them via Bayes’ rule and  then compute a set of posteriors.


The set of priors is convex and the priors are Dirichlet (thus, conjugate to the likelihood); this allows to compute the set of posteriors exactly and efficiently.


I [Corani] have used this approach for classification, extending  naive Bayes and TAN to imprecise probabilities. Classifiers based on imprecise probabilities return more classes when they find that the most probable class is prior-dependent, i.e., if picking different priors in the convex set leads to identify different classes as the most probable one. Instead of returning a single (unreliable) prior-dependent class, credal classifiers in this case preserve reliability by</p><p>3 0.7498588 <a title="1209-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-27-%E2%80%9CKeeping_things_unridiculous%E2%80%9D%3A__Berger%2C_O%E2%80%99Hagan%2C_and_me_on_weakly_informative_priors.html">1087 andrew gelman stats-2011-12-27-“Keeping things unridiculous”:  Berger, O’Hagan, and me on weakly informative priors</a></p>
<p>Introduction: Deborah Mayo sent me  this quote  from Jim Berger:
  
Too often I see people pretending to be subjectivists, and then using “weakly informative” priors that the objective Bayesian community knows are terrible and will give ridiculous answers; subjectivism is then being used as a shield to hide ignorance. . . . In my own more provocative moments, I claim that the only true subjectivists are the objective Bayesians, because they refuse to use subjectivism as a shield against criticism of sloppy pseudo-Bayesian practice.
  
This caught my attention because I’ve become more and more convinced that weakly informative priors are  the right way to go  in many different situations.  I don’t think Berger was talking about  me , though, as the above quote came from a publication in 2006, at which time I’d only started writing about weakly informative priors.
 
Going back to Berger’s  article , I see that his “weakly informative priors” remark was aimed at  this article  by Anthony O’Hagan, who w</p><p>4 0.72200465 <a title="1209-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-Understanding_how_estimates_change_when_you_move_to_a_multilevel_model.html">850 andrew gelman stats-2011-08-11-Understanding how estimates change when you move to a multilevel model</a></p>
<p>Introduction: Ramu Sudhagoni writes:
  
 
I am working on combining three longitudinal studies using Bayesian hierarchical technique.  In each study, I have at least 70 subjects follow up on 5 different visit months. My model consists of 10 different covariates including longitudinal and cross-sectional effects. Mixed models are used to fit the three studies individually using Bayesian approach and I noticed that few covariates were significant. When I combined using three level hierarchical approach, all the covariates became non-significant at the population level,  and large estimates were found for variance parameters at the population level. I am struggling to understand why I am getting large variances at population level and wider credible intervals. I assumed non-informative normal priors for all my cross sectional and longitudinal effects, and non-informative inverse-gamma priors for variance parameters. I followed the approach explained by Inoue et al. (Title: Combining Longitudinal Studie</p><p>5 0.70757961 <a title="1209-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<p>Introduction: A couple days ago we  discussed  some remarks by Tony O’Hagan and Jim Berger on weakly informative priors.  Jim  followed up  on Deborah Mayo’s blog with this:
  
Objective Bayesian priors are often improper (i.e., have infinite total mass), but this is not a problem when they are developed correctly. But not every improper prior is satisfactory. For instance, the constant prior is known to be unsatisfactory in many situations. The ‘solution’ pseudo-Bayesians often use is to choose a constant prior over a large but bounded set (a ‘weakly informative’ prior), saying it is now proper and so all is well. This is not true; if the constant prior on the whole parameter space is bad, so will be the constant prior over the bounded set. The problem is, in part, that some people confuse proper priors with subjective priors and, having learned that true subjective priors are fine, incorrectly presume that weakly informative proper priors are fine.
  
I have a few reactions to this:
 
1.  I agree</p><p>6 0.70524192 <a title="1209-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<p>7 0.69717634 <a title="1209-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-05-More_plain_old_everyday_Bayesianism.html">1926 andrew gelman stats-2013-07-05-More plain old everyday Bayesianism</a></p>
<p>8 0.69630373 <a title="1209-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-13-%E2%80%9CWhat_are_some_situations_in_which_the_classical_approach_%28or_a_naive_implementation_of_it%2C_based_on_cookbook_recipes%29_gives_worse_results_than_a_Bayesian_approach%2C_results_that_actually_impeded_the_science%3F%E2%80%9D.html">2099 andrew gelman stats-2013-11-13-“What are some situations in which the classical approach (or a naive implementation of it, based on cookbook recipes) gives worse results than a Bayesian approach, results that actually impeded the science?”</a></p>
<p>9 0.69127858 <a title="1209-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-On_the_half-Cauchy_prior_for_a_global_scale_parameter.html">801 andrew gelman stats-2011-07-13-On the half-Cauchy prior for a global scale parameter</a></p>
<p>10 0.6893301 <a title="1209-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<p>11 0.67727566 <a title="1209-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-02-The_problem_of_overestimation_of_group-level_variance_parameters.html">63 andrew gelman stats-2010-06-02-The problem of overestimation of group-level variance parameters</a></p>
<p>12 0.67477447 <a title="1209-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-03-Is_0.05_too_strict_as_a_p-value_threshold%3F.html">446 andrew gelman stats-2010-12-03-Is 0.05 too strict as a p-value threshold?</a></p>
<p>13 0.67315668 <a title="1209-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-30-Infill_asymptotics_and_sprawl_asymptotics.html">1877 andrew gelman stats-2013-05-30-Infill asymptotics and sprawl asymptotics</a></p>
<p>14 0.67046058 <a title="1209-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-01-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Cox_and_Mayo.html">1149 andrew gelman stats-2012-02-01-Philosophy of Bayesian statistics:  my reactions to Cox and Mayo</a></p>
<p>15 0.66705132 <a title="1209-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-Philosophy_of_Bayesian_statistics%3A_my_reactions_to_Hendry.html">1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</a></p>
<p>16 0.65489113 <a title="1209-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-15-Reputations_changeable%2C_situations_tolerable.html">1858 andrew gelman stats-2013-05-15-Reputations changeable, situations tolerable</a></p>
<p>17 0.65301132 <a title="1209-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-11-Weakly_informative_priors_for_Bayesian_nonparametric_models%3F.html">1454 andrew gelman stats-2012-08-11-Weakly informative priors for Bayesian nonparametric models?</a></p>
<p>18 0.65223926 <a title="1209-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Correcting_for_multiple_comparisons_in_a_Bayesian_regression_model.html">1989 andrew gelman stats-2013-08-20-Correcting for multiple comparisons in a Bayesian regression model</a></p>
<p>19 0.65006268 <a title="1209-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-15-Prior_Selection_for_Vector_Autoregressions.html">1674 andrew gelman stats-2013-01-15-Prior Selection for Vector Autoregressions</a></p>
<p>20 0.64840263 <a title="1209-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-17-Ma_conf%C3%A9rence_demain_%28mardi%29_%C3%A0_l%E2%80%99%C3%89cole_Polytechnique.html">2252 andrew gelman stats-2014-03-17-Ma conférence demain (mardi) à l’École Polytechnique</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(10, 0.057), (15, 0.014), (16, 0.052), (21, 0.023), (23, 0.013), (24, 0.237), (42, 0.014), (45, 0.011), (55, 0.023), (63, 0.012), (69, 0.012), (95, 0.028), (98, 0.012), (99, 0.393)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99216586 <a title="1209-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-03-Question_about_predictive_checks.html">1363 andrew gelman stats-2012-06-03-Question about predictive checks</a></p>
<p>Introduction: Klaas Metselaar writes: 
  
  
I [Metselaar] am currently involved in a discussion about the use of the notion “predictive” as used in “posterior predictive check”. I would argue that the notion “predictive” should be reserved for posterior checks using information not used in the determination of the posterior. 
I quote from the discussion: 
“However, the predictive uncertainty in a Bayesian calculation requires sampling from all the random variables, and this includes both the model parameters and the residual error”.


My [Metselaar's] comment:


This may be exactly the point I am worried about: shouldn’t the predictive uncertainty be defined as sampling from the posterior parameter distribution +  residual error + sampling from the prediction error distribution? 
Residual error reduces to measurement error in the case of a  model which is perfect for the sample of experiments. Measurement error could be reduced to almost zero by ideal and perfect measurement instruments. 
I would h</p><p>2 0.98833776 <a title="1209-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-08-Statistical_significance_and_the_dangerous_lure_of_certainty.html">1974 andrew gelman stats-2013-08-08-Statistical significance and the dangerous lure of certainty</a></p>
<p>Introduction: In a discussion of some of the recent controversy over promiscuously statistically-significant science,  Jeff Leek  Rafael Irizarry  points out  there is a tradeoff between stringency and discovery and suggests that raising the bar of statistical significance (for example, to the .01 or .001 level instead of the conventional .05) will reduce the noise level but will also reduce the rate of identification of actual discoveries.
 
I agree.  But I should clarify that when I criticize a claim of statistical significance, arguing that the claimed “p less than .05″ could easily occur under the null hypothesis, given that the hypothesis test that is chosen is contingent on the data (see examples  here  of clothing and menstrual cycle, arm circumference and political attitudes, and ESP), I am  not  recommending a switch to a more stringent p-value threshold.  Rather, I would prefer p-values not to be used as a threshold for publication at all.
 
Here’s my point:  The question is not  whether</p><p>3 0.98823488 <a title="1209-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-17-Is_chartjunk_really_%E2%80%9Cmore_useful%E2%80%9D_than_plain_graphs%3F__I_don%E2%80%99t_think_so..html">37 andrew gelman stats-2010-05-17-Is chartjunk really “more useful” than plain graphs?  I don’t think so.</a></p>
<p>Introduction: Helen DeWitt  links  to  this blog  that reports on  a study  by Scott Bateman, Carl Gutwin, David McDine, Regan Mandryk, Aaron Genest, and Christopher Brooks that claims the following:
  
Guidelines for designing information charts often state that the presentation should reduce ‘chart junk’–visual embellishments that are not essential to understanding the data. . . . we conducted an experiment that compared embellished charts with plain ones, and measured both interpretation accuracy and long-term recall. We found that people’s accuracy in describing the embellished charts was no worse than for plain charts, and that their recall after a two-to-three-week gap was significantly better.
  
As the above-linked blogger puts it, “chartjunk is more useful than plain graphs. . . . Tufte is not going to like this.”
 
I can’t speak for Ed Tufte, but I’m not gonna take this claim about chartjunk lying down.
 
I have two points to make which I hope can stop the above-linked study from being sla</p><p>4 0.98740971 <a title="1209-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-24-Bell_Labs.html">970 andrew gelman stats-2011-10-24-Bell Labs</a></p>
<p>Introduction: Sining Chen told me they’re hiring in the  statistics group at Bell Labs .  I’ll do my bit for economic stimulus by announcing this job (see below).
 
I love Bell Labs.  I worked there for three summers, in a physics lab in 1985-86 under the supervision of Loren Pfeiffer, and by myself in the statistics group in 1990.
 
I learned a lot working for Loren.  He was a really smart and driven guy.  His lab was a small set of rooms—in Bell Labs, everything’s in a small room, as they value the positive externality of close physical proximity of different labs, which you get by making each lab compact—and it was Loren, his assistant (a guy named Ken West who kept everything running in the lab), and three summer students: me, Gowton Achaibar, and a girl whose name I’ve forgotten.  Gowtan and I had a lot of fun chatting in the lab.  One day I made a silly comment about Gowton’s accent—he was from Guyana and pronounced “three” as “tree”—and then I apologized and said:  Hey, here I am making fun o</p><p>5 0.98690295 <a title="1209-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-01-Why_big_effects_are_more_important_than_small_effects.html">1744 andrew gelman stats-2013-03-01-Why big effects are more important than small effects</a></p>
<p>Introduction: The title of this post is silly but I have an important point to make, regarding an implicit model which I think many people assume even though it does not really make sense.
 
Following a link from Sanjay Srivastava, I came across  a post  from David Funder saying that it’s useful to talk about the sizes of effects (I actually prefer the term “comparisons” so as to avoid the causal baggage) rather than just their signs.  I  agree , and I wanted to elaborate a bit on a point that comes up in Funder’s discussion.  He quotes an (unnamed) prominent social psychologist as writing:
  
The key to our research . . . [is not] to accurately estimate effect size. If I were testing an advertisement for a marketing research firm and wanted to be sure that the cost of the ad would produce enough sales to make it worthwhile, effect size would be crucial. But when I am testing a theory about whether, say, positive mood reduces information processing in comparison with negative mood, I am worried abou</p><p>6 0.98622489 <a title="1209-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>7 0.98595285 <a title="1209-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-01-Ice_cream%21_and_temperature.html">1402 andrew gelman stats-2012-07-01-Ice cream! and temperature</a></p>
<p>same-blog 8 0.98514259 <a title="1209-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-12-As_a_Bayesian_I_want_scientists_to_report_their_data_non-Bayesianly.html">1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</a></p>
<p>9 0.98438799 <a title="1209-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>10 0.98434818 <a title="1209-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-10-Cross-validation_and_Bayesian_estimation_of_tuning_parameters.html">2129 andrew gelman stats-2013-12-10-Cross-validation and Bayesian estimation of tuning parameters</a></p>
<p>11 0.98429632 <a title="1209-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-05-Prior_distribution_for_a_predicted_probability.html">2200 andrew gelman stats-2014-02-05-Prior distribution for a predicted probability</a></p>
<p>12 0.98415744 <a title="1209-lda-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-17-How_to_think_about_the_statistical_evidence_when_the_statistical_evidence_can%E2%80%99t_be_conclusive%3F.html">2174 andrew gelman stats-2014-01-17-How to think about the statistical evidence when the statistical evidence can’t be conclusive?</a></p>
<p>13 0.98413289 <a title="1209-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-How_does_Bayes_do_it%3F.html">247 andrew gelman stats-2010-09-01-How does Bayes do it?</a></p>
<p>14 0.98394048 <a title="1209-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>15 0.98371577 <a title="1209-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-25-A_statistical_graphics_course_and_statistical_graphics_advice.html">2266 andrew gelman stats-2014-03-25-A statistical graphics course and statistical graphics advice</a></p>
<p>16 0.98361367 <a title="1209-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>17 0.98255759 <a title="1209-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-02-The_inevitable_problems_with_statistical_significance_and_95%25_intervals.html">1150 andrew gelman stats-2012-02-02-The inevitable problems with statistical significance and 95% intervals</a></p>
<p>18 0.98234558 <a title="1209-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-Infovis%2C_infographics%2C_and_data_visualization%3A__Where_I%E2%80%99m_coming_from%2C_and_where_I%E2%80%99d_like_to_go.html">878 andrew gelman stats-2011-08-29-Infovis, infographics, and data visualization:  Where I’m coming from, and where I’d like to go</a></p>
<p>19 0.98178303 <a title="1209-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-18-Question_on_Type_M_errors.html">963 andrew gelman stats-2011-10-18-Question on Type M errors</a></p>
<p>20 0.98164892 <a title="1209-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
