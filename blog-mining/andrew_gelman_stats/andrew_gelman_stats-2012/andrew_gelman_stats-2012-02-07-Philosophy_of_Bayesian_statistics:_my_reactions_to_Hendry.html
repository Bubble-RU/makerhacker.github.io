<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1157" href="#">andrew_gelman_stats-2012-1157</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1157-html" href="http://andrewgelman.com/2012/02/07/philosophy-of-bayesian-statistics-my-reactions-to-hendry/">html</a></p><p>Introduction: Continuing with my discussion  here  and  here  of the articles in the special issue of the journal Rationality, Markets and Morals on the philosophy of Bayesian statistics:
 
   
 
David Hendry, “Empirical Economic Model Discovery and Theory Evaluation”:
 
Hendry presents a wide-ranging overview of scientific learning, with an interesting comparison of physical with social sciences.  (For some reason, he discusses many physical sciences but restricts his social-science examples to economics and psychology.)
 
The only part of Hendry’s long and interesting article that I will discuss, however, is the part where he decides to take a gratuitous swing at Bayes.  I don’t know why he did this, but maybe it’s part of some fraternity initiation thing, like TP-ing the dean’s house on Halloween.
 
Here’s the story.  Hendry writes:
  
‘Prior distributions’ widely used in Bayesian analyses, whether subjective or ‘objective’, cannot be formed in such a setting either, absent a falsely assumed crys</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 )   The only part of Hendry’s long and interesting article that I will discuss, however, is the part where he decides to take a gratuitous swing at Bayes. [sent-3, score-0.161]
</p><p>2 Hendry writes:    ‘Prior distributions’ widely used in Bayesian analyses, whether subjective or ‘objective’, cannot be formed in such a setting either, absent a falsely assumed crystal ball. [sent-6, score-0.199]
</p><p>3 Rather, imposing a prior distribution that is consistent with an assumed model when breaks are not included is a recipe for a bad analysis in macroeconomics. [sent-7, score-0.306]
</p><p>4 Fortunately, priors are neither necessary nor sufficient in the context of discovery. [sent-8, score-0.377]
</p><p>5 With sufficient effort, I think you can solve all statistical problems with Bayesian methods, or with robust methods, or with bootstrapping, or with any number of alternative approaches. [sent-31, score-0.238]
</p><p>6 Different approaches have different advantages, but I’m sure that if Hendry adopts a self-denying ordinance and decides to never use priors, he can solve all sorts of data analysis problems. [sent-33, score-0.152]
</p><p>7 But, to be fair, there are some problems that I have to work really hard on too. [sent-35, score-0.143]
</p><p>8 In short:  econometrics methods tend to require more effort in complicated settings, but they often have appealing robustness properties. [sent-36, score-0.208]
</p><p>9 My most serious criticism with Hendry’s above paragraph is the old, old story:  he’s singling out Bayesian methods and priors as being particularly bad. [sent-39, score-0.244]
</p><p>10 Hendry’s standing at the back window with a shotgun, scanning for priors coming over the hill, while a million assumptions just walk right into his house through the front door. [sent-42, score-0.187]
</p><p>11 I could give a million examples of useful knowledge that can be discovered with the aid of prior distributions. [sent-45, score-0.175]
</p><p>12 I’m not even saying that Bayesian methods are needed to solve the problems listed in the above paragraph. [sent-54, score-0.234]
</p><p>13 What I am saying is, why is Hendry so sure that “prior distributions should play a minimal role” etc. [sent-56, score-0.242]
</p><p>14 I’m really bothered when people go beyond the simple and direct, “I have no personal experience with Bayesian inference solving a useful problem” to prescriptive (and wrong) statements such as “prior distributions should play a minimal role. [sent-58, score-0.342]
</p><p>15 ”  And it’s just silly to say that priors are “unhelpful in a changing world. [sent-59, score-0.189]
</p><p>16 Hendry also pulls the no-true-Scotsman trick:    Fortunately, priors are neither necessary nor sufficient in the context of discovery. [sent-61, score-0.377]
</p><p>17 Certainly, a general language system seems to be hard wired in the human brain (see Pinker 1994; 2002) but that hardly constitutes a prior. [sent-64, score-0.424]
</p><p>18 Thus, in one of the most complicated tasks imaginable, which computers still struggle to emulate, priors are not needed. [sent-65, score-0.187]
</p><p>19 I just wish he’d cut out the part where he implicitly disparages the work of Mosteller and Wallace, Lax and Phillips, and a few zillion other researchers who’ve used Bayesian methods to solve problems. [sent-78, score-0.322]
</p><p>20 All he needs to do is to retreat to present the positive virtues of his preferred inferential approach along with his explanations as to why Bayesian methods have not seemed useful for him. [sent-80, score-0.157]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hendry', 0.748), ('priors', 0.143), ('bayesian', 0.125), ('prior', 0.119), ('sufficient', 0.105), ('methods', 0.101), ('distributions', 0.097), ('arabic', 0.096), ('solve', 0.085), ('minimal', 0.083), ('crystal', 0.082), ('econometrician', 0.079), ('unhelpful', 0.079), ('mosteller', 0.076), ('recipe', 0.076), ('wired', 0.074), ('human', 0.07), ('dinardo', 0.07), ('constitutes', 0.069), ('clark', 0.069), ('wallace', 0.067), ('falsely', 0.067), ('fortunately', 0.067), ('decides', 0.067), ('neither', 0.067), ('brains', 0.066), ('robustness', 0.063), ('play', 0.062), ('language', 0.062), ('necessary', 0.062), ('breaks', 0.061), ('chinese', 0.061), ('useful', 0.056), ('brain', 0.051), ('hard', 0.05), ('objective', 0.05), ('assumed', 0.05), ('english', 0.049), ('functions', 0.048), ('problems', 0.048), ('hardly', 0.048), ('part', 0.047), ('changing', 0.046), ('physical', 0.045), ('work', 0.045), ('house', 0.044), ('complicated', 0.044), ('prescriptive', 0.044), ('shotgun', 0.044), ('disparages', 0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1157-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-Philosophy_of_Bayesian_statistics%3A_my_reactions_to_Hendry.html">1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</a></p>
<p>Introduction: Continuing with my discussion  here  and  here  of the articles in the special issue of the journal Rationality, Markets and Morals on the philosophy of Bayesian statistics:
 
   
 
David Hendry, “Empirical Economic Model Discovery and Theory Evaluation”:
 
Hendry presents a wide-ranging overview of scientific learning, with an interesting comparison of physical with social sciences.  (For some reason, he discusses many physical sciences but restricts his social-science examples to economics and psychology.)
 
The only part of Hendry’s long and interesting article that I will discuss, however, is the part where he decides to take a gratuitous swing at Bayes.  I don’t know why he did this, but maybe it’s part of some fraternity initiation thing, like TP-ing the dean’s house on Halloween.
 
Here’s the story.  Hendry writes:
  
‘Prior distributions’ widely used in Bayesian analyses, whether subjective or ‘objective’, cannot be formed in such a setting either, absent a falsely assumed crys</p><p>2 0.17075405 <a title="1157-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-30-Articles_on_the_philosophy_of_Bayesian_statistics_by_Cox%2C_Mayo%2C_Senn%2C_and_others%21.html">932 andrew gelman stats-2011-09-30-Articles on the philosophy of Bayesian statistics by Cox, Mayo, Senn, and others!</a></p>
<p>Introduction: Deborah Mayo, Aris Spanos, and Kent Staley edited a special issue on the philosophy of Bayesian statistics for the journal Rationality, Markets and Morals.
 
Here are  the contents :
  
David Cox and Deborah G. Mayo, “Statistical Scientist Meets a Philosopher of Science: A Conversation”


Deborah G. Mayo, “Statistical Science and Philosophy of Science: Where Do/Should They Meet in 2011 (and Beyond)?”


Stephen Senn,  “You May Believe You Are a Bayesian But You Are Probably Wrong” 


Andrew Gelman, “ Induction and Deduction in Bayesian Data Analysis “


Jan Sprenger, “The Renegade Subjectivist: Jose Bernardo’s Objective Bayesianism”


Aris Spanos. “Foundational Issues in Statistical Modeling: Statistical Model Specification and Validation”


David F. Hendry, “Empirical Economic Model Discovery and Theory Evaluation” 	 	 


Larry Wasserman, “Low Assumptions, High Dimensions”
  
For some reason, not all the articles are yet online, but it says they’re coming soon.  In the meantime, you ca</p><p>3 0.16370225 <a title="1157-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-18-Those_wacky_anti-Bayesians_used_to_be_intimidating%2C_but_now_they%E2%80%99re_just_pathetic.html">2254 andrew gelman stats-2014-03-18-Those wacky anti-Bayesians used to be intimidating, but now they’re just pathetic</a></p>
<p>Introduction: From 2006 :
  
Eric Archer forwarded  this document  by Nick Freemantle, “The Reverend Bayes—was he really a prophet?”, in the Journal of the Royal Society of Medicine:

 

Does [Bayes's] contribution merit the enthusiasms of his followers? Or is his legacy overhyped? . . .


First, Bayesians appear to have an absolute right to disapprove of any conventional approach in statistics without offering a workable alternative—for example, a colleague recently stated at a meeting that ‘. . . it is OK to have multiple comparisons because Bayesians’ don’t believe in alpha spending’. . . .


Second, Bayesians appear to build an army of straw men—everything it seems is different and better from a Bayesian perspective, although many of the concepts seem remarkably familiar. For example, a very well known Bayesian statistician recently surprised the audience with his discovery of the P value as a useful Bayesian statistic at a meeting in Birmingham.


Third, Bayesians possess enormous enthusiasm fo</p><p>4 0.15153581 <a title="1157-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>Introduction: Robert Bell pointed me to  this post  by Brad De Long on Bayesian statistics, and then I also noticed  this  from Noah Smith, who wrote:
  
My impression is that although the Bayesian/Frequentist debate is interesting and intellectually fun, there’s really not much “there” there… despite being so-hip-right-now, Bayesian is not the Statistical Jesus.
  
I’m happy to see the discussion going in this direction.  Twenty-five years ago or so, when I got into this biz, there were some serious anti-Bayesian attitudes floating around in mainstream statistics.  Discussions in the journals sometimes devolved into debates of the form, “Bayesians:  knaves or fools?”.  You’d get all sorts of free-floating skepticism about any prior distribution at all, even while people were accepting without question (and doing theory on) logistic regressions, proportional hazards models, and all sorts of strong strong models.  (In the subfield of survey sampling, various prominent researchers would refuse to mode</p><p>5 0.14443284 <a title="1157-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<p>Introduction: A couple days ago we  discussed  some remarks by Tony O’Hagan and Jim Berger on weakly informative priors.  Jim  followed up  on Deborah Mayo’s blog with this:
  
Objective Bayesian priors are often improper (i.e., have infinite total mass), but this is not a problem when they are developed correctly. But not every improper prior is satisfactory. For instance, the constant prior is known to be unsatisfactory in many situations. The ‘solution’ pseudo-Bayesians often use is to choose a constant prior over a large but bounded set (a ‘weakly informative’ prior), saying it is now proper and so all is well. This is not true; if the constant prior on the whole parameter space is bad, so will be the constant prior over the bounded set. The problem is, in part, that some people confuse proper priors with subjective priors and, having learned that true subjective priors are fine, incorrectly presume that weakly informative proper priors are fine.
  
I have a few reactions to this:
 
1.  I agree</p><p>6 0.14037967 <a title="1157-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-05-What_is_a_prior_distribution%3F.html">1155 andrew gelman stats-2012-02-05-What is a prior distribution?</a></p>
<p>7 0.13558483 <a title="1157-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-01-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Cox_and_Mayo.html">1149 andrew gelman stats-2012-02-01-Philosophy of Bayesian statistics:  my reactions to Cox and Mayo</a></p>
<p>8 0.13412237 <a title="1157-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<p>9 0.12988983 <a title="1157-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-More_on_Bayesian_methods_and_multilevel_modeling.html">2033 andrew gelman stats-2013-09-23-More on Bayesian methods and multilevel modeling</a></p>
<p>10 0.12874262 <a title="1157-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>11 0.12786695 <a title="1157-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>12 0.1245499 <a title="1157-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>13 0.12376852 <a title="1157-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>14 0.1227325 <a title="1157-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>15 0.12118343 <a title="1157-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>16 0.11977731 <a title="1157-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-27-%E2%80%9CKeeping_things_unridiculous%E2%80%9D%3A__Berger%2C_O%E2%80%99Hagan%2C_and_me_on_weakly_informative_priors.html">1087 andrew gelman stats-2011-12-27-“Keeping things unridiculous”:  Berger, O’Hagan, and me on weakly informative priors</a></p>
<p>17 0.11853376 <a title="1157-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>18 0.11525964 <a title="1157-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<p>19 0.11421807 <a title="1157-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>20 0.11279648 <a title="1157-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-07-Prior_distributions_for_regression_coefficients.html">1486 andrew gelman stats-2012-09-07-Prior distributions for regression coefficients</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.198), (1, 0.121), (2, -0.059), (3, 0.054), (4, -0.102), (5, -0.012), (6, 0.017), (7, 0.033), (8, -0.049), (9, 0.011), (10, -0.002), (11, -0.031), (12, 0.009), (13, 0.03), (14, 0.03), (15, 0.017), (16, 0.025), (17, 0.009), (18, -0.019), (19, 0.019), (20, -0.038), (21, 0.001), (22, -0.03), (23, 0.025), (24, -0.004), (25, 0.011), (26, 0.032), (27, 0.006), (28, -0.017), (29, 0.028), (30, 0.006), (31, -0.02), (32, 0.01), (33, -0.021), (34, 0.038), (35, -0.017), (36, -0.013), (37, 0.017), (38, 0.008), (39, 0.012), (40, 0.001), (41, 0.009), (42, 0.016), (43, -0.009), (44, 0.02), (45, 0.003), (46, -0.029), (47, -0.011), (48, -0.0), (49, 0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97590917 <a title="1157-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-Philosophy_of_Bayesian_statistics%3A_my_reactions_to_Hendry.html">1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</a></p>
<p>Introduction: Continuing with my discussion  here  and  here  of the articles in the special issue of the journal Rationality, Markets and Morals on the philosophy of Bayesian statistics:
 
   
 
David Hendry, “Empirical Economic Model Discovery and Theory Evaluation”:
 
Hendry presents a wide-ranging overview of scientific learning, with an interesting comparison of physical with social sciences.  (For some reason, he discusses many physical sciences but restricts his social-science examples to economics and psychology.)
 
The only part of Hendry’s long and interesting article that I will discuss, however, is the part where he decides to take a gratuitous swing at Bayes.  I don’t know why he did this, but maybe it’s part of some fraternity initiation thing, like TP-ing the dean’s house on Halloween.
 
Here’s the story.  Hendry writes:
  
‘Prior distributions’ widely used in Bayesian analyses, whether subjective or ‘objective’, cannot be formed in such a setting either, absent a falsely assumed crys</p><p>2 0.85750788 <a title="1157-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<p>Introduction: Continuing with  my discussion of the articles in the special issue  of the journal Rationality, Markets and Morals on the philosophy of Bayesian statistics:
 
   
 
Stephen Senn, “You May Believe You Are a Bayesian But You Are Probably Wrong”:
 
I agree with Senn’s comments on the impossibility of the de Finetti subjective Bayesian approach.  As I wrote in 2008, if you could really construct a subjective prior you believe in, why not just look at the data and write down your subjective posterior.  The immense practical difficulties with  any  serious system of inference render it absurd to think that it would be possible to just write down a probability distribution to represent uncertainty.  I wish, however, that Senn would recognize  my  Bayesian approach (which is also that of John Carlin, Hal Stern, Don Rubin, and, I believe, others).  De Finetti is no longer around, but we are!
 
I have to admit that my own Bayesian views and practices have changed.  In particular, I resonate wit</p><p>3 0.84877849 <a title="1157-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>Introduction: Prasanta Bandyopadhyay and Gordon Brittan  write :
  
We introduce a distinction, unnoticed in the literature, between four varieties of objective Bayesianism. What we call ‘strong objective Bayesianism’ is characterized by two claims, that all scientific inference is ‘logical’ and that, given the same background information two agents will ascribe a unique probability to their priors. We think that neither of these claims can be sustained; in this sense, they are ‘dogmatic’. The first fails to recognize that some scientific inference, in particular that concerning evidential relations, is not (in the appropriate sense) logical, the second fails to provide a non-question-begging account of ‘same background information’. We urge that a suitably objective Bayesian account of scientific inference does not require either of the claims. Finally, we argue that Bayesianism needs to be fine-grained in the same way that Bayesians fine-grain their beliefs.
  
I have not read their paper in detai</p><p>4 0.84509319 <a title="1157-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>Introduction: Robert Bell pointed me to  this post  by Brad De Long on Bayesian statistics, and then I also noticed  this  from Noah Smith, who wrote:
  
My impression is that although the Bayesian/Frequentist debate is interesting and intellectually fun, there’s really not much “there” there… despite being so-hip-right-now, Bayesian is not the Statistical Jesus.
  
I’m happy to see the discussion going in this direction.  Twenty-five years ago or so, when I got into this biz, there were some serious anti-Bayesian attitudes floating around in mainstream statistics.  Discussions in the journals sometimes devolved into debates of the form, “Bayesians:  knaves or fools?”.  You’d get all sorts of free-floating skepticism about any prior distribution at all, even while people were accepting without question (and doing theory on) logistic regressions, proportional hazards models, and all sorts of strong strong models.  (In the subfield of survey sampling, various prominent researchers would refuse to mode</p><p>5 0.84332526 <a title="1157-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-17-Christian_Robert_on_the_Jeffreys-Lindley_paradox%3B_more_generally%2C_it%E2%80%99s_good_news_when_philosophical_arguments_can_be_transformed_into_technical_modeling_issues.html">2027 andrew gelman stats-2013-09-17-Christian Robert on the Jeffreys-Lindley paradox; more generally, it’s good news when philosophical arguments can be transformed into technical modeling issues</a></p>
<p>Introduction: X  writes :
  
This paper discusses the dual interpretation of the Jeffreys– Lindley’s paradox associated with Bayesian posterior probabilities and Bayes factors, both as a differentiation between frequentist and Bayesian statistics and as a pointer to the difficulty of using improper priors while testing. We stress the considerable impact of this paradox on the foundations of both classical and Bayesian statistics.
  
I like this paper in that he is transforming what is often seen as a philosophical argument into a technical issue, in this case a question of priors.  Certain conventional priors (the so-called spike and slab) have poor statistical properties in settings such as model comparison (in addition to not making sense as prior distributions of any realistic state of knowledge).  This reminds me of the way that we nowadays think about hierarchical models.  In the old days there was much thoughtful debate about exchangeability and the so-called Stein paradox that partial pooling</p><p>6 0.83968616 <a title="1157-lsi-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-18-Those_wacky_anti-Bayesians_used_to_be_intimidating%2C_but_now_they%E2%80%99re_just_pathetic.html">2254 andrew gelman stats-2014-03-18-Those wacky anti-Bayesians used to be intimidating, but now they’re just pathetic</a></p>
<p>7 0.83795917 <a title="1157-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-27-%E2%80%9CKeeping_things_unridiculous%E2%80%9D%3A__Berger%2C_O%E2%80%99Hagan%2C_and_me_on_weakly_informative_priors.html">1087 andrew gelman stats-2011-12-27-“Keeping things unridiculous”:  Berger, O’Hagan, and me on weakly informative priors</a></p>
<p>8 0.83771282 <a title="1157-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-30-Infill_asymptotics_and_sprawl_asymptotics.html">1877 andrew gelman stats-2013-05-30-Infill asymptotics and sprawl asymptotics</a></p>
<p>9 0.83624792 <a title="1157-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-11-Bayesian_brains%3F.html">1529 andrew gelman stats-2012-10-11-Bayesian brains?</a></p>
<p>10 0.83357745 <a title="1157-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>11 0.81729186 <a title="1157-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-09-The_anti-Bayesian_moment_and_its_passing.html">1571 andrew gelman stats-2012-11-09-The anti-Bayesian moment and its passing</a></p>
<p>12 0.81547582 <a title="1157-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>13 0.81350315 <a title="1157-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<p>14 0.80779958 <a title="1157-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-01-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Cox_and_Mayo.html">1149 andrew gelman stats-2012-02-01-Philosophy of Bayesian statistics:  my reactions to Cox and Mayo</a></p>
<p>15 0.80447644 <a title="1157-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-14-Trying_to_be_precise_about_vagueness.html">342 andrew gelman stats-2010-10-14-Trying to be precise about vagueness</a></p>
<p>16 0.80298734 <a title="1157-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<p>17 0.80288142 <a title="1157-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-10-Cross-validation_and_Bayesian_estimation_of_tuning_parameters.html">2129 andrew gelman stats-2013-12-10-Cross-validation and Bayesian estimation of tuning parameters</a></p>
<p>18 0.79765713 <a title="1157-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-13-Silly_Sas_lays_out_old-fashioned_statistical_thinking.html">83 andrew gelman stats-2010-06-13-Silly Sas lays out old-fashioned statistical thinking</a></p>
<p>19 0.79721731 <a title="1157-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>20 0.79391575 <a title="1157-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-04-Generalized_Method_of_Moments%2C_whatever_that_is.html">449 andrew gelman stats-2010-12-04-Generalized Method of Moments, whatever that is</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.014), (15, 0.022), (16, 0.057), (18, 0.01), (21, 0.034), (24, 0.13), (39, 0.104), (42, 0.02), (45, 0.032), (53, 0.01), (55, 0.023), (57, 0.016), (73, 0.013), (86, 0.033), (87, 0.011), (95, 0.012), (96, 0.013), (99, 0.281)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9675836 <a title="1157-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-02-Automating_my_graphics_advice.html">443 andrew gelman stats-2010-12-02-Automating my graphics advice</a></p>
<p>Introduction: After seeing  this graph :
 
   
 
I have the following message for Sharad:
 
Rotate the graph 90 degrees so you can see the words.  Also you can ditch the lines.  Then what you have is a dotplot, following the principles of Cleveland (1985).  You can lay out a few on one page to see some interactions with demographics.
 
 The real challenge here . . . 
 
. . . is to automate this sort of advice.  Or maybe we just need a really nice dotplot() function and enough examples, and people will start doing it?
 
 P.S. 
 
Often a lineplot is better.  See  here  for a discussion of another Sharad example.</p><p>same-blog 2 0.96672106 <a title="1157-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-Philosophy_of_Bayesian_statistics%3A_my_reactions_to_Hendry.html">1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</a></p>
<p>Introduction: Continuing with my discussion  here  and  here  of the articles in the special issue of the journal Rationality, Markets and Morals on the philosophy of Bayesian statistics:
 
   
 
David Hendry, “Empirical Economic Model Discovery and Theory Evaluation”:
 
Hendry presents a wide-ranging overview of scientific learning, with an interesting comparison of physical with social sciences.  (For some reason, he discusses many physical sciences but restricts his social-science examples to economics and psychology.)
 
The only part of Hendry’s long and interesting article that I will discuss, however, is the part where he decides to take a gratuitous swing at Bayes.  I don’t know why he did this, but maybe it’s part of some fraternity initiation thing, like TP-ing the dean’s house on Halloween.
 
Here’s the story.  Hendry writes:
  
‘Prior distributions’ widely used in Bayesian analyses, whether subjective or ‘objective’, cannot be formed in such a setting either, absent a falsely assumed crys</p><p>3 0.95727605 <a title="1157-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-25-And_now%2C_here%E2%80%99s_something_we_hope_you%E2%80%99ll_really_like.html">1343 andrew gelman stats-2012-05-25-And now, here’s something we hope you’ll really like</a></p>
<p>Introduction: This came in the email:
  
Postdoctoral Researcher (3 years) in State-Space Modeling of Animal Movement and Population Dynamics in Universities of Turku and Helsinki, Finland


We seek for a statistician/mathematician with experience in ecological modeling or an ecologist with strong quantitative training to join an interdisciplinary research team focusing on dispersal and dynamics of the Siberian flying squirrel (Pteromys volans).


The Postdoctoral Researcher will develop modeling approaches (from individual based models to population level models) to assess the dispersal and population dynamics of the flying squirrel. A key challenge will be the integration of different kinds of data (census data, telemetry data, mark-recapture data, life-history data, and data on environmental covariates such as forest structure) into the modeling framework using Bayesian State-Space models or other such approaches.


The project will be supervised by Dr. Vesa Selonen (a flying squirrel specialist;</p><p>4 0.95501924 <a title="1157-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-07-Update_on_the_new_Handbook_of_MCMC.html">844 andrew gelman stats-2011-08-07-Update on the new Handbook of MCMC</a></p>
<p>Introduction: It’s edited by Steve Brooks, Galin Jones, Xiao-Li Meng, and myself.   Here’s  the information and some sample chapters (including my own chapter with Ken Shirley on inference and monitoring convergence and Radford’s instant classic on Hamiltonian Monte Carlo).
 
Sorry about the $100 price tag–nobody asked me about that!  But if you’re doing these computations as part of your work, I think the book will be well worth it.</p><p>5 0.94858992 <a title="1157-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-19-David_Blackwell.html">155 andrew gelman stats-2010-07-19-David Blackwell</a></p>
<p>Introduction: David Blackwell was already retired by the time I came to Berkeley, and probably our closest connection was that I taught the class in decision theory that he used to teach.  I enjoyed that class a lot, partly because it took me out of my usual comfort zone of statistical inference and data analysis toward something more theoretical and mathematical.  Blackwell was one of the legendary figures in the department at that time and was also one of the most tolerant of alternative approaches to statistics, perhaps because of combination of a mathematical background, applied research in the war and after (which I learned about in  this recent obituary ), and personal experiences,
 
Blackwell may be best known in statistics for the  Rao-Blackwell theorem .  Rao, of course, is also famoust for the Cramer-Rao lower bound.  Both theorems relate to minimum-variance statistical estimators.
 
Here’s a quote from Thomas (Jesus’s dad) Ferguson in Blackwell’s  obituary :
  
He went from one area to an</p><p>6 0.94714504 <a title="1157-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-08-Here%E2%80%99s_how_rumors_get_started%3A__Lineplots%2C_dotplots%2C_and_nonfunctional_modernist_architecture.html">262 andrew gelman stats-2010-09-08-Here’s how rumors get started:  Lineplots, dotplots, and nonfunctional modernist architecture</a></p>
<p>7 0.94582987 <a title="1157-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-11-Herman_Chernoff_used_to_do_that_too%3B_also%2C_some_puzzlement_over_another%E2%80%99s_puzzlement_over_another%E2%80%99s_preferences.html">334 andrew gelman stats-2010-10-11-Herman Chernoff used to do that too; also, some puzzlement over another’s puzzlement over another’s preferences</a></p>
<p>8 0.93775892 <a title="1157-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>9 0.93614733 <a title="1157-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-28-Behavioral_economics_doesn%E2%80%99t_seem_to_have_much_to_say_about_marriage.html">594 andrew gelman stats-2011-02-28-Behavioral economics doesn’t seem to have much to say about marriage</a></p>
<p>10 0.9358871 <a title="1157-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-12-Misunderstanding_the_p-value.html">1760 andrew gelman stats-2013-03-12-Misunderstanding the p-value</a></p>
<p>11 0.9356091 <a title="1157-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-22-Struggles_over_the_criticism_of_the_%E2%80%9Ccannabis_users_and_IQ_change%E2%80%9D_paper.html">1910 andrew gelman stats-2013-06-22-Struggles over the criticism of the “cannabis users and IQ change” paper</a></p>
<p>12 0.93552852 <a title="1157-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-Attractive_but_hard-to-read_graph_could_be_made_much_much_better.html">670 andrew gelman stats-2011-04-20-Attractive but hard-to-read graph could be made much much better</a></p>
<p>13 0.93541616 <a title="1157-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-11-Bayesian_brains%3F.html">1529 andrew gelman stats-2012-10-11-Bayesian brains?</a></p>
<p>14 0.93497413 <a title="1157-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-03-Double_standard%3F__Plagiarizing_journos_get_slammed%2C_plagiarizing_profs_just_shrug_it_off.html">1442 andrew gelman stats-2012-08-03-Double standard?  Plagiarizing journos get slammed, plagiarizing profs just shrug it off</a></p>
<p>15 0.93491954 <a title="1157-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-31-A_data_visualization_manifesto.html">61 andrew gelman stats-2010-05-31-A data visualization manifesto</a></p>
<p>16 0.93474972 <a title="1157-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-Infovis%2C_infographics%2C_and_data_visualization%3A__Where_I%E2%80%99m_coming_from%2C_and_where_I%E2%80%99d_like_to_go.html">878 andrew gelman stats-2011-08-29-Infovis, infographics, and data visualization:  Where I’m coming from, and where I’d like to go</a></p>
<p>17 0.93474758 <a title="1157-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-08-Poli_sci_plagiarism_update%2C_and_a_note_about_the_benefits_of_not_caring.html">400 andrew gelman stats-2010-11-08-Poli sci plagiarism update, and a note about the benefits of not caring</a></p>
<p>18 0.93472683 <a title="1157-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Contest_for_developing_an_R_package_recommendation_system.html">324 andrew gelman stats-2010-10-07-Contest for developing an R package recommendation system</a></p>
<p>19 0.93469977 <a title="1157-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>20 0.93453759 <a title="1157-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-16-Infovis_and_statgraphics_update_update.html">855 andrew gelman stats-2011-08-16-Infovis and statgraphics update update</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
