<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1438 andrew gelman stats-2012-07-31-What is a Bayesian?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1438" href="#">andrew_gelman_stats-2012-1438</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1438 andrew gelman stats-2012-07-31-What is a Bayesian?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1438-html" href="http://andrewgelman.com/2012/07/31/what-is-a-bayesian/">html</a></p><p>Introduction: Deborah Mayo recommended that I consider coming up with a new name for the statistical methods that I used, given that the term “Bayesian” has all sorts of associations that I dislike (as discussed, for example, in section 1 of  this article ).
 
I replied that I agree on Bayesian, I never liked the term and always wanted something better, but I couldn’t think of any convenient alternative.  Also, I was finding that Bayesians (even the Bayesians I disagreed with) were reading my research articles, while non-Bayesians were simply ignoring them.  So I thought it was best to identify with, and communicate with, those people who were willing to engage with me.
 
More formally, I’m happy defining “Bayesian” as “using inference from the posterior distribution, p(theta|y)”.  This says nothing about where the probability distributions come from (thus, no requirement to be “subjective” or “objective”) and it says nothing about the models (thus, no requirement to use the discrete models that hav</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Deborah Mayo recommended that I consider coming up with a new name for the statistical methods that I used, given that the term “Bayesian” has all sorts of associations that I dislike (as discussed, for example, in section 1 of  this article ). [sent-1, score-0.968]
</p><p>2 I replied that I agree on Bayesian, I never liked the term and always wanted something better, but I couldn’t think of any convenient alternative. [sent-2, score-0.621]
</p><p>3 Also, I was finding that Bayesians (even the Bayesians I disagreed with) were reading my research articles, while non-Bayesians were simply ignoring them. [sent-3, score-0.539]
</p><p>4 So I thought it was best to identify with, and communicate with, those people who were willing to engage with me. [sent-4, score-0.487]
</p><p>5 More formally, I’m happy defining “Bayesian” as “using inference from the posterior distribution, p(theta|y)”. [sent-5, score-0.318]
</p><p>6 This says nothing about where the probability distributions come from (thus, no requirement to be “subjective” or “objective”) and it says nothing about the models (thus, no requirement to use the discrete models that have been favored by the Bayesian model selection crew). [sent-6, score-1.913]
</p><p>7 Based on my minimal definition, I’m as Bayesian as anyone else. [sent-7, score-0.222]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('requirement', 0.301), ('bayesian', 0.284), ('bayesians', 0.246), ('term', 0.187), ('crew', 0.185), ('favored', 0.172), ('says', 0.163), ('associations', 0.156), ('disagreed', 0.156), ('dislike', 0.152), ('thus', 0.148), ('formally', 0.144), ('deborah', 0.144), ('mayo', 0.144), ('defining', 0.14), ('nothing', 0.139), ('minimal', 0.138), ('ignoring', 0.137), ('engage', 0.135), ('communicate', 0.134), ('theta', 0.133), ('convenient', 0.126), ('objective', 0.124), ('definition', 0.124), ('liked', 0.121), ('recommended', 0.121), ('discrete', 0.121), ('subjective', 0.119), ('identify', 0.11), ('models', 0.109), ('willing', 0.108), ('replied', 0.102), ('selection', 0.099), ('couldn', 0.099), ('finding', 0.097), ('distributions', 0.097), ('section', 0.096), ('posterior', 0.09), ('happy', 0.088), ('name', 0.088), ('sorts', 0.086), ('wanted', 0.085), ('anyone', 0.084), ('coming', 0.082), ('articles', 0.081), ('discussed', 0.081), ('else', 0.079), ('simply', 0.078), ('distribution', 0.076), ('reading', 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1438-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>Introduction: Deborah Mayo recommended that I consider coming up with a new name for the statistical methods that I used, given that the term “Bayesian” has all sorts of associations that I dislike (as discussed, for example, in section 1 of  this article ).
 
I replied that I agree on Bayesian, I never liked the term and always wanted something better, but I couldn’t think of any convenient alternative.  Also, I was finding that Bayesians (even the Bayesians I disagreed with) were reading my research articles, while non-Bayesians were simply ignoring them.  So I thought it was best to identify with, and communicate with, those people who were willing to engage with me.
 
More formally, I’m happy defining “Bayesian” as “using inference from the posterior distribution, p(theta|y)”.  This says nothing about where the probability distributions come from (thus, no requirement to be “subjective” or “objective”) and it says nothing about the models (thus, no requirement to use the discrete models that hav</p><p>2 0.24333078 <a title="1438-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>Introduction: Prasanta Bandyopadhyay and Gordon Brittan  write :
  
We introduce a distinction, unnoticed in the literature, between four varieties of objective Bayesianism. What we call ‘strong objective Bayesianism’ is characterized by two claims, that all scientific inference is ‘logical’ and that, given the same background information two agents will ascribe a unique probability to their priors. We think that neither of these claims can be sustained; in this sense, they are ‘dogmatic’. The first fails to recognize that some scientific inference, in particular that concerning evidential relations, is not (in the appropriate sense) logical, the second fails to provide a non-question-begging account of ‘same background information’. We urge that a suitably objective Bayesian account of scientific inference does not require either of the claims. Finally, we argue that Bayesianism needs to be fine-grained in the same way that Bayesians fine-grain their beliefs.
  
I have not read their paper in detai</p><p>3 0.21368937 <a title="1438-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>Introduction: I’ll answer the above question after first sharing some background and history on the the philosophy of Bayesian statistics, which appeared at the end of our  rejoinder  to the discussion to which I  linked  the other day:
  
When we were beginning our statistical educations, the word ‘Bayesian’ conveyed membership in an obscure cult. Statisticians who were outside the charmed circle could ignore the Bayesian subfield, while Bayesians themselves tended to be either apologetic or brazenly defiant. These two extremes manifested themselves in ever more elaborate proposals for non-informative priors, on the one hand, and declarations of the purity of subjective probability, on the other.


Much has changed in the past 30 years. ‘Bayesian’ is now often used in casual scientific parlance as a synonym for ‘rational’, the anti-Bayesians have mostly disappeared, and non-Bayesian statisticians feel the need to keep up with developments in Bayesian modelling and computation. Bayesians themselves</p><p>4 0.20638116 <a title="1438-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>Introduction: Deborah Mayo  collected  some reactions to my recent  article , Induction and Deduction in Bayesian Data Analysis.
 
I’m pleased that that everybody (philosopher Mayo, applied statistician Stephen Senn, and theoretical statistician Larry Wasserman) is so positive about my article and that nobody’s defending the sort of hard-core inductivism that’s featured on the Bayesian inference wikipedia page.  Here’s the Wikipedia definition, which I  disagree  with:
  
Bayesian inference uses aspects of the scientific method, which involves collecting evidence that is meant to be consistent or inconsistent with a given hypothesis. As evidence accumulates, the degree of belief in a hypothesis ought to change. With enough evidence, it should become very high or very low. . . . Bayesian inference uses a numerical estimate of the degree of belief in a hypothesis before evidence has been observed and calculates a numerical estimate of the degree of belief in the hypothesis after evidence has been obse</p><p>5 0.18964116 <a title="1438-tfidf-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>Introduction: I sent Deborah Mayo a link to  my paper  with Cosma Shalizi on the philosophy of statistics, and she sent me the link to this conference which unfortunately already occurred.  (It’s too bad, because I’d have liked to have been there.)  I summarized my philosophy as follows:
  
I am highly sympathetic to the approach of Lakatos (or of Popper, if you consider Lakatos’s “Popper_2″ to be a reasonable simulation of the true Popperism), in that (a) I view statistical models as being built within theoretical structures, and (b) I see the checking and refutation of models to be a key part of scientific progress.  A big problem I have with mainstream Bayesianism is its “inductivist” view that science can operate completely smoothly with posterior updates:  the idea that new data causes us to increase the posterior probability of good models and decrease the posterior probability of bad models.  I don’t buy that:  I see models as ever-changing entities that are flexible and can be patched and ex</p><p>6 0.18919998 <a title="1438-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>7 0.18309741 <a title="1438-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>8 0.18072212 <a title="1438-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>9 0.18026182 <a title="1438-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>10 0.17955868 <a title="1438-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>11 0.17809628 <a title="1438-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>12 0.17372712 <a title="1438-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>13 0.17348038 <a title="1438-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-30-Articles_on_the_philosophy_of_Bayesian_statistics_by_Cox%2C_Mayo%2C_Senn%2C_and_others%21.html">932 andrew gelman stats-2011-09-30-Articles on the philosophy of Bayesian statistics by Cox, Mayo, Senn, and others!</a></p>
<p>14 0.17195903 <a title="1438-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-18-Those_wacky_anti-Bayesians_used_to_be_intimidating%2C_but_now_they%E2%80%99re_just_pathetic.html">2254 andrew gelman stats-2014-03-18-Those wacky anti-Bayesians used to be intimidating, but now they’re just pathetic</a></p>
<p>15 0.17124629 <a title="1438-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>16 0.16639948 <a title="1438-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>17 0.15220475 <a title="1438-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>18 0.14933529 <a title="1438-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-05-Error_statistics.html">890 andrew gelman stats-2011-09-05-Error statistics</a></p>
<p>19 0.14749728 <a title="1438-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-23-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1868 andrew gelman stats-2013-05-23-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>20 0.14364225 <a title="1438-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.197), (1, 0.193), (2, -0.107), (3, 0.089), (4, -0.161), (5, -0.022), (6, -0.019), (7, 0.081), (8, 0.035), (9, -0.091), (10, -0.008), (11, -0.063), (12, -0.028), (13, 0.054), (14, 0.054), (15, 0.044), (16, 0.088), (17, 0.004), (18, -0.012), (19, 0.038), (20, -0.014), (21, 0.042), (22, 0.016), (23, -0.045), (24, 0.021), (25, -0.045), (26, 0.007), (27, 0.009), (28, 0.008), (29, 0.026), (30, 0.01), (31, 0.032), (32, 0.015), (33, 0.015), (34, 0.041), (35, 0.02), (36, -0.015), (37, 0.024), (38, -0.017), (39, -0.004), (40, 0.022), (41, 0.008), (42, 0.023), (43, -0.02), (44, 0.001), (45, -0.021), (46, 0.038), (47, 0.081), (48, -0.008), (49, 0.006)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98917758 <a title="1438-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>Introduction: Deborah Mayo recommended that I consider coming up with a new name for the statistical methods that I used, given that the term “Bayesian” has all sorts of associations that I dislike (as discussed, for example, in section 1 of  this article ).
 
I replied that I agree on Bayesian, I never liked the term and always wanted something better, but I couldn’t think of any convenient alternative.  Also, I was finding that Bayesians (even the Bayesians I disagreed with) were reading my research articles, while non-Bayesians were simply ignoring them.  So I thought it was best to identify with, and communicate with, those people who were willing to engage with me.
 
More formally, I’m happy defining “Bayesian” as “using inference from the posterior distribution, p(theta|y)”.  This says nothing about where the probability distributions come from (thus, no requirement to be “subjective” or “objective”) and it says nothing about the models (thus, no requirement to use the discrete models that hav</p><p>2 0.91171521 <a title="1438-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>Introduction: Prasanta Bandyopadhyay and Gordon Brittan  write :
  
We introduce a distinction, unnoticed in the literature, between four varieties of objective Bayesianism. What we call ‘strong objective Bayesianism’ is characterized by two claims, that all scientific inference is ‘logical’ and that, given the same background information two agents will ascribe a unique probability to their priors. We think that neither of these claims can be sustained; in this sense, they are ‘dogmatic’. The first fails to recognize that some scientific inference, in particular that concerning evidential relations, is not (in the appropriate sense) logical, the second fails to provide a non-question-begging account of ‘same background information’. We urge that a suitably objective Bayesian account of scientific inference does not require either of the claims. Finally, we argue that Bayesianism needs to be fine-grained in the same way that Bayesians fine-grain their beliefs.
  
I have not read their paper in detai</p><p>3 0.88738155 <a title="1438-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>Introduction: Deborah Mayo  collected  some reactions to my recent  article , Induction and Deduction in Bayesian Data Analysis.
 
I’m pleased that that everybody (philosopher Mayo, applied statistician Stephen Senn, and theoretical statistician Larry Wasserman) is so positive about my article and that nobody’s defending the sort of hard-core inductivism that’s featured on the Bayesian inference wikipedia page.  Here’s the Wikipedia definition, which I  disagree  with:
  
Bayesian inference uses aspects of the scientific method, which involves collecting evidence that is meant to be consistent or inconsistent with a given hypothesis. As evidence accumulates, the degree of belief in a hypothesis ought to change. With enough evidence, it should become very high or very low. . . . Bayesian inference uses a numerical estimate of the degree of belief in a hypothesis before evidence has been observed and calculates a numerical estimate of the degree of belief in the hypothesis after evidence has been obse</p><p>4 0.88314563 <a title="1438-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>Introduction: Yes, checking calibration of probability forecasts is part of Bayesian statistics.  At the end of this post are three figures from Chapter 1 of Bayesian Data Analysis illustrating empirical evaluation of forecasts.
 
But first the background.  Why am I bringing this up now?  It’s because of something Larry Wasserman  wrote the other day : 
  
  
One of the striking facts about [baseball/political forecaster Nate Silver's recent] book is the emphasis the Silver places on frequency calibration. . . . Have no doubt about it: Nate Silver is a frequentist. For example, he says:

 
One of the most important tests of a forecast — I would argue that it is the single most important one — is called calibration. Out of all the times you said there was a 40 percent chance of rain, how often did rain actually occur? If over the long run, it really did rain about 40 percent of the time, that means your forecasts were well calibrated.
 
  
I had some discussion with Larry in the comments section of h</p><p>5 0.88094002 <a title="1438-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>Introduction: I came across  this article  on the philosophy of statistics by University of Michigan economist John DiNardo.  I don’t have much to say about the substance of the article because most of it is an argument against something called “Bayesian methods” that doesn’t have much in common with the Bayesian data analysis that I do.
 
If an quantitative, empirically-minded economist at a top university doesn’t know about modern Bayesian methods, then it’s a pretty good guess that confusion holds in many other quarters as well, so I thought I’d try to clear a couple of things up.  (See also  here .)
 
In the short term, I know I have some readers at the University of Michigan, so maybe a couple of you could go over to Prof. DiNardo’s office and discuss this with him?  For the rest of you, please spread the word.
 
My point here is not to claim that DiNardo  should  be using Bayesian methods or to claim that he’s doing anything wrong in his applied work.  It’s just that he’s fighting against a bu</p><p>6 0.86855948 <a title="1438-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<p>7 0.86158282 <a title="1438-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-09-The_anti-Bayesian_moment_and_its_passing.html">1571 andrew gelman stats-2012-11-09-The anti-Bayesian moment and its passing</a></p>
<p>8 0.86113399 <a title="1438-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>9 0.86083937 <a title="1438-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>10 0.85790956 <a title="1438-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>11 0.85038757 <a title="1438-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>12 0.84996891 <a title="1438-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>13 0.84828556 <a title="1438-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-18-Those_wacky_anti-Bayesians_used_to_be_intimidating%2C_but_now_they%E2%80%99re_just_pathetic.html">2254 andrew gelman stats-2014-03-18-Those wacky anti-Bayesians used to be intimidating, but now they’re just pathetic</a></p>
<p>14 0.84672922 <a title="1438-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>15 0.84387791 <a title="1438-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-25-Continuous_variables_in_Bayesian_networks.html">1228 andrew gelman stats-2012-03-25-Continuous variables in Bayesian networks</a></p>
<p>16 0.84201276 <a title="1438-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-04-Generalized_Method_of_Moments%2C_whatever_that_is.html">449 andrew gelman stats-2010-12-04-Generalized Method of Moments, whatever that is</a></p>
<p>17 0.83798373 <a title="1438-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-12-%E2%80%9CNot_only_defended_but_also_applied%E2%80%9D%3A_The_perceived_absurdity_of_Bayesian_inference.html">1262 andrew gelman stats-2012-04-12-“Not only defended but also applied”: The perceived absurdity of Bayesian inference</a></p>
<p>18 0.82959133 <a title="1438-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-28-Why_during_the_1950-1960%E2%80%B2s_did_Jerry_Cornfield_become_a_Bayesian%3F.html">2000 andrew gelman stats-2013-08-28-Why during the 1950-1960′s did Jerry Cornfield become a Bayesian?</a></p>
<p>19 0.8253361 <a title="1438-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-23-That_odd_couple%2C_%E2%80%9Csubjectivity%E2%80%9D_and_%E2%80%9Crationality%E2%80%9D.html">921 andrew gelman stats-2011-09-23-That odd couple, “subjectivity” and “rationality”</a></p>
<p>20 0.82492369 <a title="1438-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.077), (21, 0.012), (24, 0.243), (53, 0.014), (77, 0.138), (84, 0.054), (86, 0.055), (99, 0.303)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97578269 <a title="1438-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>Introduction: Deborah Mayo recommended that I consider coming up with a new name for the statistical methods that I used, given that the term “Bayesian” has all sorts of associations that I dislike (as discussed, for example, in section 1 of  this article ).
 
I replied that I agree on Bayesian, I never liked the term and always wanted something better, but I couldn’t think of any convenient alternative.  Also, I was finding that Bayesians (even the Bayesians I disagreed with) were reading my research articles, while non-Bayesians were simply ignoring them.  So I thought it was best to identify with, and communicate with, those people who were willing to engage with me.
 
More formally, I’m happy defining “Bayesian” as “using inference from the posterior distribution, p(theta|y)”.  This says nothing about where the probability distributions come from (thus, no requirement to be “subjective” or “objective”) and it says nothing about the models (thus, no requirement to use the discrete models that hav</p><p>2 0.97514498 <a title="1438-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-An_epithet_I_can_live_with.html">1604 andrew gelman stats-2012-12-04-An epithet I can live with</a></p>
<p>Introduction: Here . Indeed, I’d much rather be a legend than a myth.
 
I just want to clarify one thing.  Walter Hickey writes:
  
[Antony Unwin and Andrew Gelman] collaborated on this presentation where they take a hard look at what’s wrong with the recent trends of data visualization and infographics.


The takeaway is that while there have been great leaps in visualization technology, some of the visualizations that have garnered the highest praises have actually been lacking in a number of key areas.


Specifically, the pair does a takedown of the top visualizations of 2008 as decided by the popular statistics blog Flowing Data.
  
This is a fair summary, but I want to emphasize that, although our dislike of some award-winning visualizations is central to our argument, it is only the first part of our story.  As Antony and I worked more on our paper, and especially after seeing the discussions by Robert Kosara, Stephen Few, Hadley Wickham, and Paul Murrell (all to appear in Journal of Computati</p><p>3 0.9682613 <a title="1438-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-08-Silly_old_chi-square%21.html">401 andrew gelman stats-2010-11-08-Silly old chi-square!</a></p>
<p>Introduction: Brian Mulford writes:
  
I [Mulford] ran across  this blog post  and found myself questioning the relevance of the test used.


I’d think Chi-Square would be inappropriate for trying to measure significance of choice in the manner presented here; irrespective of the cute hamster.  Since this is a common test for marketers and website developers – I’d be interested in which techniques you might suggest?


For tests of this nature, I typically measure a variety of variables (image placement, size, type, page speed, “page feel” as expressed in a factor, etc) and use LOGIT, Cluster and possibly a simple Bayesian model to determine which variables were most significant (chosen). Pearson Chi-squared may be used to express relationships between variables and outcome but I’ve typically not used it to simply judge a 0/1 choice as statistically significant or not.
  
My reply:
 
I like the decision-theoretic way that the blogger (Jason Cohen, according to the webpage) starts:
  
If you wait too</p><p>4 0.95879525 <a title="1438-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-20-Ugly_ugly_ugly.html">1684 andrew gelman stats-2013-01-20-Ugly ugly ugly</a></p>
<p>Introduction: Denis Cote sends the  following , under the heading, “Some bad graphs for your enjoyment”:
 
 
 
To start with, they don’t know how to spell “color.”  Seriously, though, the graph is a mess.  The circular display implies a circular or periodic structure that isn’t actually in the data, the cramped display requires the use of an otherwise-unnecessary color code that makes it difficult to find or make sense of the information, the alphabetical ordering (without even supplying state names, only abbreviations) makes it further difficult to find any patterns.  It would be so much better, and even easier, to just display a set of small maps shading states on whether they have different laws.  But that’s part of the problem—the clearer graph would also be easier to make!  To get a distinctive graph, there needs to be some degree of difficulty.
 
The designers continue with these monstrosities:
 
 
 
Here they decide to display only 5 states at a time so that it’s really hard to see any big pi</p><p>5 0.95374948 <a title="1438-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Statistician_cracks_Toronto_lottery.html">562 andrew gelman stats-2011-02-06-Statistician cracks Toronto lottery</a></p>
<p>Introduction: Christian points me to  this  amusing story by Jonah Lehrer about Mohan Srivastava, (perhaps the same person as R. Mohan Srivastava, coauthor of a book called Applied Geostatistics) who discovered a flaw in a scratch-off game in which he could figure out which tickets were likely to win based on partial information visible on the ticket.  It appears that scratch-off lotteries elsewhere have similar flaws in their design.
 
The obvious question is, why doesn’t the lottery create the patterns on the tickets (including which “teaser” numbers to reveal) completely at random?  It shouldn’t be hard to design this so that zero information is supplied from the outside. in which case Srivastava’s trick would be impossible.
 
So why not put down the numbers randomly?  Lehrer quotes Srivastava as saying:
  
The tickets are clearly mass-produced, which means there must be some computer program that lays down the numbers. Of course, it would be really nice if the computer could just spit out random</p><p>6 0.95256114 <a title="1438-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-01-Wolfram_on_Mandelbrot.html">1784 andrew gelman stats-2013-04-01-Wolfram on Mandelbrot</a></p>
<p>7 0.95002592 <a title="1438-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>8 0.94559705 <a title="1438-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-10-The_birthday_problem.html">1976 andrew gelman stats-2013-08-10-The birthday problem</a></p>
<p>9 0.94536209 <a title="1438-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-21-Stan_Model_of_the_Week%3A_Hierarchical_Modeling_of_Supernovas.html">2299 andrew gelman stats-2014-04-21-Stan Model of the Week: Hierarchical Modeling of Supernovas</a></p>
<p>10 0.94522703 <a title="1438-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-18-Tips_on_%E2%80%9Cgreat_design%E2%80%9D_from_._._._Microsoft%21.html">1219 andrew gelman stats-2012-03-18-Tips on “great design” from . . . Microsoft!</a></p>
<p>11 0.94364506 <a title="1438-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-17-How_to_map_geographically-detailed_survey_responses%3F.html">1124 andrew gelman stats-2012-01-17-How to map geographically-detailed survey responses?</a></p>
<p>12 0.94073135 <a title="1438-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-08-Traffic_Prediction.html">752 andrew gelman stats-2011-06-08-Traffic Prediction</a></p>
<p>13 0.93735576 <a title="1438-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-07-X_on_JLP.html">1792 andrew gelman stats-2013-04-07-X on JLP</a></p>
<p>14 0.9372142 <a title="1438-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-15-Reputations_changeable%2C_situations_tolerable.html">1858 andrew gelman stats-2013-05-15-Reputations changeable, situations tolerable</a></p>
<p>15 0.93460345 <a title="1438-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-19-Standardized_writing_styles_and_standardized_graphing_styles.html">1176 andrew gelman stats-2012-02-19-Standardized writing styles and standardized graphing styles</a></p>
<p>16 0.9345814 <a title="1438-lda-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>17 0.93423307 <a title="1438-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-13-Test_scores_and_grades_predict_job_performance_%28but_maybe_not_at_Google%29.html">1980 andrew gelman stats-2013-08-13-Test scores and grades predict job performance (but maybe not at Google)</a></p>
<p>18 0.93383402 <a title="1438-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-14-Pourquoi_Google_search_est_devenu_plus_raisonnable%3F.html">207 andrew gelman stats-2010-08-14-Pourquoi Google search est devenu plus raisonnable?</a></p>
<p>19 0.93356109 <a title="1438-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-19-Tradeoffs_in_information_graphics.html">1584 andrew gelman stats-2012-11-19-Tradeoffs in information graphics</a></p>
<p>20 0.93346477 <a title="1438-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
