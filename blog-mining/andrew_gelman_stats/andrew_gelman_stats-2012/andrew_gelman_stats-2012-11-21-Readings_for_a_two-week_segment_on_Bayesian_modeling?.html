<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1586 andrew gelman stats-2012-11-21-Readings for a two-week segment on Bayesian modeling?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1586" href="#">andrew_gelman_stats-2012-1586</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1586 andrew gelman stats-2012-11-21-Readings for a two-week segment on Bayesian modeling?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1586-html" href="http://andrewgelman.com/2012/11/21/readings-for-a-two-week-segment-on-bayesian-modeling/">html</a></p><p>Introduction: Michael Landy writes:
  
I’m in Psych and Center for Neural Science and I’m teaching a doctoral course this term in methods in psychophysics (never mind the details) at the tail end of which I’m planning on at least 2 lectures on Bayesian parameter estimation and Bayesian model comparison. So far, all the readings I have are a bit too obscure and either glancing (bits of machine-learning books: Bishop, MacKay) or too low-level. The only useful reference I’ve got is an application of these methods (a methods article of mine in a Neuroscience Methods journal). The idea is to give them a decent idea of both estimation (Jeffries priors, marginals of the posterior over the parameters) and model comparison (cross-validation, AIC, BIC, full-blown Bayesian model posterior comparisons, Bayes factor, Occam factor, blah blah blah).


So: have you any suggestions for articles or chapters that might be suitable (yes, I’m aware you have an entire book that’s obviously relevant)?  In the class topic</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Michael Landy writes:    I’m in Psych and Center for Neural Science and I’m teaching a doctoral course this term in methods in psychophysics (never mind the details) at the tail end of which I’m planning on at least 2 lectures on Bayesian parameter estimation and Bayesian model comparison. [sent-1, score-1.104]
</p><p>2 So far, all the readings I have are a bit too obscure and either glancing (bits of machine-learning books: Bishop, MacKay) or too low-level. [sent-2, score-0.313]
</p><p>3 The only useful reference I’ve got is an application of these methods (a methods article of mine in a Neuroscience Methods journal). [sent-3, score-0.447]
</p><p>4 The idea is to give them a decent idea of both estimation (Jeffries priors, marginals of the posterior over the parameters) and model comparison (cross-validation, AIC, BIC, full-blown Bayesian model posterior comparisons, Bayes factor, Occam factor, blah blah blah). [sent-4, score-1.379]
</p><p>5 So: have you any suggestions for articles or chapters that might be suitable (yes, I’m aware you have an entire book that’s obviously relevant)? [sent-5, score-0.165]
</p><p>6 In the class topic (psychophysics), the data being modeled are typically choice data (binomial data), but my methods paper happens to be on data from measuring movement errors (continuous data), not that any of that matters. [sent-6, score-1.083]
</p><p>7 I recommend you (and your students) take a look at my  1995 article with Rubin  in Sociological Methodology (if you go to my home page, go to published papers, and search, you’ll find that paper) for a thorough discussion of what we hate about this. [sent-8, score-0.293]
</p><p>8 I also think Jeffreys priors are a waste of time. [sent-9, score-0.202]
</p><p>9 I wouldn’t spend one moment on that in your course if I were you. [sent-10, score-0.073]
</p><p>10 Regarding choice models, you could take a look at the section on choice models in chapter 6 of my book with Jennifer Hill. [sent-11, score-0.642]
</p><p>11 I also have a paper in Technometrics,  Multilevel modeling:  What it can and cannot do . [sent-12, score-0.081]
</p><p>12 Regarding the topic of model checking, you could take a look at chapter 6 of Bayesian Data Analysis. [sent-13, score-0.496]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('blah', 0.306), ('psychophysics', 0.259), ('factor', 0.244), ('occam', 0.234), ('bic', 0.225), ('methods', 0.188), ('choice', 0.167), ('bayesian', 0.135), ('technometrics', 0.129), ('glancing', 0.129), ('marginals', 0.129), ('estimation', 0.122), ('priors', 0.121), ('jeffreys', 0.117), ('bayes', 0.114), ('chapter', 0.109), ('mackay', 0.109), ('bishop', 0.107), ('doctoral', 0.107), ('posterior', 0.106), ('data', 0.105), ('model', 0.102), ('readings', 0.102), ('neural', 0.102), ('psych', 0.102), ('aic', 0.102), ('look', 0.1), ('decent', 0.1), ('regarding', 0.1), ('take', 0.099), ('neuroscience', 0.097), ('tail', 0.094), ('thorough', 0.094), ('binomial', 0.091), ('suitable', 0.09), ('lectures', 0.086), ('topic', 0.086), ('bits', 0.085), ('movement', 0.085), ('sociological', 0.085), ('modeled', 0.083), ('obscure', 0.082), ('paper', 0.081), ('waste', 0.081), ('measuring', 0.078), ('chapters', 0.075), ('methodology', 0.074), ('course', 0.073), ('planning', 0.073), ('mine', 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="1586-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-21-Readings_for_a_two-week_segment_on_Bayesian_modeling%3F.html">1586 andrew gelman stats-2012-11-21-Readings for a two-week segment on Bayesian modeling?</a></p>
<p>Introduction: Michael Landy writes:
  
I’m in Psych and Center for Neural Science and I’m teaching a doctoral course this term in methods in psychophysics (never mind the details) at the tail end of which I’m planning on at least 2 lectures on Bayesian parameter estimation and Bayesian model comparison. So far, all the readings I have are a bit too obscure and either glancing (bits of machine-learning books: Bishop, MacKay) or too low-level. The only useful reference I’ve got is an application of these methods (a methods article of mine in a Neuroscience Methods journal). The idea is to give them a decent idea of both estimation (Jeffries priors, marginals of the posterior over the parameters) and model comparison (cross-validation, AIC, BIC, full-blown Bayesian model posterior comparisons, Bayes factor, Occam factor, blah blah blah).


So: have you any suggestions for articles or chapters that might be suitable (yes, I’m aware you have an entire book that’s obviously relevant)?  In the class topic</p><p>2 0.26888272 <a title="1586-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>Introduction: In my comments on David MacKay’s 2003 book on Bayesian inference, I  wrote  that I hate all the Occam-factor stuff that MacKay talks about, and I linked to  this quote  from Radford Neal:
  
Sometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.
  
MacKay replied as follows:
  
When you said you disagree with me on Occam factors I think what you meant was that you agree with me on them.  I’ve read your post on the topic and completely agreed with you (and Radford) that we should be using models the size of a  house, models that we believe in, and that anyone who thinks it is a good idea to  bias the model toward</p><p>3 0.19010767 <a title="1586-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>Introduction: Cosma Shalizi  and  Larry Wasserman  discuss some papers from a conference on Ockham’s Razor.  I don’t have anything new to add on this so let me link to  past blog entries  on the topic and repost the following  from 2004 :
  
A lot has been written in statistics about “parsimony”—that is, the desire to explain phenomena using fewer parameters–but I’ve never seen any good general justification for parsimony.  (I don’t count “Occam’s Razor,” or “Ockham’s Razor,” or whatever, as a justification.  You gotta do better than digging up a 700-year-old quote.)


Maybe it’s because I work in social science, but my feeling is:  if you can approximate reality with just a few parameters, fine.  If you can use more parameters to fold in more information, that’s even better.


In practice, I often use simple models—because they are less effort to fit and, especially, to understand.  But I don’t kid myself that they’re better than more complicated efforts!


My favorite quote on this comes from  Rad</p><p>4 0.17372176 <a title="1586-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>Introduction: In response to  my remarks  on his online book, Think Bayes, Allen Downey wrote: 
   
I [Downey] have a question about one of your comments: 
   My [Gelman's] main criticism with both books is that they talk a lot about inference but not so much about model building or model checking (recall the three steps of Bayesian data analysis). I think it’s ok for an introductory book to focus on inference, which of course is central to the data-analytic process—but I’d like them to at least mention that Bayesian ideas arise in model building and model checking as well. 

This sounds like something I agree with, and one of the things I tried to do in the book is to put modeling decisions front and center.  But the word “modeling” is used in lots of ways, so I want to see if we are talking about the same thing.


For example, in many chapters, I start with a simple model of the scenario, do some analysis, then check whether the model is good enough, and iterate.  Here’s the discussion of modeling</p><p>5 0.15350284 <a title="1586-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>Introduction: Bayesian inference, conditional on the model and data, conforms to the likelihood principle. But there is more to Bayesian methods than Bayesian inference. See chapters 6 and 7 of Bayesian Data Analysis for much discussion of this point.
 
It saddens me to see that people are still  confused  on this issue.</p><p>6 0.1441763 <a title="1586-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>7 0.13796134 <a title="1586-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>8 0.13601734 <a title="1586-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>9 0.13243806 <a title="1586-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-07-Feedback_on_my_Bayesian_Data_Analysis_class_at_Columbia.html">1611 andrew gelman stats-2012-12-07-Feedback on my Bayesian Data Analysis class at Columbia</a></p>
<p>10 0.1312246 <a title="1586-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>11 0.13048878 <a title="1586-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>12 0.12697956 <a title="1586-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>13 0.12452625 <a title="1586-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-19-Revised_evidence_for_statistical_standards.html">2140 andrew gelman stats-2013-12-19-Revised evidence for statistical standards</a></p>
<p>14 0.12385375 <a title="1586-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>15 0.12341411 <a title="1586-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>16 0.12329298 <a title="1586-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>17 0.12302168 <a title="1586-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-18-What_to_read_to_catch_up_on_multivariate_statistics%3F.html">1726 andrew gelman stats-2013-02-18-What to read to catch up on multivariate statistics?</a></p>
<p>18 0.12091924 <a title="1586-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>19 0.11690683 <a title="1586-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-21-Bayes_related.html">1948 andrew gelman stats-2013-07-21-Bayes related</a></p>
<p>20 0.11490571 <a title="1586-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-18-How_to_teach_methods_we_don%E2%80%99t_like%3F.html">1582 andrew gelman stats-2012-11-18-How to teach methods we don’t like?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.221), (1, 0.166), (2, -0.097), (3, 0.039), (4, -0.048), (5, 0.049), (6, -0.004), (7, 0.008), (8, 0.029), (9, 0.013), (10, 0.092), (11, 0.024), (12, -0.018), (13, 0.01), (14, 0.102), (15, -0.021), (16, -0.011), (17, 0.022), (18, -0.024), (19, -0.011), (20, 0.009), (21, 0.025), (22, 0.034), (23, -0.01), (24, -0.039), (25, -0.02), (26, -0.01), (27, 0.004), (28, 0.064), (29, -0.015), (30, -0.069), (31, -0.009), (32, 0.026), (33, 0.002), (34, 0.006), (35, 0.033), (36, -0.008), (37, -0.047), (38, 0.015), (39, 0.034), (40, -0.045), (41, 0.021), (42, -0.024), (43, 0.022), (44, 0.011), (45, -0.026), (46, 0.024), (47, 0.02), (48, -0.025), (49, -0.002)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97140402 <a title="1586-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-21-Readings_for_a_two-week_segment_on_Bayesian_modeling%3F.html">1586 andrew gelman stats-2012-11-21-Readings for a two-week segment on Bayesian modeling?</a></p>
<p>Introduction: Michael Landy writes:
  
I’m in Psych and Center for Neural Science and I’m teaching a doctoral course this term in methods in psychophysics (never mind the details) at the tail end of which I’m planning on at least 2 lectures on Bayesian parameter estimation and Bayesian model comparison. So far, all the readings I have are a bit too obscure and either glancing (bits of machine-learning books: Bishop, MacKay) or too low-level. The only useful reference I’ve got is an application of these methods (a methods article of mine in a Neuroscience Methods journal). The idea is to give them a decent idea of both estimation (Jeffries priors, marginals of the posterior over the parameters) and model comparison (cross-validation, AIC, BIC, full-blown Bayesian model posterior comparisons, Bayes factor, Occam factor, blah blah blah).


So: have you any suggestions for articles or chapters that might be suitable (yes, I’m aware you have an entire book that’s obviously relevant)?  In the class topic</p><p>2 0.82708764 <a title="1586-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-23-Bayesian_adaptive_methods_for_clinical_trials.html">427 andrew gelman stats-2010-11-23-Bayesian adaptive methods for clinical trials</a></p>
<p>Introduction: Scott Berry, Brad Carlin, Jack Lee, and Peter Muller recently came out with  a book  with the above title.
 
The book packs a lot into its 280 pages and is fun to read as well (even if they do use the word “modalities” in their first paragraph, and later on they use the phrase “DIC criterion,” which upsets my tidy, logical mind).  The book starts off fast on page 1 and never lets go.
 
Clinical trials are a big part of statistics and it’s cool to see the topic taken seriously and being treated rigorously.  (Here I’m not talking about empty mathematical rigor (or, should I say, “rigor”), so-called optimal designs and all that, but rather the rigor of applied statistics, mapping models to reality.)
 
Also I have a few technical suggestions.
 
1.  The authors fit a lot of models in Bugs, which is fine, but they go overboard on the WinBUGS thing.  There’s WinBUGS, OpenBUGS, JAGS:  they’re all Bugs recommend running Bugs from R using the clunky BRugs interface rather than the smoother bugs(</p><p>3 0.78491551 <a title="1586-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-21-Bayes_related.html">1948 andrew gelman stats-2013-07-21-Bayes related</a></p>
<p>Introduction: Dave Decker writes:
  
I’ve seen some Bayes related things recently that might make for interesting fodder on your blog.


There are two books, teaching Bayesian analysis from a programming perspective.


And also a “web application for data analysis using powerful Bayesian statistical methods.”
  
   
I took a look.  The first book is  Think Bayes: Bayesian Statistics Made Simple, by Allen B. Downey .  It’s super readable and, amazingly, has approximately zero overlap with Bayesian Data Analysis.  Downey discusses lots of little problems in a conversational way.  In some ways it’s like an old-style math stat textbook (although with a programming rather than mathematical flavor) in that the examples are designed for simplicity rather than realism.  I like it!  Our book already exists; it’s good to have something else for people to read, coming from an entirely different perspective.
 
The second book is  Probabilistic Programming and Bayesian Methods for Hackers , by Cameron Davidson-P</p><p>4 0.77276748 <a title="1586-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>Introduction: In my comments on David MacKay’s 2003 book on Bayesian inference, I  wrote  that I hate all the Occam-factor stuff that MacKay talks about, and I linked to  this quote  from Radford Neal:
  
Sometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.
  
MacKay replied as follows:
  
When you said you disagree with me on Occam factors I think what you meant was that you agree with me on them.  I’ve read your post on the topic and completely agreed with you (and Radford) that we should be using models the size of a  house, models that we believe in, and that anyone who thinks it is a good idea to  bias the model toward</p><p>5 0.7657662 <a title="1586-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-22-Spell-checking_example_demonstrates_key_aspects_of_Bayesian_data_analysis.html">2182 andrew gelman stats-2014-01-22-Spell-checking example demonstrates key aspects of Bayesian data analysis</a></p>
<p>Introduction: One of the new examples for the third edition of Bayesian Data Analysis is a spell-checking story.   Here it is  (just start at 2/3 down on the first page, with “Spelling correction”).
 
I like this example—it demonstrates the Bayesian algebra, also gives a sense of the way that probability models (both “likelihood” and “prior”) are constructed from existing assumptions and data.  The models aren’t just specified as a mathematical exercise, they represent some statement about reality.  And the problem is close enough to our experience that we can consider ways in which the model can be criticized and improved, all in a simple example that has only three possibilities.</p><p>6 0.76271832 <a title="1586-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-09-The_anti-Bayesian_moment_and_its_passing.html">1571 andrew gelman stats-2012-11-09-The anti-Bayesian moment and its passing</a></p>
<p>7 0.76141298 <a title="1586-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-More_on_Bayesian_methods_and_multilevel_modeling.html">2033 andrew gelman stats-2013-09-23-More on Bayesian methods and multilevel modeling</a></p>
<p>8 0.75566232 <a title="1586-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>9 0.75420552 <a title="1586-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>10 0.74822986 <a title="1586-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-30-Infill_asymptotics_and_sprawl_asymptotics.html">1877 andrew gelman stats-2013-05-30-Infill asymptotics and sprawl asymptotics</a></p>
<p>11 0.73930711 <a title="1586-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-19-An_interweaving-transformation_strategy_for_boosting_MCMC_efficiency.html">964 andrew gelman stats-2011-10-19-An interweaving-transformation strategy for boosting MCMC efficiency</a></p>
<p>12 0.73487562 <a title="1586-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-References_%28with_code%29_for_Bayesian_hierarchical_%28multilevel%29_modeling_and_structural_equation_modeling.html">2273 andrew gelman stats-2014-03-29-References (with code) for Bayesian hierarchical (multilevel) modeling and structural equation modeling</a></p>
<p>13 0.73377693 <a title="1586-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-01-Peter_Huber%E2%80%99s_reflections_on_data_analysis.html">690 andrew gelman stats-2011-05-01-Peter Huber’s reflections on data analysis</a></p>
<p>14 0.7320416 <a title="1586-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-01-My_course_this_fall_on_Bayesian_Computation.html">884 andrew gelman stats-2011-09-01-My course this fall on Bayesian Computation</a></p>
<p>15 0.72992265 <a title="1586-lsi-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-18-Those_wacky_anti-Bayesians_used_to_be_intimidating%2C_but_now_they%E2%80%99re_just_pathetic.html">2254 andrew gelman stats-2014-03-18-Those wacky anti-Bayesians used to be intimidating, but now they’re just pathetic</a></p>
<p>16 0.72943747 <a title="1586-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>17 0.72801894 <a title="1586-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-22-Deviance%2C_DIC%2C_AIC%2C_cross-validation%2C_etc.html">776 andrew gelman stats-2011-06-22-Deviance, DIC, AIC, cross-validation, etc</a></p>
<p>18 0.72697902 <a title="1586-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-Bayesian_models_for_simultaneous_equation_systems%3F.html">183 andrew gelman stats-2010-08-04-Bayesian models for simultaneous equation systems?</a></p>
<p>19 0.72277641 <a title="1586-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-14-Progress%21__%28on_the_understanding_of_the_role_of_randomization_in_Bayesian_inference%29.html">1898 andrew gelman stats-2013-06-14-Progress!  (on the understanding of the role of randomization in Bayesian inference)</a></p>
<p>20 0.71964711 <a title="1586-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.087), (21, 0.019), (24, 0.07), (41, 0.011), (42, 0.027), (43, 0.011), (56, 0.011), (63, 0.014), (65, 0.012), (79, 0.023), (81, 0.016), (86, 0.275), (99, 0.305)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98869121 <a title="1586-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-26-Luck_or_knowledge%3F.html">873 andrew gelman stats-2011-08-26-Luck or knowledge?</a></p>
<p>Introduction: Joan Ginther has won the Texas lottery four times.  First, she won $5.4 million, then a decade later, she won $2million, then two years later $3million and in the summer of 2010, she hit a $10million jackpot. The odds of this has been calculated at one in eighteen septillion and luck like this could only come once every quadrillion years. 
 
 According to Forbes, the residents of Bishop, Texas, seem to believe God was behind it all.  The Texas Lottery Commission told Mr Rich that Ms Ginther must have been ‘born under a lucky star’, and that they don’t suspect foul play.  
 
 Harper’s reporter Nathanial Rich recently wrote an article about Ms Ginther, which calls the the validity of her ‘luck’ into question. First, he points out, Ms Ginther is a former math professor with a PhD from Stanford University specialising in statistics. 
 
More at  Daily Mail. 
 
[Edited Saturday] In comments, C Ryan King points to the original article at  Harper’s  and  Bill Jefferys  to  Wired .</p><p>2 0.9788276 <a title="1586-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-11-Migrating_your_blog_from_Movable_Type_to_WordPress.html">1530 andrew gelman stats-2012-10-11-Migrating your blog from Movable Type to WordPress</a></p>
<p>Introduction: Cord Blomquist, who did a great job moving us from horrible Movable Type to nice nice WordPress, writes:
  
I [Cord] wanted to share a little news with you related to the original work we did for you last year.  When ReadyMadeWeb converted your Movable Type blog to WordPress, we got a lot of other requestes for the same service, so we started thinking about a bigger market for such a product.  After a bit of research, we started work on automating the data conversion, writing rules, and exceptions to the rules, on how Movable Type and TypePad data could be translated to WordPress.


After many months of work, we’re getting ready to announce  TP2WP.com , a service that converts Movable Type and TypePad export files to WordPress import files, so anyone who wants to migrate to WordPress can do so easily and without losing permalinks, comments, images, or other files.  By automating our service, we’ve been able to drop the price to just $99.
  
I recommend it (and, no, Cord is not paying m</p><p>3 0.97530591 <a title="1586-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-24-More_from_the_sister_blog.html">1427 andrew gelman stats-2012-07-24-More from the sister blog</a></p>
<p>Introduction: Anthropologist Bruce Mannheim  reports  that a recent well-publicized study on the genetics of native Americans, which used genetic analysis to find “at least three streams of Asian gene flow,” is in fact a confirmation of a long-known fact.  Mannheim writes:
  
This three-way distinction was known linguistically since the 1920s (for example, Sapir 1921). Basically, it’s a division among the Eskimo-Aleut languages, which straddle the Bering Straits even today, the Athabaskan languages (which were discovered to be related to a small Siberian language family only within the last few years, not by Greenberg as Wade suggested), and everything else.
  
This is not to say that the results from genetics are unimportant, but it’s good to see how it fits with other aspects of our understanding.</p><p>4 0.97451115 <a title="1586-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-13-My_wikipedia_edit.html">904 andrew gelman stats-2011-09-13-My wikipedia edit</a></p>
<p>Introduction: The other day someone mentioned my complaint about the Wikipedia article on “Bayesian inference” (see footnote 1 of  this article ) and he said I should fix the Wikipedia entry myself.
 
And  so I did .  I didn’t have the energy to rewrite the whole article–in particular, all of its examples involve discrete parameters, whereas the Bayesian problems I work on generally have continuous parameters, and its “mathematical foundations” section focuses on “independent identically distributed observations x” rather than data y which can have different distributions.  It’s just a wacky, unbalanced article.  But I altered the first few paragraphs to get rid of the stuff about the posterior probability that a model is true.
 
I much prefer the  Scholarpedia article on Bayesian statistics  by David Spiegelhalter and Kenneth Rice, but I couldn’t bring myself to simply delete the Wikipedia article and replace it with the Scholarpedia content.
 
Just to be clear:  I’m not at all trying to disparage</p><p>5 0.9720493 <a title="1586-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Both_R_and_Stata.html">76 andrew gelman stats-2010-06-09-Both R and Stata</a></p>
<p>Introduction: A student I’m working with writes:
  
I was planning on getting a applied stat text as a desk reference, and for that I’m assuming you’d recommend your own book. Also, being an economics student, I was initially planning on doing my analysis in STATA, but I noticed on your blog that you use R, and apparently so does the rest of the statistics profession. Would you rather I do my programming in R this summer, or does it not matter? It doesn’t look too hard to learn, so just let me know what’s most convenient for you.
  
My reply:  Yes, I recommend my book with Jennifer Hill.  Also the book by John Fox, An R and S-plus Companion to Applied Regression, is a good way to get into R.  I recommend you use both Stata and R.  If you’re already familiar with Stata, then stick with it–it’s a great system for working with big datasets.  You can grab your data in Stata, do some basic manipulations, then save a smaller dataset to read into R (using R’s read.dta() function).  Once you want to make fu</p><p>6 0.97007281 <a title="1586-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Toward_a_framework_for_automatic_model_building.html">1718 andrew gelman stats-2013-02-11-Toward a framework for automatic model building</a></p>
<p>7 0.96904671 <a title="1586-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-03-Gladwell_vs_Pinker.html">253 andrew gelman stats-2010-09-03-Gladwell vs Pinker</a></p>
<p>8 0.95849025 <a title="1586-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-05-Fattening_of_the_world_and_good_use_of_the_alpha_channel.html">558 andrew gelman stats-2011-02-05-Fattening of the world and good use of the alpha channel</a></p>
<p>9 0.94717312 <a title="1586-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-25-College_football%2C_voting%2C_and_the_law_of_large_numbers.html">1547 andrew gelman stats-2012-10-25-College football, voting, and the law of large numbers</a></p>
<p>10 0.92612231 <a title="1586-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-14-Don%E2%80%99t_look_at_just_one_poll_number%E2%80%93unless_you_really_know_what_you%E2%80%99re_doing%21.html">276 andrew gelman stats-2010-09-14-Don’t look at just one poll number–unless you really know what you’re doing!</a></p>
<p>11 0.92592192 <a title="1586-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-29-%E2%80%9CCommunication_is_a_central_task_of_statistics%2C_and_ideally_a_state-of-the-art_data_analysis_can_have_state-of-the-art_displays_to_match%E2%80%9D.html">1552 andrew gelman stats-2012-10-29-“Communication is a central task of statistics, and ideally a state-of-the-art data analysis can have state-of-the-art displays to match”</a></p>
<p>same-blog 12 0.92415833 <a title="1586-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-21-Readings_for_a_two-week_segment_on_Bayesian_modeling%3F.html">1586 andrew gelman stats-2012-11-21-Readings for a two-week segment on Bayesian modeling?</a></p>
<p>13 0.92304361 <a title="1586-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-18-Comments_on_%E2%80%9CA_Bayesian_approach_to_complex_clinical_diagnoses%3A_a_case-study_in_child_abuse%E2%80%9D.html">1327 andrew gelman stats-2012-05-18-Comments on “A Bayesian approach to complex clinical diagnoses: a case-study in child abuse”</a></p>
<p>14 0.9212001 <a title="1586-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>15 0.91500151 <a title="1586-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-30-Berri_Gladwell_Loken_football_update.html">2082 andrew gelman stats-2013-10-30-Berri Gladwell Loken football update</a></p>
<p>16 0.91359818 <a title="1586-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-13-The_Road_to_a_B.html">515 andrew gelman stats-2011-01-13-The Road to a B</a></p>
<p>17 0.90787148 <a title="1586-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-15-Mr._P_by_another_name_._._._is_still_great%21.html">769 andrew gelman stats-2011-06-15-Mr. P by another name . . . is still great!</a></p>
<p>18 0.90446806 <a title="1586-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-29-Decision_science_vs._social_psychology.html">305 andrew gelman stats-2010-09-29-Decision science vs. social psychology</a></p>
<p>19 0.90155786 <a title="1586-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-23-%E2%80%9CAny_old_map_will_do%E2%80%9D_meets_%E2%80%9CGod_is_in_every_leaf_of_every_tree%E2%80%9D.html">1278 andrew gelman stats-2012-04-23-“Any old map will do” meets “God is in every leaf of every tree”</a></p>
<p>20 0.8968811 <a title="1586-lda-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-21-The_world%E2%80%99s_most_popular_languages_that_the_Mac_documentation_hasn%E2%80%99t_been_translated_into.html">2219 andrew gelman stats-2014-02-21-The world’s most popular languages that the Mac documentation hasn’t been translated into</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
