<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1489 andrew gelman stats-2012-09-09-Commercial Bayesian inference software is popping up all over</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1489" href="#">andrew_gelman_stats-2012-1489</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1489 andrew gelman stats-2012-09-09-Commercial Bayesian inference software is popping up all over</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1489-html" href="http://andrewgelman.com/2012/09/09/commercial-bayesian-inference-software-is-popping-up-all-over/">html</a></p><p>Introduction: Steve Cohen writes:
  
As someone who has been working with Bayesian statistical models for the past several years, I [Cohen] have been challenged recently to describe the difference between Bayesian Networks (as implemented in BayesiaLab software) and modeling and inference using MCMC methods.


I hope you have the time to give me (or to write on your blog) and relatively simple explanation that an advanced layman could understand.
  
My reply:
 
I skimmed the above website but I couldn’t quite see what they do.  My guess is that they use MCMC and also various parametric approximations such as variational Bayes.  They also seem to have something set up for decision analysis.
 
My guess is that, compared to a general-purpose tool such as Stan, this Bayesia software is more accessible to non-academics in particular application areas (in this case, it looks like business marketing).  But I can’t be sure.
 
I’ve also heard about another company that looks to be doing something similar:  h</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Steve Cohen writes:    As someone who has been working with Bayesian statistical models for the past several years, I [Cohen] have been challenged recently to describe the difference between Bayesian Networks (as implemented in BayesiaLab software) and modeling and inference using MCMC methods. [sent-1, score-1.042]
</p><p>2 I hope you have the time to give me (or to write on your blog) and relatively simple explanation that an advanced layman could understand. [sent-2, score-0.788]
</p><p>3 My reply:   I skimmed the above website but I couldn’t quite see what they do. [sent-3, score-0.421]
</p><p>4 My guess is that they use MCMC and also various parametric approximations such as variational Bayes. [sent-4, score-0.839]
</p><p>5 They also seem to have something set up for decision analysis. [sent-5, score-0.349]
</p><p>6 My guess is that, compared to a general-purpose tool such as Stan, this Bayesia software is more accessible to non-academics in particular application areas (in this case, it looks like business marketing). [sent-6, score-1.221]
</p><p>7 I’ve also heard about another company that looks to be doing something similar:  https://www. [sent-8, score-0.569]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cohen', 0.322), ('mcmc', 0.28), ('layman', 0.234), ('skimmed', 0.234), ('software', 0.224), ('variational', 0.188), ('challenged', 0.184), ('https', 0.18), ('parametric', 0.172), ('looks', 0.17), ('approximations', 0.165), ('accessible', 0.15), ('guess', 0.149), ('marketing', 0.149), ('implemented', 0.146), ('advanced', 0.139), ('networks', 0.136), ('steve', 0.132), ('explanation', 0.126), ('relatively', 0.125), ('bayesian', 0.121), ('tool', 0.12), ('company', 0.117), ('application', 0.113), ('website', 0.112), ('describe', 0.11), ('couldn', 0.106), ('areas', 0.104), ('stan', 0.102), ('decision', 0.1), ('business', 0.099), ('heard', 0.099), ('also', 0.092), ('compared', 0.092), ('hope', 0.091), ('something', 0.091), ('past', 0.083), ('modeling', 0.081), ('difference', 0.081), ('similar', 0.078), ('quite', 0.075), ('inference', 0.074), ('recently', 0.074), ('several', 0.073), ('various', 0.073), ('simple', 0.073), ('working', 0.07), ('reply', 0.068), ('set', 0.066), ('someone', 0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1489-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-09-Commercial_Bayesian_inference_software_is_popping_up_all_over.html">1489 andrew gelman stats-2012-09-09-Commercial Bayesian inference software is popping up all over</a></p>
<p>Introduction: Steve Cohen writes:
  
As someone who has been working with Bayesian statistical models for the past several years, I [Cohen] have been challenged recently to describe the difference between Bayesian Networks (as implemented in BayesiaLab software) and modeling and inference using MCMC methods.


I hope you have the time to give me (or to write on your blog) and relatively simple explanation that an advanced layman could understand.
  
My reply:
 
I skimmed the above website but I couldn’t quite see what they do.  My guess is that they use MCMC and also various parametric approximations such as variational Bayes.  They also seem to have something set up for decision analysis.
 
My guess is that, compared to a general-purpose tool such as Stan, this Bayesia software is more accessible to non-academics in particular application areas (in this case, it looks like business marketing).  But I can’t be sure.
 
I’ve also heard about another company that looks to be doing something similar:  h</p><p>2 0.23689994 <a title="1489-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-24-Yet_another_Bayesian_job_opportunity.html">231 andrew gelman stats-2010-08-24-Yet another Bayesian job opportunity</a></p>
<p>Introduction: Steve Cohen writes:
  
My [Cohen's] firm is looking for strong candidates to help us in developing software and analyzing data using Bayesian methods.


We have been developing a suite of programs in C++ which allow us to do Bayesian hierarchical regression and logit/probit models on marketing data. These efforts have included the use of high performance computing tools like nVidia’s CUDA and the new OpenCL standard, which allow parallel processing of Bayesian models. Our software is very, very fast – even on databases that are ½ terabyte in size. The software still needs many additions and improvements and a person with the right skill set will have the chance to make a significant contribution.
  
Here’s the job description he sent:
  
 
Bayesian statistician and C++ programmer


The company


In4mation Insights is a marketing research, analytics, and consulting firm which operates on the leading-edge of our industry.  Our clients are Fortune 500 companies and major management consul</p><p>3 0.15920579 <a title="1489-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-15-Our_blog_makes_connections%21.html">1497 andrew gelman stats-2012-09-15-Our blog makes connections!</a></p>
<p>Introduction: Steve Cohen writes:
  
Thank you for fulfilling another request of mine almost two years ago. I gave you a job description of a senior Bayesian statistical software developer that I was loooking to hire.  You kindly  posted it  on your site.


THAT EVENING, I received a response from a fellow in Florida who had worked as a C++ programmer for 10+ years and — inexplicably — was now finishing his PhD in Bayesian econometrics.  We hired him and he has done magical things with our software, making estimating hierarchical Bayesian models in “real time” on very large, complex datasets a reality.  He’s a super guy, to boot!  Together with others on our staff, we now have fully parallelized versions of most econometric models working on over 100 cores.  (You may have read a paper by one of my partners, Prof John Liechty at Penn State, on parallel slicer samplers).</p><p>4 0.15268701 <a title="1489-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<p>Introduction: Tiago Fragoso writes:
  
Suppose I fit a two stage regression model


Y = a + bx + e 
a = cw + d + e1


I could fit it all in one step by using MCMC for example (my model is more complicated than that, so I’ll have to do it by MCMC). However, I could fit the first regression only using MCMC because those estimates are hard to obtain and perform the second regression using least squares or a separate MCMC. 


So there’s an ‘one step’ inference based on doing it all at the same time and a ‘two step’ inference by fitting one and using the estimates on the further steps. What is gained or lost between both? Is anything done in this question?
  
My response:
 
Rather than answering your particular question, I’ll give you my generic answer, which is to simulate fake data from your model, then fit your model both ways and see how the results differ.  Repeat the simulation a few thousand times and you can make all the statistical comparisons you like.</p><p>5 0.13640858 <a title="1489-tfidf-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-03-Running_into_a_Stan_Reference_by_Accident.html">2231 andrew gelman stats-2014-03-03-Running into a Stan Reference by Accident</a></p>
<p>Introduction: We were talking about parallelizing MCMC and I came up with what I thought was a neat idea for parallelizing MCMC (sample with fractional prior, average samples on a per-draw basis).  But then I realized this approach could get the right posterior mean or right posterior variance, but not both, depending on how the prior was divided (for a beta-binomial example).  Then  Aki  told me it had already been done in a more general form in a paper of Scott et al.,  Bayes and Big Data , which was then used as the baseline in: 
 
Willie Neiswanger, Chong Wang, and Eric Xing. 2013.   Asymptotically Exact, Embarrassingly Parallel MCMC .  arXiv  1311.4780. 
 
It’s a neat paper, which Xi’an  already blogged  about months ago.  But what really struck me was the following quote:
  

We use Stan, an automated Hamiltonian Monte Carlo (HMC) software package, to perform sampling for both the true posterior (for groundtruth and comparison methods) and for the subposteriors on each machine. One advantage o</p><p>6 0.12239176 <a title="1489-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-17-How_to_think_about_the_statistical_evidence_when_the_statistical_evidence_can%E2%80%99t_be_conclusive%3F.html">2174 andrew gelman stats-2014-01-17-How to think about the statistical evidence when the statistical evidence can’t be conclusive?</a></p>
<p>7 0.11584147 <a title="1489-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Let%E2%80%99s_play_%E2%80%9CGuess_the_smoother%E2%80%9D%21.html">1283 andrew gelman stats-2012-04-26-Let’s play “Guess the smoother”!</a></p>
<p>8 0.1122966 <a title="1489-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-21-Bayes_related.html">1948 andrew gelman stats-2013-07-21-Bayes related</a></p>
<p>9 0.11148321 <a title="1489-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-22-My_talks_that_were_scheduled_for_Tues_at_the_Data_Skeptics_meetup_and_Wed_at_the_Open_Statistical_Programming_meetup.html">1950 andrew gelman stats-2013-07-22-My talks that were scheduled for Tues at the Data Skeptics meetup and Wed at the Open Statistical Programming meetup</a></p>
<p>10 0.10897515 <a title="1489-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<p>11 0.10360022 <a title="1489-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-12-Val%E2%80%99s_Number_Scroll%3A_Helping_kids_visualize_math.html">1006 andrew gelman stats-2011-11-12-Val’s Number Scroll: Helping kids visualize math</a></p>
<p>12 0.10311751 <a title="1489-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-14-Transitioning_to_Stan.html">2291 andrew gelman stats-2014-04-14-Transitioning to Stan</a></p>
<p>13 0.10253849 <a title="1489-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>14 0.10177125 <a title="1489-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-18-Derivative-based_MCMC_as_a_breakthrough_technique_for_implementing_Bayesian_statistics.html">419 andrew gelman stats-2010-11-18-Derivative-based MCMC as a breakthrough technique for implementing Bayesian statistics</a></p>
<p>15 0.10097076 <a title="1489-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-29-Bayesian_spam%21.html">635 andrew gelman stats-2011-03-29-Bayesian spam!</a></p>
<p>16 0.099083841 <a title="1489-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-08-Silly_old_chi-square%21.html">401 andrew gelman stats-2010-11-08-Silly old chi-square!</a></p>
<p>17 0.097274169 <a title="1489-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-17-%E2%80%9CStop_and_frisk%E2%80%9D_statistics.html">1942 andrew gelman stats-2013-07-17-“Stop and frisk” statistics</a></p>
<p>18 0.095174372 <a title="1489-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-01-MCMC_machine.html">122 andrew gelman stats-2010-07-01-MCMC machine</a></p>
<p>19 0.095127426 <a title="1489-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-15-Postdoc_involving_pathbreaking_work_in_MRP%2C_Stan%2C_and_the_2014_election%21.html">2173 andrew gelman stats-2014-01-15-Postdoc involving pathbreaking work in MRP, Stan, and the 2014 election!</a></p>
<p>20 0.094775528 <a title="1489-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-20-%E2%80%9CPeople_with_an_itch_to_scratch%E2%80%9D.html">101 andrew gelman stats-2010-06-20-“People with an itch to scratch”</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.161), (1, 0.066), (2, -0.077), (3, 0.069), (4, 0.017), (5, 0.063), (6, -0.05), (7, -0.073), (8, 0.017), (9, -0.024), (10, -0.053), (11, -0.074), (12, 0.024), (13, -0.015), (14, 0.012), (15, 0.058), (16, 0.023), (17, 0.01), (18, -0.022), (19, 0.056), (20, 0.003), (21, 0.041), (22, -0.041), (23, -0.019), (24, 0.027), (25, -0.038), (26, -0.007), (27, 0.001), (28, -0.03), (29, -0.024), (30, 0.045), (31, -0.023), (32, 0.047), (33, -0.031), (34, 0.016), (35, 0.016), (36, -0.023), (37, 0.044), (38, -0.054), (39, 0.031), (40, -0.051), (41, 0.049), (42, -0.045), (43, 0.015), (44, -0.001), (45, -0.008), (46, -0.057), (47, 0.041), (48, 0.055), (49, -0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96338218 <a title="1489-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-09-Commercial_Bayesian_inference_software_is_popping_up_all_over.html">1489 andrew gelman stats-2012-09-09-Commercial Bayesian inference software is popping up all over</a></p>
<p>Introduction: Steve Cohen writes:
  
As someone who has been working with Bayesian statistical models for the past several years, I [Cohen] have been challenged recently to describe the difference between Bayesian Networks (as implemented in BayesiaLab software) and modeling and inference using MCMC methods.


I hope you have the time to give me (or to write on your blog) and relatively simple explanation that an advanced layman could understand.
  
My reply:
 
I skimmed the above website but I couldn’t quite see what they do.  My guess is that they use MCMC and also various parametric approximations such as variational Bayes.  They also seem to have something set up for decision analysis.
 
My guess is that, compared to a general-purpose tool such as Stan, this Bayesia software is more accessible to non-academics in particular application areas (in this case, it looks like business marketing).  But I can’t be sure.
 
I’ve also heard about another company that looks to be doing something similar:  h</p><p>2 0.79314339 <a title="1489-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-24-Yet_another_Bayesian_job_opportunity.html">231 andrew gelman stats-2010-08-24-Yet another Bayesian job opportunity</a></p>
<p>Introduction: Steve Cohen writes:
  
My [Cohen's] firm is looking for strong candidates to help us in developing software and analyzing data using Bayesian methods.


We have been developing a suite of programs in C++ which allow us to do Bayesian hierarchical regression and logit/probit models on marketing data. These efforts have included the use of high performance computing tools like nVidia’s CUDA and the new OpenCL standard, which allow parallel processing of Bayesian models. Our software is very, very fast – even on databases that are ½ terabyte in size. The software still needs many additions and improvements and a person with the right skill set will have the chance to make a significant contribution.
  
Here’s the job description he sent:
  
 
Bayesian statistician and C++ programmer


The company


In4mation Insights is a marketing research, analytics, and consulting firm which operates on the leading-edge of our industry.  Our clients are Fortune 500 companies and major management consul</p><p>3 0.78819984 <a title="1489-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-15-Our_blog_makes_connections%21.html">1497 andrew gelman stats-2012-09-15-Our blog makes connections!</a></p>
<p>Introduction: Steve Cohen writes:
  
Thank you for fulfilling another request of mine almost two years ago. I gave you a job description of a senior Bayesian statistical software developer that I was loooking to hire.  You kindly  posted it  on your site.


THAT EVENING, I received a response from a fellow in Florida who had worked as a C++ programmer for 10+ years and — inexplicably — was now finishing his PhD in Bayesian econometrics.  We hired him and he has done magical things with our software, making estimating hierarchical Bayesian models in “real time” on very large, complex datasets a reality.  He’s a super guy, to boot!  Together with others on our staff, we now have fully parallelized versions of most econometric models working on over 100 cores.  (You may have read a paper by one of my partners, Prof John Liechty at Penn State, on parallel slicer samplers).</p><p>4 0.71668649 <a title="1489-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-29-Bayesian_spam%21.html">635 andrew gelman stats-2011-03-29-Bayesian spam!</a></p>
<p>Introduction: Cool!  I know Bayes has reached the big time when I receive spam like this:
  
Bayesian networks are rapidly emerging as a new research paradigm . . . With this monthly newsletter, we’ll keep you up to date . . . Financial Analytics Webinar . . . will exhibit at this year’s INFORMS Analytics Conference in downtown Chicago. Please join us for our Bayesian networks technology workshop on April 10 . . . a powerful desktop application (Windows/Mac/Unix) for knowledge discovery, data mining, analytics, predictive modeling and simulation . . . the world’s only comprehensive software package for learning, editing and analyzing Bayesian networks . . . If you no longer wish to receive these emails, please reply to this message with “Unsubscribe” in the subject line . . .
  
You know the saying, “It’s not real unless it’s on TV”?  My saying is:  It’s not real until it’s on spam.</p><p>5 0.70469964 <a title="1489-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-18-Derivative-based_MCMC_as_a_breakthrough_technique_for_implementing_Bayesian_statistics.html">419 andrew gelman stats-2010-11-18-Derivative-based MCMC as a breakthrough technique for implementing Bayesian statistics</a></p>
<p>Introduction: John Salvatier pointed me to  this blog  on derivative based MCMC algorithms (also sometimes called “hybrid” or “Hamiltonian” Monte Carlo) and automatic differentiation as the future of MCMC.
 
This all makes sense to me and is consistent both with my mathematical intuition from studying Metropolis algorithms and my experience with Matt using hybrid MCMC when fitting hierarchical spline models. In particular, I agree with Salvatier’s point about the potential for computation of analytic derivatives of the log-density function.  As long as we’re mostly snapping together our models using analytically-simple pieces, the same part of the program that handles the computation of log-posterior densities should also be able to compute derivatives analytically.
 
I’ve been a big fan of automatic derivative-based MCMC methods since I started hearing about them a couple years ago (I’m thinking of the DREAM project and of Mark Girolami’s paper), and I too wonder why they haven’t been used more.  I</p><p>6 0.70149785 <a title="1489-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-12-Samplers_for_Big_Science%3A__emcee_and_BAT.html">2020 andrew gelman stats-2013-09-12-Samplers for Big Science:  emcee and BAT</a></p>
<p>7 0.67198068 <a title="1489-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<p>8 0.67157596 <a title="1489-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-20-%E2%80%9CPeople_with_an_itch_to_scratch%E2%80%9D.html">101 andrew gelman stats-2010-06-20-“People with an itch to scratch”</a></p>
<p>9 0.66069049 <a title="1489-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-18-Those_wacky_anti-Bayesians_used_to_be_intimidating%2C_but_now_they%E2%80%99re_just_pathetic.html">2254 andrew gelman stats-2014-03-18-Those wacky anti-Bayesians used to be intimidating, but now they’re just pathetic</a></p>
<p>10 0.65798092 <a title="1489-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-30-Stan_uses_Nuts%21.html">1036 andrew gelman stats-2011-11-30-Stan uses Nuts!</a></p>
<p>11 0.64965755 <a title="1489-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-19-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1019 andrew gelman stats-2011-11-19-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>12 0.64230651 <a title="1489-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-13-Arnold_Zellner.html">205 andrew gelman stats-2010-08-13-Arnold Zellner</a></p>
<p>13 0.63669932 <a title="1489-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-What_are_the_trickiest_models_to_fit%3F.html">575 andrew gelman stats-2011-02-15-What are the trickiest models to fit?</a></p>
<p>14 0.63497585 <a title="1489-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>15 0.63199186 <a title="1489-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-25-Continuous_variables_in_Bayesian_networks.html">1228 andrew gelman stats-2012-03-25-Continuous variables in Bayesian networks</a></p>
<p>16 0.62592518 <a title="1489-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-13-Silly_Sas_lays_out_old-fashioned_statistical_thinking.html">83 andrew gelman stats-2010-06-13-Silly Sas lays out old-fashioned statistical thinking</a></p>
<p>17 0.61973852 <a title="1489-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-05-Identifying_pathways_for_managing_multiple_disturbances_to_limit_plant_invasions.html">2360 andrew gelman stats-2014-06-05-Identifying pathways for managing multiple disturbances to limit plant invasions</a></p>
<p>18 0.61637759 <a title="1489-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-04-Shlemiel_the_Software_Developer_and_Unknown_Unknowns.html">2089 andrew gelman stats-2013-11-04-Shlemiel the Software Developer and Unknown Unknowns</a></p>
<p>19 0.60874307 <a title="1489-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<p>20 0.60721815 <a title="1489-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.018), (6, 0.113), (9, 0.024), (16, 0.039), (21, 0.029), (24, 0.189), (42, 0.02), (45, 0.017), (86, 0.055), (89, 0.019), (90, 0.024), (99, 0.345)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9788388 <a title="1489-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-18-Prior_information_._._._about_the_likelihood.html">618 andrew gelman stats-2011-03-18-Prior information . . . about the likelihood</a></p>
<p>Introduction: I read  this story  by Adrian Chen on Gawker (yeah, yeah, so sue me):
  
Why That ‘NASA Discovers Alien Life’ Story Is Bullshit






Fox News has a super-exciting article today: “Exclusive: NASA Scientist claims Evidence of Alien Life on Meteorite.” OMG, aliens exist! Except this NASA scientist has been claiming to have evidence of alien life on meteorites for years.
  
Chen continues with a quote from the Fox News item:
  
[NASA scientist Richard B. Hoover] gave FoxNews.com early access to the out-of-this-world research, published late Friday evening in the March edition of the Journal of Cosmology. In it, Hoover describes the latest findings in his study of an extremely rare class of meteorites, called CI1 carbonaceous chondrites — only nine such meteorites are known to exist on Earth. . . . 
  
The bad news is that Hoover reported this same sort of finding in various low-rent venues for several years.  Replication, huh?  Chen also helpfully points us to the  website  of the Journal</p><p>same-blog 2 0.97778457 <a title="1489-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-09-Commercial_Bayesian_inference_software_is_popping_up_all_over.html">1489 andrew gelman stats-2012-09-09-Commercial Bayesian inference software is popping up all over</a></p>
<p>Introduction: Steve Cohen writes:
  
As someone who has been working with Bayesian statistical models for the past several years, I [Cohen] have been challenged recently to describe the difference between Bayesian Networks (as implemented in BayesiaLab software) and modeling and inference using MCMC methods.


I hope you have the time to give me (or to write on your blog) and relatively simple explanation that an advanced layman could understand.
  
My reply:
 
I skimmed the above website but I couldn’t quite see what they do.  My guess is that they use MCMC and also various parametric approximations such as variational Bayes.  They also seem to have something set up for decision analysis.
 
My guess is that, compared to a general-purpose tool such as Stan, this Bayesia software is more accessible to non-academics in particular application areas (in this case, it looks like business marketing).  But I can’t be sure.
 
I’ve also heard about another company that looks to be doing something similar:  h</p><p>3 0.97755086 <a title="1489-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-08-Is_linear_regression_unethical_in_that_it_gives_more_weight_to_cases_that_are_far_from_the_average%3F.html">1409 andrew gelman stats-2012-07-08-Is linear regression unethical in that it gives more weight to cases that are far from the average?</a></p>
<p>Introduction: I received the following note from someone who’d like to remain anonymous: 
  
  
I read  your post  on ethics and statistics, and the comments therein, with much interest.


I did notice, however, that most of the dialogue was about ethical behavior of scientists.  Herein I’d like to suggest a different take, one that focuses on the statistical methods of scientists.


For example, fitting a line to a scatter plot of data using OLS [linear regression] gives more weight to outliers.  If each data point represents a person we are weighting people differently.  And surely the ethical implications are different if we use a least absolute deviation estimator.


Recently I reviewed a paper where the authors claimed one advantage of non-parametric rank-based tests is their robustness to outliers.  Again, maybe that outlier is the 10th person who dies from an otherwise beneficial medicine.  Should we ignore him in assessing the effect of the medicine?


I guess this gets me partly into loss f</p><p>4 0.9645952 <a title="1489-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-06-The_new_Stan_1.1.1%2C_featuring_Gaussian_processes%21.html">1710 andrew gelman stats-2013-02-06-The new Stan 1.1.1, featuring Gaussian processes!</a></p>
<p>Introduction: We just released Stan 1.1.1 and RStan 1.1.1
 
As usual, you can find download and install instructions at:
 
http://mc-stan.org/
 
This is a patch release and is fully backward compatible with Stan and RStan 1.1.0.  The main thing you should notice is that the multivariate models should be much faster and all the bugs reported for 1.1.0 have been fixed.  We’ve also added a bit more functionality.  The substantial changes are listed in the following release notes. 
   
v1.1.1 (5 February 2012) 
======================================================================
 
Bug Fixes 
———————————- 
* fixed bug in comparison operators, which swapped operator< with operator<= and swapped operator> with operator>= semantics 
* auto-initialize all variables to prevent segfaults 
* atan2 gradient propagation fixed 
* fixed off-by-one in NUTS treedepth bound so NUTS goes at most to specified tree depth rather than specified depth + 1 
* various compiler compatibility and minor consistency issues 
* f</p><p>5 0.96157128 <a title="1489-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-28-Understanding_simulations_in_terms_of_predictive_inference%3F.html">1287 andrew gelman stats-2012-04-28-Understanding simulations in terms of predictive inference?</a></p>
<p>Introduction: David Hogg writes:
  
My (now deceased) collaborator and guru in all things inference, Sam Roweis, used to emphasize to me that we should evaluate models in the data space — not the parameter space — because models are always effectively “effective” and not really, fundamentally true. Or, in other words, models should be compared in the space of their predictions, not in the space of their parameters (the  parameters didn’t really “exist” at all for Sam).  In that spirit, when we estimate the effectiveness of a MCMC method or tuning — by autocorrelation time or ESJD or anything else — shouldn’t we be looking at the changes in the model predictions over time, rather than the changes in the parameters over time?  That is, the autocorrelation time should be the autocorrelation time in what the model (at the walker position) predicts for the data, and the ESJD should be the expected squared jump distance in what the model predicts for the data?  This might resolve the concern I expressed a</p><p>6 0.96047556 <a title="1489-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-17-Christian_Robert_on_the_Jeffreys-Lindley_paradox%3B_more_generally%2C_it%E2%80%99s_good_news_when_philosophical_arguments_can_be_transformed_into_technical_modeling_issues.html">2027 andrew gelman stats-2013-09-17-Christian Robert on the Jeffreys-Lindley paradox; more generally, it’s good news when philosophical arguments can be transformed into technical modeling issues</a></p>
<p>7 0.96040976 <a title="1489-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-05-Monitor_the_efficiency_of_your_Markov_chain_sampler_using_expected_squared_jumped_distance%21.html">650 andrew gelman stats-2011-04-05-Monitor the efficiency of your Markov chain sampler using expected squared jumped distance!</a></p>
<p>8 0.95811224 <a title="1489-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-19-%E2%80%9CBehind_a_cancer-treatment_firm%E2%80%99s_rosy_survival_claims%E2%80%9D.html">1906 andrew gelman stats-2013-06-19-“Behind a cancer-treatment firm’s rosy survival claims”</a></p>
<p>9 0.9569959 <a title="1489-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-06-That_silly_ESP_paper_and_some_silliness_in_a_rebuttal_as_well.html">506 andrew gelman stats-2011-01-06-That silly ESP paper and some silliness in a rebuttal as well</a></p>
<p>10 0.95504135 <a title="1489-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-21-Busted%21.html">221 andrew gelman stats-2010-08-21-Busted!</a></p>
<p>11 0.95267868 <a title="1489-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-15-%E2%80%9CI_coach_the_jumpers_here_at_Boise_State_._._.%E2%80%9D.html">1625 andrew gelman stats-2012-12-15-“I coach the jumpers here at Boise State . . .”</a></p>
<p>12 0.95177817 <a title="1489-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-02-Fishing_for_cherries.html">1746 andrew gelman stats-2013-03-02-Fishing for cherries</a></p>
<p>13 0.95160925 <a title="1489-lda-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-07-My_recent_debugging_experience.html">2161 andrew gelman stats-2014-01-07-My recent debugging experience</a></p>
<p>14 0.95151949 <a title="1489-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-17-How_to_think_about_the_statistical_evidence_when_the_statistical_evidence_can%E2%80%99t_be_conclusive%3F.html">2174 andrew gelman stats-2014-01-17-How to think about the statistical evidence when the statistical evidence can’t be conclusive?</a></p>
<p>15 0.95128036 <a title="1489-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-24-Don%E2%80%99t_idealize_%E2%80%9Crisk_aversion%E2%80%9D.html">819 andrew gelman stats-2011-07-24-Don’t idealize “risk aversion”</a></p>
<p>16 0.95120662 <a title="1489-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-03-Kuhn%2C_1-f_noise%2C_and_the_fractal_nature_of_scientific_revolutions.html">1924 andrew gelman stats-2013-07-03-Kuhn, 1-f noise, and the fractal nature of scientific revolutions</a></p>
<p>17 0.95105886 <a title="1489-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-05-How_much_do_we_trust_a_new_claim_that_early_childhood_stimulation_raised_earnings_by_42%25%3F.html">2090 andrew gelman stats-2013-11-05-How much do we trust a new claim that early childhood stimulation raised earnings by 42%?</a></p>
<p>18 0.95102686 <a title="1489-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-19-Scalability_in_education.html">1502 andrew gelman stats-2012-09-19-Scalability in education</a></p>
<p>19 0.95077133 <a title="1489-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>20 0.949965 <a title="1489-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-22-My_talks_that_were_scheduled_for_Tues_at_the_Data_Skeptics_meetup_and_Wed_at_the_Open_Statistical_Programming_meetup.html">1950 andrew gelman stats-2013-07-22-My talks that were scheduled for Tues at the Data Skeptics meetup and Wed at the Open Statistical Programming meetup</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
