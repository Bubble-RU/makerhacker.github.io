<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1182" href="#">andrew_gelman_stats-2012-1182</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1182-html" href="http://andrewgelman.com/2012/02/24/untangling-the-jeffreys-lindley-paradox/">html</a></p><p>Introduction: Ryan Ickert writes:
  
I was wondering if you’d seen  this post , by a particle physicist with some degree of influence.  Dr. Dorigo works at CERN and Fermilab.


The penultimate paragraph is:

 
From the above expression, the Frequentist researcher concludes that the tracker is indeed biased, and rejects the null hypothesis H0, since there is a less-than-2% probability (P’<α) that a result as the one observed could arise by chance! A Frequentist thus draws, strongly, the opposite conclusion than a Bayesian from the same set of data. How to solve the riddle?
 

He goes on to not solve the riddle.  Perhaps you can?


Surely with the large sample size they have (n=10^6), the precision on the frequentist p-value is pretty good, is it not?
  
My reply:
 
The first comment on the site (by Anonymous [who, just to be clear, is not me; I have no idea who wrote that comment], 22 Feb 2012, 21:27pm) pretty much nails it:  In setting up the Bayesian model, Dorigo assumed a silly distribution on th</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Ryan Ickert writes:    I was wondering if you’d seen  this post , by a particle physicist with some degree of influence. [sent-1, score-0.35]
</p><p>2 The penultimate paragraph is:    From the above expression, the Frequentist researcher concludes that the tracker is indeed biased, and rejects the null hypothesis H0, since there is a less-than-2% probability (P’<α) that a result as the one observed could arise by chance! [sent-4, score-0.423]
</p><p>3 Surely with the large sample size they have (n=10^6), the precision on the frequentist p-value is pretty good, is it not? [sent-9, score-0.188]
</p><p>4 My reply:   The first comment on the site (by Anonymous [who, just to be clear, is not me; I have no idea who wrote that comment], 22 Feb 2012, 21:27pm) pretty much nails it:  In setting up the Bayesian model, Dorigo assumed a silly distribution on the underlying parameter. [sent-10, score-0.419]
</p><p>5 All sorts of silly models can work in some settings, but when a model gives nonsensical results—in this case, stating with near-certainty that a parameter equals zero, when the data clearly reject that hypothesis—then, it’s time to go back and figure out what in the model went wrong. [sent-11, score-0.551]
</p><p>6 Our models are approximations that work reasonably well in some settings but not in others. [sent-13, score-0.19]
</p><p>7 Dorigo also writes:    A Bayesian researcher will need a prior probability density function (PDF) to make a statistical inference: a function describing the pre-experiment degree of belief on the value of R. [sent-16, score-0.597]
</p><p>8 First, in general there is nothing more subjective about a prior distribution than about a data model:  both are based on assumptions. [sent-19, score-0.373]
</p><p>9 Second, if you have information, then it’s not “the lesser evil” to include it. [sent-20, score-0.159]
</p><p>10 They said it was ok, but one wrote:    There is a lot of poop being thrown these days between bayesians and frequentists. [sent-28, score-0.176]
</p><p>11 I am not sure why; that fight seems so 2003 to me. [sent-29, score-0.072]
</p><p>12 One thing I like about Bayesian methods is how they force you to put your assumptions out there, potentially to be criticized. [sent-33, score-0.166]
</p><p>13 But I understand that others prefer a mode of inference that makes minimal assumptions. [sent-34, score-0.282]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dorigo', 0.367), ('evil', 0.258), ('bayesian', 0.232), ('frequentist', 0.188), ('subjective', 0.182), ('lesser', 0.159), ('pdf', 0.15), ('physicist', 0.142), ('inference', 0.142), ('agreed', 0.131), ('degree', 0.12), ('prior', 0.114), ('settings', 0.111), ('solve', 0.109), ('equals', 0.105), ('riddle', 0.105), ('poop', 0.105), ('cern', 0.101), ('silly', 0.1), ('function', 0.098), ('assumptions', 0.097), ('researcher', 0.096), ('rejects', 0.094), ('nonsensical', 0.094), ('misconceptions', 0.092), ('nails', 0.092), ('hypothesis', 0.09), ('model', 0.088), ('particle', 0.088), ('feb', 0.088), ('particularly', 0.085), ('questionable', 0.083), ('approximations', 0.079), ('endless', 0.079), ('highlight', 0.078), ('distribution', 0.077), ('ryan', 0.077), ('stating', 0.076), ('comment', 0.075), ('idea', 0.075), ('fight', 0.072), ('indeed', 0.072), ('anonymous', 0.071), ('thrown', 0.071), ('standpoint', 0.071), ('useful', 0.071), ('probability', 0.071), ('minimal', 0.07), ('mode', 0.07), ('force', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="1182-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>Introduction: Ryan Ickert writes:
  
I was wondering if you’d seen  this post , by a particle physicist with some degree of influence.  Dr. Dorigo works at CERN and Fermilab.


The penultimate paragraph is:

 
From the above expression, the Frequentist researcher concludes that the tracker is indeed biased, and rejects the null hypothesis H0, since there is a less-than-2% probability (P’<α) that a result as the one observed could arise by chance! A Frequentist thus draws, strongly, the opposite conclusion than a Bayesian from the same set of data. How to solve the riddle?
 

He goes on to not solve the riddle.  Perhaps you can?


Surely with the large sample size they have (n=10^6), the precision on the frequentist p-value is pretty good, is it not?
  
My reply:
 
The first comment on the site (by Anonymous [who, just to be clear, is not me; I have no idea who wrote that comment], 22 Feb 2012, 21:27pm) pretty much nails it:  In setting up the Bayesian model, Dorigo assumed a silly distribution on th</p><p>2 0.24195756 <a title="1182-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>Introduction: I sent Deborah Mayo a link to  my paper  with Cosma Shalizi on the philosophy of statistics, and she sent me the link to this conference which unfortunately already occurred.  (It’s too bad, because I’d have liked to have been there.)  I summarized my philosophy as follows:
  
I am highly sympathetic to the approach of Lakatos (or of Popper, if you consider Lakatos’s “Popper_2″ to be a reasonable simulation of the true Popperism), in that (a) I view statistical models as being built within theoretical structures, and (b) I see the checking and refutation of models to be a key part of scientific progress.  A big problem I have with mainstream Bayesianism is its “inductivist” view that science can operate completely smoothly with posterior updates:  the idea that new data causes us to increase the posterior probability of good models and decrease the posterior probability of bad models.  I don’t buy that:  I see models as ever-changing entities that are flexible and can be patched and ex</p><p>3 0.23458192 <a title="1182-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-05-What_is_a_prior_distribution%3F.html">1155 andrew gelman stats-2012-02-05-What is a prior distribution?</a></p>
<p>Introduction: Some recent blog discussion revealed some confusion that I’ll try to resolve here.
 
I  wrote  that I’m not a big fan of subjective priors.  Various commenters had difficulty with this point, and I think the issue was most clearly stated by Bill Jeff re erys, who  wrote :
  
It seems to me that your prior has to reflect your subjective information before you look at the data. How can it not?


But this does not mean that the (subjective) prior that you choose is irrefutable; Surely a prior that reflects prior information just does not have to be inconsistent with that information. But that still leaves a range of priors that are consistent with it, the sort of priors that one would use in a sensitivity analysis, for example.
  
I think I see what Bill is getting at.  A prior represents your subjective belief, or some approximation to your subjective belief, even if it’s not perfect.  That sounds reasonable but I don’t think it works.  Or, at least, it often doesn’t work.
 
Let’s start</p><p>4 0.22319467 <a title="1182-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>Introduction: Prasanta Bandyopadhyay and Gordon Brittan  write :
  
We introduce a distinction, unnoticed in the literature, between four varieties of objective Bayesianism. What we call ‘strong objective Bayesianism’ is characterized by two claims, that all scientific inference is ‘logical’ and that, given the same background information two agents will ascribe a unique probability to their priors. We think that neither of these claims can be sustained; in this sense, they are ‘dogmatic’. The first fails to recognize that some scientific inference, in particular that concerning evidential relations, is not (in the appropriate sense) logical, the second fails to provide a non-question-begging account of ‘same background information’. We urge that a suitably objective Bayesian account of scientific inference does not require either of the claims. Finally, we argue that Bayesianism needs to be fine-grained in the same way that Bayesians fine-grain their beliefs.
  
I have not read their paper in detai</p><p>5 0.22013801 <a title="1182-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>Introduction: Robert Bell pointed me to  this post  by Brad De Long on Bayesian statistics, and then I also noticed  this  from Noah Smith, who wrote:
  
My impression is that although the Bayesian/Frequentist debate is interesting and intellectually fun, there’s really not much “there” there… despite being so-hip-right-now, Bayesian is not the Statistical Jesus.
  
I’m happy to see the discussion going in this direction.  Twenty-five years ago or so, when I got into this biz, there were some serious anti-Bayesian attitudes floating around in mainstream statistics.  Discussions in the journals sometimes devolved into debates of the form, “Bayesians:  knaves or fools?”.  You’d get all sorts of free-floating skepticism about any prior distribution at all, even while people were accepting without question (and doing theory on) logistic regressions, proportional hazards models, and all sorts of strong strong models.  (In the subfield of survey sampling, various prominent researchers would refuse to mode</p><p>6 0.21649195 <a title="1182-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>7 0.20833953 <a title="1182-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>8 0.20830277 <a title="1182-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>9 0.19906449 <a title="1182-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<p>10 0.1982232 <a title="1182-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-How_does_Bayes_do_it%3F.html">247 andrew gelman stats-2010-09-01-How does Bayes do it?</a></p>
<p>11 0.18353087 <a title="1182-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>12 0.18309741 <a title="1182-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>13 0.18236019 <a title="1182-tfidf-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-05-Prior_distribution_for_a_predicted_probability.html">2200 andrew gelman stats-2014-02-05-Prior distribution for a predicted probability</a></p>
<p>14 0.17941402 <a title="1182-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>15 0.17776889 <a title="1182-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>16 0.17502521 <a title="1182-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-01-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Cox_and_Mayo.html">1149 andrew gelman stats-2012-02-01-Philosophy of Bayesian statistics:  my reactions to Cox and Mayo</a></p>
<p>17 0.17475086 <a title="1182-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>18 0.17189571 <a title="1182-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<p>19 0.17173426 <a title="1182-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>20 0.17140222 <a title="1182-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.256), (1, 0.241), (2, -0.075), (3, 0.073), (4, -0.156), (5, -0.05), (6, 0.019), (7, 0.09), (8, 0.007), (9, -0.077), (10, -0.033), (11, -0.026), (12, 0.008), (13, 0.004), (14, 0.014), (15, 0.046), (16, 0.035), (17, -0.019), (18, 0.002), (19, 0.018), (20, 0.0), (21, 0.02), (22, -0.027), (23, -0.016), (24, -0.003), (25, -0.025), (26, 0.028), (27, -0.027), (28, -0.013), (29, 0.021), (30, 0.029), (31, -0.026), (32, 0.021), (33, 0.027), (34, -0.029), (35, -0.01), (36, 0.0), (37, -0.021), (38, 0.001), (39, 0.017), (40, -0.017), (41, -0.023), (42, -0.003), (43, -0.021), (44, -0.019), (45, 0.03), (46, 0.029), (47, 0.017), (48, -0.046), (49, -0.012)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97829556 <a title="1182-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>Introduction: Ryan Ickert writes:
  
I was wondering if you’d seen  this post , by a particle physicist with some degree of influence.  Dr. Dorigo works at CERN and Fermilab.


The penultimate paragraph is:

 
From the above expression, the Frequentist researcher concludes that the tracker is indeed biased, and rejects the null hypothesis H0, since there is a less-than-2% probability (P’<α) that a result as the one observed could arise by chance! A Frequentist thus draws, strongly, the opposite conclusion than a Bayesian from the same set of data. How to solve the riddle?
 

He goes on to not solve the riddle.  Perhaps you can?


Surely with the large sample size they have (n=10^6), the precision on the frequentist p-value is pretty good, is it not?
  
My reply:
 
The first comment on the site (by Anonymous [who, just to be clear, is not me; I have no idea who wrote that comment], 22 Feb 2012, 21:27pm) pretty much nails it:  In setting up the Bayesian model, Dorigo assumed a silly distribution on th</p><p>2 0.91624057 <a title="1182-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-17-Christian_Robert_on_the_Jeffreys-Lindley_paradox%3B_more_generally%2C_it%E2%80%99s_good_news_when_philosophical_arguments_can_be_transformed_into_technical_modeling_issues.html">2027 andrew gelman stats-2013-09-17-Christian Robert on the Jeffreys-Lindley paradox; more generally, it’s good news when philosophical arguments can be transformed into technical modeling issues</a></p>
<p>Introduction: X  writes :
  
This paper discusses the dual interpretation of the Jeffreys– Lindley’s paradox associated with Bayesian posterior probabilities and Bayes factors, both as a differentiation between frequentist and Bayesian statistics and as a pointer to the difficulty of using improper priors while testing. We stress the considerable impact of this paradox on the foundations of both classical and Bayesian statistics.
  
I like this paper in that he is transforming what is often seen as a philosophical argument into a technical issue, in this case a question of priors.  Certain conventional priors (the so-called spike and slab) have poor statistical properties in settings such as model comparison (in addition to not making sense as prior distributions of any realistic state of knowledge).  This reminds me of the way that we nowadays think about hierarchical models.  In the old days there was much thoughtful debate about exchangeability and the so-called Stein paradox that partial pooling</p><p>3 0.90641487 <a title="1182-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>Introduction: Prasanta Bandyopadhyay and Gordon Brittan  write :
  
We introduce a distinction, unnoticed in the literature, between four varieties of objective Bayesianism. What we call ‘strong objective Bayesianism’ is characterized by two claims, that all scientific inference is ‘logical’ and that, given the same background information two agents will ascribe a unique probability to their priors. We think that neither of these claims can be sustained; in this sense, they are ‘dogmatic’. The first fails to recognize that some scientific inference, in particular that concerning evidential relations, is not (in the appropriate sense) logical, the second fails to provide a non-question-begging account of ‘same background information’. We urge that a suitably objective Bayesian account of scientific inference does not require either of the claims. Finally, we argue that Bayesianism needs to be fine-grained in the same way that Bayesians fine-grain their beliefs.
  
I have not read their paper in detai</p><p>4 0.88603783 <a title="1182-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>Introduction: I sent Deborah Mayo a link to  my paper  with Cosma Shalizi on the philosophy of statistics, and she sent me the link to this conference which unfortunately already occurred.  (It’s too bad, because I’d have liked to have been there.)  I summarized my philosophy as follows:
  
I am highly sympathetic to the approach of Lakatos (or of Popper, if you consider Lakatos’s “Popper_2″ to be a reasonable simulation of the true Popperism), in that (a) I view statistical models as being built within theoretical structures, and (b) I see the checking and refutation of models to be a key part of scientific progress.  A big problem I have with mainstream Bayesianism is its “inductivist” view that science can operate completely smoothly with posterior updates:  the idea that new data causes us to increase the posterior probability of good models and decrease the posterior probability of bad models.  I don’t buy that:  I see models as ever-changing entities that are flexible and can be patched and ex</p><p>5 0.86454874 <a title="1182-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>Introduction: Deborah Mayo recommended that I consider coming up with a new name for the statistical methods that I used, given that the term “Bayesian” has all sorts of associations that I dislike (as discussed, for example, in section 1 of  this article ).
 
I replied that I agree on Bayesian, I never liked the term and always wanted something better, but I couldn’t think of any convenient alternative.  Also, I was finding that Bayesians (even the Bayesians I disagreed with) were reading my research articles, while non-Bayesians were simply ignoring them.  So I thought it was best to identify with, and communicate with, those people who were willing to engage with me.
 
More formally, I’m happy defining “Bayesian” as “using inference from the posterior distribution, p(theta|y)”.  This says nothing about where the probability distributions come from (thus, no requirement to be “subjective” or “objective”) and it says nothing about the models (thus, no requirement to use the discrete models that hav</p><p>6 0.86158884 <a title="1182-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<p>7 0.85594225 <a title="1182-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>8 0.85455167 <a title="1182-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-Philosophy_of_Bayesian_statistics%3A_my_reactions_to_Hendry.html">1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</a></p>
<p>9 0.85369861 <a title="1182-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-11-Bayesian_brains%3F.html">1529 andrew gelman stats-2012-10-11-Bayesian brains?</a></p>
<p>10 0.84998882 <a title="1182-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>11 0.84683627 <a title="1182-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<p>12 0.8392182 <a title="1182-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-22-Spell-checking_example_demonstrates_key_aspects_of_Bayesian_data_analysis.html">2182 andrew gelman stats-2014-01-22-Spell-checking example demonstrates key aspects of Bayesian data analysis</a></p>
<p>13 0.83638722 <a title="1182-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-20-Problemen_met_het_boek.html">1332 andrew gelman stats-2012-05-20-Problemen met het boek</a></p>
<p>14 0.82944614 <a title="1182-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>15 0.82861686 <a title="1182-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-Rob_Kass_on_statistical_pragmatism%2C_and_my_reactions.html">317 andrew gelman stats-2010-10-04-Rob Kass on statistical pragmatism, and my reactions</a></p>
<p>16 0.82358074 <a title="1182-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>17 0.82312244 <a title="1182-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>18 0.82170266 <a title="1182-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>19 0.82038254 <a title="1182-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-08-The_virtues_of_incoherence%3F.html">792 andrew gelman stats-2011-07-08-The virtues of incoherence?</a></p>
<p>20 0.81701976 <a title="1182-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.011), (16, 0.072), (21, 0.024), (24, 0.227), (27, 0.014), (42, 0.035), (45, 0.012), (66, 0.022), (86, 0.02), (93, 0.138), (99, 0.303)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98414648 <a title="1182-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-27-%E2%80%9CGet_off_my_lawn%E2%80%9D-blogging.html">1432 andrew gelman stats-2012-07-27-“Get off my lawn”-blogging</a></p>
<p>Introduction: Jay Livingston  critiques  the recent pronouncements of sociologist and  cigarette shill  Peter Berger, who recently has moved into cultural criticism of New York’s mayor for living with “a woman to whom he is not married” (this is apparently a European sort of thing, I guess they don’t have unmarried partners in the parts of the U.S. where Berger hangs out).
 
But what impresses me is that Berger is doing  regular blogging   at the age of 84 , writing a long essay each week.  That’s really amazing to me.  Some of the blogging is a bit suspect, for example  the bit  where he claims that he personally could convert gays to heterosexual orientation (“A few stubborn individuals may resist the Berger conversion program. The majority will succumb”)—but, really, you gotta admire that he’s doing this.  I hope I’m that active when (if) I reach my mid-80s.  (As a nonsmoker, I should have a pretty good chance of reaching that point.)
 
P.S.   More rant  at the sister blog.
 
P.P.S.  In comments,</p><p>2 0.96882319 <a title="1182-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-28-50_shades_of_gray%3A__A_research_story.html">1959 andrew gelman stats-2013-07-28-50 shades of gray:  A research story</a></p>
<p>Introduction: This is a killer story  (from Brian Nosek, Jeffrey Spies, and Matt Motyl).
 
Part 1:
  
Two of the present authors, Motyl and Nosek, share interests in political ideology. We were inspired by the fast growing literature on embodiment that demonstrates surprising links between body and mind (Markman & Brendl, 2005; Proffitt, 2006) to investigate embodiment of political extremism. Participants from the political left, right and center (N = 1,979) completed a perceptual judgment task in which words were presented in different shades of gray. Participants had to click along a gradient representing grays from near black to near white to select a shade that matched the shade of the word. We calculated accuracy: How close to the actual shade did participants get? The results were stunning. Moderates perceived the shades of gray more accurately than extremists on the left and right (p = .01). Our conclusion: political extremists perceive the world in black-and-white, figuratively and literally</p><p>3 0.9646886 <a title="1182-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Stand_Your_Ground_laws_and_homicides.html">1397 andrew gelman stats-2012-06-27-Stand Your Ground laws and homicides</a></p>
<p>Introduction: Jeff points me to  a paper  by Chandler McClellan and Erdal Tekin which begins as follows:
  
The controversies surrounding Stand Your Ground laws have recently captured the nation’s attention. Since 2005, eighteen states have passed laws extending the right to self-defense with no duty to retreat to any place a person has a legal right to be, and several additional states are debating the adoption of similar legislation. Despite the implications that these laws may have for public safety, there has been little empirical investigation of their impact on crime and victimization. In this paper, we use monthly data from the U.S. Vital Statistics to examine how Stand Your Ground laws affect homicides. We identify the impact of these laws by exploiting variation in the effective date of these laws across states. Our results indicate that Stand Your Ground laws are associated with a significant increase in the number of homicides among whites, especially white males.	According to our estimat</p><p>4 0.96345019 <a title="1182-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-13-Infographic_on_the_economy.html">1116 andrew gelman stats-2012-01-13-Infographic on the economy</a></p>
<p>Introduction: Gabriel Bergin writes:
  
Just thought I’d share  an infographic  you might enjoy. I [Bergin] quite like what they did with the colored ranges of previous curves in the two middle graphs:
  
   
 
I like it.  Would it be possible to put the two long time series on the same scale?  As it is, one starts in 1948 and the other starts in 1980.  The only thing about the display that I really  don’t  like are those balls on the top indicating the duration of recessions.  It looks weird to me to display a time duration in the form of the area of a ball.</p><p>5 0.9598878 <a title="1182-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-How_Open_Should_Academic_Papers_Be%3F.html">1711 andrew gelman stats-2013-02-07-How Open Should Academic Papers Be?</a></p>
<p>Introduction: Richard Van Noorden reports  in  Nature  that 95% of the authors submitting to the Nature Publishing Group choose more restrictive open-source licenses, CC-BY-NC-SA or CC-BY-NC-ND, even when given the opportunity to use a much more open license, CC-BY.  (I include their data below.)
 
How open should papers be?  Should authors own their work or should universities?  What if they’re paid for by a government research grant?  For instance, should NIH go further in requiring openness than it already has?  
 
Personally, I don’t mind publishers trying to make a buck off my papers.  But I don’t want to write something and then hand them the copyright, because then they’ll try to restrict the distribution.
  Creative Commons Licenses  
Here’s the license cheat sheet, straight from  Creative Commons :
 
 CC-BY :  This license lets others distribute, remix, tweak, and build upon your work, even commercially, as long as they credit you for the original creation. This is the most accommodating of</p><p>6 0.95897311 <a title="1182-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Subsidized_driving.html">1693 andrew gelman stats-2013-01-25-Subsidized driving</a></p>
<p>7 0.95447206 <a title="1182-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-19-%E2%80%9CPoor_Smokers_in_New_York_State_Spend_25%25_of_Income_on_Cigarettes%2C_Study_Finds%E2%80%9D.html">1503 andrew gelman stats-2012-09-19-“Poor Smokers in New York State Spend 25% of Income on Cigarettes, Study Finds”</a></p>
<p>8 0.95360136 <a title="1182-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-25-Dyson%E2%80%99s_baffling_love_of_crackpots.html">1281 andrew gelman stats-2012-04-25-Dyson’s baffling love of crackpots</a></p>
<p>same-blog 9 0.95270061 <a title="1182-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>10 0.94823211 <a title="1182-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-28-Asymmetry_in_Political_Bias.html">683 andrew gelman stats-2011-04-28-Asymmetry in Political Bias</a></p>
<p>11 0.94602972 <a title="1182-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-08-30-30-40_Nation.html">1569 andrew gelman stats-2012-11-08-30-30-40 Nation</a></p>
<p>12 0.93690479 <a title="1182-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-11-There_are_four_ways_to_get_fired_from_Caesars%3A__%281%29_theft%2C_%282%29_sexual_harassment%2C_%283%29_running_an_experiment_without_a_control_group%2C_and_%284%29_keeping_a_gambling_addict_away_from_the_casino.html">1619 andrew gelman stats-2012-12-11-There are four ways to get fired from Caesars:  (1) theft, (2) sexual harassment, (3) running an experiment without a control group, and (4) keeping a gambling addict away from the casino</a></p>
<p>13 0.93566 <a title="1182-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-17-Big_corporations_are_more_popular_than_you_might_realize.html">1123 andrew gelman stats-2012-01-17-Big corporations are more popular than you might realize</a></p>
<p>14 0.93314135 <a title="1182-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>15 0.93260467 <a title="1182-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>16 0.93178982 <a title="1182-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Blogads_update.html">1240 andrew gelman stats-2012-04-02-Blogads update</a></p>
<p>17 0.93178374 <a title="1182-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-05-What_is_a_prior_distribution%3F.html">1155 andrew gelman stats-2012-02-05-What is a prior distribution?</a></p>
<p>18 0.93175089 <a title="1182-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-07-X_on_JLP.html">1792 andrew gelman stats-2013-04-07-X on JLP</a></p>
<p>19 0.93057346 <a title="1182-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-03-Did_you_buy_laundry_detergent_on_their_most_recent_trip_to_the_store%3F__Also_comments_on_scientific_publication_and_yet_another_suggestion_to_do_a_study_that_allows_within-person_comparisons.html">2358 andrew gelman stats-2014-06-03-Did you buy laundry detergent on their most recent trip to the store?  Also comments on scientific publication and yet another suggestion to do a study that allows within-person comparisons</a></p>
<p>20 0.93056381 <a title="1182-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-24-Bell_Labs.html">970 andrew gelman stats-2011-10-24-Bell Labs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
