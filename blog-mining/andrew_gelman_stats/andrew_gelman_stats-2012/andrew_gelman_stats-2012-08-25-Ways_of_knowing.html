<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1469 andrew gelman stats-2012-08-25-Ways of knowing</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1469" href="#">andrew_gelman_stats-2012-1469</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1469 andrew gelman stats-2012-08-25-Ways of knowing</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1469-html" href="http://andrewgelman.com/2012/08/25/progress-bayesian-methods-have-moved-from-plaything-to-practical-tool/">html</a></p><p>Introduction: In  this discussion  from last month, computer science student and Judea Pearl collaborator Elias Barenboim expressed an attitude that hierarchical Bayesian methods might be fine in practice but that they lack theory, that Bayesians can’t succeed in toy problems.  I posted a P.S. there which might not have been noticed so I will put it here:
 
I now realize that there is some disagreement about what constitutes a “guarantee.”  In one of his comments, Barenboim writes, “the assurance we have that the result must hold as long as the assumptions in the model are correct should be regarded as a guarantee.”  In that sense, yes, we have guarantees!  It is fundamental to Bayesian inference that the result must hold if the assumptions in the model are correct.  We have lots of that in Bayesian Data Analysis (particularly in the first four chapters but implicitly elsewhere as well), and this is also covered in the classic books by Lindley, Jaynes, and others.  This sort of guarantee is indeed p</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In  this discussion  from last month, computer science student and Judea Pearl collaborator Elias Barenboim expressed an attitude that hierarchical Bayesian methods might be fine in practice but that they lack theory, that Bayesians can’t succeed in toy problems. [sent-1, score-0.606]
</p><p>2 ”  In one of his comments, Barenboim writes, “the assurance we have that the result must hold as long as the assumptions in the model are correct should be regarded as a guarantee. [sent-5, score-0.244]
</p><p>3 It is fundamental to Bayesian inference that the result must hold if the assumptions in the model are correct. [sent-7, score-0.368]
</p><p>4 This sort of guarantee is indeed pleasant, and there is a long history of Bayesians studying it in theory and in toy problems. [sent-9, score-0.649]
</p><p>5 Arguably, many of the examples in Bayesian Data Analysis (for example, the 8 schools example in chapter 5) can be seen as toy problems. [sent-10, score-0.507]
</p><p>6 As I wrote earlier, I don’t think theoretical proofs or toy problems are useless, I just find applied examples to be more convincing. [sent-11, score-0.673]
</p><p>7 Bayesian methods have moved from plaything to practical tool    Go back in time 50 years or so and read the discussions of Bayesian inference back then. [sent-21, score-0.448]
</p><p>8 At that time, there were some applied successes (for example, I. [sent-22, score-0.205]
</p><p>9 Good repeatedly referred to his successes using Bayesian methods to break codes in the second world war) but most of the arguments in favor of Bayes were theoretical. [sent-24, score-0.33]
</p><p>10 The whole discussion then shifts to whether the model is true, or, better, how the methods perform under the (essentially certain) condition that the model’s assumptions are violated, which leads into the tangle of various theorems about robustness or lack thereof. [sent-26, score-0.546]
</p><p>11 50 years ago one of Bayesianism’s major assets was its theoretical coference, with various theorems demonstrating that, under the right assumptions, Bayesian inference is optimal. [sent-27, score-0.524]
</p><p>12 Bayesians also spent a lot of time writing about toy problems (for example, Basu’s example of the weights of elephants). [sent-28, score-0.543]
</p><p>13 To me, the key turning points occurred around 1970-1980, when statisticians such as Lindley, Novick, Smith, Dempster, and Rubin applied hierarchical Bayesian modeling to solve problems in education research that could not be easily attacked otherwise. [sent-31, score-0.378]
</p><p>14 The key in any case was to use partial pooling to learn about groups for which there was only a small amount of local data. [sent-33, score-0.21]
</p><p>15 ) with the next step folding this approach back into the Bayesian formalism via hierarchical modeling. [sent-37, score-0.321]
</p><p>16 This is a pattern that has happened with just about every successful statistical method I can think of:  an interplay between theory and practice. [sent-41, score-0.251]
</p><p>17 I think that’s right—Markov chain simulation methods indeed allow us to get out of the pick-your-model-from-the-cookbook trap—but I think the hierarchical models of the 1970s (which were fit using various approximations, no MCMC) showed the way. [sent-44, score-0.46]
</p><p>18 To get back to the discussion from last month:   Of course  Bayesian inference has “theoretical guarantees” of the sort that our correspondent Barenboim was looking for. [sent-45, score-0.213]
</p><p>19 Back 50 years ago, this theoretical guarantee was almost  all  that Bayesian statisticians had to offer. [sent-46, score-0.376]
</p><p>20 Bayesian inference seemed like a theoretical toy and was considered by many leading statisticians as  somewhere between a joke and a menace , but the hardcore Bayesians persisted and got some useful methods out of it. [sent-51, score-1.035]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('toy', 0.34), ('bayesian', 0.262), ('theory', 0.19), ('bayesians', 0.189), ('barenboim', 0.168), ('novick', 0.168), ('theoretical', 0.166), ('lindley', 0.158), ('methods', 0.146), ('pooling', 0.145), ('successes', 0.13), ('inference', 0.124), ('assumptions', 0.122), ('hierarchical', 0.12), ('guarantee', 0.119), ('example', 0.111), ('problems', 0.092), ('statisticians', 0.091), ('guarantees', 0.09), ('back', 0.089), ('theorems', 0.086), ('validation', 0.085), ('predictions', 0.081), ('success', 0.079), ('approximations', 0.079), ('demonstrating', 0.078), ('applied', 0.075), ('etc', 0.071), ('models', 0.07), ('various', 0.07), ('external', 0.07), ('model', 0.066), ('partial', 0.065), ('simulations', 0.064), ('assumed', 0.064), ('method', 0.061), ('estimates', 0.058), ('schools', 0.056), ('basu', 0.056), ('hardcore', 0.056), ('menace', 0.056), ('formalism', 0.056), ('folding', 0.056), ('persisted', 0.056), ('tangle', 0.056), ('hold', 0.056), ('fit', 0.054), ('application', 0.054), ('favor', 0.054), ('month', 0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="1469-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>Introduction: In  this discussion  from last month, computer science student and Judea Pearl collaborator Elias Barenboim expressed an attitude that hierarchical Bayesian methods might be fine in practice but that they lack theory, that Bayesians can’t succeed in toy problems.  I posted a P.S. there which might not have been noticed so I will put it here:
 
I now realize that there is some disagreement about what constitutes a “guarantee.”  In one of his comments, Barenboim writes, “the assurance we have that the result must hold as long as the assumptions in the model are correct should be regarded as a guarantee.”  In that sense, yes, we have guarantees!  It is fundamental to Bayesian inference that the result must hold if the assumptions in the model are correct.  We have lots of that in Bayesian Data Analysis (particularly in the first four chapters but implicitly elsewhere as well), and this is also covered in the classic books by Lindley, Jaynes, and others.  This sort of guarantee is indeed p</p><p>2 0.4091779 <a title="1469-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-23-Examples_of_the_use_of_hierarchical_modeling_to_generalize_to_new_settings.html">1425 andrew gelman stats-2012-07-23-Examples of the use of hierarchical modeling to generalize to new settings</a></p>
<p>Introduction: In a link to our  back-and-forth  on causal inference and the use of hierarchical models to bridge between different inferential settings, Elias Bareinboim (a computer scientist who is working with Judea Pearl)  writes :
  
In the past week, I have been engaged in a discussion with Andrew Gelman and his blog readers regarding causal inference, selection bias, confounding, and generalizability. I was trying to understand how his method which he calls “hierarchical modeling” would handle these issues and what guarantees it provides. . . . If anyone understands how “hierarchical modeling” can solve a simple toy problem (e.g., M-bias, control of confounding, mediation, generalizability), please share with us.
  
In his post, Bareinboim raises a direct question about hierarchical modeling and also indirectly brings up larger questions about what is convincing evidence when evaluating a statistical method.  As I wrote earlier, Bareinboim believes that “The only way investigators can decide w</p><p>3 0.27094066 <a title="1469-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>Introduction: Elias Bareinboim asked what I thought about  his comment  on selection bias in which he referred to a  paper  by himself and Judea Pearl, “Controlling Selection Bias in Causal Inference.”
 
I replied that I have no problem with what he wrote, but that from my perspective I find it easier to conceptualize such problems in terms of multilevel models. I elaborated on that point in a  recent post , “Hierarchical modeling as a framework for extrapolation,” which I think was read by only a few people (I say this because it received only two comments).
 
I don’t think Bareinboim objected to anything I wrote, but like me he is comfortable working within his own framework.  He wrote the following to me: 
  
  
In some sense, “not ad hoc” could mean logically consistent. In other words, if one agrees with the assumptions encoded in the model, one must also agree with the conclusions entailed by these assumptions. I am not aware of any other way of doing mathematics. As it turns out, to get causa</p><p>4 0.25743663 <a title="1469-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>Introduction: Robert Bell pointed me to  this post  by Brad De Long on Bayesian statistics, and then I also noticed  this  from Noah Smith, who wrote:
  
My impression is that although the Bayesian/Frequentist debate is interesting and intellectually fun, there’s really not much “there” there… despite being so-hip-right-now, Bayesian is not the Statistical Jesus.
  
I’m happy to see the discussion going in this direction.  Twenty-five years ago or so, when I got into this biz, there were some serious anti-Bayesian attitudes floating around in mainstream statistics.  Discussions in the journals sometimes devolved into debates of the form, “Bayesians:  knaves or fools?”.  You’d get all sorts of free-floating skepticism about any prior distribution at all, even while people were accepting without question (and doing theory on) logistic regressions, proportional hazards models, and all sorts of strong strong models.  (In the subfield of survey sampling, various prominent researchers would refuse to mode</p><p>5 0.23783608 <a title="1469-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>Introduction: Deborah Mayo  collected  some reactions to my recent  article , Induction and Deduction in Bayesian Data Analysis.
 
I’m pleased that that everybody (philosopher Mayo, applied statistician Stephen Senn, and theoretical statistician Larry Wasserman) is so positive about my article and that nobody’s defending the sort of hard-core inductivism that’s featured on the Bayesian inference wikipedia page.  Here’s the Wikipedia definition, which I  disagree  with:
  
Bayesian inference uses aspects of the scientific method, which involves collecting evidence that is meant to be consistent or inconsistent with a given hypothesis. As evidence accumulates, the degree of belief in a hypothesis ought to change. With enough evidence, it should become very high or very low. . . . Bayesian inference uses a numerical estimate of the degree of belief in a hypothesis before evidence has been observed and calculates a numerical estimate of the degree of belief in the hypothesis after evidence has been obse</p><p>6 0.22942378 <a title="1469-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>7 0.22446153 <a title="1469-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>8 0.22087656 <a title="1469-tfidf-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-18-Those_wacky_anti-Bayesians_used_to_be_intimidating%2C_but_now_they%E2%80%99re_just_pathetic.html">2254 andrew gelman stats-2014-03-18-Those wacky anti-Bayesians used to be intimidating, but now they’re just pathetic</a></p>
<p>9 0.21279022 <a title="1469-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>10 0.20076647 <a title="1469-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>11 0.19890803 <a title="1469-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-03-Statistical_methods_that_work_in_some_settings_but_not_others.html">1560 andrew gelman stats-2012-11-03-Statistical methods that work in some settings but not others</a></p>
<p>12 0.19805454 <a title="1469-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-11-Bayesian_brains%3F.html">1529 andrew gelman stats-2012-10-11-Bayesian brains?</a></p>
<p>13 0.1980179 <a title="1469-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>14 0.1912387 <a title="1469-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>15 0.18682069 <a title="1469-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>16 0.1837301 <a title="1469-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-16-How_do_we_choose_our_default_methods%3F.html">1859 andrew gelman stats-2013-05-16-How do we choose our default methods?</a></p>
<p>17 0.18235895 <a title="1469-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>18 0.18033409 <a title="1469-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>19 0.17941402 <a title="1469-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>20 0.17674713 <a title="1469-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.318), (1, 0.224), (2, -0.123), (3, 0.064), (4, -0.149), (5, 0.056), (6, -0.104), (7, 0.074), (8, 0.077), (9, -0.041), (10, -0.013), (11, -0.047), (12, -0.031), (13, 0.018), (14, 0.049), (15, 0.054), (16, 0.039), (17, -0.005), (18, -0.034), (19, 0.026), (20, -0.013), (21, 0.004), (22, -0.012), (23, 0.069), (24, 0.039), (25, 0.016), (26, -0.007), (27, 0.025), (28, -0.009), (29, 0.027), (30, 0.019), (31, 0.003), (32, 0.037), (33, -0.03), (34, -0.011), (35, -0.048), (36, -0.061), (37, -0.02), (38, -0.022), (39, -0.001), (40, -0.045), (41, 0.06), (42, -0.029), (43, -0.022), (44, -0.019), (45, -0.066), (46, 0.002), (47, 0.006), (48, -0.0), (49, 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98604769 <a title="1469-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>Introduction: In  this discussion  from last month, computer science student and Judea Pearl collaborator Elias Barenboim expressed an attitude that hierarchical Bayesian methods might be fine in practice but that they lack theory, that Bayesians can’t succeed in toy problems.  I posted a P.S. there which might not have been noticed so I will put it here:
 
I now realize that there is some disagreement about what constitutes a “guarantee.”  In one of his comments, Barenboim writes, “the assurance we have that the result must hold as long as the assumptions in the model are correct should be regarded as a guarantee.”  In that sense, yes, we have guarantees!  It is fundamental to Bayesian inference that the result must hold if the assumptions in the model are correct.  We have lots of that in Bayesian Data Analysis (particularly in the first four chapters but implicitly elsewhere as well), and this is also covered in the classic books by Lindley, Jaynes, and others.  This sort of guarantee is indeed p</p><p>2 0.8929351 <a title="1469-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>Introduction: I sent Deborah Mayo a link to  my paper  with Cosma Shalizi on the philosophy of statistics, and she sent me the link to this conference which unfortunately already occurred.  (It’s too bad, because I’d have liked to have been there.)  I summarized my philosophy as follows:
  
I am highly sympathetic to the approach of Lakatos (or of Popper, if you consider Lakatos’s “Popper_2″ to be a reasonable simulation of the true Popperism), in that (a) I view statistical models as being built within theoretical structures, and (b) I see the checking and refutation of models to be a key part of scientific progress.  A big problem I have with mainstream Bayesianism is its “inductivist” view that science can operate completely smoothly with posterior updates:  the idea that new data causes us to increase the posterior probability of good models and decrease the posterior probability of bad models.  I don’t buy that:  I see models as ever-changing entities that are flexible and can be patched and ex</p><p>3 0.89181119 <a title="1469-lsi-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-18-Those_wacky_anti-Bayesians_used_to_be_intimidating%2C_but_now_they%E2%80%99re_just_pathetic.html">2254 andrew gelman stats-2014-03-18-Those wacky anti-Bayesians used to be intimidating, but now they’re just pathetic</a></p>
<p>Introduction: From 2006 :
  
Eric Archer forwarded  this document  by Nick Freemantle, “The Reverend Bayes—was he really a prophet?”, in the Journal of the Royal Society of Medicine:

 

Does [Bayes's] contribution merit the enthusiasms of his followers? Or is his legacy overhyped? . . .


First, Bayesians appear to have an absolute right to disapprove of any conventional approach in statistics without offering a workable alternative—for example, a colleague recently stated at a meeting that ‘. . . it is OK to have multiple comparisons because Bayesians’ don’t believe in alpha spending’. . . .


Second, Bayesians appear to build an army of straw men—everything it seems is different and better from a Bayesian perspective, although many of the concepts seem remarkably familiar. For example, a very well known Bayesian statistician recently surprised the audience with his discovery of the P value as a useful Bayesian statistic at a meeting in Birmingham.


Third, Bayesians possess enormous enthusiasm fo</p><p>4 0.88281047 <a title="1469-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>Introduction: Deborah Mayo  collected  some reactions to my recent  article , Induction and Deduction in Bayesian Data Analysis.
 
I’m pleased that that everybody (philosopher Mayo, applied statistician Stephen Senn, and theoretical statistician Larry Wasserman) is so positive about my article and that nobody’s defending the sort of hard-core inductivism that’s featured on the Bayesian inference wikipedia page.  Here’s the Wikipedia definition, which I  disagree  with:
  
Bayesian inference uses aspects of the scientific method, which involves collecting evidence that is meant to be consistent or inconsistent with a given hypothesis. As evidence accumulates, the degree of belief in a hypothesis ought to change. With enough evidence, it should become very high or very low. . . . Bayesian inference uses a numerical estimate of the degree of belief in a hypothesis before evidence has been observed and calculates a numerical estimate of the degree of belief in the hypothesis after evidence has been obse</p><p>5 0.88001066 <a title="1469-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-09-The_anti-Bayesian_moment_and_its_passing.html">1571 andrew gelman stats-2012-11-09-The anti-Bayesian moment and its passing</a></p>
<p>Introduction: Xian and I respond to the four discussants of our paper, “Not only defended but also applied”: The perceived absurdity of Bayesian inference.”  Here’s the abstract of  our rejoinder :
  
Over the years we have often felt frustration, both at smug Bayesians—in particular, those who object to checking of the fit of model to data, either because all Bayesian models are held to be subjective and thus unquestioned (an odd combination indeed, but that is the subject of another article)—and angry anti-Bayesians who, as we wrote in our article, strain on the gnat of the prior distribution while swallowing the camel that is the likelihood. The present article arose from our memory of a particularly intemperate anti-Bayesian statement that appeared in Feller’s beautiful and classic book on probability theory. We felt that it was worth exploring the very extremeness of Feller’s words, along with similar anti-Bayesian remarks by others, in order to better understand the background underlying contr</p><p>6 0.871387 <a title="1469-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-29-Another_Feller_theory.html">1781 andrew gelman stats-2013-03-29-Another Feller theory</a></p>
<p>7 0.85750258 <a title="1469-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>8 0.85208136 <a title="1469-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-13-Arnold_Zellner.html">205 andrew gelman stats-2010-08-13-Arnold Zellner</a></p>
<p>9 0.84772247 <a title="1469-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-Philosophy_of_Bayesian_statistics%3A_my_reactions_to_Hendry.html">1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</a></p>
<p>10 0.84756523 <a title="1469-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-11-Bayesian_brains%3F.html">1529 andrew gelman stats-2012-10-11-Bayesian brains?</a></p>
<p>11 0.84613091 <a title="1469-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>12 0.8449176 <a title="1469-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>13 0.8422913 <a title="1469-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-14-Progress%21__%28on_the_understanding_of_the_role_of_randomization_in_Bayesian_inference%29.html">1898 andrew gelman stats-2013-06-14-Progress!  (on the understanding of the role of randomization in Bayesian inference)</a></p>
<p>14 0.84114093 <a title="1469-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>15 0.83870208 <a title="1469-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>16 0.83783329 <a title="1469-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>17 0.82525557 <a title="1469-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-28-More_on_Bayesian_deduction-induction.html">114 andrew gelman stats-2010-06-28-More on Bayesian deduction-induction</a></p>
<p>18 0.82493669 <a title="1469-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-24-Non-Bayesian_analysis_of_Bayesian_agents%3F.html">1280 andrew gelman stats-2012-04-24-Non-Bayesian analysis of Bayesian agents?</a></p>
<p>19 0.8234334 <a title="1469-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-Bayes_in_astronomy.html">1091 andrew gelman stats-2011-12-29-Bayes in astronomy</a></p>
<p>20 0.82342112 <a title="1469-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-02-A_important_new_survey_of_Bayesian_predictive_methods_for_model_assessment%2C_selection_and_comparison.html">1648 andrew gelman stats-2013-01-02-A important new survey of Bayesian predictive methods for model assessment, selection and comparison</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.021), (15, 0.037), (16, 0.063), (21, 0.038), (24, 0.117), (39, 0.028), (63, 0.017), (77, 0.013), (86, 0.035), (99, 0.429)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99625033 <a title="1469-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>Introduction: In  this discussion  from last month, computer science student and Judea Pearl collaborator Elias Barenboim expressed an attitude that hierarchical Bayesian methods might be fine in practice but that they lack theory, that Bayesians can’t succeed in toy problems.  I posted a P.S. there which might not have been noticed so I will put it here:
 
I now realize that there is some disagreement about what constitutes a “guarantee.”  In one of his comments, Barenboim writes, “the assurance we have that the result must hold as long as the assumptions in the model are correct should be regarded as a guarantee.”  In that sense, yes, we have guarantees!  It is fundamental to Bayesian inference that the result must hold if the assumptions in the model are correct.  We have lots of that in Bayesian Data Analysis (particularly in the first four chapters but implicitly elsewhere as well), and this is also covered in the classic books by Lindley, Jaynes, and others.  This sort of guarantee is indeed p</p><p>2 0.99428856 <a title="1469-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-27-Should_statistics_have_a_Nobel_prize%3F.html">2151 andrew gelman stats-2013-12-27-Should statistics have a Nobel prize?</a></p>
<p>Introduction: Xiao-Li  says  yes:
  
The most compelling reason for having highly visible awards in any field is to enhance its ability to attract future talent. Virtually all the media and public attention our profession received in recent years has been on the utility of statistics in all walks of life. We are extremely happy for and proud of this recognition—it is long overdue. However, the media and public have given much more attention to the Fields Medal than to the COPSS Award, even though the former has hardly been about direct or even indirect impact on everyday life. Why this difference? . . . these awards arouse media and public interest by featuring how ingenious the awardees are and how difficult the problems they solved, much like how conquering Everest bestows admiration not because the admirers care or even know much about Everest itself but because it represents the ultimate physical feat. In this sense, the biggest winner of the Fields Medal is mathematics itself: enticing the brig</p><p>3 0.99304628 <a title="1469-lda-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-02-Am_I_too_negative%3F.html">2279 andrew gelman stats-2014-04-02-Am I too negative?</a></p>
<p>Introduction: For background, you can start by reading my recent article,  Is It Possible to Be an Ethicist Without Being Mean to People?  and then a blog post,  Quality over Quantity , by John Cook, who writes:
  
At one point [Ed] Tufte spoke more generally and more personally about pursuing quality over quantity. He said most papers are not worth reading and that he learned early on to concentrate on the great papers, maybe one in 500, that are worth reading and rereading rather than trying to “keep up with the literature.” He also explained how over time he has concentrated more on showcasing excellent work than on criticizing bad work. You can see this in the progression from his first book to his latest. (Criticizing bad work is important too, but you’ll have to read his early books to find more of that. He won’t spend as much time talking about it in his course.) That reminded me of Jesse Robbins’ line: “Don’t fight stupid. You are better than that. Make more awesome.”
  
This made me stop an</p><p>4 0.99266291 <a title="1469-lda-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-18-Never_back_down%3A__The_culture_of_poverty_and_the_culture_of_journalism.html">2337 andrew gelman stats-2014-05-18-Never back down:  The culture of poverty and the culture of journalism</a></p>
<p>Introduction: Ta-Nehisi Coates recently published  a fascinating column  on the “culture of poverty,” in particular focusing on the idea that behavior that is rational and adaptive in some settings is not so appropriate in others:
  
The set of practices required for a young man to secure his safety on the streets of his troubled neighborhood are not the same as those required to place him on an honor roll . . . The way to guide him through this transition is not to insult his native language. . . .


For black men like us, the feeling of having something to lose, beyond honor and face, is foreign. We grew up in communities—New York, Baltimore, Chicago—where the Code of the Streets was the first code we learned. Respect and reputation are everything there. These values are often denigrated by people who have never been punched in the face. But when you live around violence there is no opting out. A reputation for meeting violence with violence is a shield. That protection increases when you are part</p><p>5 0.9924407 <a title="1469-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-10-Controversy_over_the_Christakis-Fowler_findings_on_the_contagion_of_obesity.html">757 andrew gelman stats-2011-06-10-Controversy over the Christakis-Fowler findings on the contagion of obesity</a></p>
<p>Introduction: Nicholas Christakis and James Fowler are famous for finding that obesity is contagious.  Their claims, which have been received with both respect and skepticism (perhaps we need a new word for this:  “respecticism”?) are based on analysis of data from the Framingham heart study, a large longitudinal public-health study that happened to have some social network data (for the odd reason that each participant was asked to provide the name of a friend who could help the researchers locate them if they were to move away during the study period.
 
The short story is that if your close contact became obese, you were likely to become obese also.  The long story is a debate about the reliability of this finding (that is, can it be explained by measurement error and sampling variability) and its causal implications.
 
This sort of study is in my wheelhouse, as it were, but I have never looked at the Christakis-Fowler work in detail.  Thus, my previous and current comments are more along the line</p><p>6 0.99238718 <a title="1469-lda-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-12-More_on_publishing_in_journals.html">2245 andrew gelman stats-2014-03-12-More on publishing in journals</a></p>
<p>7 0.99238533 <a title="1469-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-29-The_blogroll.html">1832 andrew gelman stats-2013-04-29-The blogroll</a></p>
<p>8 0.99225271 <a title="1469-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-07-Looking_for_a_purpose_in_life%3A__Update_on_that_underworked_and_overpaid_sociologist_whose_%E2%80%9Cmain_task_as_a_university_professor_was_self-cultivation%E2%80%9D.html">750 andrew gelman stats-2011-06-07-Looking for a purpose in life:  Update on that underworked and overpaid sociologist whose “main task as a university professor was self-cultivation”</a></p>
<p>9 0.9921236 <a title="1469-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-03-%E2%80%9CRationality%E2%80%9D_reinforces%2C_does_not_compete_with%2C_other_models_of_behavior.html">692 andrew gelman stats-2011-05-03-“Rationality” reinforces, does not compete with, other models of behavior</a></p>
<p>10 0.99163461 <a title="1469-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>11 0.99162424 <a title="1469-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-07-Selection_bias_in_the_reporting_of_shaky_research.html">2236 andrew gelman stats-2014-03-07-Selection bias in the reporting of shaky research</a></p>
<p>12 0.99160415 <a title="1469-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>13 0.9914782 <a title="1469-lda-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-13-Judea_Pearl_overview_on_causal_inference%2C_and_more_general_thoughts_on_the_reexpression_of_existing_methods_by_considering_their_implicit_assumptions.html">2170 andrew gelman stats-2014-01-13-Judea Pearl overview on causal inference, and more general thoughts on the reexpression of existing methods by considering their implicit assumptions</a></p>
<p>14 0.99136418 <a title="1469-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Pay_for_an_A%3F.html">71 andrew gelman stats-2010-06-07-Pay for an A?</a></p>
<p>15 0.99129218 <a title="1469-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-14-Statistics_for_firefighters%3A__update.html">1722 andrew gelman stats-2013-02-14-Statistics for firefighters:  update</a></p>
<p>16 0.9912802 <a title="1469-lda-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-03-Booze%3A_Been_There._Done_That..html">2158 andrew gelman stats-2014-01-03-Booze: Been There. Done That.</a></p>
<p>17 0.99094677 <a title="1469-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-09-R_on_the_cloud.html">793 andrew gelman stats-2011-07-09-R on the cloud</a></p>
<p>18 0.99090892 <a title="1469-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-29-We_go_to_war_with_the_data_we_have%2C_not_the_data_we_want.html">1289 andrew gelman stats-2012-04-29-We go to war with the data we have, not the data we want</a></p>
<p>19 0.99069166 <a title="1469-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Data_problems%2C_coding_errors%E2%80%A6what_can_be_done%3F.html">1807 andrew gelman stats-2013-04-17-Data problems, coding errors…what can be done?</a></p>
<p>20 0.9906581 <a title="1469-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Evaluating_evidence_from_published_research.html">2006 andrew gelman stats-2013-09-03-Evaluating evidence from published research</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
