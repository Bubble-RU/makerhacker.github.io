<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1445 andrew gelman stats-2012-08-06-Slow progress</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1445" href="#">andrew_gelman_stats-2012-1445</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1445 andrew gelman stats-2012-08-06-Slow progress</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1445-html" href="http://andrewgelman.com/2012/08/06/slow-progress/">html</a></p><p>Introduction: I received the following message:
  
I am a Psychology postgraduate at the University of Glasgow and am writing for an article request. I’ve just read your 2008 published article titled “A weakly informative default prior distribution for logistic and other regression models” and found from it that your group also wrote a report on applying the Bayesian logistic regression approach to multilevel model, which is titled “An approximate EM algorithm for multilevel generalized linear models”. I have been looking for it online but did find it, and was wondering if I may request this report from you?
  
My first thought is that this is a good sign that psychology undergraduates are reading papers like this.  Unfortunately I had to reply as follows:
  
Hi, we actually programmed this up but never debugged it!  So no actual paper . . .
  
I think I could’ve done it if I had ever focused on the problem.  Between the messiness of the algebra and the messiness of the R code, I never got it all to</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I received the following message:    I am a Psychology postgraduate at the University of Glasgow and am writing for an article request. [sent-1, score-0.246]
</p><p>2 I have been looking for it online but did find it, and was wondering if I may request this report from you? [sent-3, score-0.569]
</p><p>3 My first thought is that this is a good sign that psychology undergraduates are reading papers like this. [sent-4, score-0.608]
</p><p>4 Unfortunately I had to reply as follows:    Hi, we actually programmed this up but never debugged it! [sent-5, score-0.579]
</p><p>5 I think I could’ve done it if I had ever focused on the problem. [sent-9, score-0.259]
</p><p>6 Between the messiness of the algebra and the messiness of the R code, I never got it all to work. [sent-10, score-1.173]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('messiness', 0.417), ('titled', 0.302), ('logistic', 0.227), ('debugged', 0.221), ('multilevel', 0.184), ('programmed', 0.174), ('undergraduates', 0.174), ('psychology', 0.171), ('em', 0.163), ('hi', 0.158), ('report', 0.155), ('algebra', 0.154), ('regression', 0.142), ('request', 0.141), ('weakly', 0.138), ('generalized', 0.136), ('approximate', 0.126), ('applying', 0.125), ('never', 0.12), ('algorithm', 0.116), ('sign', 0.116), ('focused', 0.115), ('default', 0.115), ('models', 0.111), ('follows', 0.104), ('wondering', 0.104), ('message', 0.103), ('informative', 0.101), ('online', 0.098), ('unfortunately', 0.098), ('linear', 0.098), ('code', 0.097), ('received', 0.093), ('actual', 0.089), ('article', 0.086), ('group', 0.08), ('university', 0.079), ('ever', 0.077), ('distribution', 0.076), ('papers', 0.075), ('prior', 0.075), ('ve', 0.075), ('reading', 0.072), ('looking', 0.071), ('approach', 0.07), ('done', 0.067), ('writing', 0.067), ('got', 0.065), ('reply', 0.064), ('published', 0.064)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1445-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-06-Slow_progress.html">1445 andrew gelman stats-2012-08-06-Slow progress</a></p>
<p>Introduction: I received the following message:
  
I am a Psychology postgraduate at the University of Glasgow and am writing for an article request. I’ve just read your 2008 published article titled “A weakly informative default prior distribution for logistic and other regression models” and found from it that your group also wrote a report on applying the Bayesian logistic regression approach to multilevel model, which is titled “An approximate EM algorithm for multilevel generalized linear models”. I have been looking for it online but did find it, and was wondering if I may request this report from you?
  
My first thought is that this is a good sign that psychology undergraduates are reading papers like this.  Unfortunately I had to reply as follows:
  
Hi, we actually programmed this up but never debugged it!  So no actual paper . . .
  
I think I could’ve done it if I had ever focused on the problem.  Between the messiness of the algebra and the messiness of the R code, I never got it all to</p><p>2 0.19046828 <a title="1445-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-How_does_Bayes_do_it%3F.html">247 andrew gelman stats-2010-09-01-How does Bayes do it?</a></p>
<p>Introduction: I received the following message from a statistician working in industry:
  
I am studying your paper,  A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models . I am not clear why the Bayesian approaches with some priors can usually handle the issue of nonidentifiability or can get stable estimates of parameters in model fit, while the frequentist approaches cannot.
  
My reply:
 
1.  The term “frequentist approach” is pretty general.  “Frequentist” refers to an approach for evaluating inferences, not a method for creating estimates.  In particular, any Bayes estimate can be viewed as a frequentist inference if you feel like evaluating its frequency properties.  In logistic regression, maximum likelihood has some big problems that are solved with penalized likelihood–equivalently, Bayesian inference.  A frequentist can feel free to consider the prior as a penalty function rather than a probability distribution of parameters.
 
2.  The reason our approa</p><p>3 0.16694349 <a title="1445-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<p>Introduction: Ryan King writes:
  
I was wondering if you have a brief comment on the state of the art for objective priors for hierarchical generalized linear models (generalized linear mixed models).  I have been working off the papers in Bayesian Analysis (2006) 1, Number 3 (Browne and Draper, Kass and Natarajan, Gelman).  There seems to have been continuous work for matching priors in linear mixed models, but GLMMs less so because of the lack of an analytic marginal likelihood for the variance components.  There are a number of additional suggestions in the literature since 2006, but little robust practical guidance.


I’m interested in both mean parameters and the variance components.  I’m almost always concerned with logistic random effect models.  I’m fascinated by the matching-priors idea of higher-order asymptotic improvements to maximum likelihood, and need to make some kind of defensible default recommendation.  Given the massive scale of the datasets (genetics …), extensive sensitivity a</p><p>4 0.16486067 <a title="1445-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-05-Prior_distribution_for_a_predicted_probability.html">2200 andrew gelman stats-2014-02-05-Prior distribution for a predicted probability</a></p>
<p>Introduction: I received the following email:
  
I have an interesting thought on a prior for a logistic regression, and would love your input on how to make it “work.”


Some of my research, two published papers, are on mathematical models of **.  Along those lines, I’m interested in developing more models for **. . . .  Empirical studies show that the public is rather smart and that the wisdom-of-the-crowd is fairly accurate.


So, my thought would be to tread the public’s probability of the event as a prior, and then see how adding data, through a model, would change or perturb our inferred probability of **.  (Similarly, I could envision using previously published epidemiological research as a prior probability of a disease, and then seeing how the addition of new testing protocols would update that belief.)


However, everything I learned about hierarchical Bayesian models has a prior as a distribution on the coefficients.  I don’t know how to start with a prior point estimate for the probabili</p><p>5 0.14040753 <a title="1445-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-13-Checking_your_model_using_fake_data.html">852 andrew gelman stats-2011-08-13-Checking your model using fake data</a></p>
<p>Introduction: Someone sent me the following email:
  
I tried to do a logistic regression . . . I programmed the model in different ways and got different answers . . . can’t get the results to match . . . What am I doing wrong? . . . Here’s my code . . . 
  
I didn’t have the time to look at his code so I gave the following general response:
 
One way to check things is to try simulating data from the fitted model, then fit your model again to the simulated data and see what happens.
 
P.S.  He followed my suggestion and responded a few days later:
  
Yeah, that did the trick!  I was treating a factor variable as a covariate!
  
I love it when generic advice works out!</p><p>6 0.13653612 <a title="1445-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-27-%E2%80%9CKeeping_things_unridiculous%E2%80%9D%3A__Berger%2C_O%E2%80%99Hagan%2C_and_me_on_weakly_informative_priors.html">1087 andrew gelman stats-2011-12-27-“Keeping things unridiculous”:  Berger, O’Hagan, and me on weakly informative priors</a></p>
<p>7 0.13287573 <a title="1445-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-30-Computational_problems_with_glm_etc..html">1516 andrew gelman stats-2012-09-30-Computational problems with glm etc.</a></p>
<p>8 0.12930119 <a title="1445-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-29-The_gradual_transition_to_replicable_science.html">2117 andrew gelman stats-2013-11-29-The gradual transition to replicable science</a></p>
<p>9 0.12748976 <a title="1445-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-11-%E2%80%9CInformative_g-Priors_for_Logistic_Regression%E2%80%9D.html">2017 andrew gelman stats-2013-09-11-“Informative g-Priors for Logistic Regression”</a></p>
<p>10 0.12727976 <a title="1445-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-18-Should_we_always_be_using_the_t_and_robit_instead_of_the_normal_and_logit%3F.html">773 andrew gelman stats-2011-06-18-Should we always be using the t and robit instead of the normal and logit?</a></p>
<p>11 0.12362594 <a title="1445-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<p>12 0.12278938 <a title="1445-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-25-Avoiding_boundary_estimates_using_a_prior_distribution_as_regularization.html">779 andrew gelman stats-2011-06-25-Avoiding boundary estimates using a prior distribution as regularization</a></p>
<p>13 0.11972331 <a title="1445-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-My_talk_Tues_24_Sept_at_12h30_at_Universit%C3%A9_de_Technologie_de_Compi%C3%A8gne.html">2034 andrew gelman stats-2013-09-23-My talk Tues 24 Sept at 12h30 at Université de Technologie de Compiègne</a></p>
<p>14 0.11771498 <a title="1445-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>15 0.11635977 <a title="1445-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Multilevel_quantile_regression.html">397 andrew gelman stats-2010-11-06-Multilevel quantile regression</a></p>
<p>16 0.11567335 <a title="1445-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-07-Prior_distributions_for_regression_coefficients.html">1486 andrew gelman stats-2012-09-07-Prior distributions for regression coefficients</a></p>
<p>17 0.10878292 <a title="1445-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>18 0.107457 <a title="1445-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-29-My_talk_in_Amsterdam_tomorrow_%28Wed_29_Oct%29%3A__Can_we_use_Bayesian_methods_to_resolve_the_current_crisis_of_statistically-significant_research_findings_that_don%E2%80%99t_hold_up%3F.html">2081 andrew gelman stats-2013-10-29-My talk in Amsterdam tomorrow (Wed 29 Oct):  Can we use Bayesian methods to resolve the current crisis of statistically-significant research findings that don’t hold up?</a></p>
<p>19 0.10455792 <a title="1445-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-07-Robust_logistic_regression.html">1886 andrew gelman stats-2013-06-07-Robust logistic regression</a></p>
<p>20 0.10245153 <a title="1445-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-02-2013.html">2157 andrew gelman stats-2014-01-02-2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.178), (1, 0.117), (2, -0.033), (3, 0.01), (4, 0.023), (5, 0.002), (6, 0.064), (7, -0.071), (8, -0.027), (9, 0.087), (10, 0.106), (11, -0.013), (12, 0.044), (13, 0.044), (14, 0.05), (15, 0.014), (16, -0.028), (17, -0.006), (18, 0.018), (19, 0.018), (20, -0.001), (21, 0.022), (22, 0.046), (23, -0.024), (24, -0.029), (25, -0.096), (26, 0.002), (27, -0.061), (28, -0.066), (29, -0.038), (30, -0.027), (31, 0.028), (32, 0.003), (33, 0.037), (34, -0.008), (35, -0.072), (36, -0.003), (37, 0.029), (38, -0.002), (39, -0.04), (40, 0.018), (41, 0.036), (42, 0.039), (43, -0.053), (44, 0.033), (45, 0.072), (46, -0.019), (47, 0.043), (48, -0.008), (49, -0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96944886 <a title="1445-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-06-Slow_progress.html">1445 andrew gelman stats-2012-08-06-Slow progress</a></p>
<p>Introduction: I received the following message:
  
I am a Psychology postgraduate at the University of Glasgow and am writing for an article request. I’ve just read your 2008 published article titled “A weakly informative default prior distribution for logistic and other regression models” and found from it that your group also wrote a report on applying the Bayesian logistic regression approach to multilevel model, which is titled “An approximate EM algorithm for multilevel generalized linear models”. I have been looking for it online but did find it, and was wondering if I may request this report from you?
  
My first thought is that this is a good sign that psychology undergraduates are reading papers like this.  Unfortunately I had to reply as follows:
  
Hi, we actually programmed this up but never debugged it!  So no actual paper . . .
  
I think I could’ve done it if I had ever focused on the problem.  Between the messiness of the algebra and the messiness of the R code, I never got it all to</p><p>2 0.68128067 <a title="1445-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>Introduction: Bill Harris writes:
  
On pp. 250-251 of BDA second edition, you write about multiple comparisons, and you write about stepwise regression on p. 405.  How would you look at stepwise regression analyses in light of the multiple comparisons problem?  Is there an issue?
  
My reply:
 
In this case I think the right approach is to keep all the coefs but partially pool them toward 0 (after suitable transformation).  But then the challenge is coming up with a general way to construct good prior distributions.  Iâ&euro;&trade;m still thinking about that one!  Yet another approach is to put something together purely nonparametrically as with Bart.</p><p>3 0.67953205 <a title="1445-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Multilevel_quantile_regression.html">397 andrew gelman stats-2010-11-06-Multilevel quantile regression</a></p>
<p>Introduction: Ryan Seals writes:
  
I’m an epidemiologist at Emory University, and I’m working on a project of release patterns in jails (basically trying to model how long individuals are in jail before they’re release, for purposes of designing short-term health interventions, i.e. HIV testing, drug counseling, etc…). The question lends itself to quantile regression; we’re interested in the # of days it takes for 50% and 75% of inmates to be released. But being a clustered/nested data structure, it also obviously lends itself to multilevel modeling, with the group-level being individual jails.


So: do you know of any work on multilevel quantile regression? My quick lit search didn’t yield much, and I don’t see any preprogrammed way to do it in SAS.
  
My reply:
 
To start with, I’m putting in the R keyword here, on the hope that some readers might be able to refer you to an R function that does what you want.  Beyond this, I think it should be possible to program something in Bugs.  In ARM we hav</p><p>4 0.67333519 <a title="1445-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-29-The_gradual_transition_to_replicable_science.html">2117 andrew gelman stats-2013-11-29-The gradual transition to replicable science</a></p>
<p>Introduction: Somebody emailed me:
  
I am a researcher at ** University and I have recently read your article on average predictive comparisons for statistical models published 2007 in the journal “Sociological Methodology”.


Gelman, Andrew/Iain Pardoe. 2007. “Average Predictive Comparisons for Models with Nonlinearity, Interactions, and Variance Components”. Sociological Methodology 37: 23-51.


Currently I am working with multilevel models and find your approach very interesting and useful.


May I ask you whether replication materials (e.g. R Code) for this article are available?
  
I had to reply:
  
Hi—I’m embarrassed to say that our R files are a mess!  I had ideas of programming the approach more generally as an R package but this has not yet happened yet.</p><p>5 0.66986269 <a title="1445-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-29-Alternatives_to_regression_for_social_science_predictions.html">10 andrew gelman stats-2010-04-29-Alternatives to regression for social science predictions</a></p>
<p>Introduction: Somebody named David writes:
  
I [David] thought you might be interested or have an opinion on the paper referenced below. I am largely skeptical on the techniques presented and thought you might have some insight because you work with datasets more similar to those in ‘social science’ than myself.


Dana and Dawes. The superiority of simple alternatives to regression for social science predictions. Journal of Educational and Behavioral Statistics (2004) vol. 29 (3) pp. 317.
  
My reply:  I read the abstract (available online) and it seemed reasonable to me.  They prefer simple averages or weights based on correlations rather than regressions.  From a Bayesian perspective, what they’re saying is that least-squares regression and similar methods are noisy, and they can do better via massive simplification.  
 
 I’ve been a big fan of Robyn Dawes ever since reading his article in the classic Kahneman, Slovic, and Tversky volume.  I have no idea how much Dawes knows about modern Bayesian</p><p>6 0.66635704 <a title="1445-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>7 0.66532314 <a title="1445-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-Displaying_inferences_from_complex_models.html">1815 andrew gelman stats-2013-04-20-Displaying inferences from complex models</a></p>
<p>8 0.6636638 <a title="1445-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-07-Prior_distributions_for_regression_coefficients.html">1486 andrew gelman stats-2012-09-07-Prior distributions for regression coefficients</a></p>
<p>9 0.661955 <a title="1445-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Correcting_for_multiple_comparisons_in_a_Bayesian_regression_model.html">1989 andrew gelman stats-2013-08-20-Correcting for multiple comparisons in a Bayesian regression model</a></p>
<p>10 0.66164976 <a title="1445-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-There_are_never_70_distinct_parameters.html">327 andrew gelman stats-2010-10-07-There are never 70 distinct parameters</a></p>
<p>11 0.66160077 <a title="1445-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-22-The_scaled_inverse_Wishart_prior_distribution_for_a_covariance_matrix_in_a_hierarchical_model.html">1466 andrew gelman stats-2012-08-22-The scaled inverse Wishart prior distribution for a covariance matrix in a hierarchical model</a></p>
<p>12 0.65717256 <a title="1445-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>13 0.65627557 <a title="1445-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-Why_we_hate_stepwise_regression.html">2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</a></p>
<p>14 0.6543318 <a title="1445-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-18-Tibshirani_announces_new_research_result%3A__A_significance_test_for_the_lasso.html">1769 andrew gelman stats-2013-03-18-Tibshirani announces new research result:  A significance test for the lasso</a></p>
<p>15 0.65171218 <a title="1445-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-17-Modeling_group-level_predictors_in_a_multilevel_regression.html">1216 andrew gelman stats-2012-03-17-Modeling group-level predictors in a multilevel regression</a></p>
<p>16 0.64905292 <a title="1445-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-22-Handling_multiple_versions_of_an_outcome_variable.html">726 andrew gelman stats-2011-05-22-Handling multiple versions of an outcome variable</a></p>
<p>17 0.64890665 <a title="1445-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-How_does_Bayes_do_it%3F.html">247 andrew gelman stats-2010-09-01-How does Bayes do it?</a></p>
<p>18 0.64518404 <a title="1445-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-10-I_guess_they_noticed_that_if_you_take_the_first_word_on_every_seventeenth_page%2C_it_spells_out_%E2%80%9CDeath_to_the_Shah%E2%80%9D.html">510 andrew gelman stats-2011-01-10-I guess they noticed that if you take the first word on every seventeenth page, it spells out “Death to the Shah”</a></p>
<p>19 0.64509374 <a title="1445-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>20 0.64121765 <a title="1445-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-That_xkcd_cartoon_on_multiple_comparisons_that_all_of_you_were_sending_me_a_couple_months_ago.html">848 andrew gelman stats-2011-08-11-That xkcd cartoon on multiple comparisons that all of you were sending me a couple months ago</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.017), (16, 0.029), (24, 0.228), (40, 0.103), (47, 0.023), (55, 0.024), (56, 0.019), (63, 0.014), (75, 0.022), (86, 0.03), (99, 0.38)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98018736 <a title="1445-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-06-Slow_progress.html">1445 andrew gelman stats-2012-08-06-Slow progress</a></p>
<p>Introduction: I received the following message:
  
I am a Psychology postgraduate at the University of Glasgow and am writing for an article request. I’ve just read your 2008 published article titled “A weakly informative default prior distribution for logistic and other regression models” and found from it that your group also wrote a report on applying the Bayesian logistic regression approach to multilevel model, which is titled “An approximate EM algorithm for multilevel generalized linear models”. I have been looking for it online but did find it, and was wondering if I may request this report from you?
  
My first thought is that this is a good sign that psychology undergraduates are reading papers like this.  Unfortunately I had to reply as follows:
  
Hi, we actually programmed this up but never debugged it!  So no actual paper . . .
  
I think I could’ve done it if I had ever focused on the problem.  Between the messiness of the algebra and the messiness of the R code, I never got it all to</p><p>2 0.9732089 <a title="1445-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-18-Is_it_really_true_that_only_8%25_of_people_who_buy_Herbalife_products_are_Herbalife_distributors%3F.html">1679 andrew gelman stats-2013-01-18-Is it really true that only 8% of people who buy Herbalife products are Herbalife distributors?</a></p>
<p>Introduction: A reporter emailed me the other day with a question about a case I’d never heard of before, a company called Herbalife that is being accused of being a pyramid scheme.  The reporter pointed me to  this document  which describes a survey conducted by “a third party firm called Lieberman Research”:
  
Two independent studies took place using real time (aka “river”) sampling, in which respondents 
were intercepted across a wide array of websites


Sample size of 2,000 adults 18+ matched to U.S. census on age, gender, income, region and ethnicity
  
“River sampling” in this case appears to mean, according to the reporter, that “people were invited into it through online ads.”  The survey found that 5% of U.S. households had purchased Herbalife products during the past three months (with a “0.8% margin of error,” ha ha ha).
 
They they did a multiplication and a division to estimate that only 8% of households who bought these products were Herbalife distributors:  480,000 active distributor</p><p>3 0.97123468 <a title="1445-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-13-Preregistration_of_Studies_and_Mock_Reports.html">1671 andrew gelman stats-2013-01-13-Preregistration of Studies and Mock Reports</a></p>
<p>Introduction: The traditional system of scientific and scholarly publishing is breaking down in two different directions.
 
On one hand, we are moving away from relying on a small set of journals as gatekeepers: the number of papers and research projects is increasing, the number of publication outlets is increasing, and important manuscripts are being posted on SSRN, Arxiv, and other nonrefereed sites.
 
At the same time, many researchers are worried about the profusion of published claims that turn out to not replicate or in plain language, to be false. This concern is not new–some prominent discussions include Rosenthal (1979), Ioannidis (2005), and Vul et al. (2009)–but there is a growing sense that the scientific signal is being swamped by noise.
 
I recently had the opportunity to comment in the journal Political Analysis on two papers, one by Humphreys, Sierra, and Windt, and one by Monogan, on the preregistration of studies and mock reports.   Here’s  the issue of the journal.
 
Given the hi</p><p>4 0.96832359 <a title="1445-lda-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-05-Prior_distribution_for_a_predicted_probability.html">2200 andrew gelman stats-2014-02-05-Prior distribution for a predicted probability</a></p>
<p>Introduction: I received the following email:
  
I have an interesting thought on a prior for a logistic regression, and would love your input on how to make it “work.”


Some of my research, two published papers, are on mathematical models of **.  Along those lines, I’m interested in developing more models for **. . . .  Empirical studies show that the public is rather smart and that the wisdom-of-the-crowd is fairly accurate.


So, my thought would be to tread the public’s probability of the event as a prior, and then see how adding data, through a model, would change or perturb our inferred probability of **.  (Similarly, I could envision using previously published epidemiological research as a prior probability of a disease, and then seeing how the addition of new testing protocols would update that belief.)


However, everything I learned about hierarchical Bayesian models has a prior as a distribution on the coefficients.  I don’t know how to start with a prior point estimate for the probabili</p><p>5 0.96606731 <a title="1445-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-19-BDA3_still_%28I_hope%29_at_40%25_off%21__%28and_a_link_to_one_of_my_favorite_papers%29.html">1988 andrew gelman stats-2013-08-19-BDA3 still (I hope) at 40% off!  (and a link to one of my favorite papers)</a></p>
<p>Introduction: Follow the  Amazon link  and check to see  if it’s still on sale .
 
P.S.  I don’t make any money through this link.  We do get some royalties from the book, but only a very small amount.  I’m pushing the Amazon link right now because (a) I think the book is great, and I want as many people as possible to have it, and (b) 40% off is a pretty good deal and I don’t know how long this will last.
 
P.P.S.  Just so this post has some statistical content,  here’s one of my favorite papers , Bayesian model-building by pure thought: some principles and examples.  It’s from 1996, and here’s the abstract:</p><p>6 0.96587169 <a title="1445-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-10-Cross-validation_and_Bayesian_estimation_of_tuning_parameters.html">2129 andrew gelman stats-2013-12-10-Cross-validation and Bayesian estimation of tuning parameters</a></p>
<p>7 0.96518993 <a title="1445-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-24-Bell_Labs.html">970 andrew gelman stats-2011-10-24-Bell Labs</a></p>
<p>8 0.96482527 <a title="1445-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-05-How_much_do_we_trust_a_new_claim_that_early_childhood_stimulation_raised_earnings_by_42%25%3F.html">2090 andrew gelman stats-2013-11-05-How much do we trust a new claim that early childhood stimulation raised earnings by 42%?</a></p>
<p>9 0.96418917 <a title="1445-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-22-Krugman_sets_the_bar_too_high.html">1733 andrew gelman stats-2013-02-22-Krugman sets the bar too high</a></p>
<p>10 0.96411777 <a title="1445-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-19-The_mysterious_Gamma_%281.4%2C_0.4%29.html">669 andrew gelman stats-2011-04-19-The mysterious Gamma (1.4, 0.4)</a></p>
<p>11 0.96395791 <a title="1445-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>12 0.96354485 <a title="1445-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-16-A_previous_discussion_with_Charles_Murray_about_liberals%2C_conservatives%2C_and_social_class.html">1170 andrew gelman stats-2012-02-16-A previous discussion with Charles Murray about liberals, conservatives, and social class</a></p>
<p>13 0.96317899 <a title="1445-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-14-%E2%80%9CToo_much_data%E2%80%9D%3F.html">86 andrew gelman stats-2010-06-14-“Too much data”?</a></p>
<p>14 0.96285743 <a title="1445-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>15 0.96270525 <a title="1445-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-06-Inbox_zero.__Really..html">259 andrew gelman stats-2010-09-06-Inbox zero.  Really.</a></p>
<p>16 0.9627037 <a title="1445-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>17 0.9624998 <a title="1445-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-02-The_inevitable_problems_with_statistical_significance_and_95%25_intervals.html">1150 andrew gelman stats-2012-02-02-The inevitable problems with statistical significance and 95% intervals</a></p>
<p>18 0.96182233 <a title="1445-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-11-Incumbency_advantage_in_2010.html">408 andrew gelman stats-2010-11-11-Incumbency advantage in 2010</a></p>
<p>19 0.96172708 <a title="1445-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-06-An_old_discussion_of_food_deserts.html">2283 andrew gelman stats-2014-04-06-An old discussion of food deserts</a></p>
<p>20 0.96150231 <a title="1445-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-22-Procrastination_as_a_positive_productivity_strategy.html">1225 andrew gelman stats-2012-03-22-Procrastination as a positive productivity strategy</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
