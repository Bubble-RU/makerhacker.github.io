<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1139" href="#">andrew_gelman_stats-2012-1139</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1139-html" href="http://andrewgelman.com/2012/01/26/suggested-resolution-of-the-bem-paradox/">html</a></p><p>Introduction: There has been an increasing discussion about the proliferation of flawed research in psychology and medicine, with some landmark events being John Ioannides’s  article , “Why most published research findings are false” (according to Google Scholar, cited 973 times since its appearance in 2005), the scandals of Marc Hauser and Diederik Stapel, two leading psychology professors who resigned after disclosures of scientific misconduct, and Daryl Bem’s  dubious  recent paper on ESP, published to much  fanfare  in Journal of Personality and Social Psychology, one of the top journals in the field.
 
Alongside all this are the plagiarism scandals, which are uninteresting from a scientific context but are relevant in that, in many cases, neither the institutions housing the plagiarists nor the editors and publishers of the plagiarized material seem to care.  Perhaps these universities and publishers are more worried about bad publicity (and maybe lawsuits, given that many of the plagiarism cas</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Alongside all this are the plagiarism scandals, which are uninteresting from a scientific context but are relevant in that, in many cases, neither the institutions housing the plagiarists nor the editors and publishers of the plagiarized material seem to care. [sent-2, score-0.482]
</p><p>2 Perhaps these universities and publishers are more worried about bad publicity (and maybe lawsuits, given that many of the plagiarism cases involve law professors) than they are about scholarly misconduct. [sent-3, score-0.487]
</p><p>3 Before going on, perhaps it’s worth briefly reviewing who is hurt by the publication of flawed research. [sent-4, score-0.236]
</p><p>4 - Fake science news bumping real science news off the front page. [sent-7, score-0.27]
</p><p>5 - When the errors and scandals come to light, a decline in the prestige of higher-quality scientific work. [sent-8, score-0.28]
</p><p>6 I’m most interested in presumably sincere and honest scientific efforts that are misunderstood and misrepresented into more than they really are (the breakthrough-of-the-week mentality criticized by Ioannides and exemplfied by Bem). [sent-12, score-0.279]
</p><p>7 As noted above, the cases of outright fraud have little scientific interest but I brought them up to indicate that, even in extreme cases, the groups whose reputations seem at risk from the unethical behavior often seem more inclined to bury the evidence than to stop the madness. [sent-13, score-0.592]
</p><p>8 If universities, publishers, and editors are inclined to look away when confronted with out-and-out fraud and plagiarism, we can hardly be surprised if they’re not aggressive against merely dubious research claims. [sent-14, score-0.546]
</p><p>9 In the last section of this post, I briefly discuss several examples of dubious research that I’ve encountered, just to give a sense of the difficulties that can arise in evaluating such reports. [sent-15, score-0.341]
</p><p>10 Recall that the Bem paper was published, which means in some sense that its reviewers thought the paper’s flaws were no worse than what usually gets published in JPSP. [sent-26, score-0.245]
</p><p>11 Long-term, sure, we’d like to improve methodological rigor, but in the meantime a key problem with Bem’s paper was not  just  its methodological flaws, it was also the implausibility of the claimed results. [sent-27, score-0.418]
</p><p>12 Instead of publishing speculative results in top journals such as JPSP, Science, Nature, etc. [sent-29, score-0.235]
</p><p>13 For example, Bem could publish his experiments in some specialized journal of psychological measurement. [sent-31, score-0.435]
</p><p>14 (I assume there’s also a journal of parapsychology but that’s probably just for true believers; it’s fair enough that Bem etc would like to publish somewhere that outsiders would respect. [sent-34, score-0.237]
</p><p>15 )   Under this system, JPSP could feel free to reject the Bem paper on the grounds that it’s too speculative to get the journal’s implicit endorsement. [sent-35, score-0.306]
</p><p>16 This is not suppression or censorship or anything like it, it’s just a recommendation that the paper be sent to a more specialized journal where there will be a chance for criticism and replication. [sent-36, score-0.358]
</p><p>17 At some point, if the findings are tested and replicated and seem to hold up, then it could be time for a publication in JPSP, Science, or Nature. [sent-37, score-0.288]
</p><p>18 I’ve encountered a lot of these borderline research findings over the past several years, and my own reaction is typically formed by some mix of my personal scientific knowledge, the statistical work involved, and my general impressions. [sent-44, score-0.409]
</p><p>19 I’m as well prepared as anyone to evaluate research claims, but as a consumer I can be pretty credulous when the research is not close to my expertise. [sent-62, score-0.292]
</p><p>20 If there is any coherent message from the above examples, it is that my own rules for how to evaluate research claims are not clear, even to me. [sent-63, score-0.235]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bem', 0.343), ('jpsp', 0.215), ('dubious', 0.161), ('inclined', 0.145), ('scientific', 0.144), ('specialized', 0.136), ('scandals', 0.136), ('methodological', 0.123), ('journal', 0.121), ('research', 0.117), ('publish', 0.116), ('publicity', 0.115), ('publishers', 0.114), ('ioannides', 0.108), ('flawed', 0.102), ('paper', 0.101), ('cases', 0.099), ('journals', 0.098), ('plagiarism', 0.095), ('skeptical', 0.089), ('findings', 0.085), ('psychology', 0.083), ('science', 0.078), ('published', 0.078), ('speculative', 0.077), ('publication', 0.071), ('problem', 0.071), ('seem', 0.07), ('criticized', 0.069), ('reject', 0.066), ('honest', 0.066), ('flaws', 0.066), ('fraud', 0.064), ('universities', 0.064), ('encountered', 0.063), ('briefly', 0.063), ('could', 0.062), ('professors', 0.062), ('skepticism', 0.062), ('potentially', 0.061), ('medicine', 0.061), ('top', 0.06), ('articles', 0.06), ('review', 0.06), ('claims', 0.06), ('individual', 0.059), ('editors', 0.059), ('evaluate', 0.058), ('personally', 0.057), ('news', 0.057)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="1139-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>Introduction: There has been an increasing discussion about the proliferation of flawed research in psychology and medicine, with some landmark events being John Ioannides’s  article , “Why most published research findings are false” (according to Google Scholar, cited 973 times since its appearance in 2005), the scandals of Marc Hauser and Diederik Stapel, two leading psychology professors who resigned after disclosures of scientific misconduct, and Daryl Bem’s  dubious  recent paper on ESP, published to much  fanfare  in Journal of Personality and Social Psychology, one of the top journals in the field.
 
Alongside all this are the plagiarism scandals, which are uninteresting from a scientific context but are relevant in that, in many cases, neither the institutions housing the plagiarists nor the editors and publishers of the plagiarized material seem to care.  Perhaps these universities and publishers are more worried about bad publicity (and maybe lawsuits, given that many of the plagiarism cas</p><p>2 0.33308756 <a title="1139-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<p>Introduction: The other day I was talking with someone who knows Daryl Bem a bit, and he was sharing his thoughts on that  notorious  ESP paper that was published in a leading journal in the field but then was mocked, shot down, and was repeatedly replicated with no success.  My friend said that overall the Bem paper had positive effects in forcing psychologists to think more carefully about what sorts of research results should or should not be published in top journals, the role of replications, and other things.
 
I expressed agreement and shared my thought that, at some level, I don’t think Bem himself fully believes his ESP effects are real.  Why do I say this?  Because he seemed oddly content to publish results that were not quite conclusive.  He ran a bunch of experiments, looked at the data, and computed some post-hoc p-values in the .01 to .05 range.  If he really were confident that the phenomenon was real (that is, that the results would apply to new data), then he could’ve easily run the</p><p>3 0.31386223 <a title="1139-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-13-How_should_journals_handle_replication_studies%3F.html">762 andrew gelman stats-2011-06-13-How should journals handle replication studies?</a></p>
<p>Introduction: Sanjay Srivastava  reports :
  
Recently  Ben Goldacre wrote  about a group of researchers (Stuart Ritchie, Chris French, and Richard Wiseman) whose null replication of 3 experiments from the infamous Bem ESP paper was rejected by JPSP – the same journal that published Bem’s paper.
  
Srivastava recognizes that JPSP does not usually publish replications but this is a different story because it’s an anti-replication.
 
Here’s the paradox:
 
- From a scientific point of view, the Ritchie et al. results are boring.  To find out that there’s no evidence for ESP . . . that adds essentially zero to our scientific understanding.  What next, a paper demonstrating that pigeons can fly higher than chickens?  Maybe an article in the Journal of the Materials Research Society demonstrating that diamonds can scratch marble but not the reverse??
 
- But from a science-communication perspective, the null replication is a big deal because it adds credence to  my hypothesis  that the earlier ESP claims</p><p>4 0.27593288 <a title="1139-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>Introduction: The other day we  discussed  that paper on ovulation and voting (you may recall that the authors reported a scattered bunch of comparisons, significance tests, and p-values, and I recommended that they would’ve done better to simply report complete summaries of their data, so that readers could see the comparisons of interest in full context), and I was thinking a bit more about why I was so bothered that it was published in Psychological Science, which I’d thought of as a serious research journal. 
   
My concern isn’t just that that the paper is bad—after all, lots of bad papers get published—but rather that it had nothing really going for it,  except  that it was headline bait.  It was a survey done on Mechanical Turk, that’s it.  No clever design, no clever questions, no care in dealing with nonresponse problems, no innovative data analysis, no nothing.  The paper had nothing to offer, except that it had no obvious flaws.  Psychology is a huge field full of brilliant researchers.</p><p>5 0.25003755 <a title="1139-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>Introduction: This seems to be the topic of the week.  Yesterday I posted on the sister blog  some further thoughts  on those “Psychological Science” papers on menstrual cycles, biceps size, and political attitudes, tied to a horrible press release from the journal Psychological Science hyping the biceps and politics study.
 
Then I was pointed to these  suggestions  from Richard Lucas and M. Brent Donnellan have on improving the replicability and reproducibility of research published in the Journal of Research in Personality:
  
It goes without saying that editors of scientific journals strive to publish research that is not only theoretically interesting but also methodologically rigorous. The goal is to select papers that advance the field. Accordingly, editors want to publish findings that can be reproduced and replicated by other scientists. Unfortunately, there has been a recent “crisis in confidence” among psychologists about the quality of psychological research (Pashler & Wagenmakers, 2012)</p><p>6 0.24089664 <a title="1139-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>7 0.2312264 <a title="1139-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-12-More_on_publishing_in_journals.html">2245 andrew gelman stats-2014-03-12-More on publishing in journals</a></p>
<p>8 0.20397706 <a title="1139-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-With_a_bit_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_again_on_this_topic%2C_and_with_a_lot_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_today.html">576 andrew gelman stats-2011-02-15-With a bit of precognition, you’d have known I was going to post again on this topic, and with a lot of precognition, you’d have known I was going to post today</a></p>
<p>9 0.20327136 <a title="1139-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>10 0.19859788 <a title="1139-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-06-How_to_think_about_papers_published_in_low-grade_journals%3F.html">1928 andrew gelman stats-2013-07-06-How to think about papers published in low-grade journals?</a></p>
<p>11 0.18103032 <a title="1139-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-06-Against_optimism_about_social_science.html">1844 andrew gelman stats-2013-05-06-Against optimism about social science</a></p>
<p>12 0.17954127 <a title="1139-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-17-How_can_statisticians_help_psychologists_do_their_research_better%3F.html">1860 andrew gelman stats-2013-05-17-How can statisticians help psychologists do their research better?</a></p>
<p>13 0.17550536 <a title="1139-tfidf-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-06-How_much_time_%28if_any%29_should_we_spend_criticizing_research_that%E2%80%99s_fraudulent%2C_crappy%2C_or_just_plain_pointless%3F.html">2235 andrew gelman stats-2014-03-06-How much time (if any) should we spend criticizing research that’s fraudulent, crappy, or just plain pointless?</a></p>
<p>14 0.17495009 <a title="1139-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>15 0.17031756 <a title="1139-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Evaluating_evidence_from_published_research.html">2006 andrew gelman stats-2013-09-03-Evaluating evidence from published research</a></p>
<p>16 0.15954246 <a title="1139-tfidf-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-27-Beyond_the_Valley_of_the_Trolls.html">2269 andrew gelman stats-2014-03-27-Beyond the Valley of the Trolls</a></p>
<p>17 0.15897164 <a title="1139-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>18 0.15683956 <a title="1139-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-24-Difficulties_in_publishing_non-replications_of_implausible_findings.html">1137 andrew gelman stats-2012-01-24-Difficulties in publishing non-replications of implausible findings</a></p>
<p>19 0.15582083 <a title="1139-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-More_proposals_to_reform_the_peer-review_system.html">1272 andrew gelman stats-2012-04-20-More proposals to reform the peer-review system</a></p>
<p>20 0.15500799 <a title="1139-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-Some_thoughts_on_academic_cheating%2C_inspired_by_Frey%2C_Wegman%2C_Fischer%2C_Hauser%2C_Stapel.html">901 andrew gelman stats-2011-09-12-Some thoughts on academic cheating, inspired by Frey, Wegman, Fischer, Hauser, Stapel</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.303), (1, -0.102), (2, -0.11), (3, -0.228), (4, -0.129), (5, -0.095), (6, 0.002), (7, -0.12), (8, -0.059), (9, 0.019), (10, 0.089), (11, 0.019), (12, -0.076), (13, -0.007), (14, -0.004), (15, -0.058), (16, 0.003), (17, 0.018), (18, 0.006), (19, -0.024), (20, -0.011), (21, 0.015), (22, -0.01), (23, -0.006), (24, -0.058), (25, -0.041), (26, -0.035), (27, -0.006), (28, -0.037), (29, -0.02), (30, -0.008), (31, 0.011), (32, 0.009), (33, 0.001), (34, -0.009), (35, -0.003), (36, -0.012), (37, 0.003), (38, -0.046), (39, 0.014), (40, -0.019), (41, 0.064), (42, -0.003), (43, 0.003), (44, 0.006), (45, 0.026), (46, 0.006), (47, 0.061), (48, -0.007), (49, 0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98158491 <a title="1139-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>Introduction: There has been an increasing discussion about the proliferation of flawed research in psychology and medicine, with some landmark events being John Ioannides’s  article , “Why most published research findings are false” (according to Google Scholar, cited 973 times since its appearance in 2005), the scandals of Marc Hauser and Diederik Stapel, two leading psychology professors who resigned after disclosures of scientific misconduct, and Daryl Bem’s  dubious  recent paper on ESP, published to much  fanfare  in Journal of Personality and Social Psychology, one of the top journals in the field.
 
Alongside all this are the plagiarism scandals, which are uninteresting from a scientific context but are relevant in that, in many cases, neither the institutions housing the plagiarists nor the editors and publishers of the plagiarized material seem to care.  Perhaps these universities and publishers are more worried about bad publicity (and maybe lawsuits, given that many of the plagiarism cas</p><p>2 0.92975974 <a title="1139-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>Introduction: Jeff Leek  points to  a post by Alex Holcombe, who disputes the idea that science is self-correcting.  Holcombe  writes  [scroll down to get to his part]:
  
The pace of scientific production has quickened, and self-correction has suffered. Findings that might correct old results are considered less interesting than results from more original research questions. Potential corrections are also more contested. As the competition for space in prestigious journals has become increasingly frenzied, doing and publishing studies that would confirm the rapidly accumulating new discoveries, or would correct them, became a losing proposition.
  
Holcombe picks up on some points that we’ve discussed a lot here in the past year.  Here’s Holcombe:
  
In certain subfields, almost all new work appears in only a very few journals, all associated with a single professional society. There is then no way around the senior gatekeepers, who may then suppress corrections with impunity. . . .


The bias agai</p><p>3 0.92878497 <a title="1139-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-13-How_should_journals_handle_replication_studies%3F.html">762 andrew gelman stats-2011-06-13-How should journals handle replication studies?</a></p>
<p>Introduction: Sanjay Srivastava  reports :
  
Recently  Ben Goldacre wrote  about a group of researchers (Stuart Ritchie, Chris French, and Richard Wiseman) whose null replication of 3 experiments from the infamous Bem ESP paper was rejected by JPSP – the same journal that published Bem’s paper.
  
Srivastava recognizes that JPSP does not usually publish replications but this is a different story because it’s an anti-replication.
 
Here’s the paradox:
 
- From a scientific point of view, the Ritchie et al. results are boring.  To find out that there’s no evidence for ESP . . . that adds essentially zero to our scientific understanding.  What next, a paper demonstrating that pigeons can fly higher than chickens?  Maybe an article in the Journal of the Materials Research Society demonstrating that diamonds can scratch marble but not the reverse??
 
- But from a science-communication perspective, the null replication is a big deal because it adds credence to  my hypothesis  that the earlier ESP claims</p><p>4 0.92394656 <a title="1139-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>Introduction: This seems to be the topic of the week.  Yesterday I posted on the sister blog  some further thoughts  on those “Psychological Science” papers on menstrual cycles, biceps size, and political attitudes, tied to a horrible press release from the journal Psychological Science hyping the biceps and politics study.
 
Then I was pointed to these  suggestions  from Richard Lucas and M. Brent Donnellan have on improving the replicability and reproducibility of research published in the Journal of Research in Personality:
  
It goes without saying that editors of scientific journals strive to publish research that is not only theoretically interesting but also methodologically rigorous. The goal is to select papers that advance the field. Accordingly, editors want to publish findings that can be reproduced and replicated by other scientists. Unfortunately, there has been a recent “crisis in confidence” among psychologists about the quality of psychological research (Pashler & Wagenmakers, 2012)</p><p>5 0.91399467 <a title="1139-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<p>Introduction: The other day I was talking with someone who knows Daryl Bem a bit, and he was sharing his thoughts on that  notorious  ESP paper that was published in a leading journal in the field but then was mocked, shot down, and was repeatedly replicated with no success.  My friend said that overall the Bem paper had positive effects in forcing psychologists to think more carefully about what sorts of research results should or should not be published in top journals, the role of replications, and other things.
 
I expressed agreement and shared my thought that, at some level, I don’t think Bem himself fully believes his ESP effects are real.  Why do I say this?  Because he seemed oddly content to publish results that were not quite conclusive.  He ran a bunch of experiments, looked at the data, and computed some post-hoc p-values in the .01 to .05 range.  If he really were confident that the phenomenon was real (that is, that the results would apply to new data), then he could’ve easily run the</p><p>6 0.91191727 <a title="1139-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>7 0.90119809 <a title="1139-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-24-Too_Good_To_Be_True%3A__The_Scientific_Mass_Production_of_Spurious_Statistical_Significance.html">1954 andrew gelman stats-2013-07-24-Too Good To Be True:  The Scientific Mass Production of Spurious Statistical Significance</a></p>
<p>8 0.90111578 <a title="1139-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>9 0.89263314 <a title="1139-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>10 0.87404722 <a title="1139-lsi-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-20-The_AAA_Tranche_of_Subprime_Science.html">2179 andrew gelman stats-2014-01-20-The AAA Tranche of Subprime Science</a></p>
<p>11 0.87019062 <a title="1139-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>12 0.86026841 <a title="1139-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-06-Against_optimism_about_social_science.html">1844 andrew gelman stats-2013-05-06-Against optimism about social science</a></p>
<p>13 0.85827911 <a title="1139-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-24-Difficulties_in_publishing_non-replications_of_implausible_findings.html">1137 andrew gelman stats-2012-01-24-Difficulties in publishing non-replications of implausible findings</a></p>
<p>14 0.85446531 <a title="1139-lsi-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-17-The_Washington_Post_reprints_university_press_releases_without_editing_them.html">2215 andrew gelman stats-2014-02-17-The Washington Post reprints university press releases without editing them</a></p>
<p>15 0.85250354 <a title="1139-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-05-Against_double-blind_reviewing%3A__Political_science_and_statistics_are_not_like_biology_and_physics.html">601 andrew gelman stats-2011-03-05-Against double-blind reviewing:  Political science and statistics are not like biology and physics</a></p>
<p>16 0.84856415 <a title="1139-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-01-I_owe_it_all_to_the_haters.html">834 andrew gelman stats-2011-08-01-I owe it all to the haters</a></p>
<p>17 0.84772456 <a title="1139-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-06-How_to_think_about_papers_published_in_low-grade_journals%3F.html">1928 andrew gelman stats-2013-07-06-How to think about papers published in low-grade journals?</a></p>
<p>18 0.84380209 <a title="1139-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-15-A_statistical_research_project%3A__Weeding_out_the_fraudulent_citations.html">1321 andrew gelman stats-2012-05-15-A statistical research project:  Weeding out the fraudulent citations</a></p>
<p>19 0.84060806 <a title="1139-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-16-%E2%80%9CGroundbreaking_or_Definitive%3F_Journals_Need_to_Pick_One%E2%80%9D.html">1122 andrew gelman stats-2012-01-16-“Groundbreaking or Definitive? Journals Need to Pick One”</a></p>
<p>20 0.83645809 <a title="1139-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.012), (15, 0.097), (16, 0.067), (21, 0.031), (24, 0.118), (27, 0.023), (53, 0.015), (55, 0.012), (57, 0.018), (62, 0.092), (72, 0.01), (76, 0.013), (77, 0.011), (86, 0.026), (98, 0.014), (99, 0.286)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96736979 <a title="1139-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-16-%E2%80%9CIt_doesn%E2%80%99t_matter_if_you_believe_in_God.__What_matters_is_if_God_believes_in_you.%E2%80%9D.html">715 andrew gelman stats-2011-05-16-“It doesn’t matter if you believe in God.  What matters is if God believes in you.”</a></p>
<p>Introduction: Mark Chaves sent me  this great article  on religion and religious practice:
  
After reading a book or article in the scientific study of religion, I [Chaves] wonder if you ever find yourself thinking, “I just don’t believe it.” I have this experience uncomfortably often, and I think it’s because of a pervasive problem in the scientific study of religion. I want to describe that problem and how to overcome it.


The problem is illustrated in a story told by Meyer Fortes. He once asked a rainmaker in 
a native culture he was studying to perform the rainmaking ceremony for him. The rainmaker refused, replying: “Don’t be a fool, whoever makes a rain-making ceremony in the dry season?”


The problem is illustrated in a different way in a story told by Jay Demerath. He was in Israel, visiting friends for a Sabbath dinner. The man of the house, a conservative rabbi, stopped in the middle of chanting the prayers to say cheerfully: “You know, we don’t believe in any of this. But then in Judai</p><p>same-blog 2 0.96629763 <a title="1139-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>Introduction: There has been an increasing discussion about the proliferation of flawed research in psychology and medicine, with some landmark events being John Ioannides’s  article , “Why most published research findings are false” (according to Google Scholar, cited 973 times since its appearance in 2005), the scandals of Marc Hauser and Diederik Stapel, two leading psychology professors who resigned after disclosures of scientific misconduct, and Daryl Bem’s  dubious  recent paper on ESP, published to much  fanfare  in Journal of Personality and Social Psychology, one of the top journals in the field.
 
Alongside all this are the plagiarism scandals, which are uninteresting from a scientific context but are relevant in that, in many cases, neither the institutions housing the plagiarists nor the editors and publishers of the plagiarized material seem to care.  Perhaps these universities and publishers are more worried about bad publicity (and maybe lawsuits, given that many of the plagiarism cas</p><p>3 0.95093906 <a title="1139-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>Introduction: Prasanta Bandyopadhyay and Gordon Brittan  write :
  
We introduce a distinction, unnoticed in the literature, between four varieties of objective Bayesianism. What we call ‘strong objective Bayesianism’ is characterized by two claims, that all scientific inference is ‘logical’ and that, given the same background information two agents will ascribe a unique probability to their priors. We think that neither of these claims can be sustained; in this sense, they are ‘dogmatic’. The first fails to recognize that some scientific inference, in particular that concerning evidential relations, is not (in the appropriate sense) logical, the second fails to provide a non-question-begging account of ‘same background information’. We urge that a suitably objective Bayesian account of scientific inference does not require either of the claims. Finally, we argue that Bayesianism needs to be fine-grained in the same way that Bayesians fine-grain their beliefs.
  
I have not read their paper in detai</p><p>4 0.94768244 <a title="1139-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-The_importance_of_style_in_academic_writing.html">902 andrew gelman stats-2011-09-12-The importance of style in academic writing</a></p>
<p>Introduction: In my comments on  academic cheating , I briefly discussed the question of how some of these papers could’ve been published in the first place, given that they tend to be of low quality.  (It’s rare that people plagiarize the good stuff, and, when they do—for example when a senior scholar takes credit for a junior researcher’s contributions without giving proper credit—there’s not always a paper trail, and there can be legitimate differences of opinion about the relative contributions of the participants.)
 
Anyway, to get back to the cases at hand:  how did these rulebreakers get published in the first place?  The question here is not how did they get away with cheating but how is it that top journals were publishing mediocre research? 
   
In the case of the profs who falsified data (Diederik Stapel) or did not follow scientific protocol (Mark Hauser), the answer is clear:  By cheating, they were able to get the sort of too-good-to-be-true results which, if they  were  true, would be</p><p>5 0.9471491 <a title="1139-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-14-Battle_of_the_Americans%3A__Writer_at_the_American_Enterprise_Institute_disparages_the_American_Political_Science_Association.html">274 andrew gelman stats-2010-09-14-Battle of the Americans:  Writer at the American Enterprise Institute disparages the American Political Science Association</a></p>
<p>Introduction: Steven Hayward at the American Enterprise Institute wrote  an article , sure to attract the attention of people such as myself, entitled, “The irrelevance of modern political science,” in which he discusses some silly-sounding papers presented at the recent American Political Science Association and then moves to a larger critique of quantitative political science:
  
 
I [Hayward] have often taken a random article from the American Political Science Review, which resembles a mathematical journal on most of its pages, and asked students if they can envision this method providing the mathematical formula that will deliver peace in the Middle East. Even the dullest students usually grasp the point without difficulty.
 

 
At the sister blog, John Sides  discusses and dismisses  Hayward’s arguments, point on that, among other things, political science might very well be useful  even if  it doesn’t deliver peace in the Middle East.  After all, the U.S. Army didn’t deliver peace in the Midd</p><p>6 0.94640398 <a title="1139-lda-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>7 0.94619006 <a title="1139-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>8 0.94610488 <a title="1139-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>9 0.9453789 <a title="1139-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-09-A_tale_of_two_discussion_papers.html">1848 andrew gelman stats-2013-05-09-A tale of two discussion papers</a></p>
<p>10 0.94512379 <a title="1139-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-12-Steven_Pinker%E2%80%99s_unconvincing_debunking_of_group_selection.html">1414 andrew gelman stats-2012-07-12-Steven Pinker’s unconvincing debunking of group selection</a></p>
<p>11 0.94398022 <a title="1139-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-29-%E2%80%9CQuestioning_The_Lancet%2C_PLOS%2C_And_Other_Surveys_On_Iraqi_Deaths%2C_An_Interview_With_Univ._of_London_Professor_Michael_Spagat%E2%80%9D.html">2191 andrew gelman stats-2014-01-29-“Questioning The Lancet, PLOS, And Other Surveys On Iraqi Deaths, An Interview With Univ. of London Professor Michael Spagat”</a></p>
<p>12 0.94314855 <a title="1139-lda-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-%E2%80%9CThe_British_amateur_who_debunked_the_mathematics_of_happiness%E2%80%9D.html">2177 andrew gelman stats-2014-01-19-“The British amateur who debunked the mathematics of happiness”</a></p>
<p>13 0.94067222 <a title="1139-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>14 0.94066674 <a title="1139-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>15 0.94062984 <a title="1139-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>16 0.9402445 <a title="1139-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<p>17 0.94001198 <a title="1139-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-The_most-cited_statistics_papers_ever.html">2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</a></p>
<p>18 0.940005 <a title="1139-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-%E2%80%9CConfirmation%2C_on_the_other_hand%2C_is_not_sexy%E2%80%9D.html">1683 andrew gelman stats-2013-01-19-“Confirmation, on the other hand, is not sexy”</a></p>
<p>19 0.93993956 <a title="1139-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Cross-validation_%28What_is_it_good_for%3F%29.html">1395 andrew gelman stats-2012-06-27-Cross-validation (What is it good for?)</a></p>
<p>20 0.93978393 <a title="1139-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
