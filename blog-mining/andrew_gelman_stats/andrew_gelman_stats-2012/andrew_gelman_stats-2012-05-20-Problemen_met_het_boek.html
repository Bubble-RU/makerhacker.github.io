<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1332 andrew gelman stats-2012-05-20-Problemen met het boek</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1332" href="#">andrew_gelman_stats-2012-1332</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1332 andrew gelman stats-2012-05-20-Problemen met het boek</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1332-html" href="http://andrewgelman.com/2012/05/20/problemen-met-het-boek/">html</a></p><p>Introduction: Regarding the so-called Dutch Book argument for Bayesian inference (the idea that, if your inferences do not correspond to a Bayesian posterior distribution, you can be forced to make incoherent bets and ultimately become a money pump), I wrote:
 
I have never found this argument appealing, because a bet is a game not a decision.  A bet requires 2 players, and one player has to offer the bets.  I do agree that in some bounded settings (for example, betting on win place show in a horse race), I’d want my bets to be coherent; if they are incoherent (e.g., if my bets correspond to P(A|B)*P(B) not being equal to P(A,B)), then I should be able to do better by examining the incoherence.  But in an “open system” (to borrow some physics jargon), I don’t think coherence is possible.  There is always new information coming in, and there is always additional prior information in reserve that hasn’t entered the model.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A bet requires 2 players, and one player has to offer the bets. [sent-2, score-0.526]
</p><p>2 I do agree that in some bounded settings (for example, betting on win place show in a horse race), I’d want my bets to be coherent; if they are incoherent (e. [sent-3, score-1.596]
</p><p>3 , if my bets correspond to P(A|B)*P(B) not being equal to P(A,B)), then I should be able to do better by examining the incoherence. [sent-5, score-1.047]
</p><p>4 But in an “open system” (to borrow some physics jargon), I don’t think coherence is possible. [sent-6, score-0.387]
</p><p>5 There is always new information coming in, and there is always additional prior information in reserve that hasn’t entered the model. [sent-7, score-0.918]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bets', 0.493), ('incoherent', 0.292), ('correspond', 0.245), ('bet', 0.228), ('pump', 0.178), ('entered', 0.155), ('borrow', 0.152), ('horse', 0.149), ('dutch', 0.149), ('betting', 0.146), ('reserve', 0.146), ('argument', 0.141), ('examining', 0.141), ('coherence', 0.141), ('jargon', 0.139), ('bounded', 0.137), ('forced', 0.133), ('player', 0.12), ('appealing', 0.117), ('hasn', 0.116), ('coherent', 0.112), ('players', 0.11), ('race', 0.107), ('equal', 0.102), ('information', 0.099), ('bayesian', 0.098), ('always', 0.098), ('win', 0.095), ('game', 0.094), ('settings', 0.094), ('physics', 0.094), ('inferences', 0.092), ('requires', 0.091), ('additional', 0.089), ('offer', 0.087), ('ultimately', 0.085), ('posterior', 0.078), ('become', 0.077), ('money', 0.075), ('open', 0.074), ('regarding', 0.073), ('system', 0.071), ('coming', 0.07), ('place', 0.069), ('able', 0.066), ('distribution', 0.065), ('show', 0.065), ('prior', 0.064), ('inference', 0.06), ('agree', 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1332-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-20-Problemen_met_het_boek.html">1332 andrew gelman stats-2012-05-20-Problemen met het boek</a></p>
<p>Introduction: Regarding the so-called Dutch Book argument for Bayesian inference (the idea that, if your inferences do not correspond to a Bayesian posterior distribution, you can be forced to make incoherent bets and ultimately become a money pump), I wrote:
 
I have never found this argument appealing, because a bet is a game not a decision.  A bet requires 2 players, and one player has to offer the bets.  I do agree that in some bounded settings (for example, betting on win place show in a horse race), I’d want my bets to be coherent; if they are incoherent (e.g., if my bets correspond to P(A|B)*P(B) not being equal to P(A,B)), then I should be able to do better by examining the incoherence.  But in an “open system” (to borrow some physics jargon), I don’t think coherence is possible.  There is always new information coming in, and there is always additional prior information in reserve that hasn’t entered the model.</p><p>2 0.15839742 <a title="1332-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>Introduction: Konrad Scheffler writes:
  
I was interested by your  paper  “Induction and deduction in Bayesian data analysis” and was wondering if you would entertain a few questions:
  
  
  
 – Under the banner of objective Bayesianism, I would posit something like this as a description of Bayesian inference:


“Objective Bayesian probability is not a degree of belief (which would necessarily be subjective) but a measure of the plausibility of a hypothesis, conditional on a formally specified information state. One way of specifying a formal information state is to specify a model, which involves specifying both a prior distribution (typically for a set of unobserved variables) and a likelihood function (typically for a set of observed variables, conditioned on the values of the unobserved variables). Bayesian inference involves calculating the objective degree of plausibility of a hypothesis (typically the truth value of the hypothesis is a function of the variables mentioned above) given such a</p><p>3 0.13789463 <a title="1332-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-10-Creating_a_good_wager_based_on_probability_estimates.html">138 andrew gelman stats-2010-07-10-Creating a good wager based on probability estimates</a></p>
<p>Introduction: Suppose you and I agree on a probability estimate…perhaps we both agree there is a 2/3 chance Spain will beat Netherlands in tomorrow’s World Cup.  In this case, we could agree on a wager: if Spain beats Netherlands, I pay you $x.  If Netherlands beats Spain, you pay me $2x.  It is easy to see that my expected loss (or win) is $0, and that the same is true for you. Either of us should be indifferent to taking this bet, and to which side of the bet we are on.  We might make this bet just to increase our interest in watching the game, but neither of us would see a money-making opportunity here. 
 
By the way, the relationship between “odds” and the event probability — a 1/3 chance of winning turning into a bet at 2:1 odds — is that if the event probability is p, then a fair bet has odds of (1/p – 1):1.  
 
More interesting, and more relevant to many real-world situations, is the case that we disagree on the probability of an event.  If we disagree on the probability, then there should be</p><p>4 0.13092887 <a title="1332-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-12-Reputational_Capital_and_Incentives_in_Organizations.html">81 andrew gelman stats-2010-06-12-Reputational Capital and Incentives in Organizations</a></p>
<p>Introduction: Rajiv Sethi  offers  a fascinating discussion of the incentives involved in paying people zillions of dollars to lie, cheat, and steal.  Iâ&euro;&trade;d been aware for a long time of the general problem of the system of one-way bets in which purported risk-takers can make huge fortunes with little personal risks, but Rajiv and his commenters go further by getting into the specifics of management at financial firms.</p><p>5 0.12702292 <a title="1332-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-17-Weak_identification_provides_partial_information.html">1903 andrew gelman stats-2013-06-17-Weak identification provides partial information</a></p>
<p>Introduction: Matt Selove writes: 
  
  
My question is about Bayesian analysis of the linear regression model. It seems to me that in some cases this approach throws out useful information.


As an example, imagine you have two basketball players randomly drawn from the pool of NBA players (which provides the prior). You’d like to estimate how many free throws each can make out of 100. You have two pieces of information:


- Session 1: Each player shoots 100 shots, and you learn player A’s total minus player B’s total


- Session 2: Player A does another session where he shoots 100 shots alone, and you learn his total


If we take the regression approach:


y_i = number of shots made 
beta_A = player A’s expected number out of 100 
beta_B = player B’s expected number out of 100 
x_i = vector of zeros and ones showing which player took shots


In the above example, our datapoints are:


y_1 (first number reported) = beta_A * 1 + beta_B * (-1) + epsilon_1 
y_2 (second number reported) = beta_A * 1 +</p><p>6 0.12492293 <a title="1332-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>7 0.099107258 <a title="1332-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>8 0.092041187 <a title="1332-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-21-Scrabble%21.html">813 andrew gelman stats-2011-07-21-Scrabble!</a></p>
<p>9 0.089872748 <a title="1332-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>10 0.08262381 <a title="1332-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>11 0.080856368 <a title="1332-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>12 0.080798514 <a title="1332-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-01-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Cox_and_Mayo.html">1149 andrew gelman stats-2012-02-01-Philosophy of Bayesian statistics:  my reactions to Cox and Mayo</a></p>
<p>13 0.078736573 <a title="1332-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-20-Who_exactly_are_those_silly_academics_who_aren%E2%80%99t_as_smart_as_a_Vegas_bookie%3F.html">1632 andrew gelman stats-2012-12-20-Who exactly are those silly academics who aren’t as smart as a Vegas bookie?</a></p>
<p>14 0.077095047 <a title="1332-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-05-What_is_a_prior_distribution%3F.html">1155 andrew gelman stats-2012-02-05-What is a prior distribution?</a></p>
<p>15 0.077033482 <a title="1332-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>16 0.075473405 <a title="1332-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<p>17 0.07504458 <a title="1332-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-03-Question_about_predictive_checks.html">1363 andrew gelman stats-2012-06-03-Question about predictive checks</a></p>
<p>18 0.068257608 <a title="1332-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>19 0.067633674 <a title="1332-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-28-Turing_chess_run_update.html">1473 andrew gelman stats-2012-08-28-Turing chess run update</a></p>
<p>20 0.067473926 <a title="1332-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.111), (1, 0.073), (2, -0.022), (3, 0.07), (4, -0.061), (5, -0.014), (6, 0.048), (7, 0.028), (8, -0.008), (9, -0.017), (10, -0.024), (11, -0.011), (12, -0.004), (13, -0.004), (14, -0.014), (15, 0.015), (16, 0.036), (17, -0.014), (18, 0.033), (19, 0.006), (20, -0.022), (21, 0.027), (22, 0.017), (23, 0.035), (24, 0.01), (25, 0.025), (26, 0.028), (27, 0.033), (28, -0.01), (29, -0.036), (30, 0.007), (31, -0.059), (32, -0.009), (33, 0.022), (34, 0.011), (35, 0.036), (36, 0.005), (37, -0.013), (38, 0.002), (39, 0.048), (40, 0.009), (41, -0.025), (42, -0.003), (43, -0.022), (44, -0.006), (45, -0.041), (46, 0.029), (47, -0.002), (48, -0.017), (49, 0.007)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95946026 <a title="1332-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-20-Problemen_met_het_boek.html">1332 andrew gelman stats-2012-05-20-Problemen met het boek</a></p>
<p>Introduction: Regarding the so-called Dutch Book argument for Bayesian inference (the idea that, if your inferences do not correspond to a Bayesian posterior distribution, you can be forced to make incoherent bets and ultimately become a money pump), I wrote:
 
I have never found this argument appealing, because a bet is a game not a decision.  A bet requires 2 players, and one player has to offer the bets.  I do agree that in some bounded settings (for example, betting on win place show in a horse race), I’d want my bets to be coherent; if they are incoherent (e.g., if my bets correspond to P(A|B)*P(B) not being equal to P(A,B)), then I should be able to do better by examining the incoherence.  But in an “open system” (to borrow some physics jargon), I don’t think coherence is possible.  There is always new information coming in, and there is always additional prior information in reserve that hasn’t entered the model.</p><p>2 0.74517959 <a title="1332-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-17-Weak_identification_provides_partial_information.html">1903 andrew gelman stats-2013-06-17-Weak identification provides partial information</a></p>
<p>Introduction: Matt Selove writes: 
  
  
My question is about Bayesian analysis of the linear regression model. It seems to me that in some cases this approach throws out useful information.


As an example, imagine you have two basketball players randomly drawn from the pool of NBA players (which provides the prior). You’d like to estimate how many free throws each can make out of 100. You have two pieces of information:


- Session 1: Each player shoots 100 shots, and you learn player A’s total minus player B’s total


- Session 2: Player A does another session where he shoots 100 shots alone, and you learn his total


If we take the regression approach:


y_i = number of shots made 
beta_A = player A’s expected number out of 100 
beta_B = player B’s expected number out of 100 
x_i = vector of zeros and ones showing which player took shots


In the above example, our datapoints are:


y_1 (first number reported) = beta_A * 1 + beta_B * (-1) + epsilon_1 
y_2 (second number reported) = beta_A * 1 +</p><p>3 0.7126323 <a title="1332-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>Introduction: Ryan Ickert writes:
  
I was wondering if you’d seen  this post , by a particle physicist with some degree of influence.  Dr. Dorigo works at CERN and Fermilab.


The penultimate paragraph is:

 
From the above expression, the Frequentist researcher concludes that the tracker is indeed biased, and rejects the null hypothesis H0, since there is a less-than-2% probability (P’<α) that a result as the one observed could arise by chance! A Frequentist thus draws, strongly, the opposite conclusion than a Bayesian from the same set of data. How to solve the riddle?
 

He goes on to not solve the riddle.  Perhaps you can?


Surely with the large sample size they have (n=10^6), the precision on the frequentist p-value is pretty good, is it not?
  
My reply:
 
The first comment on the site (by Anonymous [who, just to be clear, is not me; I have no idea who wrote that comment], 22 Feb 2012, 21:27pm) pretty much nails it:  In setting up the Bayesian model, Dorigo assumed a silly distribution on th</p><p>4 0.71243227 <a title="1332-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-09-The_boxer%2C_the_wrestler%2C_and_the_coin_flip%2C_again.html">566 andrew gelman stats-2011-02-09-The boxer, the wrestler, and the coin flip, again</a></p>
<p>Introduction: Mike Grosskopf writes:
  
 
I came across your blog the other day and noticed  your paper  about “The Boxer, the Wrestler, and the Coin Flip” . . . I do not understand the objection to the robust Bayesian inference for conditioning on X=Y in the problem as you describe in the paper.  The paper talks about how using Robust Bayes when conditioning on X=Y “degrades our inference about the coin flip” and “has led us to the claim that we can say nothing at all about the coin ﬂip”. Does that have to be the case however, because while conditioning on X=Y does mean that p({X=1}|{X=Y}I) =  p({Y=1}|{X=Y}I), I don’t see why it has to mean that both have the same π-distribution where Pr(Y = 1) = π.


Which type of inference is being done about Y in the problem?


If you are trying to make an inference on the results of the fight between the boxer and the wrestler that has already happened, in which your friend tells you that either the boxer won and he flipped heads with a coin or the boxer lost a</p><p>5 0.69136846 <a title="1332-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-20-Non-statistical_thinking_in_the_US_foreign_policy_establishment.html">721 andrew gelman stats-2011-05-20-Non-statistical thinking in the US foreign policy establishment</a></p>
<p>Introduction: I’m a few weeks behind in my New Yorker reading and so just recently read  this fascinating article  by Ryan Lizza on the current administration’s foreign policy.  He gives some insights into the transformation Obama from antiwar candidate to a president conducting three wars.
 
Speaking as a statistician, though, what grabbed my eye was a doctrine of journalist/professor/policymaker Samantha Power.  Lizza writes:
  
In 2002, after graduating from Harvard Law School, she wrote “A Problem from Hell,” which surveyed the grim history of six genocides committed in the twentieth century. Propounding a liberal-interventionist view, Power argued that “mass killing” on the scale of Rwanda or Bosnia must be prevented by other nations, including the United States. She wrote that America and its allies rarely have perfect information about when a regime is about to commit genocide; a President, therefore, must have “a bias toward belief” that massacres are imminent.
  
From a statistical perspect</p><p>6 0.69116598 <a title="1332-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>7 0.68619293 <a title="1332-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-17-Christian_Robert_on_the_Jeffreys-Lindley_paradox%3B_more_generally%2C_it%E2%80%99s_good_news_when_philosophical_arguments_can_be_transformed_into_technical_modeling_issues.html">2027 andrew gelman stats-2013-09-17-Christian Robert on the Jeffreys-Lindley paradox; more generally, it’s good news when philosophical arguments can be transformed into technical modeling issues</a></p>
<p>8 0.68582034 <a title="1332-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<p>9 0.66751438 <a title="1332-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-Philosophy_of_Bayesian_statistics%3A_my_reactions_to_Hendry.html">1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</a></p>
<p>10 0.65700829 <a title="1332-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>11 0.6567806 <a title="1332-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-14-Oswald_evidence.html">2134 andrew gelman stats-2013-12-14-Oswald evidence</a></p>
<p>12 0.65525091 <a title="1332-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-22-Spell-checking_example_demonstrates_key_aspects_of_Bayesian_data_analysis.html">2182 andrew gelman stats-2014-01-22-Spell-checking example demonstrates key aspects of Bayesian data analysis</a></p>
<p>13 0.64874667 <a title="1332-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-12-How_to_think_about_%E2%80%9Cidentifiability%E2%80%9D_in_Bayesian_inference%3F.html">2208 andrew gelman stats-2014-02-12-How to think about “identifiability” in Bayesian inference?</a></p>
<p>14 0.64780456 <a title="1332-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-08-The_virtues_of_incoherence%3F.html">792 andrew gelman stats-2011-07-08-The virtues of incoherence?</a></p>
<p>15 0.64754027 <a title="1332-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<p>16 0.63343239 <a title="1332-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>17 0.63155764 <a title="1332-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-14-Progress%21__%28on_the_understanding_of_the_role_of_randomization_in_Bayesian_inference%29.html">1898 andrew gelman stats-2013-06-14-Progress!  (on the understanding of the role of randomization in Bayesian inference)</a></p>
<p>18 0.62924677 <a title="1332-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<p>19 0.62230653 <a title="1332-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<p>20 0.61890191 <a title="1332-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-15-Static_sensitivity_analysis.html">804 andrew gelman stats-2011-07-15-Static sensitivity analysis</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(4, 0.021), (9, 0.339), (15, 0.047), (16, 0.034), (21, 0.031), (24, 0.154), (39, 0.021), (63, 0.017), (89, 0.032), (99, 0.185)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96478808 <a title="1332-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-16-Annals_of_really_really_stupid_spam.html">577 andrew gelman stats-2011-02-16-Annals of really really stupid spam</a></p>
<p>Introduction: This came in the inbox today:
  
 
Dear Dr. Gelman,


GenWay recently found your article titled “Multiple imputation for model checking: completed-data plots with missing and latent data.” (Biometrics. 2005 Mar;61(1):74-85.) and thought you might be interested in learning about our superior quality signaling proteins.  


GenWay prides itself on being a leader in customer service aiming to exceed your expectations with the quality and price of our products.  With more than 60,000 reagents backed by our outstanding guarantee you are sure to find the products you have been searching for.


Please feel free to visit the following resource pages:


    * Apoptosis Pathway (product list) 
    * Adipocytokine (product list) 
    * Cell Cycle Pathway (product list) 
    * Jak STAT (product list) 
    * GnRH (product list) 
    * MAPK (product list) 
    * mTOR (product list) 
    * T Cell Receptor (product list) 
    * TGF-beta (product list) 
    * Wnt (product list) 
    * View All Pathways</p><p>2 0.95473909 <a title="1332-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-05-The_sort_of_thing_that_gives_technocratic_reasoning_a_bad_name.html">993 andrew gelman stats-2011-11-05-The sort of thing that gives technocratic reasoning a bad name</a></p>
<p>Introduction: 1.  Freakonomics  characterizes  drunk driving as an example of “the human tendency to worry about rare problems that are unlikely to happen.”
 
2.  The CDC  reports , “Alcohol-impaired drivers are involved in about 1 in 3 crash deaths, resulting in nearly 11,000 deaths in 2009.”
 
No offense to the tenured faculty at the University of Chicago, but I’m going with the CDC on this one. 
   
P.S.  The Freakonomics blog deserves to be dinged another time, not just for claiming, based on  implausible assumptions  and making the all-else-equal  fallacy  that “drunk walking is 8 times more likely to result in your death than drunk driving” but for presenting this weak inference as a fact rather than as a speculation.
 
When doing “Freakonomics,” you can be counterintuitive, or you can be sensible, but it’s hard to be both. I mean, sure, sometimes you can be. But there’s a tradeoff, and in this case, they’re choosing to push the envelope on counterintuitiveness.</p><p>3 0.90804982 <a title="1332-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Question_21_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1356 andrew gelman stats-2012-05-31-Question 21 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>Introduction: 21. A country is divided into three regions with populations of 2 million, 2 million, and 0.5 million, respectively. A survey is done asking about foreign policy opinions.. Somebody proposes taking a sample of 50 people from each reason. Give a reason why this non-proportional sample would not usually be done, and also a reason why it might actually be a good idea.
 
 Solution to question 20 
 
From  yesterday :
  
20. Explain in two sentences why we expect survey respondents to be honest about vote preferences but possibly dishonest about reporting unhealty behaviors.
  
Solution:  Respondents tend to be sincere about vote preferences because this affects the outcome of the poll, and people are motivated to have their candidate poll well.  This motivation is typically not present in reporting behaviors; you have no particular reason for wanting to affect the average survey response.</p><p>same-blog 4 0.89434296 <a title="1332-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-20-Problemen_met_het_boek.html">1332 andrew gelman stats-2012-05-20-Problemen met het boek</a></p>
<p>Introduction: Regarding the so-called Dutch Book argument for Bayesian inference (the idea that, if your inferences do not correspond to a Bayesian posterior distribution, you can be forced to make incoherent bets and ultimately become a money pump), I wrote:
 
I have never found this argument appealing, because a bet is a game not a decision.  A bet requires 2 players, and one player has to offer the bets.  I do agree that in some bounded settings (for example, betting on win place show in a horse race), I’d want my bets to be coherent; if they are incoherent (e.g., if my bets correspond to P(A|B)*P(B) not being equal to P(A,B)), then I should be able to do better by examining the incoherence.  But in an “open system” (to borrow some physics jargon), I don’t think coherence is possible.  There is always new information coming in, and there is always additional prior information in reserve that hasn’t entered the model.</p><p>5 0.87745857 <a title="1332-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-30-Systematic_review_of_publication_bias_in_studies_on_publication_bias.html">1291 andrew gelman stats-2012-04-30-Systematic review of publication bias in studies on publication bias</a></p>
<p>Introduction: Via  Yalda Afshar ,  a 2005 paper  by Hans-Hermann Dubben and Hans-Peter Beck-Bornholdt:
  
Publication bias is a well known phenomenon in clinical literature, in which positive results have a better chance of being published, are published earlier, and are published in journals with higher impact factors. Conclusions exclusively based on published studies, therefore, can be misleading. Selective under-reporting of research might be more widespread and more likely to have adverse consequences for patients than publication of deliberately falsified data. We investigated whether there is preferential publication of positive papers on publication bias.
  
They conclude, “We found no evidence of publication bias in reports on publication bias.”  But of course that’s the sort of finding regarding publication bias of findings on publication bias that you’d expect would get published.  What we really need is a careful meta-analysis to estimate the level of publication bias in studies of publi</p><p>6 0.86140263 <a title="1332-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-22-Extreme_events_as_evidence_for_differences_in_distributions.html">1424 andrew gelman stats-2012-07-22-Extreme events as evidence for differences in distributions</a></p>
<p>7 0.85685474 <a title="1332-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-13-A_real-life_dollar_auction_game%21.html">1532 andrew gelman stats-2012-10-13-A real-life dollar auction game!</a></p>
<p>8 0.85467559 <a title="1332-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-21-%E2%80%9CCity_Opens_Inquiry_on_Grading_Practices_at_a_Top-Scoring_Bronx_School%E2%80%9D.html">529 andrew gelman stats-2011-01-21-“City Opens Inquiry on Grading Practices at a Top-Scoring Bronx School”</a></p>
<p>9 0.83752048 <a title="1332-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-10-Recently_in_the_sister_blog%3A__Brussels_sprouts%2C_ugly_graphs%2C_and_switched_at_birth.html">1664 andrew gelman stats-2013-01-10-Recently in the sister blog:  Brussels sprouts, ugly graphs, and switched at birth</a></p>
<p>10 0.80912256 <a title="1332-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-29-Postdocs_in_probabilistic_modeling%21__With_David_Blei%21__And_Stan%21.html">1961 andrew gelman stats-2013-07-29-Postdocs in probabilistic modeling!  With David Blei!  And Stan!</a></p>
<p>11 0.79313147 <a title="1332-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-01-Why_it_can_be_rational_to_vote.html">389 andrew gelman stats-2010-11-01-Why it can be rational to vote</a></p>
<p>12 0.79312909 <a title="1332-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-06-Why_it_can_be_rational_to_vote.html">1565 andrew gelman stats-2012-11-06-Why it can be rational to vote</a></p>
<p>13 0.78950715 <a title="1332-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-07-A_question_about_voting_systems%E2%80%94unrelated_to_U.S._elections%21.html">1566 andrew gelman stats-2012-11-07-A question about voting systems—unrelated to U.S. elections!</a></p>
<p>14 0.78360265 <a title="1332-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Education_and_Poverty.html">560 andrew gelman stats-2011-02-06-Education and Poverty</a></p>
<p>15 0.77027202 <a title="1332-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-Difficulties_with_the_1-4-power_transformation.html">1142 andrew gelman stats-2012-01-29-Difficulties with the 1-4-power transformation</a></p>
<p>16 0.76227111 <a title="1332-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-10-Jobs_in_statistics_research%21__In_New_Jersey%21.html">1110 andrew gelman stats-2012-01-10-Jobs in statistics research!  In New Jersey!</a></p>
<p>17 0.75435293 <a title="1332-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-22-Story_time_meets_the_all-else-equal_fallacy_and_the_fallacy_of_measurement.html">1226 andrew gelman stats-2012-03-22-Story time meets the all-else-equal fallacy and the fallacy of measurement</a></p>
<p>18 0.75165689 <a title="1332-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-12-Probability_of_successive_wins_in_baseball.html">29 andrew gelman stats-2010-05-12-Probability of successive wins in baseball</a></p>
<p>19 0.73985392 <a title="1332-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-09-Thomas_Hobbes_would_be_spinning_in_his_grave.html">1715 andrew gelman stats-2013-02-09-Thomas Hobbes would be spinning in his grave</a></p>
<p>20 0.72806895 <a title="1332-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-31-Why_Edit_Wikipedia%3F.html">640 andrew gelman stats-2011-03-31-Why Edit Wikipedia?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
