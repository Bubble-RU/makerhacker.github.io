<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1248" href="#">andrew_gelman_stats-2012-1248</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1248-html" href="http://andrewgelman.com/2012/04/06/17-groups-6-group-level-predictors-what-to-do/">html</a></p><p>Introduction: Yi-Chun Ou writes: 
  
  
I am using a multilevel model with three levels. I read that you wrote a book about multilevel models, and wonder if you can solve the following question.  


The data structure is like this: 


Level one: customer (8444 customers) 
Level two: companys (90 companies) 
Level three: industry (17 industries) 


I use 6 level-three variables (i.e. industry characteristics) to explain the variance of the level-one effect across industries. The question here is whether there is an over-fitting problem since there are only 17 industries. I understand that this must be a problem for non-multilevel models, but is it also a problem for multilevel models?
  
My reply:  Yes, this could be a problem.  I’d suggest combining some of your variables into a common score, or using only some of the variables, or using strong priors to control the inferences.  This is an interesting and important area of statistics research, to do this sort of thing systematically.  There’s lots o</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Yi-Chun Ou writes:        I am using a multilevel model with three levels. [sent-1, score-0.631]
</p><p>2 I read that you wrote a book about multilevel models, and wonder if you can solve the following question. [sent-2, score-0.786]
</p><p>3 The data structure is like this:    Level one: customer (8444 customers)  Level two: companys (90 companies)  Level three: industry (17 industries)    I use 6 level-three variables (i. [sent-3, score-1.02]
</p><p>4 industry characteristics) to explain the variance of the level-one effect across industries. [sent-5, score-0.69]
</p><p>5 The question here is whether there is an over-fitting problem since there are only 17 industries. [sent-6, score-0.366]
</p><p>6 I understand that this must be a problem for non-multilevel models, but is it also a problem for multilevel models? [sent-7, score-0.8]
</p><p>7 I’d suggest combining some of your variables into a common score, or using only some of the variables, or using strong priors to control the inferences. [sent-9, score-1.253]
</p><p>8 This is an interesting and important area of statistics research, to do this sort of thing systematically. [sent-10, score-0.402]
</p><p>9 There’s lots of work on what to do with hundreds of data points and thousands of predictors, but not so much with 17 data and 6 predictors. [sent-11, score-0.616]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('industry', 0.314), ('multilevel', 0.312), ('variables', 0.274), ('level', 0.244), ('predictors', 0.236), ('industries', 0.218), ('customer', 0.206), ('customers', 0.19), ('models', 0.188), ('problem', 0.164), ('three', 0.162), ('using', 0.157), ('characteristics', 0.155), ('combining', 0.148), ('companies', 0.144), ('hundreds', 0.141), ('thousands', 0.133), ('score', 0.133), ('structure', 0.124), ('solve', 0.122), ('priors', 0.117), ('variance', 0.113), ('area', 0.109), ('suggest', 0.105), ('data', 0.102), ('control', 0.101), ('explain', 0.1), ('common', 0.098), ('strong', 0.096), ('wonder', 0.093), ('across', 0.089), ('must', 0.086), ('yes', 0.083), ('effect', 0.074), ('understand', 0.074), ('lots', 0.073), ('reply', 0.073), ('whether', 0.072), ('since', 0.071), ('following', 0.066), ('book', 0.065), ('points', 0.065), ('read', 0.065), ('interesting', 0.064), ('important', 0.064), ('wrote', 0.063), ('question', 0.059), ('sort', 0.057), ('thing', 0.056), ('statistics', 0.052)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1248-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>Introduction: Yi-Chun Ou writes: 
  
  
I am using a multilevel model with three levels. I read that you wrote a book about multilevel models, and wonder if you can solve the following question.  


The data structure is like this: 


Level one: customer (8444 customers) 
Level two: companys (90 companies) 
Level three: industry (17 industries) 


I use 6 level-three variables (i.e. industry characteristics) to explain the variance of the level-one effect across industries. The question here is whether there is an over-fitting problem since there are only 17 industries. I understand that this must be a problem for non-multilevel models, but is it also a problem for multilevel models?
  
My reply:  Yes, this could be a problem.  I’d suggest combining some of your variables into a common score, or using only some of the variables, or using strong priors to control the inferences.  This is an interesting and important area of statistics research, to do this sort of thing systematically.  There’s lots o</p><p>2 0.206047 <a title="1248-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>Introduction: Steve Miller writes: 
  
  
Much of what I do is cross-national analyses of survey data (largely World Values Survey). . . . My big question pertains to (what I would call) exploratory analysis of multilevel data, especially when the group-level predictors are of theoretical importance. A lot of what I do involves analyzing cross-national survey items of citizen attitudes, typically of political leadership. These survey items are usually yes/no responses, or four-part responses indicating a level of agreement (strongly agree, agree, disagree, strongly disagree) that can be condensed into a binary variable. I believe these can be explained by reference to country-level factors. Much of the group-level variables of interest are count variables with a modal value of 0, which can be quite messy.


How would you recommend exploring the variation in the dependent variable as it could be explained by the group-level count variable of interest, before fitting the multilevel model itself? When</p><p>3 0.19482379 <a title="1248-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<p>Introduction: Stephen Collins writes:
  
I’m reading your Multilevel modeling book and am trying to apply it to my work.  I’m concerned with how to estimate a random intercept model if there are hundreds/thousands of levels.  In the Gibbs sampling, am I sampling a parameter for each level?  Or, just the hyper-parameters?  In other words, say I had 500 zipcode intercepts modeled as ~ N(m,s).  Would my posterior be two dimensional, sampling for “m” and “s,” or would it have 502 dimensions?
  
My reply:  Indeed you will have hundreds or thousands of parameters—or, in classical terms, hundreds or thousands of predictive quantities.  But that’s ok.  Even if none of those predictions is precise, you’re learning  about the model.
 
See page 526 of the book for more discussion of the number of parameters in a multilevel model.</p><p>4 0.18718986 <a title="1248-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>Introduction: Nelson Villoria writes:
  
I find the multilevel approach very useful for a problem I am dealing with, and I was wondering whether you could point me to some references about poolability tests for multilevel models. I am working with time series of cross sectional data and I want to test whether the data supports cross sectional and/or time pooling. In a standard panel data setting I do this with Chow tests and/or CUSUM. Are these ideas directly transferable to the multilevel setting?
  
My reply:  I think you should do partial pooling.  Once the question arises, just do it.  Other models are just special cases.  I donâ&euro;&trade;t see the need for any test.
 
That said, if you do a group-level model, you need to consider including group-level averages of individual predictors (see  here ).  And if the number of groups is small, there can be real gains from using an informative prior distribution on the hierarchical variance parameters.  This is something that Jennifer and I do not discuss in our</p><p>5 0.18405502 <a title="1248-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>Introduction: Zoltan Fazekas writes:
  
I am a 2nd year graduate student in political science at the University of Vienna. In my empirical research I often employ multilevel modeling, and recently I came across a situation that kept me wondering for quite a while. As I did not find much on this in the literature and considering the topics that you work on and blog about, I figured I will try to contact you.
      
The situation is as follows: in a linear multilevel model, there are two important individual level predictors (x1 and x2) and a set of controls. Let us assume that there is a theoretically grounded argument suggesting that an interaction between x1 and x2 should be included in the model (x1 * x2). Both x1 and x2 are let to vary randomly across groups. Would this directly imply that the coefficient of the interaction should also be left to vary across country? This is even more burning if there is no specific hypothesis on the variance of the conditional effect across countries. And then i</p><p>6 0.18252866 <a title="1248-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>7 0.18053742 <a title="1248-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-Understanding_how_estimates_change_when_you_move_to_a_multilevel_model.html">850 andrew gelman stats-2011-08-11-Understanding how estimates change when you move to a multilevel model</a></p>
<p>8 0.17391431 <a title="1248-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>9 0.17121302 <a title="1248-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>10 0.16616592 <a title="1248-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>11 0.16549218 <a title="1248-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>12 0.16535161 <a title="1248-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>13 0.16129002 <a title="1248-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>14 0.16049036 <a title="1248-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-Clutering_and_variance_components.html">417 andrew gelman stats-2010-11-17-Clutering and variance components</a></p>
<p>15 0.15778491 <a title="1248-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>16 0.15568332 <a title="1248-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>17 0.15397744 <a title="1248-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-21-Building_a_regression_model_._._._with_only_27_data_points.html">1506 andrew gelman stats-2012-09-21-Building a regression model . . . with only 27 data points</a></p>
<p>18 0.15054594 <a title="1248-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>19 0.14667092 <a title="1248-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Sof%5Bt%5D.html">77 andrew gelman stats-2010-06-09-Sof[t]</a></p>
<p>20 0.14556132 <a title="1248-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-More_on_Bayesian_methods_and_multilevel_modeling.html">2033 andrew gelman stats-2013-09-23-More on Bayesian methods and multilevel modeling</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.213), (1, 0.148), (2, 0.066), (3, -0.016), (4, 0.123), (5, 0.067), (6, 0.001), (7, -0.053), (8, 0.09), (9, 0.211), (10, 0.057), (11, 0.004), (12, 0.05), (13, 0.004), (14, 0.067), (15, 0.025), (16, -0.049), (17, 0.003), (18, 0.028), (19, -0.027), (20, -0.029), (21, 0.038), (22, 0.016), (23, 0.033), (24, -0.068), (25, -0.109), (26, -0.006), (27, 0.006), (28, -0.037), (29, 0.01), (30, -0.02), (31, -0.004), (32, 0.02), (33, -0.01), (34, -0.004), (35, 0.017), (36, 0.026), (37, 0.008), (38, 0.018), (39, 0.004), (40, -0.02), (41, -0.031), (42, 0.047), (43, -0.009), (44, -0.016), (45, -0.007), (46, 0.025), (47, 0.02), (48, -0.046), (49, -0.029)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96908814 <a title="1248-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>Introduction: Yi-Chun Ou writes: 
  
  
I am using a multilevel model with three levels. I read that you wrote a book about multilevel models, and wonder if you can solve the following question.  


The data structure is like this: 


Level one: customer (8444 customers) 
Level two: companys (90 companies) 
Level three: industry (17 industries) 


I use 6 level-three variables (i.e. industry characteristics) to explain the variance of the level-one effect across industries. The question here is whether there is an over-fitting problem since there are only 17 industries. I understand that this must be a problem for non-multilevel models, but is it also a problem for multilevel models?
  
My reply:  Yes, this could be a problem.  I’d suggest combining some of your variables into a common score, or using only some of the variables, or using strong priors to control the inferences.  This is an interesting and important area of statistics research, to do this sort of thing systematically.  There’s lots o</p><p>2 0.84724313 <a title="1248-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>Introduction: Zoltan Fazekas writes:
  
I am a 2nd year graduate student in political science at the University of Vienna. In my empirical research I often employ multilevel modeling, and recently I came across a situation that kept me wondering for quite a while. As I did not find much on this in the literature and considering the topics that you work on and blog about, I figured I will try to contact you.
      
The situation is as follows: in a linear multilevel model, there are two important individual level predictors (x1 and x2) and a set of controls. Let us assume that there is a theoretically grounded argument suggesting that an interaction between x1 and x2 should be included in the model (x1 * x2). Both x1 and x2 are let to vary randomly across groups. Would this directly imply that the coefficient of the interaction should also be left to vary across country? This is even more burning if there is no specific hypothesis on the variance of the conditional effect across countries. And then i</p><p>3 0.84676409 <a title="1248-lsi-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>Introduction: Nelson Villoria writes:
  
I find the multilevel approach very useful for a problem I am dealing with, and I was wondering whether you could point me to some references about poolability tests for multilevel models. I am working with time series of cross sectional data and I want to test whether the data supports cross sectional and/or time pooling. In a standard panel data setting I do this with Chow tests and/or CUSUM. Are these ideas directly transferable to the multilevel setting?
  
My reply:  I think you should do partial pooling.  Once the question arises, just do it.  Other models are just special cases.  I donâ&euro;&trade;t see the need for any test.
 
That said, if you do a group-level model, you need to consider including group-level averages of individual predictors (see  here ).  And if the number of groups is small, there can be real gains from using an informative prior distribution on the hierarchical variance parameters.  This is something that Jennifer and I do not discuss in our</p><p>4 0.83706409 <a title="1248-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-19-Index_or_indicator_variables.html">2296 andrew gelman stats-2014-04-19-Index or indicator variables</a></p>
<p>Introduction: Someone who doesn’t want his name shared (for the perhaps reasonable reason that he’ll “one day not be confused, and would rather my confusion not live on online forever”) writes:
  
I’m exploring HLMs and stan, using your book with Jennifer Hill as my field guide to this new territory. I think I have a generally clear grasp on the material, but wanted to be sure I haven’t gone astray. 


The problem in working on involves a multi-nation survey of students, and I’m especially interested in understanding the effects of country, religion, and sex, and the interactions among those factors (using IRT to estimate individual-level ability, then estimating individual, school, and country effects).


Following the basic approach laid out in chapter 13 for such interactions between levels, I think I need to create a matrix of indicator variables for religion and sex. Elsewhere in the book, you recommend against indicator variables in favor of a single index variable. 


Am I right in thinking t</p><p>5 0.82771486 <a title="1248-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>Introduction: Robert Birkelbach:
  
I am writing my Bachelor Thesis in which I want to assess the reading competencies of German elementary school children using the PIRLS2006 data. My levels are classrooms and the individuals. However, my dependent variable is a multiple imputed (m=5) reading test. The problem I have is, that I do not know, whether I can just calculate 5 linear multilevel models and then average all the results (the coefficients, standard deviation, bic, intra class correlation, R2, t-statistics, p-values etc) or if I need different formulas for integrating the results of the five models into one because it is a multilevel analysis? Do you think there’s a better way in solving my problem? I would greatly appreciate if you could help me with a problem regarding my analysis — I am quite a newbie to multilevel modeling and especially to multiple imputation. Also: Is it okay to use frequentist models when the multiple imputation was done bayesian? Would the different philosophies of sc</p><p>6 0.8217302 <a title="1248-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-10-Combining_data_from_many_sources.html">948 andrew gelman stats-2011-10-10-Combining data from many sources</a></p>
<p>7 0.8099941 <a title="1248-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-Displaying_inferences_from_complex_models.html">1815 andrew gelman stats-2013-04-20-Displaying inferences from complex models</a></p>
<p>8 0.80328572 <a title="1248-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>9 0.79732835 <a title="1248-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>10 0.7889877 <a title="1248-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>11 0.77771944 <a title="1248-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>12 0.77617729 <a title="1248-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>13 0.77407318 <a title="1248-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>14 0.77336162 <a title="1248-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>15 0.77235186 <a title="1248-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Multilevel_quantile_regression.html">397 andrew gelman stats-2010-11-06-Multilevel quantile regression</a></p>
<p>16 0.76938879 <a title="1248-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>17 0.76590383 <a title="1248-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-24-Multilevel_modeling_and_instrumental_variables.html">1468 andrew gelman stats-2012-08-24-Multilevel modeling and instrumental variables</a></p>
<p>18 0.75481236 <a title="1248-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-More_on_Bayesian_methods_and_multilevel_modeling.html">2033 andrew gelman stats-2013-09-23-More on Bayesian methods and multilevel modeling</a></p>
<p>19 0.75374794 <a title="1248-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>20 0.75235844 <a title="1248-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Modeling_y_%3D_a_%2B_b_%2B_c.html">1294 andrew gelman stats-2012-05-01-Modeling y = a + b + c</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.022), (16, 0.02), (24, 0.107), (41, 0.019), (44, 0.043), (56, 0.093), (76, 0.026), (77, 0.018), (89, 0.021), (99, 0.513)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99065739 <a title="1248-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>Introduction: Yi-Chun Ou writes: 
  
  
I am using a multilevel model with three levels. I read that you wrote a book about multilevel models, and wonder if you can solve the following question.  


The data structure is like this: 


Level one: customer (8444 customers) 
Level two: companys (90 companies) 
Level three: industry (17 industries) 


I use 6 level-three variables (i.e. industry characteristics) to explain the variance of the level-one effect across industries. The question here is whether there is an over-fitting problem since there are only 17 industries. I understand that this must be a problem for non-multilevel models, but is it also a problem for multilevel models?
  
My reply:  Yes, this could be a problem.  I’d suggest combining some of your variables into a common score, or using only some of the variables, or using strong priors to control the inferences.  This is an interesting and important area of statistics research, to do this sort of thing systematically.  There’s lots o</p><p>2 0.97800738 <a title="1248-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-13-More_Bell_Labs_happy_talk.html">1670 andrew gelman stats-2013-01-13-More Bell Labs happy talk</a></p>
<p>Introduction: Mort Panish writes:
  
I just read your  review  of Gertnerâ&euro;&trade;s book.  I agree with most of what you say re Bell labs.


I worked in the research area from 1964 to 1992 having arrived in what I regarded as a sort of heaven after 10 years in industrial research elsewhere. For much of that time I headed the Materials Science Research Dept. in the Solid State Electronics Laboratory. For a large number of the senior staff the eight hour day was the exception, not the rule, and even on weekends the parking lot was often 1/4 full. Most of the people I worked with were self driven and loved their work and the opportunities the Labs. provided to be maximally scientifically productive. Even during lunch in the cafeteria productive interactions were a common occurrence. I could go on and on, but just wanted to thank you for bring back pleasant memories of a long and productive career at Bell Labs after 20 years in retirement.
  
Also, for thsoe who missed it, my personal reminiscences of Bell Labs</p><p>3 0.97644472 <a title="1248-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-20-%E2%80%9CI_know_you_aren%E2%80%99t_the_plagiarism_police%2C_but_._._.%E2%80%9D.html">1585 andrew gelman stats-2012-11-20-“I know you aren’t the plagiarism police, but . . .”</a></p>
<p>Introduction: Someone I don’t know writes in:
  
I have followed your thoughts on plagiarism rather closely, and I ran across something in the Economics literature that I felt might interest you (and if you were to share this, I’d rather remain anonymous as a junior faculty not looking to step on toes anywhere).  I know you aren’t the plagiarism police, but figured you would have some input.


I’ve been reading up on some literature regarding all-pay auctions for some research I have been working on and came across an interesting paper in J. Political Economy (1998) with the following intro:

 
“Many economic allocations are decided by competition for a prize on the basis of costly activities. For example, monopoly licenses may be awarded to the person (or group) that lobbies the hardest (Tullock, 1967), or tickets may be given to those who wait in line the longest (Holt and Sherman 1982). In such contests, losers’ efforts are costly and are generally not compensated. These situations, which are esp</p><p>4 0.97563303 <a title="1248-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-07-Small_world%3A__MIT%2C_asymptotic_behavior_of_differential-difference_equations%2C_Susan_Assmann%2C_subgroup_analysis%2C_multilevel_modeling.html">507 andrew gelman stats-2011-01-07-Small world:  MIT, asymptotic behavior of differential-difference equations, Susan Assmann, subgroup analysis, multilevel modeling</a></p>
<p>Introduction: A colleague recently sent me a copy of some articles on the estimation of treatment interactions (a topic that’s interested me for awhile).  One of the articles, which appeared in the Lancet in 2000, was called “ Subgroup analysis and other (mis)uses of baseline data in clinical trials ,” by Susan F. Assmann, Stuart J. Pocock, Laura E. Enos, and Linda E. Kasten. . . . 
 
Hey, wait a minute–I know Susan Assmann!  Well, I sort of know her.  When I was a freshman in college, I asked my adviser, who was an applied math prof, if I could do some research.  He connected me to Susan, who was one of his Ph.D. students, and she gave me a tiny part of her thesis to work on.
 
The problem went as follows.  You have a function f(x), for x going from 0 to infinity, that is defined as follows.  Between 0 and 1, f(x)=x.  Then, for x higher than 1, f’(x) = f(x) – f(x-1).  The goal is to figure out what f(x) does.  I think I’m getting this right here, but I might be getting confused on some of the detai</p><p>5 0.97542477 <a title="1248-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-19-%E2%80%9COne_of_the_easiest_ways_to_differentiate_an_economist_from_almost_anyone_else_in_society%E2%80%9D.html">809 andrew gelman stats-2011-07-19-“One of the easiest ways to differentiate an economist from almost anyone else in society”</a></p>
<p>Introduction: I think I’m starting to resolve a puzzle that’s been bugging me for awhile.
 
Pop economists (or, at least, pop micro-economists) are often making one of two arguments:
 
1.  People are rational and respond to incentives.  Behavior that looks irrational is actually completely rational once you think like an economist.
 
2.  People are irrational and they need economists, with their open minds, to show them how to be rational and efficient.
 
Argument 1 is associated with “why do they do that?” sorts of puzzles.  Why do they charge so much for candy at the movie theater, why are airline ticket prices such a mess, why are people drug addicts, etc.  The usual answer is that there’s some rational reason for what seems like silly or self-destructive behavior.
 
Argument 2 is associated with “we can do better” claims such as why we should fire 80% of public-schools teachers or Moneyball-style stories about how some clever entrepreneur has made a zillion dollars by exploiting some inefficienc</p><p>6 0.97517002 <a title="1248-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-30-More_on_the_correlation_between_statistical_and_political_ideology.html">638 andrew gelman stats-2011-03-30-More on the correlation between statistical and political ideology</a></p>
<p>7 0.97515261 <a title="1248-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-27-Overfitting.html">1431 andrew gelman stats-2012-07-27-Overfitting</a></p>
<p>8 0.97506678 <a title="1248-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-02-Graphical_communication_for_legal_scholarship.html">1096 andrew gelman stats-2012-01-02-Graphical communication for legal scholarship</a></p>
<p>9 0.97491753 <a title="1248-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-23-Examples_of_the_use_of_hierarchical_modeling_to_generalize_to_new_settings.html">1425 andrew gelman stats-2012-07-23-Examples of the use of hierarchical modeling to generalize to new settings</a></p>
<p>10 0.97484356 <a title="1248-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Using_economics_to_reduce_bike_theft.html">1536 andrew gelman stats-2012-10-16-Using economics to reduce bike theft</a></p>
<p>11 0.97445035 <a title="1248-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-17-Tenure-track_position_at_U._North_Carolina_in_survey_methods_and_social_statistics.html">153 andrew gelman stats-2010-07-17-Tenure-track position at U. North Carolina in survey methods and social statistics</a></p>
<p>12 0.97397739 <a title="1248-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-24-On_summarizing_a_noisy_scatterplot_with_a_single_comparison_of_two_points.html">589 andrew gelman stats-2011-02-24-On summarizing a noisy scatterplot with a single comparison of two points</a></p>
<p>13 0.97372746 <a title="1248-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-21-Defensive_political_science_responds_defensively_to_an_attack_on_social_science.html">1949 andrew gelman stats-2013-07-21-Defensive political science responds defensively to an attack on social science</a></p>
<p>14 0.97361535 <a title="1248-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-22-Handling_multiple_versions_of_an_outcome_variable.html">726 andrew gelman stats-2011-05-22-Handling multiple versions of an outcome variable</a></p>
<p>15 0.97307467 <a title="1248-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-01-Martin_and_Liu%3A__Probabilistic_inference_based_on_consistency_of_model_with_data.html">1095 andrew gelman stats-2012-01-01-Martin and Liu:  Probabilistic inference based on consistency of model with data</a></p>
<p>16 0.97306502 <a title="1248-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>17 0.97291309 <a title="1248-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-17-%E2%80%9Cthe_Tea_Party%E2%80%99s_ire%2C_directed_at_Democrats_and_Republicans_alike%E2%80%9D.html">521 andrew gelman stats-2011-01-17-“the Tea Party’s ire, directed at Democrats and Republicans alike”</a></p>
<p>18 0.97274899 <a title="1248-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-01-%E2%80%9COn_Inspiring_Students_and_Being_Human%E2%80%9D.html">1517 andrew gelman stats-2012-10-01-“On Inspiring Students and Being Human”</a></p>
<p>19 0.97274274 <a title="1248-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-13-D._Kahneman_serves_up_a_wacky_counterfactual.html">709 andrew gelman stats-2011-05-13-D. Kahneman serves up a wacky counterfactual</a></p>
<p>20 0.97263139 <a title="1248-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-10-Controversy_over_the_Christakis-Fowler_findings_on_the_contagion_of_obesity.html">757 andrew gelman stats-2011-06-10-Controversy over the Christakis-Fowler findings on the contagion of obesity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
