<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1194" href="#">andrew_gelman_stats-2012-1194</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1194-html" href="http://andrewgelman.com/2012/03/04/multilevel-modeling-even-when-youre-not-interested-in-predictions-for-new-groups/">html</a></p><p>Introduction: Fred Wu writes: 
  
  
I work at National Prescribing Services in Australia.  I have a database representing say, antidiabetic drug utilisation for the entire Australia in the past few years. I planned to do a longitudinal analysis across GP Division Network (112 divisions in AUS) using mixed-effects models (or as you called in your book varying intercept and varying slope) on this data. 


The problem here is: as data actually represent the population who use antidiabetic drugs in AUS, should I use 112 fixed dummy variables to capture the random variations or use varying intercept and varying slope for the model ? Because some one may aruge, like divisions in AUS or states in USA can hardly be considered from a “superpopulation”, then fixed dummies should be used.  What I think is the population are those who use the drugs, what will happen when the rest need to use them? In terms of exchangeability, using varying intercept and varying slopes can be justified.


Also you provided in y</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I have a database representing say, antidiabetic drug utilisation for the entire Australia in the past few years. [sent-2, score-0.394]
</p><p>2 I planned to do a longitudinal analysis across GP Division Network (112 divisions in AUS) using mixed-effects models (or as you called in your book varying intercept and varying slope) on this data. [sent-3, score-1.472]
</p><p>3 The problem here is: as data actually represent the population who use antidiabetic drugs in AUS, should I use 112 fixed dummy variables to capture the random variations or use varying intercept and varying slope for the model ? [sent-4, score-2.628]
</p><p>4 Because some one may aruge, like divisions in AUS or states in USA can hardly be considered from a “superpopulation”, then fixed dummies should be used. [sent-5, score-0.587]
</p><p>5 What I think is the population are those who use the drugs, what will happen when the rest need to use them? [sent-6, score-0.342]
</p><p>6 In terms of exchangeability, using varying intercept and varying slopes can be justified. [sent-7, score-1.14]
</p><p>7 My reply:   Even if you only want to estimate these 112 parameters, I’d think you’d want to estimate them as accurately as possible. [sent-9, score-0.21]
</p><p>8 And I think that would be done using multilevel modeling. [sent-10, score-0.209]
</p><p>9 There’s no particular reason to expect that least squares is the best way to go, and lots of reasons to expect otherwise. [sent-11, score-0.248]
</p><p>10 we’re only interested in our 50 states, not any others—we’re not sitting around waiting for D. [sent-13, score-0.136]
</p><p>11 and Puerto Rico to be added in as #51 and #52—and multilevel modeling is a good way of doing that. [sent-15, score-0.217]
</p><p>12 For some justification of multilevel modeling in such situations, see  this paper  by the Twins. [sent-16, score-0.295]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('varying', 0.369), ('aus', 0.368), ('intercept', 0.247), ('antidiabetic', 0.245), ('fixed', 0.21), ('divisions', 0.184), ('random', 0.169), ('longitudinal', 0.16), ('slope', 0.158), ('drugs', 0.148), ('covariates', 0.145), ('multilevel', 0.139), ('effects', 0.139), ('population', 0.126), ('prescribing', 0.112), ('puerto', 0.112), ('rico', 0.112), ('wu', 0.112), ('use', 0.108), ('dummies', 0.105), ('superpopulation', 0.105), ('exchangeability', 0.101), ('twins', 0.101), ('dummy', 0.101), ('australia', 0.094), ('variations', 0.094), ('expect', 0.089), ('states', 0.088), ('fred', 0.086), ('slopes', 0.085), ('usa', 0.079), ('justification', 0.078), ('modeling', 0.078), ('database', 0.077), ('state', 0.075), ('planned', 0.073), ('representing', 0.072), ('waiting', 0.071), ('preference', 0.071), ('services', 0.071), ('using', 0.07), ('estimate', 0.07), ('squares', 0.07), ('accurately', 0.07), ('division', 0.068), ('capture', 0.068), ('sitting', 0.065), ('network', 0.064), ('situations', 0.063), ('definition', 0.063)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1194-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>Introduction: Fred Wu writes: 
  
  
I work at National Prescribing Services in Australia.  I have a database representing say, antidiabetic drug utilisation for the entire Australia in the past few years. I planned to do a longitudinal analysis across GP Division Network (112 divisions in AUS) using mixed-effects models (or as you called in your book varying intercept and varying slope) on this data. 


The problem here is: as data actually represent the population who use antidiabetic drugs in AUS, should I use 112 fixed dummy variables to capture the random variations or use varying intercept and varying slope for the model ? Because some one may aruge, like divisions in AUS or states in USA can hardly be considered from a “superpopulation”, then fixed dummies should be used.  What I think is the population are those who use the drugs, what will happen when the rest need to use them? In terms of exchangeability, using varying intercept and varying slopes can be justified.


Also you provided in y</p><p>2 0.25873703 <a title="1194-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>Introduction: Someone writes:
  
I am hoping you can give me some advice about when to use fixed and random effects model. I am currently working on a paper that examines the effect of . . . by comparing states . . .


It got reviewed . . . by three economists and all suggest that we run a fixed effects model.  We ran a hierarchial model in the paper that allow the intercept and slope to vary before and after . . . My question is which is correct? We have ran it both ways and really it makes no difference which model you run, the results are very similar. But for my own learning, I would really like to understand which to use under what circumstances.  Is the fact that we use the whole population reason enough to just run a fixed effect model?


Perhaps you can suggest a good reference to this question of when to run a fixed vs. random effects model.
  
I’m not always sure what is meant by a “fixed effects model”; see my paper on Anova for discussion of the problems with this terminology:
 
http://w</p><p>3 0.24217615 <a title="1194-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>Introduction: Lee Mobley writes:
  
I recently read what you posted on your blog  How does statistical analysis differ when analyzing the entire population rather than a sample? 


What you said in the blog accords with my training in econometrics.  However I am concerned about a new wrinkle on this problem that derives from multilevel modeling.
      
We are analyzing multilevel models of the probability of using cancer screening for the entire Medicare population. I argue that every state has different systems in place (politics, cancer control efforts, culture, insurance regulations, etc) so that essentially a different probability generating mechanism is in place for each state. Thus I estimate 50 separate regressions for the populations in each state, and then note and map the variability in the effect estimates (slope parameters) for each covariate.


Reviewers argue that I should be using random slopes modeling, pooling all individuals in all states together. I am familiar with this approach</p><p>4 0.21034141 <a title="1194-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Fixed_effects_and_identification.html">1241 andrew gelman stats-2012-04-02-Fixed effects and identification</a></p>
<p>Introduction: Tom Clark writes:
  
Drew Linzer and I [Tom] have been working on a paper about the use of modeled (“random”) and unmodeled (“fixed”) effects. Not directly in response to the paper, but in conversations about the topic over the past few months, several people have said to us things to the effect of “I prefer fixed effects over random effects because I care about identification.” Neither Drew nor I has any idea what this comment is supposed to mean. Have you come across someone saying something like this? Do you have any thoughts about what these people could possibly mean? I want to respond to this concern when people raise it, but I have failed thus far to inquire what is meant and so do not know what to say.
  
My reply:
 
I have a “cultural” reply, which is that so-called fixed effects are thought to make fewer assumptions, and making fewer assumptions is considered a generally good thing that serious people do, and identification is considered a concern of serious people, so they g</p><p>5 0.19949117 <a title="1194-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>Introduction: Stuart Buck writes:
  
I have a question about  fixed effects vs. random effects . Amongst economists who study teacher value-added, it has become common to see people saying that they estimated teacher fixed effects (via least squares dummy variables, so that there is a parameter for each teacher), but that they then applied empirical Bayes shrinkage so that the teacher effects are brought closer to the mean.  (See  this paper  by Jacob and Lefgren, for example.)


Can that really be what they are doing? Why wouldn’t they just run random (modeled) effects in the first place? I feel like there’s something I’m missing.
  
My reply:  I don’t know the full story here, but I’m thinking there are two goals, first to get an unbiased estimate of an overall treatment effect (and there the econometricians prefer so-called fixed effects; I disagree with them on this but I know where they’re coming from) and second to estimate individual teacher effects (and there it makes sense to use so-called</p><p>6 0.19149579 <a title="1194-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>7 0.17055047 <a title="1194-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-Understanding_how_estimates_change_when_you_move_to_a_multilevel_model.html">850 andrew gelman stats-2011-08-11-Understanding how estimates change when you move to a multilevel model</a></p>
<p>8 0.14794041 <a title="1194-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<p>9 0.14295165 <a title="1194-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>10 0.13437 <a title="1194-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>11 0.13320123 <a title="1194-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>12 0.11628868 <a title="1194-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>13 0.11176059 <a title="1194-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-Varying_treatment_effects%2C_again.html">1310 andrew gelman stats-2012-05-09-Varying treatment effects, again</a></p>
<p>14 0.10988834 <a title="1194-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-A_new_R_package_for_fititng_multilevel_models.html">501 andrew gelman stats-2011-01-04-A new R package for fititng multilevel models</a></p>
<p>15 0.10965221 <a title="1194-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>16 0.10876937 <a title="1194-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>17 0.10805716 <a title="1194-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-Clutering_and_variance_components.html">417 andrew gelman stats-2010-11-17-Clutering and variance components</a></p>
<p>18 0.10706417 <a title="1194-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Sof%5Bt%5D.html">77 andrew gelman stats-2010-06-09-Sof[t]</a></p>
<p>19 0.10642289 <a title="1194-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>20 0.10536213 <a title="1194-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.148), (1, 0.085), (2, 0.106), (3, -0.041), (4, 0.077), (5, 0.037), (6, -0.005), (7, -0.046), (8, 0.061), (9, 0.077), (10, 0.01), (11, -0.032), (12, 0.055), (13, -0.018), (14, 0.104), (15, 0.035), (16, -0.071), (17, 0.028), (18, -0.019), (19, 0.022), (20, -0.014), (21, 0.009), (22, -0.023), (23, 0.018), (24, -0.042), (25, -0.115), (26, -0.121), (27, 0.113), (28, -0.015), (29, 0.051), (30, -0.038), (31, -0.054), (32, -0.051), (33, -0.018), (34, -0.007), (35, -0.007), (36, -0.022), (37, -0.027), (38, 0.024), (39, 0.014), (40, 0.024), (41, -0.018), (42, 0.005), (43, -0.011), (44, -0.072), (45, 0.01), (46, 0.033), (47, 0.0), (48, -0.053), (49, 0.002)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97606999 <a title="1194-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>Introduction: Fred Wu writes: 
  
  
I work at National Prescribing Services in Australia.  I have a database representing say, antidiabetic drug utilisation for the entire Australia in the past few years. I planned to do a longitudinal analysis across GP Division Network (112 divisions in AUS) using mixed-effects models (or as you called in your book varying intercept and varying slope) on this data. 


The problem here is: as data actually represent the population who use antidiabetic drugs in AUS, should I use 112 fixed dummy variables to capture the random variations or use varying intercept and varying slope for the model ? Because some one may aruge, like divisions in AUS or states in USA can hardly be considered from a “superpopulation”, then fixed dummies should be used.  What I think is the population are those who use the drugs, what will happen when the rest need to use them? In terms of exchangeability, using varying intercept and varying slopes can be justified.


Also you provided in y</p><p>2 0.84803814 <a title="1194-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>Introduction: Lee Mobley writes:
  
I recently read what you posted on your blog  How does statistical analysis differ when analyzing the entire population rather than a sample? 


What you said in the blog accords with my training in econometrics.  However I am concerned about a new wrinkle on this problem that derives from multilevel modeling.
      
We are analyzing multilevel models of the probability of using cancer screening for the entire Medicare population. I argue that every state has different systems in place (politics, cancer control efforts, culture, insurance regulations, etc) so that essentially a different probability generating mechanism is in place for each state. Thus I estimate 50 separate regressions for the populations in each state, and then note and map the variability in the effect estimates (slope parameters) for each covariate.


Reviewers argue that I should be using random slopes modeling, pooling all individuals in all states together. I am familiar with this approach</p><p>3 0.82288152 <a title="1194-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>Introduction: I received the following email from someone who wishes to remain anonymous:
  
My colleague and I are trying to understand the best way to approach a problem involving measuring a group of individuals’ abilities across time, and are hoping you can offer some guidance.


We are trying to analyze the combined effect of two distinct groups of people (A and B, with no overlap between A and B) who collaborate to produce a binary outcome, using a mixed logistic regression along the lines of the following.


Outcome ~ (1 | A) + (1 | B) + Other variables


What we’re interested in testing was whether the observed A random effects in period  1 are predictive of the A random effects in the following period 2.  Our idea being create two models, each using a different period’s worth of data, to create two sets of A coefficients, then observe the relationship between the two.  If the A’s have a persistent ability across periods, the coefficients should be correlated or show a linear-ish relationshi</p><p>4 0.79350597 <a title="1194-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Fixed_effects_and_identification.html">1241 andrew gelman stats-2012-04-02-Fixed effects and identification</a></p>
<p>Introduction: Tom Clark writes:
  
Drew Linzer and I [Tom] have been working on a paper about the use of modeled (“random”) and unmodeled (“fixed”) effects. Not directly in response to the paper, but in conversations about the topic over the past few months, several people have said to us things to the effect of “I prefer fixed effects over random effects because I care about identification.” Neither Drew nor I has any idea what this comment is supposed to mean. Have you come across someone saying something like this? Do you have any thoughts about what these people could possibly mean? I want to respond to this concern when people raise it, but I have failed thus far to inquire what is meant and so do not know what to say.
  
My reply:
 
I have a “cultural” reply, which is that so-called fixed effects are thought to make fewer assumptions, and making fewer assumptions is considered a generally good thing that serious people do, and identification is considered a concern of serious people, so they g</p><p>5 0.78831702 <a title="1194-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>Introduction: Dean Eckles writes:
  
I remember reading on your blog that you were working on some tools to fit multilevel models that also include “fixed” effects — such as continuous predictors — that are also estimated with shrinkage (for example, an L1 or L2 penalty). Any new developments on this front?


I often find myself wanting to fit a multilevel model to some data, but also needing to include a number of “fixed” effects, mainly continuous variables. This makes me wary of overfitting to these predictors, so then I’d want to use some kind of shrinkage.


As far as I can tell, the main options for doing this now is by going fully Bayesian and using a Gibbs sampler. With MCMCglmm or BUGS/JAGS I could just specify a prior on the fixed effects that corresponds to a desired penalty. However, this is pretty slow, especially with a large data set and because I’d like to select the penalty parameter by cross-validation (which is where this isn’t very Bayesian I guess?).
  
My reply:
 
We allow info</p><p>6 0.77060294 <a title="1194-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>7 0.75913054 <a title="1194-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>8 0.7479744 <a title="1194-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>9 0.73036307 <a title="1194-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-10-R_vs._Stata%2C_or%2C_Different_ways_to_estimate_multilevel_models.html">269 andrew gelman stats-2010-09-10-R vs. Stata, or, Different ways to estimate multilevel models</a></p>
<p>10 0.71001351 <a title="1194-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-12-year_%2B_%281%7Cyear%29.html">851 andrew gelman stats-2011-08-12-year + (1|year)</a></p>
<p>11 0.705365 <a title="1194-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>12 0.70179462 <a title="1194-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<p>13 0.70069742 <a title="1194-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>14 0.70025396 <a title="1194-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-Understanding_how_estimates_change_when_you_move_to_a_multilevel_model.html">850 andrew gelman stats-2011-08-11-Understanding how estimates change when you move to a multilevel model</a></p>
<p>15 0.69584805 <a title="1194-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>16 0.6897397 <a title="1194-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>17 0.68931323 <a title="1194-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>18 0.68791026 <a title="1194-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-Clutering_and_variance_components.html">417 andrew gelman stats-2010-11-17-Clutering and variance components</a></p>
<p>19 0.68488199 <a title="1194-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>20 0.67426068 <a title="1194-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Sof%5Bt%5D.html">77 andrew gelman stats-2010-06-09-Sof[t]</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(7, 0.224), (16, 0.072), (24, 0.138), (31, 0.017), (32, 0.011), (42, 0.015), (45, 0.012), (47, 0.03), (48, 0.013), (59, 0.011), (82, 0.012), (89, 0.023), (99, 0.296)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95048237 <a title="1194-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-27-Art-math.html">1592 andrew gelman stats-2012-11-27-Art-math</a></p>
<p>Introduction: This  seems like the sort of thing I would like:
 
Drawing from My Mind’s Eye: 
Dorothea Rockburne in Conversation with David Cohen 
Introduced by Nina Samuel
 
Thursday, November 29 
6 pm 
BGC, 38 West 86th Street
 
Benoît Mandelbrot, unusual among mathematicians of the twentieth century, harnessed the power of visual images to express his theories and to pursue new lines of thought. In this conversation artist Dorothea Rockburne will share memories of studying with mathematician Max Dehn at Black Mountain College, of meeting Mandelbrot, and discuss her recent work.
 
Exhibition curator Nina Samuel will discuss the related exhibition “The Islands of Benoît Mandelbrot: Fractals, Chaos, and the Materiality of Thinking,” on view in the BGC Focus Gallery through January 27, 2013.
 
  
   
David Cohen is editor and publisher of artcritical.com as well as founder and moderator of The Review Panel.
 
Dorothea Rockburne is a distinguished artist whose work has been inspired by her lifelong st</p><p>2 0.94515723 <a title="1194-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-27-Caffeine_keeps_your_Mac_awake.html">975 andrew gelman stats-2011-10-27-Caffeine keeps your Mac awake</a></p>
<p>Introduction: Sometimes my computer goes blank when I’m giving a presentation and I haven’t clicked on anything for awhile.  I mentioned this to Malecki and he installed  Caffeine  on my computer; problem solved.</p><p>3 0.9306885 <a title="1194-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-08-Ethical_standards_in_different_data_communities.html">1525 andrew gelman stats-2012-10-08-Ethical standards in different data communities</a></p>
<p>Introduction: I opened the paper today and saw  this  from Paul Krugman, on
  
Jack Welch, the former chairman of General Electric, who posted an assertion on Twitter that the [recent unemployment data] had been cooked to help President Obama’s re-election campaign. His claim was quickly picked up by right-wing pundits and media personalities.


It was nonsense, of course. Job numbers are prepared by professional civil servants, at an agency that currently has no political appointees. But then maybe Mr. Welch — under whose leadership G.E. reported remarkably smooth earnings growth, with none of the short-term fluctuations you might have expected (fluctuations that reappeared under his successor) — doesn’t know how hard it would be to cook the jobs data.
  
I was curious so I googled *general electric historical earnings*.  It was surprisingly difficult to find the numbers!  Most of the links just went back to 2011, or to 2008.  Eventually I came across  this blog  by Barry Ritholtz that showed this</p><p>4 0.92649829 <a title="1194-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-20-Non-statistical_thinking_in_the_US_foreign_policy_establishment.html">721 andrew gelman stats-2011-05-20-Non-statistical thinking in the US foreign policy establishment</a></p>
<p>Introduction: I’m a few weeks behind in my New Yorker reading and so just recently read  this fascinating article  by Ryan Lizza on the current administration’s foreign policy.  He gives some insights into the transformation Obama from antiwar candidate to a president conducting three wars.
 
Speaking as a statistician, though, what grabbed my eye was a doctrine of journalist/professor/policymaker Samantha Power.  Lizza writes:
  
In 2002, after graduating from Harvard Law School, she wrote “A Problem from Hell,” which surveyed the grim history of six genocides committed in the twentieth century. Propounding a liberal-interventionist view, Power argued that “mass killing” on the scale of Rwanda or Bosnia must be prevented by other nations, including the United States. She wrote that America and its allies rarely have perfect information about when a regime is about to commit genocide; a President, therefore, must have “a bias toward belief” that massacres are imminent.
  
From a statistical perspect</p><p>same-blog 5 0.91728723 <a title="1194-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>Introduction: Fred Wu writes: 
  
  
I work at National Prescribing Services in Australia.  I have a database representing say, antidiabetic drug utilisation for the entire Australia in the past few years. I planned to do a longitudinal analysis across GP Division Network (112 divisions in AUS) using mixed-effects models (or as you called in your book varying intercept and varying slope) on this data. 


The problem here is: as data actually represent the population who use antidiabetic drugs in AUS, should I use 112 fixed dummy variables to capture the random variations or use varying intercept and varying slope for the model ? Because some one may aruge, like divisions in AUS or states in USA can hardly be considered from a “superpopulation”, then fixed dummies should be used.  What I think is the population are those who use the drugs, what will happen when the rest need to use them? In terms of exchangeability, using varying intercept and varying slopes can be justified.


Also you provided in y</p><p>6 0.91168016 <a title="1194-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-03-Somebody_listened_to_me%21.html">1603 andrew gelman stats-2012-12-03-Somebody listened to me!</a></p>
<p>7 0.90931785 <a title="1194-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-21-%E2%80%9CHow_segregated_is_your_city%3F%E2%80%9D%3A__A_story_of_why_every_graph%2C_no_matter_how_clear_it_seems_to_be%2C_needs_a_caption_to_anchor_the_reader_in_some_numbers.html">289 andrew gelman stats-2010-09-21-“How segregated is your city?”:  A story of why every graph, no matter how clear it seems to be, needs a caption to anchor the reader in some numbers</a></p>
<p>8 0.89902431 <a title="1194-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-31-Fowlerpalooza%21.html">1699 andrew gelman stats-2013-01-31-Fowlerpalooza!</a></p>
<p>9 0.89476049 <a title="1194-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-09-San_Fernando_Valley_cityscapes%3A__An_example_of_the_benefits_of_fractal_devastation%3F.html">2165 andrew gelman stats-2014-01-09-San Fernando Valley cityscapes:  An example of the benefits of fractal devastation?</a></p>
<p>10 0.885472 <a title="1194-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-09-Kaggle%3A__forecasting_competitions_in_the_classroom.html">402 andrew gelman stats-2010-11-09-Kaggle:  forecasting competitions in the classroom</a></p>
<p>11 0.8761282 <a title="1194-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>12 0.86957908 <a title="1194-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-23-More_on_those_L.A._Times_estimates_of_teacher_effectiveness.html">226 andrew gelman stats-2010-08-23-More on those L.A. Times estimates of teacher effectiveness</a></p>
<p>13 0.86511928 <a title="1194-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-10-The_birthday_problem.html">1976 andrew gelman stats-2013-08-10-The birthday problem</a></p>
<p>14 0.85997719 <a title="1194-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-24-An_open_site_for_researchers_to_post_and_share_papers.html">2304 andrew gelman stats-2014-04-24-An open site for researchers to post and share papers</a></p>
<p>15 0.85725057 <a title="1194-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-02-What_is_it_with_Americans_in_Olympic_ski_teams_from_tropical_countries%3F.html">2230 andrew gelman stats-2014-03-02-What is it with Americans in Olympic ski teams from tropical countries?</a></p>
<p>16 0.85154015 <a title="1194-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-14-In_an_introductory_course%2C_when_does_learning_occur%3F.html">277 andrew gelman stats-2010-09-14-In an introductory course, when does learning occur?</a></p>
<p>17 0.84460217 <a title="1194-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Online_Education_and_Jazz.html">1752 andrew gelman stats-2013-03-06-Online Education and Jazz</a></p>
<p>18 0.83790386 <a title="1194-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-13-Retractions%2C_retractions%3A__%E2%80%9Cleft-wing_enough_to_not_care_about_truth_if_it_confirms_their_social_theories%2C_right-wing_enough_to_not_care_as_long_as_they%E2%80%99re_getting_paid_enough%E2%80%9D.html">1415 andrew gelman stats-2012-07-13-Retractions, retractions:  “left-wing enough to not care about truth if it confirms their social theories, right-wing enough to not care as long as they’re getting paid enough”</a></p>
<p>19 0.83678484 <a title="1194-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>20 0.83334762 <a title="1194-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-05-Update_on_state_size_and_governors%E2%80%99_popularity.html">187 andrew gelman stats-2010-08-05-Update on state size and governors’ popularity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
