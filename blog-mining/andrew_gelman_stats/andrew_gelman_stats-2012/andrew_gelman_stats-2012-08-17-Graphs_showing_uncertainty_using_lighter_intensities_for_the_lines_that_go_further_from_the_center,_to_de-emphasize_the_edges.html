<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1461" href="#">andrew_gelman_stats-2012-1461</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1461-html" href="http://andrewgelman.com/2012/08/17/graphs-showing-uncertainty-using-lighter-intensities-for-the-lines-that-go-further-from-the-center-to-de-emphasize-the-edges/">html</a></p><p>Introduction: Following up on our  recent discussion  of visually-weighted displays of uncertainty in regression curves, Lucas Leeman sent in the following two graphs:
 
First, the basic spaghetti-style plot showing inferential uncertainty in the E(y|x) curve:
 
   
 
Then, a version using even lighter intensities for the lines that go further from the center, to further de-emphasize the edges:
 
   
 
P.S.  More (including code!)  here .</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('intensities', 0.319), ('leeman', 0.319), ('uncertainty', 0.297), ('lucas', 0.286), ('lighter', 0.278), ('edges', 0.261), ('curves', 0.236), ('inferential', 0.222), ('displays', 0.22), ('curve', 0.204), ('following', 0.178), ('plot', 0.162), ('center', 0.161), ('showing', 0.154), ('lines', 0.154), ('version', 0.149), ('code', 0.148), ('basic', 0.137), ('sent', 0.132), ('graphs', 0.125), ('regression', 0.108), ('including', 0.107), ('recent', 0.087), ('discussion', 0.083), ('go', 0.076), ('using', 0.071), ('first', 0.066), ('two', 0.064), ('even', 0.051)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1461-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-17-Graphs_showing_uncertainty_using_lighter_intensities_for_the_lines_that_go_further_from_the_center%2C_to_de-emphasize_the_edges.html">1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</a></p>
<p>Introduction: Following up on our  recent discussion  of visually-weighted displays of uncertainty in regression curves, Lucas Leeman sent in the following two graphs:
 
First, the basic spaghetti-style plot showing inferential uncertainty in the E(y|x) curve:
 
   
 
Then, a version using even lighter intensities for the lines that go further from the center, to further de-emphasize the edges:
 
   
 
P.S.  More (including code!)  here .</p><p>2 0.35668623 <a title="1461-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-09-Visually_weighting_regression_displays.html">1452 andrew gelman stats-2012-08-09-Visually weighting regression displays</a></p>
<p>Introduction: Solomon Hsiang  writes :
  
One of my colleagues suggested that I send you  this very short note  that I wrote on a new approach for displaying regression result uncertainty (attached). It’s very simple, and I’ve found it effective in one of my papers where I actually use it, but if you have a chance to glance over it and have any ideas for how to sell the approach or make it better, I’d be very interested to hear them. (Also, if you’ve seen that someone else has already made this point, I’d appreciate knowing that too.)
  
Here’s an example:
 
   
 
Hsiang writes:
  
In Panel A, our eyes are drawn outward, away from the center of the display and toward the swirling confidence intervals at the edges. But in Panel B, our eyes are attracted to the middle of the regression line, where the high contrast between the line and the background is sharp and visually heavy. By using visual-weighting, we focus our readers’s attention on those portions of the regression that contain the most inform</p><p>3 0.19167976 <a title="1461-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-21-Model_complexity_as_a_function_of_sample_size.html">1543 andrew gelman stats-2012-10-21-Model complexity as a function of sample size</a></p>
<p>Introduction: As we get more data, we can fit more model.  But at some point we become so overwhelmed by data that, for computational reasons, we can barely do anything at all.  Thus, the curve above could be thought of as the product of two curves:  a steadily increasing curve showing the  statistical  ability to fit more complex models with more data, and a steadily decreasing curve showing the  computational  feasibility of doing so.</p><p>4 0.15534928 <a title="1461-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>Introduction: A sociologist writes in:
  
Samuel Lucas has just published  a paper  in Quality and Quantity arguing that anything less than a full probability sample of higher levels in HLMs yields biased and unusable results. If I follow him correctly, he is arguing that not only are the SEs too small, but the parameter estimates themselves are biased and we cannot say in advance whether the bias is positive or negative.


Lucas has thrown down a big gauntlet, advising us throw away our data unless the sample of macro units is right and ignore the published results that fail this standard. Extreme. 
Is there another conclusion to be drawn? 
Other advice to be given? 
A Bayesian path out of the valley?
  
Heres’s the abstract to Lucas’s paper:
  
The multilevel model has become a staple of social research. I textually and formally explicate sample design features that, I contend, are required for unbiased estimation of macro-level multilevel model parameters and the use of tools for statistical infe</p><p>5 0.12961958 <a title="1461-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>Introduction: After  our discussion  of visual displays of regression uncertainty, I asked Solomon Hsiang and Lucas Leeman to send me their code.  Both of them replied.
 
Solomon wrote: 
  
  
The matlab and stata functions I wrote, as well as the script that replicates my figures, are all posted on  my website .


Also, I just added options to the main matlab function (vwregress.m) to make it display the spaghetti plot (similar to what Lucas did, but a simple bootstrap) and the shaded CI that you suggested (see figs below). They’re good suggestions.


   


   


Personally, I [Hsiang] like the shaded CI better, since I think that all the visual activity in the spaghetti plot is a little distracting and sometimes adds visual weight in places where I wouldn’t want it.  But the option is there in case people like it.
  
Solomon then followed up with:
  
I just thought of this small adjustment to your filled CI idea that seems neat. Cartographers like map projections that conserve area.  We can do som</p><p>6 0.12020929 <a title="1461-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-31-Watercolor_regression.html">1478 andrew gelman stats-2012-08-31-Watercolor regression</a></p>
<p>7 0.097527713 <a title="1461-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-21-Stan_Model_of_the_Week%3A_Hierarchical_Modeling_of_Supernovas.html">2299 andrew gelman stats-2014-04-21-Stan Model of the Week: Hierarchical Modeling of Supernovas</a></p>
<p>8 0.094404116 <a title="1461-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-13-Checking_your_model_using_fake_data.html">852 andrew gelman stats-2011-08-13-Checking your model using fake data</a></p>
<p>9 0.093460374 <a title="1461-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-17-Joanne_Gowa_scooped_me_by_22_years_in_my_criticism_of_Axelrod%E2%80%99s_Evolution_of_Cooperation.html">348 andrew gelman stats-2010-10-17-Joanne Gowa scooped me by 22 years in my criticism of Axelrod’s Evolution of Cooperation</a></p>
<p>10 0.090964265 <a title="1461-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-14-The_statistics_and_the_science.html">146 andrew gelman stats-2010-07-14-The statistics and the science</a></p>
<p>11 0.089210428 <a title="1461-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-21-Instead_of_%E2%80%9Cconfidence_interval%2C%E2%80%9D_let%E2%80%99s_say_%E2%80%9Cuncertainty_interval%E2%80%9D.html">480 andrew gelman stats-2010-12-21-Instead of “confidence interval,” let’s say “uncertainty interval”</a></p>
<p>12 0.084685296 <a title="1461-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-23-Lowess_is_great.html">293 andrew gelman stats-2010-09-23-Lowess is great</a></p>
<p>13 0.08035849 <a title="1461-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-R_needs_a_good_function_to_make_line_plots.html">252 andrew gelman stats-2010-09-02-R needs a good function to make line plots</a></p>
<p>14 0.078804426 <a title="1461-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Bayesian_Uncertainty_Quantification_for_Differential_Equations%21.html">2311 andrew gelman stats-2014-04-29-Bayesian Uncertainty Quantification for Differential Equations!</a></p>
<p>15 0.077253945 <a title="1461-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-01-Martin_and_Liu%3A__Probabilistic_inference_based_on_consistency_of_model_with_data.html">1095 andrew gelman stats-2012-01-01-Martin and Liu:  Probabilistic inference based on consistency of model with data</a></p>
<p>16 0.075797856 <a title="1461-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Let%E2%80%99s_play_%E2%80%9CGuess_the_smoother%E2%80%9D%21.html">1283 andrew gelman stats-2012-04-26-Let’s play “Guess the smoother”!</a></p>
<p>17 0.07574413 <a title="1461-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-12-How_to_best_graph_the_Beveridge_curve%2C_relating_the_vacancy_rate_in_jobs_to_the_unemployment_rate%3F.html">1894 andrew gelman stats-2013-06-12-How to best graph the Beveridge curve, relating the vacancy rate in jobs to the unemployment rate?</a></p>
<p>18 0.074215002 <a title="1461-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-27-A_use_for_tables_%28really%29.html">372 andrew gelman stats-2010-10-27-A use for tables (really)</a></p>
<p>19 0.071170874 <a title="1461-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-18-Course_proposal%3A_Bayesian_and_advanced_likelihood_statistical_methods_for_zombies..html">96 andrew gelman stats-2010-06-18-Course proposal: Bayesian and advanced likelihood statistical methods for zombies.</a></p>
<p>20 0.07035327 <a title="1461-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Contest_for_developing_an_R_package_recommendation_system.html">324 andrew gelman stats-2010-10-07-Contest for developing an R package recommendation system</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.083), (1, 0.014), (2, 0.007), (3, 0.023), (4, 0.101), (5, -0.071), (6, -0.05), (7, -0.022), (8, -0.009), (9, 0.0), (10, 0.013), (11, -0.006), (12, -0.014), (13, -0.002), (14, 0.006), (15, 0.018), (16, 0.02), (17, -0.003), (18, -0.024), (19, -0.026), (20, 0.056), (21, 0.07), (22, 0.028), (23, -0.017), (24, 0.029), (25, -0.014), (26, 0.038), (27, -0.062), (28, 0.003), (29, 0.008), (30, 0.052), (31, 0.01), (32, -0.06), (33, 0.004), (34, -0.008), (35, -0.067), (36, -0.022), (37, 0.042), (38, 0.034), (39, -0.065), (40, 0.041), (41, 0.048), (42, 0.038), (43, 0.01), (44, 0.065), (45, 0.006), (46, -0.069), (47, 0.072), (48, 0.034), (49, -0.05)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98602194 <a title="1461-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-17-Graphs_showing_uncertainty_using_lighter_intensities_for_the_lines_that_go_further_from_the_center%2C_to_de-emphasize_the_edges.html">1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</a></p>
<p>Introduction: Following up on our  recent discussion  of visually-weighted displays of uncertainty in regression curves, Lucas Leeman sent in the following two graphs:
 
First, the basic spaghetti-style plot showing inferential uncertainty in the E(y|x) curve:
 
   
 
Then, a version using even lighter intensities for the lines that go further from the center, to further de-emphasize the edges:
 
   
 
P.S.  More (including code!)  here .</p><p>2 0.82251257 <a title="1461-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-31-Watercolor_regression.html">1478 andrew gelman stats-2012-08-31-Watercolor regression</a></p>
<p>Introduction: Solomon Hsiang writes:
  
Two small follow-ups based on the  discussion  (the second/bigger one is to address your comment about the 95% CI edges).


1. I realized that if we plot the confidence intervals as a solid color that fades (eg. using the “fixed ink” scheme from before) we can make sure the regression line also has heightened visual weight where confidence is high by plotting the line white. This makes the contrast (and thus visual weight) between the regression line and the CI highest when the CI is narrow and dark. As the CI fade near the edges, so does the contrast with the regression line. This is a small adjustment, but I like it because it is so simple and it makes the graph much nicer. (see “visually_weighted_fill_reverse” attached). My posted code has been updated to do this automatically.


2. You and your readers didn’t like that the edges of the filled CI were so sharp and arbitrary. But I didn’t like that the contrast between the spaghetti lines and the background</p><p>3 0.82207865 <a title="1461-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-09-Visually_weighting_regression_displays.html">1452 andrew gelman stats-2012-08-09-Visually weighting regression displays</a></p>
<p>Introduction: Solomon Hsiang  writes :
  
One of my colleagues suggested that I send you  this very short note  that I wrote on a new approach for displaying regression result uncertainty (attached). It’s very simple, and I’ve found it effective in one of my papers where I actually use it, but if you have a chance to glance over it and have any ideas for how to sell the approach or make it better, I’d be very interested to hear them. (Also, if you’ve seen that someone else has already made this point, I’d appreciate knowing that too.)
  
Here’s an example:
 
   
 
Hsiang writes:
  
In Panel A, our eyes are drawn outward, away from the center of the display and toward the swirling confidence intervals at the edges. But in Panel B, our eyes are attracted to the middle of the regression line, where the high contrast between the line and the background is sharp and visually heavy. By using visual-weighting, we focus our readers’s attention on those portions of the regression that contain the most inform</p><p>4 0.75579858 <a title="1461-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>Introduction: After  our discussion  of visual displays of regression uncertainty, I asked Solomon Hsiang and Lucas Leeman to send me their code.  Both of them replied.
 
Solomon wrote: 
  
  
The matlab and stata functions I wrote, as well as the script that replicates my figures, are all posted on  my website .


Also, I just added options to the main matlab function (vwregress.m) to make it display the spaghetti plot (similar to what Lucas did, but a simple bootstrap) and the shaded CI that you suggested (see figs below). They’re good suggestions.


   


   


Personally, I [Hsiang] like the shaded CI better, since I think that all the visual activity in the spaghetti plot is a little distracting and sometimes adds visual weight in places where I wouldn’t want it.  But the option is there in case people like it.
  
Solomon then followed up with:
  
I just thought of this small adjustment to your filled CI idea that seems neat. Cartographers like map projections that conserve area.  We can do som</p><p>5 0.68005717 <a title="1461-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-The_R_code_for_those_time-use_graphs.html">672 andrew gelman stats-2011-04-20-The R code for those time-use graphs</a></p>
<p>Introduction: By popular demand, hereâ&euro;&trade;s my R script for the  time-use graphs :
  

 
 
# The data
a1 <- c(4.2,3.2,11.1,1.3,2.2,2.0)
a2 <- c(3.9,3.2,10.0,0.8,3.1,3.1)
a3 <- c(6.3,2.5,9.8,0.9,2.2,2.4)
a4 <- c(4.4,3.1,9.8,0.8,3.3,2.7)
a5 <- c(4.8,3.0,9.9,0.7,3.3,2.4)
a6 <- c(4.0,3.4,10.5,0.7,3.3,2.1)
a <- rbind(a1,a2,a3,a4,a5,a6)
avg <- colMeans (a)
avg.array <- t (array (avg, rev(dim(a))))
diff <- a - avg.array
country.name <- c("France", "Germany", "Japan", "Britain", "USA", "Turkey")

# The line plots

par (mfrow=c(2,3), mar=c(4,4,2,.5), mgp=c(2,.7,0), tck=-.02, oma=c(3,0,4,0),
  bg="gray96", fg="gray30")
for (i in 1:6){
  plot (c(1,6), c(-1,1.7), xlab="", ylab="", xaxt="n", yaxt="n",
    bty="l", type="n")
  lines (1:6, diff[i,], col="blue")
  points (1:6, diff[i,], pch=19, col="black")
  if (i>3){
    axis (1, c(1,3,5), c ("Work,\nstudy", "Eat,\nsleep",
      "Leisure"), mgp=c(2,1.5,0), tck=0, cex.axis=1.2)
    axis (1, c(2,4,6), c ("Unpaid\nwork",
      "Personal\nCare", "Other"), mgp=c(2,1.5,0),</p><p>6 0.66389805 <a title="1461-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Let%E2%80%99s_play_%E2%80%9CGuess_the_smoother%E2%80%9D%21.html">1283 andrew gelman stats-2012-04-26-Let’s play “Guess the smoother”!</a></p>
<p>7 0.63740319 <a title="1461-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-R_needs_a_good_function_to_make_line_plots.html">252 andrew gelman stats-2010-09-02-R needs a good function to make line plots</a></p>
<p>8 0.63523293 <a title="1461-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-23-Lowess_is_great.html">293 andrew gelman stats-2010-09-23-Lowess is great</a></p>
<p>9 0.60222059 <a title="1461-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-29-I%E2%80%99m_looking_for_a_quadrille_notebook_with_faint_lines.html">1235 andrew gelman stats-2012-03-29-I’m looking for a quadrille notebook with faint lines</a></p>
<p>10 0.57207298 <a title="1461-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-27-Visual_diagnostics_for_discrete-data_regressions.html">929 andrew gelman stats-2011-09-27-Visual diagnostics for discrete-data regressions</a></p>
<p>11 0.55756909 <a title="1461-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-28-%E2%80%9C._._._extending_for_dozens_of_pages%E2%80%9D.html">1090 andrew gelman stats-2011-12-28-“. . . extending for dozens of pages”</a></p>
<p>12 0.55574781 <a title="1461-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-16-Choices_in_graphing_parallel_time_series.html">1498 andrew gelman stats-2012-09-16-Choices in graphing parallel time series</a></p>
<p>13 0.55272746 <a title="1461-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-10-Why_display_6_years_instead_of_30%3F.html">1258 andrew gelman stats-2012-04-10-Why display 6 years instead of 30?</a></p>
<p>14 0.55126673 <a title="1461-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-13-Hey%21__Here%E2%80%99s_a_referee_report_for_you%21.html">144 andrew gelman stats-2010-07-13-Hey!  Here’s a referee report for you!</a></p>
<p>15 0.54937679 <a title="1461-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-26-A_simple_semigraphic_display.html">296 andrew gelman stats-2010-09-26-A simple semigraphic display</a></p>
<p>16 0.54197824 <a title="1461-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Contest_for_developing_an_R_package_recommendation_system.html">324 andrew gelman stats-2010-10-07-Contest for developing an R package recommendation system</a></p>
<p>17 0.5368492 <a title="1461-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Stephen_Kosslyn%E2%80%99s_principles_of_graphics_and_one_more%3A__There%E2%80%99s_no_need_to_cram_everything_into_a_single_plot.html">1609 andrew gelman stats-2012-12-06-Stephen Kosslyn’s principles of graphics and one more:  There’s no need to cram everything into a single plot</a></p>
<p>18 0.53440523 <a title="1461-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-01-A_book_with_a_bunch_of_simple_graphs.html">1439 andrew gelman stats-2012-08-01-A book with a bunch of simple graphs</a></p>
<p>19 0.53171629 <a title="1461-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-18-Course_proposal%3A_Bayesian_and_advanced_likelihood_statistical_methods_for_zombies..html">96 andrew gelman stats-2010-06-18-Course proposal: Bayesian and advanced likelihood statistical methods for zombies.</a></p>
<p>20 0.531268 <a title="1461-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-14-The_statistics_and_the_science.html">146 andrew gelman stats-2010-07-14-The statistics and the science</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(14, 0.258), (16, 0.078), (21, 0.04), (24, 0.07), (51, 0.042), (89, 0.04), (90, 0.051), (99, 0.265)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.939937 <a title="1461-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Recently_in_the_award-winning_sister_blog.html">755 andrew gelman stats-2011-06-09-Recently in the award-winning sister blog</a></p>
<p>Introduction: In case you haven’t been following:
 
-  Top ten excuses  for plagiarism
 
- Why I  won’t be sad  to see Anthony Weiner retire
 
- U.S. voter participation  has not  fallen steadily over the past few decades
 
- Scott Adams had an  interesting idea</p><p>2 0.92133176 <a title="1461-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-NUTS_discussed_on_Xi%E2%80%99an%E2%80%99s_Og.html">1809 andrew gelman stats-2013-04-17-NUTS discussed on Xi’an’s Og</a></p>
<p>Introduction: Xi’an’s Og  (aka Christian Robert’s blog) is featuring a very nice  presentation of NUTS  by Marco Banterle, with discussion and some suggestions.
 
I’m not even sure how they found Michael Betancourt’s paper on geometric NUTS — I don’t see it on the arXiv yet, or I’d provide a link.</p><p>3 0.91254222 <a title="1461-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-16-Zero_Dark_Thirty_and_Bayes%E2%80%99_theorem.html">1724 andrew gelman stats-2013-02-16-Zero Dark Thirty and Bayes’ theorem</a></p>
<p>Introduction: A moviegoing colleague writes:
  
I just watched the movie Zero Dark Thirty about the hunt for Osama Bin Laden.  What struck me about it was: (1) Bayes theorem underlies the whole movie; (2) CIA top brass do not know Bayes theorem (at least as portrayed in the movie).


Obviously one does not need to know physics to play billiards, but it helps with the reasoning.


Essentially, at some point the key CIA agent locates what she strongly believes is OBL’s hidding place in Pakistan.  Then it takes the White House some 150 days to make the decision to attack the compound.  Why so long? And why, even on the eve of the operation, were senior brass only some 60% OBL was there?  


Fear of false positives is the answer.  After all, the compound could belong to a drug lord, or some other terrorist.  Here is the math:


There are two possibilities, according to movie: OBL is in a compound (C) in a city or he is in the mountains in tribal regions.  Say P(OBL in C) = 0.5.


A diagnosis is made on</p><p>same-blog 4 0.90194523 <a title="1461-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-17-Graphs_showing_uncertainty_using_lighter_intensities_for_the_lines_that_go_further_from_the_center%2C_to_de-emphasize_the_edges.html">1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</a></p>
<p>Introduction: Following up on our  recent discussion  of visually-weighted displays of uncertainty in regression curves, Lucas Leeman sent in the following two graphs:
 
First, the basic spaghetti-style plot showing inferential uncertainty in the E(y|x) curve:
 
   
 
Then, a version using even lighter intensities for the lines that go further from the center, to further de-emphasize the edges:
 
   
 
P.S.  More (including code!)  here .</p><p>5 0.88618594 <a title="1461-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Milo_and_Milo.html">824 andrew gelman stats-2011-07-26-Milo and Milo</a></p>
<p>Introduction: I recently finished two enjoyable novels that I was pretty sure I’d like, given that they were both sequels of a sort.  The main characters of both books were named Milo, a name that in literature appears only (to my knowledge) in The Phantom Tollbooth and Catch-22.
 
The Milos in the new books I just read are much different than the two classic literary Milos.  One, featured in the new thriller by  Olen Steinhauer , is a cool, effective CIA killing machine (but of the good-guy variety, also he has some little character flaws to make him tolerable but he’s basically a superhero).  The other is not any sort of killing machine, more of more of a Sam Lipsyte character.  Which makes sense since he’s the star of The Ask, the follow-up to Lipsyte’s hilarious lovable-loser saga, Home Land.
 
I have two questions about The Ask.
 
1.  The driver of the plot is as follows.  Milo has just been fired from his crappy job at a college in NYC.  Milo has a rich friend who asks him to do a favor; in re</p><p>6 0.88265246 <a title="1461-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-07-A_False_Consensus_about_Public_Opinion_on_Torture.html">130 andrew gelman stats-2010-07-07-A False Consensus about Public Opinion on Torture</a></p>
<p>7 0.88207597 <a title="1461-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-10-Towards_a_Theory_of_Trust_in_Networks_of_Humans_and_Computers.html">1051 andrew gelman stats-2011-12-10-Towards a Theory of Trust in Networks of Humans and Computers</a></p>
<p>8 0.86195028 <a title="1461-lda-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-23-The_gremlins_did_it%3F__Iffy_statistics_drive_strong_policy_recommendations.html">2344 andrew gelman stats-2014-05-23-The gremlins did it?  Iffy statistics drive strong policy recommendations</a></p>
<p>9 0.85121536 <a title="1461-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-29-The_latest_in_economics_exceptionalism.html">1696 andrew gelman stats-2013-01-29-The latest in economics exceptionalism</a></p>
<p>10 0.84389418 <a title="1461-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-19-Retraction_watch.html">1770 andrew gelman stats-2013-03-19-Retraction watch</a></p>
<p>11 0.82993323 <a title="1461-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Predicting_marathon_times.html">245 andrew gelman stats-2010-08-31-Predicting marathon times</a></p>
<p>12 0.80220103 <a title="1461-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-06-I%E2%80%99m_skeptical_about_this_skeptical_article_about_left-handedness.html">1303 andrew gelman stats-2012-05-06-I’m skeptical about this skeptical article about left-handedness</a></p>
<p>13 0.79596686 <a title="1461-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-29-The_gradual_transition_to_replicable_science.html">2117 andrew gelman stats-2013-11-29-The gradual transition to replicable science</a></p>
<p>14 0.79050595 <a title="1461-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-27-Why_do_we_never_see_a_full_decision_analysis_for_a_clinical_trial%3F.html">1471 andrew gelman stats-2012-08-27-Why do we never see a full decision analysis for a clinical trial?</a></p>
<p>15 0.78122497 <a title="1461-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-29-Resolution_of_Diederik_Stapel_case.html">1236 andrew gelman stats-2012-03-29-Resolution of Diederik Stapel case</a></p>
<p>16 0.76732069 <a title="1461-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-12-Visualization%2C_%E2%80%9Cbig_data%E2%80%9D%2C_and_EDA.html">2059 andrew gelman stats-2013-10-12-Visualization, “big data”, and EDA</a></p>
<p>17 0.76167721 <a title="1461-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-04-Retraction_Watch.html">838 andrew gelman stats-2011-08-04-Retraction Watch</a></p>
<p>18 0.75401825 <a title="1461-lda-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-08-Disagreeing_to_disagree.html">2237 andrew gelman stats-2014-03-08-Disagreeing to disagree</a></p>
<p>19 0.75267553 <a title="1461-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-26-%E2%80%9CPlease_make_fun_of_this_claim%E2%80%9D.html">2114 andrew gelman stats-2013-11-26-“Please make fun of this claim”</a></p>
<p>20 0.75222182 <a title="1461-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-R_needs_a_good_function_to_make_line_plots.html">252 andrew gelman stats-2010-09-02-R needs a good function to make line plots</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
