<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1543 andrew gelman stats-2012-10-21-Model complexity as a function of sample size</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2012" href="../home/andrew_gelman_stats-2012_home.html">andrew_gelman_stats-2012</a> <a title="andrew_gelman_stats-2012-1543" href="#">andrew_gelman_stats-2012-1543</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1543 andrew gelman stats-2012-10-21-Model complexity as a function of sample size</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2012-1543-html" href="http://andrewgelman.com/2012/10/21/model-complexity-as-a-function-of-sample-size/">html</a></p><p>Introduction: As we get more data, we can fit more model.  But at some point we become so overwhelmed by data that, for computational reasons, we can barely do anything at all.  Thus, the curve above could be thought of as the product of two curves:  a steadily increasing curve showing the  statistical  ability to fit more complex models with more data, and a steadily decreasing curve showing the  computational  feasibility of doing so.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 But at some point we become so overwhelmed by data that, for computational reasons, we can barely do anything at all. [sent-2, score-1.063]
</p><p>2 Thus, the curve above could be thought of as the product of two curves:  a steadily increasing curve showing the  statistical  ability to fit more complex models with more data, and a steadily decreasing curve showing the  computational  feasibility of doing so. [sent-3, score-4.635]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('curve', 0.505), ('steadily', 0.41), ('computational', 0.281), ('feasibility', 0.263), ('showing', 0.254), ('overwhelmed', 0.224), ('decreasing', 0.212), ('barely', 0.202), ('curves', 0.195), ('fit', 0.18), ('product', 0.165), ('increasing', 0.147), ('ability', 0.13), ('complex', 0.129), ('reasons', 0.116), ('data', 0.113), ('become', 0.113), ('thus', 0.094), ('anything', 0.079), ('models', 0.07), ('thought', 0.069), ('statistical', 0.054), ('two', 0.052), ('point', 0.051), ('could', 0.04), ('get', 0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1543-tfidf-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-21-Model_complexity_as_a_function_of_sample_size.html">1543 andrew gelman stats-2012-10-21-Model complexity as a function of sample size</a></p>
<p>Introduction: As we get more data, we can fit more model.  But at some point we become so overwhelmed by data that, for computational reasons, we can barely do anything at all.  Thus, the curve above could be thought of as the product of two curves:  a steadily increasing curve showing the  statistical  ability to fit more complex models with more data, and a steadily decreasing curve showing the  computational  feasibility of doing so.</p><p>2 0.19167976 <a title="1543-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-17-Graphs_showing_uncertainty_using_lighter_intensities_for_the_lines_that_go_further_from_the_center%2C_to_de-emphasize_the_edges.html">1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</a></p>
<p>Introduction: Following up on our  recent discussion  of visually-weighted displays of uncertainty in regression curves, Lucas Leeman sent in the following two graphs:
 
First, the basic spaghetti-style plot showing inferential uncertainty in the E(y|x) curve:
 
   
 
Then, a version using even lighter intensities for the lines that go further from the center, to further de-emphasize the edges:
 
   
 
P.S.  More (including code!)  here .</p><p>3 0.18932134 <a title="1543-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-21-Stan_Model_of_the_Week%3A_Hierarchical_Modeling_of_Supernovas.html">2299 andrew gelman stats-2014-04-21-Stan Model of the Week: Hierarchical Modeling of Supernovas</a></p>
<p>Introduction: The Stan Model of the Week showcases research using Stan to push the limits of applied statistics.  If you have a model that you would like to submit for a future post then send us an  email . 
 
Our inaugural post comes from Nathan Sanders, a graduate student finishing up his thesis on astrophysics at Harvard. Nathan writes,
  
“Core-collapse supernovae, the luminous explosions of massive stars, exhibit an expansive and meaningful diversity of behavior in their brightness evolution over time (their “light curves”). Our group discovers and monitors these events using the Pan-STARRS1 telescope in Hawaii, and we’ve collected a dataset of about 20,000 individual photometric observations of about 80 Type IIP supernovae, the class my work has focused on. While this dataset provides one of the best available tools to infer the explosion properties of these supernovae, due to the nature of extragalactic astronomy (observing from distances 
  1 billion light years), these light curves typicall</p><p>4 0.17829351 <a title="1543-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Let%E2%80%99s_play_%E2%80%9CGuess_the_smoother%E2%80%9D%21.html">1283 andrew gelman stats-2012-04-26-Let’s play “Guess the smoother”!</a></p>
<p>Introduction: Andre de Boer writes:
  
In my profession as a risk manager I encountered this graph:


   


I can’t figure out what kind of regression this is, would you be so kind to enlighten me? 
The points represent (maturity,yield) of bonds.
  
My reply:  That’s a fun problem, reverse-engineering a curve fit!  My first guess is lowess, although it seems too flat and asympoty on the right side of the graph to be lowess.  Maybe a Gaussian process?  Looks too smooth to be a spline.  I guess I’ll go with my original guess, on the theory that lowess is the most accessible smoother out there, and if someone fit something much more complicated they’d make more of a big deal about it.  On the other hand, if the curve is an automatic output of some software (Excel? Stata?) then it could be just about anything.
 
Does anyone have any ideas?</p><p>5 0.1580193 <a title="1543-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-09-Visually_weighting_regression_displays.html">1452 andrew gelman stats-2012-08-09-Visually weighting regression displays</a></p>
<p>Introduction: Solomon Hsiang  writes :
  
One of my colleagues suggested that I send you  this very short note  that I wrote on a new approach for displaying regression result uncertainty (attached). It’s very simple, and I’ve found it effective in one of my papers where I actually use it, but if you have a chance to glance over it and have any ideas for how to sell the approach or make it better, I’d be very interested to hear them. (Also, if you’ve seen that someone else has already made this point, I’d appreciate knowing that too.)
  
Here’s an example:
 
   
 
Hsiang writes:
  
In Panel A, our eyes are drawn outward, away from the center of the display and toward the swirling confidence intervals at the edges. But in Panel B, our eyes are attracted to the middle of the regression line, where the high contrast between the line and the background is sharp and visually heavy. By using visual-weighting, we focus our readers’s attention on those portions of the regression that contain the most inform</p><p>6 0.15743043 <a title="1543-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-03-Reinventing_the_wheel%2C_only_more_so..html">447 andrew gelman stats-2010-12-03-Reinventing the wheel, only more so.</a></p>
<p>7 0.12024715 <a title="1543-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-12-How_to_best_graph_the_Beveridge_curve%2C_relating_the_vacancy_rate_in_jobs_to_the_unemployment_rate%3F.html">1894 andrew gelman stats-2013-06-12-How to best graph the Beveridge curve, relating the vacancy rate in jobs to the unemployment rate?</a></p>
<p>8 0.1076381 <a title="1543-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-16-Annals_of_really_really_stupid_spam.html">577 andrew gelman stats-2011-02-16-Annals of really really stupid spam</a></p>
<p>9 0.10751095 <a title="1543-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Recently_in_the_award-winning_sister_blog.html">755 andrew gelman stats-2011-06-09-Recently in the award-winning sister blog</a></p>
<p>10 0.10347376 <a title="1543-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-03-Boot.html">1881 andrew gelman stats-2013-06-03-Boot</a></p>
<p>11 0.099596277 <a title="1543-tfidf-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-22-Quickies.html">2220 andrew gelman stats-2014-02-22-Quickies</a></p>
<p>12 0.092854828 <a title="1543-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-21-Discussion_of_the_paper_by_Girolami_and_Calderhead_on_Bayesian_computation.html">288 andrew gelman stats-2010-09-21-Discussion of the paper by Girolami and Calderhead on Bayesian computation</a></p>
<p>13 0.091720991 <a title="1543-tfidf-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-21-Models_with_constraints.html">2342 andrew gelman stats-2014-05-21-Models with constraints</a></p>
<p>14 0.089598857 <a title="1543-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<p>15 0.077212878 <a title="1543-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-28-Simplify_until_your_fake-data_check_works%2C_then_add_complications_until_you_can_figure_out_where_the_problem_is_coming_from.html">1875 andrew gelman stats-2013-05-28-Simplify until your fake-data check works, then add complications until you can figure out where the problem is coming from</a></p>
<p>16 0.073636442 <a title="1543-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-21-The_future_%28and_past%29_of_statistical_sciences.html">2072 andrew gelman stats-2013-10-21-The future (and past) of statistical sciences</a></p>
<p>17 0.072136 <a title="1543-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<p>18 0.071819216 <a title="1543-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-13-Duke_postdoctoral_fellowships_in_nonparametric_Bayes_%26_high-dimensional_data.html">903 andrew gelman stats-2011-09-13-Duke postdoctoral fellowships in nonparametric Bayes & high-dimensional data</a></p>
<p>19 0.069290012 <a title="1543-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-06-Question_27_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1368 andrew gelman stats-2012-06-06-Question 27 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>20 0.069183081 <a title="1543-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-10-%E2%80%9CVersatile%2C_affordable_chicken_has_grown_in_popularity%E2%80%9D.html">655 andrew gelman stats-2011-04-10-“Versatile, affordable chicken has grown in popularity”</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.079), (1, 0.041), (2, -0.006), (3, 0.02), (4, 0.034), (5, -0.011), (6, -0.05), (7, -0.018), (8, 0.002), (9, 0.027), (10, 0.005), (11, 0.015), (12, -0.055), (13, -0.01), (14, -0.027), (15, -0.003), (16, 0.037), (17, -0.044), (18, -0.002), (19, -0.02), (20, 0.028), (21, 0.003), (22, -0.017), (23, -0.039), (24, 0.018), (25, -0.003), (26, -0.003), (27, -0.025), (28, 0.038), (29, -0.007), (30, 0.005), (31, -0.009), (32, -0.008), (33, 0.002), (34, -0.01), (35, 0.013), (36, -0.023), (37, 0.01), (38, -0.0), (39, -0.027), (40, 0.033), (41, 0.034), (42, 0.017), (43, 0.0), (44, 0.044), (45, -0.021), (46, -0.033), (47, 0.031), (48, 0.015), (49, -0.068)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.89913052 <a title="1543-lsi-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-21-Model_complexity_as_a_function_of_sample_size.html">1543 andrew gelman stats-2012-10-21-Model complexity as a function of sample size</a></p>
<p>Introduction: As we get more data, we can fit more model.  But at some point we become so overwhelmed by data that, for computational reasons, we can barely do anything at all.  Thus, the curve above could be thought of as the product of two curves:  a steadily increasing curve showing the  statistical  ability to fit more complex models with more data, and a steadily decreasing curve showing the  computational  feasibility of doing so.</p><p>2 0.71972418 <a title="1543-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-27-Visual_diagnostics_for_discrete-data_regressions.html">929 andrew gelman stats-2011-09-27-Visual diagnostics for discrete-data regressions</a></p>
<p>Introduction: Jeff asked me what I thought of  this  recent AJPS article by Brian Greenhill, Michael Ward, and Audrey Sacks, “The Separation Plot: A New Visual Method for Evaluating the Fit of Binary Models.”  It’s similar to a graph of observed vs. predicted values, but using color rather than the y-axis to display the observed values.  It seems like it could be useful, also could be applied more generally to discrete-data regressions with more than two categories.
 
When it comes to checking the model fit, I recommend binned residual plots, as discussed in  this 2000 article  with Yuri Goegebeur, Francis Tuerlinckx, and Iven Van Mechelen.</p><p>3 0.65932423 <a title="1543-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<p>Introduction: Tiago Fragoso writes:
  
Suppose I fit a two stage regression model


Y = a + bx + e 
a = cw + d + e1


I could fit it all in one step by using MCMC for example (my model is more complicated than that, so I’ll have to do it by MCMC). However, I could fit the first regression only using MCMC because those estimates are hard to obtain and perform the second regression using least squares or a separate MCMC. 


So there’s an ‘one step’ inference based on doing it all at the same time and a ‘two step’ inference by fitting one and using the estimates on the further steps. What is gained or lost between both? Is anything done in this question?
  
My response:
 
Rather than answering your particular question, I’ll give you my generic answer, which is to simulate fake data from your model, then fit your model both ways and see how the results differ.  Repeat the simulation a few thousand times and you can make all the statistical comparisons you like.</p><p>4 0.64918774 <a title="1543-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-19-An_interweaving-transformation_strategy_for_boosting_MCMC_efficiency.html">964 andrew gelman stats-2011-10-19-An interweaving-transformation strategy for boosting MCMC efficiency</a></p>
<p>Introduction: Yaming Yu and Xiao-Li Meng  write in  with a cool new idea for improving the efficiency of Gibbs and Metropolis in multilevel models:
  
For a broad class of multilevel models, there exist two well-known competing parameterizations, the centered parameterization (CP) and the non-centered parameterization (NCP), for effective MCMC implementation. Much literature has been devoted to the questions of when to use which and how to compromise between them via partial CP/NCP. This article introduces an alternative strategy for boosting MCMC efficiency via simply interweaving—but not alternating—the two parameterizations. This strategy has the surprising property that failure of both the CP and NCP chains to converge geometrically does not prevent the interweaving algorithm from doing so. It achieves this seemingly magical property by taking advantage of the discordance of the two parameterizations, namely, the sufficiency of CP and the ancillarity of NCP, to substantially reduce the Markovian</p><p>5 0.64453423 <a title="1543-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-17-Graphs_showing_uncertainty_using_lighter_intensities_for_the_lines_that_go_further_from_the_center%2C_to_de-emphasize_the_edges.html">1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</a></p>
<p>Introduction: Following up on our  recent discussion  of visually-weighted displays of uncertainty in regression curves, Lucas Leeman sent in the following two graphs:
 
First, the basic spaghetti-style plot showing inferential uncertainty in the E(y|x) curve:
 
   
 
Then, a version using even lighter intensities for the lines that go further from the center, to further de-emphasize the edges:
 
   
 
P.S.  More (including code!)  here .</p><p>6 0.64349657 <a title="1543-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>7 0.61610276 <a title="1543-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>8 0.61487907 <a title="1543-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-R_needs_a_good_function_to_make_line_plots.html">252 andrew gelman stats-2010-09-02-R needs a good function to make line plots</a></p>
<p>9 0.6111092 <a title="1543-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-16-%E2%80%9CReal_data_can_be_a_pain%E2%80%9D.html">1460 andrew gelman stats-2012-08-16-“Real data can be a pain”</a></p>
<p>10 0.60653627 <a title="1543-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-30-David_Hogg_on_statistics.html">1401 andrew gelman stats-2012-06-30-David Hogg on statistics</a></p>
<p>11 0.60352808 <a title="1543-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>12 0.60144508 <a title="1543-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-28-Using_predator-prey_models_on_the_Canadian_lynx_series.html">1141 andrew gelman stats-2012-01-28-Using predator-prey models on the Canadian lynx series</a></p>
<p>13 0.59715074 <a title="1543-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>14 0.59699935 <a title="1543-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-20-The_pervasive_twoishness_of_statistics%3B_in_particular%2C_the_%E2%80%9Csampling_distribution%E2%80%9D_and_the_%E2%80%9Clikelihood%E2%80%9D_are_two_different_models%2C_and_that%E2%80%99s_a_good_thing.html">774 andrew gelman stats-2011-06-20-The pervasive twoishness of statistics; in particular, the “sampling distribution” and the “likelihood” are two different models, and that’s a good thing</a></p>
<p>15 0.59471256 <a title="1543-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-13-Checking_your_model_using_fake_data.html">852 andrew gelman stats-2011-08-13-Checking your model using fake data</a></p>
<p>16 0.59209031 <a title="1543-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-15-The_UN_Plot_to_Force_Bayesianism_on_Unsuspecting_Americans_%28penalized_B-Spline_edition%29.html">2135 andrew gelman stats-2013-12-15-The UN Plot to Force Bayesianism on Unsuspecting Americans (penalized B-Spline edition)</a></p>
<p>17 0.59145242 <a title="1543-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-07-Bayesian_hierarchical_model_for_the_prediction_of_soccer_results.html">20 andrew gelman stats-2010-05-07-Bayesian hierarchical model for the prediction of soccer results</a></p>
<p>18 0.58450389 <a title="1543-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-04-When_is_there_%E2%80%9Chidden_structure_in_data%E2%80%9D_to_be_discovered%3F.html">1788 andrew gelman stats-2013-04-04-When is there “hidden structure in data” to be discovered?</a></p>
<p>19 0.57971936 <a title="1543-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-15-How_I_think_about_mixture_models.html">1459 andrew gelman stats-2012-08-15-How I think about mixture models</a></p>
<p>20 0.579265 <a title="1543-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-R_package_for_Bayes_factors.html">1682 andrew gelman stats-2013-01-19-R package for Bayes factors</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.034), (10, 0.041), (24, 0.133), (51, 0.336), (84, 0.045), (86, 0.056), (99, 0.176)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.83887988 <a title="1543-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-21-Model_complexity_as_a_function_of_sample_size.html">1543 andrew gelman stats-2012-10-21-Model complexity as a function of sample size</a></p>
<p>Introduction: As we get more data, we can fit more model.  But at some point we become so overwhelmed by data that, for computational reasons, we can barely do anything at all.  Thus, the curve above could be thought of as the product of two curves:  a steadily increasing curve showing the  statistical  ability to fit more complex models with more data, and a steadily decreasing curve showing the  computational  feasibility of doing so.</p><p>2 0.72194827 <a title="1543-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-28-My_talk_on_statistical_graphics_at_Mit_this_Thurs_aft.html">1594 andrew gelman stats-2012-11-28-My talk on statistical graphics at Mit this Thurs aft</a></p>
<p>Introduction: Infovis and Statistical Graphics: Different Goals, Different Looks  (and  here’s  the article)
 
Speaker: Andrew Gelman, Columbia University 
 Date: Thursday, November 29 2012 
Time: 4:00PM to 5:00PM  
Location: 32-D463 (Star Conference Room) 
Host: Polina Golland, CSAIL 
Contact: Polina Golland, 6172538005, polina@csail.mit.edu
 
The importance of graphical displays in statistical practice has been recognized sporadically in the statistical literature over the past century, with wider awareness following Tukey’s Exploratory Data Analysis (1977) and Tufte’s books in the succeeding decades. But statistical graphics still occupies an awkward in-between position: Within statistics, exploratory and graphical methods represent a minor subfield and are not well-integrated with larger themes of modeling and inference. Outside of statistics, infographics (also called information visualization or Infovis) is huge, but their purveyors and enthusiasts appear largely to be uninterested in statisti</p><p>3 0.69646198 <a title="1543-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-30-Statistical_Murder.html">1147 andrew gelman stats-2012-01-30-Statistical Murder</a></p>
<p>Introduction: Image via Wikipedia
 

  
 
  
 
     
 Robert Zubrin  writes in  “How Much Is an Astronaut’s Life Worth?”  ( Reason ,  Feb 2012 ):
     
…policy analyst John D. Graham and his colleagues at the Harvard Center for Risk Analysis found in 1997 that the median cost for lifesaving expenditures and regulations by the U.S. government in the health care, residential, transportation, and occupational areas ranges from about $1 million to $3 million spent per life saved in today’s dollars. The only marked exception to this pattern occurs in the area of environmental health protection (such as the Superfund program) which costs about $200 million per life saved.


Graham and his colleagues call the latter kind of inefficiency “ statistical murder ,” since thousands of additional lives could be saved each year if the money were used more cost-effectively. To avoid such deadly waste, the Department of Transportation has a policy of rejecting any proposed safety expenditure that costs more than $3</p><p>4 0.64176643 <a title="1543-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-27-The_M%C3%B6bius_strip%2C_or%2C_marketing_that_is_impervious_to_criticism.html">1641 andrew gelman stats-2012-12-27-The Möbius strip, or, marketing that is impervious to criticism</a></p>
<p>Introduction: Johnny Carson had this great trick where, after a joke bombed, he’d do such a good double-take that he’d end up getting a huge laugh.  This gimmick could never have worked as his sole shtick—at some point, Johnny had to tell some good jokes—but it was a reliable way to limit the downside.  For the purpose of our discussion here, the point is that, even when the joke failed, Carson had a way out.
 
I thought of this today after following a link from a commenter that led to  this blog  on publicity-minded author Tim Ferriss.  I’ve never read anything by Ferriss but I’ve read about him on occasion:  his gimmick is he promotes his book using ingenious marketing strategies.  Sort of like how Madonna is famous for being famous, and Paris Hilton is famous for being famous for being famous, Ferriss is famous for self-promotion.
 
Matt Metzgar  writes :
  
I [Metzgar] saw a bunch of ads on the internet today for Tim Ferriss’ new book.  Even though the book was released today, it already has all</p><p>5 0.62641442 <a title="1543-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-29-Edgar_Allan_Poe_was_a_statistician.html">2001 andrew gelman stats-2013-08-29-Edgar Allan Poe was a statistician</a></p>
<p>Introduction: Antony Unwin writes:
  
Rereading Edgar Allan Poe’s “Murder in the Rue Morgue” reminded me of his astute remarks on analysis.  For instance

 
But it is in matters beyond the limits of mere rule that the skill of the analyst is evinced. He makes, in silence, a host of observations and inferences.
 

and

 
and the difference in the extent of the information obtained, lies not so much in the validity of the inference as in the quality of the observation. The necessary knowledge is that of what to observe.
 

and

 
He impaired his vision by holding the object too close. He might see, perhaps, one or two points with unusual clearness, but in so doing he, necessarily, lost sight of the matter as a whole.
 

However, I had forgotten his following comment, which rang all sorts of bells in connection with some scientific articles I have seen recently:

 
what is only complex is mistaken (a not unusual error) for what is profound.
 

How about asking referees to rate articles on their complex</p><p>6 0.62198865 <a title="1543-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-05-Any_available_cookbooks_on_Bayesian_designs%3F.html">1199 andrew gelman stats-2012-03-05-Any available cookbooks on Bayesian designs?</a></p>
<p>7 0.61033881 <a title="1543-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-03-Statistical_methods_for_healthcare_regulation%3A_rating%2C_screening_and_surveillance.html">744 andrew gelman stats-2011-06-03-Statistical methods for healthcare regulation: rating, screening and surveillance</a></p>
<p>8 0.58383727 <a title="1543-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-18-Subtle_statistical_issues_to_be_debated_on_TV..html">350 andrew gelman stats-2010-10-18-Subtle statistical issues to be debated on TV.</a></p>
<p>9 0.57469857 <a title="1543-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-21-Stan_Model_of_the_Week%3A_Hierarchical_Modeling_of_Supernovas.html">2299 andrew gelman stats-2014-04-21-Stan Model of the Week: Hierarchical Modeling of Supernovas</a></p>
<p>10 0.57399148 <a title="1543-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-19-Tradeoffs_in_information_graphics.html">1584 andrew gelman stats-2012-11-19-Tradeoffs in information graphics</a></p>
<p>11 0.57378739 <a title="1543-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-10-Who%E2%80%99s_holding_the_pen%3F%2C_The_split_screen%2C_and_other_ideas_for_one-on-one_instruction.html">462 andrew gelman stats-2010-12-10-Who’s holding the pen?, The split screen, and other ideas for one-on-one instruction</a></p>
<p>12 0.57001722 <a title="1543-lda-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-26-A_good_comment_on_one_of_my_papers.html">2225 andrew gelman stats-2014-02-26-A good comment on one of my papers</a></p>
<p>13 0.56620258 <a title="1543-lda-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-23-Win_probabilities_during_a_sporting_event.html">2262 andrew gelman stats-2014-03-23-Win probabilities during a sporting event</a></p>
<p>14 0.56187111 <a title="1543-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-Hypothesis_testing_with_multiple_imputations.html">799 andrew gelman stats-2011-07-13-Hypothesis testing with multiple imputations</a></p>
<p>15 0.55932498 <a title="1543-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-19-Standardized_writing_styles_and_standardized_graphing_styles.html">1176 andrew gelman stats-2012-02-19-Standardized writing styles and standardized graphing styles</a></p>
<p>16 0.55930996 <a title="1543-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-11-My_talk_at_the_NY_data_visualization_meetup_this_Monday%21.html">1668 andrew gelman stats-2013-01-11-My talk at the NY data visualization meetup this Monday!</a></p>
<p>17 0.55904871 <a title="1543-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-21-Models_with_constraints.html">2342 andrew gelman stats-2014-05-21-Models with constraints</a></p>
<p>18 0.5586741 <a title="1543-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-13-%E2%80%9CWhat_are_some_situations_in_which_the_classical_approach_%28or_a_naive_implementation_of_it%2C_based_on_cookbook_recipes%29_gives_worse_results_than_a_Bayesian_approach%2C_results_that_actually_impeded_the_science%3F%E2%80%9D.html">2099 andrew gelman stats-2013-11-13-“What are some situations in which the classical approach (or a naive implementation of it, based on cookbook recipes) gives worse results than a Bayesian approach, results that actually impeded the science?”</a></p>
<p>19 0.55777264 <a title="1543-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-24-Textbook_for_data_visualization%3F.html">1637 andrew gelman stats-2012-12-24-Textbook for data visualization?</a></p>
<p>20 0.55607116 <a title="1543-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-20-A_qualified_but_incomplete_thanks_to_Gregg_Easterbrook%E2%80%99s_editor_at_Reuters.html">966 andrew gelman stats-2011-10-20-A qualified but incomplete thanks to Gregg Easterbrook’s editor at Reuters</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
