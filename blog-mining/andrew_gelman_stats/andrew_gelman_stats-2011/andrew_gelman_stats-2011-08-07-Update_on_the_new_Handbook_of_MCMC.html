<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>844 andrew gelman stats-2011-08-07-Update on the new Handbook of MCMC</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-844" href="#">andrew_gelman_stats-2011-844</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>844 andrew gelman stats-2011-08-07-Update on the new Handbook of MCMC</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-844-html" href="http://andrewgelman.com/2011/08/07/update_on_the_n/">html</a></p><p>Introduction: It’s edited by Steve Brooks, Galin Jones, Xiao-Li Meng, and myself.   Here’s  the information and some sample chapters (including my own chapter with Ken Shirley on inference and monitoring convergence and Radford’s instant classic on Hamiltonian Monte Carlo).
 
Sorry about the $100 price tag–nobody asked me about that!  But if you’re doing these computations as part of your work, I think the book will be well worth it.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 It’s edited by Steve Brooks, Galin Jones, Xiao-Li Meng, and myself. [sent-1, score-0.2]
</p><p>2 Here’s  the information and some sample chapters (including my own chapter with Ken Shirley on inference and monitoring convergence and Radford’s instant classic on Hamiltonian Monte Carlo). [sent-2, score-1.354]
</p><p>3 Sorry about the $100 price tag–nobody asked me about that! [sent-3, score-0.262]
</p><p>4 But if you’re doing these computations as part of your work, I think the book will be well worth it. [sent-4, score-0.582]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('galin', 0.293), ('tag', 0.247), ('radford', 0.231), ('instant', 0.231), ('shirley', 0.231), ('jones', 0.231), ('computations', 0.226), ('ken', 0.222), ('monitoring', 0.219), ('meng', 0.207), ('edited', 0.2), ('convergence', 0.196), ('hamiltonian', 0.192), ('brooks', 0.182), ('carlo', 0.182), ('monte', 0.173), ('chapters', 0.169), ('steve', 0.166), ('sorry', 0.162), ('price', 0.153), ('classic', 0.146), ('nobody', 0.131), ('chapter', 0.124), ('asked', 0.109), ('worth', 0.108), ('sample', 0.099), ('inference', 0.093), ('including', 0.093), ('part', 0.079), ('information', 0.077), ('book', 0.076), ('well', 0.061), ('re', 0.052), ('work', 0.05), ('think', 0.032)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="844-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-07-Update_on_the_new_Handbook_of_MCMC.html">844 andrew gelman stats-2011-08-07-Update on the new Handbook of MCMC</a></p>
<p>Introduction: It’s edited by Steve Brooks, Galin Jones, Xiao-Li Meng, and myself.   Here’s  the information and some sample chapters (including my own chapter with Ken Shirley on inference and monitoring convergence and Radford’s instant classic on Hamiltonian Monte Carlo).
 
Sorry about the $100 price tag–nobody asked me about that!  But if you’re doing these computations as part of your work, I think the book will be well worth it.</p><p>2 0.33230984 <a title="844-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-21-Handbook_of_Markov_Chain_Monte_Carlo.html">674 andrew gelman stats-2011-04-21-Handbook of Markov Chain Monte Carlo</a></p>
<p>Introduction: Galin Jones, Steve Brooks, Xiao-Li Meng and I edited a handbook of Markov Chain Monte Carlo that has  just been published .  My chapter (with Kenny Shirley) is  here , and it begins like this:
  
Convergence of Markov chain simulations can be monitored by measuring the diffusion and mixing of multiple independently-simulated chains, but different levels of convergence are appropriate for different goals. When considering inference from stochastic simulation, we need to separate two tasks: (1) inference about parameters and functions of parameters based on broad characteristics of their distribution, and (2) more precise computation of expectations and other functions of probability distributions. For the first task, there is a natural limit to precision beyond which additional simulations add essentially nothing; for the second task, the appropriate precision must be decided from external considerations. We illustrate with an example from our current research, a hierarchical model of t</p><p>3 0.17121848 <a title="844-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-23-Learning_Differential_Geometry_for_Hamiltonian_Monte_Carlo.html">1339 andrew gelman stats-2012-05-23-Learning Differential Geometry for Hamiltonian Monte Carlo</a></p>
<p>Introduction: You can get a taste of Hamiltonian Monte Carlo (HMC) by reading the very gentle introduction in David MacKay’s general text on information theory:
  
  MacKay, D.  2003.    Information Theory, Inference, and Learning Algorithms  .  Cambridge University Press.  [see Chapter 31, which is relatively standalone and can be downloaded separately.]
   
Follow this up with Radford Neal’s much more thorough introduction to HMC:
  
 Neal, R. 2011.   MCMC Using Hamiltonian Dynamics .  In Brooks, Gelman, Jones and Meng, eds.,  Handbook of Markov Chain Monte Carlo .  Chapman and Hall/CRC Press.
   
To understand why HMC works and set yourself on the path to understanding generalizations like  Riemann manifold HMC , you’ll need to know a bit about differential geometry.  I really liked the combination of these two books:
  
  Magnus, J. R. and H. Neudecker.  2007.   Matrix Differential Calculus with Application in Statistics and Econometrics .  3rd Edition.  Wiley?
   
and
  
  Leimkuhler, B. and S.</p><p>4 0.12927213 <a title="844-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-31-Bayes%3A_radical%2C_liberal%2C_or_conservative%3F.html">639 andrew gelman stats-2011-03-31-Bayes: radical, liberal, or conservative?</a></p>
<p>Introduction: Radford  writes :
  
The word “conservative” gets used many ways, for various political purposes, but I would take it’s basic meaning to be someone who thinks there’s a lot of wisdom in traditional ways of doing things, even if we don’t understand exactly why those ways are good, so we should be reluctant to change unless we have a strong argument that some other way is better. This sounds very Bayesian, with a prior reducing the impact of new data.
  
I agree completely, and I think Radford will very much enjoy  my article with Aleks Jakulin , “Bayes: radical, liberal, or conservative?”  Radford’s comment also fits with my increasing inclination to use informative prior distributions.</p><p>5 0.12819815 <a title="844-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-20-Stan_at_Google_this_Thurs_and_at_Berkeley_this_Fri_noon.html">1772 andrew gelman stats-2013-03-20-Stan at Google this Thurs and at Berkeley this Fri noon</a></p>
<p>Introduction: Michael Betancourt  will be speaking at Google and at the University of California, Berkeley.  The Google talk is closed to outsiders (but if you work at Google, you should go!); the Berkeley talk is open to all:
  
Friday March 22, 12:10 pm, Evans Hall 1011.


Title of talk:  Stan : Practical Bayesian Inference with Hamiltonian Monte Carlo


Abstract: Practical implementations of Bayesian inference are often limited to approximation methods that only slowly explore the posterior distribution.  By taking advantage of the curvature of the posterior, however, Hamiltonian Monte Carlo (HMC) efficiently explores even the most highly contorted distributions.  In this talk I will review the foundations of and recent developments within HMC, concluding with a discussion of Stan, a powerful inference engine that utilizes HMC, automatic differentiation, and adaptive methods to minimize user input.
  
This is cool stuff.  And heâ&euro;&trade;ll be showing the whirlpool movie!</p><p>6 0.11939935 <a title="844-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-20-My_beef_with_Brooks%3A__the_alternative_to_%E2%80%9Cgood_statistics%E2%80%9D_is_not_%E2%80%9Cno_statistics%2C%E2%80%9D_it%E2%80%99s_%E2%80%9Cbad_statistics%E2%80%9D.html">1729 andrew gelman stats-2013-02-20-My beef with Brooks:  the alternative to “good statistics” is not “no statistics,” it’s “bad statistics”</a></p>
<p>7 0.1122712 <a title="844-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-04-Stan_in_L.A._this_Wed_3%3A30pm.html">1749 andrew gelman stats-2013-03-04-Stan in L.A. this Wed 3:30pm</a></p>
<p>8 0.099079043 <a title="844-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-30-Stan_Project%3A__Continuous_Relaxations_for_Discrete_MRFs.html">2003 andrew gelman stats-2013-08-30-Stan Project:  Continuous Relaxations for Discrete MRFs</a></p>
<p>9 0.088975966 <a title="844-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-14-1.5_million_people_were_told_that_extreme_conservatives_are_happier_than_political_moderates.__Approximately_.0001_million_Americans_learned_that_the_opposite_is_true..html">1458 andrew gelman stats-2012-08-14-1.5 million people were told that extreme conservatives are happier than political moderates.  Approximately .0001 million Americans learned that the opposite is true.</a></p>
<p>10 0.084555209 <a title="844-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Education_could_use_some_systematic_evaluation.html">1271 andrew gelman stats-2012-04-20-Education could use some systematic evaluation</a></p>
<p>11 0.084525473 <a title="844-tfidf-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-03-As_the_boldest_experiment_in_journalism_history%2C_you_admit_you_made_a_mistake.html">2280 andrew gelman stats-2014-04-03-As the boldest experiment in journalism history, you admit you made a mistake</a></p>
<p>12 0.083421148 <a title="844-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>13 0.082889535 <a title="844-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-29-Hamiltonian_Monte_Carlo_stories.html">931 andrew gelman stats-2011-09-29-Hamiltonian Monte Carlo stories</a></p>
<p>14 0.080305383 <a title="844-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-14-Do_we_need_an_integrated_Bayesian-likelihood_inference%3F.html">467 andrew gelman stats-2010-12-14-Do we need an integrated Bayesian-likelihood inference?</a></p>
<p>15 0.080102079 <a title="844-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>16 0.079369456 <a title="844-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-24-Always_check_your_evidence.html">1025 andrew gelman stats-2011-11-24-Always check your evidence</a></p>
<p>17 0.077786729 <a title="844-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-The_first_version_of_my_%E2%80%9Cinference_from_iterative_simulation_using_parallel_sequences%E2%80%9D_paper%21.html">1309 andrew gelman stats-2012-05-09-The first version of my “inference from iterative simulation using parallel sequences” paper!</a></p>
<p>18 0.072508529 <a title="844-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>19 0.071296513 <a title="844-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Extreem_p-values%21.html">1691 andrew gelman stats-2013-01-25-Extreem p-values!</a></p>
<p>20 0.068924293 <a title="844-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-03-5_books.html">499 andrew gelman stats-2011-01-03-5 books</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.069), (1, 0.018), (2, -0.02), (3, 0.027), (4, -0.001), (5, 0.042), (6, 0.006), (7, -0.021), (8, 0.001), (9, -0.043), (10, -0.015), (11, -0.025), (12, -0.055), (13, 0.024), (14, 0.055), (15, -0.003), (16, -0.023), (17, 0.005), (18, 0.041), (19, -0.017), (20, 0.009), (21, -0.011), (22, 0.048), (23, 0.021), (24, 0.039), (25, 0.029), (26, -0.008), (27, 0.006), (28, 0.045), (29, 0.031), (30, -0.039), (31, 0.002), (32, 0.017), (33, 0.004), (34, -0.017), (35, -0.005), (36, -0.002), (37, -0.035), (38, 0.013), (39, 0.041), (40, -0.029), (41, 0.015), (42, -0.011), (43, -0.022), (44, -0.006), (45, 0.023), (46, -0.004), (47, -0.026), (48, 0.029), (49, -0.022)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94150871 <a title="844-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-07-Update_on_the_new_Handbook_of_MCMC.html">844 andrew gelman stats-2011-08-07-Update on the new Handbook of MCMC</a></p>
<p>Introduction: It’s edited by Steve Brooks, Galin Jones, Xiao-Li Meng, and myself.   Here’s  the information and some sample chapters (including my own chapter with Ken Shirley on inference and monitoring convergence and Radford’s instant classic on Hamiltonian Monte Carlo).
 
Sorry about the $100 price tag–nobody asked me about that!  But if you’re doing these computations as part of your work, I think the book will be well worth it.</p><p>2 0.73941588 <a title="844-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-23-Learning_Differential_Geometry_for_Hamiltonian_Monte_Carlo.html">1339 andrew gelman stats-2012-05-23-Learning Differential Geometry for Hamiltonian Monte Carlo</a></p>
<p>Introduction: You can get a taste of Hamiltonian Monte Carlo (HMC) by reading the very gentle introduction in David MacKay’s general text on information theory:
  
  MacKay, D.  2003.    Information Theory, Inference, and Learning Algorithms  .  Cambridge University Press.  [see Chapter 31, which is relatively standalone and can be downloaded separately.]
   
Follow this up with Radford Neal’s much more thorough introduction to HMC:
  
 Neal, R. 2011.   MCMC Using Hamiltonian Dynamics .  In Brooks, Gelman, Jones and Meng, eds.,  Handbook of Markov Chain Monte Carlo .  Chapman and Hall/CRC Press.
   
To understand why HMC works and set yourself on the path to understanding generalizations like  Riemann manifold HMC , you’ll need to know a bit about differential geometry.  I really liked the combination of these two books:
  
  Magnus, J. R. and H. Neudecker.  2007.   Matrix Differential Calculus with Application in Statistics and Econometrics .  3rd Edition.  Wiley?
   
and
  
  Leimkuhler, B. and S.</p><p>3 0.6923973 <a title="844-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-21-Handbook_of_Markov_Chain_Monte_Carlo.html">674 andrew gelman stats-2011-04-21-Handbook of Markov Chain Monte Carlo</a></p>
<p>Introduction: Galin Jones, Steve Brooks, Xiao-Li Meng and I edited a handbook of Markov Chain Monte Carlo that has  just been published .  My chapter (with Kenny Shirley) is  here , and it begins like this:
  
Convergence of Markov chain simulations can be monitored by measuring the diffusion and mixing of multiple independently-simulated chains, but different levels of convergence are appropriate for different goals. When considering inference from stochastic simulation, we need to separate two tasks: (1) inference about parameters and functions of parameters based on broad characteristics of their distribution, and (2) more precise computation of expectations and other functions of probability distributions. For the first task, there is a natural limit to precision beyond which additional simulations add essentially nothing; for the second task, the appropriate precision must be decided from external considerations. We illustrate with an example from our current research, a hierarchical model of t</p><p>4 0.6017344 <a title="844-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-04-Stan_in_L.A._this_Wed_3%3A30pm.html">1749 andrew gelman stats-2013-03-04-Stan in L.A. this Wed 3:30pm</a></p>
<p>Introduction: Michael Betancourt  will be speaking at UCLA:
  
The location for refreshment is in room 51-254 CHS at 3:00 PM.


The place for the seminar is at CHS 33-105A  at 3:30pm – 4:30pm, Wed 6 Mar.


["CHS" stands for Center for Health Sciences, the building of the UCLA schools of medicine and public health.   Here's a map with directions .]


Title of talk:  Stan : Practical Bayesian Inference with Hamiltonian Monte Carlo


Abstract: Practical implementations of Bayesian inference are often limited to approximation methods that only slowly explore the posterior distribution.  By taking advantage of the curvature of the posterior, however, Hamiltonian Monte Carlo (HMC) efficiently explores even the most highly contorted distributions.  In this talk I will review the foundations of and recent developments within HMC, concluding with a discussion of Stan, a powerful inference engine that utilizes HMC, automatic differentiation, and adaptive methods to minimize user input.
  
This is cool stuff.</p><p>5 0.55935812 <a title="844-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-The_most-cited_statistics_papers_ever.html">2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</a></p>
<p>Introduction: Robert Grant has a  list .  I’ll just give the ones with more than 10,000 Google Scholar cites:
  

Cox (1972) Regression and life tables: 35,512 citations. 


Dempster, Laird, Rubin (1977) Maximum likelihood from incomplete data via the EM algorithm: 34,988


Bland & Altman (1986) Statistical methods for assessing agreement between two methods of clinical measurement: 27,181


Geman & Geman (1984) Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images: 15,106
  
We can find some more via searching Google scholar for familiar names and topics; thus:
  

Metropolis et al. (1953) Equation of state calculations by fast computing machines: 26,000


Benjamini and Hochberg (1995) Controlling the false discovery rate: a practical and powerful approach to multiple testing: 21,000


White (1980) A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity: 18,000


Heckman (1977) Sample selection bias as a specification error:</p><p>6 0.55649948 <a title="844-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-20-Stan_at_Google_this_Thurs_and_at_Berkeley_this_Fri_noon.html">1772 andrew gelman stats-2013-03-20-Stan at Google this Thurs and at Berkeley this Fri noon</a></p>
<p>7 0.52130389 <a title="844-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-29-Hamiltonian_Monte_Carlo_stories.html">931 andrew gelman stats-2011-09-29-Hamiltonian Monte Carlo stories</a></p>
<p>8 0.51518953 <a title="844-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-04-Inequality_and_health.html">127 andrew gelman stats-2010-07-04-Inequality and health</a></p>
<p>9 0.51503211 <a title="844-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-26-WAIC_and_cross-validation_in_Stan%21.html">2349 andrew gelman stats-2014-05-26-WAIC and cross-validation in Stan!</a></p>
<p>10 0.51427317 <a title="844-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-23-Bayesian_adaptive_methods_for_clinical_trials.html">427 andrew gelman stats-2010-11-23-Bayesian adaptive methods for clinical trials</a></p>
<p>11 0.51417929 <a title="844-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>12 0.50480157 <a title="844-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-28-New_book_by_Stef_van_Buuren_on_missing-data_imputation_looks_really_good%21.html">1642 andrew gelman stats-2012-12-28-New book by Stef van Buuren on missing-data imputation looks really good!</a></p>
<p>13 0.50222111 <a title="844-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-13-Swiss_Jonah_Lehrer.html">2021 andrew gelman stats-2013-09-13-Swiss Jonah Lehrer</a></p>
<p>14 0.49936324 <a title="844-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-04-Handy_Matrix_Cheat_Sheet%2C_with_Gradients.html">555 andrew gelman stats-2011-02-04-Handy Matrix Cheat Sheet, with Gradients</a></p>
<p>15 0.49770612 <a title="844-lsi-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-03-Running_into_a_Stan_Reference_by_Accident.html">2231 andrew gelman stats-2014-03-03-Running into a Stan Reference by Accident</a></p>
<p>16 0.49518529 <a title="844-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-28-Reference_on_longitudinal_models%3F.html">1188 andrew gelman stats-2012-02-28-Reference on longitudinal models?</a></p>
<p>17 0.49082622 <a title="844-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-05-Identifying_pathways_for_managing_multiple_disturbances_to_limit_plant_invasions.html">2360 andrew gelman stats-2014-06-05-Identifying pathways for managing multiple disturbances to limit plant invasions</a></p>
<p>18 0.4906905 <a title="844-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-01-David_MacKay_sez_._._._12%3F%3F.html">984 andrew gelman stats-2011-11-01-David MacKay sez . . . 12??</a></p>
<p>19 0.48856845 <a title="844-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-01-MacKay_update%3A__where_12_comes_from.html">986 andrew gelman stats-2011-11-01-MacKay update:  where 12 comes from</a></p>
<p>20 0.48793235 <a title="844-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-The_first_version_of_my_%E2%80%9Cinference_from_iterative_simulation_using_parallel_sequences%E2%80%9D_paper%21.html">1309 andrew gelman stats-2012-05-09-The first version of my “inference from iterative simulation using parallel sequences” paper!</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.04), (15, 0.037), (16, 0.098), (24, 0.086), (29, 0.037), (39, 0.186), (53, 0.044), (82, 0.033), (84, 0.032), (86, 0.067), (99, 0.203)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91737342 <a title="844-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-07-Update_on_the_new_Handbook_of_MCMC.html">844 andrew gelman stats-2011-08-07-Update on the new Handbook of MCMC</a></p>
<p>Introduction: It’s edited by Steve Brooks, Galin Jones, Xiao-Li Meng, and myself.   Here’s  the information and some sample chapters (including my own chapter with Ken Shirley on inference and monitoring convergence and Radford’s instant classic on Hamiltonian Monte Carlo).
 
Sorry about the $100 price tag–nobody asked me about that!  But if you’re doing these computations as part of your work, I think the book will be well worth it.</p><p>2 0.8877666 <a title="844-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-25-And_now%2C_here%E2%80%99s_something_we_hope_you%E2%80%99ll_really_like.html">1343 andrew gelman stats-2012-05-25-And now, here’s something we hope you’ll really like</a></p>
<p>Introduction: This came in the email:
  
Postdoctoral Researcher (3 years) in State-Space Modeling of Animal Movement and Population Dynamics in Universities of Turku and Helsinki, Finland


We seek for a statistician/mathematician with experience in ecological modeling or an ecologist with strong quantitative training to join an interdisciplinary research team focusing on dispersal and dynamics of the Siberian flying squirrel (Pteromys volans).


The Postdoctoral Researcher will develop modeling approaches (from individual based models to population level models) to assess the dispersal and population dynamics of the flying squirrel. A key challenge will be the integration of different kinds of data (census data, telemetry data, mark-recapture data, life-history data, and data on environmental covariates such as forest structure) into the modeling framework using Bayesian State-Space models or other such approaches.


The project will be supervised by Dr. Vesa Selonen (a flying squirrel specialist;</p><p>3 0.86170924 <a title="844-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-02-Automating_my_graphics_advice.html">443 andrew gelman stats-2010-12-02-Automating my graphics advice</a></p>
<p>Introduction: After seeing  this graph :
 
   
 
I have the following message for Sharad:
 
Rotate the graph 90 degrees so you can see the words.  Also you can ditch the lines.  Then what you have is a dotplot, following the principles of Cleveland (1985).  You can lay out a few on one page to see some interactions with demographics.
 
 The real challenge here . . . 
 
. . . is to automate this sort of advice.  Or maybe we just need a really nice dotplot() function and enough examples, and people will start doing it?
 
 P.S. 
 
Often a lineplot is better.  See  here  for a discussion of another Sharad example.</p><p>4 0.79812688 <a title="844-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-14-Can_gambling_addicts_be_identified_in_gambling_venues%3F.html">1622 andrew gelman stats-2012-12-14-Can gambling addicts be identified in gambling venues?</a></p>
<p>Introduction: Mark Griffiths, a psychologist who apparently is Europeâ&euro;&trade;s only Professor of Gambling Studies, writes:
  
 You  made the comment about how difficult it is to spot problem gamblers. I and a couple of colleagues [Paul Delfabbro and Daniel Kingjust] published this review of all the research done on spotting problem gamblers in online and offline gaming venues (attached) that I  covered in one of my recent blogs .</p><p>5 0.7968756 <a title="844-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-13-Visualization_in_1939.html">31 andrew gelman stats-2010-05-13-Visualization in 1939</a></p>
<p>Introduction: Willard Cope Brintonâ&euro;&trade;s second book Graphic Presentation (1939) surprised me with the quality of its graphics. Prof. Michael Stoll has some scans at  Flickr . For example:
 
  
  
 
The whole book can be downloaded (in a worse resolution) from  Archive.Org .</p><p>6 0.78897381 <a title="844-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-01-Mapmaking_software.html">441 andrew gelman stats-2010-12-01-Mapmaking software</a></p>
<p>7 0.78766114 <a title="844-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-21-Handbook_of_Markov_Chain_Monte_Carlo.html">674 andrew gelman stats-2011-04-21-Handbook of Markov Chain Monte Carlo</a></p>
<p>8 0.78102863 <a title="844-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-Philosophy_of_Bayesian_statistics%3A_my_reactions_to_Hendry.html">1157 andrew gelman stats-2012-02-07-Philosophy of Bayesian statistics: my reactions to Hendry</a></p>
<p>9 0.77705133 <a title="844-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-05-%E2%80%9CNumbersense%3A__How_to_use_big_data_to_your_advantage%E2%80%9D.html">1927 andrew gelman stats-2013-07-05-“Numbersense:  How to use big data to your advantage”</a></p>
<p>10 0.77229446 <a title="844-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-11-Herman_Chernoff_used_to_do_that_too%3B_also%2C_some_puzzlement_over_another%E2%80%99s_puzzlement_over_another%E2%80%99s_preferences.html">334 andrew gelman stats-2010-10-11-Herman Chernoff used to do that too; also, some puzzlement over another’s puzzlement over another’s preferences</a></p>
<p>11 0.76967931 <a title="844-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-01-When_should_you_worry_about_imputed_data%3F.html">935 andrew gelman stats-2011-10-01-When should you worry about imputed data?</a></p>
<p>12 0.76890898 <a title="844-lda-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-15-Problematic_interpretations_of_confidence_intervals.html">2248 andrew gelman stats-2014-03-15-Problematic interpretations of confidence intervals</a></p>
<p>13 0.76507103 <a title="844-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-Participate_in_a_short_survey_about_the_weight_of_evidence_provided_by_statistics.html">1681 andrew gelman stats-2013-01-19-Participate in a short survey about the weight of evidence provided by statistics</a></p>
<p>14 0.76424015 <a title="844-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-22-Spell-checking_example_demonstrates_key_aspects_of_Bayesian_data_analysis.html">2182 andrew gelman stats-2014-01-22-Spell-checking example demonstrates key aspects of Bayesian data analysis</a></p>
<p>15 0.76366079 <a title="844-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-01-Post-publication_peer_review%3A__How_it_%28sometimes%29_really_works.html">2004 andrew gelman stats-2013-09-01-Post-publication peer review:  How it (sometimes) really works</a></p>
<p>16 0.76191187 <a title="844-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-19-David_Blackwell.html">155 andrew gelman stats-2010-07-19-David Blackwell</a></p>
<p>17 0.75873572 <a title="844-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-03-Kuhn%2C_1-f_noise%2C_and_the_fractal_nature_of_scientific_revolutions.html">1924 andrew gelman stats-2013-07-03-Kuhn, 1-f noise, and the fractal nature of scientific revolutions</a></p>
<p>18 0.758237 <a title="844-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-13-Test_scores_and_grades_predict_job_performance_%28but_maybe_not_at_Google%29.html">1980 andrew gelman stats-2013-08-13-Test scores and grades predict job performance (but maybe not at Google)</a></p>
<p>19 0.75755513 <a title="844-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-18-Beautiful_Line_Charts.html">1125 andrew gelman stats-2012-01-18-Beautiful Line Charts</a></p>
<p>20 0.75647986 <a title="844-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-23-%E2%80%9CAny_old_map_will_do%E2%80%9D_meets_%E2%80%9CGod_is_in_every_leaf_of_every_tree%E2%80%9D.html">1278 andrew gelman stats-2012-04-23-“Any old map will do” meets “God is in every leaf of every tree”</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
