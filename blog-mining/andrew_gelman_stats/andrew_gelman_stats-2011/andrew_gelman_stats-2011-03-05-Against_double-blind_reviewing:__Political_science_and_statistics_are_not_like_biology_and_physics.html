<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>601 andrew gelman stats-2011-03-05-Against double-blind reviewing:  Political science and statistics are not like biology and physics</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-601" href="#">andrew_gelman_stats-2011-601</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>601 andrew gelman stats-2011-03-05-Against double-blind reviewing:  Political science and statistics are not like biology and physics</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-601-html" href="http://andrewgelman.com/2011/03/05/against_double/">html</a></p><p>Introduction: Responding to a proposal to move the journal Political Analysis from double-blind to single-blind reviewing (that is, authors would not know who is reviewing their papers but reviewers would know the authors’ names), Tom Palfrey writes:
  
I agree with the editors’ recommendation. I have served on quite a few editorial boards of journals with different blinding policies, and have seen no evidence that double blind procedures are a useful way to improve the quality of articles published in a journal. Aside from the obvious administrative nuisance and the fact that authorship anonymity is a thing of the past in our discipline, the theoretical and empirical arguments in both directions lead to an ambiguous conclusion. Also keep in mind that the editors know the identity of the authors (they need to know for practical reasons), their identity is not hidden from authors, and ultimately it is they who make the accept/reject decision, and also lobby their friends and colleagues to submit “the</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Responding to a proposal to move the journal Political Analysis from double-blind to single-blind reviewing (that is, authors would not know who is reviewing their papers but reviewers would know the authors’ names), Tom Palfrey writes:    I agree with the editors’ recommendation. [sent-1, score-0.632]
</p><p>2 I have served on quite a few editorial boards of journals with different blinding policies, and have seen no evidence that double blind procedures are a useful way to improve the quality of articles published in a journal. [sent-2, score-1.264]
</p><p>3 Aside from the obvious administrative nuisance and the fact that authorship anonymity is a thing of the past in our discipline, the theoretical and empirical arguments in both directions lead to an ambiguous conclusion. [sent-3, score-0.269]
</p><p>4 Bias at the editorial level is far more likely to affect publication decisions than bias at the referee level, and double blind procedures don’t affect this. [sent-5, score-1.202]
</p><p>5 One could argue then that perhaps the main thing double blinding does is shift the power over journal content even further from referees and associate editors to editors. [sent-6, score-0.945]
</p><p>6 Another point of fact is that the use of double blind procedures in economics and political science shares essentially none of the justifications for it with the other science disciplines from which the idea was borrowed. [sent-8, score-1.254]
</p><p>7 In these other disciplines, like biology, such procedures exist for different (and good) reasons. [sent-9, score-0.254]
</p><p>8 Rather than a concern about biasing in favor of well-known versus lesser-known authors, in these other fields it is driven by a concern of bias because of the rat-race competition over a rapidly moving frontier of discovery. [sent-10, score-0.83]
</p><p>9 Because of the speed at which the frontier is moving, authors of new papers are intensely secretive (almost paranoid) about their work. [sent-11, score-0.506]
</p><p>10 Results are kept under wrap until the result has been accepted for publication – or in some cases until it is actually published. [sent-12, score-0.139]
</p><p>11 [Extra, Extra, Read All About It: PNAS article reports that Caltech astronomer Joe Shmoe discovered a new planet three months ago. [sent-13, score-0.141]
</p><p>12 ] Double blind is indeed not a fiction in these disciplines. [sent-16, score-0.237]
</p><p>13 Consider the contrast with our discipline, in which many researchers drool over invitations from top places to present their newest results, even if the paper does not yet exist or is in very rough draft form. [sent-18, score-0.164]
</p><p>14 Furthermore, financial incentives for bias in these other disciplines are very strong, given the enormous stakes of funding. [sent-19, score-0.817]
</p><p>15 ] Basically none of the rationales for double blinding in those disciplines applies to political science. [sent-21, score-1.085]
</p><p>16 This may have to do with the potential bias that results from intense competition in disciplines where financial stakes are enormous and the frontier of discovery moves at ‘blinding’ speed. [sent-25, score-1.166]
</p><p>17 Tom’s comparison of the different fields was a new point to me and it seems sensible. [sent-26, score-0.076]
</p><p>18 I’d also add that I’m baffled by many people’s attitudes toward reviewing articles for journals. [sent-27, score-0.356]
</p><p>19 As I’ve noted  before , I don’t think people make enough of the fact that editing and reviewing journal articles is volunteer work. [sent-28, score-0.427]
</p><p>20 Everyone’s always getting angry at referees and saying what they should or should not do, but, hey–we’re doing it for free. [sent-29, score-0.101]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('disciplines', 0.338), ('blinding', 0.306), ('double', 0.295), ('blind', 0.237), ('frontier', 0.194), ('reviewing', 0.194), ('bias', 0.171), ('authors', 0.17), ('editors', 0.169), ('procedures', 0.167), ('stakes', 0.129), ('identity', 0.118), ('discipline', 0.108), ('editorial', 0.107), ('enormous', 0.106), ('referees', 0.101), ('competition', 0.091), ('tom', 0.089), ('exist', 0.087), ('articles', 0.085), ('extra', 0.084), ('affect', 0.079), ('concern', 0.078), ('secretive', 0.077), ('invitations', 0.077), ('baffled', 0.077), ('moving', 0.077), ('fields', 0.076), ('none', 0.074), ('fact', 0.074), ('journal', 0.074), ('financial', 0.073), ('astronomer', 0.072), ('rationales', 0.072), ('telescope', 0.072), ('wrap', 0.072), ('lobby', 0.069), ('paranoid', 0.069), ('justifications', 0.069), ('planet', 0.069), ('publication', 0.067), ('boards', 0.067), ('anonymity', 0.067), ('caltech', 0.067), ('intensely', 0.065), ('biasing', 0.065), ('informational', 0.065), ('nuisance', 0.065), ('results', 0.064), ('ambiguous', 0.063)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="601-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-05-Against_double-blind_reviewing%3A__Political_science_and_statistics_are_not_like_biology_and_physics.html">601 andrew gelman stats-2011-03-05-Against double-blind reviewing:  Political science and statistics are not like biology and physics</a></p>
<p>Introduction: Responding to a proposal to move the journal Political Analysis from double-blind to single-blind reviewing (that is, authors would not know who is reviewing their papers but reviewers would know the authors’ names), Tom Palfrey writes:
  
I agree with the editors’ recommendation. I have served on quite a few editorial boards of journals with different blinding policies, and have seen no evidence that double blind procedures are a useful way to improve the quality of articles published in a journal. Aside from the obvious administrative nuisance and the fact that authorship anonymity is a thing of the past in our discipline, the theoretical and empirical arguments in both directions lead to an ambiguous conclusion. Also keep in mind that the editors know the identity of the authors (they need to know for practical reasons), their identity is not hidden from authors, and ultimately it is they who make the accept/reject decision, and also lobby their friends and colleagues to submit “the</p><p>2 0.15432951 <a title="601-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-12-Historical_Arc_of_Universities.html">2330 andrew gelman stats-2014-05-12-Historical Arc of Universities</a></p>
<p>Introduction: This post is by  David K. Park 
 
Even though I’m an engineer with a PhD in political science, I tend to gravitate toward history to anchor my contextual lens. (If fact, if I were pressed to put a methodological stake in the ground, I would say I’m a historical comparative institutional ecologist.) In that regard, it may be helpful to situate this discussion within the broader historical arc of intellectual pursuits at universities. As we know with the birth of universities, we had scholars who embodied so many disciplines such as mathematics, philosophy, religion law, etc into one individual. Then in the 50′s and 60′s we started going into hyper-specialization mode, and it was necessary because we needed to better understand our specific domains. In the 80s and 90s, certain disciplines started to recognize the importance of other disciplines on their work but the tendency was to bring those skills into a single individual. So we produced, by way of e.g., law professors who could do ga</p><p>3 0.14145379 <a title="601-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-30-Systematic_review_of_publication_bias_in_studies_on_publication_bias.html">1291 andrew gelman stats-2012-04-30-Systematic review of publication bias in studies on publication bias</a></p>
<p>Introduction: Via  Yalda Afshar ,  a 2005 paper  by Hans-Hermann Dubben and Hans-Peter Beck-Bornholdt:
  
Publication bias is a well known phenomenon in clinical literature, in which positive results have a better chance of being published, are published earlier, and are published in journals with higher impact factors. Conclusions exclusively based on published studies, therefore, can be misleading. Selective under-reporting of research might be more widespread and more likely to have adverse consequences for patients than publication of deliberately falsified data. We investigated whether there is preferential publication of positive papers on publication bias.
  
They conclude, “We found no evidence of publication bias in reports on publication bias.”  But of course that’s the sort of finding regarding publication bias of findings on publication bias that you’d expect would get published.  What we really need is a careful meta-analysis to estimate the level of publication bias in studies of publi</p><p>4 0.13681704 <a title="601-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-12-More_on_publishing_in_journals.html">2245 andrew gelman stats-2014-03-12-More on publishing in journals</a></p>
<p>Introduction: I’m postponing today’s scheduled post (“Empirical implications of Empirical Implications of Theoretical Models”) to continue the lively discussion from yesterday,  What if I were to stop publishing in journals? . 
   
 An example:  my papers with Basbøll 
 
Thomas Basbøll and I got into a long discussion on our blogs about business school professor Karl Weick and other cases of  plagiarism  copying text without attribution.  We felt it useful to take our ideas to the next level and write them up as a manuscript, which ended up being logical to split into two papers.  At that point I put some effort into getting these papers published, which I eventually did:   To throw away data: Plagiarism as a statistical crime  went into American Scientist and  When do stories work? Evidence and illustration in the social sciences  will appear in Sociological Methods and Research.  The second paper, in particular, took some effort to place; I got some advice from colleagues in sociology as to where</p><p>5 0.12350021 <a title="601-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>Introduction: Stan Liebowitz writes:
  
Have you ever heard of an article being retracted in economics? I know you have only been doing this for a few years but I suspect that the answer is that none or very few are retracted. No economist would ever deceive another. There is virtually no interest in detecting cheating. And what good would that do if there is no form of punishment? I say this because I think I have found a case in one of our top journals but the editor allowed the authors of the original article to write an anonymous referee report defending themselves and used this report to reject my comment even though an independent referee recommended publication.
  
My reply:  I wonder how this sort of thing will change in the future as journals become less important.  My impression is that, on one side, researchers are increasingly citing NBER reports, Arxiv preprints, and the like; while, from the other direction, journals such as Science and Nature are developing the reputations of being “t</p><p>6 0.11987973 <a title="601-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>7 0.11279088 <a title="601-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<p>8 0.10352227 <a title="601-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-26-Our_broken_scholarly_publishing_system.html">1429 andrew gelman stats-2012-07-26-Our broken scholarly publishing system</a></p>
<p>9 0.10287668 <a title="601-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-01-I_owe_it_all_to_the_haters.html">834 andrew gelman stats-2011-08-01-I owe it all to the haters</a></p>
<p>10 0.10104164 <a title="601-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-30-You_can%E2%80%99t_put_Pandora_back_in_the_box.html">120 andrew gelman stats-2010-06-30-You can’t put Pandora back in the box</a></p>
<p>11 0.1003309 <a title="601-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-15-A_statistical_research_project%3A__Weeding_out_the_fraudulent_citations.html">1321 andrew gelman stats-2012-05-15-A statistical research project:  Weeding out the fraudulent citations</a></p>
<p>12 0.10010626 <a title="601-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-22-Arrow%E2%80%99s_other_theorem.html">675 andrew gelman stats-2011-04-22-Arrow’s other theorem</a></p>
<p>13 0.096079484 <a title="601-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>14 0.088829115 <a title="601-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>15 0.088532008 <a title="601-tfidf-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>16 0.088367797 <a title="601-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>17 0.086862765 <a title="601-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-The_importance_of_style_in_academic_writing.html">902 andrew gelman stats-2011-09-12-The importance of style in academic writing</a></p>
<p>18 0.086432181 <a title="601-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-27-Beyond_the_Valley_of_the_Trolls.html">2269 andrew gelman stats-2014-03-27-Beyond the Valley of the Trolls</a></p>
<p>19 0.08583159 <a title="601-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>20 0.08480648 <a title="601-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-04-%E2%80%9CDon%E2%80%99t_think_of_it_as_duplication._Think_of_it_as_a_single_paper_in_a_superposition_of_two_quantum_journals.%E2%80%9D.html">1654 andrew gelman stats-2013-01-04-“Don’t think of it as duplication. Think of it as a single paper in a superposition of two quantum journals.”</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.157), (1, -0.06), (2, -0.023), (3, -0.094), (4, -0.063), (5, -0.038), (6, -0.012), (7, -0.068), (8, -0.019), (9, 0.034), (10, 0.041), (11, -0.004), (12, -0.041), (13, 0.003), (14, 0.006), (15, -0.03), (16, -0.003), (17, 0.005), (18, -0.006), (19, -0.001), (20, 0.011), (21, -0.001), (22, 0.02), (23, 0.042), (24, 0.003), (25, 0.015), (26, 0.025), (27, -0.006), (28, 0.023), (29, 0.007), (30, -0.022), (31, -0.013), (32, 0.024), (33, 0.001), (34, -0.004), (35, -0.005), (36, -0.019), (37, 0.029), (38, 0.013), (39, 0.01), (40, 0.021), (41, -0.013), (42, -0.025), (43, -0.005), (44, -0.014), (45, 0.021), (46, 0.057), (47, 0.034), (48, 0.014), (49, 0.009)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96821499 <a title="601-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-05-Against_double-blind_reviewing%3A__Political_science_and_statistics_are_not_like_biology_and_physics.html">601 andrew gelman stats-2011-03-05-Against double-blind reviewing:  Political science and statistics are not like biology and physics</a></p>
<p>Introduction: Responding to a proposal to move the journal Political Analysis from double-blind to single-blind reviewing (that is, authors would not know who is reviewing their papers but reviewers would know the authors’ names), Tom Palfrey writes:
  
I agree with the editors’ recommendation. I have served on quite a few editorial boards of journals with different blinding policies, and have seen no evidence that double blind procedures are a useful way to improve the quality of articles published in a journal. Aside from the obvious administrative nuisance and the fact that authorship anonymity is a thing of the past in our discipline, the theoretical and empirical arguments in both directions lead to an ambiguous conclusion. Also keep in mind that the editors know the identity of the authors (they need to know for practical reasons), their identity is not hidden from authors, and ultimately it is they who make the accept/reject decision, and also lobby their friends and colleagues to submit “the</p><p>2 0.85686129 <a title="601-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>Introduction: I discussed two problems:
 
1.  An artificial scarcity applied to journal publication, a scarcity which I believe is being enforced based on a monetary principle of not wanting to reduce the value of publication.  The problem is that journals don’t just spread information and improve communication, they also represent chits for hiring and promotion.  I’d prefer to separate these two aspects of publication. To keep these functions tied together seems to me like a terrible mistake.  It would be as if, instead of using dollar bills as currency, we were to just use  paper , and then if the government kept paper artificially scarce to retain the value of money, so that we were reduced to scratching notes to each other on walls and tables.
 
2.  The discontinuous way in which unpublished papers and submissions to journals are taken as highly suspect and requiring a strong justification of all methods and assumptions, but once a paper becomes published its conclusions are taken as true unless</p><p>3 0.85550845 <a title="601-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>Introduction: Dan Kahan  writes :
  
The basic idea . . . is to promote identification of study designs that scholars who disagree about a proposition would agree would generate evidence relevant to their competing conjectures—regardless of what studies based on such designs actually find. Articles proposing designs of this sort would be selected for publication and only then be carried out, by the proposing researchers with funding from the journal, which would publish the results too.


Now I [Kahan] am aware of a set of real journals that have a similar motivation.


One is the  Journal of Articles in Support of the Null Hypothesis, which as its title implies publishes papers reporting studies that fail to “reject” the null. Like JASNH, LR ≠1J would try to offset the “file drawer” bias and like bad consequences associated with the convention of publishing only findings that are “significant at p < 0.05."


But it would try to do more. By publishing studies that are deemed to have valid designs an</p><p>4 0.85074973 <a title="601-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>Introduction: Jeff Leek  points to  a post by Alex Holcombe, who disputes the idea that science is self-correcting.  Holcombe  writes  [scroll down to get to his part]:
  
The pace of scientific production has quickened, and self-correction has suffered. Findings that might correct old results are considered less interesting than results from more original research questions. Potential corrections are also more contested. As the competition for space in prestigious journals has become increasingly frenzied, doing and publishing studies that would confirm the rapidly accumulating new discoveries, or would correct them, became a losing proposition.
  
Holcombe picks up on some points that we’ve discussed a lot here in the past year.  Here’s Holcombe:
  
In certain subfields, almost all new work appears in only a very few journals, all associated with a single professional society. There is then no way around the senior gatekeepers, who may then suppress corrections with impunity. . . .


The bias agai</p><p>5 0.84864497 <a title="601-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>Introduction: This seems to be the topic of the week.  Yesterday I posted on the sister blog  some further thoughts  on those “Psychological Science” papers on menstrual cycles, biceps size, and political attitudes, tied to a horrible press release from the journal Psychological Science hyping the biceps and politics study.
 
Then I was pointed to these  suggestions  from Richard Lucas and M. Brent Donnellan have on improving the replicability and reproducibility of research published in the Journal of Research in Personality:
  
It goes without saying that editors of scientific journals strive to publish research that is not only theoretically interesting but also methodologically rigorous. The goal is to select papers that advance the field. Accordingly, editors want to publish findings that can be reproduced and replicated by other scientists. Unfortunately, there has been a recent “crisis in confidence” among psychologists about the quality of psychological research (Pashler & Wagenmakers, 2012)</p><p>6 0.84021145 <a title="601-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<p>7 0.83984721 <a title="601-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-16-%E2%80%9CGroundbreaking_or_Definitive%3F_Journals_Need_to_Pick_One%E2%80%9D.html">1122 andrew gelman stats-2012-01-16-“Groundbreaking or Definitive? Journals Need to Pick One”</a></p>
<p>8 0.83916676 <a title="601-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>9 0.83313024 <a title="601-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-30-Systematic_review_of_publication_bias_in_studies_on_publication_bias.html">1291 andrew gelman stats-2012-04-30-Systematic review of publication bias in studies on publication bias</a></p>
<p>10 0.83088529 <a title="601-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>11 0.83030134 <a title="601-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>12 0.82344097 <a title="601-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-01-I_owe_it_all_to_the_haters.html">834 andrew gelman stats-2011-08-01-I owe it all to the haters</a></p>
<p>13 0.81622177 <a title="601-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Evaluating_evidence_from_published_research.html">2006 andrew gelman stats-2013-09-03-Evaluating evidence from published research</a></p>
<p>14 0.81598538 <a title="601-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-06-Against_optimism_about_social_science.html">1844 andrew gelman stats-2013-05-06-Against optimism about social science</a></p>
<p>15 0.81206572 <a title="601-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-06-How_to_think_about_papers_published_in_low-grade_journals%3F.html">1928 andrew gelman stats-2013-07-06-How to think about papers published in low-grade journals?</a></p>
<p>16 0.81157964 <a title="601-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-15-A_statistical_research_project%3A__Weeding_out_the_fraudulent_citations.html">1321 andrew gelman stats-2012-05-15-A statistical research project:  Weeding out the fraudulent citations</a></p>
<p>17 0.80654615 <a title="601-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-01-Post-publication_peer_review%3A__How_it_%28sometimes%29_really_works.html">2004 andrew gelman stats-2013-09-01-Post-publication peer review:  How it (sometimes) really works</a></p>
<p>18 0.80156523 <a title="601-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>19 0.79541993 <a title="601-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-13-Data_sharing_update.html">1055 andrew gelman stats-2011-12-13-Data sharing update</a></p>
<p>20 0.79316044 <a title="601-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-04-Literal_vs._rhetorical.html">2233 andrew gelman stats-2014-03-04-Literal vs. rhetorical</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.028), (13, 0.01), (15, 0.083), (16, 0.074), (21, 0.021), (24, 0.066), (27, 0.013), (32, 0.026), (43, 0.243), (47, 0.017), (63, 0.015), (86, 0.026), (99, 0.244)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94109464 <a title="601-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-21-In_which_I_compare_%E2%80%9CPOLITICO%E2%80%99s_chief_political_columnist%E2%80%9D_unfavorably_to_a_cranky_old_dead_guy_and_one_of_the_funniest_writers_who%E2%80%99s_ever_lived.html">1077 andrew gelman stats-2011-12-21-In which I compare “POLITICO’s chief political columnist” unfavorably to a cranky old dead guy and one of the funniest writers who’s ever lived</a></p>
<p>Introduction: Neil Malhotra writes:
  
I just wanted to alert to this completely misinformed Politico article by Roger Simon, equating sampling theory with “magic.” Normally, I wouldn’t send you this, but I sent him a helpful email and he was a complete jerk about it.
  
Wow—this is really bad. It’s so bad I refuse to link to it. I don’t know who this dude is, but it’s pitiful. Andy Rooney could do better. And I don’t mean Andy Rooney in his prime, I mean Andy Rooney right now. The piece appears to be an attempt at jocularity, but it’s about 10 million times worse than whatever the worst thing is that Dave Barry has ever written.
 
My question to Neil Malhotra is . . . what made you click on this in the first place?
 
P.S.  John Sides  piles on  with some Gallup quotes.</p><p>2 0.9375602 <a title="601-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-08-Cool_GSS_training_video%21__And_cumulative_file_1972-2012%21.html">1754 andrew gelman stats-2013-03-08-Cool GSS training video!  And cumulative file 1972-2012!</a></p>
<p>Introduction: Felipe Osorio made the above video to help people use the General Social Survey and R to answer research questions in social science.  Go for it!
 
Meanwhile, Tom Smith reports:
  
The initial release of the General Social Survey (GSS), cumulative file for 1972-2012 is now  on our website . Codebooks and copies of questionnaires will be posted shortly. Later additional files including the GSS reinterview panels  and additional variables in the cumulative file will be added.
  
P.S.  R scripts are  here .</p><p>3 0.93570757 <a title="601-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-22-Third-party_Dream_Ticket.html">531 andrew gelman stats-2011-01-22-Third-party Dream Ticket</a></p>
<p>Introduction: Who are the only major politicians who are viewed more positively than negatively by the American public?
 
     
 
(See page 3 of  this report .)</p><p>4 0.90798312 <a title="601-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-03-Disconnect_between_drug_and_medical_device_approval.html">314 andrew gelman stats-2010-10-03-Disconnect between drug and medical device approval</a></p>
<p>Introduction: Sanjay Kaul wrotes:
  
By statute (“the least burdensome” pathway), the approval standard for devices by the US FDA is lower than for drugs. Before a new drug can be marketed, the sponsor must show “substantial evidence of effectiveness” as based on two or more well-controlled clinical studies (which literally means 2 trials, each with a p value of <0.05, or 1 large trial with a robust p value <0.00125). In contrast, the sponsor of a new device, especially those that are designated as high-risk (Class III) device, need only demonstrate "substantial equivalence" to an FDA-approved device via the 510(k) exemption or a "reasonable assurance of safety and effectiveness", evaluated through a pre-market approval and typically based on a single study.


What does “reasonable assurance” or “substantial equivalence” imply to you as a Bayesian? These are obviously qualitative constructs, but if one were to quantify them, how would you go about addressing it?
      
The regulatory definitions for</p><p>same-blog 5 0.90518832 <a title="601-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-05-Against_double-blind_reviewing%3A__Political_science_and_statistics_are_not_like_biology_and_physics.html">601 andrew gelman stats-2011-03-05-Against double-blind reviewing:  Political science and statistics are not like biology and physics</a></p>
<p>Introduction: Responding to a proposal to move the journal Political Analysis from double-blind to single-blind reviewing (that is, authors would not know who is reviewing their papers but reviewers would know the authors’ names), Tom Palfrey writes:
  
I agree with the editors’ recommendation. I have served on quite a few editorial boards of journals with different blinding policies, and have seen no evidence that double blind procedures are a useful way to improve the quality of articles published in a journal. Aside from the obvious administrative nuisance and the fact that authorship anonymity is a thing of the past in our discipline, the theoretical and empirical arguments in both directions lead to an ambiguous conclusion. Also keep in mind that the editors know the identity of the authors (they need to know for practical reasons), their identity is not hidden from authors, and ultimately it is they who make the accept/reject decision, and also lobby their friends and colleagues to submit “the</p><p>6 0.88389647 <a title="601-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-17-Bayes_pays.html">857 andrew gelman stats-2011-08-17-Bayes pays</a></p>
<p>7 0.85427785 <a title="601-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-27-Macromuddle.html">1347 andrew gelman stats-2012-05-27-Macromuddle</a></p>
<p>8 0.85003972 <a title="601-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-05-Glenn_Hubbard_and_I_were_on_opposite_sides_of_a_court_case_and_I_didn%E2%80%99t_even_know_it%21.html">1707 andrew gelman stats-2013-02-05-Glenn Hubbard and I were on opposite sides of a court case and I didn’t even know it!</a></p>
<p>9 0.84439749 <a title="601-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-08-Technology_speedup_graph.html">1253 andrew gelman stats-2012-04-08-Technology speedup graph</a></p>
<p>10 0.84336472 <a title="601-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-08-%E2%80%9CIs_the_cyber_mob_a_threat_to_freedom%3F%E2%80%9D.html">75 andrew gelman stats-2010-06-08-“Is the cyber mob a threat to freedom?”</a></p>
<p>11 0.80675292 <a title="601-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-25-Postdoc_Position_%232%3A__Hierarchical_Modeling_and_Statistical_Graphics.html">538 andrew gelman stats-2011-01-25-Postdoc Position #2:  Hierarchical Modeling and Statistical Graphics</a></p>
<p>12 0.80431819 <a title="601-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-25-My_talk_at_Stanford_on_Tuesday.html">679 andrew gelman stats-2011-04-25-My talk at Stanford on Tuesday</a></p>
<p>13 0.79924798 <a title="601-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Mister_P_goes_on_a_date.html">70 andrew gelman stats-2010-06-07-Mister P goes on a date</a></p>
<p>14 0.79813045 <a title="601-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-22-The_Jumpstart_financial_literacy_survey_and_the_different_purposes_of_tests.html">481 andrew gelman stats-2010-12-22-The Jumpstart financial literacy survey and the different purposes of tests</a></p>
<p>15 0.79356503 <a title="601-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-17-How_can_statisticians_help_psychologists_do_their_research_better%3F.html">1860 andrew gelman stats-2013-05-17-How can statisticians help psychologists do their research better?</a></p>
<p>16 0.79171622 <a title="601-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-03-The_statistical_properties_of_smart_chains_%28and_referral_chains_more_generally%29.html">1882 andrew gelman stats-2013-06-03-The statistical properties of smart chains (and referral chains more generally)</a></p>
<p>17 0.7896831 <a title="601-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-30-%E2%80%9CNon-statistical%E2%80%9D_statistics_tools.html">1920 andrew gelman stats-2013-06-30-“Non-statistical” statistics tools</a></p>
<p>18 0.78697097 <a title="601-lda-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-12-Historical_Arc_of_Universities.html">2330 andrew gelman stats-2014-05-12-Historical Arc of Universities</a></p>
<p>19 0.78579807 <a title="601-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-14-1.5_million_people_were_told_that_extreme_conservatives_are_happier_than_political_moderates.__Approximately_.0001_million_Americans_learned_that_the_opposite_is_true..html">1458 andrew gelman stats-2012-08-14-1.5 million people were told that extreme conservatives are happier than political moderates.  Approximately .0001 million Americans learned that the opposite is true.</a></p>
<p>20 0.77440369 <a title="601-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-Displaying_inferences_from_complex_models.html">1815 andrew gelman stats-2013-04-20-Displaying inferences from complex models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
