<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>946 andrew gelman stats-2011-10-07-Analysis of Power Law of Participation</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-946" href="#">andrew_gelman_stats-2011-946</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>946 andrew gelman stats-2011-10-07-Analysis of Power Law of Participation</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-946-html" href="http://andrewgelman.com/2011/10/07/analysis-of-powerlaw-of-participation/">html</a></p><p>Introduction: Rick Wash writes:
  
A colleague as USC (Lian Jian) and I  were recently discussing a statistical analysis issue that both of us have run into recently.


We both mostly do research about how people use online interactive websites.  One property that most of these systems have is known as the “powerlaw of participation” — the distribution of the number of contributions from each person follows a powerlaw.  This mean that a few people contribution a TON and many, many people are in the “long tail” and contribute very rarely.   For example, Facebook posts and twitter posts both have this distribution, as do comments on blogs and many other forms of user contribution online.


This distribution has proven to be a problem when we analyze individual behavior.  The basic problem is that we’d like to account for the fact that we have repeated data from many users, but a large number of users only have 1 or 2 data points.   For example, Lian 
recently analyzed data about monetary contributions</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We both mostly do research about how people use online interactive websites. [sent-2, score-0.255]
</p><p>2 One property that most of these systems have is known as the “powerlaw of participation” — the distribution of the number of contributions from each person follows a powerlaw. [sent-3, score-0.715]
</p><p>3 This mean that a few people contribution a TON and many, many people are in the “long tail” and contribute very rarely. [sent-4, score-0.532]
</p><p>4 For example, Facebook posts and twitter posts both have this distribution, as do comments on blogs and many other forms of user contribution online. [sent-5, score-0.661]
</p><p>5 This distribution has proven to be a problem when we analyze individual behavior. [sent-6, score-0.477]
</p><p>6 The basic problem is that we’d like to account for the fact that we have repeated data from many users, but a large number of users only have 1 or 2 data points. [sent-7, score-0.751]
</p><p>7 For example, Lian  recently analyzed data about monetary contributions on the website Spot. [sent-8, score-0.663]
</p><p>8 Us and in her dataset, over 70% of the contributions were the sole contribution of the contributor. [sent-9, score-0.773]
</p><p>9 com found similar patterns, with large numbers of tags being used only once or twice. [sent-11, score-0.315]
</p><p>10 How would you analyze this, taking advantage of the knowledge that some data points are the same individual? [sent-12, score-0.402]
</p><p>11 Use a hierarchical model with contributions nested within people. [sent-14, score-0.739]
</p><p>12 (AKA use a random effect for people)  But this has problems when the majority of people only have exactly one data point? [sent-15, score-0.514]
</p><p>13 Indeed, with a powerlaw, a large percentage of the data points come from the few high  contributors. [sent-20, score-0.359]
</p><p>14 Use a hierarchical model with contributions nested within people, but lump all of the “low contributors” into a single large category. [sent-22, score-0.938]
</p><p>15 This is what I did for my analysis of delicious tagging data, but it was unsatisfying because the relationship between data points in that category is different than the relationship between data points in the other categories (which each represent one individual). [sent-23, score-0.959]
</p><p>16 It’s fine that the majority of people have exactly one data point. [sent-26, score-0.424]
</p><p>17 Here are some free ones:   - A person-level predictor which is the total number of contributions from that person. [sent-29, score-0.8]
</p><p>18 (Or maybe the logarithm or reciprocal of this total number or will work better as a predictor in a linear model. [sent-30, score-0.541]
</p><p>19 )   - If the contributions are time-ordered, the reciprocal of the time ranking of the contribution (so if someone has 3 contributions, this predictor will be 1, 1/2, and 1/3 for his or her contributions). [sent-31, score-1.122]
</p><p>20 This will catch if there is anything going on when people post a lot of times, if their first few posts are different. [sent-32, score-0.237]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('contributions', 0.445), ('lian', 0.306), ('contribution', 0.26), ('powerlaw', 0.204), ('tags', 0.204), ('reciprocal', 0.186), ('predictor', 0.16), ('analyze', 0.154), ('data', 0.151), ('nested', 0.149), ('posts', 0.135), ('large', 0.111), ('number', 0.109), ('individual', 0.102), ('people', 0.102), ('relationship', 0.101), ('users', 0.1), ('majority', 0.099), ('points', 0.097), ('distribution', 0.096), ('tagging', 0.093), ('usc', 0.093), ('use', 0.09), ('lump', 0.088), ('ton', 0.088), ('total', 0.086), ('unsatisfying', 0.084), ('delicious', 0.084), ('hierarchical', 0.08), ('wash', 0.079), ('worries', 0.076), ('nuanced', 0.076), ('contributors', 0.075), ('exactly', 0.072), ('aka', 0.072), ('thoughts', 0.072), ('ranking', 0.071), ('rick', 0.071), ('away', 0.069), ('sole', 0.068), ('many', 0.068), ('tail', 0.067), ('monetary', 0.067), ('within', 0.065), ('property', 0.065), ('facebook', 0.065), ('proven', 0.064), ('twitter', 0.063), ('interactive', 0.063), ('problem', 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="946-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-07-Analysis_of_Power_Law_of_Participation.html">946 andrew gelman stats-2011-10-07-Analysis of Power Law of Participation</a></p>
<p>Introduction: Rick Wash writes:
  
A colleague as USC (Lian Jian) and I  were recently discussing a statistical analysis issue that both of us have run into recently.


We both mostly do research about how people use online interactive websites.  One property that most of these systems have is known as the “powerlaw of participation” — the distribution of the number of contributions from each person follows a powerlaw.  This mean that a few people contribution a TON and many, many people are in the “long tail” and contribute very rarely.   For example, Facebook posts and twitter posts both have this distribution, as do comments on blogs and many other forms of user contribution online.


This distribution has proven to be a problem when we analyze individual behavior.  The basic problem is that we’d like to account for the fact that we have repeated data from many users, but a large number of users only have 1 or 2 data points.   For example, Lian 
recently analyzed data about monetary contributions</p><p>2 0.18327494 <a title="946-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-28-Combining_two_of_my_interests.html">2228 andrew gelman stats-2014-02-28-Combining two of my interests</a></p>
<p>Introduction: Paul Alper writes:
  
Hi Andrew (or Andy or even Gelman [17 of them]):


 Go to this link  and have some fun with (useless? powerful?) data mining.


As the authors say, it is addictive. 
Paul (no other way to spell it) Alper [215 of us]
  
I’m reminded of  this discussion  from 2012, “Michael’s a Republican, Susan’s a Democrat.”  As I wrote at the time:
  
It’s no surprise that men give more to Republicans and women to Democrats, or that the average contribution to a Republican has a larger dollar value than the average contribution to a Democrat, nor perhaps should we be surprised that “Tom” splits his support between the two parties while “Thomas” is a strong Republican. Still, it’s fun to see the data.


Overall, I think this graph understates contributions to Republicans because it doesn’t include those new super-pacs.
  
But the new tool seems to be based on a different dataset, opinion polls rather than campaign contributions.  Playing around a bit, I see a lot less variability</p><p>3 0.12460989 <a title="946-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-27-Should_statistics_have_a_Nobel_prize%3F.html">2151 andrew gelman stats-2013-12-27-Should statistics have a Nobel prize?</a></p>
<p>Introduction: Xiao-Li  says  yes:
  
The most compelling reason for having highly visible awards in any field is to enhance its ability to attract future talent. Virtually all the media and public attention our profession received in recent years has been on the utility of statistics in all walks of life. We are extremely happy for and proud of this recognition—it is long overdue. However, the media and public have given much more attention to the Fields Medal than to the COPSS Award, even though the former has hardly been about direct or even indirect impact on everyday life. Why this difference? . . . these awards arouse media and public interest by featuring how ingenious the awardees are and how difficult the problems they solved, much like how conquering Everest bestows admiration not because the admirers care or even know much about Everest itself but because it represents the ultimate physical feat. In this sense, the biggest winner of the Fields Medal is mathematics itself: enticing the brig</p><p>4 0.10167672 <a title="946-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>Introduction: A research psychologist writes in with a question that’s so long that I’ll put my answer first, then put the question itself below the fold.
 
Here’s my reply:
 
As I wrote in my Anova paper and in my book with Jennifer Hill, I do think that multilevel models can completely replace Anova.  At the same time, I think the central idea of Anova should persist in our understanding of these models.  To me the central idea of Anova is not F-tests or p-values or sums of squares, but rather the idea of predicting an outcome based on factors with discrete levels, and understanding these factors using variance components.
 
The continuous or categorical response thing doesn’t really matter so much to me.  I have no problem using a normal linear model for continuous outcomes (perhaps suitably transformed) and a logistic model for binary outcomes.
 
I don’t want to throw away interactions just because they’re not statistically significant.  I’d rather partially pool them toward zero using an inform</p><p>5 0.099749655 <a title="946-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>Introduction: Dan Kahan writes: 
  
  
Okay, have done due diligence here & can’t find the reference. It was in recent blog — and was more or less an aside — but you ripped into researchers (pretty sure econometricians, but this could be my memory adding to your account recollections it conjured from my own experience) who purport to make estimates or predictions based on multivariate regression in which the value of particular predictor is set at some level while others “held constant” etc., on ground that variance in that particular predictor independent of covariance in other model predictors is unrealistic.  You made it sound, too, as if this were one of the pet peeves in your menagerie — leading me to think you had blasted into it before.


Know what I’m talking about?


Also — isn’t this really just a way of saying that the model is misspecified — at least if the goal is to try to make a valid & unbiased estimate of the impact of that particular predictor? The problem can’t be that one is usin</p><p>6 0.099578917 <a title="946-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-01-Why_it_can_be_rational_to_vote.html">389 andrew gelman stats-2010-11-01-Why it can be rational to vote</a></p>
<p>7 0.099578917 <a title="946-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-06-Why_it_can_be_rational_to_vote.html">1565 andrew gelman stats-2012-11-06-Why it can be rational to vote</a></p>
<p>8 0.096378557 <a title="946-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-21-Building_a_regression_model_._._._with_only_27_data_points.html">1506 andrew gelman stats-2012-09-21-Building a regression model . . . with only 27 data points</a></p>
<p>9 0.093370438 <a title="946-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>10 0.093284637 <a title="946-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-The_importance_of_style_in_academic_writing.html">902 andrew gelman stats-2011-09-12-The importance of style in academic writing</a></p>
<p>11 0.093090996 <a title="946-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-19-Analysis_of_survey_data%3A_Design_based_models_vs._hierarchical_modeling%3F.html">352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</a></p>
<p>12 0.090045512 <a title="946-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>13 0.089395285 <a title="946-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-07-Reproducible_science_FAIL_%28so_far%29%3A__What%E2%80%99s_stoppin_people_from_sharin_data_and_code%3F.html">1447 andrew gelman stats-2012-08-07-Reproducible science FAIL (so far):  What’s stoppin people from sharin data and code?</a></p>
<p>14 0.089098811 <a title="946-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-23-Examples_of_the_use_of_hierarchical_modeling_to_generalize_to_new_settings.html">1425 andrew gelman stats-2012-07-23-Examples of the use of hierarchical modeling to generalize to new settings</a></p>
<p>15 0.08706516 <a title="946-tfidf-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-21-Random_matrices_in_the_news.html">2258 andrew gelman stats-2014-03-21-Random matrices in the news</a></p>
<p>16 0.085485756 <a title="946-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-05-Question_26_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1367 andrew gelman stats-2012-06-05-Question 26 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>17 0.081654586 <a title="946-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-06-W%E2%80%99man_%3C_W%E2%80%99pedia%2C_again.html">945 andrew gelman stats-2011-10-06-W’man < W’pedia, again</a></p>
<p>18 0.080476187 <a title="946-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-Another_reason_why_you_can_get_good_inferences_from_a_bad_model.html">1527 andrew gelman stats-2012-10-10-Another reason why you can get good inferences from a bad model</a></p>
<p>19 0.079779223 <a title="946-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>20 0.079561621 <a title="946-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-24-The_Tweets-Votes_Curve.html">1823 andrew gelman stats-2013-04-24-The Tweets-Votes Curve</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.192), (1, 0.036), (2, 0.033), (3, -0.011), (4, 0.056), (5, 0.007), (6, -0.017), (7, -0.026), (8, -0.002), (9, 0.022), (10, 0.009), (11, -0.008), (12, 0.007), (13, -0.013), (14, -0.02), (15, 0.044), (16, 0.031), (17, -0.006), (18, 0.02), (19, -0.002), (20, -0.009), (21, 0.006), (22, -0.005), (23, 0.022), (24, -0.053), (25, -0.003), (26, 0.012), (27, 0.019), (28, 0.015), (29, 0.022), (30, 0.02), (31, -0.02), (32, 0.019), (33, 0.007), (34, 0.014), (35, 0.065), (36, 0.026), (37, 0.021), (38, -0.043), (39, 0.019), (40, 0.003), (41, -0.032), (42, -0.028), (43, -0.02), (44, -0.025), (45, 0.007), (46, 0.008), (47, -0.048), (48, -0.012), (49, -0.002)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95982546 <a title="946-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-07-Analysis_of_Power_Law_of_Participation.html">946 andrew gelman stats-2011-10-07-Analysis of Power Law of Participation</a></p>
<p>Introduction: Rick Wash writes:
  
A colleague as USC (Lian Jian) and I  were recently discussing a statistical analysis issue that both of us have run into recently.


We both mostly do research about how people use online interactive websites.  One property that most of these systems have is known as the “powerlaw of participation” — the distribution of the number of contributions from each person follows a powerlaw.  This mean that a few people contribution a TON and many, many people are in the “long tail” and contribute very rarely.   For example, Facebook posts and twitter posts both have this distribution, as do comments on blogs and many other forms of user contribution online.


This distribution has proven to be a problem when we analyze individual behavior.  The basic problem is that we’d like to account for the fact that we have repeated data from many users, but a large number of users only have 1 or 2 data points.   For example, Lian 
recently analyzed data about monetary contributions</p><p>2 0.82238078 <a title="946-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-14-Controversy_about_a_ranking_of_philosophy_departments%2C_or_How_should_we_think_about_statistical_results_when_we_can%E2%80%99t_see_the_raw_data%3F.html">1212 andrew gelman stats-2012-03-14-Controversy about a ranking of philosophy departments, or How should we think about statistical results when we can’t see the raw data?</a></p>
<p>Introduction: Jeff Helzner writes:
  
A friend of mine and I  cited  your  open data article  in our attempts to persuade a professor at another institution [Brian Leiter] into releasing the raw data from his influential rankings of philosophy departments. He is now claiming the national security response:

 
. . . disclosing the reputational data would violate the terms on  which the evaluators agreed to complete the surveys (did they even bother to read the description of the methodology, one wonders?).
 

I [Helzner] do not find this to be a compelling reply in this case. In fact, I  would say that when such data cannot be disclosed it reveals a flaw in the design of the survey. Experimental designs must be open so  that others can run the experiment. Mathematical proofs must be open so that they can be reviewed by others. Likewise, it seems to me that the details of statistical argument should be open to inspection. Do you have any thoughts on this? Or do you know of any other leading statistici</p><p>3 0.81964236 <a title="946-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-21-Building_a_regression_model_._._._with_only_27_data_points.html">1506 andrew gelman stats-2012-09-21-Building a regression model . . . with only 27 data points</a></p>
<p>Introduction: Dan Silitonga writes:
  
I was wondering whether you would have any advice on building a regression model on a very small datasets. I’m in the midst of revamping the model to predict tax collections from unincorporated businesses. But I only have 27 data points, 27 years of annual data.  Any advice would be much appreciated.
  
My reply:
 
This sounds tough, especially given that 27 years of annual data isn’t even 27 independent data points.  
 
I have various essentially orthogonal suggestions:
 
1 [added after seeing John Cook's comment below].  Do your best, making as many assumptions as you need.  In a Bayesian context, this means that you’d use a strong and informative prior and let the data update it as appropriate.  In a less formal setting, you’d start with a guess of a model and then alter it to the extent that your data contradict your original guess.
 
2.  Get more data.  Not by getting information on more years (I assume you can’t do that) but by breaking up the data you do</p><p>4 0.8003726 <a title="946-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-18-Hierarchical_modeling_as_a_framework_for_extrapolation.html">1383 andrew gelman stats-2012-06-18-Hierarchical modeling as a framework for extrapolation</a></p>
<p>Introduction: Phil recently  posted  on the challenge of extrapolation of inferences to new data.  After telling the story of a colleague who flat-out refused to make predictions from his model of buildings to new data, Phil wrote, “This is an interesting problem because it is sort of outside the realm of statistics, and into some sort of meta-statistical area. How can you judge whether your results can be extrapolated to the ‘real world,’ if you cant get a real-world sample to compare to?”
 
In reply, I wrote:
  
I agree that this is an important and general problem, but I don’t think it is outside the realm of statistics! I think that one useful statistical framework here is multilevel modeling. Suppose you are applying a procedure to J cases and want to predict case J+1 (in this case, the cases are buildings and J=52). Let the parameters be theta_1,…,theta_{J+1}, with data y_1,…,y_{J+1}, and case-level predictors X_1,…,X_{J+1}. The question is how to generalize from (theta_1,…,theta_J) to theta_{</p><p>5 0.79477614 <a title="946-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-29-We_go_to_war_with_the_data_we_have%2C_not_the_data_we_want.html">1289 andrew gelman stats-2012-04-29-We go to war with the data we have, not the data we want</a></p>
<p>Introduction: This post is by Phil.
 
Psychologists perform experiments on Canadian undergraduate psychology students and draws conclusions that (they believe) apply to humans in general; they publish in Science. A drug company decides to embark on additional trials that will cost tens of millions of dollars based on the results of a careful double-blind study….whose patients are all volunteers from two hospitals. A movie studio holds 9 screenings of a new movie for volunteer viewers and, based on their survey responses, decides to spend another $8 million to re-shoot the ending.  A researcher interested in the effect of ventilation on worker performance conducts a months-long study in which ventilation levels are varied and worker performance is monitored…in a single building.
 
In almost all fields of research, most studies are based on convenience samples, or on random samples from a larger population that is itself a convenience sample. The paragraph above gives just a few examples.  The benefit</p><p>6 0.79388684 <a title="946-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-12-Get_the_Data.html">569 andrew gelman stats-2011-02-12-Get the Data</a></p>
<p>7 0.79372591 <a title="946-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-16-Memo_to_Reinhart_and_Rogoff%3A__I_think_it%E2%80%99s_best_to_admit_your_errors_and_go_on_from_there.html">1805 andrew gelman stats-2013-04-16-Memo to Reinhart and Rogoff:  I think it’s best to admit your errors and go on from there</a></p>
<p>8 0.79261941 <a title="946-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-10-Combining_data_from_many_sources.html">948 andrew gelman stats-2011-10-10-Combining data from many sources</a></p>
<p>9 0.78469485 <a title="946-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-18-Predictive_checks_for_hierarchical_models.html">154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</a></p>
<p>10 0.77891117 <a title="946-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-A_poll_that_throws_away_data%3F%3F%3F.html">1940 andrew gelman stats-2013-07-16-A poll that throws away data???</a></p>
<p>11 0.77661425 <a title="946-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Mister_P_goes_on_a_date.html">70 andrew gelman stats-2010-06-07-Mister P goes on a date</a></p>
<p>12 0.77463055 <a title="946-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-29-Splitting_the_data.html">544 andrew gelman stats-2011-01-29-Splitting the data</a></p>
<p>13 0.77184129 <a title="946-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Deducer_update.html">211 andrew gelman stats-2010-08-17-Deducer update</a></p>
<p>14 0.77160639 <a title="946-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-20-Cars_vs._trucks.html">527 andrew gelman stats-2011-01-20-Cars vs. trucks</a></p>
<p>15 0.76980805 <a title="946-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-07-Reproducible_science_FAIL_%28so_far%29%3A__What%E2%80%99s_stoppin_people_from_sharin_data_and_code%3F.html">1447 andrew gelman stats-2012-08-07-Reproducible science FAIL (so far):  What’s stoppin people from sharin data and code?</a></p>
<p>16 0.76664954 <a title="946-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-21-How_many_data_points_do_you_really_have%3F.html">1178 andrew gelman stats-2012-02-21-How many data points do you really have?</a></p>
<p>17 0.76102197 <a title="946-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-01-Peter_Huber%E2%80%99s_reflections_on_data_analysis.html">690 andrew gelman stats-2011-05-01-Peter Huber’s reflections on data analysis</a></p>
<p>18 0.75908387 <a title="946-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-12-Visualization%2C_%E2%80%9Cbig_data%E2%80%9D%2C_and_EDA.html">2059 andrew gelman stats-2013-10-12-Visualization, “big data”, and EDA</a></p>
<p>19 0.75898194 <a title="946-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-24-The_Tweets-Votes_Curve.html">1823 andrew gelman stats-2013-04-24-The Tweets-Votes Curve</a></p>
<p>20 0.75883234 <a title="946-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-18-DataMarket.html">215 andrew gelman stats-2010-08-18-DataMarket</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(13, 0.021), (15, 0.025), (16, 0.071), (21, 0.023), (24, 0.116), (42, 0.024), (63, 0.027), (73, 0.017), (75, 0.173), (86, 0.047), (95, 0.022), (99, 0.295)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97178268 <a title="946-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-06-Julian_Symons_on_Frances_Newman.html">893 andrew gelman stats-2011-09-06-Julian Symons on Frances Newman</a></p>
<p>Introduction: “She was forty years old when she died.  It is possible that her art might have developed to include a wider area of human experience, just as possible that the chilling climate of the thirties might have withered it altogether.  But what she actually wrote was greatly talented.  She deserves a place, although obviously not a foremost one, in any literary history of the years between the wars.  The last letter she wrote, or rather dictated, to the printer of the Laforgue translations shows the invariable fastidiousness of her talent, a fastidiousness which is often infuriating but just as often impressive, and is in any case rare enough to be worth remembrance:
  
 To the Printer of Six Moral Tales 






This book is to be spelled and its words are to be hyphenated according to the usage of the Concise Oxford Dictionary.


Page introduction continuously with the tales.


Do not put brackets around the numbers of the pages.


All the ‘todays’ and all the ‘tomorrows’ should be spelled w</p><p>2 0.96775103 <a title="946-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-18-Problems_with_Haiti_elections%3F.html">522 andrew gelman stats-2011-01-18-Problems with Haiti elections?</a></p>
<p>Introduction: Mark Weisbrot points me to  this report  trashing a recent OAS report on Haiti’s elections.  Weisbrot writes:
  
The two simplest things that are wrong with the OAS analysis are: (1)  By looking only at a sample of the tally sheets and not using any statistical test, they have no idea how many other tally sheets would also be thrown out by the same criteria that they used, and how that would change the result  and (2)  The missing/quarantined tally sheets are much greater in number than the ones that they threw out; our analysis indicates that if these votes had been counted, the result would go the other way.
  
I have not had a chance to take a look at this myself but I’m posting it here so that experts on election irregularities can see this and give their judgments.
 
P.S.  Weisbrot updates:
  
 
We [Weisbrot et al.] published our actual paper on the OAS Mission’s Report today.  The press release is  here  and gives a very good summary of the major problems with the OAS Mission rep</p><p>3 0.96559155 <a title="946-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-18-Christopher_Hitchens_was_a_Bayesian.html">1067 andrew gelman stats-2011-12-18-Christopher Hitchens was a Bayesian</a></p>
<p>Introduction: 1.
 
We Bayesian statisticians like to say there are three kinds of statisticians:
 
a.  Bayesians; 
b.  People who are Bayesians but don’t realize it (that is, they act in coherence with some unstated probability); 
c.  Failed Bayesians (that is, people whose inference could be improved by some attention to coherence).
 
So, if a statistician does great work, we are inclined to claim this person for the Bayesian cause, even if he or she vehemently denies any Bayesian leanings.
 
2.
 
In his autobiography, Bertrand Russell tells the story of when he went to prison for opposing World War 1:
  
I [Russell] was much cheered on my arrival by the warden at the gate, who had to take particulars about me. He asked my religion, and I replied ‘agnostic.’ He asked how to spell it, and remarked with a sigh: “Well, there are many religions, but I suppose they all worship the same God.” This remark kept me cheerful for about a week.
  
3.
 
In  an op-ed  today, Ross Douthat argues that celebrated a</p><p>4 0.96301556 <a title="946-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-12-Alert%3A__Incompetent_colleague_wastes_time_of_hardworking_Wolfram_Research_publicist.html">28 andrew gelman stats-2010-05-12-Alert:  Incompetent colleague wastes time of hardworking Wolfram Research publicist</a></p>
<p>Introduction: Marty McKee at Wolfram Research appears to have a very very stupid colleague.  McKee  wrote  to Christian Robert:
  
Your article, “Evidence and Evolution: A review”, caught the attention of one of my colleagues, who thought that it could be developed into an interesting Demonstration to add to the Wolfram Demonstrations Project.
  
As Christian points out, adapting his book review into a computer demonstration would be quite a feat!  I wonder what McKee’s colleague could be thinking?  I recommend that Wolfram fire McKee’s colleague immediately:  what an idiot!
 
P.S.  I’m not actually sure that McKee was the author of this email; I’m guessing this was the case because this other  very similar  email was written under his name.
 
P.P.S.  To head off the inevitable comments:  Yes, yes, I know this is no big deal and I shouldn’t get bent out of shape about it.  But . . . Wolfram Research has contributed such great things to the world, that I hate to think of them wasting any money paying</p><p>5 0.9548673 <a title="946-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Recently_in_the_sister_blog.html">1396 andrew gelman stats-2012-06-27-Recently in the sister blog</a></p>
<p>Introduction: If Paul Krugman is right and it’s 1931, what happens next? 
 
 What’s with Niall Ferguson? 
 
 Hey, this reminds me of the Democrats in the U.S. . . . 
 
 Would President Romney contract the economy? 
 
 Inconsistency with prior knowledge triggers children’s causal explanatory reasoning</p><p>same-blog 6 0.93619889 <a title="946-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-07-Analysis_of_Power_Law_of_Participation.html">946 andrew gelman stats-2011-10-07-Analysis of Power Law of Participation</a></p>
<p>7 0.93397909 <a title="946-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-11-%24.html">1003 andrew gelman stats-2011-11-11-$</a></p>
<p>8 0.93279546 <a title="946-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Excel-bashing.html">1808 andrew gelman stats-2013-04-17-Excel-bashing</a></p>
<p>9 0.92956793 <a title="946-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-The_first_version_of_my_%E2%80%9Cinference_from_iterative_simulation_using_parallel_sequences%E2%80%9D_paper%21.html">1309 andrew gelman stats-2012-05-09-The first version of my “inference from iterative simulation using parallel sequences” paper!</a></p>
<p>10 0.91000879 <a title="946-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-My_talk_Tues_24_Sept_at_12h30_at_Universit%C3%A9_de_Technologie_de_Compi%C3%A8gne.html">2034 andrew gelman stats-2013-09-23-My talk Tues 24 Sept at 12h30 at Université de Technologie de Compiègne</a></p>
<p>11 0.90429717 <a title="946-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-02-2013.html">2157 andrew gelman stats-2014-01-02-2013</a></p>
<p>12 0.89816439 <a title="946-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-29-My_talk_in_Amsterdam_tomorrow_%28Wed_29_Oct%29%3A__Can_we_use_Bayesian_methods_to_resolve_the_current_crisis_of_statistically-significant_research_findings_that_don%E2%80%99t_hold_up%3F.html">2081 andrew gelman stats-2013-10-29-My talk in Amsterdam tomorrow (Wed 29 Oct):  Can we use Bayesian methods to resolve the current crisis of statistically-significant research findings that don’t hold up?</a></p>
<p>13 0.89050072 <a title="946-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-28-Advice_to_help_the_rich_get_richer.html">8 andrew gelman stats-2010-04-28-Advice to help the rich get richer</a></p>
<p>14 0.88139892 <a title="946-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-06-How_much_time_%28if_any%29_should_we_spend_criticizing_research_that%E2%80%99s_fraudulent%2C_crappy%2C_or_just_plain_pointless%3F.html">2235 andrew gelman stats-2014-03-06-How much time (if any) should we spend criticizing research that’s fraudulent, crappy, or just plain pointless?</a></p>
<p>15 0.88114715 <a title="946-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-28-Combining_two_of_my_interests.html">2228 andrew gelman stats-2014-02-28-Combining two of my interests</a></p>
<p>16 0.87789261 <a title="946-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-20-Picking_on_Gregg_Easterbrook.html">967 andrew gelman stats-2011-10-20-Picking on Gregg Easterbrook</a></p>
<p>17 0.87586057 <a title="946-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-03-He_doesn%E2%80%99t_trust_the_fit_._._._r%3D.999.html">315 andrew gelman stats-2010-10-03-He doesn’t trust the fit . . . r=.999</a></p>
<p>18 0.8753581 <a title="946-lda-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>19 0.87458843 <a title="946-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-22-Struggles_over_the_criticism_of_the_%E2%80%9Ccannabis_users_and_IQ_change%E2%80%9D_paper.html">1910 andrew gelman stats-2013-06-22-Struggles over the criticism of the “cannabis users and IQ change” paper</a></p>
<p>20 0.87384921 <a title="946-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-05-Watership_Down%2C_thick_description%2C_applied_statistics%2C_immutability_of_stories%2C_and_playing_tennis_with_a_net.html">1750 andrew gelman stats-2013-03-05-Watership Down, thick description, applied statistics, immutability of stories, and playing tennis with a net</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
