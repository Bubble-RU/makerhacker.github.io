<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>998 andrew gelman stats-2011-11-08-Bayes-Godel</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-998" href="#">andrew_gelman_stats-2011-998</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>998 andrew gelman stats-2011-11-08-Bayes-Godel</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-998-html" href="http://andrewgelman.com/2011/11/08/bayesgodel/">html</a></p><p>Introduction: Sean O’Riordain writes:
  
Your article, “ The holes in my philosophy of Bayesian data analysis ” caused me to wonder whether it was possible to have a consistent philosophy of data analysis and whether it could it be possible that Godel’s incompleteness theorem extends as far as to say that it wasn’t possible?
  
I don’t know but my guess is that this is all related to our lack of a good model for hypothesis generation.  Statistics focuses on deductive inference within models and model checking to evaluate models, but we don’t have a good handle on the creation of models.  (I’m hoping that some of our network-of-models stuff will be helpful.)</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I don’t know but my guess is that this is all related to our lack of a good model for hypothesis generation. [sent-2, score-0.754]
</p><p>2 Statistics focuses on deductive inference within models and model checking to evaluate models, but we don’t have a good handle on the creation of models. [sent-3, score-1.755]
</p><p>3 (I’m hoping that some of our network-of-models stuff will be helpful. [sent-4, score-0.292]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('philosophy', 0.327), ('possible', 0.283), ('sean', 0.278), ('deductive', 0.261), ('extends', 0.254), ('holes', 0.243), ('creation', 0.234), ('focuses', 0.193), ('whether', 0.177), ('theorem', 0.175), ('handle', 0.174), ('caused', 0.174), ('hoping', 0.173), ('evaluate', 0.166), ('models', 0.154), ('checking', 0.143), ('lack', 0.141), ('consistent', 0.141), ('wasn', 0.133), ('analysis', 0.132), ('hypothesis', 0.125), ('model', 0.122), ('stuff', 0.119), ('related', 0.116), ('wonder', 0.115), ('within', 0.108), ('good', 0.102), ('far', 0.099), ('guess', 0.099), ('inference', 0.098), ('data', 0.084), ('bayesian', 0.08), ('statistics', 0.065), ('article', 0.06), ('say', 0.059), ('know', 0.049), ('writes', 0.047), ('could', 0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="998-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-08-Bayes-Godel.html">998 andrew gelman stats-2011-11-08-Bayes-Godel</a></p>
<p>Introduction: Sean O’Riordain writes:
  
Your article, “ The holes in my philosophy of Bayesian data analysis ” caused me to wonder whether it was possible to have a consistent philosophy of data analysis and whether it could it be possible that Godel’s incompleteness theorem extends as far as to say that it wasn’t possible?
  
I don’t know but my guess is that this is all related to our lack of a good model for hypothesis generation.  Statistics focuses on deductive inference within models and model checking to evaluate models, but we don’t have a good handle on the creation of models.  (I’m hoping that some of our network-of-models stuff will be helpful.)</p><p>2 0.23940799 <a title="998-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<p>Introduction: Here’s an article  that I believe is flat-out entertaining to read.  It’s about philosophy, so it’s supposed to be entertaining, in any case.
 
Here’s the abstract:
  
A substantial school in the philosophy of science identifies Bayesian inference with inductive inference and even rationality as such, and seems to be strengthened by the rise and practical success of Bayesian statistics. We argue that the most successful forms of Bayesian statistics do not actually support that particular philosophy but rather accord much better with sophisticated forms of hypothetico-deductivism. We examine the actual role played by prior distributions in Bayesian models, and the crucial aspects of model checking and model revision, which fall outside the scope of Bayesian confirmation theory. We draw on the literature on the consistency of Bayesian updating and also on our experience of applied work in social science.






Clarity about these matters should benefit not just philosophy of science, but</p><p>3 0.23867801 <a title="998-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>Introduction: I’ll answer the above question after first sharing some background and history on the the philosophy of Bayesian statistics, which appeared at the end of our  rejoinder  to the discussion to which I  linked  the other day:
  
When we were beginning our statistical educations, the word ‘Bayesian’ conveyed membership in an obscure cult. Statisticians who were outside the charmed circle could ignore the Bayesian subfield, while Bayesians themselves tended to be either apologetic or brazenly defiant. These two extremes manifested themselves in ever more elaborate proposals for non-informative priors, on the one hand, and declarations of the purity of subjective probability, on the other.


Much has changed in the past 30 years. ‘Bayesian’ is now often used in casual scientific parlance as a synonym for ‘rational’, the anti-Bayesians have mostly disappeared, and non-Bayesian statisticians feel the need to keep up with developments in Bayesian modelling and computation. Bayesians themselves</p><p>4 0.21431981 <a title="998-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>Introduction: In  my remarks  on Arrow’s theorem (the weak form of Arrow’s Theorem is that any result can be published no more than five times. The strong form is that every result will be published five times), I meant no criticism of Bruno Frey, the author of the articles in question:  I agree that it can be a contribution to publish in multiple places.  Regarding the evaluation of contributions, it should be possible to evaluate research contributions and also evaluate communication.  One problem is that communication is both under- and over-counted.  It’s undercounted in that we mostly get credit for original ideas not for exposition; it’s overcounted in that we need communication skills to publish in the top journals.  But I don’t think these two biases cancel out.
 
The real reason I’m bringing this up, though, is because Arrow’s theorem happened to me recently and in interesting way.  Here’s the story.
 
Two years ago I was contacted by Harold Kincaid to write a chapter on Bayesian statistics</p><p>5 0.1886238 <a title="998-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>Introduction: I’ve been writing a lot about my philosophy of Bayesian statistics and how it fits into Popper’s ideas about falsification and Kuhn’s ideas about scientific revolutions.
 
 Here’s  my long, somewhat technical paper with Cosma Shalizi. 
 Here’s  our shorter overview for the volume on the philosophy of social science. 
 Here’s  my latest try (for an online symposium), focusing on the key issues.
 
I’m pretty happy with my approach–the familiar idea that Bayesian data analysis iterates the three steps of model building, inference, and model checking–but it does have some unresolved (maybe unresolvable) problems.  Here are a couple mentioned in the third of the above links.
 
Consider a simple model with independent data y_1, y_2, .., y_10 ~ N(θ,σ^2), with a prior distribution θ ~ N(0,10^2) and σ known and taking on some value of approximately 10. Inference about μ is straightforward, as is model checking, whether based on graphs or numerical summaries such as the sample variance and skewn</p><p>6 0.17069326 <a title="998-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>7 0.16669111 <a title="998-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>8 0.15530336 <a title="998-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>9 0.14934543 <a title="998-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-27-Jelte_Wicherts_lays_down_the_stats_on_IQ.html">6 andrew gelman stats-2010-04-27-Jelte Wicherts lays down the stats on IQ</a></p>
<p>10 0.14822216 <a title="998-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Popper_and_Jaynes.html">2007 andrew gelman stats-2013-09-03-Popper and Jaynes</a></p>
<p>11 0.14382195 <a title="998-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>12 0.13750124 <a title="998-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-01-Tukey%E2%80%99s_philosophy.html">496 andrew gelman stats-2011-01-01-Tukey’s philosophy</a></p>
<p>13 0.13730213 <a title="998-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>14 0.1369482 <a title="998-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>15 0.13602486 <a title="998-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>16 0.13430674 <a title="998-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>17 0.12480961 <a title="998-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>18 0.11918946 <a title="998-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>19 0.11592004 <a title="998-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<p>20 0.10733181 <a title="998-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.156), (1, 0.135), (2, -0.081), (3, 0.044), (4, -0.083), (5, 0.026), (6, -0.069), (7, 0.033), (8, 0.121), (9, -0.002), (10, 0.016), (11, -0.003), (12, -0.052), (13, 0.01), (14, -0.0), (15, 0.03), (16, 0.071), (17, -0.002), (18, -0.012), (19, 0.03), (20, -0.025), (21, 0.012), (22, -0.012), (23, -0.061), (24, -0.015), (25, -0.042), (26, -0.052), (27, -0.008), (28, -0.035), (29, -0.017), (30, 0.035), (31, -0.044), (32, 0.011), (33, -0.028), (34, -0.015), (35, 0.046), (36, 0.017), (37, -0.011), (38, 0.009), (39, 0.004), (40, 0.005), (41, -0.052), (42, -0.02), (43, 0.009), (44, 0.082), (45, 0.043), (46, 0.033), (47, -0.071), (48, 0.004), (49, -0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97019273 <a title="998-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-08-Bayes-Godel.html">998 andrew gelman stats-2011-11-08-Bayes-Godel</a></p>
<p>Introduction: Sean O’Riordain writes:
  
Your article, “ The holes in my philosophy of Bayesian data analysis ” caused me to wonder whether it was possible to have a consistent philosophy of data analysis and whether it could it be possible that Godel’s incompleteness theorem extends as far as to say that it wasn’t possible?
  
I don’t know but my guess is that this is all related to our lack of a good model for hypothesis generation.  Statistics focuses on deductive inference within models and model checking to evaluate models, but we don’t have a good handle on the creation of models.  (I’m hoping that some of our network-of-models stuff will be helpful.)</p><p>2 0.81966221 <a title="998-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-13-My_wikipedia_edit.html">904 andrew gelman stats-2011-09-13-My wikipedia edit</a></p>
<p>Introduction: The other day someone mentioned my complaint about the Wikipedia article on “Bayesian inference” (see footnote 1 of  this article ) and he said I should fix the Wikipedia entry myself.
 
And  so I did .  I didn’t have the energy to rewrite the whole article–in particular, all of its examples involve discrete parameters, whereas the Bayesian problems I work on generally have continuous parameters, and its “mathematical foundations” section focuses on “independent identically distributed observations x” rather than data y which can have different distributions.  It’s just a wacky, unbalanced article.  But I altered the first few paragraphs to get rid of the stuff about the posterior probability that a model is true.
 
I much prefer the  Scholarpedia article on Bayesian statistics  by David Spiegelhalter and Kenneth Rice, but I couldn’t bring myself to simply delete the Wikipedia article and replace it with the Scholarpedia content.
 
Just to be clear:  I’m not at all trying to disparage</p><p>3 0.81530756 <a title="998-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>Introduction: I’ll answer the above question after first sharing some background and history on the the philosophy of Bayesian statistics, which appeared at the end of our  rejoinder  to the discussion to which I  linked  the other day:
  
When we were beginning our statistical educations, the word ‘Bayesian’ conveyed membership in an obscure cult. Statisticians who were outside the charmed circle could ignore the Bayesian subfield, while Bayesians themselves tended to be either apologetic or brazenly defiant. These two extremes manifested themselves in ever more elaborate proposals for non-informative priors, on the one hand, and declarations of the purity of subjective probability, on the other.


Much has changed in the past 30 years. ‘Bayesian’ is now often used in casual scientific parlance as a synonym for ‘rational’, the anti-Bayesians have mostly disappeared, and non-Bayesian statisticians feel the need to keep up with developments in Bayesian modelling and computation. Bayesians themselves</p><p>4 0.80634129 <a title="998-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>Introduction: Deborah Mayo  collected  some reactions to my recent  article , Induction and Deduction in Bayesian Data Analysis.
 
I’m pleased that that everybody (philosopher Mayo, applied statistician Stephen Senn, and theoretical statistician Larry Wasserman) is so positive about my article and that nobody’s defending the sort of hard-core inductivism that’s featured on the Bayesian inference wikipedia page.  Here’s the Wikipedia definition, which I  disagree  with:
  
Bayesian inference uses aspects of the scientific method, which involves collecting evidence that is meant to be consistent or inconsistent with a given hypothesis. As evidence accumulates, the degree of belief in a hypothesis ought to change. With enough evidence, it should become very high or very low. . . . Bayesian inference uses a numerical estimate of the degree of belief in a hypothesis before evidence has been observed and calculates a numerical estimate of the degree of belief in the hypothesis after evidence has been obse</p><p>5 0.8026666 <a title="998-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>Introduction: Astrophysicist Andrew Jaffe pointed me to  this and discussion  of my  philosophy  of statistics (which is, in turn, my rational reconstruction of the statistical practice of Bayesians such as Rubin and Jaynes).  Jaffe’s summary is fair enough and I only disagree in a few points: 
   
1.  Jaffe writes:
  
Subjective probability, at least the way it is actually used by practicing scientists, is a sort of “as-if” subjectivity — how would an agent reason if her beliefs were reflected in a certain set of probability distributions? This is why when I discuss probability I try to make the pedantic point that all probabilities are conditional, at least on some background prior information or context.
  
I agree, and my problem with the usual procedures used for Bayesian model comparison and Bayesian model averaging is not that these approaches are subjective but that the particular models being considered don’t make sense.  I’m thinking of the sorts of models that say the truth is either A or</p><p>6 0.80159307 <a title="998-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<p>7 0.78401655 <a title="998-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>8 0.77466238 <a title="998-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>9 0.77459872 <a title="998-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>10 0.76469982 <a title="998-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>11 0.76149261 <a title="998-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>12 0.75102109 <a title="998-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>13 0.74881727 <a title="998-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>14 0.74367416 <a title="998-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>15 0.73880696 <a title="998-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>16 0.73068023 <a title="998-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Valencia%3A___Summer_of_1991.html">72 andrew gelman stats-2010-06-07-Valencia:   Summer of 1991</a></p>
<p>17 0.73023063 <a title="998-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>18 0.72592831 <a title="998-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-09-The_anti-Bayesian_moment_and_its_passing.html">1571 andrew gelman stats-2012-11-09-The anti-Bayesian moment and its passing</a></p>
<p>19 0.72128671 <a title="998-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>20 0.71667027 <a title="998-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.028), (16, 0.131), (24, 0.02), (36, 0.224), (81, 0.041), (99, 0.412)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95115304 <a title="998-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-10-%E2%80%9CProposition_and_experiment%E2%80%9D.html">1797 andrew gelman stats-2013-04-10-“Proposition and experiment”</a></p>
<p>Introduction: Anna Lena Phillips  writes :
  
I. Many people will not, of their own accord, look at a poem.


II. Millions of people will, of their own accord, spend lots and lots of time looking at photographs of cats.


III. Therefore, earlier this year, I concluded that the best strategy for increasing the number of viewers for poems would be to print them on top of photographs of cats.


IV. I happen to like looking at both poems and cats.


V. So this is, for me, a win-win situation.


VI. Fortunately, my own cat is a patient model, and (if I am to be believed) quite photogenic.


VII. The aforementioned cat is Tisko Tansi, small hero.


VII. Thus I present to you (albeit in digital rather than physical form) an Endearments broadside, featuring a poem that originally appeared in BlazeVOX spring 2011.


VIII. If you want to share a copy of this image, please ask first. If you want a real copy, you can ask about that too.
  
She follows up with an image of a cat, on which is superimposed a short</p><p>2 0.94796753 <a title="998-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-27-In_Linux%2C_use_jags%28%29_to_call_Jags_instead_of_using_bugs%28%29_to_call_OpenBugs.html">55 andrew gelman stats-2010-05-27-In Linux, use jags() to call Jags instead of using bugs() to call OpenBugs</a></p>
<p>Introduction: Douglas Anderton informed us that, in a Linux system, you can’t call OpenBugs from R using bugs() from the R2Winbugs package.  Instead, you should call Jags using jags() from the R2jags package.
 
P.S.  Not the Rotter’s Club guy.</p><p>3 0.94127572 <a title="998-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-02-Obama_and_Reagan%2C_sitting_in_a_tree%2C_etc..html">551 andrew gelman stats-2011-02-02-Obama and Reagan, sitting in a tree, etc.</a></p>
<p>Introduction: I saw this picture staring at me from the newsstand the other day:
 
 
 
 Here’s  the accompanying article, by Michael Scherer and Michael Duffy, which echoes some of the points I made  a few months ago , following the midterm election:
  
Why didn’t Obama do a better job of leveling with the American people? In his first months in office, why didn’t he anticipate the example of the incoming British government and warn people of economic blood, sweat, and tears? Why did his economic team release overly-optimistic graphs such as shown here? Wouldn’t it have been better to have set low expectations and then exceed them, rather than the reverse?


I don’t know, but here’s my theory. When Obama came into office, I imagine one of his major goals was to avoid repeating the experiences of Bill Clinton and Jimmy Carter in their first two years.


Clinton, you may recall, was elected with less then 50% of the vote, was never given the respect of a “mandate” by congressional Republicans, wasted</p><p>same-blog 4 0.93535876 <a title="998-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-08-Bayes-Godel.html">998 andrew gelman stats-2011-11-08-Bayes-Godel</a></p>
<p>Introduction: Sean O’Riordain writes:
  
Your article, “ The holes in my philosophy of Bayesian data analysis ” caused me to wonder whether it was possible to have a consistent philosophy of data analysis and whether it could it be possible that Godel’s incompleteness theorem extends as far as to say that it wasn’t possible?
  
I don’t know but my guess is that this is all related to our lack of a good model for hypothesis generation.  Statistics focuses on deductive inference within models and model checking to evaluate models, but we don’t have a good handle on the creation of models.  (I’m hoping that some of our network-of-models stuff will be helpful.)</p><p>5 0.92407644 <a title="998-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-20-%E2%80%9CPeople_with_an_itch_to_scratch%E2%80%9D.html">101 andrew gelman stats-2010-06-20-“People with an itch to scratch”</a></p>
<p>Introduction: Derek Sonderegger writes:
  
I have just finished my Ph.D. in statistics and am currently working in applied statistics (plant ecology) using Bayesian statistics.  As the statistician in the group I only ever get the ‘hard analysis’ problems that don’t readily fit into standard models.  As I delve into the computational aspects of Bayesian analysis, I find myself increasingly frustrated with the current set of tools.  I was delighted to see  JAGS 2.0  just came out and spent yesterday happily playing with it.


My question is, where do you see the short-term future of Bayesian computing going and what can we do to steer it in a particular direction?
      
In your book with Dr Hill, you mention that you expect BUGS (or its successor) to become increasingly sophisticated and, for example, re-parameterizations that increase convergence rates would be handled automatically.  Just as R has been successful because users can extend it, I think progress here also will be made by input from ‘p</p><p>6 0.92267478 <a title="998-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-31-Watercolor_regression.html">1478 andrew gelman stats-2012-08-31-Watercolor regression</a></p>
<p>7 0.91809231 <a title="998-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-02-Information_is_good.html">176 andrew gelman stats-2010-08-02-Information is good</a></p>
<p>8 0.91802841 <a title="998-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-10-They%E2%80%99d_rather_be_rigorous_than_right.html">1666 andrew gelman stats-2013-01-10-They’d rather be rigorous than right</a></p>
<p>9 0.9133268 <a title="998-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-17-NSF_program_%E2%80%9Cto_support_analytic_and_methodological_research_in_support_of_its_surveys%E2%80%9D.html">1217 andrew gelman stats-2012-03-17-NSF program “to support analytic and methodological research in support of its surveys”</a></p>
<p>10 0.91284621 <a title="998-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-19-If_a_comment_is_flagged_as_spam%2C_it_will_disappear_forever.html">619 andrew gelman stats-2011-03-19-If a comment is flagged as spam, it will disappear forever</a></p>
<p>11 0.9077487 <a title="998-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Who_gets_wedding_announcements_in_the_Times%3F.html">370 andrew gelman stats-2010-10-25-Who gets wedding announcements in the Times?</a></p>
<p>12 0.90201533 <a title="998-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-08-Of_parsing_and_chess.html">1847 andrew gelman stats-2013-05-08-Of parsing and chess</a></p>
<p>13 0.89978528 <a title="998-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>14 0.89143449 <a title="998-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-18-What%E2%80%99s_my_Kasparov_number%3F.html">2105 andrew gelman stats-2013-11-18-What’s my Kasparov number?</a></p>
<p>15 0.8897047 <a title="998-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-22-Battle_of_the_Repo_Man_quotes%3A__Reid_Hastie%E2%80%99s_turn.html">1336 andrew gelman stats-2012-05-22-Battle of the Repo Man quotes:  Reid Hastie’s turn</a></p>
<p>16 0.88938516 <a title="998-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-15-The_two_faces_of_Erving_Goffman%3A__Subtle_observer_of_human_interactions%2C_and_Smug_organzation_man.html">415 andrew gelman stats-2010-11-15-The two faces of Erving Goffman:  Subtle observer of human interactions, and Smug organzation man</a></p>
<p>17 0.88404596 <a title="998-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>18 0.88237023 <a title="998-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-17-Joanne_Gowa_scooped_me_by_22_years_in_my_criticism_of_Axelrod%E2%80%99s_Evolution_of_Cooperation.html">348 andrew gelman stats-2010-10-17-Joanne Gowa scooped me by 22 years in my criticism of Axelrod’s Evolution of Cooperation</a></p>
<p>19 0.87911081 <a title="998-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-26-Musical_chairs_in_econ_journals.html">371 andrew gelman stats-2010-10-26-Musical chairs in econ journals</a></p>
<p>20 0.87750047 <a title="998-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-17-G%2B_hangout_for_test_run_of_BDA_course.html">2066 andrew gelman stats-2013-10-17-G+ hangout for test run of BDA course</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
