<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1062 andrew gelman stats-2011-12-16-Mr. Pearson, meet Mr. Mandelbrot:  Detecting Novel Associations in Large Data Sets</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-1062" href="#">andrew_gelman_stats-2011-1062</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1062 andrew gelman stats-2011-12-16-Mr. Pearson, meet Mr. Mandelbrot:  Detecting Novel Associations in Large Data Sets</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-1062-html" href="http://andrewgelman.com/2011/12/16/mr-pearson-meet-mr-mandelbrot-detecting-novel-associations-in-large-data-sets/">html</a></p><p>Introduction: Jeremy Fox asks what I think about  this paper  by David N. Reshef, Yakir Reshef, Hilary Finucane, Sharon  Grossman, Gilean McVean, Peter Turnbaugh, Eric Lander, Michael Mitzenmacher, and Pardis Sabeti which proposes a new nonlinear R-squared-like measure.
 
My quick answer is that it looks really cool!
 
From my quick reading of the paper, it appears that the method reduces on average to the usual R-squared when fit to data of the form y = a + bx + error, and that it also has a similar interpretation when “a + bx” is replaced by other continuous functions.
 
Unlike R-squared, the method of Reshef et al. depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way.  The dependence on scale is inevitable for such a general method.  Just consider:  if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data.  So the sca</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Jeremy Fox asks what I think about  this paper  by David N. [sent-1, score-0.085]
</p><p>2 Reshef, Yakir Reshef, Hilary Finucane, Sharon  Grossman, Gilean McVean, Peter Turnbaugh, Eric Lander, Michael Mitzenmacher, and Pardis Sabeti which proposes a new nonlinear R-squared-like measure. [sent-2, score-0.078]
</p><p>3 From my quick reading of the paper, it appears that the method reduces on average to the usual R-squared when fit to data of the form y = a + bx + error, and that it also has a similar interpretation when “a + bx” is replaced by other continuous functions. [sent-4, score-0.796]
</p><p>4 depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way. [sent-6, score-0.156]
</p><p>5 The dependence on scale is inevitable for such a general method. [sent-7, score-0.309]
</p><p>6 Just consider:  if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data. [sent-8, score-0.493]
</p><p>7 The clever idea of the paper is that, instead of going for an absolute measure (which, as we’ve seen, will be scale-dependent), they focus on the problem of summarizing the grid of pairwise dependences in a large set of variables. [sent-10, score-0.756]
</p><p>8 As they put it:  “Imagine a data set with hundreds of variables, which may contain important, undiscovered relationships. [sent-11, score-0.102]
</p><p>9 If you do not already know what kinds of relationships to search for, how do you efficiently identify the important ones? [sent-15, score-0.071]
</p><p>10 provide a relative rather than absolute measure of association, suitable for comparing pairs of variables within a single dataset even if the interpretation is not so clear between datasets. [sent-17, score-0.76]
</p><p>11 I suspect that the R-squared-like nature of the method will bother some purists who have bashed R-squared’s dependence on the range of x in the data. [sent-18, score-0.394]
</p><p>12 But, as regular readers will know, I like R-squared (in its place) and I have warm feelings about this generalization. [sent-19, score-0.072]
</p><p>13 What is the value of their association measure if applied to data that are on a circle? [sent-21, score-0.31]
</p><p>14 For example, suppose you generate these 1000 points in R:     n <- 1000  theta <- runif (n, 0, 2*pi)  x <- cos (theta)  y <- sin (theta)      Simulated in this way, x and y have an R-squared of 0. [sent-22, score-0.455]
</p><p>15 But, from the description of the method in the paper, it seems that their R-squared-like measure might be very close to 1. [sent-24, score-0.439]
</p><p>16 If you can capture a bivariate distribution by a simple curve, that’s great; on the other hand if you can’t predict x from y or y from x, then I don’t know that I’d want a R-squared-like summary to be close to 1. [sent-27, score-0.303]
</p><p>17 No measure can be all things to all datasets, so let me emphasize that the above is not a criticism of the idea of Reshef et al. [sent-28, score-0.341]
</p><p>18 I wonder if they’d do even better by log-transforming any variables that are all-positive. [sent-31, score-0.112]
</p><p>19 )  A more general approach would be for their grid boxes to be adaptive. [sent-33, score-0.226]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reshef', 0.462), ('measure', 0.211), ('bx', 0.193), ('theta', 0.187), ('bivariate', 0.153), ('method', 0.149), ('grid', 0.145), ('dependence', 0.143), ('pairs', 0.135), ('absolute', 0.134), ('fit', 0.132), ('et', 0.13), ('variables', 0.112), ('lander', 0.102), ('grossman', 0.102), ('purists', 0.102), ('sin', 0.102), ('undiscovered', 0.102), ('association', 0.099), ('interpretation', 0.097), ('runif', 0.092), ('dependences', 0.092), ('discretization', 0.092), ('pairwise', 0.089), ('scale', 0.088), ('hilary', 0.086), ('paper', 0.085), ('quick', 0.084), ('pi', 0.082), ('boxes', 0.081), ('sharon', 0.081), ('tuning', 0.081), ('close', 0.079), ('britain', 0.078), ('inevitable', 0.078), ('proposes', 0.078), ('polynomial', 0.076), ('coast', 0.075), ('jeremy', 0.074), ('cos', 0.074), ('tens', 0.073), ('warm', 0.072), ('circle', 0.072), ('efficiently', 0.071), ('suitable', 0.071), ('adaptive', 0.071), ('reduces', 0.071), ('distribution', 0.071), ('average', 0.07), ('fox', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1062-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-16-Mr._Pearson%2C_meet_Mr._Mandelbrot%3A__Detecting_Novel_Associations_in_Large_Data_Sets.html">1062 andrew gelman stats-2011-12-16-Mr. Pearson, meet Mr. Mandelbrot:  Detecting Novel Associations in Large Data Sets</a></p>
<p>Introduction: Jeremy Fox asks what I think about  this paper  by David N. Reshef, Yakir Reshef, Hilary Finucane, Sharon  Grossman, Gilean McVean, Peter Turnbaugh, Eric Lander, Michael Mitzenmacher, and Pardis Sabeti which proposes a new nonlinear R-squared-like measure.
 
My quick answer is that it looks really cool!
 
From my quick reading of the paper, it appears that the method reduces on average to the usual R-squared when fit to data of the form y = a + bx + error, and that it also has a similar interpretation when “a + bx” is replaced by other continuous functions.
 
Unlike R-squared, the method of Reshef et al. depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way.  The dependence on scale is inevitable for such a general method.  Just consider:  if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data.  So the sca</p><p>2 0.55675226 <a title="1062-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-04-Too_many_MC%E2%80%99s_not_enough_MIC%E2%80%99s%2C_or_What_principles_should_govern_attempts_to_summarize_bivariate_associations_in_large_multivariate_datasets%3F.html">1706 andrew gelman stats-2013-02-04-Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets?</a></p>
<p>Introduction: Justin Kinney writes:
  
Since your blog has discussed the “maximal information coefficient” (MIC) of Reshef et al., I figured you might want to see  the critique  that Gurinder Atwal and I have posted.


In short,  Reshef et al.’s central claim that MIC is “equitable” is incorrect.  


We [Kinney and Atwal] offer mathematical proof that the definition of “equitability” Reshef et al. propose is unsatisfiable—no nontrivial dependence measure, including MIC, has this property. Replicating the simulations in their paper with modestly larger data sets validates this finding. 


The heuristic notion of equitability, however, can be formalized instead as a self-consistency condition closely related to the Data Processing Inequality. Mutual information satisfies this new definition of equitability but MIC does not.  We therefore propose that simply estimating mutual information will, in many cases, provide the sort of dependence measure Reshef et al. seek.
  
For background, here are my two p</p><p>3 0.38715547 <a title="1062-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-26-Further_thoughts_on_nonparametric_correlation_measures.html">1230 andrew gelman stats-2012-03-26-Further thoughts on nonparametric correlation measures</a></p>
<p>Introduction: Malka Gorfine, Ruth Heller, and Yair Heller write a comment on the paper of Reshef et al. that we  discussed  a few months ago.
 
Just to remind you what’s going on here, here’s my quick summary from December:
  
Reshef et al. propose a new nonlinear R-squared-like measure.


Unlike R-squared, this new method depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way. The dependence on scale is inevitable for such a general method. Just consider: if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data. So the scale of the fit matters.


The clever idea of the paper is that, instead of going for an absolute measure (which, as we’ve seen, will be scale-dependent), they focus on the problem of summarizing the grid of pairwise dependences in a large set of variables. As they put it: “Imagine a data set with hundreds</p><p>4 0.24498324 <a title="1062-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-14-The_maximal_information_coefficient.html">2247 andrew gelman stats-2014-03-14-The maximal information coefficient</a></p>
<p>Introduction: Justin Kinney writes:
  
I wanted to let you know that the critique Mickey Atwal and I wrote regarding equitability and the maximal information coefficient has just been  published .
  
We discussed this paper last year, under the heading,  Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets? 
 
Kinney and Atwal’s paper is interesting, with my only criticism being that in some places they seem to aim for what might not be possible.  For example, they write that “mutual information is already widely believed to quantify dependencies without bias for relationships of one type or another,” which seems a bit vague to me.  And later they write, “How to compute such an estimate that does not bias the resulting mutual information value remains an open problem,” which seems to me to miss the point in that unbiased statistical estimates are not generally possible and indeed are often not desirable.
 
Their</p><p>5 0.146393 <a title="1062-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-28-Path_sampling_for_models_of_varying_dimension.html">1089 andrew gelman stats-2011-12-28-Path sampling for models of varying dimension</a></p>
<p>Introduction: Somebody asks: 
  
  
Iâ&euro;&trade;m reading your paper on path sampling. It essentially solves the 
problem of computing the ratio \int q0(omega)d omega/\int q1(omega) d omega. I.e the arguments in q0() and q1() are the same. But this assumption is not always true in Bayesian model selection using Bayes factor.


In general (for BF), we have this problem, t1 and t2 may have no relation at all.


\int f1(y|t1)p1(t1) d t1 / \int f2(y|t2)p2(t2) d t2


As an example, suppose that we want to compare two sets of normally distributed data with known variance whether they have the same mean (H0) or they are not necessarily have the same mean (H1). Then the dummy variable should be mu in H0 (which is the common mean of both set of samples), and should be (mu1, mu2) (which are the means for each set of samples).


One straight method to address my problem is to preform path integration for the numerate and the denominator, as both the numerate and the denominator are integrals. Each integral can be rewrit</p><p>6 0.12676391 <a title="1062-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>7 0.11818317 <a title="1062-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-31-Using_sample_size_in_the_prior_distribution.html">547 andrew gelman stats-2011-01-31-Using sample size in the prior distribution</a></p>
<p>8 0.11452204 <a title="1062-tfidf-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Bayesian_Uncertainty_Quantification_for_Differential_Equations%21.html">2311 andrew gelman stats-2014-04-29-Bayesian Uncertainty Quantification for Differential Equations!</a></p>
<p>9 0.11409961 <a title="1062-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-23-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1868 andrew gelman stats-2013-05-23-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>10 0.1121626 <a title="1062-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-16-The_%E2%80%9CWashington_read%E2%80%9D_and_the_algebra_of_conditional_distributions.html">961 andrew gelman stats-2011-10-16-The “Washington read” and the algebra of conditional distributions</a></p>
<p>11 0.10494737 <a title="1062-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-27-Average_predictive_comparisons_when_changing_a_pair_of_variables.html">1346 andrew gelman stats-2012-05-27-Average predictive comparisons when changing a pair of variables</a></p>
<p>12 0.10222995 <a title="1062-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-20-Prior_beliefs_about_locations_of_decision_boundaries.html">1130 andrew gelman stats-2012-01-20-Prior beliefs about locations of decision boundaries</a></p>
<p>13 0.10192798 <a title="1062-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>14 0.10165124 <a title="1062-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-24-On_summarizing_a_noisy_scatterplot_with_a_single_comparison_of_two_points.html">589 andrew gelman stats-2011-02-24-On summarizing a noisy scatterplot with a single comparison of two points</a></p>
<p>15 0.0999908 <a title="1062-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-29-More_on_scaled-inverse_Wishart_and_prior_independence.html">1474 andrew gelman stats-2012-08-29-More on scaled-inverse Wishart and prior independence</a></p>
<p>16 0.098889336 <a title="1062-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<p>17 0.097833551 <a title="1062-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<p>18 0.097809292 <a title="1062-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-10-Cross-validation_and_Bayesian_estimation_of_tuning_parameters.html">2129 andrew gelman stats-2013-12-10-Cross-validation and Bayesian estimation of tuning parameters</a></p>
<p>19 0.093342878 <a title="1062-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Stan_is_fast.html">1476 andrew gelman stats-2012-08-30-Stan is fast</a></p>
<p>20 0.092996575 <a title="1062-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-08-Regression_and_causality_and_variable_ordering.html">2364 andrew gelman stats-2014-06-08-Regression and causality and variable ordering</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.183), (1, 0.073), (2, 0.037), (3, -0.025), (4, 0.065), (5, -0.053), (6, 0.025), (7, -0.011), (8, -0.021), (9, 0.009), (10, 0.027), (11, 0.009), (12, -0.047), (13, -0.028), (14, -0.032), (15, -0.004), (16, 0.035), (17, -0.001), (18, -0.009), (19, -0.07), (20, 0.076), (21, 0.018), (22, 0.082), (23, -0.046), (24, 0.095), (25, 0.093), (26, 0.058), (27, 0.045), (28, 0.17), (29, 0.051), (30, 0.111), (31, 0.105), (32, 0.085), (33, -0.019), (34, 0.029), (35, 0.009), (36, 0.023), (37, 0.002), (38, -0.097), (39, -0.05), (40, 0.085), (41, 0.071), (42, 0.031), (43, -0.015), (44, -0.077), (45, -0.044), (46, 0.122), (47, -0.039), (48, -0.085), (49, 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96664113 <a title="1062-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-16-Mr._Pearson%2C_meet_Mr._Mandelbrot%3A__Detecting_Novel_Associations_in_Large_Data_Sets.html">1062 andrew gelman stats-2011-12-16-Mr. Pearson, meet Mr. Mandelbrot:  Detecting Novel Associations in Large Data Sets</a></p>
<p>Introduction: Jeremy Fox asks what I think about  this paper  by David N. Reshef, Yakir Reshef, Hilary Finucane, Sharon  Grossman, Gilean McVean, Peter Turnbaugh, Eric Lander, Michael Mitzenmacher, and Pardis Sabeti which proposes a new nonlinear R-squared-like measure.
 
My quick answer is that it looks really cool!
 
From my quick reading of the paper, it appears that the method reduces on average to the usual R-squared when fit to data of the form y = a + bx + error, and that it also has a similar interpretation when “a + bx” is replaced by other continuous functions.
 
Unlike R-squared, the method of Reshef et al. depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way.  The dependence on scale is inevitable for such a general method.  Just consider:  if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data.  So the sca</p><p>2 0.93590069 <a title="1062-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-04-Too_many_MC%E2%80%99s_not_enough_MIC%E2%80%99s%2C_or_What_principles_should_govern_attempts_to_summarize_bivariate_associations_in_large_multivariate_datasets%3F.html">1706 andrew gelman stats-2013-02-04-Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets?</a></p>
<p>Introduction: Justin Kinney writes:
  
Since your blog has discussed the “maximal information coefficient” (MIC) of Reshef et al., I figured you might want to see  the critique  that Gurinder Atwal and I have posted.


In short,  Reshef et al.’s central claim that MIC is “equitable” is incorrect.  


We [Kinney and Atwal] offer mathematical proof that the definition of “equitability” Reshef et al. propose is unsatisfiable—no nontrivial dependence measure, including MIC, has this property. Replicating the simulations in their paper with modestly larger data sets validates this finding. 


The heuristic notion of equitability, however, can be formalized instead as a self-consistency condition closely related to the Data Processing Inequality. Mutual information satisfies this new definition of equitability but MIC does not.  We therefore propose that simply estimating mutual information will, in many cases, provide the sort of dependence measure Reshef et al. seek.
  
For background, here are my two p</p><p>3 0.91898715 <a title="1062-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-26-Further_thoughts_on_nonparametric_correlation_measures.html">1230 andrew gelman stats-2012-03-26-Further thoughts on nonparametric correlation measures</a></p>
<p>Introduction: Malka Gorfine, Ruth Heller, and Yair Heller write a comment on the paper of Reshef et al. that we  discussed  a few months ago.
 
Just to remind you what’s going on here, here’s my quick summary from December:
  
Reshef et al. propose a new nonlinear R-squared-like measure.


Unlike R-squared, this new method depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way. The dependence on scale is inevitable for such a general method. Just consider: if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data. So the scale of the fit matters.


The clever idea of the paper is that, instead of going for an absolute measure (which, as we’ve seen, will be scale-dependent), they focus on the problem of summarizing the grid of pairwise dependences in a large set of variables. As they put it: “Imagine a data set with hundreds</p><p>4 0.91324836 <a title="1062-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-14-The_maximal_information_coefficient.html">2247 andrew gelman stats-2014-03-14-The maximal information coefficient</a></p>
<p>Introduction: Justin Kinney writes:
  
I wanted to let you know that the critique Mickey Atwal and I wrote regarding equitability and the maximal information coefficient has just been  published .
  
We discussed this paper last year, under the heading,  Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets? 
 
Kinney and Atwal’s paper is interesting, with my only criticism being that in some places they seem to aim for what might not be possible.  For example, they write that “mutual information is already widely believed to quantify dependencies without bias for relationships of one type or another,” which seems a bit vague to me.  And later they write, “How to compute such an estimate that does not bias the resulting mutual information value remains an open problem,” which seems to me to miss the point in that unbiased statistical estimates are not generally possible and indeed are often not desirable.
 
Their</p><p>5 0.82451028 <a title="1062-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-07-Once_more_on_nonparametric_measures_of_mutual_information.html">2324 andrew gelman stats-2014-05-07-Once more on nonparametric measures of mutual information</a></p>
<p>Introduction: Ben Murell writes:
  
Our reply to Kinney and Atwal has come out (http://www.pnas.org/content/early/2014/04/29/1403623111.full.pdf) along with their response (http://www.pnas.org/content/early/2014/04/29/1404661111.full.pdf). I feel like they somewhat missed the point. If you’re still interested in this line of discussion, feel free to post, and maybe the Murrells and Kinney can bash it out in your comments!
  
Background:
 
 Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets? 
 
 Heller, Heller, and Gorfine on univariate and multivariate information measures 
 
 Kinney and Atwal on the maximal information coefficient 
 
 Mr. Pearson, meet Mr. Mandelbrot: Detecting Novel Associations in Large Data Sets 
 
 Gorfine, Heller, Heller, Simon, and Tibshirani don’t like MIC 
 
The fun thing is that all these people are sending me their papers, and I’m enough of an outsider in this field that each of the</p><p>6 0.81780022 <a title="1062-lsi-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-01-Heller%2C_Heller%2C_and_Gorfine_on_univariate_and_multivariate_information_measures.html">2314 andrew gelman stats-2014-05-01-Heller, Heller, and Gorfine on univariate and multivariate information measures</a></p>
<p>7 0.6913867 <a title="1062-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-25-It%E2%80%99s_binless%21__A_program_for_computing_normalizing_functions.html">1825 andrew gelman stats-2013-04-25-It’s binless!  A program for computing normalizing functions</a></p>
<p>8 0.64968038 <a title="1062-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-27-Average_predictive_comparisons_when_changing_a_pair_of_variables.html">1346 andrew gelman stats-2012-05-27-Average predictive comparisons when changing a pair of variables</a></p>
<p>9 0.63965684 <a title="1062-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-15-Of_forecasts_and_graph_theory_and_characterizing_a_statistical_method_by_the_information_it_uses.html">1214 andrew gelman stats-2012-03-15-Of forecasts and graph theory and characterizing a statistical method by the information it uses</a></p>
<p>10 0.62333912 <a title="1062-lsi-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-02-Discovering_general_multidimensional_associations.html">2315 andrew gelman stats-2014-05-02-Discovering general multidimensional associations</a></p>
<p>11 0.61877102 <a title="1062-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-28-Path_sampling_for_models_of_varying_dimension.html">1089 andrew gelman stats-2011-12-28-Path sampling for models of varying dimension</a></p>
<p>12 0.61530179 <a title="1062-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-16-Update_on_the_generalized_method_of_moments.html">519 andrew gelman stats-2011-01-16-Update on the generalized method of moments</a></p>
<p>13 0.6038667 <a title="1062-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Bayesian_Uncertainty_Quantification_for_Differential_Equations%21.html">2311 andrew gelman stats-2014-04-29-Bayesian Uncertainty Quantification for Differential Equations!</a></p>
<p>14 0.59815192 <a title="1062-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-22-Extreme_events_as_evidence_for_differences_in_distributions.html">1424 andrew gelman stats-2012-07-22-Extreme events as evidence for differences in distributions</a></p>
<p>15 0.55920714 <a title="1062-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-DBQQ_rounding_for_labeling_charts_and_communicating_tolerances.html">939 andrew gelman stats-2011-10-03-DBQQ rounding for labeling charts and communicating tolerances</a></p>
<p>16 0.54889166 <a title="1062-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-09-How_to_model_distributions_that_have_outliers_in_one_direction.html">2128 andrew gelman stats-2013-12-09-How to model distributions that have outliers in one direction</a></p>
<p>17 0.53901166 <a title="1062-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-29-Going_negative.html">1918 andrew gelman stats-2013-06-29-Going negative</a></p>
<p>18 0.53058255 <a title="1062-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-28-Correlation%2C_prediction%2C_variation%2C_etc..html">301 andrew gelman stats-2010-09-28-Correlation, prediction, variation, etc.</a></p>
<p>19 0.5275256 <a title="1062-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-24-Analyzing_photon_counts.html">1509 andrew gelman stats-2012-09-24-Analyzing photon counts</a></p>
<p>20 0.52521825 <a title="1062-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.017), (15, 0.029), (16, 0.044), (24, 0.317), (41, 0.129), (43, 0.025), (53, 0.011), (56, 0.013), (84, 0.011), (86, 0.042), (99, 0.214)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96089184 <a title="1062-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-16-Mr._Pearson%2C_meet_Mr._Mandelbrot%3A__Detecting_Novel_Associations_in_Large_Data_Sets.html">1062 andrew gelman stats-2011-12-16-Mr. Pearson, meet Mr. Mandelbrot:  Detecting Novel Associations in Large Data Sets</a></p>
<p>Introduction: Jeremy Fox asks what I think about  this paper  by David N. Reshef, Yakir Reshef, Hilary Finucane, Sharon  Grossman, Gilean McVean, Peter Turnbaugh, Eric Lander, Michael Mitzenmacher, and Pardis Sabeti which proposes a new nonlinear R-squared-like measure.
 
My quick answer is that it looks really cool!
 
From my quick reading of the paper, it appears that the method reduces on average to the usual R-squared when fit to data of the form y = a + bx + error, and that it also has a similar interpretation when “a + bx” is replaced by other continuous functions.
 
Unlike R-squared, the method of Reshef et al. depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way.  The dependence on scale is inevitable for such a general method.  Just consider:  if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data.  So the sca</p><p>2 0.94397521 <a title="1062-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-04-Too_many_MC%E2%80%99s_not_enough_MIC%E2%80%99s%2C_or_What_principles_should_govern_attempts_to_summarize_bivariate_associations_in_large_multivariate_datasets%3F.html">1706 andrew gelman stats-2013-02-04-Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets?</a></p>
<p>Introduction: Justin Kinney writes:
  
Since your blog has discussed the “maximal information coefficient” (MIC) of Reshef et al., I figured you might want to see  the critique  that Gurinder Atwal and I have posted.


In short,  Reshef et al.’s central claim that MIC is “equitable” is incorrect.  


We [Kinney and Atwal] offer mathematical proof that the definition of “equitability” Reshef et al. propose is unsatisfiable—no nontrivial dependence measure, including MIC, has this property. Replicating the simulations in their paper with modestly larger data sets validates this finding. 


The heuristic notion of equitability, however, can be formalized instead as a self-consistency condition closely related to the Data Processing Inequality. Mutual information satisfies this new definition of equitability but MIC does not.  We therefore propose that simply estimating mutual information will, in many cases, provide the sort of dependence measure Reshef et al. seek.
  
For background, here are my two p</p><p>3 0.94211292 <a title="1062-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-11-Steve_Jobs%E2%80%99s_cancer_and_science-based_medicine.html">953 andrew gelman stats-2011-10-11-Steve Jobs’s cancer and science-based medicine</a></p>
<p>Introduction: Interesting discussion  from David Gorski (which I found via  this  link from Joseph Delaney).
 
I don’t have anything really to add to this discussion except to note the value of this sort of anecdote in a statistics discussion.  It’s only n=1 and adds almost nothing to the literature on the effectiveness of various treatments, but a story like this can help focus one’s thoughts on the decision problems.</p><p>4 0.9399358 <a title="1062-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-23-Capitalism_as_a_form_of_voluntarism.html">482 andrew gelman stats-2010-12-23-Capitalism as a form of voluntarism</a></p>
<p>Introduction: Interesting discussion  by Alex Tabarrok (following up on an article by Rebecca Solnit) on the continuum between voluntarism (or, more generally, non-cash transactions) and markets with monetary exchange.  I just have a few comments of my own:
 
1.  Solnit writes of “the iceberg economy,” which she characterizes as “based on gift economies, barter, mutual aid, and giving without hope of return . . . the relations between friends, between family members, the activities of volunteers or those who have chosen their vocation on principle rather than for profit.”  I just wonder whether “barter” completely fits in here.  Maybe it depends on context.  Sometimes barter is an informal way of keeping track (you help me and I help you), but in settings of low liquidity I could imagine barter being simply an inefficient way of performing an economic transaction.
 
2.  I am no expert on capitalism but my impression is that it’s not just about “competition and selfishness” but also is related to the</p><p>5 0.93848163 <a title="1062-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-12-Fixing_the_race%2C_ethnicity%2C_and_national_origin_questions_on_the_U.S._Census.html">1978 andrew gelman stats-2013-08-12-Fixing the race, ethnicity, and national origin questions on the U.S. Census</a></p>
<p>Introduction: In his new book, “What is Your Race?  The Census and Our Flawed Efforts to Classify Americans,” former Census Bureau director Ken Prewitt recommends taking the race question off the decennial census:
 
 
 
He recommends gradual changes, integrating the race and national origin questions while improving both.  In particular, he would replace the main “race” question by a “race or origin” question, with the instruction to “Mark one or more” of the following boxes: “White,” “Black, African Am., or Negro,” “Hispanic, Latino, or Spanish origin,” “American Indian or Alaska Native,” “Asian”, “Native Hawaiian or Other Pacific Islander,” and “Some other race or origin.”  Then the next question is to write in “specific race, origin, or enrolled or principal tribe.”
 
Prewitt writes:
 
 
 
His suggestion is to go with these questions in 2020 and 2030, then in 2040 “drop the race question and use only the national origin question.”  He’s also relying on the American Community Survey to gather a lo</p><p>6 0.93611687 <a title="1062-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-Comparing_prediction_errors.html">938 andrew gelman stats-2011-10-03-Comparing prediction errors</a></p>
<p>7 0.93576753 <a title="1062-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-03-An_argument_that_can%E2%80%99t_possibly_make_sense.html">743 andrew gelman stats-2011-06-03-An argument that can’t possibly make sense</a></p>
<p>8 0.93573487 <a title="1062-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<p>9 0.93461049 <a title="1062-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-23-Win_probabilities_during_a_sporting_event.html">2262 andrew gelman stats-2014-03-23-Win probabilities during a sporting event</a></p>
<p>10 0.93414068 <a title="1062-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-29-Ethics_and_statistics_in_development_research.html">241 andrew gelman stats-2010-08-29-Ethics and statistics in development research</a></p>
<p>11 0.93345141 <a title="1062-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-12-Simple_graph_WIN%3A__the_example_of_birthday_frequencies.html">1376 andrew gelman stats-2012-06-12-Simple graph WIN:  the example of birthday frequencies</a></p>
<p>12 0.93264794 <a title="1062-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-01-Mothers_and_Moms.html">1479 andrew gelman stats-2012-09-01-Mothers and Moms</a></p>
<p>13 0.93168402 <a title="1062-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-15-Advice_that_might_make_sense_for_individuals_but_is_negative-sum_overall.html">278 andrew gelman stats-2010-09-15-Advice that might make sense for individuals but is negative-sum overall</a></p>
<p>14 0.93105769 <a title="1062-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-12-Probabilistic_screening_to_get_an_approximate_self-weighted_sample.html">1455 andrew gelman stats-2012-08-12-Probabilistic screening to get an approximate self-weighted sample</a></p>
<p>15 0.93056393 <a title="1062-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>16 0.92940974 <a title="1062-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-18-Breastfeeding%2C_infant_hyperbilirubinemia%2C_statistical_graphics%2C_and_modern_medicine.html">38 andrew gelman stats-2010-05-18-Breastfeeding, infant hyperbilirubinemia, statistical graphics, and modern medicine</a></p>
<p>17 0.92880923 <a title="1062-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-04-Wanna_be_the_next_Tyler_Cowen%3F__It%E2%80%99s_not_as_easy_as_you_might_think%21.html">1787 andrew gelman stats-2013-04-04-Wanna be the next Tyler Cowen?  It’s not as easy as you might think!</a></p>
<p>18 0.92798913 <a title="1062-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-27-Bayesian_model_averaging_or_fitting_a_larger_model.html">1999 andrew gelman stats-2013-08-27-Bayesian model averaging or fitting a larger model</a></p>
<p>19 0.92751408 <a title="1062-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-06-Question_27_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1368 andrew gelman stats-2012-06-06-Question 27 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>20 0.92450213 <a title="1062-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-11-%E2%80%9CInformative_g-Priors_for_Logistic_Regression%E2%80%9D.html">2017 andrew gelman stats-2013-09-11-“Informative g-Priors for Logistic Regression”</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
