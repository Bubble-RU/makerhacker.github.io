<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>907 andrew gelman stats-2011-09-14-Reproducibility in Practice</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-907" href="#">andrew_gelman_stats-2011-907</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>907 andrew gelman stats-2011-09-14-Reproducibility in Practice</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-907-html" href="http://andrewgelman.com/2011/09/14/reproducibility-in-practice/">html</a></p><p>Introduction: In light of the recent  article  about drug-target research and replication (Andrew blogged it  here ) and  l’affaire   Potti , I have mentioned the  “Forensic Bioinformatics” paper  (Baggerly & Coombes 2009) to several colleagues in passing this week. I have concluded that it has not gotten the attention it deserves, though it has been  discussed  on this blog before too.
 
     Figure 1 from Baggerly & Coombes 2009
  
  
 
The authors try to reproduce published data, and end up “reverse engineering” what the original authors had to have done. Some examples:
  
 §2.2: “Training data sensitive/resistant labels are reversed.” 
 §2.4: “Only 84/122 test samples are distinct; some samples are labeled both sensitive and resistant.” 
 §2.7: Almost half of the data is incorrectly labeled resistant. 
 §3.2: “This offset involves a single row shift: for example, … [data from] row 98 were used instead of those from row 97.” 
 §5.4: “Poor documentation led a report on drug A to include a heatmap</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Figure 1 from Baggerly & Coombes 2009         The authors try to reproduce published data, and end up “reverse engineering” what the original authors had to have done. [sent-3, score-0.229]
</p><p>2 4: “Only 84/122 test samples are distinct; some samples are labeled both sensitive and resistant. [sent-7, score-0.346]
</p><p>3 7: Almost half of the data is incorrectly labeled resistant. [sent-9, score-0.291]
</p><p>4 2: “This offset involves a single row shift: for example, … [data from] row 98 were used instead of those from row 97. [sent-11, score-0.761]
</p><p>5 4: “Poor documentation led a report on drug A to include a heatmap for drug B and a gene list for drug C. [sent-13, score-0.797]
</p><p>6 These results are based on simple visual inspection and counting, and are not documented further. [sent-14, score-0.184]
</p><p>7 Continuing in the usual theme of my occasional posts, I’ll share what reproducible research means for me in practice. [sent-16, score-0.083]
</p><p>8 Here is my  xetex template  if you care about typography. [sent-19, score-0.153]
</p><p>9 Eventually I save objects that took a long time to compute, set their evaluation to false, and then load the saved object immediately below, but crucially I still have their generative code  right there . [sent-20, score-0.787]
</p><p>10 Rdata") @    So once I was satisfied that computation1 produced the object. [sent-25, score-0.076]
</p><p>11 1 of my dreams, I could just flip eval=FALSE on the first code chunk and save myself the hassle. [sent-26, score-0.551]
</p><p>12 It is generally not painful to leave any pre-processing / data loading and joining, and recoding in the first code chunk. [sent-28, score-0.575]
</p><p>13 This will prevent you from having a stylized data file that you don’t know what you did to it, because you actually redo it from scratch every time. [sent-29, score-0.669]
</p><p>14 It sometimes makes sense to separate this out into a file that you  source() . [sent-30, score-0.253]
</p><p>15 For presentations or other destinations, I can just copy the paper. [sent-31, score-0.083]
</p><p>16 Rnw, make any necessary changes (to the size in the code chunk argument, for example, to make Beamer-friendly images). [sent-33, score-0.467]
</p><p>17 Rnw  on this will ensure that my names are consistent (“pres-gfx-codechunkname. [sent-35, score-0.076]
</p><p>18 pdf”) and I don’t do something completely different or accidentally use the wrong model on the wrong graphic. [sent-36, score-0.083]
</p><p>19 I could, if I had truly mastered  ediff , easily merge any changes I made for presentation back to the paper. [sent-37, score-0.303]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('file', 0.253), ('sweave', 0.231), ('row', 0.223), ('baggerly', 0.211), ('coombes', 0.211), ('chunk', 0.19), ('code', 0.184), ('load', 0.178), ('save', 0.177), ('drug', 0.177), ('template', 0.153), ('labeled', 0.128), ('samples', 0.109), ('mastered', 0.105), ('forensic', 0.105), ('heatmap', 0.105), ('loading', 0.105), ('merge', 0.105), ('recoding', 0.105), ('inspection', 0.099), ('false', 0.097), ('painful', 0.095), ('dreams', 0.095), ('changes', 0.093), ('crucially', 0.092), ('offset', 0.092), ('redo', 0.092), ('potti', 0.089), ('joining', 0.087), ('data', 0.086), ('documented', 0.085), ('accidentally', 0.083), ('presentations', 0.083), ('reproducible', 0.083), ('documentation', 0.081), ('scratch', 0.08), ('gene', 0.08), ('generative', 0.08), ('stylized', 0.079), ('prevent', 0.079), ('authors', 0.078), ('incorrectly', 0.077), ('ensure', 0.076), ('satisfied', 0.076), ('saved', 0.076), ('gross', 0.074), ('reproduce', 0.073), ('distinct', 0.073), ('deserves', 0.073), ('almost', 0.073)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="907-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-14-Reproducibility_in_Practice.html">907 andrew gelman stats-2011-09-14-Reproducibility in Practice</a></p>
<p>Introduction: In light of the recent  article  about drug-target research and replication (Andrew blogged it  here ) and  l’affaire   Potti , I have mentioned the  “Forensic Bioinformatics” paper  (Baggerly & Coombes 2009) to several colleagues in passing this week. I have concluded that it has not gotten the attention it deserves, though it has been  discussed  on this blog before too.
 
     Figure 1 from Baggerly & Coombes 2009
  
  
 
The authors try to reproduce published data, and end up “reverse engineering” what the original authors had to have done. Some examples:
  
 §2.2: “Training data sensitive/resistant labels are reversed.” 
 §2.4: “Only 84/122 test samples are distinct; some samples are labeled both sensitive and resistant.” 
 §2.7: Almost half of the data is incorrectly labeled resistant. 
 §3.2: “This offset involves a single row shift: for example, … [data from] row 98 were used instead of those from row 97.” 
 §5.4: “Poor documentation led a report on drug A to include a heatmap</p><p>2 0.2361128 <a title="907-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-21-Forensic_bioinformatics%2C_or%2C_Don%E2%80%99t_believe_everything_you_read_in_the_%28scientific%29_papers.html">360 andrew gelman stats-2010-10-21-Forensic bioinformatics, or, Don’t believe everything you read in the (scientific) papers</a></p>
<p>Introduction: Hadley Wickham sent me  this , by Keith Baggerly and Kevin Coombes:
  
In this report we [Baggerly and Coombes] examine several related papers purporting to use microarray-based signatures of drug sensitivity derived from cell lines to predict patient response. Patients in clinical trials are currently being allocated to treatment arms on the basis of these results. However, we show in five case studies that the results incorporate several simple errors that may be putting patients at risk. One theme that emerges is that the most common errors are simple (e.g., row or column offsets); conversely, it is our experience that the most simple errors are common.
  
This is horrible!  But, in a way, it’s not surprising.  I make big mistakes in my applied work all the time.  I mean, all the time.  Sometimes I scramble the order of the 50 states, or I’m plotting a pure noise variable, or whatever.  But usually I don’t drift too far from reality because I have a lot of cross-checks and I (or my</p><p>3 0.14378637 <a title="907-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-07-Reproducible_science_FAIL_%28so_far%29%3A__What%E2%80%99s_stoppin_people_from_sharin_data_and_code%3F.html">1447 andrew gelman stats-2012-08-07-Reproducible science FAIL (so far):  What’s stoppin people from sharin data and code?</a></p>
<p>Introduction: David Karger writes:
  
Your  recent post  on sharing data was of great interest to me, as my own research in computer science asks how to incentivize and lower barriers to data sharing.   I was particularly curious about your highlighting of effort as the major dis-incentive to sharing.  I would love to hear more, as this question of effort is on we specifically target in our development of tools for data authoring and publishing.


As a straw man, let me point out that sharing data technically requires no more than posting an excel spreadsheet online.  And that you likely already produced that spreadsheet during your own analytic work.   So, in what way does such low-tech publishing fail to meet your data sharing objectives?


Our own hypothesis has been that the effort is really quite low, with the problem being a lack of *immediate/tangible* benefits (as opposed to the long-term values you accurately describe).  To attack this problem, we’re developing  tools  (and, since it appear</p><p>4 0.13725612 <a title="907-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Data_problems%2C_coding_errors%E2%80%A6what_can_be_done%3F.html">1807 andrew gelman stats-2013-04-17-Data problems, coding errors…what can be done?</a></p>
<p>Introduction: This post is by Phil
 
A  recent post on this blog  discusses a prominent case of an Excel error leading to substantially wrong results from a statistical analysis. Excel is notorious for this because it is easy to add a row or column of data (or intermediate results) but forget to update equations so that they correctly use the new data. That particular error is less common in a language like R because R programmers usually refer to data by variable name (or by applying functions to a named variable), so the same code works even if you add or remove data.
 
Still, there is plenty of opportunity for errors no matter what language one uses. Andrew  ran into problems  fairly recently, and also blogged about  another instance.  I’ve never had to retract a paper, but that’s partly because I haven’t published a whole lot of papers. Certainly I have found plenty of substantial errors pretty late in some of my data analyses, and I obviously don’t have sufficient mechanisms in place to be sure</p><p>5 0.10930879 <a title="907-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-14-Looking_at_many_comparisons_may_increase_the_risk_of_finding_something_statistically_significant_by_epidemiologists%2C_a_population_with_relatively_low_multilevel_modeling_consumption.html">1059 andrew gelman stats-2011-12-14-Looking at many comparisons may increase the risk of finding something statistically significant by epidemiologists, a population with relatively low multilevel modeling consumption</a></p>
<p>Introduction: To understand the above title, see  here .
 
Masanao writes:
  
 This  report claims that eating meat increases the risk of cancer.  I’m sure you can’t read the page but you probably can understand the graphs. Different bars represent subdivision in the amount of the particular type of meat one consumes. And each chunk is different types of meat. Left is for male right is for female.


They claim that the difference is significant, but they are clearly not!!


I’m for not eating much meat but this is just way too much…
  
Here’s the graph:
 
   
 
I don’t know what to think.  If you look carefully you can find one or two statistically significant differences but overall the pattern doesn’t look so compelling.  I don’t know what the top and bottom rows are, though.  Overall, the pattern in the top row looks like it could represent a real trend, while the graphs on the bottom row look like noise.
 
This could be a good example for our multiple comparisons paper.  If the researchers won’t</p><p>6 0.10142946 <a title="907-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-19-Updated_R_code_and_data_for_ARM.html">41 andrew gelman stats-2010-05-19-Updated R code and data for ARM</a></p>
<p>7 0.09269838 <a title="907-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-26-%E2%80%9CThe_Bayesian_approach_to_forensic_evidence%E2%80%9D.html">2078 andrew gelman stats-2013-10-26-“The Bayesian approach to forensic evidence”</a></p>
<p>8 0.088585675 <a title="907-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-19-Updated_solutions_to_Bayesian_Data_Analysis_homeworks.html">42 andrew gelman stats-2010-05-19-Updated solutions to Bayesian Data Analysis homeworks</a></p>
<p>9 0.08567372 <a title="907-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-08-Cool_GSS_training_video%21__And_cumulative_file_1972-2012%21.html">1754 andrew gelman stats-2013-03-08-Cool GSS training video!  And cumulative file 1972-2012!</a></p>
<p>10 0.085059933 <a title="907-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-11-Multilevel_modeling_in_R_on_a_Mac.html">198 andrew gelman stats-2010-08-11-Multilevel modeling in R on a Mac</a></p>
<p>11 0.079790026 <a title="907-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-11-The_happiness_gene%3A__My_bottom_line_%28for_now%29.html">706 andrew gelman stats-2011-05-11-The happiness gene:  My bottom line (for now)</a></p>
<p>12 0.079603866 <a title="907-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-13-Checking_your_model_using_fake_data.html">852 andrew gelman stats-2011-08-13-Checking your model using fake data</a></p>
<p>13 0.075539157 <a title="907-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>14 0.07442151 <a title="907-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>15 0.074365988 <a title="907-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-09-%E2%80%9CDiscovered%3A_the_genetic_secret_of_a_happy_life%E2%80%9D.html">702 andrew gelman stats-2011-05-09-“Discovered: the genetic secret of a happy life”</a></p>
<p>16 0.074306905 <a title="907-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-18-Predictive_checks_for_hierarchical_models.html">154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</a></p>
<p>17 0.074011967 <a title="907-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-23-Thinking_of_doing_a_list_experiment%3F__Here%E2%80%99s_a_list_of_reasons_why_you_should_think_again.html">2303 andrew gelman stats-2014-04-23-Thinking of doing a list experiment?  Here’s a list of reasons why you should think again</a></p>
<p>18 0.073187493 <a title="907-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-09-iPython_Notebook.html">1716 andrew gelman stats-2013-02-09-iPython Notebook</a></p>
<p>19 0.070626304 <a title="907-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-14-Wickham_R_short_course.html">1009 andrew gelman stats-2011-11-14-Wickham R short course</a></p>
<p>20 0.070174821 <a title="907-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.15), (1, -0.007), (2, -0.018), (3, -0.024), (4, 0.052), (5, -0.037), (6, -0.004), (7, -0.051), (8, 0.005), (9, -0.019), (10, -0.019), (11, 0.013), (12, -0.019), (13, -0.039), (14, 0.006), (15, 0.019), (16, 0.016), (17, -0.012), (18, 0.006), (19, -0.0), (20, 0.023), (21, 0.027), (22, -0.022), (23, -0.006), (24, -0.039), (25, 0.011), (26, 0.008), (27, -0.018), (28, 0.051), (29, 0.009), (30, 0.027), (31, -0.011), (32, 0.003), (33, 0.041), (34, 0.039), (35, -0.021), (36, -0.018), (37, 0.039), (38, -0.003), (39, 0.008), (40, -0.003), (41, -0.002), (42, 0.005), (43, -0.002), (44, -0.007), (45, 0.042), (46, -0.036), (47, -0.016), (48, 0.047), (49, -0.007)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95442873 <a title="907-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-14-Reproducibility_in_Practice.html">907 andrew gelman stats-2011-09-14-Reproducibility in Practice</a></p>
<p>Introduction: In light of the recent  article  about drug-target research and replication (Andrew blogged it  here ) and  l’affaire   Potti , I have mentioned the  “Forensic Bioinformatics” paper  (Baggerly & Coombes 2009) to several colleagues in passing this week. I have concluded that it has not gotten the attention it deserves, though it has been  discussed  on this blog before too.
 
     Figure 1 from Baggerly & Coombes 2009
  
  
 
The authors try to reproduce published data, and end up “reverse engineering” what the original authors had to have done. Some examples:
  
 §2.2: “Training data sensitive/resistant labels are reversed.” 
 §2.4: “Only 84/122 test samples are distinct; some samples are labeled both sensitive and resistant.” 
 §2.7: Almost half of the data is incorrectly labeled resistant. 
 §3.2: “This offset involves a single row shift: for example, … [data from] row 98 were used instead of those from row 97.” 
 §5.4: “Poor documentation led a report on drug A to include a heatmap</p><p>2 0.85743344 <a title="907-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Data_problems%2C_coding_errors%E2%80%A6what_can_be_done%3F.html">1807 andrew gelman stats-2013-04-17-Data problems, coding errors…what can be done?</a></p>
<p>Introduction: This post is by Phil
 
A  recent post on this blog  discusses a prominent case of an Excel error leading to substantially wrong results from a statistical analysis. Excel is notorious for this because it is easy to add a row or column of data (or intermediate results) but forget to update equations so that they correctly use the new data. That particular error is less common in a language like R because R programmers usually refer to data by variable name (or by applying functions to a named variable), so the same code works even if you add or remove data.
 
Still, there is plenty of opportunity for errors no matter what language one uses. Andrew  ran into problems  fairly recently, and also blogged about  another instance.  I’ve never had to retract a paper, but that’s partly because I haven’t published a whole lot of papers. Certainly I have found plenty of substantial errors pretty late in some of my data analyses, and I obviously don’t have sufficient mechanisms in place to be sure</p><p>3 0.81178188 <a title="907-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-13-Ross_Ihaka_to_R%3A__Drop_Dead.html">272 andrew gelman stats-2010-09-13-Ross Ihaka to R:  Drop Dead</a></p>
<p>Introduction: Christian Robert posts  these thoughts :
  
I [Ross Ihaka] have been worried for some time that R isn’t going to provide the base that we’re going to need for statistical computation in the future. (It may well be that the future is already upon us.)  There are certainly efficiency problems (speed and memory use), but there are more fundamental issues too. Some of these were inherited from S and some are peculiar to R.

 One of the worst problems is scoping. Consider the following little gem.

 
  f =function() { 
if (runif(1) > .5) 
x = 10 
x 
} 

 

The x being returned by this function is randomly local or global. There are other examples where variables alternate between local and non-local throughout the body of a function. No sensible language would allow this.  It’s ugly and it makes optimisation really difficult.  This isn’t the only problem, even weirder things happen  because of interactions between scoping and lazy evaluation.


In light of this, I [Ihaka] have come to the c</p><p>4 0.78727615 <a title="907-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-07-Reproducible_science_FAIL_%28so_far%29%3A__What%E2%80%99s_stoppin_people_from_sharin_data_and_code%3F.html">1447 andrew gelman stats-2012-08-07-Reproducible science FAIL (so far):  What’s stoppin people from sharin data and code?</a></p>
<p>Introduction: David Karger writes:
  
Your  recent post  on sharing data was of great interest to me, as my own research in computer science asks how to incentivize and lower barriers to data sharing.   I was particularly curious about your highlighting of effort as the major dis-incentive to sharing.  I would love to hear more, as this question of effort is on we specifically target in our development of tools for data authoring and publishing.


As a straw man, let me point out that sharing data technically requires no more than posting an excel spreadsheet online.  And that you likely already produced that spreadsheet during your own analytic work.   So, in what way does such low-tech publishing fail to meet your data sharing objectives?


Our own hypothesis has been that the effort is really quite low, with the problem being a lack of *immediate/tangible* benefits (as opposed to the long-term values you accurately describe).  To attack this problem, we’re developing  tools  (and, since it appear</p><p>5 0.78580093 <a title="907-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-09-iPython_Notebook.html">1716 andrew gelman stats-2013-02-09-iPython Notebook</a></p>
<p>Introduction: Burak Bayramli writes:
  
I wanted to inform you on iPython Notebook technology – allowing markup, Python code to reside in one document. Someone ported  one of your examples from ARM .


iPynb file is actually a live document, can be downloaded and reran locally, hence change of code on document means change of images, results. Graphs (as well as text output) which are generated by the code, are placed inside the document automatically. No more referencing image files seperately. 


For now running notebooks locally require a notebook server, but that part can live “on the cloud” as part of an educational software. Viewers, such as nbviewer.ipython.org, do not even need that much, since all recent results of a notebook are embedded in the notebook itself. 


A lot of people are excited about this; Also out of nowhere, Alfred P. Sloan Foundation dropped a $1.15 million grant on the developers of ipython which provided some extra energy on the project.
  
Cool.  We’ll have to do that ex</p><p>6 0.76360244 <a title="907-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-09-The_future_of_R.html">266 andrew gelman stats-2010-09-09-The future of R</a></p>
<p>7 0.76347184 <a title="907-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-21-Forensic_bioinformatics%2C_or%2C_Don%E2%80%99t_believe_everything_you_read_in_the_%28scientific%29_papers.html">360 andrew gelman stats-2010-10-21-Forensic bioinformatics, or, Don’t believe everything you read in the (scientific) papers</a></p>
<p>8 0.76106817 <a title="907-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-04-Shlemiel_the_Software_Developer_and_Unknown_Unknowns.html">2089 andrew gelman stats-2013-11-04-Shlemiel the Software Developer and Unknown Unknowns</a></p>
<p>9 0.74785835 <a title="907-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-16-%E2%80%9CFor_individuals_with_wine_training%2C_however%2C_we_find__indications_of_a_positive_relationship_between_price_and_enjoyment%E2%80%9D.html">470 andrew gelman stats-2010-12-16-“For individuals with wine training, however, we find  indications of a positive relationship between price and enjoyment”</a></p>
<p>10 0.7462644 <a title="907-lsi-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-31-Jessica_Tracy_and_Alec_Beall_%28authors_of_the_fertile-women-wear-pink_study%29_comment_on_our_Garden_of_Forking_Paths_paper%2C_and_I_comment_on_their_comments.html">2355 andrew gelman stats-2014-05-31-Jessica Tracy and Alec Beall (authors of the fertile-women-wear-pink study) comment on our Garden of Forking Paths paper, and I comment on their comments</a></p>
<p>11 0.74021345 <a title="907-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-16-Memo_to_Reinhart_and_Rogoff%3A__I_think_it%E2%80%99s_best_to_admit_your_errors_and_go_on_from_there.html">1805 andrew gelman stats-2013-04-16-Memo to Reinhart and Rogoff:  I think it’s best to admit your errors and go on from there</a></p>
<p>12 0.73500675 <a title="907-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-29-Response_to_%E2%80%9CWhy_Tables_Are_Really_Much_Better_Than_Graphs%E2%80%9D.html">736 andrew gelman stats-2011-05-29-Response to “Why Tables Are Really Much Better Than Graphs”</a></p>
<p>13 0.72998172 <a title="907-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Excel-bashing.html">1808 andrew gelman stats-2013-04-17-Excel-bashing</a></p>
<p>14 0.7256043 <a title="907-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Lessons_learned_from_a_recent_R_package_submission.html">1134 andrew gelman stats-2012-01-21-Lessons learned from a recent R package submission</a></p>
<p>15 0.7252863 <a title="907-lsi-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-18-Never_back_down%3A__The_culture_of_poverty_and_the_culture_of_journalism.html">2337 andrew gelman stats-2014-05-18-Never back down:  The culture of poverty and the culture of journalism</a></p>
<p>16 0.72454602 <a title="907-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-06-Your_conclusion_is_only_as_good_as_your_data.html">1369 andrew gelman stats-2012-06-06-Your conclusion is only as good as your data</a></p>
<p>17 0.72389424 <a title="907-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-10-Fighting_Migraine_with_Multilevel_Modeling.html">268 andrew gelman stats-2010-09-10-Fighting Migraine with Multilevel Modeling</a></p>
<p>18 0.72211361 <a title="907-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-02-RStudio_%E2%80%93_new_cross-platform_IDE_for_R.html">597 andrew gelman stats-2011-03-02-RStudio – new cross-platform IDE for R</a></p>
<p>19 0.719356 <a title="907-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-29-When_you_believe_in_things_that_you_don%E2%80%99t_understand.html">2352 andrew gelman stats-2014-05-29-When you believe in things that you don’t understand</a></p>
<p>20 0.71514881 <a title="907-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-31-Dispute_about_ethics_of_data_sharing.html">1238 andrew gelman stats-2012-03-31-Dispute about ethics of data sharing</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(4, 0.16), (16, 0.055), (21, 0.052), (24, 0.116), (47, 0.033), (63, 0.029), (76, 0.02), (84, 0.073), (86, 0.017), (89, 0.016), (96, 0.026), (97, 0.013), (99, 0.244)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94566226 <a title="907-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-08-GiveWell_sez%3A__Cost-effectiveness_of_de-worming_was_overstated_by_a_factor_of_100_%28%21%29_due_to_a_series_of_sloppy_calculations.html">947 andrew gelman stats-2011-10-08-GiveWell sez:  Cost-effectiveness of de-worming was overstated by a factor of 100 (!) due to a series of sloppy calculations</a></p>
<p>Introduction: Alexander at GiveWell  writes :
  
The Disease Control Priorities in Developing Countries (DCP2), a major report funded by the Gates Foundation . . . provides an estimate of $3.41 per disability-adjusted life-year (DALY) for the cost-effectiveness of soil-transmitted-helminth (STH) treatment, implying that STH treatment is one of the most cost-effective interventions for global health. In investigating this figure, we have corresponded, over a period of months, with six scholars who had been directly or indirectly involved in the production of the estimate. Eventually, we were able to obtain the spreadsheet that was used to generate the $3.41/DALY estimate. That spreadsheet contains five separate errors that, when corrected, shift the estimated cost effectiveness of deworming from $3.41 to $326.43. [I think they mean to say $300 -- ed.] We came to this conclusion a year after learning that the DCP2’s published cost-effectiveness estimate for schistosomiasis treatment – another kind of</p><p>2 0.93592745 <a title="907-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-11-The_consulting_biz.html">1618 andrew gelman stats-2012-12-11-The consulting biz</a></p>
<p>Introduction: I received the following (unsolicited) email:
  
Hello, 


*** LLC, a ***-based market research company, has a financial client who is interested in speaking with a statistician who has done research in the field of Alzheimer’s Disease and preferably familiar with the SOLA and BAPI trials.  We offer an honorarium of $200 for a 30 minute telephone interview.


Please advise us if you have an employment or consulting agreement with any organization or operate professionally pursuant to an organization’s code of conduct or employee manual that may control activities by you outside of your regular present and former employment, such as participating in this consulting project for MedPanel.  If there are such contracts or other documents that do apply to you, please forward MedPanel a copy of each such document asap as we are obligated to review such documents to determine if you are permitted to participate as a consultant for MedPanel on a project with this particular client.


If you are</p><p>same-blog 3 0.9355039 <a title="907-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-14-Reproducibility_in_Practice.html">907 andrew gelman stats-2011-09-14-Reproducibility in Practice</a></p>
<p>Introduction: In light of the recent  article  about drug-target research and replication (Andrew blogged it  here ) and  l’affaire   Potti , I have mentioned the  “Forensic Bioinformatics” paper  (Baggerly & Coombes 2009) to several colleagues in passing this week. I have concluded that it has not gotten the attention it deserves, though it has been  discussed  on this blog before too.
 
     Figure 1 from Baggerly & Coombes 2009
  
  
 
The authors try to reproduce published data, and end up “reverse engineering” what the original authors had to have done. Some examples:
  
 §2.2: “Training data sensitive/resistant labels are reversed.” 
 §2.4: “Only 84/122 test samples are distinct; some samples are labeled both sensitive and resistant.” 
 §2.7: Almost half of the data is incorrectly labeled resistant. 
 §3.2: “This offset involves a single row shift: for example, … [data from] row 98 were used instead of those from row 97.” 
 §5.4: “Poor documentation led a report on drug A to include a heatmap</p><p>4 0.92477572 <a title="907-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-13-Can_you_write_a_program_to_determine_the_causal_order%3F.html">1801 andrew gelman stats-2013-04-13-Can you write a program to determine the causal order?</a></p>
<p>Introduction: Mike Zyphur writes:
  
Kaggle.com has launched a  competition  to determine what’s an effect and what’s a cause. They’ve got correlated variables, they’re deprived of context, and you’re asked to determine the causal order.  $5,000 prizes.
  
I followed the link and the example they gave didn’t make much sense to me (the two variables were temperature and altitude of cities in Germany, and they said that altitude causes temperature).  It has the feeling to me of one of those weird standardized tests we used to see sometimes in school, where there’s no real correct answer so the goal is to figure out what the test-writer wanted you to say.
 
Nonetheless, this might be of interest, so I’m passing it along to you.</p><p>5 0.91399169 <a title="907-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-29-R_sucks.html">1919 andrew gelman stats-2013-06-29-R sucks</a></p>
<p>Introduction: I was trying to make some new graphs using 5-year-old R code and I got all these problems because I was reading in files with variable names such as “co.fipsid” and now R is automatically changing them to “co_fipsid”.  Or maybe the names had underbars all along, and the old R had changed them into dots.  Whatever.  I understand that backward compatibility can be hard to maintain, but this is just annoying.</p><p>6 0.91353405 <a title="907-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-29-Going_negative.html">1918 andrew gelman stats-2013-06-29-Going negative</a></p>
<p>7 0.90661949 <a title="907-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-27-No_radon_lobby.html">238 andrew gelman stats-2010-08-27-No radon lobby</a></p>
<p>8 0.8930707 <a title="907-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-28-Advocacy_in_the_form_of_a_%E2%80%9Cdeliberative_forum%E2%80%9D.html">113 andrew gelman stats-2010-06-28-Advocacy in the form of a “deliberative forum”</a></p>
<p>9 0.89044797 <a title="907-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-18-Derivative-based_MCMC_as_a_breakthrough_technique_for_implementing_Bayesian_statistics.html">419 andrew gelman stats-2010-11-18-Derivative-based MCMC as a breakthrough technique for implementing Bayesian statistics</a></p>
<p>10 0.87921381 <a title="907-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-28-Plain_old_everyday_Bayesianism%21.html">1829 andrew gelman stats-2013-04-28-Plain old everyday Bayesianism!</a></p>
<p>11 0.876284 <a title="907-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-14-The_popularity_of_certain_baby_names_is_falling_off_the_clifffffffffffff.html">2211 andrew gelman stats-2014-02-14-The popularity of certain baby names is falling off the clifffffffffffff</a></p>
<p>12 0.87399244 <a title="907-lda-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-15-Mary%2C_Mary%2C_why_ya_buggin.html">2212 andrew gelman stats-2014-02-15-Mary, Mary, why ya buggin</a></p>
<p>13 0.87203443 <a title="907-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>14 0.86974883 <a title="907-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-26-%E2%80%9CThe_Bayesian_approach_to_forensic_evidence%E2%80%9D.html">2078 andrew gelman stats-2013-10-26-“The Bayesian approach to forensic evidence”</a></p>
<p>15 0.86770707 <a title="907-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-28-Why_during_the_1950-1960%E2%80%B2s_did_Jerry_Cornfield_become_a_Bayesian%3F.html">2000 andrew gelman stats-2013-08-28-Why during the 1950-1960′s did Jerry Cornfield become a Bayesian?</a></p>
<p>16 0.86358255 <a title="907-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-Measurement_error_in_monkey_studies.html">1997 andrew gelman stats-2013-08-24-Measurement error in monkey studies</a></p>
<p>17 0.85385597 <a title="907-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-28-Value-added_assessment%3A__What_went_wrong%3F.html">1350 andrew gelman stats-2012-05-28-Value-added assessment:  What went wrong?</a></p>
<p>18 0.85156602 <a title="907-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-06-Ideas_that_spread_fast_and_slow.html">2053 andrew gelman stats-2013-10-06-Ideas that spread fast and slow</a></p>
<p>19 0.85066295 <a title="907-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-Write_This_Book.html">1605 andrew gelman stats-2012-12-04-Write This Book</a></p>
<p>20 0.85004729 <a title="907-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-21-Forensic_bioinformatics%2C_or%2C_Don%E2%80%99t_believe_everything_you_read_in_the_%28scientific%29_papers.html">360 andrew gelman stats-2010-10-21-Forensic bioinformatics, or, Don’t believe everything you read in the (scientific) papers</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
