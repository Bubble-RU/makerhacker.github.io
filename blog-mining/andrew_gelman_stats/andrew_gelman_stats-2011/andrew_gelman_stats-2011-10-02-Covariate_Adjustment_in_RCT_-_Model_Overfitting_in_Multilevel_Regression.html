<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>936 andrew gelman stats-2011-10-02-Covariate Adjustment in RCT - Model Overfitting in Multilevel Regression</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-936" href="#">andrew_gelman_stats-2011-936</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>936 andrew gelman stats-2011-10-02-Covariate Adjustment in RCT - Model Overfitting in Multilevel Regression</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-936-html" href="http://andrewgelman.com/2011/10/02/covariate-adjustment-in-rct-model-overfitting-in-multilevel-regression/">html</a></p><p>Introduction: Makoto Hanita writes:
  
We have been discussing the following two issues amongst ourselves, then with our methodological consultant for several days. However, we have not been able to arrive at a consensus. Consequently, we decided to seek an opinion from nationally known experts. FYI, we sent a similar inquiry to Larry Hedges and David Rogosa . . .  


1)      We are wondering if a post-hoc covariate adjustment is a good practice in the context of RCTs [randomized clinical trials]. We have a situation where we found a significant baseline difference between the treatment and the control groups in 3 variables. Some of us argue that adding those three variables to the original impact analysis model is a good idea, as that would remove the confound from the impact estimate. Others among us, on the other hand, argue that a post-hoc covariate adjustment should never be done, on the ground that those covariates are correlated with the treatment, which makes the analysis model that of quasi</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Makoto Hanita writes:    We have been discussing the following two issues amongst ourselves, then with our methodological consultant for several days. [sent-1, score-0.164]
</p><p>2 1)      We are wondering if a post-hoc covariate adjustment is a good practice in the context of RCTs [randomized clinical trials]. [sent-7, score-0.484]
</p><p>3 We have a situation where we found a significant baseline difference between the treatment and the control groups in 3 variables. [sent-8, score-0.551]
</p><p>4 Some of us argue that adding those three variables to the original impact analysis model is a good idea, as that would remove the confound from the impact estimate. [sent-9, score-0.702]
</p><p>5 Others among us, on the other hand, argue that a post-hoc covariate adjustment should never be done, on the ground that those covariates are correlated with the treatment, which makes the analysis model that of quasi-experimental. [sent-10, score-1.002]
</p><p>6 For your information, we are all in agreement as to the use of covariates for RCTs that are pre-specified, for the purpose of variance reduction. [sent-11, score-0.368]
</p><p>7 What we cannot agree on is the use of covariates for the purpose of equating two groups in the context of RCTs. [sent-12, score-0.633]
</p><p>8 2)      Despite our disagreement on #1, we went ahead and tried fitting the model including those 3 additional covariates to our data. [sent-13, score-0.614]
</p><p>9 Some of us are suspicious of the results of this analysis because of the possible model overfitting. [sent-14, score-0.323]
</p><p>10 The situation involves fitting the below model to the sample of 14 schools and 800 students. [sent-15, score-0.354]
</p><p>11 As you can see, there are 5 fixed effects at the school level to be estimated. [sent-16, score-0.156]
</p><p>12 The analysis was done on multiply-imputed data (5 imputations were made). [sent-17, score-0.175]
</p><p>13 From what I have read, assessing model overfitting is rather difficult for multilevel models. [sent-18, score-0.307]
</p><p>14 In our case, we have an additional complexity of multiply-imputed data:   PostTest ij  = b 0  + b 1 (Treatment j ) + b 2  (School Cov1 j ) + b 3 (School Cov2 j ) + b 4 (School Cov3 j ) + b 5 (PreTest ij ) + b 6 (FRL% j ) + u j  + e ij     My reply:   1. [sent-19, score-0.957]
</p><p>15 Ultimately I think the right approach would be to use informative priors on the coefficients, to partially pool them toward zero and thus compromise between the two alternatives of no adjustment and simple least-squares adjustment. [sent-22, score-0.725]
</p><p>16 I doubt you’d want to do that, though, and I imagine you’d also be uncomfortable with an approximation such as to fit the adjusted model and then divide the coefficients for the adjustment by 2 (that’s a simple compromise). [sent-23, score-0.766]
</p><p>17 In your case my inclination would be to adjust for the 3 variables. [sent-24, score-0.196]
</p><p>18 As noted above, I might consider informative priors on the b’s. [sent-28, score-0.188]
</p><p>19 Possibly more importantly, I’d suggest allowing the coefficient for pre-test to interact with treatment vary by school. [sent-29, score-0.293]
</p><p>20 And, in  my experience , pre-test coefficients are systematically different in treatment and control groups. [sent-31, score-0.451]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ij', 0.287), ('covariates', 0.263), ('adjustment', 0.249), ('hedges', 0.223), ('rogosa', 0.223), ('treatment', 0.215), ('rcts', 0.191), ('model', 0.16), ('school', 0.156), ('covariate', 0.154), ('coefficients', 0.154), ('compromise', 0.152), ('adjust', 0.121), ('purpose', 0.105), ('fyi', 0.101), ('situation', 0.099), ('impact', 0.097), ('additional', 0.096), ('equating', 0.096), ('confound', 0.096), ('posttest', 0.096), ('fitting', 0.095), ('priors', 0.095), ('informative', 0.093), ('pretest', 0.092), ('argue', 0.089), ('imputations', 0.088), ('groups', 0.088), ('analysis', 0.087), ('consequently', 0.084), ('arrive', 0.084), ('inquiry', 0.082), ('consultant', 0.082), ('nationally', 0.082), ('amongst', 0.082), ('control', 0.082), ('context', 0.081), ('interact', 0.078), ('overfitting', 0.078), ('us', 0.076), ('inclination', 0.075), ('hand', 0.072), ('partially', 0.07), ('importantly', 0.07), ('adjusted', 0.069), ('assessing', 0.069), ('uncomfortable', 0.068), ('baseline', 0.067), ('divide', 0.066), ('pool', 0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="936-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-02-Covariate_Adjustment_in_RCT_-_Model_Overfitting_in_Multilevel_Regression.html">936 andrew gelman stats-2011-10-02-Covariate Adjustment in RCT - Model Overfitting in Multilevel Regression</a></p>
<p>Introduction: Makoto Hanita writes:
  
We have been discussing the following two issues amongst ourselves, then with our methodological consultant for several days. However, we have not been able to arrive at a consensus. Consequently, we decided to seek an opinion from nationally known experts. FYI, we sent a similar inquiry to Larry Hedges and David Rogosa . . .  


1)      We are wondering if a post-hoc covariate adjustment is a good practice in the context of RCTs [randomized clinical trials]. We have a situation where we found a significant baseline difference between the treatment and the control groups in 3 variables. Some of us argue that adding those three variables to the original impact analysis model is a good idea, as that would remove the confound from the impact estimate. Others among us, on the other hand, argue that a post-hoc covariate adjustment should never be done, on the ground that those covariates are correlated with the treatment, which makes the analysis model that of quasi</p><p>2 0.15410627 <a title="936-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>Introduction: Avi sent along  this old paper  from Bryk and Raudenbush, who write:
  
The presence of heterogeneity of variance across groups indicates that the standard statistical model for treatment effects no longer applies. Specifically, the assumption that treatments add a constant to each subject’s development fails. An alternative model is required to represent how treatment effects are distributed across individuals. We develop in this article a simple statistical model to demonstrate the link between heterogeneity of variance and random treatment effects. Next, we illustrate with results from two previously published studies how a failure to recognize the substantive importance of heterogeneity of variance obscured significant results present in these data. The article concludes with a review and synthesis of techniques for modeling variances. Although these methods have been well established in the statistical literature, they are not widely known by social and behavioral scientists.
  
T</p><p>3 0.15150981 <a title="936-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Matching_at_two_levels.html">213 andrew gelman stats-2010-08-17-Matching at two levels</a></p>
<p>Introduction: Steve Porter writes with a question about matching for inferences in a hierarchical data structure.  I’ve never thought about this particular issue, but it seems potentially important.
 
Maybe one or more of you have some useful suggestions?
 
Porter writes:
  
 
After immersing myself in the relatively sparse literature on propensity scores with clustered data, it seems as if people take one of two approaches. If the treatment is at the cluster-level (like school policies), they match on only the cluster-level covariates. If the treatment is at the individual level, they match on individual-level covariates. (I have also found some papers that match on individual-level covariates when it seems as if the treatment is really at the cluster-level.) But what if there is a selection process at both levels?


For my research question (effect of tenure systems on faculty behavior) there is a two-step selection process: first colleges choose whether to have a tenure system for faculty; then f</p><p>4 0.15130389 <a title="936-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-Understanding_how_estimates_change_when_you_move_to_a_multilevel_model.html">850 andrew gelman stats-2011-08-11-Understanding how estimates change when you move to a multilevel model</a></p>
<p>Introduction: Ramu Sudhagoni writes:
  
 
I am working on combining three longitudinal studies using Bayesian hierarchical technique.  In each study, I have at least 70 subjects follow up on 5 different visit months. My model consists of 10 different covariates including longitudinal and cross-sectional effects. Mixed models are used to fit the three studies individually using Bayesian approach and I noticed that few covariates were significant. When I combined using three level hierarchical approach, all the covariates became non-significant at the population level,  and large estimates were found for variance parameters at the population level. I am struggling to understand why I am getting large variances at population level and wider credible intervals. I assumed non-informative normal priors for all my cross sectional and longitudinal effects, and non-informative inverse-gamma priors for variance parameters. I followed the approach explained by Inoue et al. (Title: Combining Longitudinal Studie</p><p>5 0.14753681 <a title="936-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-07-Prior_distributions_for_regression_coefficients.html">1486 andrew gelman stats-2012-09-07-Prior distributions for regression coefficients</a></p>
<p>Introduction: Eric Brown writes:
  
I have come across a number of recommendations over the years about best practices for multilevel regression modeling.  For example, the use of t-distributed priors for coefficients in logistic regression and standardizing input variables from one of your 2008 Annals of Applied Statistics papers; or recommendations for priors on variance parameters from your 2006 Bayesian Analysis paper.  I understand that these are often of varied opinion of people in the field, but I was wondering if you have a reference that you point people to for a place to get started?  I’ve tried looking through your blog posts but couldn’t find any summaries.


For example, what are some examples of when I should use more than a two-level hierarchical model?  Can I use a spike-slab coefficient model with a t-distributed prior for the slab rather than a normal? If I assume that my model is a priori wrong (but still useful), what are some recommended ways to choose how many interactions to u</p><p>6 0.14623556 <a title="936-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>7 0.12709519 <a title="936-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Including_interactions_or_not.html">823 andrew gelman stats-2011-07-26-Including interactions or not</a></p>
<p>8 0.12057535 <a title="936-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-02-The_inevitable_problems_with_statistical_significance_and_95%25_intervals.html">1150 andrew gelman stats-2012-02-02-The inevitable problems with statistical significance and 95% intervals</a></p>
<p>9 0.12030571 <a title="936-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>10 0.11981472 <a title="936-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>11 0.11887252 <a title="936-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>12 0.11858758 <a title="936-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>13 0.1183916 <a title="936-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-15-Wacky_priors_can_work_well%3F.html">1723 andrew gelman stats-2013-02-15-Wacky priors can work well?</a></p>
<p>14 0.11706369 <a title="936-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-14-%E2%80%9CToo_much_data%E2%80%9D%3F.html">86 andrew gelman stats-2010-06-14-“Too much data”?</a></p>
<p>15 0.11471098 <a title="936-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-28-Value-added_assessment%3A__What_went_wrong%3F.html">1350 andrew gelman stats-2012-05-28-Value-added assessment:  What went wrong?</a></p>
<p>16 0.11415481 <a title="936-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>17 0.11383853 <a title="936-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<p>18 0.11161054 <a title="936-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-12-As_a_Bayesian_I_want_scientists_to_report_their_data_non-Bayesianly.html">1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</a></p>
<p>19 0.10918744 <a title="936-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-23-Modeling_heterogenous_treatment_effects.html">2 andrew gelman stats-2010-04-23-Modeling heterogenous treatment effects</a></p>
<p>20 0.10758355 <a title="936-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-Varying_treatment_effects%2C_again.html">1310 andrew gelman stats-2012-05-09-Varying treatment effects, again</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.197), (1, 0.125), (2, 0.068), (3, -0.044), (4, 0.055), (5, 0.025), (6, 0.023), (7, 0.013), (8, 0.046), (9, 0.12), (10, 0.028), (11, 0.055), (12, 0.016), (13, -0.012), (14, -0.009), (15, 0.008), (16, 0.011), (17, 0.011), (18, -0.025), (19, 0.042), (20, -0.035), (21, 0.006), (22, -0.01), (23, -0.033), (24, -0.016), (25, 0.003), (26, -0.022), (27, -0.006), (28, -0.081), (29, 0.044), (30, -0.023), (31, -0.015), (32, 0.01), (33, 0.064), (34, -0.01), (35, 0.023), (36, -0.013), (37, 0.003), (38, 0.074), (39, 0.022), (40, -0.011), (41, -0.04), (42, 0.034), (43, 0.017), (44, 0.017), (45, 0.006), (46, -0.01), (47, -0.065), (48, -0.028), (49, 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9592849 <a title="936-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-02-Covariate_Adjustment_in_RCT_-_Model_Overfitting_in_Multilevel_Regression.html">936 andrew gelman stats-2011-10-02-Covariate Adjustment in RCT - Model Overfitting in Multilevel Regression</a></p>
<p>Introduction: Makoto Hanita writes:
  
We have been discussing the following two issues amongst ourselves, then with our methodological consultant for several days. However, we have not been able to arrive at a consensus. Consequently, we decided to seek an opinion from nationally known experts. FYI, we sent a similar inquiry to Larry Hedges and David Rogosa . . .  


1)      We are wondering if a post-hoc covariate adjustment is a good practice in the context of RCTs [randomized clinical trials]. We have a situation where we found a significant baseline difference between the treatment and the control groups in 3 variables. Some of us argue that adding those three variables to the original impact analysis model is a good idea, as that would remove the confound from the impact estimate. Others among us, on the other hand, argue that a post-hoc covariate adjustment should never be done, on the ground that those covariates are correlated with the treatment, which makes the analysis model that of quasi</p><p>2 0.82568038 <a title="936-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>Introduction: Zoltan Fazekas writes:
  
I am a 2nd year graduate student in political science at the University of Vienna. In my empirical research I often employ multilevel modeling, and recently I came across a situation that kept me wondering for quite a while. As I did not find much on this in the literature and considering the topics that you work on and blog about, I figured I will try to contact you.
      
The situation is as follows: in a linear multilevel model, there are two important individual level predictors (x1 and x2) and a set of controls. Let us assume that there is a theoretically grounded argument suggesting that an interaction between x1 and x2 should be included in the model (x1 * x2). Both x1 and x2 are let to vary randomly across groups. Would this directly imply that the coefficient of the interaction should also be left to vary across country? This is even more burning if there is no specific hypothesis on the variance of the conditional effect across countries. And then i</p><p>3 0.81759757 <a title="936-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Including_interactions_or_not.html">823 andrew gelman stats-2011-07-26-Including interactions or not</a></p>
<p>Introduction: Liz Sanders writes:
  
I viewed your 2005 presentation “Interactions in multilevel models” and was hoping you or one of your students/colleagues could point me to some readings about the issue of using all possible vs. only particular interaction terms in regression models with continuous covariates (I think “functional form validity” is the term I have encountered in the past). 


In particular, I am trying to understand whether I would be mis-specifying a model if I deleted two of its interaction terms (in favor of using only 2-way treatment interaction terms). The general full model, for example, is:


Y = intercept + txt + pre1 + pre2 + txt*pre1 + txt*pre2 + pre1*pre2 + txt*pre1*pre2, where txt is effect coded (1=treatment, -1=control) and pre1 and pre2 are two different pretests that are assumed normally distributed. (The model is actually a multilevel model; the error terms are not listed for brevity.)


The truncated model, on the other hand, would only test 2-way treatment inte</p><p>4 0.80485183 <a title="936-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Matching_at_two_levels.html">213 andrew gelman stats-2010-08-17-Matching at two levels</a></p>
<p>Introduction: Steve Porter writes with a question about matching for inferences in a hierarchical data structure.  I’ve never thought about this particular issue, but it seems potentially important.
 
Maybe one or more of you have some useful suggestions?
 
Porter writes:
  
 
After immersing myself in the relatively sparse literature on propensity scores with clustered data, it seems as if people take one of two approaches. If the treatment is at the cluster-level (like school policies), they match on only the cluster-level covariates. If the treatment is at the individual level, they match on individual-level covariates. (I have also found some papers that match on individual-level covariates when it seems as if the treatment is really at the cluster-level.) But what if there is a selection process at both levels?


For my research question (effect of tenure systems on faculty behavior) there is a two-step selection process: first colleges choose whether to have a tenure system for faculty; then f</p><p>5 0.79566991 <a title="936-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>Introduction: Chris Che-Castaldo writes:
  
I am trying to compute variance components for a hierarchical model where the group level has two binary predictors and their interaction. When I model each of these three predictors as N(0, tau) the model will not converge, perhaps because the number of coefficients in each batch is so small (2 for the main effects and 4 for the interaction). Although I could simply leave all these as predictors as unmodeled fixed effects, the last sentence of section 21.2 on page 462 of Gelman and Hill (2007) suggests this would not be a wise course of action:

 
For example, it is not clear how to define the (finite) standard deviation of variables that are included in interactions.
 

I am curious – is there still no clear cut way to directly compute the finite standard deviation for binary unmodeled variables that are also part of an interaction as well as the interaction itself?
  
My reply:  I’d recommend including these in your model (it’s probably easiest to do so</p><p>6 0.78591216 <a title="936-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-Interactions_of_predictors_in_a_causal_model.html">251 andrew gelman stats-2010-09-02-Interactions of predictors in a causal model</a></p>
<p>7 0.78340369 <a title="936-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-03-He_doesn%E2%80%99t_trust_the_fit_._._._r%3D.999.html">315 andrew gelman stats-2010-10-03-He doesn’t trust the fit . . . r=.999</a></p>
<p>8 0.77807182 <a title="936-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-14-%E2%80%9CToo_much_data%E2%80%9D%3F.html">86 andrew gelman stats-2010-06-14-“Too much data”?</a></p>
<p>9 0.75830704 <a title="936-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Modeling_y_%3D_a_%2B_b_%2B_c.html">1294 andrew gelman stats-2012-05-01-Modeling y = a + b + c</a></p>
<p>10 0.75596666 <a title="936-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>11 0.75185513 <a title="936-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-The_scope_for_snooping.html">1070 andrew gelman stats-2011-12-19-The scope for snooping</a></p>
<p>12 0.74064291 <a title="936-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>13 0.73521823 <a title="936-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>14 0.7344557 <a title="936-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-Blending_results_from_two_relatively_independent_multi-level_models.html">250 andrew gelman stats-2010-09-02-Blending results from two relatively independent multi-level models</a></p>
<p>15 0.73016018 <a title="936-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Sof%5Bt%5D.html">77 andrew gelman stats-2010-06-09-Sof[t]</a></p>
<p>16 0.72699779 <a title="936-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>17 0.72670788 <a title="936-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-24-Multilevel_modeling_and_instrumental_variables.html">1468 andrew gelman stats-2012-08-24-Multilevel modeling and instrumental variables</a></p>
<p>18 0.72046095 <a title="936-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>19 0.71923542 <a title="936-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-28-Matching_for_preprocessing_data_for_causal_inference.html">375 andrew gelman stats-2010-10-28-Matching for preprocessing data for causal inference</a></p>
<p>20 0.71701014 <a title="936-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-18-Hierarchical_modeling_as_a_framework_for_extrapolation.html">1383 andrew gelman stats-2012-06-18-Hierarchical modeling as a framework for extrapolation</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(4, 0.018), (15, 0.04), (16, 0.077), (21, 0.016), (24, 0.211), (34, 0.184), (57, 0.014), (76, 0.017), (82, 0.033), (84, 0.019), (86, 0.024), (99, 0.225)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9570502 <a title="936-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-27-Visual_diagnostics_for_discrete-data_regressions.html">929 andrew gelman stats-2011-09-27-Visual diagnostics for discrete-data regressions</a></p>
<p>Introduction: Jeff asked me what I thought of  this  recent AJPS article by Brian Greenhill, Michael Ward, and Audrey Sacks, “The Separation Plot: A New Visual Method for Evaluating the Fit of Binary Models.”  It’s similar to a graph of observed vs. predicted values, but using color rather than the y-axis to display the observed values.  It seems like it could be useful, also could be applied more generally to discrete-data regressions with more than two categories.
 
When it comes to checking the model fit, I recommend binned residual plots, as discussed in  this 2000 article  with Yuri Goegebeur, Francis Tuerlinckx, and Iven Van Mechelen.</p><p>2 0.94785941 <a title="936-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<p>Introduction: Stephen Collins writes:
  
I’m reading your Multilevel modeling book and am trying to apply it to my work.  I’m concerned with how to estimate a random intercept model if there are hundreds/thousands of levels.  In the Gibbs sampling, am I sampling a parameter for each level?  Or, just the hyper-parameters?  In other words, say I had 500 zipcode intercepts modeled as ~ N(m,s).  Would my posterior be two dimensional, sampling for “m” and “s,” or would it have 502 dimensions?
  
My reply:  Indeed you will have hundreds or thousands of parameters—or, in classical terms, hundreds or thousands of predictive quantities.  But that’s ok.  Even if none of those predictions is precise, you’re learning  about the model.
 
See page 526 of the book for more discussion of the number of parameters in a multilevel model.</p><p>3 0.94780326 <a title="936-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-23-AI_Stats_conference_on_Stan_etc..html">1911 andrew gelman stats-2013-06-23-AI Stats conference on Stan etc.</a></p>
<p>Introduction: Jaakko Peltonen writes:
  
The Seventeenth International Conference on Artificial Intelligence and Statistics (http://www.aistats.org) will be next April in Reykjavik, Iceland. AISTATS is an interdisciplinary conference at the intersection of computer science, artificial intelligence, machine learning, statistics, and related areas.
  
  
  
============================================================================== 
AISTATS 2014 Call for Papers 
Seventeenth International Conference on Artificial Intelligence and Statistics 
April 22 – 25, 2014, Reykjavik, Iceland


http://www.aistats.org


Colocated with a MLSS Machine Learning Summer School 
==============================================================================


AISTATS is an interdisciplinary gathering of researchers at the intersection of computer science, artificial intelligence, machine learning, statistics, and related areas. Since its inception in 1985, the primary goal of AISTATS has been to broaden research in the</p><p>4 0.93285334 <a title="936-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-18-More_studies_on_the_economic_effects_of_climate_change.html">1501 andrew gelman stats-2012-09-18-More studies on the economic effects of climate change</a></p>
<p>Introduction: After writing  yesterday’s post , I was going through Solomon Hsiang’s blog and found  a post  pointing to three studies from researchers at business schools:
  
Severe Weather and Automobile Assembly Productivity


Gérard P. Cachon, Santiago Gallino and Marcelo Olivares


Abstract: It is expected that climate change could lead to an increased frequency of severe weather. In turn, severe weather intuitively should hamper the productivity of work that occurs outside. But what is the effect of rain, snow, fog, heat and wind on work that occurs indoors, such as the production of automobiles? Using weekly production data from 64 automobile plants in the United States over a ten-year period, we ﬁnd that adverse weather conditions lead to a signiﬁcant reduction in production. For example, one additional day of high wind advisory by the National Weather Service (i.e., maximum winds generally in excess of 44 miles per hour) reduces production by 26%, which is comparable in order of magnitude t</p><p>same-blog 5 0.93086398 <a title="936-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-02-Covariate_Adjustment_in_RCT_-_Model_Overfitting_in_Multilevel_Regression.html">936 andrew gelman stats-2011-10-02-Covariate Adjustment in RCT - Model Overfitting in Multilevel Regression</a></p>
<p>Introduction: Makoto Hanita writes:
  
We have been discussing the following two issues amongst ourselves, then with our methodological consultant for several days. However, we have not been able to arrive at a consensus. Consequently, we decided to seek an opinion from nationally known experts. FYI, we sent a similar inquiry to Larry Hedges and David Rogosa . . .  


1)      We are wondering if a post-hoc covariate adjustment is a good practice in the context of RCTs [randomized clinical trials]. We have a situation where we found a significant baseline difference between the treatment and the control groups in 3 variables. Some of us argue that adding those three variables to the original impact analysis model is a good idea, as that would remove the confound from the impact estimate. Others among us, on the other hand, argue that a post-hoc covariate adjustment should never be done, on the ground that those covariates are correlated with the treatment, which makes the analysis model that of quasi</p><p>6 0.9243744 <a title="936-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-09-Rasmussen_sez%3A__%E2%80%9C108%25_of_Respondents_Say_._._.%E2%80%9D.html">135 andrew gelman stats-2010-07-09-Rasmussen sez:  “108% of Respondents Say . . .”</a></p>
<p>7 0.91419673 <a title="936-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-23-Doug_Hibbs_on_the_fundamentals_in_2010.html">292 andrew gelman stats-2010-09-23-Doug Hibbs on the fundamentals in 2010</a></p>
<p>8 0.91130912 <a title="936-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-23-Life_in_the_C-suite%3A__A_graph_that_is_both_ugly_and_bad%2C_and_an_unrelated_story.html">1734 andrew gelman stats-2013-02-23-Life in the C-suite:  A graph that is both ugly and bad, and an unrelated story</a></p>
<p>9 0.90032268 <a title="936-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-17-%E2%80%9C2%25_per_degree_Celsius_._._._the_magic_number_for_how_worker_productivity_responds_to_warm-hot_temperatures%E2%80%9D.html">1500 andrew gelman stats-2012-09-17-“2% per degree Celsius . . . the magic number for how worker productivity responds to warm-hot temperatures”</a></p>
<p>10 0.88790679 <a title="936-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-01-The_placebo_effect_in_pharma.html">388 andrew gelman stats-2010-11-01-The placebo effect in pharma</a></p>
<p>11 0.88626671 <a title="936-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-25-Revised_statistical_standards_for_evidence_%28comments_to_Val_Johnson%E2%80%99s_comments_on_our_comments_on_Val%E2%80%99s_comments_on_p-values%29.html">2305 andrew gelman stats-2014-04-25-Revised statistical standards for evidence (comments to Val Johnson’s comments on our comments on Val’s comments on p-values)</a></p>
<p>12 0.88426399 <a title="936-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-15-Wacky_priors_can_work_well%3F.html">1723 andrew gelman stats-2013-02-15-Wacky priors can work well?</a></p>
<p>13 0.88245386 <a title="936-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-05-Cleaning_up_science.html">1842 andrew gelman stats-2013-05-05-Cleaning up science</a></p>
<p>14 0.87573838 <a title="936-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-10-The_blog_of_the_Cultural_Cognition_Project.html">1111 andrew gelman stats-2012-01-10-The blog of the Cultural Cognition Project</a></p>
<p>15 0.87184215 <a title="936-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-13-Hey%2C_you%21__Don%E2%80%99t_take_that_class%21.html">956 andrew gelman stats-2011-10-13-Hey, you!  Don’t take that class!</a></p>
<p>16 0.87120593 <a title="936-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-06-Josh_Tenenbaum_presents_._._._a_model_of_folk_physics%21.html">994 andrew gelman stats-2011-11-06-Josh Tenenbaum presents . . . a model of folk physics!</a></p>
<p>17 0.86843908 <a title="936-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-19-Revised_evidence_for_statistical_standards.html">2140 andrew gelman stats-2013-12-19-Revised evidence for statistical standards</a></p>
<p>18 0.86566412 <a title="936-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-19-Updated_solutions_to_Bayesian_Data_Analysis_homeworks.html">42 andrew gelman stats-2010-05-19-Updated solutions to Bayesian Data Analysis homeworks</a></p>
<p>19 0.86226928 <a title="936-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-08-The_Case_for_More_False_Positives_in_Anti-doping_Testing.html">1612 andrew gelman stats-2012-12-08-The Case for More False Positives in Anti-doping Testing</a></p>
<p>20 0.86173713 <a title="936-lda-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-10-Small_multiples_of_lineplots_%3E_maps_%28ok%2C_not_always%2C_but_yes_in_this_case%29.html">2288 andrew gelman stats-2014-04-10-Small multiples of lineplots > maps (ok, not always, but yes in this case)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
