<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>935 andrew gelman stats-2011-10-01-When should you worry about imputed data?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-935" href="#">andrew_gelman_stats-2011-935</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>935 andrew gelman stats-2011-10-01-When should you worry about imputed data?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-935-html" href="http://andrewgelman.com/2011/10/01/when-should-you-worry-about-imputed-data/">html</a></p><p>Introduction: Majid Ezzati writes:
  
My research group is increasingly focusing on a series of problems that involve data that either have missingness or measurements that may have bias/error.  We have at times developed our own approaches to imputation (as simple as interpolating a missing unit and as sophisticated as a problem-specific Bayesian hierarchical model) and at other times, other groups impute the data. 


The outputs are being used to investigate the basic associations between pairs of variables, Xs and Ys, in regressions; we may or may not interpret these as causal.  I am contacting colleagues with relevant expertise to suggest good references on whether having imputed X and/or Y in a subsequent regression is correct or if it could somehow lead to biased/spurious associations.   Thinking about this, we can have at least the following situations (these could all be Bayesian or not):


1)  X and Y both measured (perhaps with error) 
2)  Y imputed using some data and a model and X measur</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Majid Ezzati writes:    My research group is increasingly focusing on a series of problems that involve data that either have missingness or measurements that may have bias/error. [sent-1, score-0.488]
</p><p>2 We have at times developed our own approaches to imputation (as simple as interpolating a missing unit and as sophisticated as a problem-specific Bayesian hierarchical model) and at other times, other groups impute the data. [sent-2, score-0.638]
</p><p>3 The outputs are being used to investigate the basic associations between pairs of variables, Xs and Ys, in regressions; we may or may not interpret these as causal. [sent-3, score-0.568]
</p><p>4 I am contacting colleagues with relevant expertise to suggest good references on whether having imputed X and/or Y in a subsequent regression is correct or if it could somehow lead to biased/spurious associations. [sent-4, score-1.172]
</p><p>5 8) Y and X imputed in a joint model – multiple imputation   Any suggestions you may have on readings on whether such regressions could lead to spurious or biased associations or if they are OK to do would be appreciated. [sent-6, score-1.866]
</p><p>6 My reply:   The short answer is that if your imputation model is correct (that is, if the likelihood you are using corresponds to the process by which the data and missingness were generated) then it should be fine to impute randomly conditional on all available information. [sent-7, score-1.038]
</p><p>7 But in real life the model won’t be correct so there can be problems. [sent-8, score-0.286]
</p><p>8 I don’t have any general thoughts on the 8 situations above. [sent-9, score-0.103]
</p><p>9 The  1994 paper  by Xiao-Li Meng on congenial inference may be useful in developing your understanding. [sent-10, score-0.314]
</p><p>10 Also, if you’re planning to check the fit of your imputation model (as I think you should), my  paper with Kobi  could be a useful starting point. [sent-11, score-0.569]
</p><p>11 It’s frustrating that there’s no general answer but I think that’s the way it often is in statistics, that much depends on the reasonableness of the model. [sent-12, score-0.2]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('imputed', 0.677), ('covariate', 0.275), ('imputation', 0.228), ('model', 0.179), ('missingness', 0.153), ('measured', 0.152), ('impute', 0.149), ('imputing', 0.14), ('associations', 0.13), ('may', 0.12), ('correct', 0.107), ('situations', 0.103), ('regressions', 0.1), ('kobi', 0.091), ('interpolating', 0.091), ('xs', 0.091), ('separate', 0.088), ('congenial', 0.086), ('contacting', 0.086), ('reasonableness', 0.086), ('lead', 0.082), ('outputs', 0.073), ('readings', 0.071), ('common', 0.071), ('spurious', 0.07), ('investigate', 0.065), ('subsequent', 0.064), ('meng', 0.064), ('generated', 0.061), ('pairs', 0.06), ('increasingly', 0.059), ('times', 0.058), ('useful', 0.058), ('answer', 0.057), ('frustrating', 0.057), ('using', 0.057), ('unit', 0.056), ('corresponds', 0.056), ('sophisticated', 0.056), ('biased', 0.053), ('could', 0.053), ('focusing', 0.052), ('measurements', 0.052), ('involve', 0.052), ('randomly', 0.052), ('whether', 0.052), ('joint', 0.051), ('expertise', 0.051), ('planning', 0.051), ('developing', 0.05)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="935-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-01-When_should_you_worry_about_imputed_data%3F.html">935 andrew gelman stats-2011-10-01-When should you worry about imputed data?</a></p>
<p>Introduction: Majid Ezzati writes:
  
My research group is increasingly focusing on a series of problems that involve data that either have missingness or measurements that may have bias/error.  We have at times developed our own approaches to imputation (as simple as interpolating a missing unit and as sophisticated as a problem-specific Bayesian hierarchical model) and at other times, other groups impute the data. 


The outputs are being used to investigate the basic associations between pairs of variables, Xs and Ys, in regressions; we may or may not interpret these as causal.  I am contacting colleagues with relevant expertise to suggest good references on whether having imputed X and/or Y in a subsequent regression is correct or if it could somehow lead to biased/spurious associations.   Thinking about this, we can have at least the following situations (these could all be Bayesian or not):


1)  X and Y both measured (perhaps with error) 
2)  Y imputed using some data and a model and X measur</p><p>2 0.50112081 <a title="935-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-Hypothesis_testing_with_multiple_imputations.html">799 andrew gelman stats-2011-07-13-Hypothesis testing with multiple imputations</a></p>
<p>Introduction: Vincent Yip writes:
  
I have read  your paper  [with Kobi Abayomi and Marc Levy] regarding multiple imputation application.


In order to diagnostic my imputed data, I used Kolmogorov-Smirnov (K-S) tests to compare the distribution differences between the imputed and observed values of a single attribute as mentioned in your paper. My question is:


For example I have this attribute X with the following data:  (NA = missing)


Original dataset: 1, NA, 3, 4, 1, 5, NA


Imputed dataset: 1, 2  , 3, 4, 1, 5, 6


a) in order to run the KS test, will I treat the observed data as 1, 3, 4,1, 5?


b) and for the observed data, will I treat 1, 2  , 3, 4, 1, 5, 6 as the imputed dataset for the K-S test? or just 2 ,6?


c) if I used m=5, I will have 5 set of imputed data sets. How would I apply K-S test to 5 of them and compare to the single observed distribution? Do I combine the 5 imputed data set into one by averaging each imputed values so I get one single imputed data and compare with the ob</p><p>3 0.24493824 <a title="935-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-19-Cross-validation_to_check_missing-data_imputation.html">1330 andrew gelman stats-2012-05-19-Cross-validation to check missing-data imputation</a></p>
<p>Introduction: Aureliano Crameri writes: 
  
  
I have questions regarding one technique you and your colleagues described in your papers: the cross validation (Multiple Imputation with Diagnostics (mi) in R: Opening Windows into the Black Box, with reference to Gelman, King, and Liu, 1998). I think this is the technique I need for my purpose, but I am not sure I understand it right. I want to use the multiple imputation to estimate the outcome of psychotherapies based on longitudinal data. First I have to demonstrate that I am able to get unbiased estimates with the multiple imputation. The expected bias is the overestimation of the outcome of dropouts.


I will test my imputation strategies by means of a series of simulations (delete values, impute, compare with the original). Due to the complexity of the statistical analyses I think I need at least 200 cases. Now I don’t have so many cases without any missings. My data have missing values in different variables. The proportion of missing values is</p><p>4 0.22508955 <a title="935-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-12-Single_or_multiple_imputation%3F.html">608 andrew gelman stats-2011-03-12-Single or multiple imputation?</a></p>
<p>Introduction: Vishnu Ganglani writes:
  
It appears that multiple imputation appears to be the best way to impute missing data because of the more accurate quantification of variance. However, when imputing missing data for income values in national household surveys, would you recommend it would be practical to maintain the multiple datasets associated with multiple imputations, or a single imputation method would suffice. I have worked on household survey projects (in Scotland) and in the past gone with suggesting single methods for ease of implementation, but with the availability of open source R software I am think of performing multiple imputation methodologies, but a bit apprehensive because of the complexity and also the need to maintain multiple datasets (ease of implementation).
  
My reply:  In many applications I’ve just used a single random imputation to avoid the awkwardness of working with multiple datasets.  But if there’s any concern, I’d recommend doing parallel analyses on multipl</p><p>5 0.21633133 <a title="935-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-25-Question_15_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1344 andrew gelman stats-2012-05-25-Question 15 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>Introduction: 15. A researcher conducts a random-digit-dial survey of individuals and married couples. The design is as follows: if only one person lives in a household, he or she is interviewed. If there are multiple adults in the household, one is selected at random: he or she is interviewed and, if he or she is married to one of the other adults in the household, the spouse is interviewed as well. Come up with a scheme for inverse-probability weights (ignoring nonresponse and assuming there is exactly one phone line per household).
 
 Solution to question 14 
 
From  yesterday :
  
14. A public health survey of elderly Americans includes many questions, including “How many hours per week did you exercise in your most active years as a young adult?” and also several questions about current mobility and health status. Response rates are high for the questions about recent activities and status, but there is a lot of nonresponse for the question on past activity. You are considering imputing the mis</p><p>6 0.21391922 <a title="935-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>7 0.19235271 <a title="935-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-24-Question_14_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1341 andrew gelman stats-2012-05-24-Question 14 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>8 0.17933187 <a title="935-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-18-Check_your_missing-data_imputations_using_cross-validation.html">1218 andrew gelman stats-2012-03-18-Check your missing-data imputations using cross-validation</a></p>
<p>9 0.17062077 <a title="935-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>10 0.15658425 <a title="935-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Racism%21.html">321 andrew gelman stats-2010-10-05-Racism!</a></p>
<p>11 0.12920161 <a title="935-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-31-Value-added_modeling_in_education%3A__Gaming_the_system_by_sending_kids_on_a_field_trip_at_test_time.html">2083 andrew gelman stats-2013-10-31-Value-added modeling in education:  Gaming the system by sending kids on a field trip at test time</a></p>
<p>12 0.12553284 <a title="935-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-09-%E2%80%9CMuch_of_the_recent_reported_drop_in_interstate_migration_is_a_statistical_artifact%E2%80%9D.html">404 andrew gelman stats-2010-11-09-“Much of the recent reported drop in interstate migration is a statistical artifact”</a></p>
<p>13 0.11887547 <a title="935-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-13-Checking_your_model_using_fake_data.html">852 andrew gelman stats-2011-08-13-Checking your model using fake data</a></p>
<p>14 0.11581943 <a title="935-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-All_inference_is_about_generalizing_from_sample_to_population.html">1996 andrew gelman stats-2013-08-24-All inference is about generalizing from sample to population</a></p>
<p>15 0.11227199 <a title="935-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>16 0.11207137 <a title="935-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>17 0.11104077 <a title="935-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-Displaying_a_fitted_multilevel_model.html">328 andrew gelman stats-2010-10-08-Displaying a fitted multilevel model</a></p>
<p>18 0.10568531 <a title="935-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-27-Bayesian_model_averaging_or_fitting_a_larger_model.html">1999 andrew gelman stats-2013-08-27-Bayesian model averaging or fitting a larger model</a></p>
<p>19 0.10356265 <a title="935-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>20 0.097875386 <a title="935-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.141), (1, 0.131), (2, 0.023), (3, -0.003), (4, 0.039), (5, 0.049), (6, -0.034), (7, -0.028), (8, 0.114), (9, 0.037), (10, 0.023), (11, 0.046), (12, -0.038), (13, 0.007), (14, -0.022), (15, 0.026), (16, 0.044), (17, -0.008), (18, -0.007), (19, -0.006), (20, 0.005), (21, 0.032), (22, -0.016), (23, -0.054), (24, -0.018), (25, 0.008), (26, 0.004), (27, -0.08), (28, 0.073), (29, 0.002), (30, 0.015), (31, -0.002), (32, 0.039), (33, 0.101), (34, -0.007), (35, 0.013), (36, 0.053), (37, 0.061), (38, 0.011), (39, -0.003), (40, -0.071), (41, -0.004), (42, -0.001), (43, -0.003), (44, 0.014), (45, 0.013), (46, 0.058), (47, -0.035), (48, -0.005), (49, 0.009)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92119455 <a title="935-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-01-When_should_you_worry_about_imputed_data%3F.html">935 andrew gelman stats-2011-10-01-When should you worry about imputed data?</a></p>
<p>Introduction: Majid Ezzati writes:
  
My research group is increasingly focusing on a series of problems that involve data that either have missingness or measurements that may have bias/error.  We have at times developed our own approaches to imputation (as simple as interpolating a missing unit and as sophisticated as a problem-specific Bayesian hierarchical model) and at other times, other groups impute the data. 


The outputs are being used to investigate the basic associations between pairs of variables, Xs and Ys, in regressions; we may or may not interpret these as causal.  I am contacting colleagues with relevant expertise to suggest good references on whether having imputed X and/or Y in a subsequent regression is correct or if it could somehow lead to biased/spurious associations.   Thinking about this, we can have at least the following situations (these could all be Bayesian or not):


1)  X and Y both measured (perhaps with error) 
2)  Y imputed using some data and a model and X measur</p><p>2 0.74559522 <a title="935-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-25-Question_15_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1344 andrew gelman stats-2012-05-25-Question 15 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>Introduction: 15. A researcher conducts a random-digit-dial survey of individuals and married couples. The design is as follows: if only one person lives in a household, he or she is interviewed. If there are multiple adults in the household, one is selected at random: he or she is interviewed and, if he or she is married to one of the other adults in the household, the spouse is interviewed as well. Come up with a scheme for inverse-probability weights (ignoring nonresponse and assuming there is exactly one phone line per household).
 
 Solution to question 14 
 
From  yesterday :
  
14. A public health survey of elderly Americans includes many questions, including “How many hours per week did you exercise in your most active years as a young adult?” and also several questions about current mobility and health status. Response rates are high for the questions about recent activities and status, but there is a lot of nonresponse for the question on past activity. You are considering imputing the mis</p><p>3 0.73212135 <a title="935-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>Introduction: Andreas Graefe writes (see  here   here   here ):
  
The usual procedure for developing linear models to predict any kind of target variable is to identify a subset of most important predictors and to estimate weights that provide the best possible solution for a given sample. The resulting “optimally” weighted linear composite is then used when predicting new data. This approach is useful in situations with large and reliable datasets and few predictor variables. However, a large body of analytical and empirical evidence since the 1970s shows that the weighting of variables is of little, if any, value in situations with small and noisy datasets and a large number of predictor variables. In such situations, including all relevant variables is more important than their weighting. These findings have yet to impact many fields. This study uses data from nine established U.S. election-forecasting models whose forecasts are regularly published in academic journals to demonstrate the value o</p><p>4 0.72873169 <a title="935-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>Introduction: Andrew Eppig writes:
  
I’m a physicist by training who is transitioning to the social sciences. I recently came across a  reference  in the Economist to a paper on IQ and parasites which I read as I have more than a passing interest in IQ research (having read much that you and others (e.g., Shalizi, Wicherts) have written). In this paper I note that the authors find a very high correlation between national IQ and parasite prevalence. The strength of the correlation (-0.76 to -0.82) surprised me, as I’m used to much weaker correlations in the social sciences. To me, it’s a bit too high, suggesting that there are other factors at play or that one of the variables is merely a proxy for a large number of other variables. But I have no basis for this other than a gut feeling and a memory of a plot on  Language Log  about the distribution of correlation coefficients in social psychology.


So my question is this: Is a correlation in the range of (-0.82,-0.76) more likely to be a correlatio</p><p>5 0.72474229 <a title="935-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-28-Simplify_until_your_fake-data_check_works%2C_then_add_complications_until_you_can_figure_out_where_the_problem_is_coming_from.html">1875 andrew gelman stats-2013-05-28-Simplify until your fake-data check works, then add complications until you can figure out where the problem is coming from</a></p>
<p>Introduction: I received the following email: 
  
  
I am trying to develop a Bayesian model to represent the process through which individual consumers make online product rating decisions. In my model each individual faces total J product options and for each product option (j) each individual (i) needs to make three sequential decisions: 


- First he decides whether to consume a specific product option (j) or not (choice decision)


- If he decides to consume a product option j, then after consumption he decides whether to rate it or not (incidence decision) 


- If he decides to rate product j then what finally he decides what rating (k) to assign to it (evaluation decision)


We  model this decision sequence in terms of three equations. A binary response variable in the first equation represents the choice decision. Another binary response variable in the second equation represents the incidence decision that is observable only when first selection decision is 1. Finally, an ordered response v</p><p>6 0.71619314 <a title="935-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-27-Overfitting.html">1431 andrew gelman stats-2012-07-27-Overfitting</a></p>
<p>7 0.71482784 <a title="935-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-Hypothesis_testing_with_multiple_imputations.html">799 andrew gelman stats-2011-07-13-Hypothesis testing with multiple imputations</a></p>
<p>8 0.71311474 <a title="935-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>9 0.70958257 <a title="935-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-12-GLM_%E2%80%93_exposure.html">271 andrew gelman stats-2010-09-12-GLM – exposure</a></p>
<p>10 0.70562238 <a title="935-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-18-Check_your_missing-data_imputations_using_cross-validation.html">1218 andrew gelman stats-2012-03-18-Check your missing-data imputations using cross-validation</a></p>
<p>11 0.70487505 <a title="935-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-19-Cross-validation_to_check_missing-data_imputation.html">1330 andrew gelman stats-2012-05-19-Cross-validation to check missing-data imputation</a></p>
<p>12 0.69945323 <a title="935-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<p>13 0.69859332 <a title="935-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-13-Checking_your_model_using_fake_data.html">852 andrew gelman stats-2011-08-13-Checking your model using fake data</a></p>
<p>14 0.69526964 <a title="935-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-24-Multilevel_modeling_and_instrumental_variables.html">1468 andrew gelman stats-2012-08-24-Multilevel modeling and instrumental variables</a></p>
<p>15 0.682459 <a title="935-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-09-Using_ranks_as_numbers.html">136 andrew gelman stats-2010-07-09-Using ranks as numbers</a></p>
<p>16 0.68075699 <a title="935-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>17 0.68036115 <a title="935-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-18-Lack_of_complete_overlap.html">1017 andrew gelman stats-2011-11-18-Lack of complete overlap</a></p>
<p>18 0.67579961 <a title="935-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-Displaying_a_fitted_multilevel_model.html">328 andrew gelman stats-2010-10-08-Displaying a fitted multilevel model</a></p>
<p>19 0.67390192 <a title="935-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Including_interactions_or_not.html">823 andrew gelman stats-2011-07-26-Including interactions or not</a></p>
<p>20 0.67299974 <a title="935-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.047), (16, 0.196), (21, 0.018), (24, 0.069), (29, 0.038), (34, 0.048), (39, 0.053), (41, 0.03), (77, 0.024), (82, 0.019), (83, 0.013), (86, 0.021), (95, 0.037), (99, 0.276)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95697284 <a title="935-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-06-How_to_think_about_papers_published_in_low-grade_journals%3F.html">1928 andrew gelman stats-2013-07-06-How to think about papers published in low-grade journals?</a></p>
<p>Introduction: We’ve had lots of lively discussions of fatally-flawed papers that have been published in top, top journals such as the  American Economic Review  or the  Journal of Personality and Social Psychology  or the  American Sociological Review  or the  tabloids .  And we also know about mistakes that make their way into mid-ranking outlets such as the Journal of Theoretical Biology.
 
But what about results that appear in the lower tier of legitimate journals?  I was thinking about this after reading a  post  by Dan Kahan slamming a paper that recently appeared in PLOS-One.  I won’t discuss the paper itself here because that’s not my point.  Rather, I had some thoughts regarding Kahan’s annoyance that a paper with fatal errors was published at all.  I commented as follows:
  
Read between the lines. The paper originally was released in 2009 and was published in 2013 in PLOS-One, which is one step above appearing on Arxiv. PLOS-One publishes some good things (so does Arxiv) but it’s the place</p><p>2 0.9535979 <a title="935-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Racism%21.html">321 andrew gelman stats-2010-10-05-Racism!</a></p>
<p>Introduction: Last night I spoke at the Columbia Club of New York, along with some of my political science colleagues, in a  panel  about politics, the economy, and the forthcoming election.  The discussion was fine . . . until one guy in the audience accused us of bias based on what he imputed as our ethnicity.  One of the panelists replied by asking the questioner what of all the things we had said was biased, and the questioner couldn’t actually supply any examples.
 
It makes sense that the questioner couldn’t come up with a single example of bias on our part, considering that we were actually presenting  facts .
 
At some level, the questioner’s imputation of our ethnicity and accusation of bias isn’t so horrible.  When talking with my friends, I engage in casual ethnic stereotyping all the time–hey, it’s a free country!–and one can certainly make the  statistical  argument that you can guess people’s ethnicities from their names, appearance, and speech patterns, and in turn you can infer a lot</p><p>3 0.95103216 <a title="935-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-08-Different_attitudes_about_parenting%2C_possibly_deriving_from_different_attitudes_about_self.html">564 andrew gelman stats-2011-02-08-Different attitudes about parenting, possibly deriving from different attitudes about self</a></p>
<p>Introduction: Tyler Cowen  discusses  his and Bryan Caplan’s reaction to that notorious book by Amy Chua, the Yale law professor who boasts of screaming at her children, calling them “garbage,” not letting them go to the bathroom when they were studying piano, etc.  Caplan thinks Chua is deluded (in the sense of not being aware of research showing minimal effects of parenting on children’s intelligence and personality), foolish (in writing a book and making recommendations without trying to lean about the abundant research on child-rearing), and cruel.  Cowen takes a middle view in that he doesn’t subscribe to Chua’s parenting strategies but he does think that his friends’ kids will do well (and partly because of his friends’ parenting styles, not just from their genes).
 
 Do you view yourself as special? 
 
I have a somewhat different take on the matter, an idea that’s been stewing in my mind for awhile, ever since I  heard about  the Wall Street Journal article that started this all.  My story is</p><p>4 0.94933295 <a title="935-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-13-Coauthorship_norms.html">609 andrew gelman stats-2011-03-13-Coauthorship norms</a></p>
<p>Introduction: I followed  this link  from Chris Blattman to  an article  by economist Roland Fryer, who writes:
  
I [Fryer] find no evidence that teacher incentives increase student performance, attendance, or graduation, nor do I find any evidence that the incentives change student or teacher behavior.
  
What struck me were not the findings (which, as Fryer notes in his article, are plausible enough) but the use of the word “I” rather than “we.”  A field experiment is a big deal, and I was surprised to read that Fryer did it all by himself!
 
Here’s the note of acknowledgments (on the first page of the article):
  
This project would not have been possible without the leadership and support of Joel Klein. I am also grateful to Jennifer Bell-Ellwanger, Joanna Cannon, and Dominique West for their cooperation in collecting the data necessary for this project, and to my colleagues Edward Glaeser, Richard Holden, and Lawrence Katz for helpful comments and discussions. Vilsa E. Curto, Meghan L. Howard,</p><p>5 0.94908035 <a title="935-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>Introduction: Joshua Vogelstein asks for my thoughts as  a Bayesian on the above topic.  So here they are (briefly):
 
The concept of the bias-variance tradeoff can be useful if you don’t take it too seriously.  The basic idea is as follows:  if you’re estimating something, you can slice your data finer and finer, or perform more and more adjustments, each time getting a purer—and less biased—estimate.  But each subdivision or each adjustment reduces your sample size or increases potential estimation error, hence the variance of your estimate goes up.
 
That story is real.  In lots and lots of examples, there’s a continuum between a completely unadjusted general estimate (high bias, low variance) and a specific, focused, adjusted estimate (low bias, high variance).
 
Suppose, for example, you’re using data from a large experiment to estimate the effect of a treatment on a fairly narrow group, say, white men between the ages of 45 and 50.  At one extreme, you could just take the estimated treatment e</p><p>6 0.9488548 <a title="935-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-23-Popular_governor%2C_small_state.html">159 andrew gelman stats-2010-07-23-Popular governor, small state</a></p>
<p>7 0.94869328 <a title="935-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-21-Progress_for_the_Poor.html">1022 andrew gelman stats-2011-11-21-Progress for the Poor</a></p>
<p>8 0.94804871 <a title="935-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>same-blog 9 0.94529819 <a title="935-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-01-When_should_you_worry_about_imputed_data%3F.html">935 andrew gelman stats-2011-10-01-When should you worry about imputed data?</a></p>
<p>10 0.9445278 <a title="935-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-06-Bayesian_model-building_by_pure_thought%3A__Some_principles_and_examples.html">1156 andrew gelman stats-2012-02-06-Bayesian model-building by pure thought:  Some principles and examples</a></p>
<p>11 0.94403696 <a title="935-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-13-Win_%245000_in_the_Economist%E2%80%99s_data_visualization_competition.html">1495 andrew gelman stats-2012-09-13-Win $5000 in the Economist’s data visualization competition</a></p>
<p>12 0.9416576 <a title="935-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-06-Suspicious_pattern_of_too-strong_replications_of_medical_research.html">700 andrew gelman stats-2011-05-06-Suspicious pattern of too-strong replications of medical research</a></p>
<p>13 0.93876314 <a title="935-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-13-Ethical_concerns_in_medical_trials.html">411 andrew gelman stats-2010-11-13-Ethical concerns in medical trials</a></p>
<p>14 0.9379369 <a title="935-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-28-The_incoming_moderate_Republican_congressmembers.html">377 andrew gelman stats-2010-10-28-The incoming moderate Republican congressmembers</a></p>
<p>15 0.93696594 <a title="935-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-24-Always_check_your_evidence.html">1025 andrew gelman stats-2011-11-24-Always check your evidence</a></p>
<p>16 0.93672788 <a title="935-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-30-A_graphics_talk_with_no_visuals%21.html">1598 andrew gelman stats-2012-11-30-A graphics talk with no visuals!</a></p>
<p>17 0.93335468 <a title="935-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-20-Why_no_Wegmania%3F.html">722 andrew gelman stats-2011-05-20-Why no Wegmania?</a></p>
<p>18 0.93216509 <a title="935-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-19-Cross-validation_to_check_missing-data_imputation.html">1330 andrew gelman stats-2012-05-19-Cross-validation to check missing-data imputation</a></p>
<p>19 0.92948627 <a title="935-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-02-Reintegrating_rebels_into_civilian_life%3A_Quasi-experimental_evidence_from_Burundi.html">177 andrew gelman stats-2010-08-02-Reintegrating rebels into civilian life: Quasi-experimental evidence from Burundi</a></p>
<p>20 0.92878592 <a title="935-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-01-Do_you_own_anything_that_was_manufactured_in_the_1950s_and_still_is_in_regular%2C_active_use_in_your_life%3F.html">387 andrew gelman stats-2010-11-01-Do you own anything that was manufactured in the 1950s and still is in regular, active use in your life?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
