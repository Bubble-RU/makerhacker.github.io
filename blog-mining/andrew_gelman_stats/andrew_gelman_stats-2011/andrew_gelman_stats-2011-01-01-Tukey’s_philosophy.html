<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>496 andrew gelman stats-2011-01-01-Tukey’s philosophy</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-496" href="#">andrew_gelman_stats-2011-496</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>496 andrew gelman stats-2011-01-01-Tukey’s philosophy</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-496-html" href="http://andrewgelman.com/2011/01/01/tukeys_philosop/">html</a></p><p>Introduction: The great statistician John Tukey, in his writings from the 1970s onward (and maybe earlier) was time and again making the implicit argument that you should evaluate a statistical method based on what it does; you should {\em not} be staring at the model that purportedly underlies the method, trying to determine if the model is “true” (or “true enough”).  Tukey’s point was that models can be great to inspire methods, but the model is the scaffolding; it is the method that is the building you have to live in.
 
I don’t fully agree with this philosophy–I think models are a good way to understand data and also often connect usefully to scientific models (although not as cleanly as is thought by our friends who work in economics or statistical hypothesis testing).
 
To put it another way:  What makes a building good?  A building is good if it is useful. If a building is useful, people will use it.  Eventually improvements will be needed, partly because the building will get worn down, part</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Tukey’s point was that models can be great to inspire methods, but the model is the scaffolding; it is the method that is the building you have to live in. [sent-2, score-1.068]
</p><p>2 I don’t fully agree with this philosophy–I think models are a good way to understand data and also often connect usefully to scientific models (although not as cleanly as is thought by our friends who work in economics or statistical hypothesis testing). [sent-3, score-0.649]
</p><p>3 To put it another way:  What makes a building good? [sent-4, score-0.299]
</p><p>4 Eventually improvements will be needed, partly because the building will get worn down, partly because the interactions between the many users will inspire new, unforeseen uses, partly for the simple reason that if a building is popular, more space will be desired. [sent-7, score-1.868]
</p><p>5 And, at that point, wouldn’t it be great if some scaffolding were already around? [sent-9, score-0.495]
</p><p>6 if we now switch the analogy back from buildings to statistical methods, that scaffolding is the model that was used in constructing the method in the first place. [sent-13, score-1.098]
</p><p>7 In fact, it is the most useful, wonderful statistical methods that get the most use and need improvements most frequently. [sent-15, score-0.461]
</p><p>8 So I like the model and I don’t see the virtue in hiding it and letting the method stand alone. [sent-16, score-0.587]
</p><p>9 The model is the basis for future improvements in many directions. [sent-17, score-0.392]
</p><p>10 And this is one reason why I think that one of the most exciting areas in statistical research is the systematization of model building. [sent-18, score-0.378]
</p><p>11 But, even though I don’t agree with the implicit philosophy of late Tukey (I don’t agree with the philosophy of early Tukey either, with all that multiple comparisons stuff), I think (of course) that he made hugely important contributions. [sent-20, score-0.794]
</p><p>12 So I’d like to have this philosophy out there for statisticians and users to evaluate on their own. [sent-21, score-0.435]
</p><p>13 I have not ever seen Tukey’s ideas expressed in this way before (and they’re just my own imputation; I only met Tukey once, many years ago, and we spoke for about 30 seconds), so I’m posting them here, on the first day of this new decade. [sent-22, score-0.234]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tukey', 0.417), ('scaffolding', 0.408), ('building', 0.299), ('method', 0.223), ('philosophy', 0.216), ('improvements', 0.195), ('partly', 0.163), ('inspire', 0.16), ('model', 0.141), ('statistical', 0.118), ('users', 0.11), ('implicit', 0.109), ('evaluate', 0.109), ('models', 0.102), ('worn', 0.102), ('unforeseen', 0.096), ('cleanly', 0.096), ('onward', 0.096), ('underlies', 0.096), ('purportedly', 0.092), ('agree', 0.09), ('hiding', 0.089), ('methods', 0.089), ('great', 0.087), ('staring', 0.086), ('usefully', 0.079), ('em', 0.075), ('buildings', 0.074), ('hugely', 0.073), ('seconds', 0.072), ('constructing', 0.07), ('virtue', 0.067), ('letting', 0.067), ('spoke', 0.066), ('writings', 0.066), ('useful', 0.065), ('imputation', 0.064), ('switch', 0.064), ('true', 0.063), ('reason', 0.062), ('connect', 0.062), ('decade', 0.061), ('wonderful', 0.059), ('network', 0.058), ('exciting', 0.057), ('met', 0.056), ('expressed', 0.056), ('many', 0.056), ('point', 0.056), ('eventually', 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="496-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-01-Tukey%E2%80%99s_philosophy.html">496 andrew gelman stats-2011-01-01-Tukey’s philosophy</a></p>
<p>Introduction: The great statistician John Tukey, in his writings from the 1970s onward (and maybe earlier) was time and again making the implicit argument that you should evaluate a statistical method based on what it does; you should {\em not} be staring at the model that purportedly underlies the method, trying to determine if the model is “true” (or “true enough”).  Tukey’s point was that models can be great to inspire methods, but the model is the scaffolding; it is the method that is the building you have to live in.
 
I don’t fully agree with this philosophy–I think models are a good way to understand data and also often connect usefully to scientific models (although not as cleanly as is thought by our friends who work in economics or statistical hypothesis testing).
 
To put it another way:  What makes a building good?  A building is good if it is useful. If a building is useful, people will use it.  Eventually improvements will be needed, partly because the building will get worn down, part</p><p>2 0.21459849 <a title="496-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-30-Works_well_versus_well_understood.html">738 andrew gelman stats-2011-05-30-Works well versus well understood</a></p>
<p>Introduction: John Cook  discusses  the John Tukey quote, “The test of a good procedure is how well it works, not how well it is understood.”  Cook writes:
  
At some level, it’s hard to argue against this. Statistical procedures operate on empirical data, so it makes sense that the procedures themselves be evaluated empirically.


But I [Cook] question whether we really know that a statistical procedure works well if it isn’t well understood. Specifically, I’m skeptical of complex statistical methods whose only credentials are a handful of simulations. “We don’t have any theoretical results, buy hey, it works well in practice. Just look at the simulations.”


Every method works well on the scenarios its author publishes, almost by definition. If the method didn’t handle a scenario well, the author would publish a different scenario.
  
I agree with Cook but would give a slightly different emphasis.  I’d say that a lot of methods can work when they are done well.  See the second meta-principle liste</p><p>3 0.189026 <a title="496-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>Introduction: I’ll answer the above question after first sharing some background and history on the the philosophy of Bayesian statistics, which appeared at the end of our  rejoinder  to the discussion to which I  linked  the other day:
  
When we were beginning our statistical educations, the word ‘Bayesian’ conveyed membership in an obscure cult. Statisticians who were outside the charmed circle could ignore the Bayesian subfield, while Bayesians themselves tended to be either apologetic or brazenly defiant. These two extremes manifested themselves in ever more elaborate proposals for non-informative priors, on the one hand, and declarations of the purity of subjective probability, on the other.


Much has changed in the past 30 years. ‘Bayesian’ is now often used in casual scientific parlance as a synonym for ‘rational’, the anti-Bayesians have mostly disappeared, and non-Bayesian statisticians feel the need to keep up with developments in Bayesian modelling and computation. Bayesians themselves</p><p>4 0.1639234 <a title="496-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>Introduction: In response to  my remarks  on his online book, Think Bayes, Allen Downey wrote: 
   
I [Downey] have a question about one of your comments: 
   My [Gelman's] main criticism with both books is that they talk a lot about inference but not so much about model building or model checking (recall the three steps of Bayesian data analysis). I think it’s ok for an introductory book to focus on inference, which of course is central to the data-analytic process—but I’d like them to at least mention that Bayesian ideas arise in model building and model checking as well. 

This sounds like something I agree with, and one of the things I tried to do in the book is to put modeling decisions front and center.  But the word “modeling” is used in lots of ways, so I want to see if we are talking about the same thing.


For example, in many chapters, I start with a simple model of the scenario, do some analysis, then check whether the model is good enough, and iterate.  Here’s the discussion of modeling</p><p>5 0.13750124 <a title="496-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-08-Bayes-Godel.html">998 andrew gelman stats-2011-11-08-Bayes-Godel</a></p>
<p>Introduction: Sean O’Riordain writes:
  
Your article, “ The holes in my philosophy of Bayesian data analysis ” caused me to wonder whether it was possible to have a consistent philosophy of data analysis and whether it could it be possible that Godel’s incompleteness theorem extends as far as to say that it wasn’t possible?
  
I don’t know but my guess is that this is all related to our lack of a good model for hypothesis generation.  Statistics focuses on deductive inference within models and model checking to evaluate models, but we don’t have a good handle on the creation of models.  (I’m hoping that some of our network-of-models stuff will be helpful.)</p><p>6 0.13330269 <a title="496-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-03-%E2%80%9CThe_Case_for_Inductive_Theory_Building%E2%80%9D.html">1652 andrew gelman stats-2013-01-03-“The Case for Inductive Theory Building”</a></p>
<p>7 0.13087843 <a title="496-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>8 0.12890704 <a title="496-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<p>9 0.12796341 <a title="496-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>10 0.12604368 <a title="496-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>11 0.12520686 <a title="496-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>12 0.12496097 <a title="496-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>13 0.11722276 <a title="496-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-27-Should_statistics_have_a_Nobel_prize%3F.html">2151 andrew gelman stats-2013-12-27-Should statistics have a Nobel prize?</a></p>
<p>14 0.11719186 <a title="496-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>15 0.11475419 <a title="496-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>16 0.11337197 <a title="496-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>17 0.11126947 <a title="496-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-25-Classics_of_statistics.html">109 andrew gelman stats-2010-06-25-Classics of statistics</a></p>
<p>18 0.10941494 <a title="496-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>19 0.10871744 <a title="496-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>20 0.10862201 <a title="496-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-12-More_on_publishing_in_journals.html">2245 andrew gelman stats-2014-03-12-More on publishing in journals</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.19), (1, 0.088), (2, -0.075), (3, 0.046), (4, -0.023), (5, 0.003), (6, -0.075), (7, 0.007), (8, 0.085), (9, 0.002), (10, 0.006), (11, -0.001), (12, -0.051), (13, -0.018), (14, -0.049), (15, -0.013), (16, 0.026), (17, -0.023), (18, -0.01), (19, 0.009), (20, -0.007), (21, -0.061), (22, -0.024), (23, 0.009), (24, -0.009), (25, -0.025), (26, -0.022), (27, 0.025), (28, 0.01), (29, -0.021), (30, 0.022), (31, 0.016), (32, 0.06), (33, 0.012), (34, 0.003), (35, 0.016), (36, 0.023), (37, 0.045), (38, -0.011), (39, -0.043), (40, -0.012), (41, 0.013), (42, -0.013), (43, 0.031), (44, 0.06), (45, 0.008), (46, -0.059), (47, -0.056), (48, -0.009), (49, 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9736172 <a title="496-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-01-Tukey%E2%80%99s_philosophy.html">496 andrew gelman stats-2011-01-01-Tukey’s philosophy</a></p>
<p>Introduction: The great statistician John Tukey, in his writings from the 1970s onward (and maybe earlier) was time and again making the implicit argument that you should evaluate a statistical method based on what it does; you should {\em not} be staring at the model that purportedly underlies the method, trying to determine if the model is “true” (or “true enough”).  Tukey’s point was that models can be great to inspire methods, but the model is the scaffolding; it is the method that is the building you have to live in.
 
I don’t fully agree with this philosophy–I think models are a good way to understand data and also often connect usefully to scientific models (although not as cleanly as is thought by our friends who work in economics or statistical hypothesis testing).
 
To put it another way:  What makes a building good?  A building is good if it is useful. If a building is useful, people will use it.  Eventually improvements will be needed, partly because the building will get worn down, part</p><p>2 0.83141142 <a title="496-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>Introduction: David Duvenaud writes:
  
I’ve been following  your recent discussions  about how an AI could do statistics [see also  here ].  I was especially excited about your suggestion for new statistical methods using “a language-like approach to recursively creating new models from a specified list of distributions and transformations, and an automatic approach to checking model fit.”


Your discussion of these ideas was exciting to me and my colleagues because we recently  did some work  taking a step in this direction, automatically searching through a grammar over Gaussian process regression models.


Roger Grosse previously  did the same thing , but over matrix decomposition models using held-out predictive likelihood to check model fit.


These are both examples of automatic Bayesian model-building by a search over more and more complex models, as you suggested.  One nice thing is that both grammars include lots of standard models for free, and they seem to work pretty well, although the</p><p>3 0.8201021 <a title="496-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>Introduction: Last month I  wrote :
  
Computer scientists are often brilliant but they can be unfamiliar with what is done in the worlds of data collection and analysis. This goes the other way too: statisticians such as myself can look pretty awkward, reinventing (or failing to reinvent) various wheels when we write computer programs or, even worse, try to design software.Andrew MacNamara writes:
  
Andrew MacNamara followed up with some thoughts:
  
I [MacNamara] had some basic statistics training through my MBA program, after having completed an undergrad degree in computer science. Since then I’ve been very interested in learning more about statistical techniques, including things like GLM and censored data analyses as well as machine learning topics like neural nets, SVMs, etc. I began following your blog after some research into Bayesian analysis topics and I am trying to dig deeper on that side of things.


One thing I have noticed is that there seems to be a distinction between data analysi</p><p>4 0.80571556 <a title="496-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>Introduction: Jonathan Livengood writes:
  
I have a couple of questions on your paper with Cosma Shalizi on “Philosophy and the practice of Bayesian statistics.”


First, you distinguish between inductive approaches and hypothetico-deductive approaches to inference and locate statistical practice (at least, the practice of model building and checking) on the hypothetico-deductive side.  Do you think that there are any interesting elements of statistical practice that are properly inductive?  For example, suppose someone is playing around with a system that more or less resembles a toy model, like drawing balls from an urn or some such, and where the person has some well-defined priors.  The person makes a number of draws from the urn and applies Bayes theorem to get a posterior.  On your view, is that person making an induction?  If so, how much space is there in statistical practice for genuine inductions like this?


Second, I agree with you that one ought to distinguish induction from other kind</p><p>5 0.80333072 <a title="496-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>Introduction: David Rohde writes:
  
 
I have been thinking a lot lately about your Bayesian model checking approach.  This is in part because I have been working on exploratory data analysis and wishing to avoid controversy and mathematical statistics we omitted model checking from our discussion.  This is something that the refereeing process picked us up on and we ultimately added a critical discussion of null-hypothesis testing to  our paper .  The exploratory technique we discussed was essentially a 2D histogram approach, but we used Polya models as a formal model for the histogram.  We are currently working on a new paper, and we are thinking through how or if we should do “confirmatory analysis” or model checking in the paper.


What I find most admirable about your statistical work is that you clearly use the Bayesian approach to do useful applied statistical analysis.  My own attempts at applied Bayesian analysis makes me greatly admire your applied successes.  On the other hand it may be t</p><p>6 0.79671025 <a title="496-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>7 0.79591179 <a title="496-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>8 0.78983182 <a title="496-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-23-When_are_complicated_models_helpful_in_psychology_research_and_when_are_they_overkill%3F.html">1690 andrew gelman stats-2013-01-23-When are complicated models helpful in psychology research and when are they overkill?</a></p>
<p>9 0.77992904 <a title="496-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Valencia%3A___Summer_of_1991.html">72 andrew gelman stats-2010-06-07-Valencia:   Summer of 1991</a></p>
<p>10 0.76915318 <a title="496-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-19-Just_chaid.html">421 andrew gelman stats-2010-11-19-Just chaid</a></p>
<p>11 0.7627086 <a title="496-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-19-An_interweaving-transformation_strategy_for_boosting_MCMC_efficiency.html">964 andrew gelman stats-2011-10-19-An interweaving-transformation strategy for boosting MCMC efficiency</a></p>
<p>12 0.75711119 <a title="496-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-02-A_important_new_survey_of_Bayesian_predictive_methods_for_model_assessment%2C_selection_and_comparison.html">1648 andrew gelman stats-2013-01-02-A important new survey of Bayesian predictive methods for model assessment, selection and comparison</a></p>
<p>13 0.75400108 <a title="496-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-03-Statistical_methods_for_healthcare_regulation%3A_rating%2C_screening_and_surveillance.html">744 andrew gelman stats-2011-06-03-Statistical methods for healthcare regulation: rating, screening and surveillance</a></p>
<p>14 0.74604177 <a title="496-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-14-GPstuff%3A_Bayesian_Modeling_with_Gaussian_Processes.html">1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</a></p>
<p>15 0.74538594 <a title="496-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Popper_and_Jaynes.html">2007 andrew gelman stats-2013-09-03-Popper and Jaynes</a></p>
<p>16 0.74514383 <a title="496-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>17 0.7435618 <a title="496-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-17-Where_do_theories_come_from%3F.html">1861 andrew gelman stats-2013-05-17-Where do theories come from?</a></p>
<p>18 0.73853409 <a title="496-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-30-Works_well_versus_well_understood.html">738 andrew gelman stats-2011-05-30-Works well versus well understood</a></p>
<p>19 0.73727781 <a title="496-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>20 0.73704469 <a title="496-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.019), (16, 0.134), (21, 0.018), (24, 0.092), (30, 0.061), (42, 0.014), (45, 0.019), (54, 0.011), (73, 0.14), (76, 0.019), (86, 0.032), (99, 0.315)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.967632 <a title="496-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-09-The_quest_for_the_holy_graph.html">794 andrew gelman stats-2011-07-09-The quest for the holy graph</a></p>
<p>Introduction: Eytan Adar writes:
  
I was just going through the latest draft of  your paper with Anthony Unwin . I heard part of it at  the talk  you gave (remotely) here at UMich.  I’m curious about your discussion of the  Baby Name Voyager .


The tool in itself is simple, attractive, and useful.  No argument from me there.  It’s an awesome demonstration of how subtle interactions can be very helpful (click and it zooms, type and it filters… falls perfectly into the Shneiderman visualization mantra). It satisfies a very common use case: finding appropriate names for children.


That said, I can’t help but feeling that what you are really excited about is  the very static analysis on last letters  (you spend most of your time on this).  This analysis, incidentally, is not possible to infer from the interactive application (which doesn’t support this type of filtering and pivoting).  In a sense, the two visualizations don’t have anything to do with each other (other than a shared context/dataset).</p><p>2 0.96253878 <a title="496-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-24-Differences_in_color_perception_by_sex%2C_also_the_Bechdel_test_for_women_in_movies.html">161 andrew gelman stats-2010-07-24-Differences in color perception by sex, also the Bechdel test for women in movies</a></p>
<p>Introduction: Here’s a pretty funny example of silly statistics, caught by  Lisa Wade :
 
 A study  published in 2001 . . . asked undergraduate college students their favorite color and presented the results by sex.  Men’s favorites are on the left, women’s on the right:
 
 
 
The authors of the study, Lee Ellis and Christopher Ficek, wrote:
  
We are inclined to suspect the involvement of neurohormonal factors. Studies of rats have found average sex differences in the number of neurons comprising various parts of the visual cortex. Also, gender differences have been found in rat preferences for the amount of sweetness in drinking water. One experiment demonstrated that the sex differences in rat preferences for sweetness was eliminated by depriving males of male-typical testosterone levels in utero. Perhaps, prenatal exposure to testosterone and other sex hormones operates in a similar way to “bias” preferences for certain colors in humans.
  
As Wade points out, that all seems a bit ridiculous giv</p><p>3 0.9555403 <a title="496-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-26-What_do_statistical_p-values_mean_when_the_sample_%3D_the_population%3F.html">1511 andrew gelman stats-2012-09-26-What do statistical p-values mean when the sample = the population?</a></p>
<p>Introduction: Felipe Nunes writes:
  
I have many friends working with data that they claim to be considered as a ‘population’. For example, the universe of bills presented in a Congress, the roll call votes of all deputies in a legislature, a survey with all deputies in a country, the outcomes of an election, or the set of electoral institutions around the world. Because of the nature of these data, we do not know how to interpret the p-value. I have seen many arguments been made, but I have never seen a formal response to the question. So I don’t know what to say. The most common arguments among the community of young researchers in Brazil are: (1) don’t interpret p-value when you have population, but don’t infer anything either; (2) interpret the p-value because of error measurement which is also present, (3) there is no such a thing as a population, so always look at p-values, (4) don’t worry about p-value, interpret the coefficients substantively, and (5) if you are frequentist you interpret p-</p><p>4 0.95457059 <a title="496-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-02-Hipmunk_update.html">497 andrew gelman stats-2011-01-02-Hipmunk update</a></p>
<p>Introduction: Florence from customer support at  Hipmunk  writes:
  
Hipmunk now includes American Airlines in our search results. Please note that users will be taken directly to AA.com to complete the booking/transaction. . . . we are steadily increasing the number of flights that we offer on Hipmunk.
  
As you may recall, Hipmunk is a  really cool flight-finder that didn’t actually work  (as of 16 Sept 2010).  At the time, I was a bit annoyed at the NYT columnist who plugged Hipmunk without actually telling his readers that the site didn’t actually do the job.  (I discovered the problem myself because I couldn’t believe that my flight options to Raleigh-Durham were really so meager, so I checked on Expedia and found a good flight.)
 
I do think Hipmunk’s graphics are beautiful, though, so I’m rooting for them to catch up.
 
P.S.  Apparently they include Amtrak Northeast Corridor trains, so I’ll give them a try, next time I travel.  The regular Amtrak website is about as horrible as you’d expect.</p><p>5 0.94730413 <a title="496-lda-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-09-Hipmunk_worked.html">2238 andrew gelman stats-2014-03-09-Hipmunk worked</a></p>
<p>Introduction: In the past I’ve categorized Hipmunk as  a really cool flight-finder that doesn’t actually work , as  worse than Expedia , and as  graphics without content .
 
So, I thought it would be only fair to tell you that I bought a flight the other day using Hipmunk and it gave me the same flight as Expedia but at a lower cost (by linking to something called CheapOair, which I hope is legit).  So score one for Hipmunk.</p><p>same-blog 6 0.94432437 <a title="496-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-01-Tukey%E2%80%99s_philosophy.html">496 andrew gelman stats-2011-01-01-Tukey’s philosophy</a></p>
<p>7 0.94354129 <a title="496-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-04-%E2%80%9CVersatile%2C_affordable_chicken_has_grown_in_popularity%E2%80%9D.html">1925 andrew gelman stats-2013-07-04-“Versatile, affordable chicken has grown in popularity”</a></p>
<p>8 0.94175953 <a title="496-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-10-%E2%80%9CVersatile%2C_affordable_chicken_has_grown_in_popularity%E2%80%9D.html">655 andrew gelman stats-2011-04-10-“Versatile, affordable chicken has grown in popularity”</a></p>
<p>9 0.93926245 <a title="496-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-27-Should_Mister_P_be_allowed-encouraged_to_reside_in_counter-factual_populations%3F.html">7 andrew gelman stats-2010-04-27-Should Mister P be allowed-encouraged to reside in counter-factual populations?</a></p>
<p>10 0.93526435 <a title="496-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-04-PyStan%21.html">1748 andrew gelman stats-2013-03-04-PyStan!</a></p>
<p>11 0.93331116 <a title="496-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-12-Samplers_for_Big_Science%3A__emcee_and_BAT.html">2020 andrew gelman stats-2013-09-12-Samplers for Big Science:  emcee and BAT</a></p>
<p>12 0.92071927 <a title="496-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-12-Sometimes_a_graph_really_is_just_ugly.html">798 andrew gelman stats-2011-07-12-Sometimes a graph really is just ugly</a></p>
<p>13 0.91374999 <a title="496-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-28-Explaining_that_plot..html">631 andrew gelman stats-2011-03-28-Explaining that plot.</a></p>
<p>14 0.91349459 <a title="496-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-20-Why_no_Wegmania%3F.html">722 andrew gelman stats-2011-05-20-Why no Wegmania?</a></p>
<p>15 0.91284966 <a title="496-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-16-Meet_Hipmunk%2C_a_really_cool_flight-finder_that_doesn%E2%80%99t_actually_work.html">280 andrew gelman stats-2010-09-16-Meet Hipmunk, a really cool flight-finder that doesn’t actually work</a></p>
<p>16 0.91217482 <a title="496-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>17 0.91021287 <a title="496-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-03-As_the_boldest_experiment_in_journalism_history%2C_you_admit_you_made_a_mistake.html">2280 andrew gelman stats-2014-04-03-As the boldest experiment in journalism history, you admit you made a mistake</a></p>
<p>18 0.90762347 <a title="496-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-07-Like_Casper_the_ghost%2C_Niall_Ferguson_is_not_only_white.__He_is_also_very%2C_very_adorable..html">1846 andrew gelman stats-2013-05-07-Like Casper the ghost, Niall Ferguson is not only white.  He is also very, very adorable.</a></p>
<p>19 0.90755951 <a title="496-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-20-My_beef_with_Brooks%3A__the_alternative_to_%E2%80%9Cgood_statistics%E2%80%9D_is_not_%E2%80%9Cno_statistics%2C%E2%80%9D_it%E2%80%99s_%E2%80%9Cbad_statistics%E2%80%9D.html">1729 andrew gelman stats-2013-02-20-My beef with Brooks:  the alternative to “good statistics” is not “no statistics,” it’s “bad statistics”</a></p>
<p>20 0.90684468 <a title="496-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-18-Predictive_checks_for_hierarchical_models.html">154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
