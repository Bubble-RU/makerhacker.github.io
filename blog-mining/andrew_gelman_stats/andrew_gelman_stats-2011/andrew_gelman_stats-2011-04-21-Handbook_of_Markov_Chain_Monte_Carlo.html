<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>674 andrew gelman stats-2011-04-21-Handbook of Markov Chain Monte Carlo</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-674" href="#">andrew_gelman_stats-2011-674</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>674 andrew gelman stats-2011-04-21-Handbook of Markov Chain Monte Carlo</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-674-html" href="http://andrewgelman.com/2011/04/21/handbook_of_mar/">html</a></p><p>Introduction: Galin Jones, Steve Brooks, Xiao-Li Meng and I edited a handbook of Markov Chain Monte Carlo that has  just been published .  My chapter (with Kenny Shirley) is  here , and it begins like this:
  
Convergence of Markov chain simulations can be monitored by measuring the diffusion and mixing of multiple independently-simulated chains, but different levels of convergence are appropriate for different goals. When considering inference from stochastic simulation, we need to separate two tasks: (1) inference about parameters and functions of parameters based on broad characteristics of their distribution, and (2) more precise computation of expectations and other functions of probability distributions. For the first task, there is a natural limit to precision beyond which additional simulations add essentially nothing; for the second task, the appropriate precision must be decided from external considerations. We illustrate with an example from our current research, a hierarchical model of t</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Galin Jones, Steve Brooks, Xiao-Li Meng and I edited a handbook of Markov Chain Monte Carlo that has  just been published . [sent-1, score-0.263]
</p><p>2 My chapter (with Kenny Shirley) is  here , and it begins like this:    Convergence of Markov chain simulations can be monitored by measuring the diffusion and mixing of multiple independently-simulated chains, but different levels of convergence are appropriate for different goals. [sent-2, score-1.539]
</p><p>3 When considering inference from stochastic simulation, we need to separate two tasks: (1) inference about parameters and functions of parameters based on broad characteristics of their distribution, and (2) more precise computation of expectations and other functions of probability distributions. [sent-3, score-1.74]
</p><p>4 For the first task, there is a natural limit to precision beyond which additional simulations add essentially nothing; for the second task, the appropriate precision must be decided from external considerations. [sent-4, score-1.259]
</p><p>5 We illustrate with an example from our current research, a hierarchical model of trends in opinions on the death penalty in U. [sent-5, score-0.521]
</p><p>6 To read all the other chapters, youâ&euro;&trade;ll have to buy the book! [sent-8, score-0.089]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('markov', 0.248), ('convergence', 0.24), ('precision', 0.218), ('task', 0.212), ('chain', 0.211), ('simulations', 0.206), ('functions', 0.198), ('galin', 0.18), ('monitored', 0.162), ('diffusion', 0.156), ('appropriate', 0.15), ('parameters', 0.144), ('handbook', 0.141), ('kenny', 0.141), ('shirley', 0.141), ('jones', 0.141), ('tasks', 0.13), ('meng', 0.127), ('edited', 0.122), ('stochastic', 0.121), ('penalty', 0.121), ('mixing', 0.121), ('chains', 0.118), ('inference', 0.114), ('expectations', 0.113), ('external', 0.112), ('brooks', 0.112), ('carlo', 0.112), ('characteristics', 0.111), ('measuring', 0.108), ('death', 0.106), ('monte', 0.106), ('broad', 0.104), ('chapters', 0.104), ('limit', 0.103), ('simulation', 0.102), ('illustrate', 0.102), ('computation', 0.102), ('steve', 0.102), ('precise', 0.101), ('begins', 0.099), ('trends', 0.096), ('opinions', 0.096), ('considering', 0.089), ('buy', 0.089), ('decided', 0.088), ('separate', 0.087), ('levels', 0.086), ('additional', 0.085), ('essentially', 0.079)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="674-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-21-Handbook_of_Markov_Chain_Monte_Carlo.html">674 andrew gelman stats-2011-04-21-Handbook of Markov Chain Monte Carlo</a></p>
<p>Introduction: Galin Jones, Steve Brooks, Xiao-Li Meng and I edited a handbook of Markov Chain Monte Carlo that has  just been published .  My chapter (with Kenny Shirley) is  here , and it begins like this:
  
Convergence of Markov chain simulations can be monitored by measuring the diffusion and mixing of multiple independently-simulated chains, but different levels of convergence are appropriate for different goals. When considering inference from stochastic simulation, we need to separate two tasks: (1) inference about parameters and functions of parameters based on broad characteristics of their distribution, and (2) more precise computation of expectations and other functions of probability distributions. For the first task, there is a natural limit to precision beyond which additional simulations add essentially nothing; for the second task, the appropriate precision must be decided from external considerations. We illustrate with an example from our current research, a hierarchical model of t</p><p>2 0.33230984 <a title="674-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-07-Update_on_the_new_Handbook_of_MCMC.html">844 andrew gelman stats-2011-08-07-Update on the new Handbook of MCMC</a></p>
<p>Introduction: It’s edited by Steve Brooks, Galin Jones, Xiao-Li Meng, and myself.   Here’s  the information and some sample chapters (including my own chapter with Ken Shirley on inference and monitoring convergence and Radford’s instant classic on Hamiltonian Monte Carlo).
 
Sorry about the $100 price tag–nobody asked me about that!  But if you’re doing these computations as part of your work, I think the book will be well worth it.</p><p>3 0.26976004 <a title="674-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-The_first_version_of_my_%E2%80%9Cinference_from_iterative_simulation_using_parallel_sequences%E2%80%9D_paper%21.html">1309 andrew gelman stats-2012-05-09-The first version of my “inference from iterative simulation using parallel sequences” paper!</a></p>
<p>Introduction: From August 1990.  It was in the form of a note sent to all the people in the statistics group of Bell Labs, where I’d worked that summer.
  
To all:


Here’s the abstract of the work I’ve done this summer.  It’s stored in the file, 
/fs5/gelman/abstract.bell, and copies of the Figures 1-3 are on Trevor’s desk. 
Any comments are of course appreciated; I’m at gelman@stat.berkeley.edu.


On the Routine Use of Markov Chains for Simulation


Andrew Gelman and Donald Rubin, 6 August 1990


corrected version:  8 August 1990
  
  
  
1.  Simulation


In probability and statistics we can often specify multivariate distributions 
many of whose properties we do not fully understand–perhaps, as in the 
Ising model of statistical physics, we can write the joint density function, up 
to a multiplicative constant that cannot be expressed in closed form. 
For an example in statistics, consider the Normal random 
effects model in the analysis of variance, which can be 
easily placed in a Bayesian fram</p><p>4 0.13592727 <a title="674-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-17-Death%21.html">962 andrew gelman stats-2011-10-17-Death!</a></p>
<p>Introduction: This graph shows the estimate that Kenny Shirley and I have of support for the death penalty by sex and race in the U.S. since 1955:
 
   
 
We also found that capital punishment used to be more popular in the Northeast than in the South, but now it’s the other way around.
 
Here’s the abstract to  our paper :
  
One of the longest running questions that has been regularly included in Gallup’s national public opinion poll is “Do you favor or oppose the death penalty for persons convicted of murder?” Because the death penalty is governed by state laws rather than federal laws, it is of special interest to know how public opinion varies by state, and how it has changed over time within each state. In this paper we combine dozens of national polls taken over a fifty-year span and fit a Bayesian multilevel logistic regression model to individual response data to estimate changes in state-level public opinion over time. Such a long span of polls has not been analyzed this way before, partly</p><p>5 0.11523924 <a title="674-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-23-Learning_Differential_Geometry_for_Hamiltonian_Monte_Carlo.html">1339 andrew gelman stats-2012-05-23-Learning Differential Geometry for Hamiltonian Monte Carlo</a></p>
<p>Introduction: You can get a taste of Hamiltonian Monte Carlo (HMC) by reading the very gentle introduction in David MacKay’s general text on information theory:
  
  MacKay, D.  2003.    Information Theory, Inference, and Learning Algorithms  .  Cambridge University Press.  [see Chapter 31, which is relatively standalone and can be downloaded separately.]
   
Follow this up with Radford Neal’s much more thorough introduction to HMC:
  
 Neal, R. 2011.   MCMC Using Hamiltonian Dynamics .  In Brooks, Gelman, Jones and Meng, eds.,  Handbook of Markov Chain Monte Carlo .  Chapman and Hall/CRC Press.
   
To understand why HMC works and set yourself on the path to understanding generalizations like  Riemann manifold HMC , you’ll need to know a bit about differential geometry.  I really liked the combination of these two books:
  
  Magnus, J. R. and H. Neudecker.  2007.   Matrix Differential Calculus with Application in Statistics and Econometrics .  3rd Edition.  Wiley?
   
and
  
  Leimkuhler, B. and S.</p><p>6 0.10735993 <a title="674-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-09-A_tale_of_two_discussion_papers.html">1848 andrew gelman stats-2013-05-09-A tale of two discussion papers</a></p>
<p>7 0.10487179 <a title="674-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-12-Stan_1.3.0_and_RStan_1.3.0_Ready_for_Action.html">1799 andrew gelman stats-2013-04-12-Stan 1.3.0 and RStan 1.3.0 Ready for Action</a></p>
<p>8 0.098985955 <a title="674-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-01-David_MacKay_sez_._._._12%3F%3F.html">984 andrew gelman stats-2011-11-01-David MacKay sez . . . 12??</a></p>
<p>9 0.09836106 <a title="674-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-19-The_mysterious_Gamma_%281.4%2C_0.4%29.html">669 andrew gelman stats-2011-04-19-The mysterious Gamma (1.4, 0.4)</a></p>
<p>10 0.097581722 <a title="674-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>11 0.094549499 <a title="674-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-21-Going_viral_%E2%80%94_not%21.html">864 andrew gelman stats-2011-08-21-Going viral — not!</a></p>
<p>12 0.091906525 <a title="674-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-29-Hamiltonian_Monte_Carlo_stories.html">931 andrew gelman stats-2011-09-29-Hamiltonian Monte Carlo stories</a></p>
<p>13 0.091496587 <a title="674-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-30-Stan_Project%3A__Continuous_Relaxations_for_Discrete_MRFs.html">2003 andrew gelman stats-2013-08-30-Stan Project:  Continuous Relaxations for Discrete MRFs</a></p>
<p>14 0.087963134 <a title="674-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Stan_1.2.0_and_RStan_1.2.0.html">1753 andrew gelman stats-2013-03-06-Stan 1.2.0 and RStan 1.2.0</a></p>
<p>15 0.085780293 <a title="674-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<p>16 0.084007278 <a title="674-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Stan_is_fast.html">1476 andrew gelman stats-2012-08-30-Stan is fast</a></p>
<p>17 0.083695091 <a title="674-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-01-Why_Development_Economics_Needs_Theory%3F.html">309 andrew gelman stats-2010-10-01-Why Development Economics Needs Theory?</a></p>
<p>18 0.083222479 <a title="674-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>19 0.083010837 <a title="674-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Correcting_for_multiple_comparisons_in_a_Bayesian_regression_model.html">1989 andrew gelman stats-2013-08-20-Correcting for multiple comparisons in a Bayesian regression model</a></p>
<p>20 0.078958869 <a title="674-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-20-My_beef_with_Brooks%3A__the_alternative_to_%E2%80%9Cgood_statistics%E2%80%9D_is_not_%E2%80%9Cno_statistics%2C%E2%80%9D_it%E2%80%99s_%E2%80%9Cbad_statistics%E2%80%9D.html">1729 andrew gelman stats-2013-02-20-My beef with Brooks:  the alternative to “good statistics” is not “no statistics,” it’s “bad statistics”</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.114), (1, 0.088), (2, -0.008), (3, 0.028), (4, 0.01), (5, 0.025), (6, 0.012), (7, -0.041), (8, -0.021), (9, -0.004), (10, -0.011), (11, -0.011), (12, -0.065), (13, -0.0), (14, 0.026), (15, -0.014), (16, -0.016), (17, 0.015), (18, 0.031), (19, -0.028), (20, 0.019), (21, 0.011), (22, 0.04), (23, 0.018), (24, 0.06), (25, 0.051), (26, -0.027), (27, 0.049), (28, 0.062), (29, 0.026), (30, -0.055), (31, -0.008), (32, -0.007), (33, 0.019), (34, -0.002), (35, -0.067), (36, -0.01), (37, -0.002), (38, -0.004), (39, 0.02), (40, -0.053), (41, 0.002), (42, -0.024), (43, -0.038), (44, 0.013), (45, -0.028), (46, 0.01), (47, -0.003), (48, 0.043), (49, -0.024)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96324396 <a title="674-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-21-Handbook_of_Markov_Chain_Monte_Carlo.html">674 andrew gelman stats-2011-04-21-Handbook of Markov Chain Monte Carlo</a></p>
<p>Introduction: Galin Jones, Steve Brooks, Xiao-Li Meng and I edited a handbook of Markov Chain Monte Carlo that has  just been published .  My chapter (with Kenny Shirley) is  here , and it begins like this:
  
Convergence of Markov chain simulations can be monitored by measuring the diffusion and mixing of multiple independently-simulated chains, but different levels of convergence are appropriate for different goals. When considering inference from stochastic simulation, we need to separate two tasks: (1) inference about parameters and functions of parameters based on broad characteristics of their distribution, and (2) more precise computation of expectations and other functions of probability distributions. For the first task, there is a natural limit to precision beyond which additional simulations add essentially nothing; for the second task, the appropriate precision must be decided from external considerations. We illustrate with an example from our current research, a hierarchical model of t</p><p>2 0.8114239 <a title="674-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-29-Hamiltonian_Monte_Carlo_stories.html">931 andrew gelman stats-2011-09-29-Hamiltonian Monte Carlo stories</a></p>
<p>Introduction: Tomas Iesmantas had  asked me  for advice on a regression problem with 50 parameters, and I’d recommended Hamiltonian Monte Carlo.
 
A few weeks later he reported back: 
  
  
After trying several modifications (HMC for all parameters at once, HMC just for first level parameters and Riemman manifold Hamiltonian Monte Carlo method), I finally got it running with HMC just for first level parameters and for others using direct sampling, since conditional distributions turned out to have closed form.


However, even in this case it is quite tricky, since I had to employ mass matrix and not just diagonal but at the beginning of algorithm generated it randomly (ensuring it is positive definite). Such random generation of mass matrix is quite blind step, but it proved to be quite helpful.


Riemman manifold HMC is quite vagarious, or to be more specific, metric of manifold is very sensitive. In my model log-likelihood I had exponents and values of metrics matrix elements was very large and wh</p><p>3 0.7498455 <a title="674-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-04-Handy_Matrix_Cheat_Sheet%2C_with_Gradients.html">555 andrew gelman stats-2011-02-04-Handy Matrix Cheat Sheet, with Gradients</a></p>
<p>Introduction: This post is an (unpaid) advertisement for the following extremely useful resource:
  
 Petersen, K. B. and M. S. Pedersen. 2008.   The Matrix Cookbook  .  Tehcnical Report, Technical University of Denmark. 
  
It contains 70+ pages of useful relations and derivations involving matrices.  What grabbed my eye was the computation of gradients for matrix operations ranging from eigenvalues and determinants to multivariate normal density functions.   I had no idea the multivariate normal had such a clean gradient (see section 8).
  

 
We’ve been playing around with  Hamiltonian (aka Hybrid) Monte Carlo  for sampling from the posterior of hierarchical generalized linear models with lots of interactions.  HMC speeds up Metropolis sampling by using the gradient of the log probability to drive samples in the direction of higher probability density, which is particularly useful for correlated parameters that mix slowly with standard Gibbs sampling.   Matt “III” Hoffman ‘s already got it workin</p><p>4 0.7383408 <a title="674-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-23-Learning_Differential_Geometry_for_Hamiltonian_Monte_Carlo.html">1339 andrew gelman stats-2012-05-23-Learning Differential Geometry for Hamiltonian Monte Carlo</a></p>
<p>Introduction: You can get a taste of Hamiltonian Monte Carlo (HMC) by reading the very gentle introduction in David MacKay’s general text on information theory:
  
  MacKay, D.  2003.    Information Theory, Inference, and Learning Algorithms  .  Cambridge University Press.  [see Chapter 31, which is relatively standalone and can be downloaded separately.]
   
Follow this up with Radford Neal’s much more thorough introduction to HMC:
  
 Neal, R. 2011.   MCMC Using Hamiltonian Dynamics .  In Brooks, Gelman, Jones and Meng, eds.,  Handbook of Markov Chain Monte Carlo .  Chapman and Hall/CRC Press.
   
To understand why HMC works and set yourself on the path to understanding generalizations like  Riemann manifold HMC , you’ll need to know a bit about differential geometry.  I really liked the combination of these two books:
  
  Magnus, J. R. and H. Neudecker.  2007.   Matrix Differential Calculus with Application in Statistics and Econometrics .  3rd Edition.  Wiley?
   
and
  
  Leimkuhler, B. and S.</p><p>5 0.72870129 <a title="674-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-The_first_version_of_my_%E2%80%9Cinference_from_iterative_simulation_using_parallel_sequences%E2%80%9D_paper%21.html">1309 andrew gelman stats-2012-05-09-The first version of my “inference from iterative simulation using parallel sequences” paper!</a></p>
<p>Introduction: From August 1990.  It was in the form of a note sent to all the people in the statistics group of Bell Labs, where I’d worked that summer.
  
To all:


Here’s the abstract of the work I’ve done this summer.  It’s stored in the file, 
/fs5/gelman/abstract.bell, and copies of the Figures 1-3 are on Trevor’s desk. 
Any comments are of course appreciated; I’m at gelman@stat.berkeley.edu.


On the Routine Use of Markov Chains for Simulation


Andrew Gelman and Donald Rubin, 6 August 1990


corrected version:  8 August 1990
  
  
  
1.  Simulation


In probability and statistics we can often specify multivariate distributions 
many of whose properties we do not fully understand–perhaps, as in the 
Ising model of statistical physics, we can write the joint density function, up 
to a multiplicative constant that cannot be expressed in closed form. 
For an example in statistics, consider the Normal random 
effects model in the analysis of variance, which can be 
easily placed in a Bayesian fram</p><p>6 0.71707779 <a title="674-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>7 0.68899012 <a title="674-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>8 0.68550366 <a title="674-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-07-Update_on_the_new_Handbook_of_MCMC.html">844 andrew gelman stats-2011-08-07-Update on the new Handbook of MCMC</a></p>
<p>9 0.65061957 <a title="674-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Visualizing_Distributions_of_Covariance_Matrices.html">1477 andrew gelman stats-2012-08-30-Visualizing Distributions of Covariance Matrices</a></p>
<p>10 0.64075291 <a title="674-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-30-Stan_Project%3A__Continuous_Relaxations_for_Discrete_MRFs.html">2003 andrew gelman stats-2013-08-30-Stan Project:  Continuous Relaxations for Discrete MRFs</a></p>
<p>11 0.63196313 <a title="674-lsi-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-20-Thermodynamic_Monte_Carlo%3A__Michael_Betancourt%E2%80%99s_new_method_for_simulating_from_difficult_distributions_and_evaluating_normalizing_constants.html">2340 andrew gelman stats-2014-05-20-Thermodynamic Monte Carlo:  Michael Betancourt’s new method for simulating from difficult distributions and evaluating normalizing constants</a></p>
<p>12 0.6304673 <a title="674-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-The_most-cited_statistics_papers_ever.html">2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</a></p>
<p>13 0.63040704 <a title="674-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-05-Monitor_the_efficiency_of_your_Markov_chain_sampler_using_expected_squared_jumped_distance%21.html">650 andrew gelman stats-2011-04-05-Monitor the efficiency of your Markov chain sampler using expected squared jumped distance!</a></p>
<p>14 0.62799621 <a title="674-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<p>15 0.62557721 <a title="674-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Stan_1.2.0_and_RStan_1.2.0.html">1753 andrew gelman stats-2013-03-06-Stan 1.2.0 and RStan 1.2.0</a></p>
<p>16 0.61249697 <a title="674-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-01-David_MacKay_sez_._._._12%3F%3F.html">984 andrew gelman stats-2011-11-01-David MacKay sez . . . 12??</a></p>
<p>17 0.60604322 <a title="674-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-21-Random_matrices_in_the_news.html">2258 andrew gelman stats-2014-03-21-Random matrices in the news</a></p>
<p>18 0.60498387 <a title="674-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-22-Deviance%2C_DIC%2C_AIC%2C_cross-validation%2C_etc.html">776 andrew gelman stats-2011-06-22-Deviance, DIC, AIC, cross-validation, etc</a></p>
<p>19 0.60477358 <a title="674-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-06-Bootstrap_averaging%3A_Examples_where_it_works_and_where_it_doesn%E2%80%99t_work.html">2201 andrew gelman stats-2014-02-06-Bootstrap averaging: Examples where it works and where it doesn’t work</a></p>
<p>20 0.60260952 <a title="674-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-11-Convergence_Monitoring_for_Non-Identifiable_and_Non-Parametric_Models.html">1374 andrew gelman stats-2012-06-11-Convergence Monitoring for Non-Identifiable and Non-Parametric Models</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.019), (9, 0.017), (12, 0.012), (13, 0.017), (15, 0.014), (16, 0.127), (21, 0.024), (24, 0.127), (36, 0.039), (37, 0.014), (39, 0.052), (40, 0.043), (44, 0.019), (56, 0.015), (66, 0.124), (84, 0.038), (86, 0.027), (99, 0.178)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93654835 <a title="674-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-21-Handbook_of_Markov_Chain_Monte_Carlo.html">674 andrew gelman stats-2011-04-21-Handbook of Markov Chain Monte Carlo</a></p>
<p>Introduction: Galin Jones, Steve Brooks, Xiao-Li Meng and I edited a handbook of Markov Chain Monte Carlo that has  just been published .  My chapter (with Kenny Shirley) is  here , and it begins like this:
  
Convergence of Markov chain simulations can be monitored by measuring the diffusion and mixing of multiple independently-simulated chains, but different levels of convergence are appropriate for different goals. When considering inference from stochastic simulation, we need to separate two tasks: (1) inference about parameters and functions of parameters based on broad characteristics of their distribution, and (2) more precise computation of expectations and other functions of probability distributions. For the first task, there is a natural limit to precision beyond which additional simulations add essentially nothing; for the second task, the appropriate precision must be decided from external considerations. We illustrate with an example from our current research, a hierarchical model of t</p><p>2 0.898399 <a title="674-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-26-My_talk_at_Berkeley_on_Wednesday.html">680 andrew gelman stats-2011-04-26-My talk at Berkeley on Wednesday</a></p>
<p>Introduction: Something on Applied Bayesian Statistics
 
April 27, 4:10-5 p.m., 1011 Evans Hall
 
I will deliver  one  of the following three talks: 
1.  Of beauty, sex, and power: Statistical challenges in estimating small effects  
2.  Why we (usually) don’t worry about multiple comparisons  
3.  Parameterization and Bayesian modeling  
Whoever shows up on time to the seminar gets to vote, and I’ll give the talk that gets the most votes.</p><p>3 0.89186883 <a title="674-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-02-These_people_totally_don%E2%80%99t_know_what_Chance_magazine_is_all_about.html">1192 andrew gelman stats-2012-03-02-These people totally don’t know what Chance magazine is all about</a></p>
<p>Introduction: I received the following unsolicited email, subject line “Chance Magazine – Comedy Showcase”:
  
Hi Andrew,


Hope you’re doing well.  I’m writing to let you know that we will be putting on an industry showcase at the brand new Laughing Devil Comedy Club (4738 Vernon Blvd. Long Island City) on Thursday, February 9th at 8:00 PM. If you’re unfamiliar, it’s one stop on the 7 train from Grand Central.


Following the showcase, the club will stay open for an industry mingle/happy hour with drink specials and all the business card exchanging you can hope for.


This showcase will feature 9 of our best: Steve Hofstetter’s latest album hit #1 in the world. He’ll be hosting Collin Moulton (Showtime Half Hour Special), Tony Deyo (Aspen Comedy Festival), Tom Simmons (Winner of the SF International Comedy Festival), Marc Ryan (Host of Mudslingers), Mike Trainor (TruTV), Jessi Campbell (CMT), Danny Browning (Bob & Tom), and Joe Zimmerman (Sirius/XM).


I would love for you (and anyone you’d like to</p><p>4 0.88285369 <a title="674-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-01-A_book_with_a_bunch_of_simple_graphs.html">1439 andrew gelman stats-2012-08-01-A book with a bunch of simple graphs</a></p>
<p>Introduction: Howard Friedman sent me a new book, The Measure of a Nation, subtitled How to Regain America’s Competitive Edge and Boost Our Global Standing. Without commenting on the substance of Friedman’s recommendations, I’d like to endorse his strategy of presentation, which is to display graph after graph after graph showing the same message over and over again, which is that the U.S. is outperformed by various other countries (mostly in Europe) on a variety of measures. These aren’t graphs I would ever make—they are scatterplots in which the x-axis conveys no information. But they have the advantage of repetition: once you figure out how to read one of the graphs, you can read the others easily.
 
Here’s an  example  which I found from a quick Google:
 
   
 
I can’t actually figure out what is happening on the x-axis, nor do I understand the “star, middle child, dog” thing. But I like the use of graphics. Lots more fun than bullet points. Seriously.
 
P.S. Just to be clear: I am  not  trying</p><p>5 0.87975299 <a title="674-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-06-Fake_newspaper_headlines.html">188 andrew gelman stats-2010-08-06-Fake newspaper headlines</a></p>
<p>Introduction: I used  this convenient site  to create some images for a talk I’m preparing.  (The competing headlines:  “Beautiful parents have more daughters” vs. “No compelling evidence that beautiful parents are more or less likely to have daughters.”  The latter gets cut off at “No compelling evidence that,” which actually works pretty well to demonstrate the sort of dull headline that would result if newspapers were to publish null results.)</p><p>6 0.87083817 <a title="674-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Trends_in_partisanship_by_state.html">536 andrew gelman stats-2011-01-24-Trends in partisanship by state</a></p>
<p>7 0.8678928 <a title="674-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-09-Typo_in_Ghitza_and_Gelman_MRP_paper.html">2095 andrew gelman stats-2013-11-09-Typo in Ghitza and Gelman MRP paper</a></p>
<p>8 0.8557387 <a title="674-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-15-Question_5_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1322 andrew gelman stats-2012-05-15-Question 5 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>9 0.85286289 <a title="674-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-14-%E2%80%9CFree_energy%E2%80%9D_and_economic_resources.html">1010 andrew gelman stats-2011-11-14-“Free energy” and economic resources</a></p>
<p>10 0.8392604 <a title="674-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-13-Ethical_concerns_in_medical_trials.html">411 andrew gelman stats-2010-11-13-Ethical concerns in medical trials</a></p>
<p>11 0.83511561 <a title="674-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-02-Reintegrating_rebels_into_civilian_life%3A_Quasi-experimental_evidence_from_Burundi.html">177 andrew gelman stats-2010-08-02-Reintegrating rebels into civilian life: Quasi-experimental evidence from Burundi</a></p>
<p>12 0.83506364 <a title="674-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Who_gets_wedding_announcements_in_the_Times%3F.html">370 andrew gelman stats-2010-10-25-Who gets wedding announcements in the Times?</a></p>
<p>13 0.83163595 <a title="674-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-06-Some_economists_are_skeptical_about_microfoundations.html">1200 andrew gelman stats-2012-03-06-Some economists are skeptical about microfoundations</a></p>
<p>14 0.83005106 <a title="674-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-Clarity_on_my_email_policy.html">503 andrew gelman stats-2011-01-04-Clarity on my email policy</a></p>
<p>15 0.83004194 <a title="674-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-15-Problematic_interpretations_of_confidence_intervals.html">2248 andrew gelman stats-2014-03-15-Problematic interpretations of confidence intervals</a></p>
<p>16 0.82761335 <a title="674-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-23-Modeling_heterogenous_treatment_effects.html">2 andrew gelman stats-2010-04-23-Modeling heterogenous treatment effects</a></p>
<p>17 0.82744133 <a title="674-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-Hypothesis_testing_with_multiple_imputations.html">799 andrew gelman stats-2011-07-13-Hypothesis testing with multiple imputations</a></p>
<p>18 0.82702655 <a title="674-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-12-Sloppily-written_slam_on_moderately_celebrated_writers_is_amusing_nonetheless.html">204 andrew gelman stats-2010-08-12-Sloppily-written slam on moderately celebrated writers is amusing nonetheless</a></p>
<p>19 0.82693273 <a title="674-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-30-%E2%80%9CThere%E2%80%99s_at_least_as_much_as_an_80_percent_chance_._._.%E2%80%9D.html">982 andrew gelman stats-2011-10-30-“There’s at least as much as an 80 percent chance . . .”</a></p>
<p>20 0.82667959 <a title="674-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-19-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1019 andrew gelman stats-2011-11-19-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
