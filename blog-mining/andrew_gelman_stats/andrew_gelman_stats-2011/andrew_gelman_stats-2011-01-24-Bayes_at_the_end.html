<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>534 andrew gelman stats-2011-01-24-Bayes at the end</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-534" href="#">andrew_gelman_stats-2011-534</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>534 andrew gelman stats-2011-01-24-Bayes at the end</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-534-html" href="http://andrewgelman.com/2011/01/24/bayes_at_the_en/">html</a></p><p>Introduction: John Cook  noticed something :
  
I [Cook] was looking at the preface of an old statistics book and read this:

 
The Bayesian techniques occur at the end of each chapter; therefore they can be omitted if time does not permit their inclusion.
 

This approach is typical. Many textbooks present frequentist statistics with a little Bayesian statistics at the end of each section or at the end of the book.


There are a couple ways to look at that. One is simply that Bayesian methods are optional. They must not be that important or theyâ&euro;&trade;d get more space. The author even recommends dropping them if pressed for time.


Another way to look at this is that Bayesian statistics must be simpler than frequentist statistics since the Bayesian approach to each task requires fewer pages.
  
My reaction:
 
Classical statistics is all about summarizing the data.
 
Bayesian statistics is data + prior information.
 
On those grounds alone, Bayes is more complicated, and it makes sense to do classical sta</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 John Cook  noticed something :    I [Cook] was looking at the preface of an old statistics book and read this:    The Bayesian techniques occur at the end of each chapter; therefore they can be omitted if time does not permit their inclusion. [sent-1, score-1.676]
</p><p>2 Many textbooks present frequentist statistics with a little Bayesian statistics at the end of each section or at the end of the book. [sent-3, score-1.69]
</p><p>3 They must not be that important or theyâ&euro;&trade;d get more space. [sent-6, score-0.14]
</p><p>4 The author even recommends dropping them if pressed for time. [sent-7, score-0.593]
</p><p>5 Another way to look at this is that Bayesian statistics must be simpler than frequentist statistics since the Bayesian approach to each task requires fewer pages. [sent-8, score-1.809]
</p><p>6 My reaction:   Classical statistics is all about summarizing the data. [sent-9, score-0.477]
</p><p>7 Bayesian statistics is data + prior information. [sent-10, score-0.413]
</p><p>8 On those grounds alone, Bayes is more complicated, and it makes sense to do classical statistics first. [sent-11, score-0.667]
</p><p>9 , but estimates, standard errors, and confidence intervals for sure. [sent-13, score-0.271]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('statistics', 0.343), ('bayesian', 0.32), ('cook', 0.262), ('frequentist', 0.231), ('end', 0.209), ('pressed', 0.205), ('permit', 0.193), ('classical', 0.19), ('preface', 0.185), ('omitted', 0.169), ('recommends', 0.153), ('dropping', 0.147), ('must', 0.14), ('grounds', 0.134), ('summarizing', 0.134), ('approach', 0.131), ('simpler', 0.124), ('occur', 0.122), ('task', 0.121), ('textbooks', 0.121), ('alone', 0.115), ('fewer', 0.113), ('techniques', 0.112), ('intervals', 0.109), ('look', 0.106), ('therefore', 0.103), ('complicated', 0.103), ('reaction', 0.101), ('requires', 0.099), ('confidence', 0.098), ('necessarily', 0.096), ('noticed', 0.096), ('bayes', 0.09), ('section', 0.09), ('author', 0.088), ('chapter', 0.087), ('present', 0.084), ('errors', 0.082), ('old', 0.078), ('simply', 0.073), ('ways', 0.073), ('john', 0.073), ('estimates', 0.071), ('couple', 0.07), ('prior', 0.07), ('looking', 0.066), ('standard', 0.064), ('little', 0.06), ('methods', 0.06), ('since', 0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="534-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>Introduction: John Cook  noticed something :
  
I [Cook] was looking at the preface of an old statistics book and read this:

 
The Bayesian techniques occur at the end of each chapter; therefore they can be omitted if time does not permit their inclusion.
 

This approach is typical. Many textbooks present frequentist statistics with a little Bayesian statistics at the end of each section or at the end of the book.


There are a couple ways to look at that. One is simply that Bayesian methods are optional. They must not be that important or theyâ&euro;&trade;d get more space. The author even recommends dropping them if pressed for time.


Another way to look at this is that Bayesian statistics must be simpler than frequentist statistics since the Bayesian approach to each task requires fewer pages.
  
My reaction:
 
Classical statistics is all about summarizing the data.
 
Bayesian statistics is data + prior information.
 
On those grounds alone, Bayes is more complicated, and it makes sense to do classical sta</p><p>2 0.23697183 <a title="534-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>Introduction: I sent Deborah Mayo a link to  my paper  with Cosma Shalizi on the philosophy of statistics, and she sent me the link to this conference which unfortunately already occurred.  (It’s too bad, because I’d have liked to have been there.)  I summarized my philosophy as follows:
  
I am highly sympathetic to the approach of Lakatos (or of Popper, if you consider Lakatos’s “Popper_2″ to be a reasonable simulation of the true Popperism), in that (a) I view statistical models as being built within theoretical structures, and (b) I see the checking and refutation of models to be a key part of scientific progress.  A big problem I have with mainstream Bayesianism is its “inductivist” view that science can operate completely smoothly with posterior updates:  the idea that new data causes us to increase the posterior probability of good models and decrease the posterior probability of bad models.  I don’t buy that:  I see models as ever-changing entities that are flexible and can be patched and ex</p><p>3 0.20537557 <a title="534-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>Introduction: Robert Bell pointed me to  this post  by Brad De Long on Bayesian statistics, and then I also noticed  this  from Noah Smith, who wrote:
  
My impression is that although the Bayesian/Frequentist debate is interesting and intellectually fun, there’s really not much “there” there… despite being so-hip-right-now, Bayesian is not the Statistical Jesus.
  
I’m happy to see the discussion going in this direction.  Twenty-five years ago or so, when I got into this biz, there were some serious anti-Bayesian attitudes floating around in mainstream statistics.  Discussions in the journals sometimes devolved into debates of the form, “Bayesians:  knaves or fools?”.  You’d get all sorts of free-floating skepticism about any prior distribution at all, even while people were accepting without question (and doing theory on) logistic regressions, proportional hazards models, and all sorts of strong strong models.  (In the subfield of survey sampling, various prominent researchers would refuse to mode</p><p>4 0.19305407 <a title="534-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>Introduction: Yes, checking calibration of probability forecasts is part of Bayesian statistics.  At the end of this post are three figures from Chapter 1 of Bayesian Data Analysis illustrating empirical evaluation of forecasts.
 
But first the background.  Why am I bringing this up now?  It’s because of something Larry Wasserman  wrote the other day : 
  
  
One of the striking facts about [baseball/political forecaster Nate Silver's recent] book is the emphasis the Silver places on frequency calibration. . . . Have no doubt about it: Nate Silver is a frequentist. For example, he says:

 
One of the most important tests of a forecast — I would argue that it is the single most important one — is called calibration. Out of all the times you said there was a 40 percent chance of rain, how often did rain actually occur? If over the long run, it really did rain about 40 percent of the time, that means your forecasts were well calibrated.
 
  
I had some discussion with Larry in the comments section of h</p><p>5 0.19037877 <a title="534-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>Introduction: My article with Cosma Shalizi has appeared in the British Journal of Mathematical and Statistical Psychology.  I’m so glad this paper has come out.  I’d been thinking about writing such a paper for almost 20 years.  What got me to actually do it was an invitation a few years ago to write a chapter on Bayesian statistics for a volume on the philosophy of social sciences.  Once I started doing that, I realized I had enough for a journal article.  I contacted Cosma because he, unlike me, was familiar with the post-1970 philosophy literature (my knowledge went only up to Popper, Kuhn, and Lakatos).  We submitted it to a couple statistics journals that didn’t want it (for reasons that weren’t always  clear ), but ultimately I think it ended up in the right place, as psychologists have been as serious as anyone in thinking about statistical foundations in recent years.
 
 Here’s the issue of the journal , which also includes an introduction, several discussions, and a rejoinder:
 
 Prior app</p><p>6 0.18310404 <a title="534-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-10-I_don%E2%80%99t_like_this_cartoon.html">1572 andrew gelman stats-2012-11-10-I don’t like this cartoon</a></p>
<p>7 0.18280861 <a title="534-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>8 0.17775686 <a title="534-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Bayesian_inference_viewed_as_a_computational_approximation_to_classical_calculations.html">254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</a></p>
<p>9 0.17380036 <a title="534-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-How_does_Bayes_do_it%3F.html">247 andrew gelman stats-2010-09-01-How does Bayes do it?</a></p>
<p>10 0.17320135 <a title="534-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>11 0.16106735 <a title="534-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>12 0.16053136 <a title="534-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>13 0.15494636 <a title="534-tfidf-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>14 0.15161353 <a title="534-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-23-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1868 andrew gelman stats-2013-05-23-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>15 0.15026166 <a title="534-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>16 0.14512384 <a title="534-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>17 0.14370038 <a title="534-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>18 0.1415067 <a title="534-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-05-A_locally_organized_online_BDA_course_on_G%2B_hangout%3F.html">2009 andrew gelman stats-2013-09-05-A locally organized online BDA course on G+ hangout?</a></p>
<p>19 0.14040591 <a title="534-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>20 0.13879457 <a title="534-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.189), (1, 0.159), (2, -0.138), (3, 0.072), (4, -0.145), (5, 0.051), (6, -0.064), (7, 0.157), (8, 0.028), (9, -0.09), (10, 0.026), (11, -0.08), (12, 0.065), (13, 0.042), (14, 0.089), (15, 0.055), (16, -0.065), (17, 0.063), (18, 0.023), (19, -0.066), (20, 0.059), (21, 0.134), (22, -0.018), (23, 0.01), (24, 0.041), (25, -0.033), (26, -0.046), (27, -0.033), (28, -0.026), (29, 0.006), (30, 0.036), (31, 0.026), (32, -0.002), (33, -0.025), (34, 0.03), (35, 0.037), (36, -0.022), (37, 0.069), (38, -0.027), (39, 0.004), (40, 0.004), (41, -0.023), (42, -0.032), (43, -0.008), (44, -0.009), (45, -0.026), (46, 0.022), (47, 0.034), (48, 0.045), (49, 0.025)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98665595 <a title="534-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>Introduction: John Cook  noticed something :
  
I [Cook] was looking at the preface of an old statistics book and read this:

 
The Bayesian techniques occur at the end of each chapter; therefore they can be omitted if time does not permit their inclusion.
 

This approach is typical. Many textbooks present frequentist statistics with a little Bayesian statistics at the end of each section or at the end of the book.


There are a couple ways to look at that. One is simply that Bayesian methods are optional. They must not be that important or theyâ&euro;&trade;d get more space. The author even recommends dropping them if pressed for time.


Another way to look at this is that Bayesian statistics must be simpler than frequentist statistics since the Bayesian approach to each task requires fewer pages.
  
My reaction:
 
Classical statistics is all about summarizing the data.
 
Bayesian statistics is data + prior information.
 
On those grounds alone, Bayes is more complicated, and it makes sense to do classical sta</p><p>2 0.8491351 <a title="534-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-28-Why_during_the_1950-1960%E2%80%B2s_did_Jerry_Cornfield_become_a_Bayesian%3F.html">2000 andrew gelman stats-2013-08-28-Why during the 1950-1960′s did Jerry Cornfield become a Bayesian?</a></p>
<p>Introduction: Joel Greenhouse writes:
  
I saw your recent paper on Feller [see  here  and, for a more fanciful theory,  here ].  Looks like it was fun to write.  I recently wrote  a paper  that asks an orthogonal question to yours.  Why during the 1950-1960′s did Jerry Cornfield become a Bayesian?   It appeared in Statistics in Medicine –  “On becoming a Bayesian: Early correspondences between J. Cornfield and L. J. Savage.”
  
In his paper, Greenhouse writes:
  
Jerome Cornfield was arguably the leading proponent for the use of Bayesian methods in biostatistics during the 1960s. Prior to 1963, however, Cornfield had no publications in the area of Bayesian statistics. At a time when frequentist methods were the dominant influence on statistical practice, Cornfield went against the mainstream and embraced Bayes. . . . Cornfield’s interest in Bayesian methods began prior to 1961 and that the clarity of his Bayesian outlook began to take shape following Birnbaum’s ASA paper on the likelihood prin- cip</p><p>3 0.8485409 <a title="534-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>Introduction: Yes, checking calibration of probability forecasts is part of Bayesian statistics.  At the end of this post are three figures from Chapter 1 of Bayesian Data Analysis illustrating empirical evaluation of forecasts.
 
But first the background.  Why am I bringing this up now?  It’s because of something Larry Wasserman  wrote the other day : 
  
  
One of the striking facts about [baseball/political forecaster Nate Silver's recent] book is the emphasis the Silver places on frequency calibration. . . . Have no doubt about it: Nate Silver is a frequentist. For example, he says:

 
One of the most important tests of a forecast — I would argue that it is the single most important one — is called calibration. Out of all the times you said there was a 40 percent chance of rain, how often did rain actually occur? If over the long run, it really did rain about 40 percent of the time, that means your forecasts were well calibrated.
 
  
I had some discussion with Larry in the comments section of h</p><p>4 0.82400155 <a title="534-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-11-How_things_sound_to_us%2C_versus_how_they_sound_to_others.html">1259 andrew gelman stats-2012-04-11-How things sound to us, versus how they sound to others</a></p>
<p>Introduction: Hykel Hosni noticed  this bit  from the Lindley Prize page of the Society for Bayesan Analysis:
  
Lindley became a great missionary for the Bayesian gospel. The atmosphere of the Bayesian revival is captured in a comment by Rivett on Lindley’s move to University College London and the premier chair of statistics in Britain: “it was as though a Jehovah’s Witness had been elected Pope.”
  
From my perspective, this was amusing (if commonplace):  a group of rationalists jocularly characterizing themselves as religious fanatics.  And some of this is in response to intense opposition from outsiders (see the Background section  here ).
 
That’s my view.  I’m an insider, a statistician who’s heard all jokes about religious Bayesians, from Bayesian and non-Bayesian statisticians alike.
 
But Hosni is an outsider, and here’s how he sees the above-quoted paragraph:
  
Research, however, is not a matter of faith but a matter of arguments, which should always be evaluated with the utmost intellec</p><p>5 0.8109172 <a title="534-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-12-%E2%80%9CNot_only_defended_but_also_applied%E2%80%9D%3A_The_perceived_absurdity_of_Bayesian_inference.html">1262 andrew gelman stats-2012-04-12-“Not only defended but also applied”: The perceived absurdity of Bayesian inference</a></p>
<p>Introduction: Updated version  of my paper with Xian:
  
The missionary zeal of many Bayesians of old has been matched, in the other direction, by an attitude among some theoreticians that Bayesian methods are absurd—not merely misguided but obviously wrong in principle. We consider several examples, beginning with Feller’s classic text on probability theory and continuing with more recent cases such as the perceived Bayesian nature of the so-called doomsday argument. We analyze in this note the intellectual background behind various misconceptions about Bayesian statistics, without aiming at a complete historical coverage of the reasons for this dismissal.
  
I love this stuff.</p><p>6 0.7954728 <a title="534-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-08-Gratuitous_use_of_%E2%80%9CBayesian_Statistics%2C%E2%80%9D_a_branding_issue%3F.html">133 andrew gelman stats-2010-07-08-Gratuitous use of “Bayesian Statistics,” a branding issue?</a></p>
<p>7 0.78420973 <a title="534-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-04-Generalized_Method_of_Moments%2C_whatever_that_is.html">449 andrew gelman stats-2010-12-04-Generalized Method of Moments, whatever that is</a></p>
<p>8 0.78279114 <a title="534-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>9 0.77523178 <a title="534-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-Bayesian_models_for_simultaneous_equation_systems%3F.html">183 andrew gelman stats-2010-08-04-Bayesian models for simultaneous equation systems?</a></p>
<p>10 0.77515233 <a title="534-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>11 0.77509534 <a title="534-lsi-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>12 0.76318765 <a title="534-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-13-Silly_Sas_lays_out_old-fashioned_statistical_thinking.html">83 andrew gelman stats-2010-06-13-Silly Sas lays out old-fashioned statistical thinking</a></p>
<p>13 0.76194477 <a title="534-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-29-Another_Feller_theory.html">1781 andrew gelman stats-2013-03-29-Another Feller theory</a></p>
<p>14 0.7586804 <a title="534-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-05-A_locally_organized_online_BDA_course_on_G%2B_hangout%3F.html">2009 andrew gelman stats-2013-09-05-A locally organized online BDA course on G+ hangout?</a></p>
<p>15 0.75719637 <a title="534-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<p>16 0.75630647 <a title="534-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-16-Looking_for_Bayesian_expertise_in_India%2C_for_the_purpose_of_analysis_of_sarcoma_trials.html">2293 andrew gelman stats-2014-04-16-Looking for Bayesian expertise in India, for the purpose of analysis of sarcoma trials</a></p>
<p>17 0.75358111 <a title="534-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>18 0.74602479 <a title="534-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-25-Continuous_variables_in_Bayesian_networks.html">1228 andrew gelman stats-2012-03-25-Continuous variables in Bayesian networks</a></p>
<p>19 0.74449933 <a title="534-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>20 0.74023783 <a title="534-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.017), (16, 0.02), (21, 0.014), (24, 0.207), (29, 0.035), (55, 0.018), (56, 0.143), (86, 0.074), (99, 0.356)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97498262 <a title="534-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-27-Bridges_between_deterministic_and_probabilistic_models_for_binary_data.html">780 andrew gelman stats-2011-06-27-Bridges between deterministic and probabilistic models for binary data</a></p>
<p>Introduction: For the analysis of binary data, various deterministic models have been proposed, which are generally simpler to fit and easier to understand than probabilistic models. We claim that corresponding to any deterministic model is an implicit stochastic model in which the deterministic model fits imperfectly, with errors occurring at random. In the context of binary data, we consider a model in which the probability of error depends on the model prediction. We show how to fit this model using a stochastic modification of deterministic optimization schemes.
 
The advantages of fitting the stochastic model explicitly (rather than implicitly, by simply fitting a deterministic model and accepting the occurrence of errors) include quantification of uncertainty in the deterministic model’s parameter estimates, better estimation of the true model error rate, and the ability to check the fit of the model nontrivially. We illustrate this with a simple theoretical example of item response data and w</p><p>2 0.9716047 <a title="534-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-12-More_frustrations_trying_to_replicate_an_analysis_published_in_a_reputable_journal.html">1054 andrew gelman stats-2011-12-12-More frustrations trying to replicate an analysis published in a reputable journal</a></p>
<p>Introduction: The story starts in September, when psychology professor Fred Oswald wrote me:
  
I [Oswald] wanted to point out  this paper  in Science (Ramirez & Beilock, 2010) examining how students’ emotional writing improves their test performance in high-pressure situations.


Although replication is viewed as the hallmark of research, this paper replicates implausibly large d-values and correlations across studies, leading me to be more suspicious of the findings (not less, as is generally the case).
  
   
He also pointed me to this paper:
  
Experimental disclosure and its moderators: A meta-analysis.


Frattaroli, Joanne


Psychological Bulletin, Vol 132(6), Nov 2006, 823-865. 


Disclosing information, thoughts, and feelings about personal and meaningful topics (experimental disclosure) is purported to have various health and psychological consequences (e.g., J. W. Pennebaker, 1993). Although the results of 2 small meta-analyses (P. G. Frisina, J. C. Borod, & S. J. Lepore, 2004; J. M. Smyth</p><p>3 0.96634859 <a title="534-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-30-More_bad_news%3A__The_%28mis%29reporting_of_statistical_results_in_psychology_journals.html">933 andrew gelman stats-2011-09-30-More bad news:  The (mis)reporting of statistical results in psychology journals</a></p>
<p>Introduction: Another entry in the growing literature on systematic flaws in the scientific research literature.
 
This time the bad tidings come from Marjan Bakker and Jelte Wicherts, who  write :
  
Around 18% of statistical results in the psychological literature are incorrectly reported. Inconsistencies were more common in low-impact journals than in high-impact journals. Moreover, around 15% of the articles contained at least one statistical conclusion that proved, upon recalculation, to be incorrect; that is, recalculation rendered the previously significant result insignificant, or vice versa. These errors were often in line with researchers’ expectations.
  
Their research also had a qualitative component:
  
To obtain a better understanding of the origins of the errors made in the reporting of statistics, we contacted the authors of the articles with errors in the second study and asked them to send us the raw data. Regrettably, only 24% of the authors shared their data, despite our request</p><p>same-blog 4 0.96570736 <a title="534-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>Introduction: John Cook  noticed something :
  
I [Cook] was looking at the preface of an old statistics book and read this:

 
The Bayesian techniques occur at the end of each chapter; therefore they can be omitted if time does not permit their inclusion.
 

This approach is typical. Many textbooks present frequentist statistics with a little Bayesian statistics at the end of each section or at the end of the book.


There are a couple ways to look at that. One is simply that Bayesian methods are optional. They must not be that important or theyâ&euro;&trade;d get more space. The author even recommends dropping them if pressed for time.


Another way to look at this is that Bayesian statistics must be simpler than frequentist statistics since the Bayesian approach to each task requires fewer pages.
  
My reaction:
 
Classical statistics is all about summarizing the data.
 
Bayesian statistics is data + prior information.
 
On those grounds alone, Bayes is more complicated, and it makes sense to do classical sta</p><p>5 0.96020925 <a title="534-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-01-David_MacKay_sez_._._._12%3F%3F.html">984 andrew gelman stats-2011-11-01-David MacKay sez . . . 12??</a></p>
<p>Introduction: I’ve recently been reading David MacKay’s 2003  book , Information Theory, Inference, and Learning Algorithms. It’s great background for my Bayesian computation class because he has lots of pictures and detailed discussions of the algorithms.  (Regular readers of this blog will not be surprised to hear that I hate all the  Occam -factor stuff that MacKay talks about, but overall it’s a great book.)
 
Anyway, I happened to notice the following bit, under the heading, “How many samples are needed?”:
  
In many problems, we really only need about twelve independent samples from P(x). Imagine that x is an unknown vector such as the amount of corrosion present in each of 10 000 underground pipelines around Cambridge, and φ(x) is the total cost of repairing those pipelines. The distribution P(x) describes the probability of a state x given the tests that have been carried out on some pipelines and the assumptions about the physics of corrosion. The quantity Φ is the expected cost of the repa</p><p>6 0.9507069 <a title="534-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-09-Special_journal_issue_on_statistical_methods_for_the_social_sciences.html">24 andrew gelman stats-2010-05-09-Special journal issue on statistical methods for the social sciences</a></p>
<p>7 0.94970727 <a title="534-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-07-Stereotype_threat%21.html">1929 andrew gelman stats-2013-07-07-Stereotype threat!</a></p>
<p>8 0.947878 <a title="534-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-22-Americans_think_economy_isn%E2%80%99t_so_bad_in_their_city_but_is_crappy_nationally_and_globally.html">1388 andrew gelman stats-2012-06-22-Americans think economy isn’t so bad in their city but is crappy nationally and globally</a></p>
<p>9 0.94734168 <a title="534-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>10 0.94560599 <a title="534-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-15-World_record_running_times_vs._distance.html">1011 andrew gelman stats-2011-11-15-World record running times vs. distance</a></p>
<p>11 0.94433135 <a title="534-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<p>12 0.94347674 <a title="534-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-The_more_likely_it_is_to_be_X%2C_the_more_likely_it_is_to_be_Not_X%3F.html">1158 andrew gelman stats-2012-02-07-The more likely it is to be X, the more likely it is to be Not X?</a></p>
<p>13 0.94288838 <a title="534-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-10-Cross-validation_and_Bayesian_estimation_of_tuning_parameters.html">2129 andrew gelman stats-2013-12-10-Cross-validation and Bayesian estimation of tuning parameters</a></p>
<p>14 0.93946177 <a title="534-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-22-Postdoc_opportunity_here_at_Columbia_%E2%80%94_deadline_soon%21.html">426 andrew gelman stats-2010-11-22-Postdoc opportunity here at Columbia — deadline soon!</a></p>
<p>15 0.93863046 <a title="534-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>16 0.93681753 <a title="534-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-19-The_mysterious_Gamma_%281.4%2C_0.4%29.html">669 andrew gelman stats-2011-04-19-The mysterious Gamma (1.4, 0.4)</a></p>
<p>17 0.93580472 <a title="534-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-18-You%E2%80%99ll_get_a_high_Type_S_error_rate_if_you_use_classical_statistical_methods_to_analyze_data_from_underpowered_studies.html">1944 andrew gelman stats-2013-07-18-You’ll get a high Type S error rate if you use classical statistical methods to analyze data from underpowered studies</a></p>
<p>18 0.93568623 <a title="534-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>19 0.93524098 <a title="534-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>20 0.93510246 <a title="534-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
