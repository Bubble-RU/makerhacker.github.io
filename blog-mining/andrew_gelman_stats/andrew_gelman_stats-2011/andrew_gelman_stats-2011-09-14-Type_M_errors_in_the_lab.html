<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>908 andrew gelman stats-2011-09-14-Type M errors in the lab</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-908" href="#">andrew_gelman_stats-2011-908</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>908 andrew gelman stats-2011-09-14-Type M errors in the lab</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-908-html" href="http://andrewgelman.com/2011/09/14/more-on-type-m-errors/">html</a></p><p>Introduction: Jeff points us to this  news article  by Asher Mullard:
  
Bayer halts nearly two-thirds of its target-validation projects because in-house experimental findings fail to match up with published literature claims, finds a first-of-a-kind analysis on data irreproducibility.


An unspoken industry rule alleges that at least 50% of published studies from academic laboratories cannot be repeated in an industrial setting, wrote venture capitalist Bruce Booth in a recent blog post. A first-of-a-kind analysis of Bayer’s internal efforts to validate ‘new drug target’ claims now not only supports this view but suggests that 50% may be an underestimate; the company’s in-house experimental data do not match literature claims in 65% of target-validation projects, leading to project discontinuation. . . .


Khusru Asadullah, Head of Target Discovery at Bayer, and his colleagues looked back at 67 target-validation projects, covering the majority of Bayer’s work in oncology, women’s health and cardiov</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Jeff points us to this  news article  by Asher Mullard:    Bayer halts nearly two-thirds of its target-validation projects because in-house experimental findings fail to match up with published literature claims, finds a first-of-a-kind analysis on data irreproducibility. [sent-1, score-1.077]
</p><p>2 An unspoken industry rule alleges that at least 50% of published studies from academic laboratories cannot be repeated in an industrial setting, wrote venture capitalist Bruce Booth in a recent blog post. [sent-2, score-0.975]
</p><p>3 Khusru Asadullah, Head of Target Discovery at Bayer, and his colleagues looked back at 67 target-validation projects, covering the majority of Bayer’s work in oncology, women’s health and cardiovascular medicine over the past 4 years. [sent-7, score-0.252]
</p><p>4 Of these, results from internal experiments matched up with the published findings in only 14 projects, but were highly inconsistent in 43 (in a further 10 projects, claims were rated as mostly reproducible, partially reproducible or not applicable . [sent-8, score-1.208]
</p><p>5 High-impact journals did not seem to publish more robust claims, and, surprisingly, the confirmation of any given finding by another academic group did not improve data reliability. [sent-11, score-0.243]
</p><p>6 “We didn’t see that a target is more likely to be validated if it was reported in ten publications or in two publications,” says Asadullah. [sent-12, score-0.507]
</p><p>7 There’s also this amusing bit:    The analysis is limited by a small sample size, and cannot itself be checked because of company confidentiality concerns . [sent-16, score-0.426]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bayer', 0.515), ('projects', 0.334), ('claims', 0.217), ('target', 0.208), ('reproducible', 0.185), ('internal', 0.157), ('publications', 0.136), ('match', 0.132), ('company', 0.118), ('alleges', 0.117), ('laboratories', 0.117), ('unspoken', 0.111), ('experimental', 0.109), ('rated', 0.106), ('capitalist', 0.102), ('cardiovascular', 0.102), ('oncology', 0.102), ('published', 0.102), ('booth', 0.099), ('validated', 0.099), ('bruce', 0.096), ('applicable', 0.096), ('underestimate', 0.096), ('venture', 0.094), ('confidentiality', 0.094), ('academic', 0.094), ('findings', 0.093), ('validate', 0.092), ('industrial', 0.089), ('inconsistent', 0.088), ('literature', 0.087), ('covering', 0.084), ('matched', 0.083), ('confirmation', 0.082), ('partially', 0.081), ('supports', 0.08), ('surprisingly', 0.075), ('repeated', 0.075), ('analysis', 0.075), ('finds', 0.075), ('industry', 0.074), ('fail', 0.07), ('amusing', 0.07), ('checked', 0.069), ('discovery', 0.069), ('head', 0.068), ('robust', 0.067), ('medicine', 0.066), ('drug', 0.066), ('ten', 0.064)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="908-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-14-Type_M_errors_in_the_lab.html">908 andrew gelman stats-2011-09-14-Type M errors in the lab</a></p>
<p>Introduction: Jeff points us to this  news article  by Asher Mullard:
  
Bayer halts nearly two-thirds of its target-validation projects because in-house experimental findings fail to match up with published literature claims, finds a first-of-a-kind analysis on data irreproducibility.


An unspoken industry rule alleges that at least 50% of published studies from academic laboratories cannot be repeated in an industrial setting, wrote venture capitalist Bruce Booth in a recent blog post. A first-of-a-kind analysis of Bayer’s internal efforts to validate ‘new drug target’ claims now not only supports this view but suggests that 50% may be an underestimate; the company’s in-house experimental data do not match literature claims in 65% of target-validation projects, leading to project discontinuation. . . .


Khusru Asadullah, Head of Target Discovery at Bayer, and his colleagues looked back at 67 target-validation projects, covering the majority of Bayer’s work in oncology, women’s health and cardiov</p><p>2 0.10655738 <a title="908-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-27-%E2%80%9CWhat_Can_we_Learn_from_the_Many_Labs_Replication_Project%3F%E2%80%9D.html">2227 andrew gelman stats-2014-02-27-“What Can we Learn from the Many Labs Replication Project?”</a></p>
<p>Introduction: Aki points us to  this discussion  from Rolf Zwaan:
  
The first massive replication project in psychology has just reached completion (several others are to follow). . . . What can we learn from the ManyLabs project? The results here show the effect sizes for the replication efforts (in green and grey) as well as the original studies (in blue). The 99% confidence intervals are for the meta-analysis of the effect size (the green dots); the studies are ordered by effect size.


 


Let’s first consider what we canNOT learn from these data. Of the 13 replication attempts (when the first four are taken together), 11 succeeded and 2 did not (in fact, at some point ManyLabs suggests that a third one, Imagined Contact also doesn’t really replicate). We cannot learn from this that the vast majority of psychological findings will replicate . . .


But even if we had an accurate estimate of the percentage of findings that replicate, how useful would that be? Rather than trying to arrive at a mo</p><p>3 0.088453777 <a title="908-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>Introduction: In our recent discussion of modes of publication, Joseph Wilson wrote, “The single best reform science can make right now is to decouple publication from career advancement, thereby reducing the number of publications by an order of magnitude and then move to an entirely disjointed, informal, online free-for-all communication system for research results.”
 
My first thought on this was: Sure, yeah, that makes sense. But then I got to thinking: what would it  really  mean to decouple publication from career advancement? This is too late for me—I’m middle-aged and have no career advancement in my future—but it got me thinking more carefully about the role of publication in the research process, and this seemed worth a blog (the simplest sort of publication available to me).
 
However, somewhere between writing the above paragraphs and writing the blog entry, I forgot exactly what I was going to say!  I guess I should’ve just typed it all in then.  In the old days I just wouldn’t run this</p><p>4 0.08823546 <a title="908-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-%E2%80%9CConfirmation%2C_on_the_other_hand%2C_is_not_sexy%E2%80%9D.html">1683 andrew gelman stats-2013-01-19-“Confirmation, on the other hand, is not sexy”</a></p>
<p>Introduction: Mark Palko  writes :
  
I can understand the appeal of the cutting edge. The new stuff is sexier. It gets people’s attention. The trouble is, those cutting edge studies often collapse under scrutiny. Some can’t be replicated. Others prove to be not that important.


Confirmation, on the other hand, is not sexy. It doesn’t drive traffic. It’s harder to fit into a paragraph. In a way, though, it’s more interesting because it has a high likelihood of being true and fills in the gaps in big, important questions. The interaction between the ideas is usually the interesting part.
  
In this particular example, Palko is telling the story of a journalist who reports a finding as new when it is essentially a replication of decades-old work.  Palko’s point is not that there’s anything wrong with replication but rather that the journalist seems to feel that it is necessary to report the idea as new and cutting-edge, even if it falls within a long tradition.  (Also, Palko is not claiming that this</p><p>5 0.087402225 <a title="908-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-29-Unfinished_business.html">637 andrew gelman stats-2011-03-29-Unfinished business</a></p>
<p>Introduction: This  blog  by J. Robert Lennon on abandoned novels made me think of the more general topic of abandoned projects.  I seem to recall George V. Higgins writing that he’d written and discarded 14 novels or so before publishing The Friends of Eddie Coyle.
 
I haven’t abandoned any novels but I’ve abandoned lots of research projects (and also have started various projects that there’s no way I’ll finish).  If you think about the decisions involved, it really has to be that way. You learn while you’re working on a project whether it’s worth continuing.  Sometimes I’ve put in the hard work and pushed a project to completion, published the article, and then I think . . . what was the point?  The modal number of citations of our articles is zero, etc.</p><p>6 0.083192073 <a title="908-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-21-Literary_blurb_translation_guide.html">723 andrew gelman stats-2011-05-21-Literary blurb translation guide</a></p>
<p>7 0.079337962 <a title="908-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-27-Why_don%E2%80%99t_more_medical_discoveries_become_cures%3F.html">167 andrew gelman stats-2010-07-27-Why don’t more medical discoveries become cures?</a></p>
<p>8 0.079011776 <a title="908-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>9 0.077086851 <a title="908-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>10 0.07661286 <a title="908-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Matching_at_two_levels.html">213 andrew gelman stats-2010-08-17-Matching at two levels</a></p>
<p>11 0.076161414 <a title="908-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-20-How_to_schedule_projects_in_an_introductory_statistics_course%3F.html">423 andrew gelman stats-2010-11-20-How to schedule projects in an introductory statistics course?</a></p>
<p>12 0.074799418 <a title="908-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-13-Preregistration_of_Studies_and_Mock_Reports.html">1671 andrew gelman stats-2013-01-13-Preregistration of Studies and Mock Reports</a></p>
<p>13 0.074537128 <a title="908-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<p>14 0.07443656 <a title="908-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-16-NYT_Labs_releases_Openpaths%2C_a_utility_for_saving_your_iphone_data.html">714 andrew gelman stats-2011-05-16-NYT Labs releases Openpaths, a utility for saving your iphone data</a></p>
<p>15 0.070620224 <a title="908-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-20-%E2%80%9CSix_red_flags_for_suspect_work%E2%80%9D.html">2032 andrew gelman stats-2013-09-20-“Six red flags for suspect work”</a></p>
<p>16 0.068567514 <a title="908-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>17 0.066290095 <a title="908-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-21-Tenure-track_statistics_job_at_Teachers_College%2C_here_at_Columbia%21.html">361 andrew gelman stats-2010-10-21-Tenure-track statistics job at Teachers College, here at Columbia!</a></p>
<p>18 0.064813249 <a title="908-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-12-More_on_publishing_in_journals.html">2245 andrew gelman stats-2014-03-12-More on publishing in journals</a></p>
<p>19 0.06379579 <a title="908-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-17-How_can_statisticians_help_psychologists_do_their_research_better%3F.html">1860 andrew gelman stats-2013-05-17-How can statisticians help psychologists do their research better?</a></p>
<p>20 0.063495517 <a title="908-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-12-Job_openings_in_multilevel_modeling_in_Bristol%2C_England.html">202 andrew gelman stats-2010-08-12-Job openings in multilevel modeling in Bristol, England</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.107), (1, -0.035), (2, -0.018), (3, -0.096), (4, -0.016), (5, -0.003), (6, -0.02), (7, -0.039), (8, -0.049), (9, 0.021), (10, 0.009), (11, -0.002), (12, -0.012), (13, 0.002), (14, -0.012), (15, 0.02), (16, 0.009), (17, 0.004), (18, 0.03), (19, -0.013), (20, -0.008), (21, 0.023), (22, -0.035), (23, 0.002), (24, -0.033), (25, 0.003), (26, -0.023), (27, -0.01), (28, 0.013), (29, 0.016), (30, -0.028), (31, -0.046), (32, 0.017), (33, -0.0), (34, 0.021), (35, 0.044), (36, -0.029), (37, 0.003), (38, -0.0), (39, 0.0), (40, 0.009), (41, -0.019), (42, 0.0), (43, 0.015), (44, 0.037), (45, 0.006), (46, -0.019), (47, 0.036), (48, -0.008), (49, 0.024)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96703982 <a title="908-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-14-Type_M_errors_in_the_lab.html">908 andrew gelman stats-2011-09-14-Type M errors in the lab</a></p>
<p>Introduction: Jeff points us to this  news article  by Asher Mullard:
  
Bayer halts nearly two-thirds of its target-validation projects because in-house experimental findings fail to match up with published literature claims, finds a first-of-a-kind analysis on data irreproducibility.


An unspoken industry rule alleges that at least 50% of published studies from academic laboratories cannot be repeated in an industrial setting, wrote venture capitalist Bruce Booth in a recent blog post. A first-of-a-kind analysis of Bayer’s internal efforts to validate ‘new drug target’ claims now not only supports this view but suggests that 50% may be an underestimate; the company’s in-house experimental data do not match literature claims in 65% of target-validation projects, leading to project discontinuation. . . .


Khusru Asadullah, Head of Target Discovery at Bayer, and his colleagues looked back at 67 target-validation projects, covering the majority of Bayer’s work in oncology, women’s health and cardiov</p><p>2 0.84391654 <a title="908-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-13-Preregistration_of_Studies_and_Mock_Reports.html">1671 andrew gelman stats-2013-01-13-Preregistration of Studies and Mock Reports</a></p>
<p>Introduction: The traditional system of scientific and scholarly publishing is breaking down in two different directions.
 
On one hand, we are moving away from relying on a small set of journals as gatekeepers: the number of papers and research projects is increasing, the number of publication outlets is increasing, and important manuscripts are being posted on SSRN, Arxiv, and other nonrefereed sites.
 
At the same time, many researchers are worried about the profusion of published claims that turn out to not replicate or in plain language, to be false. This concern is not new–some prominent discussions include Rosenthal (1979), Ioannidis (2005), and Vul et al. (2009)–but there is a growing sense that the scientific signal is being swamped by noise.
 
I recently had the opportunity to comment in the journal Political Analysis on two papers, one by Humphreys, Sierra, and Windt, and one by Monogan, on the preregistration of studies and mock reports.   Here’s  the issue of the journal.
 
Given the hi</p><p>3 0.83029968 <a title="908-lsi-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-22-Ticket_to_Baaaaarf.html">2301 andrew gelman stats-2014-04-22-Ticket to Baaaaarf</a></p>
<p>Introduction: A link from the comments here took me to the wonderfully named  Barfblog  and a report by Don Schaffner on some reporting.
 
 First, the background:   A university in England issued a press release saying that “Food picked up just a few seconds after being dropped is less likely to contain bacteria than if it is left for longer periods of time . . . The findings suggest there may be some scientific basis to the ‘5 second rule’  – the urban myth about it being fine to eat food that has only had contact with the floor for five seconds or less. Although people have long followed the 5 second rule, until now it was unclear whether it actually helped.”  According to the press release, the study was “undertaken by final year Biology students” and led by a professor of microbiology.
 
The press release hit the big time, hitting NPR, Slate, Forbes, the Daily News, etc etc.  Some typical headlines:
 
“5-second rule backed up by science” — Atlanta Journal Constitution
 
“Eating food off the floo</p><p>4 0.78181314 <a title="908-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-20-The_AAA_Tranche_of_Subprime_Science.html">2179 andrew gelman stats-2014-01-20-The AAA Tranche of Subprime Science</a></p>
<p>Introduction: In  our new ethics column for Chance , Eric Loken and I write about our current favorite topic:
  
One of our ongoing themes when discussing scientific ethics is the central role of statistics in recognizing and communicating uncer- 
tainty. Unfortunately, statistics—and the scientific process more generally—often seems to be used more as a way of laundering uncertainty, processing data until researchers and consumers of research can feel safe acting as if various scientific hypotheses are unquestionably true. . . .


We have in mind an analogy with the notorious AAA-class bonds created during the mid-2000s that led to the subprime mortgage crisis. Lower-quality mortgages—that is, mortgages with high probability of default and, thus, high uncertainty—were packaged and transformed into financial instruments that were (in retrospect, falsely) characterized as low risk. There was a tremendous interest in these securities, not just among the most unscrupulous market manipulators, but in a</p><p>5 0.77946895 <a title="908-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>Introduction: This seems to be the topic of the week.  Yesterday I posted on the sister blog  some further thoughts  on those “Psychological Science” papers on menstrual cycles, biceps size, and political attitudes, tied to a horrible press release from the journal Psychological Science hyping the biceps and politics study.
 
Then I was pointed to these  suggestions  from Richard Lucas and M. Brent Donnellan have on improving the replicability and reproducibility of research published in the Journal of Research in Personality:
  
It goes without saying that editors of scientific journals strive to publish research that is not only theoretically interesting but also methodologically rigorous. The goal is to select papers that advance the field. Accordingly, editors want to publish findings that can be reproduced and replicated by other scientists. Unfortunately, there has been a recent “crisis in confidence” among psychologists about the quality of psychological research (Pashler & Wagenmakers, 2012)</p><p>6 0.76815218 <a title="908-lsi-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-22-Quickies.html">2220 andrew gelman stats-2014-02-22-Quickies</a></p>
<p>7 0.75707704 <a title="908-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-28-50_shades_of_gray%3A__A_research_story.html">1959 andrew gelman stats-2013-07-28-50 shades of gray:  A research story</a></p>
<p>8 0.75614047 <a title="908-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-26-New_research_journal_on_observational_studies.html">2268 andrew gelman stats-2014-03-26-New research journal on observational studies</a></p>
<p>9 0.75254154 <a title="908-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-13-Data_sharing_update.html">1055 andrew gelman stats-2011-12-13-Data sharing update</a></p>
<p>10 0.75126421 <a title="908-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-12-More_frustrations_trying_to_replicate_an_analysis_published_in_a_reputable_journal.html">1054 andrew gelman stats-2011-12-12-More frustrations trying to replicate an analysis published in a reputable journal</a></p>
<p>11 0.74977666 <a title="908-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>12 0.74664694 <a title="908-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>13 0.74199212 <a title="908-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-12-Meta-analysis%2C_game_theory%2C_and_incentives_to_do_replicable_research.html">1163 andrew gelman stats-2012-02-12-Meta-analysis, game theory, and incentives to do replicable research</a></p>
<p>14 0.74189204 <a title="908-lsi-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>15 0.73589903 <a title="908-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-06-Against_optimism_about_social_science.html">1844 andrew gelman stats-2013-05-06-Against optimism about social science</a></p>
<p>16 0.71666789 <a title="908-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-24-Too_Good_To_Be_True%3A__The_Scientific_Mass_Production_of_Spurious_Statistical_Significance.html">1954 andrew gelman stats-2013-07-24-Too Good To Be True:  The Scientific Mass Production of Spurious Statistical Significance</a></p>
<p>17 0.71587455 <a title="908-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>18 0.71386629 <a title="908-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<p>19 0.71237499 <a title="908-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-27-%E2%80%9CWhat_Can_we_Learn_from_the_Many_Labs_Replication_Project%3F%E2%80%9D.html">2227 andrew gelman stats-2014-02-27-“What Can we Learn from the Many Labs Replication Project?”</a></p>
<p>20 0.70877093 <a title="908-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-17-The_Washington_Post_reprints_university_press_releases_without_editing_them.html">2215 andrew gelman stats-2014-02-17-The Washington Post reprints university press releases without editing them</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.01), (15, 0.411), (16, 0.05), (24, 0.068), (35, 0.011), (41, 0.012), (48, 0.013), (53, 0.035), (68, 0.012), (76, 0.011), (82, 0.01), (95, 0.013), (98, 0.013), (99, 0.209)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98843336 <a title="908-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-30-Of_psychology_research_and_investment_tips.html">439 andrew gelman stats-2010-11-30-Of psychology research and investment tips</a></p>
<p>Introduction: A few days after “ Dramatic study shows participants are affected by psychological phenomena from the future ,” (see  here ) the British Psychological Society follows up with “ Can psychology help combat pseudoscience? .”
 
Somehow I’m reminded of that bit of financial advice which says, if you want to save some money, your best investment is to pay off your credit card bills.</p><p>2 0.92999756 <a title="908-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-99%21.html">1394 andrew gelman stats-2012-06-27-99!</a></p>
<p>Introduction: Those of you who know what I’m talking about, know what I’m talking about.</p><p>same-blog 3 0.92724895 <a title="908-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-14-Type_M_errors_in_the_lab.html">908 andrew gelman stats-2011-09-14-Type M errors in the lab</a></p>
<p>Introduction: Jeff points us to this  news article  by Asher Mullard:
  
Bayer halts nearly two-thirds of its target-validation projects because in-house experimental findings fail to match up with published literature claims, finds a first-of-a-kind analysis on data irreproducibility.


An unspoken industry rule alleges that at least 50% of published studies from academic laboratories cannot be repeated in an industrial setting, wrote venture capitalist Bruce Booth in a recent blog post. A first-of-a-kind analysis of Bayer’s internal efforts to validate ‘new drug target’ claims now not only supports this view but suggests that 50% may be an underestimate; the company’s in-house experimental data do not match literature claims in 65% of target-validation projects, leading to project discontinuation. . . .


Khusru Asadullah, Head of Target Discovery at Bayer, and his colleagues looked back at 67 target-validation projects, covering the majority of Bayer’s work in oncology, women’s health and cardiov</p><p>4 0.8841725 <a title="908-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-01-I_owe_it_all_to_the_haters.html">834 andrew gelman stats-2011-08-01-I owe it all to the haters</a></p>
<p>Introduction: Sometimes when I submit an article to a journal it is accepted right away or with minor alterations.  But many of my favorite articles were rejected or had to go through an exhausting series of revisions.  For example,  this  influential article had a very hostile referee and we had to seriously push the journal editor to accept it.   This one  was rejected by one or two journals before finally appearing with discussion.   This paper  was rejected by the American Political Science Review with no chance of revision and we had to publish it in the British Journal of Political Science, which was a bit odd given that the article was 100% about American politics.  And when I submitted  this  instant classic (actually at the invitation of the editor), the referees found it to be trivial, and the editor did me the favor of publishing it but only by officially labeling it as a discussion of another article that appeared in the same issue.  Some of my most influential papers were accepted right</p><p>5 0.86029863 <a title="908-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-24-Statistical_ethics_violation.html">1081 andrew gelman stats-2011-12-24-Statistical ethics violation</a></p>
<p>Introduction: A colleague writes:
  
When I was in NYC I went to this party by group of Japanese bio-scientists. There, one guy told me about how the biggest pharmaceutical company in Japan did their statistics. They ran 100 different tests and reported the most significant one. (This was in 2006 and he said they stopped doing this few years back so they were doing this until pretty recently…) I’m not sure if this was 100 multiple comparison or 100 different kinds of test but I’m sure they wouldn’t want to disclose their data…
  
Ouch!</p><p>6 0.83846283 <a title="908-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-15-New_prize_on_causality_in_statstistics_education.html">1624 andrew gelman stats-2012-12-15-New prize on causality in statstistics education</a></p>
<p>7 0.83725947 <a title="908-lda-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-01-Association_for_Psychological_Science_announces_a_new_journal.html">2278 andrew gelman stats-2014-04-01-Association for Psychological Science announces a new journal</a></p>
<p>8 0.82823479 <a title="908-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-More_on_those_dudes_who_will_pay_your_professor_%248000_to_assign_a_book_to_your_class%2C_and_related_stories_about_small-time_sleazoids.html">329 andrew gelman stats-2010-10-08-More on those dudes who will pay your professor $8000 to assign a book to your class, and related stories about small-time sleazoids</a></p>
<p>9 0.82623124 <a title="908-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-19-Statistical_discrimination_again.html">1541 andrew gelman stats-2012-10-19-Statistical discrimination again</a></p>
<p>10 0.79968035 <a title="908-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-06-W%E2%80%99man_%3C_W%E2%80%99pedia%2C_again.html">945 andrew gelman stats-2011-10-06-W’man < W’pedia, again</a></p>
<p>11 0.79152822 <a title="908-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-08-Gratuitous_use_of_%E2%80%9CBayesian_Statistics%2C%E2%80%9D_a_branding_issue%3F.html">133 andrew gelman stats-2010-07-08-Gratuitous use of “Bayesian Statistics,” a branding issue?</a></p>
<p>12 0.79112172 <a title="908-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-09-My_talks_in_DC_and_Baltimore_this_week.html">1794 andrew gelman stats-2013-04-09-My talks in DC and Baltimore this week</a></p>
<p>13 0.77881676 <a title="908-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-21-Interpreting_interactions_in_discrete-data_regression.html">1908 andrew gelman stats-2013-06-21-Interpreting interactions in discrete-data regression</a></p>
<p>14 0.76730216 <a title="908-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-12-Too_tired_to_mock.html">1800 andrew gelman stats-2013-04-12-Too tired to mock</a></p>
<p>15 0.74779743 <a title="908-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-13-How_should_journals_handle_replication_studies%3F.html">762 andrew gelman stats-2011-06-13-How should journals handle replication studies?</a></p>
<p>16 0.73142254 <a title="908-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-30-%E2%80%9CTragedy_of_the_science-communication_commons%E2%80%9D.html">1833 andrew gelman stats-2013-04-30-“Tragedy of the science-communication commons”</a></p>
<p>17 0.72380853 <a title="908-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<p>18 0.70238012 <a title="908-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-16-Uri_Simonsohn_is_speaking_at_Columbia_tomorrow_%28Mon%29.html">1499 andrew gelman stats-2012-09-16-Uri Simonsohn is speaking at Columbia tomorrow (Mon)</a></p>
<p>19 0.69931448 <a title="908-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-The_reverse-journal-submission_system.html">1393 andrew gelman stats-2012-06-26-The reverse-journal-submission system</a></p>
<p>20 0.69841444 <a title="908-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-08-New_Judea_Pearl_journal_of_causal_inference.html">1888 andrew gelman stats-2013-06-08-New Judea Pearl journal of causal inference</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
