<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>933 andrew gelman stats-2011-09-30-More bad news:  The (mis)reporting of statistical results in psychology journals</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-933" href="#">andrew_gelman_stats-2011-933</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>933 andrew gelman stats-2011-09-30-More bad news:  The (mis)reporting of statistical results in psychology journals</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-933-html" href="http://andrewgelman.com/2011/09/30/more-bad-news-the-misreporting-of-statistical-results-in-psychology-journals/">html</a></p><p>Introduction: Another entry in the growing literature on systematic flaws in the scientific research literature.
 
This time the bad tidings come from Marjan Bakker and Jelte Wicherts, who  write :
  
Around 18% of statistical results in the psychological literature are incorrectly reported. Inconsistencies were more common in low-impact journals than in high-impact journals. Moreover, around 15% of the articles contained at least one statistical conclusion that proved, upon recalculation, to be incorrect; that is, recalculation rendered the previously significant result insignificant, or vice versa. These errors were often in line with researchers’ expectations.
  
Their research also had a qualitative component:
  
To obtain a better understanding of the origins of the errors made in the reporting of statistics, we contacted the authors of the articles with errors in the second study and asked them to send us the raw data. Regrettably, only 24% of the authors shared their data, despite our request</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Another entry in the growing literature on systematic flaws in the scientific research literature. [sent-1, score-0.357]
</p><p>2 This time the bad tidings come from Marjan Bakker and Jelte Wicherts, who  write :    Around 18% of statistical results in the psychological literature are incorrectly reported. [sent-2, score-0.209]
</p><p>3 Moreover, around 15% of the articles contained at least one statistical conclusion that proved, upon recalculation, to be incorrect; that is, recalculation rendered the previously significant result insignificant, or vice versa. [sent-4, score-0.902]
</p><p>4 These errors were often in line with researchers’ expectations. [sent-5, score-0.171]
</p><p>5 Their research also had a qualitative component:    To obtain a better understanding of the origins of the errors made in the reporting of statistics, we contacted the authors of the articles with errors in the second study and asked them to send us the raw data. [sent-6, score-1.203]
</p><p>6 Regrettably, only 24% of the authors shared their data, despite our request being quite specific and our assurances that the authors would remain anonymous. [sent-7, score-0.625]
</p><p>7 The paper by Bakker and Wicherts features a truly ugly graph (Figure 2) and also breaks a rule by reporting percentages to inappropriate precision  (no, you don’t have to categorize 33/113 as “29. [sent-11, score-0.815]
</p><p>8 2%”), but I’ll forgive them because I like this sort of work. [sent-12, score-0.134]
</p><p>9 Wagenmakers, and John Ioannidis are much more deserving of the ASA Founders Award than is, say, I dunno, Ed Wegman? [sent-16, score-0.134]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wicherts', 0.36), ('recalculation', 0.284), ('bakker', 0.284), ('jelte', 0.256), ('errors', 0.171), ('authors', 0.157), ('categorize', 0.142), ('marjan', 0.142), ('assurances', 0.134), ('forgive', 0.134), ('deserving', 0.134), ('rendered', 0.134), ('reporting', 0.132), ('asa', 0.12), ('founders', 0.114), ('dunno', 0.112), ('origins', 0.112), ('insignificant', 0.112), ('contained', 0.108), ('wagenmakers', 0.106), ('articles', 0.105), ('literature', 0.105), ('vice', 0.104), ('incorrectly', 0.104), ('ioannidis', 0.104), ('percentages', 0.1), ('breaks', 0.099), ('qualitative', 0.097), ('moreover', 0.096), ('contacted', 0.094), ('award', 0.092), ('component', 0.092), ('incorrect', 0.091), ('request', 0.091), ('inappropriate', 0.091), ('wegman', 0.091), ('proved', 0.09), ('ed', 0.088), ('growing', 0.087), ('flaws', 0.087), ('obtain', 0.086), ('precision', 0.086), ('shared', 0.086), ('previously', 0.086), ('ugly', 0.085), ('around', 0.081), ('truly', 0.08), ('raw', 0.078), ('systematic', 0.078), ('personally', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="933-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-30-More_bad_news%3A__The_%28mis%29reporting_of_statistical_results_in_psychology_journals.html">933 andrew gelman stats-2011-09-30-More bad news:  The (mis)reporting of statistical results in psychology journals</a></p>
<p>Introduction: Another entry in the growing literature on systematic flaws in the scientific research literature.
 
This time the bad tidings come from Marjan Bakker and Jelte Wicherts, who  write :
  
Around 18% of statistical results in the psychological literature are incorrectly reported. Inconsistencies were more common in low-impact journals than in high-impact journals. Moreover, around 15% of the articles contained at least one statistical conclusion that proved, upon recalculation, to be incorrect; that is, recalculation rendered the previously significant result insignificant, or vice versa. These errors were often in line with researchers’ expectations.
  
Their research also had a qualitative component:
  
To obtain a better understanding of the origins of the errors made in the reporting of statistics, we contacted the authors of the articles with errors in the second study and asked them to send us the raw data. Regrettably, only 24% of the authors shared their data, despite our request</p><p>2 0.25270522 <a title="933-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-04-Insecure_researchers_aren%E2%80%99t_sharing_their_data.html">991 andrew gelman stats-2011-11-04-Insecure researchers aren’t sharing their data</a></p>
<p>Introduction: Jelte Wicherts writes:
  
I thought you might be interested in reading  this paper  that is to appear this week in PLoS ONE.


In it we [Wicherts, Marjan Bakker, and Dylan Molenaar] show that the willingness to share data from published psychological research is associated both with “the strength of the evidence” (against H0) and the prevalence of errors in the reporting of p-values. 


The issue of data archiving will likely be put on the agenda of granting bodies and the APA/APS because of what Diederik Stapel  did .
  
I hate hate hate hate hate when people don’t share their data.  In fact, that’s the subject of my very first column on ethics for Chance magazine.  I have a story from 22 years ago, when I contacted some scientists and showed them how I could reanalyze their data more efficiently (based on a preliminary analysis of their published summary statistics).  They seemed to feel threatened by the suggestion and refused to send me their raw data.  (It was an animal experiment</p><p>3 0.14826185 <a title="933-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-05-Cleaning_up_science.html">1842 andrew gelman stats-2013-05-05-Cleaning up science</a></p>
<p>Introduction: David Hogg pointed me to  this post  by Gary Marcus, reviewing  this skeptics’ all-star issue  of Perspectives on Psychological Science that features replication culture heroes Jelte Wicherts, Hal Pashler, Arina Bones, E. J. Wagenmakers, Gregory Francis, Hal Pashler, John Ioannidis, and Uri Simonsohn.  I agree with pretty much everything Marcus has to say.  In addition to Marcus’s suggestions, which might be called cultural or psychological, I also have various statistical ideas that might help move the field forward.  Most notably I think we  need  to go beyond uniform priors and null-hypothesis testing to a more realistic set of models for effects and variation.  I’ll discuss more at some other time, but in the meantime I thought I’d share these links.
 
P.S.  Marcus  updates  with a glass-is-half-full take.</p><p>4 0.11461592 <a title="933-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-Some_thoughts_on_academic_cheating%2C_inspired_by_Frey%2C_Wegman%2C_Fischer%2C_Hauser%2C_Stapel.html">901 andrew gelman stats-2011-09-12-Some thoughts on academic cheating, inspired by Frey, Wegman, Fischer, Hauser, Stapel</a></p>
<p>Introduction: As regular readers of this blog are aware, I am fascinated by academic and scientific cheating and the  excuses  people give for it.
 
 Bruno Frey  and colleagues published a single article (with only minor variants) in five different major journals, and these articles did not cite each other.  And there have been several other cases of his self-plagiarism (see  this review  from Olaf Storbeck).  I do not mind the general practice of repeating oneself for different audiences—in the social sciences, we call this  Arrow’s Theorem —but in this case Frey seems to have gone a bit too far.  Blogger Economic Logic has  looked into  this and concluded that this sort of common practice is standard in “the context of the German(-speaking) academic environment,” and what sets Frey apart is not his self-plagiarism or even his brazenness but rather his practice of doing it in high-visibility journals.  Economic Logic writes that “[Frey's] contribution is pedagogical, he found a good and interesting</p><p>5 0.10507104 <a title="933-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-21-Literary_blurb_translation_guide.html">723 andrew gelman stats-2011-05-21-Literary blurb translation guide</a></p>
<p>Introduction: “Just like literature, only smaller.”</p><p>6 0.098886661 <a title="933-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>7 0.092685819 <a title="933-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-17-6_links.html">806 andrew gelman stats-2011-07-17-6 links</a></p>
<p>8 0.087130293 <a title="933-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-09-The_difference_between_significant_and_not_significant%E2%80%A6.html">897 andrew gelman stats-2011-09-09-The difference between significant and not significant…</a></p>
<p>9 0.087122425 <a title="933-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-28-Wiley_Wegman_chutzpah_update%3A__Now_you_too_can_buy_a_selection_of_garbled_Wikipedia_articles%2C_for_a_mere_%241400-%242800_per_year%21.html">930 andrew gelman stats-2011-09-28-Wiley Wegman chutzpah update:  Now you too can buy a selection of garbled Wikipedia articles, for a mere $1400-$2800 per year!</a></p>
<p>10 0.084816769 <a title="933-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-24-A_%28not_quite%29_grand_unified_theory_of_plagiarism%2C_as_applied_to_the_Wegman_case.html">728 andrew gelman stats-2011-05-24-A (not quite) grand unified theory of plagiarism, as applied to the Wegman case</a></p>
<p>11 0.083802879 <a title="933-tfidf-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-12-More_on_publishing_in_journals.html">2245 andrew gelman stats-2014-03-12-More on publishing in journals</a></p>
<p>12 0.081754476 <a title="933-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-With_a_bit_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_again_on_this_topic%2C_and_with_a_lot_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_today.html">576 andrew gelman stats-2011-02-15-With a bit of precognition, you’d have known I was going to post again on this topic, and with a lot of precognition, you’d have known I was going to post today</a></p>
<p>13 0.081075147 <a title="933-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>14 0.079114579 <a title="933-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>15 0.077175222 <a title="933-tfidf-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-06-How_much_time_%28if_any%29_should_we_spend_criticizing_research_that%E2%80%99s_fraudulent%2C_crappy%2C_or_just_plain_pointless%3F.html">2235 andrew gelman stats-2014-03-06-How much time (if any) should we spend criticizing research that’s fraudulent, crappy, or just plain pointless?</a></p>
<p>16 0.076934785 <a title="933-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-Excellence_in_Statistical_Reporting_Award.html">1119 andrew gelman stats-2012-01-15-Excellence in Statistical Reporting Award</a></p>
<p>17 0.076101333 <a title="933-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-12-More_frustrations_trying_to_replicate_an_analysis_published_in_a_reputable_journal.html">1054 andrew gelman stats-2011-12-12-More frustrations trying to replicate an analysis published in a reputable journal</a></p>
<p>18 0.075982988 <a title="933-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-14-Felix_Salmon_wins_the_American_Statistical_Association%E2%80%99s_Excellence_in_Statistical_Reporting_Award.html">33 andrew gelman stats-2010-05-14-Felix Salmon wins the American Statistical Association’s Excellence in Statistical Reporting Award</a></p>
<p>19 0.075134367 <a title="933-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-Hey%2C_good_news%21__Your_p-value_just_passed_the_0.05_threshold%21.html">758 andrew gelman stats-2011-06-11-Hey, good news!  Your p-value just passed the 0.05 threshold!</a></p>
<p>20 0.072004937 <a title="933-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-22-Ticket_to_Baaaaarf.html">2301 andrew gelman stats-2014-04-22-Ticket to Baaaaarf</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.121), (1, -0.037), (2, -0.043), (3, -0.083), (4, -0.007), (5, -0.065), (6, -0.038), (7, -0.027), (8, -0.027), (9, -0.003), (10, 0.031), (11, -0.008), (12, -0.007), (13, -0.008), (14, 0.001), (15, -0.026), (16, -0.008), (17, 0.024), (18, 0.03), (19, -0.019), (20, 0.01), (21, -0.001), (22, -0.015), (23, -0.019), (24, 0.0), (25, -0.014), (26, 0.012), (27, -0.018), (28, 0.002), (29, -0.012), (30, 0.027), (31, 0.044), (32, -0.021), (33, 0.019), (34, 0.011), (35, 0.039), (36, -0.046), (37, -0.018), (38, 0.005), (39, -0.003), (40, 0.017), (41, -0.006), (42, -0.021), (43, 0.011), (44, -0.007), (45, -0.052), (46, -0.045), (47, -0.01), (48, 0.029), (49, -0.022)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96313792 <a title="933-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-30-More_bad_news%3A__The_%28mis%29reporting_of_statistical_results_in_psychology_journals.html">933 andrew gelman stats-2011-09-30-More bad news:  The (mis)reporting of statistical results in psychology journals</a></p>
<p>Introduction: Another entry in the growing literature on systematic flaws in the scientific research literature.
 
This time the bad tidings come from Marjan Bakker and Jelte Wicherts, who  write :
  
Around 18% of statistical results in the psychological literature are incorrectly reported. Inconsistencies were more common in low-impact journals than in high-impact journals. Moreover, around 15% of the articles contained at least one statistical conclusion that proved, upon recalculation, to be incorrect; that is, recalculation rendered the previously significant result insignificant, or vice versa. These errors were often in line with researchers’ expectations.
  
Their research also had a qualitative component:
  
To obtain a better understanding of the origins of the errors made in the reporting of statistics, we contacted the authors of the articles with errors in the second study and asked them to send us the raw data. Regrettably, only 24% of the authors shared their data, despite our request</p><p>2 0.76637691 <a title="933-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-20-The_AAA_Tranche_of_Subprime_Science.html">2179 andrew gelman stats-2014-01-20-The AAA Tranche of Subprime Science</a></p>
<p>Introduction: In  our new ethics column for Chance , Eric Loken and I write about our current favorite topic:
  
One of our ongoing themes when discussing scientific ethics is the central role of statistics in recognizing and communicating uncer- 
tainty. Unfortunately, statistics—and the scientific process more generally—often seems to be used more as a way of laundering uncertainty, processing data until researchers and consumers of research can feel safe acting as if various scientific hypotheses are unquestionably true. . . .


We have in mind an analogy with the notorious AAA-class bonds created during the mid-2000s that led to the subprime mortgage crisis. Lower-quality mortgages—that is, mortgages with high probability of default and, thus, high uncertainty—were packaged and transformed into financial instruments that were (in retrospect, falsely) characterized as low risk. There was a tremendous interest in these securities, not just among the most unscrupulous market manipulators, but in a</p><p>3 0.75453705 <a title="933-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-04-Insecure_researchers_aren%E2%80%99t_sharing_their_data.html">991 andrew gelman stats-2011-11-04-Insecure researchers aren’t sharing their data</a></p>
<p>Introduction: Jelte Wicherts writes:
  
I thought you might be interested in reading  this paper  that is to appear this week in PLoS ONE.


In it we [Wicherts, Marjan Bakker, and Dylan Molenaar] show that the willingness to share data from published psychological research is associated both with “the strength of the evidence” (against H0) and the prevalence of errors in the reporting of p-values. 


The issue of data archiving will likely be put on the agenda of granting bodies and the APA/APS because of what Diederik Stapel  did .
  
I hate hate hate hate hate when people don’t share their data.  In fact, that’s the subject of my very first column on ethics for Chance magazine.  I have a story from 22 years ago, when I contacted some scientists and showed them how I could reanalyze their data more efficiently (based on a preliminary analysis of their published summary statistics).  They seemed to feel threatened by the suggestion and refused to send me their raw data.  (It was an animal experiment</p><p>4 0.73887289 <a title="933-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-13-Preregistration_of_Studies_and_Mock_Reports.html">1671 andrew gelman stats-2013-01-13-Preregistration of Studies and Mock Reports</a></p>
<p>Introduction: The traditional system of scientific and scholarly publishing is breaking down in two different directions.
 
On one hand, we are moving away from relying on a small set of journals as gatekeepers: the number of papers and research projects is increasing, the number of publication outlets is increasing, and important manuscripts are being posted on SSRN, Arxiv, and other nonrefereed sites.
 
At the same time, many researchers are worried about the profusion of published claims that turn out to not replicate or in plain language, to be false. This concern is not new–some prominent discussions include Rosenthal (1979), Ioannidis (2005), and Vul et al. (2009)–but there is a growing sense that the scientific signal is being swamped by noise.
 
I recently had the opportunity to comment in the journal Political Analysis on two papers, one by Humphreys, Sierra, and Windt, and one by Monogan, on the preregistration of studies and mock reports.   Here’s  the issue of the journal.
 
Given the hi</p><p>5 0.73406714 <a title="933-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-Some_thoughts_on_academic_cheating%2C_inspired_by_Frey%2C_Wegman%2C_Fischer%2C_Hauser%2C_Stapel.html">901 andrew gelman stats-2011-09-12-Some thoughts on academic cheating, inspired by Frey, Wegman, Fischer, Hauser, Stapel</a></p>
<p>Introduction: As regular readers of this blog are aware, I am fascinated by academic and scientific cheating and the  excuses  people give for it.
 
 Bruno Frey  and colleagues published a single article (with only minor variants) in five different major journals, and these articles did not cite each other.  And there have been several other cases of his self-plagiarism (see  this review  from Olaf Storbeck).  I do not mind the general practice of repeating oneself for different audiences—in the social sciences, we call this  Arrow’s Theorem —but in this case Frey seems to have gone a bit too far.  Blogger Economic Logic has  looked into  this and concluded that this sort of common practice is standard in “the context of the German(-speaking) academic environment,” and what sets Frey apart is not his self-plagiarism or even his brazenness but rather his practice of doing it in high-visibility journals.  Economic Logic writes that “[Frey's] contribution is pedagogical, he found a good and interesting</p><p>6 0.73296642 <a title="933-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-16-%E2%80%9CFalse-positive_psychology%E2%80%9D.html">1171 andrew gelman stats-2012-02-16-“False-positive psychology”</a></p>
<p>7 0.7291128 <a title="933-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-16-The_lamest%2C_grudgingest%2C_non-retraction_retraction_ever.html">1626 andrew gelman stats-2012-12-16-The lamest, grudgingest, non-retraction retraction ever</a></p>
<p>8 0.71892279 <a title="933-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-28-50_shades_of_gray%3A__A_research_story.html">1959 andrew gelman stats-2013-07-28-50 shades of gray:  A research story</a></p>
<p>9 0.71219045 <a title="933-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-24-A_%28not_quite%29_grand_unified_theory_of_plagiarism%2C_as_applied_to_the_Wegman_case.html">728 andrew gelman stats-2011-05-24-A (not quite) grand unified theory of plagiarism, as applied to the Wegman case</a></p>
<p>10 0.70324808 <a title="933-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-08-Another_Wegman_plagiarism.html">751 andrew gelman stats-2011-06-08-Another Wegman plagiarism</a></p>
<p>11 0.70243561 <a title="933-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-09-The_difference_between_significant_and_not_significant%E2%80%A6.html">897 andrew gelman stats-2011-09-09-The difference between significant and not significant…</a></p>
<p>12 0.70101416 <a title="933-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-I_doubt_they_cheated.html">1971 andrew gelman stats-2013-08-07-I doubt they cheated</a></p>
<p>13 0.69884527 <a title="933-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>14 0.69611812 <a title="933-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>15 0.6948632 <a title="933-lsi-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-22-Quickies.html">2220 andrew gelman stats-2014-02-22-Quickies</a></p>
<p>16 0.68959171 <a title="933-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-30-%E2%80%9CThe_scientific_literature_must_be_cleansed_of_everything_that_is_fraudulent%2C_especially_if_it_involves_the_work_of_a_leading_academic%E2%80%9D.html">1599 andrew gelman stats-2012-11-30-“The scientific literature must be cleansed of everything that is fraudulent, especially if it involves the work of a leading academic”</a></p>
<p>17 0.68863648 <a title="933-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-18-You%E2%80%99ll_get_a_high_Type_S_error_rate_if_you_use_classical_statistical_methods_to_analyze_data_from_underpowered_studies.html">1944 andrew gelman stats-2013-07-18-You’ll get a high Type S error rate if you use classical statistical methods to analyze data from underpowered studies</a></p>
<p>18 0.68821913 <a title="933-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-29-Another_one_of_those_%E2%80%9CPsychological_Science%E2%80%9D_papers_%28this_time_on_biceps_size_and_political_attitudes_among_college_students%29.html">1876 andrew gelman stats-2013-05-29-Another one of those “Psychological Science” papers (this time on biceps size and political attitudes among college students)</a></p>
<p>19 0.68356097 <a title="933-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-17-How_can_statisticians_help_psychologists_do_their_research_better%3F.html">1860 andrew gelman stats-2013-05-17-How can statisticians help psychologists do their research better?</a></p>
<p>20 0.6831063 <a title="933-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-28-This_is_a_link_to_a_news_article_about_a_scientific_paper.html">302 andrew gelman stats-2010-09-28-This is a link to a news article about a scientific paper</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.012), (15, 0.044), (16, 0.054), (21, 0.013), (24, 0.12), (36, 0.01), (42, 0.013), (43, 0.015), (45, 0.011), (48, 0.014), (49, 0.013), (52, 0.013), (53, 0.037), (56, 0.223), (59, 0.011), (63, 0.028), (71, 0.01), (73, 0.012), (89, 0.02), (96, 0.02), (99, 0.222)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93207479 <a title="933-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-07-Martyn_Plummer%E2%80%99s_Secret_JAGS_Blog.html">1045 andrew gelman stats-2011-12-07-Martyn Plummer’s Secret JAGS Blog</a></p>
<p>Introduction: Martyn Plummer , the creator of the open-source, C++, graphical-model compiler  JAGS  (aka “Just Another Gibbs Sampler”), runs a forum on the JAGS site that has a very similar feel to the mail-bag posts on this blog.  Martyn answers general statistical computing questions (e.g., why slice sampling rather than Metropolis-Hastings?) and general modeling (e.g., why won’t my model converge with this prior?).
 
Here’s the link to the top-level JAGS site, and to the forum:
  
   JAGS Forum 
    JAGS Home Page 
   
The forum’s pretty active, with the stats page showing hundreds of views per day and very regular posts and answers.  Martyn’s last post was today.
 
Martyn also has a blog devoted to JAGS and other stats news:
  
  JAGS News Blog</p><p>2 0.92824781 <a title="933-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-15-World_record_running_times_vs._distance.html">1011 andrew gelman stats-2011-11-15-World record running times vs. distance</a></p>
<p>Introduction: Julyan Arbel  plots  world record running times vs. distance (on the log-log scale):
 
   
 
The line has a slope of 1.1.  I think it would be clearer to plot speed vs. distance—then you’d get a slope of -0.1, and the numbers would be more directly interpretable.
 
Indeed,  this paper  by Sandra Savaglio and Vincenzo Carbone (referred to in the comments on Julyan’s blog) plots speed vs. time.  Graphing by speed gives more resolution:
 
   
 
The upper-left graph in the grid corresponds to the human running records plotted by Arbel.  It’s funny that Arbel sees only one line whereas Savaglio and Carbone see two—but if you remove the 100m record at one end and the 100km at the other end, you can see two lines in Arbel’s graph as well.  The bottom two graphs show swimming records.   Knut  would probably have something to say about all this.</p><p>3 0.90023386 <a title="933-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-07-Stereotype_threat%21.html">1929 andrew gelman stats-2013-07-07-Stereotype threat!</a></p>
<p>Introduction: Colleen Ganley, Leigh Mingle, Allison Ryan, Katherine Ryan, Marian Vasilyeva, and Michelle Perry  write :
  
Stereotype threat has been proposed as 1 potential explanation for the gender difference in standardized mathematics test performance among high-performing students. At present, it is not entirely clear how susceptibility to stereotype threat develops, as empirical evidence for stereotype threat effects across the school years is inconsistent. In a series of 3 studies, with a total sample of 931 students, we investigated stereotype threat effects during childhood and adolescence. Three activation methods were used, ranging from implicit to explicit. Across studies, we found no evidence that the mathematics performance of school-age girls was impacted by stereotype threat. In 2 of the studies, there were gender differences on the mathematics assessment regardless of whether stereotype threat was activated. Potential reasons for these findings are discussed, including the possibil</p><p>same-blog 4 0.89469081 <a title="933-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-30-More_bad_news%3A__The_%28mis%29reporting_of_statistical_results_in_psychology_journals.html">933 andrew gelman stats-2011-09-30-More bad news:  The (mis)reporting of statistical results in psychology journals</a></p>
<p>Introduction: Another entry in the growing literature on systematic flaws in the scientific research literature.
 
This time the bad tidings come from Marjan Bakker and Jelte Wicherts, who  write :
  
Around 18% of statistical results in the psychological literature are incorrectly reported. Inconsistencies were more common in low-impact journals than in high-impact journals. Moreover, around 15% of the articles contained at least one statistical conclusion that proved, upon recalculation, to be incorrect; that is, recalculation rendered the previously significant result insignificant, or vice versa. These errors were often in line with researchers’ expectations.
  
Their research also had a qualitative component:
  
To obtain a better understanding of the origins of the errors made in the reporting of statistics, we contacted the authors of the articles with errors in the second study and asked them to send us the raw data. Regrettably, only 24% of the authors shared their data, despite our request</p><p>5 0.88808501 <a title="933-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<p>Introduction: Guy asks:
  
I am analyzing an original survey of farmers in Uganda. I am hoping to use a battery of welfare proxy variables to create a single welfare index using PCA. I have quick question which I hope you can find time to address:


How do you recommend treating count data? (for example # of rooms, # of chickens, # of cows, # of radios)? In my dataset these variables are highly skewed with many responses at zero (which makes taking the natural log problematic). In the case of # of cows or chickens several obs have values in the hundreds.
  
My response:  Hereâ&euro;&trade;s what we do in our mi package in R.  We split a variable into two parts:  an indicator for whether it is positive, and the positive part.  That is, y = u*v.  Then u is binary and can be modeled using logisitc regression, and v can be modeled on the log scale.  At the end you can round to the nearest integer  if you want to avoid fractional values.</p><p>6 0.86626691 <a title="933-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-12-More_frustrations_trying_to_replicate_an_analysis_published_in_a_reputable_journal.html">1054 andrew gelman stats-2011-12-12-More frustrations trying to replicate an analysis published in a reputable journal</a></p>
<p>7 0.857144 <a title="933-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-The_more_likely_it_is_to_be_X%2C_the_more_likely_it_is_to_be_Not_X%3F.html">1158 andrew gelman stats-2012-02-07-The more likely it is to be X, the more likely it is to be Not X?</a></p>
<p>8 0.8496111 <a title="933-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-09-This_Friday_afternoon%3A__Applied_Statistics_Center_mini-conference_on_risk_perception.html">267 andrew gelman stats-2010-09-09-This Friday afternoon:  Applied Statistics Center mini-conference on risk perception</a></p>
<p>9 0.84675419 <a title="933-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-27-Bridges_between_deterministic_and_probabilistic_models_for_binary_data.html">780 andrew gelman stats-2011-06-27-Bridges between deterministic and probabilistic models for binary data</a></p>
<p>10 0.83894444 <a title="933-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-22-Americans_think_economy_isn%E2%80%99t_so_bad_in_their_city_but_is_crappy_nationally_and_globally.html">1388 andrew gelman stats-2012-06-22-Americans think economy isn’t so bad in their city but is crappy nationally and globally</a></p>
<p>11 0.8312571 <a title="933-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-01-David_MacKay_sez_._._._12%3F%3F.html">984 andrew gelman stats-2011-11-01-David MacKay sez . . . 12??</a></p>
<p>12 0.82164186 <a title="933-lda-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-10-On_deck_this_week%3A__Things_people_sent_me.html">2240 andrew gelman stats-2014-03-10-On deck this week:  Things people sent me</a></p>
<p>13 0.81945115 <a title="933-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-09-Special_journal_issue_on_statistical_methods_for_the_social_sciences.html">24 andrew gelman stats-2010-05-09-Special journal issue on statistical methods for the social sciences</a></p>
<p>14 0.79544818 <a title="933-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>15 0.79540944 <a title="933-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-26-A_statistician%E2%80%99s_rants_and_raves.html">1185 andrew gelman stats-2012-02-26-A statistician’s rants and raves</a></p>
<p>16 0.78109086 <a title="933-lda-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-15-Problematic_interpretations_of_confidence_intervals.html">2248 andrew gelman stats-2014-03-15-Problematic interpretations of confidence intervals</a></p>
<p>17 0.77950305 <a title="933-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>18 0.77862054 <a title="933-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-22-Postdoc_opportunity_here_at_Columbia_%E2%80%94_deadline_soon%21.html">426 andrew gelman stats-2010-11-22-Postdoc opportunity here at Columbia — deadline soon!</a></p>
<p>19 0.77417225 <a title="933-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-04-Insecure_researchers_aren%E2%80%99t_sharing_their_data.html">991 andrew gelman stats-2011-11-04-Insecure researchers aren’t sharing their data</a></p>
<p>20 0.76330888 <a title="933-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-05-Cleaning_up_science.html">1842 andrew gelman stats-2013-05-05-Cleaning up science</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
