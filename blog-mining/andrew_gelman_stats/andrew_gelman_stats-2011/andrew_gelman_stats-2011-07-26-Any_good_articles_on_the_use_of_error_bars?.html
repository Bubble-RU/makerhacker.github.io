<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>822 andrew gelman stats-2011-07-26-Any good articles on the use of error bars?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-822" href="#">andrew_gelman_stats-2011-822</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>822 andrew gelman stats-2011-07-26-Any good articles on the use of error bars?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-822-html" href="http://andrewgelman.com/2011/07/26/any-good-articles-on-the-use-of-error-bars/">html</a></p><p>Introduction: Hadley Wickham asks:
  
I was wondering if you knew of any good articles on the use of error bars.  I’m particularly looking for articles that discuss the difference between error of means and error of difference in the context of models (e.g. mixed models) where they are very different.  I suspect every applied field has a couple of good articles, but it’s really hard to search for them.
  
Can anyone help on this?  My only advice is to get rid of those horrible crossbars at the ends of the error bars.  The crossbars draw attention to the error bars’ endpoints, which are generally not important at all.  See, for example,  my Anova paper , for some examples of how I like error bars to look.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Hadley Wickham asks:    I was wondering if you knew of any good articles on the use of error bars. [sent-1, score-1.033]
</p><p>2 I’m particularly looking for articles that discuss the difference between error of means and error of difference in the context of models (e. [sent-2, score-1.982]
</p><p>3 I suspect every applied field has a couple of good articles, but it’s really hard to search for them. [sent-5, score-0.673]
</p><p>4 My only advice is to get rid of those horrible crossbars at the ends of the error bars. [sent-7, score-1.461]
</p><p>5 The crossbars draw attention to the error bars’ endpoints, which are generally not important at all. [sent-8, score-1.287]
</p><p>6 See, for example,  my Anova paper , for some examples of how I like error bars to look. [sent-9, score-0.902]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('crossbars', 0.481), ('error', 0.462), ('bars', 0.295), ('articles', 0.244), ('endpoints', 0.197), ('wickham', 0.169), ('hadley', 0.161), ('anova', 0.157), ('difference', 0.151), ('rid', 0.151), ('ends', 0.127), ('mixed', 0.124), ('horrible', 0.116), ('draw', 0.111), ('knew', 0.11), ('models', 0.11), ('asks', 0.106), ('wondering', 0.103), ('attention', 0.101), ('suspect', 0.1), ('search', 0.098), ('advice', 0.093), ('context', 0.087), ('field', 0.086), ('anyone', 0.084), ('discuss', 0.083), ('particularly', 0.083), ('means', 0.079), ('generally', 0.076), ('examples', 0.075), ('couple', 0.075), ('applied', 0.074), ('good', 0.072), ('help', 0.071), ('looking', 0.07), ('every', 0.068), ('hard', 0.063), ('look', 0.056), ('important', 0.056), ('paper', 0.046), ('use', 0.042), ('really', 0.037), ('example', 0.036), ('get', 0.031), ('see', 0.029), ('like', 0.024)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="822-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Any_good_articles_on_the_use_of_error_bars%3F.html">822 andrew gelman stats-2011-07-26-Any good articles on the use of error bars?</a></p>
<p>Introduction: Hadley Wickham asks:
  
I was wondering if you knew of any good articles on the use of error bars.  I’m particularly looking for articles that discuss the difference between error of means and error of difference in the context of models (e.g. mixed models) where they are very different.  I suspect every applied field has a couple of good articles, but it’s really hard to search for them.
  
Can anyone help on this?  My only advice is to get rid of those horrible crossbars at the ends of the error bars.  The crossbars draw attention to the error bars’ endpoints, which are generally not important at all.  See, for example,  my Anova paper , for some examples of how I like error bars to look.</p><p>2 0.19463867 <a title="822-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>Introduction: Daniel Lakeland  asks , “Where do likelihoods come from?”  He describes a class of problems where you have a deterministic dynamic model that you want to fit to data.  The data won’t fit perfectly so, if you want to do Bayesian inference, you need to introduce an error model.  This looks a little bit different from the usual way that models are presented in statistics textbooks, where the focus is typically on the random error process, not on the deterministic part of the model.  A focus on the error process makes sense in some applications that have inherent randomness or variation (for example, genetics, psychology, and survey sampling) but not so much in the physical sciences, where the deterministic model can be complicated and is typically the essence of the study.  Often in these sorts of studies, the staring point (and sometimes the ending point) is what the physicists call “nonlinear least squares” or what we would call normally-distributed errors.  That’s what we did for our</p><p>3 0.1501687 <a title="822-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-Type_S_error_rates_for_classical_and_Bayesian_single_and_multiple_comparison_procedures.html">494 andrew gelman stats-2010-12-31-Type S error rates for classical and Bayesian single and multiple comparison procedures</a></p>
<p>Introduction: Type S error:  When your estimate is the wrong sign, compared to the true value of the parameter
 
Type M error:  When the magnitude of your estimate is far off, compared to the true value of the parameter 
  
More here.</p><p>4 0.13466457 <a title="822-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>Introduction: A research psychologist writes in with a question that’s so long that I’ll put my answer first, then put the question itself below the fold.
 
Here’s my reply:
 
As I wrote in my Anova paper and in my book with Jennifer Hill, I do think that multilevel models can completely replace Anova.  At the same time, I think the central idea of Anova should persist in our understanding of these models.  To me the central idea of Anova is not F-tests or p-values or sums of squares, but rather the idea of predicting an outcome based on factors with discrete levels, and understanding these factors using variance components.
 
The continuous or categorical response thing doesn’t really matter so much to me.  I have no problem using a normal linear model for continuous outcomes (perhaps suitably transformed) and a logistic model for binary outcomes.
 
I don’t want to throw away interactions just because they’re not statistically significant.  I’d rather partially pool them toward zero using an inform</p><p>5 0.12479968 <a title="822-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-17-Ripley_on_model_selection%2C_and_some_links_on_exploratory_model_analysis.html">1066 andrew gelman stats-2011-12-17-Ripley on model selection, and some links on exploratory model analysis</a></p>
<p>Introduction: This  is really fun.  I love how Ripley thinks, with just about every concept considered in broad generality while being connected to real-data examples.  He’s a great statistical storyteller as well.
 
 . . . and Wickham on exploratory model analysis 
 
I came across Ripley’s slides in a reference from Hadley Wickham’s  article on exploratory model analysis .  I’ve been interested for awhile in statistical graphics for understanding fitted models (which is different than the usual use of graphics to visualize data or to understand discrepancies of data from models).  Recently I’ve started using the term “exploratory model analysis,” and it seemed like such a natural phrase that I thought I’d google it and see what’s up.  I found the above-linked paper by Hadley, which in turn refers to  a paper  by Antony Unwin, Chris Volinksy, and Sylvia Winkler that defines “exploratory modelling analysis” as “the evaluation and comparison of many models simultaneously.”  That’s not exactly what I h</p><p>6 0.11166551 <a title="822-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-18-Should_we_always_be_using_the_t_and_robit_instead_of_the_normal_and_logit%3F.html">773 andrew gelman stats-2011-06-18-Should we always be using the t and robit instead of the normal and logit?</a></p>
<p>7 0.10938479 <a title="822-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-03-A_comment_on_a_post_at_the_Monkey_Cage.html">2048 andrew gelman stats-2013-10-03-A comment on a post at the Monkey Cage</a></p>
<p>8 0.10881423 <a title="822-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-03-Question_about_predictive_checks.html">1363 andrew gelman stats-2012-06-03-Question about predictive checks</a></p>
<p>9 0.10309381 <a title="822-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-13-A_question_about_AIC.html">1377 andrew gelman stats-2012-06-13-A question about AIC</a></p>
<p>10 0.1025997 <a title="822-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Aleks_says_this_is_the_future_of_visualization.html">795 andrew gelman stats-2011-07-10-Aleks says this is the future of visualization</a></p>
<p>11 0.099912956 <a title="822-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-13-Lame_Statistics_Patents.html">1761 andrew gelman stats-2013-03-13-Lame Statistics Patents</a></p>
<p>12 0.095357247 <a title="822-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-08-Regression_and_causality_and_variable_ordering.html">2364 andrew gelman stats-2014-06-08-Regression and causality and variable ordering</a></p>
<p>13 0.094010249 <a title="822-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Cross-validation_%28What_is_it_good_for%3F%29.html">1395 andrew gelman stats-2012-06-27-Cross-validation (What is it good for?)</a></p>
<p>14 0.088861614 <a title="822-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>15 0.087332636 <a title="822-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>16 0.085703239 <a title="822-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-How_does_multilevel_modeling_affect_the_estimate_of_the_grand_mean%3F.html">255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</a></p>
<p>17 0.084297813 <a title="822-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-10-I_don%E2%80%99t_like_this_cartoon.html">1572 andrew gelman stats-2012-11-10-I don’t like this cartoon</a></p>
<p>18 0.082605153 <a title="822-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-29-Edgar_Allan_Poe_was_a_statistician.html">2001 andrew gelman stats-2013-08-29-Edgar Allan Poe was a statistician</a></p>
<p>19 0.080894098 <a title="822-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>20 0.08023838 <a title="822-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-26-What_do_people_do_wrong%3F__WSJ_columnist_is_looking_for_examples%21.html">1640 andrew gelman stats-2012-12-26-What do people do wrong?  WSJ columnist is looking for examples!</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.115), (1, 0.034), (2, -0.007), (3, -0.027), (4, 0.041), (5, -0.019), (6, -0.006), (7, -0.017), (8, 0.032), (9, -0.013), (10, 0.043), (11, -0.027), (12, -0.029), (13, -0.008), (14, -0.025), (15, -0.018), (16, -0.022), (17, 0.016), (18, -0.012), (19, 0.006), (20, 0.026), (21, -0.017), (22, 0.057), (23, 0.008), (24, 0.018), (25, -0.026), (26, -0.017), (27, 0.031), (28, -0.031), (29, -0.025), (30, -0.003), (31, 0.064), (32, -0.013), (33, -0.047), (34, 0.039), (35, -0.027), (36, -0.07), (37, -0.03), (38, -0.019), (39, -0.055), (40, -0.043), (41, -0.039), (42, -0.061), (43, 0.056), (44, -0.029), (45, 0.072), (46, 0.008), (47, -0.0), (48, -0.023), (49, -0.006)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98114669 <a title="822-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Any_good_articles_on_the_use_of_error_bars%3F.html">822 andrew gelman stats-2011-07-26-Any good articles on the use of error bars?</a></p>
<p>Introduction: Hadley Wickham asks:
  
I was wondering if you knew of any good articles on the use of error bars.  I’m particularly looking for articles that discuss the difference between error of means and error of difference in the context of models (e.g. mixed models) where they are very different.  I suspect every applied field has a couple of good articles, but it’s really hard to search for them.
  
Can anyone help on this?  My only advice is to get rid of those horrible crossbars at the ends of the error bars.  The crossbars draw attention to the error bars’ endpoints, which are generally not important at all.  See, for example,  my Anova paper , for some examples of how I like error bars to look.</p><p>2 0.72664112 <a title="822-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-02-%E2%80%9CBased_on_my_experiences%2C_I_think_you_could_make_general_progress_by_constructing_a_solution_to_your_specific_problem.%E2%80%9D.html">1441 andrew gelman stats-2012-08-02-“Based on my experiences, I think you could make general progress by constructing a solution to your specific problem.”</a></p>
<p>Introduction: David Radwin writes:
  
I am seeking a statistic measuring an estimate’s reliability or stability as an alternative to the coefficient of variation (CV), also known as the relative standard error. The CV is the standard error of an estimate (proportion, mean, regression coefficient, etc.) divided by the estimate itself, usually expressed as a percentage. For example, if a survey finds 15% unemployment with a 6% standard error, the CV is .06/.15 = .4 = 40%.


Some US government agencies flag or suppress as unreliable any estimate with a CV over a certain threshold such as 30% or 50%. But this standard can be arbitrary (for example, 85% employment would have a much lower CV of .06/.85 = 7%), and the CV has other drawbacks I won’t elaborate here. I don’t need an evaluation of the wisdom of using the CV or anything else for measuring an estimate’s stability, but one of my projects calls for such a measure and I would like to find a better alternative.


Can you or your blog readers suggest</p><p>3 0.68386406 <a title="822-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-13-A_question_about_AIC.html">1377 andrew gelman stats-2012-06-13-A question about AIC</a></p>
<p>Introduction: Jacob Oaknin asks: 
  
  
 Akaike ‘s selection criterion is often justified on the basis of the empirical risk of a ML estimate being a biased estimate of the true generalization error of a parametric family, say the family, S_m, of linear regressors on a m-dimensional variable x=(x_1,..,x_m) with gaussian noise independent of x (for instance in “Unifying the derivations for the Akaike and Corrected Akaike information criteria”, by J.E.Cavanaugh, Statistics and Probability Letters, vol. 33, 1997, pp. 201-208).


On the other hand, the family S_m is known to have finite VC-dimension (VC = m+1), and this fact should grant  that empirical risk minimizer is asymtotically consistent regardless of the underlying probability distribution, and in particular for the assumed gaussian distribution of noise(“An overview of statistical learning theory”, by V.N.Vapnik, IEEE Transactions On Neural Networks, vol. 10, No. 5, 1999, pp. 988-999)


What am I missing?
  
My reply:  I’m no expert on AIC so</p><p>4 0.66249353 <a title="822-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-13-Lame_Statistics_Patents.html">1761 andrew gelman stats-2013-03-13-Lame Statistics Patents</a></p>
<p>Introduction: Manoel Galdino wrote in a comment off-topic on another post (which I erased):
  

I know you commented before about patents on statistical methods. Did you know this patent ( http://www.archpatent.com/patents/8032473 )? Do you have any comment on patents that don’t describe mathematically how it works and how and if they’re any different from previous methods? And what about the lack of scientific validation of the claims in such a method?

  
The patent in question, “US 8032473: “Generalized reduced error logistic regression method,” begins with the following “claim”:
  

A system for machine learning comprising: a computer including a computer-readable medium having software stored thereon that, when executed by said computer, performs a method comprising the steps of being trained to learn a logistic regression match to a target class variable so to exhibit classification learning by which: an estimated error in each variable’s moment in the logistic regression be modeled and reduce</p><p>5 0.64906538 <a title="822-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>Introduction: Alex Hoffman points me to  this interview  by Dylan Matthews of education researcher Thomas Kane, who at one point says,
  
Once you corrected for measurement error, a teacher’s score on their chosen videos and on their unchosen videos were correlated at 1. They were perfectly correlated.
  
Hoffman asks, “What do you think? Do you think that just maybe, perhaps, it’s possible we aught to consider, I’m just throwing out the possibility that it might be that the procedure for correcting measurement error might, you now, be a little too strong?”
 
I don’t know exactly what’s happening here, but it might be something that I’ve seen on occasion when fitting multilevel models using a point estimate for the group-level variance.  It goes like this:  measurement-error models are multilevel models, they involve the estimation of a distribution of a latent variable.  When fitting multilevel models, it is possible to estimate the group-level variance to be zero, even though the group-level varia</p><p>6 0.63309216 <a title="822-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-Type_S_error_rates_for_classical_and_Bayesian_single_and_multiple_comparison_procedures.html">494 andrew gelman stats-2010-12-31-Type S error rates for classical and Bayesian single and multiple comparison procedures</a></p>
<p>7 0.61251903 <a title="822-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-13-Help_with_this_problem%2C_win_valuable_prizes.html">1164 andrew gelman stats-2012-02-13-Help with this problem, win valuable prizes</a></p>
<p>8 0.61148208 <a title="822-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-02-The_winner%E2%80%99s_curse.html">310 andrew gelman stats-2010-10-02-The winner’s curse</a></p>
<p>9 0.60830337 <a title="822-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<p>10 0.59430301 <a title="822-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-27-Question_17_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1348 andrew gelman stats-2012-05-27-Question 17 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>11 0.59377784 <a title="822-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<p>12 0.58801723 <a title="822-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>13 0.58363765 <a title="822-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-18-The_estimated_effect_size_is_implausibly_large.__Under_what_models_is_this_a_piece_of_evidence_that_the_true_effect_is_small%3F.html">808 andrew gelman stats-2011-07-18-The estimated effect size is implausibly large.  Under what models is this a piece of evidence that the true effect is small?</a></p>
<p>14 0.5825913 <a title="822-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>15 0.58164066 <a title="822-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-02-Question_23_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1361 andrew gelman stats-2012-06-02-Question 23 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>16 0.57675964 <a title="822-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>17 0.56168383 <a title="822-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-29-Edgar_Allan_Poe_was_a_statistician.html">2001 andrew gelman stats-2013-08-29-Edgar Allan Poe was a statistician</a></p>
<p>18 0.55828702 <a title="822-lsi-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Bayesian_Uncertainty_Quantification_for_Differential_Equations%21.html">2311 andrew gelman stats-2014-04-29-Bayesian Uncertainty Quantification for Differential Equations!</a></p>
<p>19 0.55738759 <a title="822-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-09-Understanding_predictive_information_criteria_for_Bayesian_models.html">1975 andrew gelman stats-2013-08-09-Understanding predictive information criteria for Bayesian models</a></p>
<p>20 0.55355728 <a title="822-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-A_new_R_package_for_fititng_multilevel_models.html">501 andrew gelman stats-2011-01-04-A new R package for fititng multilevel models</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.095), (24, 0.108), (63, 0.018), (79, 0.027), (83, 0.078), (84, 0.054), (86, 0.073), (89, 0.021), (99, 0.38)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97970569 <a title="822-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Any_good_articles_on_the_use_of_error_bars%3F.html">822 andrew gelman stats-2011-07-26-Any good articles on the use of error bars?</a></p>
<p>Introduction: Hadley Wickham asks:
  
I was wondering if you knew of any good articles on the use of error bars.  I’m particularly looking for articles that discuss the difference between error of means and error of difference in the context of models (e.g. mixed models) where they are very different.  I suspect every applied field has a couple of good articles, but it’s really hard to search for them.
  
Can anyone help on this?  My only advice is to get rid of those horrible crossbars at the ends of the error bars.  The crossbars draw attention to the error bars’ endpoints, which are generally not important at all.  See, for example,  my Anova paper , for some examples of how I like error bars to look.</p><p>2 0.97253817 <a title="822-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-13-Macro%2C_micro%2C_and_conflicts_of_interest.html">1456 andrew gelman stats-2012-08-13-Macro, micro, and conflicts of interest</a></p>
<p>Introduction: Jeff points me to  this  and  this .  There seems to be a perception that “economists, the people who will cooly explain why people will be completely corrupt if the marginal benefit exceeds the marginal cost, see themselves as being completely not corrupt” (according to Atrios) and that “the economists who have decided to lend their names to the [Romney] campaign have been caught up in this culture of fraud” (according to Krugman).
 
The bloggers above are talking about macro, and perhaps they’re right that macroeconomists see themselves as uncorruptible and above it all.  As with political science, the key parts of macroeconomics are about what is good for the world (or, at least, what is good for the country), and it’s hard to do this well from a level of complete cynicism.  I’m no expert on macroeconomics, but my general impression is that, Marxists aside, macroeconomists tend to assume shared goals.
 
Micro, though, that’s completely different.  These dudes are happy to admit to t</p><p>3 0.96905649 <a title="822-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-11-Are_our_referencing_errors_undermining_our_scholarship_and_credibility%3F_The_case_of_expatriate_failure_rates.html">1312 andrew gelman stats-2012-05-11-Are our referencing errors undermining our scholarship and credibility? The case of expatriate failure rates</a></p>
<p>Introduction: Thomas Basbøll points to  this  ten-year-old article from Anne-Wil Harzing on the consequences of sloppy citations.  Harzing tells the story of an unsupported claim that is contradicted by published data but has been presented as fact in a particular area of the academic literature.  She writes that “high expatriate failure rates [with "expatriate failure" defined as "the expatriate returning home before his/her contractual period of employment abroad expires"] were in fact a myth created by massive misquotations and careless copying of references.”  Many papers claimed an expatriate failure rate of 25-40% (according to Harzing, this is much higher than the actual rate as estimated from empirical data), with this overly-high rate supported by a complicated link of references leading to . . . no real data.
 
Hartzing reports the following published claims:
  
Harvey (1996: 103): `The rate of failure of expatriate managers relocating overseas from United States based MNCs has been estima</p><p>4 0.96889555 <a title="822-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-26-Teaching_yourself_mathematics.html">236 andrew gelman stats-2010-08-26-Teaching yourself mathematics</a></p>
<p>Introduction: Some thoughts  from Mark Palko:
  
Of all the subjects a student is likely to encounter after elementary school, mathematics is by far the easiest to teach yourself. . . . 


What is it that makes math teachers so expendable? . . .


At some point all disciplines require the transition from passive to active and that transition can be challenging. In courses like high school history and science, the emphasis on passively acquiring knowledge (yes, I realize that students write essays in history classes and apply formulas in science classes but that represents a relatively small portion of their time and, more importantly, the work those students do is fundamentally different from the day-to-day work done by historians and scientists). By comparison, junior high students playing in an orchestra, writing short stories or solving math problems are almost entirely focused on processes and those processes are essentially the same as those engaged in by professional musicians, writers and mat</p><p>5 0.96831805 <a title="822-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Modeling_y_%3D_a_%2B_b_%2B_c.html">1294 andrew gelman stats-2012-05-01-Modeling y = a + b + c</a></p>
<p>Introduction: Brandon Behlendorf writes: 
  
  
I [Behlendorf] am replicating some previous research using OLS [he's talking about what we call "linear regression"---ed.] to regress a logged rate (to reduce skew) of Y on a number of predictors (Xs).  Y is the count of a phenomena divided by the population of the unit of the analysis.  The problem that I am encountering is that Y is composite count of a number of distinct phenomena [A+B+C], and these phenomena are not uniformly distributed across the sample.   Most of the research in this area has conducted regressions either with Y or with individual phenomena [A or B or C] as the dependent variable.  Yet it seems that if [A, B, C] are not uniformly distributed across the sample of units in the same proportion, then the use of Y would be biased, since as a count of [A+B+C] divided by the population, it would treat as equivalent units both [2+0.5+1.5] and [4+0+0]. 


My goal is trying to find a methodology which allows a researcher to regress Y on a</p><p>6 0.96753585 <a title="822-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-%E2%80%9CTo_find_out_what_happens_when_you_change_something%2C_it_is_necessary_to_change_it.%E2%80%9D.html">186 andrew gelman stats-2010-08-04-“To find out what happens when you change something, it is necessary to change it.”</a></p>
<p>7 0.96549684 <a title="822-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>8 0.96549183 <a title="822-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-14-Steven_Rhoads%E2%80%99s_book%2C_%E2%80%9CThe_Economist%E2%80%99s_View_of_the_World%E2%80%9D.html">711 andrew gelman stats-2011-05-14-Steven Rhoads’s book, “The Economist’s View of the World”</a></p>
<p>9 0.96342051 <a title="822-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-04-Do_you_have_any_idea_what_you%E2%80%99re_talking_about%3F.html">645 andrew gelman stats-2011-04-04-Do you have any idea what you’re talking about?</a></p>
<p>10 0.96329045 <a title="822-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-11-Gladwell_and_Chabris%2C_David_and_Goliath%2C_and_science_writing_as_stone_soup.html">2058 andrew gelman stats-2013-10-11-Gladwell and Chabris, David and Goliath, and science writing as stone soup</a></p>
<p>11 0.96285528 <a title="822-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-05-A_story_of_fake-data_checking_being_used_to_shoot_down_a_flawed_analysis_at_the_Farm_Credit_Agency.html">1884 andrew gelman stats-2013-06-05-A story of fake-data checking being used to shoot down a flawed analysis at the Farm Credit Agency</a></p>
<p>12 0.96236765 <a title="822-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-03-He_doesn%E2%80%99t_trust_the_fit_._._._r%3D.999.html">315 andrew gelman stats-2010-10-03-He doesn’t trust the fit . . . r=.999</a></p>
<p>13 0.96206433 <a title="822-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>14 0.96180791 <a title="822-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-22-That_claim_that_students_whose_parents_pay_for_more_of_college_get_worse_grades.html">1688 andrew gelman stats-2013-01-22-That claim that students whose parents pay for more of college get worse grades</a></p>
<p>15 0.96156985 <a title="822-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-28-Using_randomized_incentives_as_an_instrument_for_survey_nonresponse%3F.html">2152 andrew gelman stats-2013-12-28-Using randomized incentives as an instrument for survey nonresponse?</a></p>
<p>16 0.96152663 <a title="822-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-28-Different_modes_of_discourse.html">1743 andrew gelman stats-2013-02-28-Different modes of discourse</a></p>
<p>17 0.96100521 <a title="822-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-18-Predictive_checks_for_hierarchical_models.html">154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</a></p>
<p>18 0.96100301 <a title="822-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-07-The_hare%2C_the_pineapple%2C_and_Ed_Wegman.html">1307 andrew gelman stats-2012-05-07-The hare, the pineapple, and Ed Wegman</a></p>
<p>19 0.96020436 <a title="822-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-22-Spell-checking_example_demonstrates_key_aspects_of_Bayesian_data_analysis.html">2182 andrew gelman stats-2014-01-22-Spell-checking example demonstrates key aspects of Bayesian data analysis</a></p>
<p>20 0.95946413 <a title="822-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-05-A_locally_organized_online_BDA_course_on_G%2B_hangout%3F.html">2009 andrew gelman stats-2013-09-05-A locally organized online BDA course on G+ hangout?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
