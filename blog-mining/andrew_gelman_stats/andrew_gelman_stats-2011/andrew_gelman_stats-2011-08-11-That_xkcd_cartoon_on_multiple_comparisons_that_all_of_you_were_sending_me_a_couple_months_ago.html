<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>848 andrew gelman stats-2011-08-11-That xkcd cartoon on multiple comparisons that all of you were sending me a couple months ago</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-848" href="#">andrew_gelman_stats-2011-848</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>848 andrew gelman stats-2011-08-11-That xkcd cartoon on multiple comparisons that all of you were sending me a couple months ago</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-848-html" href="http://andrewgelman.com/2011/08/11/that_xkcd_carto/">html</a></p><p>Introduction: John Transue  sent it in  with the following thoughtful comment:
  
I’d imagine you’ve already received this, but just in case, here’s a cartoon you’d like. At first blush it seems to go against your advice (more nuanced than what I’m about to say by quoting the paper title) to not worry about multiple comparisons.


However, if I understand correctly your argument about multiple comparisons in multilevel models, the situation in this comic might have been avoided if shrinkage toward the grand mean (of all colors) had prevented the greens from clearing the .05 threshold. Is that right?</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 John Transue  sent it in  with the following thoughtful comment:    I’d imagine you’ve already received this, but just in case, here’s a cartoon you’d like. [sent-1, score-0.947]
</p><p>2 At first blush it seems to go against your advice (more nuanced than what I’m about to say by quoting the paper title) to not worry about multiple comparisons. [sent-2, score-1.263]
</p><p>3 However, if I understand correctly your argument about multiple comparisons in multilevel models, the situation in this comic might have been avoided if shrinkage toward the grand mean (of all colors) had prevented the greens from clearing the . [sent-3, score-2.648]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('transue', 0.279), ('clearing', 0.279), ('prevented', 0.257), ('cartoon', 0.243), ('nuanced', 0.243), ('avoided', 0.238), ('comic', 0.238), ('multiple', 0.225), ('quoting', 0.221), ('shrinkage', 0.209), ('colors', 0.197), ('grand', 0.192), ('thoughtful', 0.175), ('correctly', 0.161), ('situation', 0.145), ('worry', 0.144), ('title', 0.129), ('advice', 0.126), ('received', 0.125), ('comparisons', 0.125), ('multilevel', 0.123), ('toward', 0.122), ('imagine', 0.117), ('sent', 0.115), ('argument', 0.11), ('john', 0.104), ('comment', 0.1), ('however', 0.099), ('already', 0.094), ('understand', 0.087), ('mean', 0.084), ('following', 0.078), ('models', 0.074), ('right', 0.067), ('go', 0.067), ('case', 0.063), ('paper', 0.062), ('seems', 0.061), ('first', 0.057), ('say', 0.057), ('might', 0.053), ('ve', 0.05)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="848-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-That_xkcd_cartoon_on_multiple_comparisons_that_all_of_you_were_sending_me_a_couple_months_ago.html">848 andrew gelman stats-2011-08-11-That xkcd cartoon on multiple comparisons that all of you were sending me a couple months ago</a></p>
<p>Introduction: John Transue  sent it in  with the following thoughtful comment:
  
I’d imagine you’ve already received this, but just in case, here’s a cartoon you’d like. At first blush it seems to go against your advice (more nuanced than what I’m about to say by quoting the paper title) to not worry about multiple comparisons.


However, if I understand correctly your argument about multiple comparisons in multilevel models, the situation in this comic might have been avoided if shrinkage toward the grand mean (of all colors) had prevented the greens from clearing the .05 threshold. Is that right?</p><p>2 0.22048603 <a title="848-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Correcting_for_multiple_comparisons_in_a_Bayesian_regression_model.html">1989 andrew gelman stats-2013-08-20-Correcting for multiple comparisons in a Bayesian regression model</a></p>
<p>Introduction: Joe Northrup writes:
  
I have a question about correcting for multiple comparisons in a Bayesian regression model. I believe I understand the argument in  your 2012 paper  in Journal of Research on Educational Effectiveness that when you have a hierarchical model there is shrinkage of estimates towards the group-level mean and thus there is no need to add any additional penalty to correct for multiple comparisons. In my case I do not have hierarchically structured dataâ&euro;&rdquo;i.e. I have only 1 observation per group but have a categorical variable with a large number of categories. Thus, I am fitting a simple multiple regression in a Bayesian framework. Would putting a strong, mean 0, multivariate normal prior on the betas in this model accomplish the same sort of shrinkage (it seems to me that it would) and do you believe this is a valid way to address criticism of multiple comparisons in this setting?
  
My reply:  Yes, I think this makes sense.  One way to address concerns of multiple com</p><p>3 0.16843136 <a title="848-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Data_Thief.html">290 andrew gelman stats-2010-09-22-Data Thief</a></p>
<p>Introduction: John Transue sends along a link to  this software  for extracting data from graphs.  I havenâ&euro;&trade;t tried it out but it could be useful to somebody out there?</p><p>4 0.14340344 <a title="848-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>Introduction: After I gave  my talk  at an econ seminar on Why We (Usually) Don’t Care About Multiple Comparisons, I got the following comment:
  
One question that came up later was whether your argument is really with testing in general, rather than only with testing in multiple comparison settings.
  
My reply:
 
Yes, my argument is with testing in general.  But it arises with particular force in multiple comparisons.  With a single test, we can just say we dislike testing so we use confidence intervals or Bayesian inference instead, and it’s no problem—really more of a change in emphasis than a change in methods.  But with multiple tests, the classical advice is not simply to look at type 1 error rates but more specifically to make a multiplicity adjustment, for example to make confidence intervals wider to account for multiplicity.  I don’t want to do this!  So here there is a real battle to fight.
 
P.S.   Here’s  the article (with Jennifer and Masanao), to appear in the Journal of Research on</p><p>5 0.14206243 <a title="848-tfidf-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-How_does_multilevel_modeling_affect_the_estimate_of_the_grand_mean%3F.html">255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</a></p>
<p>Introduction: Subhadeep Mukhopadhyay writes:
  
I am convinced of the power of hierarchical modeling and individual parameter pooling concept. I was wondering how could multi-level modeling could influence the estimate of grad mean (NOT individual label).
  
My reply:  Multilevel modeling will affect the estimate of the grand mean in two ways:
 
1.  If the group-level mean is correlated with group size, then the partial pooling will change the estimate of the grand mean (and, indeed, you might want to include group size or some similar variable as a group-level predictor.
 
2.  In any case, the extra error term(s) in a multilevel model will typically affect the standard error of everything, including the estimate of the grand mean.</p><p>6 0.10305923 <a title="848-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>7 0.10240134 <a title="848-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-31-Even_a_good_data_display_can_sometimes_be_improved.html">832 andrew gelman stats-2011-07-31-Even a good data display can sometimes be improved</a></p>
<p>8 0.098295383 <a title="848-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-12-Single_or_multiple_imputation%3F.html">608 andrew gelman stats-2011-03-12-Single or multiple imputation?</a></p>
<p>9 0.097455502 <a title="848-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-17-%E2%80%9C1.7%25%E2%80%9D_ha_ha_ha.html">1725 andrew gelman stats-2013-02-17-“1.7%” ha ha ha</a></p>
<p>10 0.095638245 <a title="848-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>11 0.094788991 <a title="848-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-02-The_inevitable_problems_with_statistical_significance_and_95%25_intervals.html">1150 andrew gelman stats-2012-02-02-The inevitable problems with statistical significance and 95% intervals</a></p>
<p>12 0.091767237 <a title="848-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-10-I_don%E2%80%99t_like_this_cartoon.html">1572 andrew gelman stats-2012-11-10-I don’t like this cartoon</a></p>
<p>13 0.088604219 <a title="848-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Extreem_p-values%21.html">1691 andrew gelman stats-2013-01-25-Extreem p-values!</a></p>
<p>14 0.079293519 <a title="848-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>15 0.078054503 <a title="848-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-19-Data_exploration_and_multiple_comparisons.html">524 andrew gelman stats-2011-01-19-Data exploration and multiple comparisons</a></p>
<p>16 0.077235013 <a title="848-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-26-My_talk_at_Berkeley_on_Wednesday.html">680 andrew gelman stats-2011-04-26-My talk at Berkeley on Wednesday</a></p>
<p>17 0.076904021 <a title="848-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-23-Of_home_runs_and_grand_slams.html">47 andrew gelman stats-2010-05-23-Of home runs and grand slams</a></p>
<p>18 0.072134897 <a title="848-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-05-The_greatest_works_of_statistics_never_published.html">128 andrew gelman stats-2010-07-05-The greatest works of statistics never published</a></p>
<p>19 0.071282923 <a title="848-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-08-Discussion_with_Steven_Pinker_on_research_that_is_attached_to_data_that_are_so_noisy_as_to_be_essentially_uninformative.html">2326 andrew gelman stats-2014-05-08-Discussion with Steven Pinker on research that is attached to data that are so noisy as to be essentially uninformative</a></p>
<p>20 0.071207814 <a title="848-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.102), (1, 0.017), (2, 0.006), (3, -0.027), (4, 0.034), (5, -0.025), (6, 0.015), (7, -0.023), (8, 0.036), (9, 0.036), (10, 0.026), (11, 0.009), (12, 0.033), (13, -0.004), (14, 0.034), (15, 0.013), (16, -0.03), (17, -0.017), (18, -0.045), (19, -0.001), (20, 0.012), (21, 0.014), (22, 0.042), (23, 0.004), (24, -0.037), (25, -0.086), (26, 0.005), (27, 0.009), (28, -0.037), (29, -0.024), (30, -0.012), (31, 0.029), (32, 0.026), (33, 0.014), (34, -0.027), (35, -0.018), (36, 0.019), (37, 0.018), (38, 0.014), (39, 0.053), (40, -0.003), (41, 0.062), (42, -0.012), (43, -0.047), (44, -0.02), (45, -0.038), (46, -0.026), (47, 0.072), (48, -0.042), (49, -0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98063737 <a title="848-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-That_xkcd_cartoon_on_multiple_comparisons_that_all_of_you_were_sending_me_a_couple_months_ago.html">848 andrew gelman stats-2011-08-11-That xkcd cartoon on multiple comparisons that all of you were sending me a couple months ago</a></p>
<p>Introduction: John Transue  sent it in  with the following thoughtful comment:
  
I’d imagine you’ve already received this, but just in case, here’s a cartoon you’d like. At first blush it seems to go against your advice (more nuanced than what I’m about to say by quoting the paper title) to not worry about multiple comparisons.


However, if I understand correctly your argument about multiple comparisons in multilevel models, the situation in this comic might have been avoided if shrinkage toward the grand mean (of all colors) had prevented the greens from clearing the .05 threshold. Is that right?</p><p>2 0.77973014 <a title="848-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>Introduction: Robert Birkelbach:
  
I am writing my Bachelor Thesis in which I want to assess the reading competencies of German elementary school children using the PIRLS2006 data. My levels are classrooms and the individuals. However, my dependent variable is a multiple imputed (m=5) reading test. The problem I have is, that I do not know, whether I can just calculate 5 linear multilevel models and then average all the results (the coefficients, standard deviation, bic, intra class correlation, R2, t-statistics, p-values etc) or if I need different formulas for integrating the results of the five models into one because it is a multilevel analysis? Do you think there’s a better way in solving my problem? I would greatly appreciate if you could help me with a problem regarding my analysis — I am quite a newbie to multilevel modeling and especially to multiple imputation. Also: Is it okay to use frequentist models when the multiple imputation was done bayesian? Would the different philosophies of sc</p><p>3 0.68884313 <a title="848-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-11-More_reason_to_like_Sims_besides_just_his_name.html">952 andrew gelman stats-2011-10-11-More reason to like Sims besides just his name</a></p>
<p>Introduction: John Horton points to  Sims ‘s  comment on Angrist and Pischke :
  
Top of page 8—he criticizes economists for using clustered standard errors—suggests using multilevel models instead.
  
Awesome!  So now there are at least two Nobel prize winners in economics who’ve expressed skepticism about controlled experiments.  (I wonder if Sims is such a danger in a parking lot.)
 
P.S.  I’m still miffed that this journal didn’t invite  me  to comment on that article!</p><p>4 0.65470481 <a title="848-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Multilevel_quantile_regression.html">397 andrew gelman stats-2010-11-06-Multilevel quantile regression</a></p>
<p>Introduction: Ryan Seals writes:
  
I’m an epidemiologist at Emory University, and I’m working on a project of release patterns in jails (basically trying to model how long individuals are in jail before they’re release, for purposes of designing short-term health interventions, i.e. HIV testing, drug counseling, etc…). The question lends itself to quantile regression; we’re interested in the # of days it takes for 50% and 75% of inmates to be released. But being a clustered/nested data structure, it also obviously lends itself to multilevel modeling, with the group-level being individual jails.


So: do you know of any work on multilevel quantile regression? My quick lit search didn’t yield much, and I don’t see any preprogrammed way to do it in SAS.
  
My reply:
 
To start with, I’m putting in the R keyword here, on the hope that some readers might be able to refer you to an R function that does what you want.  Beyond this, I think it should be possible to program something in Bugs.  In ARM we hav</p><p>5 0.65021676 <a title="848-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-06-Slow_progress.html">1445 andrew gelman stats-2012-08-06-Slow progress</a></p>
<p>Introduction: I received the following message:
  
I am a Psychology postgraduate at the University of Glasgow and am writing for an article request. I’ve just read your 2008 published article titled “A weakly informative default prior distribution for logistic and other regression models” and found from it that your group also wrote a report on applying the Bayesian logistic regression approach to multilevel model, which is titled “An approximate EM algorithm for multilevel generalized linear models”. I have been looking for it online but did find it, and was wondering if I may request this report from you?
  
My first thought is that this is a good sign that psychology undergraduates are reading papers like this.  Unfortunately I had to reply as follows:
  
Hi, we actually programmed this up but never debugged it!  So no actual paper . . .
  
I think I could’ve done it if I had ever focused on the problem.  Between the messiness of the algebra and the messiness of the R code, I never got it all to</p><p>6 0.64875185 <a title="848-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Correcting_for_multiple_comparisons_in_a_Bayesian_regression_model.html">1989 andrew gelman stats-2013-08-20-Correcting for multiple comparisons in a Bayesian regression model</a></p>
<p>7 0.64571679 <a title="848-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-29-The_gradual_transition_to_replicable_science.html">2117 andrew gelman stats-2013-11-29-The gradual transition to replicable science</a></p>
<p>8 0.63560712 <a title="848-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>9 0.6279555 <a title="848-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>10 0.61703891 <a title="848-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>11 0.60788935 <a title="848-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>12 0.60617799 <a title="848-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Extreem_p-values%21.html">1691 andrew gelman stats-2013-01-25-Extreem p-values!</a></p>
<p>13 0.60140502 <a title="848-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-19-Paired_comparisons.html">99 andrew gelman stats-2010-06-19-Paired comparisons</a></p>
<p>14 0.60048699 <a title="848-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-15-A_silly_paper_that_tries_to_make_fun_of_multilevel_models.html">854 andrew gelman stats-2011-08-15-A silly paper that tries to make fun of multilevel models</a></p>
<p>15 0.59496522 <a title="848-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>16 0.59353435 <a title="848-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>17 0.59301138 <a title="848-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-22-Handling_multiple_versions_of_an_outcome_variable.html">726 andrew gelman stats-2011-05-22-Handling multiple versions of an outcome variable</a></p>
<p>18 0.59227633 <a title="848-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-Displaying_inferences_from_complex_models.html">1815 andrew gelman stats-2013-04-20-Displaying inferences from complex models</a></p>
<p>19 0.56919456 <a title="848-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>20 0.56747806 <a title="848-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-30-Using_the_aggregate_of_the_outcome_variable_as_a_group-level_predictor_in_a_hierarchical_model.html">2045 andrew gelman stats-2013-09-30-Using the aggregate of the outcome variable as a group-level predictor in a hierarchical model</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.086), (24, 0.164), (48, 0.281), (68, 0.03), (95, 0.031), (99, 0.27)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95693684 <a title="848-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-10-Proposed_new_section_of_the_American_Statistical_Association_on_Imaging_Sciences.html">332 andrew gelman stats-2010-10-10-Proposed new section of the American Statistical Association on Imaging Sciences</a></p>
<p>Introduction: Martin Lindquist writes that he and others are trying to start a new ASA section on statistics in imaging. If youâ&euro;&trade;re interested in being a signatory to its formation, please  send him  an email.</p><p>2 0.93497533 <a title="848-lda-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-07-%E2%80%9CDoes_researching_casual_marijuana_use_cause_brain_abnormalities%3F%E2%80%9D.html">2363 andrew gelman stats-2014-06-07-“Does researching casual marijuana use cause brain abnormalities?”</a></p>
<p>Introduction: David Austin points me to a  wonderfully-titled post  by Lior Pachter criticizing a recent paper on the purported effects of cannabis use.
 
Not the paper criticized  here .
 
Someone should send this all to David Brooks.   I’ve heard  he’s interested in the latest scientific findings, and  I know  he’s interested in marijuana.</p><p>3 0.93062091 <a title="848-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-28-Argument_in_favor_of_Ddulites.html">1088 andrew gelman stats-2011-12-28-Argument in favor of Ddulites</a></p>
<p>Introduction: Mark Palko  defines  a Ddulite as follows:
  
A preference for higher tech solutions even in cases where lower tech alternatives have greater and more appropriate functionality; a person of ddulite tendencies.


Though Ddulites are the opposite of Luddites with respect to attitudes toward technology, they occupy more or less the same point with respect to functionality.
  
As a sometime Luddite myself (no cell phone, tv, microwave oven, etc.), I should in fairness point out the logic in favor of being a Ddulite.  Old technology is typically pretty stable; new technology is improving.  It can make sense to switch early (before the new technology actually performs better than the old) to get the benefits of being familiar with the new technology once it does take off.</p><p>4 0.92456162 <a title="848-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-03-MCMC_in_Python.html">181 andrew gelman stats-2010-08-03-MCMC in Python</a></p>
<p>Introduction: John Salvatier forwards a note from Anand Patil that  a paper on PyMC  has appeared in the Journal of Statistical Software,  Weâ&euro;&trade;ll have to check this out.</p><p>5 0.90188408 <a title="848-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-06-Twitteo_killed_the_bloggio_star_._._._Not%21.html">841 andrew gelman stats-2011-08-06-Twitteo killed the bloggio star . . . Not!</a></p>
<p>Introduction: Alex Braunstein writes:
  
Thanks for the  post . You drove >800 pageviews to my site. That’s >90% of what Robert Scoble’s tweet generated with 184k followers, which I find incredibly impressive.
  
800 doesn’t sound like so much to me, but I suppose if it’s the right 800 . . .</p><p>same-blog 6 0.89598829 <a title="848-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-That_xkcd_cartoon_on_multiple_comparisons_that_all_of_you_were_sending_me_a_couple_months_ago.html">848 andrew gelman stats-2011-08-11-That xkcd cartoon on multiple comparisons that all of you were sending me a couple months ago</a></p>
<p>7 0.87935126 <a title="848-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Futures_contracts%2C_Granger_causality%2C_and_my_preference_for_estimation_to_testing.html">212 andrew gelman stats-2010-08-17-Futures contracts, Granger causality, and my preference for estimation to testing</a></p>
<p>8 0.84155858 <a title="848-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-26-Worst_statistical_graphic_I_have_seen_this_year.html">681 andrew gelman stats-2011-04-26-Worst statistical graphic I have seen this year</a></p>
<p>9 0.83564353 <a title="848-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-19-%E2%80%9CRonald_Reagan_is_a_Statistician_and_Other_Examples_of_Learning_From_Diverse_Sources_of_Information%E2%80%9D.html">1771 andrew gelman stats-2013-03-19-“Ronald Reagan is a Statistician and Other Examples of Learning From Diverse Sources of Information”</a></p>
<p>10 0.82813525 <a title="848-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-07-If_I_could%E2%80%99ve_done_it_all_over_again.html">2126 andrew gelman stats-2013-12-07-If I could’ve done it all over again</a></p>
<p>11 0.82301545 <a title="848-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-25-Measuring_Beauty.html">2147 andrew gelman stats-2013-12-25-Measuring Beauty</a></p>
<p>12 0.82045579 <a title="848-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-28-The_Supreme_Court%E2%80%99s_Many_Median_Justices.html">1234 andrew gelman stats-2012-03-28-The Supreme Court’s Many Median Justices</a></p>
<p>13 0.8174575 <a title="848-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-14-Sides_and_Vavreck_on_the_2012_election.html">1496 andrew gelman stats-2012-09-14-Sides and Vavreck on the 2012 election</a></p>
<p>14 0.81474876 <a title="848-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>15 0.81177497 <a title="848-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Including_interactions_or_not.html">823 andrew gelman stats-2011-07-26-Including interactions or not</a></p>
<p>16 0.79679334 <a title="848-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-12-Job_openings_in_multilevel_modeling_in_Bristol%2C_England.html">202 andrew gelman stats-2010-08-12-Job openings in multilevel modeling in Bristol, England</a></p>
<p>17 0.79538494 <a title="848-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-09-Does_it_feel_like_cheating_when_I_do_this%3F__Variation_in_ethical_standards_and_expectations.html">605 andrew gelman stats-2011-03-09-Does it feel like cheating when I do this?  Variation in ethical standards and expectations</a></p>
<p>18 0.78327173 <a title="848-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-02-Donate_Your_Data_to_Science%21.html">1038 andrew gelman stats-2011-12-02-Donate Your Data to Science!</a></p>
<p>19 0.78173918 <a title="848-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-02-Fighting_a_losing_battle.html">1518 andrew gelman stats-2012-10-02-Fighting a losing battle</a></p>
<p>20 0.78159773 <a title="848-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-30-%3F%3F%3F.html">2118 andrew gelman stats-2013-11-30-???</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
