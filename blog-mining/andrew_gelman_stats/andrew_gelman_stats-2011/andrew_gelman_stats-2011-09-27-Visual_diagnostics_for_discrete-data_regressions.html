<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>929 andrew gelman stats-2011-09-27-Visual diagnostics for discrete-data regressions</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-929" href="#">andrew_gelman_stats-2011-929</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>929 andrew gelman stats-2011-09-27-Visual diagnostics for discrete-data regressions</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-929-html" href="http://andrewgelman.com/2011/09/27/visual-diagnostics-for-discrete-data-regressions/">html</a></p><p>Introduction: Jeff asked me what I thought of  this  recent AJPS article by Brian Greenhill, Michael Ward, and Audrey Sacks, “The Separation Plot: A New Visual Method for Evaluating the Fit of Binary Models.”  It’s similar to a graph of observed vs. predicted values, but using color rather than the y-axis to display the observed values.  It seems like it could be useful, also could be applied more generally to discrete-data regressions with more than two categories.
 
When it comes to checking the model fit, I recommend binned residual plots, as discussed in  this 2000 article  with Yuri Goegebeur, Francis Tuerlinckx, and Iven Van Mechelen.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Jeff asked me what I thought of  this  recent AJPS article by Brian Greenhill, Michael Ward, and Audrey Sacks, “The Separation Plot: A New Visual Method for Evaluating the Fit of Binary Models. [sent-1, score-0.319]
</p><p>2 predicted values, but using color rather than the y-axis to display the observed values. [sent-3, score-0.745]
</p><p>3 It seems like it could be useful, also could be applied more generally to discrete-data regressions with more than two categories. [sent-4, score-0.618]
</p><p>4 When it comes to checking the model fit, I recommend binned residual plots, as discussed in  this 2000 article  with Yuri Goegebeur, Francis Tuerlinckx, and Iven Van Mechelen. [sent-5, score-0.995]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('audrey', 0.252), ('binned', 0.252), ('observed', 0.235), ('sacks', 0.227), ('ajps', 0.219), ('iven', 0.213), ('mechelen', 0.213), ('ward', 0.213), ('tuerlinckx', 0.213), ('residual', 0.191), ('francis', 0.188), ('separation', 0.18), ('van', 0.176), ('brian', 0.172), ('fit', 0.163), ('evaluating', 0.154), ('color', 0.144), ('binary', 0.141), ('plots', 0.14), ('regressions', 0.14), ('visual', 0.138), ('predicted', 0.135), ('jeff', 0.13), ('display', 0.127), ('plot', 0.121), ('checking', 0.117), ('michael', 0.113), ('recommend', 0.11), ('values', 0.104), ('article', 0.098), ('asked', 0.094), ('discussed', 0.094), ('method', 0.092), ('generally', 0.088), ('graph', 0.087), ('applied', 0.085), ('similar', 0.084), ('comes', 0.083), ('useful', 0.08), ('could', 0.073), ('recent', 0.065), ('thought', 0.062), ('using', 0.052), ('rather', 0.052), ('seems', 0.052), ('model', 0.05), ('two', 0.047), ('new', 0.045), ('also', 0.033), ('like', 0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="929-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-27-Visual_diagnostics_for_discrete-data_regressions.html">929 andrew gelman stats-2011-09-27-Visual diagnostics for discrete-data regressions</a></p>
<p>Introduction: Jeff asked me what I thought of  this  recent AJPS article by Brian Greenhill, Michael Ward, and Audrey Sacks, “The Separation Plot: A New Visual Method for Evaluating the Fit of Binary Models.”  It’s similar to a graph of observed vs. predicted values, but using color rather than the y-axis to display the observed values.  It seems like it could be useful, also could be applied more generally to discrete-data regressions with more than two categories.
 
When it comes to checking the model fit, I recommend binned residual plots, as discussed in  this 2000 article  with Yuri Goegebeur, Francis Tuerlinckx, and Iven Van Mechelen.</p><p>2 0.15566263 <a title="929-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Visualizing_Distributions_of_Covariance_Matrices.html">1477 andrew gelman stats-2012-08-30-Visualizing Distributions of Covariance Matrices</a></p>
<p>Introduction: Since weâ&euro;&trade;ve been  discussing  prior distributions on covariance matrices, I will recommend  this recent article  (coauthored with Tomoki Tokuda, Ben Goodrich, Iven Van Mechelen, and Francis Tuerlinckx) on their visualization:
  
We present some methods for graphing distributions of covariance matrices and demonstrate them on several models, including the Wishart, inverse-Wishart, and scaled inverse-Wishart families in different dimensions. Our visualizations follow the principle of decomposing a covariance matrix into scale parameters and correlations, pulling out marginal summaries where possible and using two and three-dimensional plots to reveal multivariate structure. Visualizing a distribution of covariance matrices is a step beyond visualizing a single covariance matrix or a single multivariate dataset. Our visualization methods are available through the R package VisCov.</p><p>3 0.13768044 <a title="929-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-09-Typo_in_Ghitza_and_Gelman_MRP_paper.html">2095 andrew gelman stats-2013-11-09-Typo in Ghitza and Gelman MRP paper</a></p>
<p>Introduction: Devin Caughey points out a typo in the second column of page 765 of  our AJPS paper .  Here’s what we have:
 
 
 
The typo is in the third line of the second paragraph above.  Where it says y^*_j = y.bar^*_j n_j, it should be y^*_j = y.bar^*_j n^*_j.
 
 One frustrating system of the current system of journal publication is that I know of no way to append this correction to the published article.  I can put it here, but anyone who misses this is stuck.  And I don’t think the AJPS can link from the article to this post.  I contacted the editor of the AJPS who said there will be no problem appending the correction to the electronic version of the article.</p><p>4 0.13295126 <a title="929-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>Introduction: This article  is a discussion of a  paper  by Greg Francis for a special issue, edited by E. J. Wagenmakers, of the Journal of Mathematical Psychology.  Here’s what I wrote:
  
Much of statistical practice is an effort to reduce or deny variation and uncertainty. The reduction is done through standardization, replication, and other practices of experimental design, with the idea being to isolate and stabilize the quantity being estimated and then average over many cases. Even so, however, uncertainty persists, and statistical hypothesis testing is in many ways an endeavor to deny this, by reporting binary accept/reject decisions.


Classical statistical methods produce binary statements, but there is no reason to assume that the world works that way. Expressions such as Type 1 error, Type 2 error, false positive, and so on, are based on a model in which the world is divided into real and non-real effects. To put it another way, I understand the general scientific distinction of real vs</p><p>5 0.12912759 <a title="929-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>Introduction: In response to our  recent posting  of Amazon’s offer of Bayesian Data Analysis 3rd edition at 40% off, some people asked what was in this new edition, with more information beyond the beautiful cover image and the  brief paragraph  I’d posted earlier.
 
 Here’s  the table of contents.  The following sections have all-new material:
 
1.4 New introduction of BDA principles using a simple spell checking example 
2.9 Weakly informative prior distributions 
5.7 Weakly informative priors for hierarchical variance parameters 
7.1-7.4 Predictive accuracy for model evaluation and comparison 
10.6 Computing environments 
11.4 Split R-hat 
11.5 New measure of effective number of simulation draws 
13.7 Variational inference 
13.8 Expectation propagation 
13.9 Other approximations 
14.6 Regularization for regression models 
C.1 Getting started with R and Stan 
C.2 Fitting a hierarchical model in Stan 
C.4 Programming Hamiltonian Monte Carlo in R
 
And the new chapters: 
20 Basis function models 
2</p><p>6 0.12631062 <a title="929-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-27-Bridges_between_deterministic_and_probabilistic_models_for_binary_data.html">780 andrew gelman stats-2011-06-27-Bridges between deterministic and probabilistic models for binary data</a></p>
<p>7 0.12568295 <a title="929-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-09-Special_journal_issue_on_statistical_methods_for_the_social_sciences.html">24 andrew gelman stats-2010-05-09-Special journal issue on statistical methods for the social sciences</a></p>
<p>8 0.12210771 <a title="929-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Contest_for_developing_an_R_package_recommendation_system.html">324 andrew gelman stats-2010-10-07-Contest for developing an R package recommendation system</a></p>
<p>9 0.10318197 <a title="929-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-Infovis%2C_infographics%2C_and_data_visualization%3A__Where_I%E2%80%99m_coming_from%2C_and_where_I%E2%80%99d_like_to_go.html">878 andrew gelman stats-2011-08-29-Infovis, infographics, and data visualization:  Where I’m coming from, and where I’d like to go</a></p>
<p>10 0.10300528 <a title="929-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-25-Postdoc_position_on_psychometrics_and_network_modeling.html">2113 andrew gelman stats-2013-11-25-Postdoc position on psychometrics and network modeling</a></p>
<p>11 0.10249853 <a title="929-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-18-%E2%80%9CI_was_finding_the_test_so_irritating_and_boring_that_I_just_started_to_click_through_as_fast_as_I_could%E2%80%9D.html">351 andrew gelman stats-2010-10-18-“I was finding the test so irritating and boring that I just started to click through as fast as I could”</a></p>
<p>12 0.098214574 <a title="929-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>13 0.094955266 <a title="929-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-28-My_talk_at_American_University.html">376 andrew gelman stats-2010-10-28-My talk at American University</a></p>
<p>14 0.094123833 <a title="929-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-Displaying_a_fitted_multilevel_model.html">328 andrew gelman stats-2010-10-08-Displaying a fitted multilevel model</a></p>
<p>15 0.090924114 <a title="929-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>16 0.087004542 <a title="929-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-20-Ugly_ugly_ugly.html">1684 andrew gelman stats-2013-01-20-Ugly ugly ugly</a></p>
<p>17 0.083621003 <a title="929-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-Hypothesis_testing_with_multiple_imputations.html">799 andrew gelman stats-2011-07-13-Hypothesis testing with multiple imputations</a></p>
<p>18 0.083559185 <a title="929-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-31-A_data_visualization_manifesto.html">61 andrew gelman stats-2010-05-31-A data visualization manifesto</a></p>
<p>19 0.0804905 <a title="929-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-R_needs_a_good_function_to_make_line_plots.html">252 andrew gelman stats-2010-09-02-R needs a good function to make line plots</a></p>
<p>20 0.079884112 <a title="929-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.109), (1, 0.05), (2, 0.004), (3, 0.035), (4, 0.08), (5, -0.074), (6, -0.051), (7, -0.004), (8, 0.034), (9, 0.013), (10, 0.027), (11, 0.018), (12, -0.068), (13, -0.005), (14, -0.028), (15, 0.001), (16, 0.039), (17, -0.027), (18, -0.029), (19, -0.008), (20, 0.023), (21, 0.007), (22, 0.019), (23, -0.048), (24, 0.028), (25, -0.006), (26, -0.003), (27, -0.015), (28, 0.029), (29, 0.005), (30, 0.014), (31, 0.024), (32, -0.01), (33, -0.012), (34, -0.018), (35, -0.016), (36, 0.002), (37, -0.026), (38, 0.003), (39, -0.003), (40, -0.001), (41, 0.004), (42, 0.043), (43, 0.034), (44, 0.017), (45, -0.003), (46, -0.025), (47, -0.011), (48, 0.028), (49, -0.007)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96599174 <a title="929-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-27-Visual_diagnostics_for_discrete-data_regressions.html">929 andrew gelman stats-2011-09-27-Visual diagnostics for discrete-data regressions</a></p>
<p>Introduction: Jeff asked me what I thought of  this  recent AJPS article by Brian Greenhill, Michael Ward, and Audrey Sacks, “The Separation Plot: A New Visual Method for Evaluating the Fit of Binary Models.”  It’s similar to a graph of observed vs. predicted values, but using color rather than the y-axis to display the observed values.  It seems like it could be useful, also could be applied more generally to discrete-data regressions with more than two categories.
 
When it comes to checking the model fit, I recommend binned residual plots, as discussed in  this 2000 article  with Yuri Goegebeur, Francis Tuerlinckx, and Iven Van Mechelen.</p><p>2 0.70856249 <a title="929-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-08-Belief_aggregation.html">2162 andrew gelman stats-2014-01-08-Belief aggregation</a></p>
<p>Introduction: Johannes Castner writes:
  
Suppose there are k scientists, each with her own model (Bayesian Net) over m random variables.  Then, because the space of Bayesian Nets over these m variables, with the square-root of the Jensen-Shannon Divergence as a distance metric is a closed and bounded space, there exists one unique Bayes Net that is a mixture of the k model joint-distributions which is at equal distance to each of the k models and may be called a “consensus graph.”  This consensus graph is in turn a Bayes Net, which can be updated with evidence.  The first question is: What are the conditions for which, given a new bit of evidence, the updated consensus graph is exactly the same graph as the consensus graph of the updated k Bayes Nets? In other words, if we arrive at a synthetic model from k models and then update this synthetic model, under what conditions is this the same thing as if we had first updated all k models and then build a synthesis.  The second question is: If these ar</p><p>3 0.69934493 <a title="929-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-07-Bayesian_hierarchical_model_for_the_prediction_of_soccer_results.html">20 andrew gelman stats-2010-05-07-Bayesian hierarchical model for the prediction of soccer results</a></p>
<p>Introduction: Gianluca Baio sends along  this article  (coauthored with Marta Blangiardo):
  
 
The problem of modelling football [soccer] data has become increasingly popular in the last few years and many different models have been proposed with the aim of estimating the characteristics that bring a team to lose or win a game, or to predict the score of a particular match. We propose a Bayesian hierarchical model to address both these aims and test its predictive strength on data about the Italian Serie A championship 1991-1992. To overcome the issue of overshrinkage produced by the Bayesian hierarchical model, we specify a more complex mixture model that results in better fit to the observed data. We test its performance using an example about the Italian Serie A championship 2007-2008.
 

 
I like the use of the hierarchical model and the focus on prediction.  I’m wondering, though, shouldn’t the model include a correlation between the “attack” and “defense” parameters?  Or maybe that’s in the m</p><p>4 0.6947313 <a title="929-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Let%E2%80%99s_play_%E2%80%9CGuess_the_smoother%E2%80%9D%21.html">1283 andrew gelman stats-2012-04-26-Let’s play “Guess the smoother”!</a></p>
<p>Introduction: Andre de Boer writes:
  
In my profession as a risk manager I encountered this graph:


   


I can’t figure out what kind of regression this is, would you be so kind to enlighten me? 
The points represent (maturity,yield) of bonds.
  
My reply:  That’s a fun problem, reverse-engineering a curve fit!  My first guess is lowess, although it seems too flat and asympoty on the right side of the graph to be lowess.  Maybe a Gaussian process?  Looks too smooth to be a spline.  I guess I’ll go with my original guess, on the theory that lowess is the most accessible smoother out there, and if someone fit something much more complicated they’d make more of a big deal about it.  On the other hand, if the curve is an automatic output of some software (Excel? Stata?) then it could be just about anything.
 
Does anyone have any ideas?</p><p>5 0.69378918 <a title="929-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-23-Lowess_is_great.html">293 andrew gelman stats-2010-09-23-Lowess is great</a></p>
<p>Introduction: I came across this  old blog entry  that was just hilarious–but it’s from 2005 so I think most of you haven’t seen it.
 
It’s the story of two people named Martin Voracek and Maryanne Fisher who in a published discussion criticized lowess (a justly popular nonlinear regression method).
 
Curious, I looked up “Martin Voracek” on the web and found an article in the British Medical Journal whose the title promised “trend analysis.”  I was wondering what statistical methods they used–something more sophisticated than lowess, perhaps?
 
They did have one figure, and here it is:
 
 
 
Voracek and Fisher, the critics of lowess, are fit straight lines to data to clearly nonlinear data!  It’s most obvious in their leftmost graph.  Voracek and Fisher get full credit for showing scatterplots, but hey . . . they should try lowess next time!  What’s really funny in the graph are the little dotted lines indicating inferential uncertainty in the regression lines–all under the assumption of linearity,</p><p>6 0.68458331 <a title="929-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-08-%E2%80%9CWhat_do_you_think_about_curved_lines_connecting_discrete_data-points%3F%E2%80%9D.html">134 andrew gelman stats-2010-07-08-“What do you think about curved lines connecting discrete data-points?”</a></p>
<p>7 0.6729247 <a title="929-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-28-Using_predator-prey_models_on_the_Canadian_lynx_series.html">1141 andrew gelman stats-2012-01-28-Using predator-prey models on the Canadian lynx series</a></p>
<p>8 0.66949582 <a title="929-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>9 0.66903257 <a title="929-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-21-Model_complexity_as_a_function_of_sample_size.html">1543 andrew gelman stats-2012-10-21-Model complexity as a function of sample size</a></p>
<p>10 0.66542101 <a title="929-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<p>11 0.66249871 <a title="929-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-Displaying_a_fitted_multilevel_model.html">328 andrew gelman stats-2010-10-08-Displaying a fitted multilevel model</a></p>
<p>12 0.66114855 <a title="929-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-14-Cool-ass_signal_processing_using_Gaussian_processes_%28birthdays_again%29.html">1379 andrew gelman stats-2012-06-14-Cool-ass signal processing using Gaussian processes (birthdays again)</a></p>
<p>13 0.6600247 <a title="929-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-The_R_code_for_those_time-use_graphs.html">672 andrew gelman stats-2011-04-20-The R code for those time-use graphs</a></p>
<p>14 0.65908992 <a title="929-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Stephen_Kosslyn%E2%80%99s_principles_of_graphics_and_one_more%3A__There%E2%80%99s_no_need_to_cram_everything_into_a_single_plot.html">1609 andrew gelman stats-2012-12-06-Stephen Kosslyn’s principles of graphics and one more:  There’s no need to cram everything into a single plot</a></p>
<p>15 0.65695137 <a title="929-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-17-Graphs_showing_uncertainty_using_lighter_intensities_for_the_lines_that_go_further_from_the_center%2C_to_de-emphasize_the_edges.html">1461 andrew gelman stats-2012-08-17-Graphs showing uncertainty using lighter intensities for the lines that go further from the center, to de-emphasize the edges</a></p>
<p>16 0.65483189 <a title="929-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-25-A_statistical_graphics_course_and_statistical_graphics_advice.html">2266 andrew gelman stats-2014-03-25-A statistical graphics course and statistical graphics advice</a></p>
<p>17 0.65182292 <a title="929-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>18 0.65005583 <a title="929-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-09-Special_journal_issue_on_statistical_methods_for_the_social_sciences.html">24 andrew gelman stats-2010-05-09-Special journal issue on statistical methods for the social sciences</a></p>
<p>19 0.63772303 <a title="929-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>20 0.6375134 <a title="929-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-31-A_data_visualization_manifesto.html">61 andrew gelman stats-2010-05-31-A data visualization manifesto</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.03), (24, 0.207), (34, 0.343), (70, 0.025), (84, 0.026), (90, 0.027), (98, 0.022), (99, 0.196)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.87785077 <a title="929-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-27-Visual_diagnostics_for_discrete-data_regressions.html">929 andrew gelman stats-2011-09-27-Visual diagnostics for discrete-data regressions</a></p>
<p>Introduction: Jeff asked me what I thought of  this  recent AJPS article by Brian Greenhill, Michael Ward, and Audrey Sacks, “The Separation Plot: A New Visual Method for Evaluating the Fit of Binary Models.”  It’s similar to a graph of observed vs. predicted values, but using color rather than the y-axis to display the observed values.  It seems like it could be useful, also could be applied more generally to discrete-data regressions with more than two categories.
 
When it comes to checking the model fit, I recommend binned residual plots, as discussed in  this 2000 article  with Yuri Goegebeur, Francis Tuerlinckx, and Iven Van Mechelen.</p><p>2 0.85547268 <a title="929-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-10-Statisticians%E2%80%99_abbreviations_are_even_less_interesting_than_these%21.html">1257 andrew gelman stats-2012-04-10-Statisticians’ abbreviations are even less interesting than these!</a></p>
<p>Introduction: From  AC, AI, and AIH to WAHM, WOHM, and WM.
 
P.S.  That was all pretty pointless, so I’ll throw in  this  viral Jim Henson link (from the same source) for free.</p><p>3 0.8400209 <a title="929-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<p>Introduction: Stephen Collins writes:
  
I’m reading your Multilevel modeling book and am trying to apply it to my work.  I’m concerned with how to estimate a random intercept model if there are hundreds/thousands of levels.  In the Gibbs sampling, am I sampling a parameter for each level?  Or, just the hyper-parameters?  In other words, say I had 500 zipcode intercepts modeled as ~ N(m,s).  Would my posterior be two dimensional, sampling for “m” and “s,” or would it have 502 dimensions?
  
My reply:  Indeed you will have hundreds or thousands of parameters—or, in classical terms, hundreds or thousands of predictive quantities.  But that’s ok.  Even if none of those predictions is precise, you’re learning  about the model.
 
See page 526 of the book for more discussion of the number of parameters in a multilevel model.</p><p>4 0.82516956 <a title="929-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-23-AI_Stats_conference_on_Stan_etc..html">1911 andrew gelman stats-2013-06-23-AI Stats conference on Stan etc.</a></p>
<p>Introduction: Jaakko Peltonen writes:
  
The Seventeenth International Conference on Artificial Intelligence and Statistics (http://www.aistats.org) will be next April in Reykjavik, Iceland. AISTATS is an interdisciplinary conference at the intersection of computer science, artificial intelligence, machine learning, statistics, and related areas.
  
  
  
============================================================================== 
AISTATS 2014 Call for Papers 
Seventeenth International Conference on Artificial Intelligence and Statistics 
April 22 – 25, 2014, Reykjavik, Iceland


http://www.aistats.org


Colocated with a MLSS Machine Learning Summer School 
==============================================================================


AISTATS is an interdisciplinary gathering of researchers at the intersection of computer science, artificial intelligence, machine learning, statistics, and related areas. Since its inception in 1985, the primary goal of AISTATS has been to broaden research in the</p><p>5 0.81501949 <a title="929-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-18-More_studies_on_the_economic_effects_of_climate_change.html">1501 andrew gelman stats-2012-09-18-More studies on the economic effects of climate change</a></p>
<p>Introduction: After writing  yesterday’s post , I was going through Solomon Hsiang’s blog and found  a post  pointing to three studies from researchers at business schools:
  
Severe Weather and Automobile Assembly Productivity


Gérard P. Cachon, Santiago Gallino and Marcelo Olivares


Abstract: It is expected that climate change could lead to an increased frequency of severe weather. In turn, severe weather intuitively should hamper the productivity of work that occurs outside. But what is the effect of rain, snow, fog, heat and wind on work that occurs indoors, such as the production of automobiles? Using weekly production data from 64 automobile plants in the United States over a ten-year period, we ﬁnd that adverse weather conditions lead to a signiﬁcant reduction in production. For example, one additional day of high wind advisory by the National Weather Service (i.e., maximum winds generally in excess of 44 miles per hour) reduces production by 26%, which is comparable in order of magnitude t</p><p>6 0.80288613 <a title="929-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-23-Doug_Hibbs_on_the_fundamentals_in_2010.html">292 andrew gelman stats-2010-09-23-Doug Hibbs on the fundamentals in 2010</a></p>
<p>7 0.7983169 <a title="929-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-04-The_Case_for_More_False_Positives_in_Anti-doping_Testing.html">648 andrew gelman stats-2011-04-04-The Case for More False Positives in Anti-doping Testing</a></p>
<p>8 0.76431239 <a title="929-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-17-%E2%80%9C2%25_per_degree_Celsius_._._._the_magic_number_for_how_worker_productivity_responds_to_warm-hot_temperatures%E2%80%9D.html">1500 andrew gelman stats-2012-09-17-“2% per degree Celsius . . . the magic number for how worker productivity responds to warm-hot temperatures”</a></p>
<p>9 0.76363969 <a title="929-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-23-Life_in_the_C-suite%3A__A_graph_that_is_both_ugly_and_bad%2C_and_an_unrelated_story.html">1734 andrew gelman stats-2013-02-23-Life in the C-suite:  A graph that is both ugly and bad, and an unrelated story</a></p>
<p>10 0.75774848 <a title="929-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-09-Rasmussen_sez%3A__%E2%80%9C108%25_of_Respondents_Say_._._.%E2%80%9D.html">135 andrew gelman stats-2010-07-09-Rasmussen sez:  “108% of Respondents Say . . .”</a></p>
<p>11 0.75438571 <a title="929-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-02-Covariate_Adjustment_in_RCT_-_Model_Overfitting_in_Multilevel_Regression.html">936 andrew gelman stats-2011-10-02-Covariate Adjustment in RCT - Model Overfitting in Multilevel Regression</a></p>
<p>12 0.74631715 <a title="929-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-10-The_blog_of_the_Cultural_Cognition_Project.html">1111 andrew gelman stats-2012-01-10-The blog of the Cultural Cognition Project</a></p>
<p>13 0.72946131 <a title="929-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-13-Hey%2C_you%21__Don%E2%80%99t_take_that_class%21.html">956 andrew gelman stats-2011-10-13-Hey, you!  Don’t take that class!</a></p>
<p>14 0.72289848 <a title="929-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-19-What_makes_a_statistician_look_like_a_hero%3F.html">2031 andrew gelman stats-2013-09-19-What makes a statistician look like a hero?</a></p>
<p>15 0.71830201 <a title="929-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-04-Special_discount_on_Stan%21__%24999_cheaper_than_Revolution_R%21.html">2198 andrew gelman stats-2014-02-04-Special discount on Stan!  $999 cheaper than Revolution R!</a></p>
<p>16 0.71411061 <a title="929-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-05-Cleaning_up_science.html">1842 andrew gelman stats-2013-05-05-Cleaning up science</a></p>
<p>17 0.71320689 <a title="929-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-01-The_placebo_effect_in_pharma.html">388 andrew gelman stats-2010-11-01-The placebo effect in pharma</a></p>
<p>18 0.71268708 <a title="929-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-15-Wacky_priors_can_work_well%3F.html">1723 andrew gelman stats-2013-02-15-Wacky priors can work well?</a></p>
<p>19 0.68845987 <a title="929-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-01-My_course_this_fall_on_Bayesian_Computation.html">884 andrew gelman stats-2011-09-01-My course this fall on Bayesian Computation</a></p>
<p>20 0.68801457 <a title="929-lda-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-25-Revised_statistical_standards_for_evidence_%28comments_to_Val_Johnson%E2%80%99s_comments_on_our_comments_on_Val%E2%80%99s_comments_on_p-values%29.html">2305 andrew gelman stats-2014-04-25-Revised statistical standards for evidence (comments to Val Johnson’s comments on our comments on Val’s comments on p-values)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
