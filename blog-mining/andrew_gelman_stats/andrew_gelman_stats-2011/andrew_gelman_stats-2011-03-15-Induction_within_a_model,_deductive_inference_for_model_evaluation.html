<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-614" href="#">andrew_gelman_stats-2011-614</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-614-html" href="http://andrewgelman.com/2011/03/15/induction_withi/">html</a></p><p>Introduction: Jonathan Livengood writes:
  
I have a couple of questions on your paper with Cosma Shalizi on “Philosophy and the practice of Bayesian statistics.”


First, you distinguish between inductive approaches and hypothetico-deductive approaches to inference and locate statistical practice (at least, the practice of model building and checking) on the hypothetico-deductive side.  Do you think that there are any interesting elements of statistical practice that are properly inductive?  For example, suppose someone is playing around with a system that more or less resembles a toy model, like drawing balls from an urn or some such, and where the person has some well-defined priors.  The person makes a number of draws from the urn and applies Bayes theorem to get a posterior.  On your view, is that person making an induction?  If so, how much space is there in statistical practice for genuine inductions like this?


Second, I agree with you that one ought to distinguish induction from other kind</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ”   First, you distinguish between inductive approaches and hypothetico-deductive approaches to inference and locate statistical practice (at least, the practice of model building and checking) on the hypothetico-deductive side. [sent-2, score-1.356]
</p><p>2 Do you think that there are any interesting elements of statistical practice that are properly inductive? [sent-3, score-0.224]
</p><p>3 For example, suppose someone is playing around with a system that more or less resembles a toy model, like drawing balls from an urn or some such, and where the person has some well-defined priors. [sent-4, score-0.378]
</p><p>4 The person makes a number of draws from the urn and applies Bayes theorem to get a posterior. [sent-5, score-0.249]
</p><p>5 On your view, is that person making an induction? [sent-6, score-0.175]
</p><p>6 If so, how much space is there in statistical practice for genuine inductions like this? [sent-7, score-0.212]
</p><p>7 Second, I agree with you that one ought to distinguish induction from other kinds of risky inference, but I’m not sure that I see a clear payoff from making the distinction. [sent-8, score-0.655]
</p><p>8 I’m worried because a lot of smart philosophers just don’t distinguish “inductive” inferences from “risky” inferences. [sent-9, score-0.255]
</p><p>9 But if that is right, then a model that survives attempts at falsification and then gets used to make predictions is still going to be open to a Humean attack. [sent-14, score-0.305]
</p><p>10 Rather, it’s a variety of induction and suffers all the same difficulties as simple enumerative induction. [sent-16, score-0.413]
</p><p>11 So, I guess what I’d like to know is in what ways you think the philosophers are misled here. [sent-17, score-0.257]
</p><p>12 What is the value / motivation for distinguishing induction from hypothetico-deductive inference? [sent-18, score-0.333]
</p><p>13 I replied:    My short answer is that inductive inference of the balls-in-urns variety takes place within a model, and the deductive Popperian reasoning takes place when evaluating a model. [sent-21, score-1.249]
</p><p>14 I think of “Popper” more as a totem than as an actual person or body of work. [sent-23, score-0.256]
</p><p>15 Crudely speaking, I think of models as a language, with models created in the same way that we create sentences, by working with recursive structures. [sent-25, score-0.297]
</p><p>16 When you say that inductive inference takes place within a model, are you claiming that an inductive inference is justified just to the extent that the model within which the induction takes place is justified (or approximately correct or some such — I know you won’t say “true” here …)? [sent-30, score-2.727]
</p><p>17 If so, then under what conditions do you think a model is justified? [sent-31, score-0.313]
</p><p>18 That is, under what conditions do you think one is justified in making *predictions* on the basis of a model? [sent-32, score-0.427]
</p><p>19 There will (almost) always be some assumptions required, some sense in which any prediction is conditional on  something . [sent-35, score-0.246]
</p><p>20 Stepping back a bit, I’d say that scientists get experience with certain models, they work well for prediction until they don’t. [sent-36, score-0.182]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('inductive', 0.375), ('hume', 0.333), ('induction', 0.271), ('justified', 0.209), ('popper', 0.203), ('inference', 0.169), ('model', 0.164), ('salmon', 0.152), ('practice', 0.15), ('livengood', 0.143), ('urn', 0.143), ('distinguish', 0.136), ('takes', 0.13), ('philosophy', 0.12), ('philosophers', 0.119), ('risky', 0.115), ('place', 0.11), ('prediction', 0.109), ('person', 0.106), ('variety', 0.081), ('within', 0.08), ('models', 0.076), ('humean', 0.076), ('totem', 0.076), ('conditions', 0.075), ('approaches', 0.075), ('think', 0.074), ('predictions', 0.073), ('say', 0.073), ('recursive', 0.071), ('conditional', 0.071), ('mind', 0.069), ('making', 0.069), ('resembles', 0.068), ('survives', 0.068), ('assumptions', 0.066), ('solves', 0.066), ('crudely', 0.066), ('payoff', 0.064), ('deductive', 0.064), ('misled', 0.064), ('distinguishing', 0.062), ('locate', 0.062), ('genuine', 0.062), ('stepping', 0.061), ('balls', 0.061), ('embarrassing', 0.061), ('suffers', 0.061), ('popperian', 0.06), ('famously', 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="614-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>Introduction: Jonathan Livengood writes:
  
I have a couple of questions on your paper with Cosma Shalizi on “Philosophy and the practice of Bayesian statistics.”


First, you distinguish between inductive approaches and hypothetico-deductive approaches to inference and locate statistical practice (at least, the practice of model building and checking) on the hypothetico-deductive side.  Do you think that there are any interesting elements of statistical practice that are properly inductive?  For example, suppose someone is playing around with a system that more or less resembles a toy model, like drawing balls from an urn or some such, and where the person has some well-defined priors.  The person makes a number of draws from the urn and applies Bayes theorem to get a posterior.  On your view, is that person making an induction?  If so, how much space is there in statistical practice for genuine inductions like this?


Second, I agree with you that one ought to distinguish induction from other kind</p><p>2 0.24544403 <a title="614-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-03-%E2%80%9CThe_Case_for_Inductive_Theory_Building%E2%80%9D.html">1652 andrew gelman stats-2013-01-03-“The Case for Inductive Theory Building”</a></p>
<p>Introduction: Professor of business management Edwin Locke sent me  an article :
  
This paper argues that theory building in the social sciences, management and psychology included, should be inductive. It begins by critiquing contemporary philosophy of science, e.g., Popper’s falsifiability theory, his stress on deduction, and the hypothetico-deductive method. Next I present some history of the concept of induction in philosophy and of inductive theory building in the hard sciences (e.g., Aristotle, Bacon, Newton). This is followed by three examples of successful theory building by induction in psychology and management (Beck’s theory, Bandura’s social-cognitive theory, goal setting theory). The paper concludes with some suggested guidelines for successful theory building through induction and some new policies that journal editors might encourage.
  
Like most social scientists (but maybe not most  Bayesians ), I’m pretty much a  Popperian  myself, so I was interested to see someone taking such a</p><p>3 0.19911288 <a title="614-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>Introduction: I’ve been writing a lot about my philosophy of Bayesian statistics and how it fits into Popper’s ideas about falsification and Kuhn’s ideas about scientific revolutions.
 
 Here’s  my long, somewhat technical paper with Cosma Shalizi. 
 Here’s  our shorter overview for the volume on the philosophy of social science. 
 Here’s  my latest try (for an online symposium), focusing on the key issues.
 
I’m pretty happy with my approach–the familiar idea that Bayesian data analysis iterates the three steps of model building, inference, and model checking–but it does have some unresolved (maybe unresolvable) problems.  Here are a couple mentioned in the third of the above links.
 
Consider a simple model with independent data y_1, y_2, .., y_10 ~ N(θ,σ^2), with a prior distribution θ ~ N(0,10^2) and σ known and taking on some value of approximately 10. Inference about μ is straightforward, as is model checking, whether based on graphs or numerical summaries such as the sample variance and skewn</p><p>4 0.19710188 <a title="614-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Popper_and_Jaynes.html">2007 andrew gelman stats-2013-09-03-Popper and Jaynes</a></p>
<p>Introduction: Deborah Mayo quotes me as saying, “Popper has argued (convincingly, in my opinion) that scientific inference is not inductive but deductive.”  She then  follows up  with:
  
Gelman employs significance test-type reasoning to reject a model when the data sufficiently disagree.


Now, strictly speaking, a model falsification, even to inferring something as weak as “the model breaks down,” is not purely deductive, but Gelman is right to see it as about as close as one can get, in statistics, to a deductive falsification of a model. But where does that leave him as a Jaynesian?
  
My reply:
 
I was influenced by reading a toy example from Jaynes’s book where he sets up a model (for the probability of a die landing on each of its six sides) based on first principles, then presents some data that contradict the model, then expands the model.
 
I’d seen very little of this sort of this reasoning before in statistics!  In physics it’s the standard way to go:  you set up a model based on physic</p><p>5 0.19543524 <a title="614-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>Introduction: In  my remarks  on Arrow’s theorem (the weak form of Arrow’s Theorem is that any result can be published no more than five times. The strong form is that every result will be published five times), I meant no criticism of Bruno Frey, the author of the articles in question:  I agree that it can be a contribution to publish in multiple places.  Regarding the evaluation of contributions, it should be possible to evaluate research contributions and also evaluate communication.  One problem is that communication is both under- and over-counted.  It’s undercounted in that we mostly get credit for original ideas not for exposition; it’s overcounted in that we need communication skills to publish in the top journals.  But I don’t think these two biases cancel out.
 
The real reason I’m bringing this up, though, is because Arrow’s theorem happened to me recently and in interesting way.  Here’s the story.
 
Two years ago I was contacted by Harold Kincaid to write a chapter on Bayesian statistics</p><p>6 0.19050278 <a title="614-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>7 0.18700029 <a title="614-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>8 0.17350926 <a title="614-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-23-Philosophy%3A__Pointer_to_Salmon.html">1181 andrew gelman stats-2012-02-23-Philosophy:  Pointer to Salmon</a></p>
<p>9 0.17281517 <a title="614-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>10 0.17183979 <a title="614-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<p>11 0.17095265 <a title="614-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>12 0.16495359 <a title="614-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>13 0.1606828 <a title="614-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>14 0.15552467 <a title="614-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>15 0.15210719 <a title="614-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>16 0.14641097 <a title="614-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>17 0.14382195 <a title="614-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-08-Bayes-Godel.html">998 andrew gelman stats-2011-11-08-Bayes-Godel</a></p>
<p>18 0.1421466 <a title="614-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>19 0.13956553 <a title="614-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-09-Popper%E2%80%99s_great%2C_but_don%E2%80%99t_bother_with_his_theory_of_probability.html">23 andrew gelman stats-2010-05-09-Popper’s great, but don’t bother with his theory of probability</a></p>
<p>20 0.13922963 <a title="614-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-04-Patterns.html">556 andrew gelman stats-2011-02-04-Patterns</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.217), (1, 0.116), (2, -0.047), (3, 0.047), (4, -0.091), (5, 0.013), (6, -0.032), (7, 0.014), (8, 0.143), (9, -0.03), (10, -0.01), (11, -0.006), (12, -0.077), (13, 0.003), (14, -0.075), (15, 0.019), (16, 0.058), (17, -0.003), (18, -0.003), (19, 0.043), (20, -0.029), (21, -0.063), (22, -0.024), (23, -0.034), (24, -0.005), (25, 0.011), (26, 0.009), (27, 0.032), (28, -0.032), (29, 0.005), (30, 0.012), (31, -0.021), (32, -0.003), (33, 0.003), (34, -0.016), (35, -0.0), (36, -0.008), (37, -0.011), (38, 0.001), (39, -0.053), (40, 0.015), (41, -0.032), (42, 0.028), (43, 0.047), (44, -0.003), (45, 0.0), (46, -0.021), (47, -0.021), (48, 0.014), (49, -0.02)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96669835 <a title="614-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>Introduction: Jonathan Livengood writes:
  
I have a couple of questions on your paper with Cosma Shalizi on “Philosophy and the practice of Bayesian statistics.”


First, you distinguish between inductive approaches and hypothetico-deductive approaches to inference and locate statistical practice (at least, the practice of model building and checking) on the hypothetico-deductive side.  Do you think that there are any interesting elements of statistical practice that are properly inductive?  For example, suppose someone is playing around with a system that more or less resembles a toy model, like drawing balls from an urn or some such, and where the person has some well-defined priors.  The person makes a number of draws from the urn and applies Bayes theorem to get a posterior.  On your view, is that person making an induction?  If so, how much space is there in statistical practice for genuine inductions like this?


Second, I agree with you that one ought to distinguish induction from other kind</p><p>2 0.86385024 <a title="614-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>Introduction: David Rohde writes:
  
 
I have been thinking a lot lately about your Bayesian model checking approach.  This is in part because I have been working on exploratory data analysis and wishing to avoid controversy and mathematical statistics we omitted model checking from our discussion.  This is something that the refereeing process picked us up on and we ultimately added a critical discussion of null-hypothesis testing to  our paper .  The exploratory technique we discussed was essentially a 2D histogram approach, but we used Polya models as a formal model for the histogram.  We are currently working on a new paper, and we are thinking through how or if we should do “confirmatory analysis” or model checking in the paper.


What I find most admirable about your statistical work is that you clearly use the Bayesian approach to do useful applied statistical analysis.  My own attempts at applied Bayesian analysis makes me greatly admire your applied successes.  On the other hand it may be t</p><p>3 0.85626209 <a title="614-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>Introduction: In response to  this article  by Cosma Shalizi and myself on the philosophy of Bayesian statistics, David Hogg writes:
  
I [Hogg] agree–even in physics and astronomy–that the models are not “True” in the God-like sense of being absolute reality (that is, I am not a realist); and I  have argued  (a philosophically very naive 
paper, but hey, I was new to all this) that for pretty fundamental reasons we could never arrive at the True (with a capital “T”) model of the Universe.  The goal of inference is to find the “best” model, where “best” might have something to do with prediction, or explanation, or message length, or (horror!) our utility.  Needless to say, most of my physics friends *are* realists, even in the face of “effective theories” as Newtonian mechanics is an effective theory of GR and GR is an effective theory of “quantum gravity” (this plays to your point, because if you think any theory is possibly an effective theory, how could you ever find Truth?).  I also liked the i</p><p>4 0.8447699 <a title="614-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>Introduction: In my comments on David MacKay’s 2003 book on Bayesian inference, I  wrote  that I hate all the Occam-factor stuff that MacKay talks about, and I linked to  this quote  from Radford Neal:
  
Sometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.
  
MacKay replied as follows:
  
When you said you disagree with me on Occam factors I think what you meant was that you agree with me on them.  I’ve read your post on the topic and completely agreed with you (and Radford) that we should be using models the size of a  house, models that we believe in, and that anyone who thinks it is a good idea to  bias the model toward</p><p>5 0.8444708 <a title="614-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>Introduction: Astrophysicist Andrew Jaffe pointed me to  this and discussion  of my  philosophy  of statistics (which is, in turn, my rational reconstruction of the statistical practice of Bayesians such as Rubin and Jaynes).  Jaffe’s summary is fair enough and I only disagree in a few points: 
   
1.  Jaffe writes:
  
Subjective probability, at least the way it is actually used by practicing scientists, is a sort of “as-if” subjectivity — how would an agent reason if her beliefs were reflected in a certain set of probability distributions? This is why when I discuss probability I try to make the pedantic point that all probabilities are conditional, at least on some background prior information or context.
  
I agree, and my problem with the usual procedures used for Bayesian model comparison and Bayesian model averaging is not that these approaches are subjective but that the particular models being considered don’t make sense.  I’m thinking of the sorts of models that say the truth is either A or</p><p>6 0.83872688 <a title="614-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Valencia%3A___Summer_of_1991.html">72 andrew gelman stats-2010-06-07-Valencia:   Summer of 1991</a></p>
<p>7 0.83427787 <a title="614-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>8 0.82662964 <a title="614-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-01-Tukey%E2%80%99s_philosophy.html">496 andrew gelman stats-2011-01-01-Tukey’s philosophy</a></p>
<p>9 0.81485367 <a title="614-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>10 0.80688924 <a title="614-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-19-The_%E2%80%9Ceither-or%E2%80%9D_fallacy_of_believing_in_discrete_models%3A__an_example_of_folk_statistics.html">217 andrew gelman stats-2010-08-19-The “either-or” fallacy of believing in discrete models:  an example of folk statistics</a></p>
<p>11 0.80026817 <a title="614-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Popper_and_Jaynes.html">2007 andrew gelman stats-2013-09-03-Popper and Jaynes</a></p>
<p>12 0.79344922 <a title="614-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>13 0.79242051 <a title="614-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>14 0.79102486 <a title="614-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-Rob_Kass_on_statistical_pragmatism%2C_and_my_reactions.html">317 andrew gelman stats-2010-10-04-Rob Kass on statistical pragmatism, and my reactions</a></p>
<p>15 0.7851032 <a title="614-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>16 0.7840361 <a title="614-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-25-Incoherence_of_Bayesian_data_analysis.html">1510 andrew gelman stats-2012-09-25-Incoherence of Bayesian data analysis</a></p>
<p>17 0.78136951 <a title="614-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>18 0.77541649 <a title="614-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>19 0.77419466 <a title="614-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<p>20 0.77164829 <a title="614-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.019), (15, 0.026), (16, 0.068), (21, 0.019), (24, 0.137), (27, 0.012), (63, 0.028), (66, 0.031), (76, 0.012), (77, 0.138), (84, 0.028), (86, 0.043), (92, 0.013), (99, 0.317)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98583293 <a title="614-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-01-Wolfram_on_Mandelbrot.html">1784 andrew gelman stats-2013-04-01-Wolfram on Mandelbrot</a></p>
<p>Introduction: The most perfect pairing of author and subject since Nicholson Baker and John Updike.  Here’s  Wolfram on the great researcher of  fractals :
  
In his way, Mandelbrot paid me some great compliments. When I was in my 20s, and he in his 60s, he would ask about my scientific work: “How can so many people take someone so young so seriously?” In 2002, my book “A New Kind of Science”—in which I argued that many phenomena across science are the complex results of relatively simple, program-like rules—appeared. Mandelbrot seemed to see it as a direct threat, once declaring that “Wolfram’s ‘science’ is not new except when it is clearly wrong; it deserves to be completely disregarded.” In private, though, several mutual friends told me, he fretted that in the long view of history it would overwhelm his work.
  
In retrospect, I don’t think Mandelbrot had much to worry about on this account.
 
The  link  from the above review came from Peter Woit, who also points to a  review  by Brian Hayes wit</p><p>2 0.98344553 <a title="614-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-20-Ugly_ugly_ugly.html">1684 andrew gelman stats-2013-01-20-Ugly ugly ugly</a></p>
<p>Introduction: Denis Cote sends the  following , under the heading, “Some bad graphs for your enjoyment”:
 
 
 
To start with, they don’t know how to spell “color.”  Seriously, though, the graph is a mess.  The circular display implies a circular or periodic structure that isn’t actually in the data, the cramped display requires the use of an otherwise-unnecessary color code that makes it difficult to find or make sense of the information, the alphabetical ordering (without even supplying state names, only abbreviations) makes it further difficult to find any patterns.  It would be so much better, and even easier, to just display a set of small maps shading states on whether they have different laws.  But that’s part of the problem—the clearer graph would also be easier to make!  To get a distinctive graph, there needs to be some degree of difficulty.
 
The designers continue with these monstrosities:
 
 
 
Here they decide to display only 5 states at a time so that it’s really hard to see any big pi</p><p>3 0.97982919 <a title="614-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-28-Cool_job_opening_with_brilliant_researchers_at_Yahoo.html">978 andrew gelman stats-2011-10-28-Cool job opening with brilliant researchers at Yahoo</a></p>
<p>Introduction: Duncan Watts writes:
  
The Human Social Dynamics Group in Yahoo Research is seeking highly qualified candidates for a post-doctoral research scientist position.


The Human and Social Dynamics group is devoted to understanding the interplay between individual-level behavior (e.g. how people make decisions about what music they like, which dates to go on, or which groups to join) and the social environment in which individual behavior necessarily plays itself out. In particular, we are interested in:


* Structure and evolution of social groups and networks 
* Decision making, social influence, diffusion, and collective decisions 
* Networking and collaborative problem solving.


The intrinsically multi-disciplinary and cross-cutting nature of the subject demands an eclectic range of researchers, both in terms of domain-expertise  (e.g. decision sciences, social psychology, sociology) and technical skills (e.g. statistical analysis, mathematical modeling, computer simulations, design o</p><p>4 0.97898436 <a title="614-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-17-How_to_map_geographically-detailed_survey_responses%3F.html">1124 andrew gelman stats-2012-01-17-How to map geographically-detailed survey responses?</a></p>
<p>Introduction: David Sparks writes:
  
I am experimenting with the mapping/visualization of survey response data, with a particular focus on using transparency to convey uncertainty. See some examples  here .


Do you think the examples are successful at communicating both local values of the variable of interest, as well as the lack of information in certain places? Also, do you have any general advice for choosing an approach to spatially smoothing the data in a way that preserves local features, but prevents individual respondents from standing out? I have experimented a lot with smoothing in these maps, and the cost of preventing the Midwest and West from looking “spotty” is the oversmoothing of the Northeast.
  
My quick impression is that the graphs are more pretty than they are informative.  But “pretty” is not such a bad thing!  The conveying-information part is more difficult:  to me, the graphs seem to be displaying a somewhat confusing mix of opinion level and population density.  Consider</p><p>5 0.97727048 <a title="614-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-An_epithet_I_can_live_with.html">1604 andrew gelman stats-2012-12-04-An epithet I can live with</a></p>
<p>Introduction: Here . Indeed, I’d much rather be a legend than a myth.
 
I just want to clarify one thing.  Walter Hickey writes:
  
[Antony Unwin and Andrew Gelman] collaborated on this presentation where they take a hard look at what’s wrong with the recent trends of data visualization and infographics.


The takeaway is that while there have been great leaps in visualization technology, some of the visualizations that have garnered the highest praises have actually been lacking in a number of key areas.


Specifically, the pair does a takedown of the top visualizations of 2008 as decided by the popular statistics blog Flowing Data.
  
This is a fair summary, but I want to emphasize that, although our dislike of some award-winning visualizations is central to our argument, it is only the first part of our story.  As Antony and I worked more on our paper, and especially after seeing the discussions by Robert Kosara, Stephen Few, Hadley Wickham, and Paul Murrell (all to appear in Journal of Computati</p><p>6 0.97114944 <a title="614-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-09-Cognitive_psychology_research_helps_us_understand_confusion_of_Jonathan_Haidt_and_others_about_working-class_voters.html">1373 andrew gelman stats-2012-06-09-Cognitive psychology research helps us understand confusion of Jonathan Haidt and others about working-class voters</a></p>
<p>7 0.97010994 <a title="614-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Cool_one-day_miniconference_at_Columbia_Fri_12_Oct_on_computational_and_online_social_science.html">1481 andrew gelman stats-2012-09-04-Cool one-day miniconference at Columbia Fri 12 Oct on computational and online social science</a></p>
<p>8 0.96785569 <a title="614-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Statistician_cracks_Toronto_lottery.html">562 andrew gelman stats-2011-02-06-Statistician cracks Toronto lottery</a></p>
<p>9 0.95986879 <a title="614-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-07-Bing_is_preferred_to_Google_by_people_who_aren%E2%80%99t_like_me.html">2054 andrew gelman stats-2013-10-07-Bing is preferred to Google by people who aren’t like me</a></p>
<p>10 0.95889056 <a title="614-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-29-Roth_and_Amsterdam.html">57 andrew gelman stats-2010-05-29-Roth and Amsterdam</a></p>
<p>same-blog 11 0.95773053 <a title="614-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>12 0.95770693 <a title="614-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-17-My_proposal_for_making_college_admissions_fairer.html">93 andrew gelman stats-2010-06-17-My proposal for making college admissions fairer</a></p>
<p>13 0.95708394 <a title="614-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-04-Someone_is_wrong_on_the_internet.html">1561 andrew gelman stats-2012-11-04-Someone is wrong on the internet</a></p>
<p>14 0.95174026 <a title="614-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-18-More_forecasting_competitions.html">216 andrew gelman stats-2010-08-18-More forecasting competitions</a></p>
<p>15 0.94986033 <a title="614-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-14-Pourquoi_Google_search_est_devenu_plus_raisonnable%3F.html">207 andrew gelman stats-2010-08-14-Pourquoi Google search est devenu plus raisonnable?</a></p>
<p>16 0.94964695 <a title="614-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-21-Bayes_related.html">1948 andrew gelman stats-2013-07-21-Bayes related</a></p>
<p>17 0.94902951 <a title="614-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>18 0.94794774 <a title="614-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-04-When_is_there_%E2%80%9Chidden_structure_in_data%E2%80%9D_to_be_discovered%3F.html">1788 andrew gelman stats-2013-04-04-When is there “hidden structure in data” to be discovered?</a></p>
<p>19 0.94737828 <a title="614-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>20 0.94703078 <a title="614-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-05-The_greatest_works_of_statistics_never_published.html">128 andrew gelman stats-2010-07-05-The greatest works of statistics never published</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
