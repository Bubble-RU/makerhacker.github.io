<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>574 andrew gelman stats-2011-02-14-“The best data visualizations should stand on their own”?  I don’t think so.</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-574" href="#">andrew_gelman_stats-2011-574</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>574 andrew gelman stats-2011-02-14-“The best data visualizations should stand on their own”?  I don’t think so.</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-574-html" href="http://andrewgelman.com/2011/02/14/the_best_data_v/">html</a></p><p>Introduction: Jimmy pointed me to  this  blog by Drew Conway on word clouds.  I don’t have much to say about Conway’s specifics–word clouds aren’t really my thing, but I’m glad that people are thinking about how to do them better–but I did notice one phrase of his that I’ll dispute.  Conway writes
  
The best data visualizations should stand on their own . . .
  
I disagree.  I prefer the saying, “A picture plus 1000 words is better than two pictures or 2000 words.”  That is, I see a positive interaction between words and pictures or, to put it another way, diminishing returns for words or pictures on their own.  I don’t have any big theory for this, but I think, when expressed as a joint value function, my idea makes sense.  Also, I live this suggestion in my own work.  I typically accompany my graphs with long captions and I try to accompany my words with pictures (although I’m not doing it here, because with the software I use, it’s much easier to type more words than to find, scale, and insert i</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Jimmy pointed me to  this  blog by Drew Conway on word clouds. [sent-1, score-0.224]
</p><p>2 I don’t have much to say about Conway’s specifics–word clouds aren’t really my thing, but I’m glad that people are thinking about how to do them better–but I did notice one phrase of his that I’ll dispute. [sent-2, score-0.383]
</p><p>3 Conway writes    The best data visualizations should stand on their own . [sent-3, score-0.241]
</p><p>4 I prefer the saying, “A picture plus 1000 words is better than two pictures or 2000 words. [sent-7, score-1.093]
</p><p>5 ”  That is, I see a positive interaction between words and pictures or, to put it another way, diminishing returns for words or pictures on their own. [sent-8, score-2.014]
</p><p>6 I don’t have any big theory for this, but I think, when expressed as a joint value function, my idea makes sense. [sent-9, score-0.395]
</p><p>7 I typically accompany my graphs with long captions and I try to accompany my words with pictures (although I’m not doing it here, because with the software I use, it’s much easier to type more words than to find, scale, and insert images). [sent-11, score-2.581]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pictures', 0.459), ('conway', 0.455), ('accompany', 0.337), ('words', 0.322), ('word', 0.155), ('captions', 0.152), ('insert', 0.139), ('diminishing', 0.139), ('jimmy', 0.124), ('drew', 0.122), ('specifics', 0.12), ('returns', 0.111), ('visualizations', 0.109), ('images', 0.106), ('glad', 0.1), ('joint', 0.095), ('interaction', 0.094), ('suggestion', 0.093), ('expressed', 0.093), ('phrase', 0.092), ('notice', 0.089), ('plus', 0.088), ('stand', 0.087), ('picture', 0.083), ('easier', 0.082), ('software', 0.081), ('live', 0.079), ('function', 0.074), ('better', 0.073), ('scale', 0.072), ('type', 0.072), ('aren', 0.07), ('pointed', 0.069), ('prefer', 0.068), ('positive', 0.066), ('typically', 0.065), ('graphs', 0.062), ('value', 0.062), ('although', 0.06), ('theory', 0.057), ('much', 0.051), ('saying', 0.051), ('long', 0.051), ('thinking', 0.051), ('try', 0.049), ('best', 0.045), ('big', 0.045), ('makes', 0.043), ('put', 0.042), ('find', 0.041)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="574-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-14-%E2%80%9CThe_best_data_visualizations_should_stand_on_their_own%E2%80%9D%3F__I_don%E2%80%99t_think_so..html">574 andrew gelman stats-2011-02-14-“The best data visualizations should stand on their own”?  I don’t think so.</a></p>
<p>Introduction: Jimmy pointed me to  this  blog by Drew Conway on word clouds.  I don’t have much to say about Conway’s specifics–word clouds aren’t really my thing, but I’m glad that people are thinking about how to do them better–but I did notice one phrase of his that I’ll dispute.  Conway writes
  
The best data visualizations should stand on their own . . .
  
I disagree.  I prefer the saying, “A picture plus 1000 words is better than two pictures or 2000 words.”  That is, I see a positive interaction between words and pictures or, to put it another way, diminishing returns for words or pictures on their own.  I don’t have any big theory for this, but I think, when expressed as a joint value function, my idea makes sense.  Also, I live this suggestion in my own work.  I typically accompany my graphs with long captions and I try to accompany my words with pictures (although I’m not doing it here, because with the software I use, it’s much easier to type more words than to find, scale, and insert i</p><p>2 0.18913546 <a title="574-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Sof%5Bt%5D.html">77 andrew gelman stats-2010-06-09-Sof[t]</a></p>
<p>Introduction: Joe Fruehwald writes:
  
I’m working with linguistic data, specifically binomial hits and misses of a certain variable for certain words (specifically whether or not the “t” sound was pronounced at the end of words like “soft”). Word frequency follows a power law, with most words appearing just once, and with some words being hyperfrequent. I’m not interested in specific word effects, but I am interested in the effect of word frequency.


A logistic model fit is going to be heavily influenced by the effect of the hyperfrequent words which constitute only one type. To control for the item effect, I would fit a multilevel model with a random intercept by word, but like I said, most of the words appear only once.


Is there a principled approach to this problem?
  
My response:  It’s ok to fit a multilevel model even if most groups only have one observation each.  You’ll want to throw in some word-level predictors too.  Think of the multilevel model not as a substitute for the usual thoug</p><p>3 0.12817807 <a title="574-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-U-Haul_statistics.html">318 andrew gelman stats-2010-10-04-U-Haul statistics</a></p>
<p>Introduction: Very freakonomic  (and I mean that in the best sense of the word).</p><p>4 0.12688293 <a title="574-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-25-Fascinating_graphs_from_facebook_data.html">1824 andrew gelman stats-2013-04-25-Fascinating graphs from facebook data</a></p>
<p>Introduction: Yair points us to  this  page full of wonderful graphs from the Stephen Wolfram blog.  Here are a few:
 
 
 
 
 
 
 
And some words:
  
People talk less about video games as they get older, and more about politics and the weather. Men typically talk more about sports and technology than women—and, somewhat surprisingly to me, they also talk more about movies, television and music. Women talk more about pets+animals, family+friends, relationships—and, at least after they reach child-bearing years, health. . . . Some of this is rather depressingly stereotypical. And most of it isn’t terribly surprising to anyone who’s known a reasonable diversity of people of different ages. But what to me is remarkable is how we can see everything laid out in such quantitative detail in the pictures above—kind of a signature of people’s thinking as they go through life. 


Of course, the pictures above are all based on aggregate data, carefully anonymized. But if we start looking at individuals, we’ll s</p><p>5 0.12023096 <a title="574-tfidf-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-R_needs_a_good_function_to_make_line_plots.html">252 andrew gelman stats-2010-09-02-R needs a good function to make line plots</a></p>
<p>Introduction: More and more I’m thinking that line plots are great.  More specifically, two-way grids of line plots on common scales, with one, two, or three lines per plot (enough to show comparisons but not so many that you can’t tell the lines apart).  Also dot plots, of the sort that have been masterfully used by Lax and Phillips to show comparisons and trends in support for gay rights.
 
There’s a big step missing, though, and that is to be able to make these graphs as a default.  We have to figure out the right way to structure the data so these graphs come naturally.
 
Then when it’s all working, we can talk the Excel people into implementing our ideas.  I’m not asking to be paid here; all our ideas are in the public domain and I’m happy for Microsoft or Google or whoever to copy us.
 
P.S.  Drew Conway writes:
  
This could be accomplished with ggplot2 using various combinations of the grammar.  If I am understanding what you mean by line plots,  here are some examples with code .


In fact,</p><p>6 0.11844701 <a title="574-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-01-Hoe_noem_je%3F.html">1191 andrew gelman stats-2012-03-01-Hoe noem je?</a></p>
<p>7 0.11522894 <a title="574-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-12-Recently_in_the_sister_blog.html">2019 andrew gelman stats-2013-09-12-Recently in the sister blog</a></p>
<p>8 0.11180928 <a title="574-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-18-Data_to_use_for_in-class_sampling_exercises%3F.html">1943 andrew gelman stats-2013-07-18-Data to use for in-class sampling exercises?</a></p>
<p>9 0.11116616 <a title="574-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-20-Teaching_Bayesian_applied_statistics_to_graduate_students_in_political_science%2C_sociology%2C_public_health%2C_education%2C_economics%2C_._._..html">2256 andrew gelman stats-2014-03-20-Teaching Bayesian applied statistics to graduate students in political science, sociology, public health, education, economics, . . .</a></p>
<p>10 0.10688664 <a title="574-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-24-Flawed_visualization_of_U.S._voting_maybe_has_some_good_features.html">428 andrew gelman stats-2010-11-24-Flawed visualization of U.S. voting maybe has some good features</a></p>
<p>11 0.10073608 <a title="574-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-19-Google%E2%80%99s_word_count_statistics_viewer.html">476 andrew gelman stats-2010-12-19-Google’s word count statistics viewer</a></p>
<p>12 0.0992397 <a title="574-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-29-Decision_science_vs._social_psychology.html">305 andrew gelman stats-2010-09-29-Decision science vs. social psychology</a></p>
<p>13 0.096397199 <a title="574-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Contest_for_developing_an_R_package_recommendation_system.html">324 andrew gelman stats-2010-10-07-Contest for developing an R package recommendation system</a></p>
<p>14 0.085610457 <a title="574-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-22-%E2%80%9CInformation_visualization%E2%80%9D_vs._%E2%80%9CStatistical_graphics%E2%80%9D.html">816 andrew gelman stats-2011-07-22-“Information visualization” vs. “Statistical graphics”</a></p>
<p>15 0.082132645 <a title="574-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-An_epithet_I_can_live_with.html">1604 andrew gelman stats-2012-12-04-An epithet I can live with</a></p>
<p>16 0.078025773 <a title="574-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-15-Google_Refine.html">910 andrew gelman stats-2011-09-15-Google Refine</a></p>
<p>17 0.072059698 <a title="574-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-30-Bill_Gates%E2%80%99s_favorite_graph_of_the_year.html">2154 andrew gelman stats-2013-12-30-Bill Gates’s favorite graph of the year</a></p>
<p>18 0.071978241 <a title="574-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-15-Postdoc_involving_pathbreaking_work_in_MRP%2C_Stan%2C_and_the_2014_election%21.html">2173 andrew gelman stats-2014-01-15-Postdoc involving pathbreaking work in MRP, Stan, and the 2014 election!</a></p>
<p>19 0.071726963 <a title="574-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-30-Annals_of_spam.html">880 andrew gelman stats-2011-08-30-Annals of spam</a></p>
<p>20 0.070663363 <a title="574-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-03-Graphical_presentation_of_risk_ratios.html">126 andrew gelman stats-2010-07-03-Graphical presentation of risk ratios</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.103), (1, -0.019), (2, -0.013), (3, 0.035), (4, 0.051), (5, -0.058), (6, 0.001), (7, 0.013), (8, 0.012), (9, -0.007), (10, -0.017), (11, -0.002), (12, 0.016), (13, -0.017), (14, -0.012), (15, -0.001), (16, -0.008), (17, -0.02), (18, -0.021), (19, -0.014), (20, -0.012), (21, -0.039), (22, -0.012), (23, 0.012), (24, -0.021), (25, -0.025), (26, 0.009), (27, 0.043), (28, -0.001), (29, 0.016), (30, -0.007), (31, 0.018), (32, -0.005), (33, 0.003), (34, 0.025), (35, -0.001), (36, -0.014), (37, 0.01), (38, 0.014), (39, -0.007), (40, 0.023), (41, -0.03), (42, -0.017), (43, 0.01), (44, -0.013), (45, 0.006), (46, 0.023), (47, 0.01), (48, 0.003), (49, 0.037)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94856697 <a title="574-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-14-%E2%80%9CThe_best_data_visualizations_should_stand_on_their_own%E2%80%9D%3F__I_don%E2%80%99t_think_so..html">574 andrew gelman stats-2011-02-14-“The best data visualizations should stand on their own”?  I don’t think so.</a></p>
<p>Introduction: Jimmy pointed me to  this  blog by Drew Conway on word clouds.  I don’t have much to say about Conway’s specifics–word clouds aren’t really my thing, but I’m glad that people are thinking about how to do them better–but I did notice one phrase of his that I’ll dispute.  Conway writes
  
The best data visualizations should stand on their own . . .
  
I disagree.  I prefer the saying, “A picture plus 1000 words is better than two pictures or 2000 words.”  That is, I see a positive interaction between words and pictures or, to put it another way, diminishing returns for words or pictures on their own.  I don’t have any big theory for this, but I think, when expressed as a joint value function, my idea makes sense.  Also, I live this suggestion in my own work.  I typically accompany my graphs with long captions and I try to accompany my words with pictures (although I’m not doing it here, because with the software I use, it’s much easier to type more words than to find, scale, and insert i</p><p>2 0.78336632 <a title="574-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-19-Web-friendly_visualizations_in_R.html">965 andrew gelman stats-2011-10-19-Web-friendly visualizations in R</a></p>
<p>Introduction: Aleks points me to this new tool from Wojciech Gryc. Right now I save my graphs as pdfs or pngs and then upload them to put them on the web. I expect I’ll still be doing this for awhile—I like having full control of what my graphs look like—but Gryc’s default plots might be useful for lots of people making their analyses more accessible.
 
 Here’s  an example: 
   
 x = rnorm(30) 
y = rnorm(30) 
wv.plot(x, y, "~/Desktop/scatterplot", height=300, width=300, xlim=c(-2.5,2.5), ylim=c(-2.5,2.5), xbreaks=c(0), ybreaks=c(0))</p><p>3 0.76123714 <a title="574-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-08-chartsnthings_%21.html">1308 andrew gelman stats-2012-05-08-chartsnthings !</a></p>
<p>Introduction: Yair pointed me to  this awesome blog  of how the NYT people make their graphs.  This blows away all other stat graphics blogs (including this one).  Lots of examples from mockup to first tries to final version.  I recognize a lot of what they’re doing from my own experience.  Also from my experience it’s hard to get all these details down:  once you have the final graph, it’s easy to forget how you go there.</p><p>4 0.75936192 <a title="574-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-05-Different_goals%2C_different_looks%3A__Infovis_and_the_Chris_Rock_effect.html">787 andrew gelman stats-2011-07-05-Different goals, different looks:  Infovis and the Chris Rock effect</a></p>
<p>Introduction: Seth writes:
  
 Here’s  my candidate for bad graphic of the year:


   


I [Seth] studied it and learned nothing. I have no idea how they assigned colors to locations. I already knew that there were more within-city calls than calls to individual distant locations — for example that there are more SF-SF calls than SF-LA calls. The researchers took a huge rich database and boiled it down to nothing (in terms of information value) — and I have a funny feeling they don’t realize how awful this is and what a waste.


I send it to you because it isn’t obvious how to do better — at least not obvious to them.
  
My reply:
 
My first reaction is to agree–I don’t get anything out of this graph either! But let me step back.
 
I think it’s best to understand this using the framework of  my paper with Antony Unwin , by thinking of the goals that are satisfied by different sorts of graphs.
 
What does this graph convey? It doesn’t tell us much about phone calls, but it does tell us that some peop</p><p>5 0.75564557 <a title="574-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-15-How_do_I_make_my_graphs%3F.html">1764 andrew gelman stats-2013-03-15-How do I make my graphs?</a></p>
<p>Introduction: Someone who wishes to remain anonymous writes: 
  
  
I’ve been following your blog a long time and enjoy your posts on visualization/statistical graphics matters.  I don’t recall however you ever describing the details of your setup for plotting.  I’m a new R user (convert from matplotlib) and would love to know your thoughts on the ideal setup: do you use mainly the R base?  Do you use lattice?  What do you think of ggplot2?  etc.  


I found ggplot2 nearly indecipherable until a recent eureka moment, and I think its default theme is a waste tremendous ink (all those silly grey backgrounds and grids are really unnecessary), but if you customize that away it can be made to look like ordinary, pretty statistical graphs.  


Feel free to respond on your blog, but if you do, please remove my name from the post (my colleagues already make fun of me for thinking about visualization too much.) 
  
I love that last bit!
 
Anyway, my response is that I do everything in base graphics (using my</p><p>6 0.74748915 <a title="574-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-08-Software_is_as_software_does.html">1661 andrew gelman stats-2013-01-08-Software is as software does</a></p>
<p>7 0.74036872 <a title="574-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-31-A_data_visualization_manifesto.html">61 andrew gelman stats-2010-05-31-A data visualization manifesto</a></p>
<p>8 0.73696047 <a title="574-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-18-Beautiful_Line_Charts.html">1125 andrew gelman stats-2012-01-18-Beautiful Line Charts</a></p>
<p>9 0.73327631 <a title="574-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-12-Sometimes_a_graph_really_is_just_ugly.html">798 andrew gelman stats-2011-07-12-Sometimes a graph really is just ugly</a></p>
<p>10 0.73133534 <a title="574-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-16-Infovis_and_statgraphics_update_update.html">855 andrew gelman stats-2011-08-16-Infovis and statgraphics update update</a></p>
<p>11 0.72679007 <a title="574-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-10-Using_a_%E2%80%9Cpure_infographic%E2%80%9D_to_explore_differences_between_information_visualization_and_statistical_graphics.html">847 andrew gelman stats-2011-08-10-Using a “pure infographic” to explore differences between information visualization and statistical graphics</a></p>
<p>12 0.72309786 <a title="574-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-%E2%80%9CWho_owns_Congress%E2%80%9D.html">319 andrew gelman stats-2010-10-04-“Who owns Congress”</a></p>
<p>13 0.71357667 <a title="574-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-04-%E2%80%9CTurn_a_Boring_Bar_Graph_into_a_3D_Masterpiece%E2%80%9D.html">1154 andrew gelman stats-2012-02-04-“Turn a Boring Bar Graph into a 3D Masterpiece”</a></p>
<p>14 0.7135613 <a title="574-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-Infovis%2C_infographics%2C_and_data_visualization%3A__Where_I%E2%80%99m_coming_from%2C_and_where_I%E2%80%99d_like_to_go.html">878 andrew gelman stats-2011-08-29-Infovis, infographics, and data visualization:  Where I’m coming from, and where I’d like to go</a></p>
<p>15 0.70965928 <a title="574-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-13-Against_the_myth_of_the_heroic_visualization.html">1896 andrew gelman stats-2013-06-13-Against the myth of the heroic visualization</a></p>
<p>16 0.70880294 <a title="574-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-30-That_puzzle-solving_feeling.html">492 andrew gelman stats-2010-12-30-That puzzle-solving feeling</a></p>
<p>17 0.70773357 <a title="574-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-27-Laws_as_expressive.html">1085 andrew gelman stats-2011-12-27-Laws as expressive</a></p>
<p>18 0.70576471 <a title="574-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-20-Ugly_ugly_ugly.html">1684 andrew gelman stats-2013-01-20-Ugly ugly ugly</a></p>
<p>19 0.69924098 <a title="574-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-10-Life_in_New_York%2C_Then_and_Now.html">139 andrew gelman stats-2010-07-10-Life in New York, Then and Now</a></p>
<p>20 0.69714147 <a title="574-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-02-RStudio_%E2%80%93_new_cross-platform_IDE_for_R.html">597 andrew gelman stats-2011-03-02-RStudio – new cross-platform IDE for R</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.055), (21, 0.092), (24, 0.236), (42, 0.014), (58, 0.128), (63, 0.033), (77, 0.03), (79, 0.015), (88, 0.019), (95, 0.045), (99, 0.203)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95024312 <a title="574-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-14-%E2%80%9CThe_best_data_visualizations_should_stand_on_their_own%E2%80%9D%3F__I_don%E2%80%99t_think_so..html">574 andrew gelman stats-2011-02-14-“The best data visualizations should stand on their own”?  I don’t think so.</a></p>
<p>Introduction: Jimmy pointed me to  this  blog by Drew Conway on word clouds.  I don’t have much to say about Conway’s specifics–word clouds aren’t really my thing, but I’m glad that people are thinking about how to do them better–but I did notice one phrase of his that I’ll dispute.  Conway writes
  
The best data visualizations should stand on their own . . .
  
I disagree.  I prefer the saying, “A picture plus 1000 words is better than two pictures or 2000 words.”  That is, I see a positive interaction between words and pictures or, to put it another way, diminishing returns for words or pictures on their own.  I don’t have any big theory for this, but I think, when expressed as a joint value function, my idea makes sense.  Also, I live this suggestion in my own work.  I typically accompany my graphs with long captions and I try to accompany my words with pictures (although I’m not doing it here, because with the software I use, it’s much easier to type more words than to find, scale, and insert i</p><p>2 0.90564489 <a title="574-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-27-One_way_that_psychology_research_is_different_than_medical_research.html">433 andrew gelman stats-2010-11-27-One way that psychology research is different than medical research</a></p>
<p>Introduction: Medical researchers care about main effects, psychologists care about interactions.  In psychology, the main effects are typically obvious, and itâ&euro;&trade;s only the interactions that are worth studying.</p><p>3 0.89899969 <a title="574-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-11-My_problem_with_the_Lindley_paradox.html">1757 andrew gelman stats-2013-03-11-My problem with the Lindley paradox</a></p>
<p>Introduction: From  a couple years ago but still relevant, I think:
  
To me, the Lindley paradox falls apart because of its noninformative prior distribution on the parameter of interest. If you really think there’s a high probability the parameter is nearly exactly zero, I don’t see the point of the model saying that you have no prior information at all on the parameter. In short: my criticism of so-called Bayesian hypothesis testing is that it’s insufficiently Bayesian.
  
P.S.  To clarify (in response to Bill’s comment below):  I’m speaking of all the examples I’ve ever worked on in social and environmental science, where in some settings I can imagine a parameter being very close to zero and in other settings I can imagine a parameter taking on just about any value in a wide range, but where I’ve never seen an example where a parameter could be  either  right at zero  or  taking on any possible value.  But such examples might occur in areas of application that I haven’t worked on.</p><p>4 0.89723456 <a title="574-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-19-Tradeoffs_in_information_graphics.html">1584 andrew gelman stats-2012-11-19-Tradeoffs in information graphics</a></p>
<p>Introduction: The visual display of quantitative information (to use Edward Tufte’s wonderful term) is a diverse field or set of fields, and its practitioners have different goals. The goals of software designers, applied statisticians, biologists, graphic designers, and journalists (to list just a few of the important creators of data graphics) often overlap—but not completely. One of our aims in writing  our article  [on Infovis and Statistical Graphics] was to emphasize the diversity of graphical goals, as it seems to us that even experts tend to consider one aspect of a graph and not others.


Our main practical suggestion was that, in the internet age, we should not have to choose between attractive graphs and informational graphs: it should be possible to display both, via interactive displays. But to follow this suggestion, one must first accept that not every beautiful graph is informative, and not every informative graph is beautiful. . . .


Yes, it can sometimes be possible for a graph to</p><p>5 0.89410865 <a title="574-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-18-Understanding_posterior_p-values.html">2029 andrew gelman stats-2013-09-18-Understanding posterior p-values</a></p>
<p>Introduction: David Kaplan writes:
  
I came across your  paper  “Understanding Posterior Predictive P-values”, and I have a question regarding your statement “If a posterior predictive p-value is 0.4, say, that means that, if we believe the model, we think there is a 40% chance that tomorrow’s value of T(y_rep) will exceed today’s T(y).” This is perfectly understandable to me and represents the idea of calibration.  However, I am unsure how this relates to statements about fit.  If T is the LR chi-square or Pearson chi-square, then your statement that there is a 40% chance that tomorrows value exceeds today’s value indicates bad fit, I think.  Yet, some literature indicates that high p-values suggest good fit.  Could you clarify this?
  
My reply:
 
I think that “fit” depends on the question being asked.  In this case, I’d say the model fits for this particular purpose, even though it might not fit for other purposes.
 
And here’s the abstract of the paper:
  
Posterior predictive p-values do not i</p><p>6 0.89305425 <a title="574-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-09-My_homework_success.html">896 andrew gelman stats-2011-09-09-My homework success</a></p>
<p>7 0.89125413 <a title="574-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>8 0.8901844 <a title="574-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-22-The_kluges_of_today_are_the_textbook_solutions_of_tomorrow..html">2143 andrew gelman stats-2013-12-22-The kluges of today are the textbook solutions of tomorrow.</a></p>
<p>9 0.88953918 <a title="574-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-24-Latest_in_blog_advertising.html">1080 andrew gelman stats-2011-12-24-Latest in blog advertising</a></p>
<p>10 0.8871417 <a title="574-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-20-Prior_beliefs_about_locations_of_decision_boundaries.html">1130 andrew gelman stats-2012-01-20-Prior beliefs about locations of decision boundaries</a></p>
<p>11 0.88561761 <a title="574-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Let%E2%80%99s_play_%E2%80%9CGuess_the_smoother%E2%80%9D%21.html">1283 andrew gelman stats-2012-04-26-Let’s play “Guess the smoother”!</a></p>
<p>12 0.88541299 <a title="574-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-12-Probabilistic_screening_to_get_an_approximate_self-weighted_sample.html">1455 andrew gelman stats-2012-08-12-Probabilistic screening to get an approximate self-weighted sample</a></p>
<p>13 0.88365722 <a title="574-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-12-Simple_graph_WIN%3A__the_example_of_birthday_frequencies.html">1376 andrew gelman stats-2012-06-12-Simple graph WIN:  the example of birthday frequencies</a></p>
<p>14 0.88337767 <a title="574-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-07-Challenges_of_experimental_design%3B_also_another_rant_on_the_practice_of_mentioning_the_publication_of_an_article_but_not_naming_its_author.html">399 andrew gelman stats-2010-11-07-Challenges of experimental design; also another rant on the practice of mentioning the publication of an article but not naming its author</a></p>
<p>15 0.88299274 <a title="574-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>16 0.88230234 <a title="574-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-03-Setting_aside_the_politics%2C_the_debate_over_the_new_health-care_study_reveals_that_we%E2%80%99re_moving_to_a_new_high_standard_of_statistical_journalism.html">1838 andrew gelman stats-2013-05-03-Setting aside the politics, the debate over the new health-care study reveals that we’re moving to a new high standard of statistical journalism</a></p>
<p>17 0.88139504 <a title="574-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-11-Steve_Jobs%E2%80%99s_cancer_and_science-based_medicine.html">953 andrew gelman stats-2011-10-11-Steve Jobs’s cancer and science-based medicine</a></p>
<p>18 0.88057876 <a title="574-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>19 0.87973112 <a title="574-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-%E2%80%9CThe_difference_between_._._.%E2%80%9D%3A__It%E2%80%99s_not_just_p%3D.05_vs._p%3D.06.html">1072 andrew gelman stats-2011-12-19-“The difference between . . .”:  It’s not just p=.05 vs. p=.06</a></p>
<p>20 0.87932986 <a title="574-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-15-Advice_that_might_make_sense_for_individuals_but_is_negative-sum_overall.html">278 andrew gelman stats-2010-09-15-Advice that might make sense for individuals but is negative-sum overall</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
