<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>524 andrew gelman stats-2011-01-19-Data exploration and multiple comparisons</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2011" href="../home/andrew_gelman_stats-2011_home.html">andrew_gelman_stats-2011</a> <a title="andrew_gelman_stats-2011-524" href="#">andrew_gelman_stats-2011-524</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>524 andrew gelman stats-2011-01-19-Data exploration and multiple comparisons</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2011-524-html" href="http://andrewgelman.com/2011/01/19/data_exploratio/">html</a></p><p>Introduction: Bill Harris writes:
  
I’ve read your  paper  and  presentation  showing why you don’t usually worry about multiple comparisons.  I see how that applies when you are comparing results across multiple settings (states, etc.).


Does the same principle hold when you are exploring data to find interesting relationships?  For example, you have some data, and you’re trying a series of models to see which gives you the most useful insight.  Do you try your models on a subset of the data so you have another subset for confirmatory analysis later, or do you simply throw all the data against your models?
  
My reply:  I’d like to estimate all the relationships at once and use a multilevel model to do partial pooling to handle the mutiplicity issues.  That said, in practice, in my applied work I’m always bouncing back and forth between different hypotheses and different datasets, and often I learn a lot when next year’s data come in and I can modify my hypotheses. The trouble with the classical</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Bill Harris writes:    I’ve read your  paper  and  presentation  showing why you don’t usually worry about multiple comparisons. [sent-1, score-0.551]
</p><p>2 I see how that applies when you are comparing results across multiple settings (states, etc. [sent-2, score-0.571]
</p><p>3 Does the same principle hold when you are exploring data to find interesting relationships? [sent-4, score-0.486]
</p><p>4 For example, you have some data, and you’re trying a series of models to see which gives you the most useful insight. [sent-5, score-0.398]
</p><p>5 Do you try your models on a subset of the data so you have another subset for confirmatory analysis later, or do you simply throw all the data against your models? [sent-6, score-1.319]
</p><p>6 My reply:  I’d like to estimate all the relationships at once and use a multilevel model to do partial pooling to handle the mutiplicity issues. [sent-7, score-0.733]
</p><p>7 That said, in practice, in my applied work I’m always bouncing back and forth between different hypotheses and different datasets, and often I learn a lot when next year’s data come in and I can modify my hypotheses. [sent-8, score-1.364]
</p><p>8 The trouble with the classical hypothesis-testing framework, at least for me, is that so-called statistical hypotheses are very precise things, whereas the sorts of hypotheses that arise in science and social science are vaguer and are not so amenable to “testing” in the classical sense. [sent-9, score-2.025]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hypotheses', 0.363), ('relationships', 0.267), ('subset', 0.263), ('amenable', 0.199), ('classical', 0.196), ('bouncing', 0.191), ('confirmatory', 0.163), ('multiple', 0.161), ('harris', 0.16), ('models', 0.159), ('modify', 0.155), ('data', 0.143), ('exploring', 0.137), ('pooling', 0.137), ('applies', 0.13), ('forth', 0.125), ('datasets', 0.124), ('partial', 0.122), ('handle', 0.119), ('precise', 0.118), ('presentation', 0.111), ('throw', 0.109), ('arise', 0.108), ('framework', 0.108), ('hold', 0.106), ('settings', 0.105), ('worry', 0.103), ('science', 0.102), ('trouble', 0.1), ('principle', 0.1), ('comparing', 0.1), ('bill', 0.097), ('showing', 0.096), ('testing', 0.096), ('whereas', 0.095), ('series', 0.089), ('multilevel', 0.088), ('different', 0.083), ('practice', 0.083), ('states', 0.083), ('sorts', 0.083), ('gives', 0.083), ('later', 0.081), ('usually', 0.08), ('learn', 0.08), ('simply', 0.076), ('across', 0.075), ('applied', 0.071), ('next', 0.07), ('useful', 0.067)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="524-tfidf-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-19-Data_exploration_and_multiple_comparisons.html">524 andrew gelman stats-2011-01-19-Data exploration and multiple comparisons</a></p>
<p>Introduction: Bill Harris writes:
  
I’ve read your  paper  and  presentation  showing why you don’t usually worry about multiple comparisons.  I see how that applies when you are comparing results across multiple settings (states, etc.).


Does the same principle hold when you are exploring data to find interesting relationships?  For example, you have some data, and you’re trying a series of models to see which gives you the most useful insight.  Do you try your models on a subset of the data so you have another subset for confirmatory analysis later, or do you simply throw all the data against your models?
  
My reply:  I’d like to estimate all the relationships at once and use a multilevel model to do partial pooling to handle the mutiplicity issues.  That said, in practice, in my applied work I’m always bouncing back and forth between different hypotheses and different datasets, and often I learn a lot when next year’s data come in and I can modify my hypotheses. The trouble with the classical</p><p>2 0.19498082 <a title="524-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>Introduction: Robert Bloomfield writes:
  
Most of the people in my field (accounting, which is basically applied economics and finance, leavened with psychology and organizational behavior) use ‘positive research methods’, which are typically described as coming to the data with a predefined theory, and using hypothesis testing to accept or reject the theory’s predictions.  But a substantial minority use ‘interpretive research methods’ (sometimes called qualitative methods, for those that call positive research ‘quantitative’).  No one seems entirely happy with the definition of this method, but I’ve found it useful to think of it as an attempt to see the world through the eyes of your subjects, much as Jane Goodall lived with gorillas and tried to see the world through their eyes.)


Interpretive researchers often criticize positive researchers by noting that the latter don’t make the best use of their data, because they come to the data with a predetermined theory, and only test a narrow set of h</p><p>3 0.17248073 <a title="524-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-28-More_on_Bayesian_deduction-induction.html">114 andrew gelman stats-2010-06-28-More on Bayesian deduction-induction</a></p>
<p>Introduction: Kevin Bryan wrote:
  
I read  your new article  on deduction/induction under Bayes.  There are a couple interesting papers from economic decision theory which are related that you might find interesting.
      
Samuelson et al have a (very) recent paper about what happens when you have some Bayesian and some non-Bayesian hypotheses.  (I  mentioned  this one on my blog earlier this year.)  Essentially, the Bayesian hypotheses are forced to “make predictions” in every future period (“if the unemployment rate is x%, the president is reelected with pr=x), whereas other forms of reasoning (say, analogies: “If the unemployment rate is above 10%, the president will not be reelected”).  Imagine you have some prior over, say, the economy and elections, with 99.9% of the hypotheses being Bayesian and the rest being analogies as above.  Then 100 years from now, because the analogies are so hard to refute, using deduction will push the proportion of Bayesian hypotheses toward zero.  


There is a</p><p>4 0.15700689 <a title="524-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-29-Splitting_the_data.html">544 andrew gelman stats-2011-01-29-Splitting the data</a></p>
<p>Introduction: Antonio Rangel writes:
  
I’m a neuroscientist at Caltech . . . I’m using the debate on the  ESP paper , as I’m sure other labs around the world are, as an opportunity to discuss some basic statistical issues/ideas w/ my lab.


Request: Is there any chance you would be willing to share your thoughts about the difference between exploratory “data mining” studies and confirmatory studies? What I have in mind is that one could use a dataset to explore/discover novel hypotheses  and then conduct another experiment to test those hypotheses rigorously. It seems that a good combination of both approaches could be the best of both worlds, since the first would lead to novel hypothesis discovery, and the later to careful testing. . . it is a fundamental issue for neuroscience and psychology.
  
My reply:
 
I know that people talk about this sort of thing . . . but in any real setting, I think I’d want all my data  right now  to answer any questions I have.  I like cross-validation and have used</p><p>5 0.14558654 <a title="524-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>Introduction: After I gave  my talk  at an econ seminar on Why We (Usually) Don’t Care About Multiple Comparisons, I got the following comment:
  
One question that came up later was whether your argument is really with testing in general, rather than only with testing in multiple comparison settings.
  
My reply:
 
Yes, my argument is with testing in general.  But it arises with particular force in multiple comparisons.  With a single test, we can just say we dislike testing so we use confidence intervals or Bayesian inference instead, and it’s no problem—really more of a change in emphasis than a change in methods.  But with multiple tests, the classical advice is not simply to look at type 1 error rates but more specifically to make a multiplicity adjustment, for example to make confidence intervals wider to account for multiplicity.  I don’t want to do this!  So here there is a real battle to fight.
 
P.S.   Here’s  the article (with Jennifer and Masanao), to appear in the Journal of Research on</p><p>6 0.1334568 <a title="524-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>7 0.13230208 <a title="524-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>8 0.12865388 <a title="524-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-27-Sampling_rate_of_human-scaled_time_series.html">112 andrew gelman stats-2010-06-27-Sampling rate of human-scaled time series</a></p>
<p>9 0.12668926 <a title="524-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>10 0.12198928 <a title="524-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>11 0.11770605 <a title="524-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>12 0.11740114 <a title="524-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-20-The_pervasive_twoishness_of_statistics%3B_in_particular%2C_the_%E2%80%9Csampling_distribution%E2%80%9D_and_the_%E2%80%9Clikelihood%E2%80%9D_are_two_different_models%2C_and_that%E2%80%99s_a_good_thing.html">774 andrew gelman stats-2011-06-20-The pervasive twoishness of statistics; in particular, the “sampling distribution” and the “likelihood” are two different models, and that’s a good thing</a></p>
<p>13 0.1152327 <a title="524-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>14 0.11385874 <a title="524-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Correcting_for_multiple_comparisons_in_a_Bayesian_regression_model.html">1989 andrew gelman stats-2013-08-20-Correcting for multiple comparisons in a Bayesian regression model</a></p>
<p>15 0.11347898 <a title="524-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>16 0.11027274 <a title="524-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>17 0.11022341 <a title="524-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Popper_and_Jaynes.html">2007 andrew gelman stats-2013-09-03-Popper and Jaynes</a></p>
<p>18 0.10951585 <a title="524-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-12-Single_or_multiple_imputation%3F.html">608 andrew gelman stats-2011-03-12-Single or multiple imputation?</a></p>
<p>19 0.10619156 <a title="524-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>20 0.10442236 <a title="524-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-08-Discussion_with_Steven_Pinker_on_research_that_is_attached_to_data_that_are_so_noisy_as_to_be_essentially_uninformative.html">2326 andrew gelman stats-2014-05-08-Discussion with Steven Pinker on research that is attached to data that are so noisy as to be essentially uninformative</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.204), (1, 0.094), (2, -0.017), (3, -0.024), (4, 0.02), (5, -0.008), (6, -0.088), (7, 0.0), (8, 0.072), (9, 0.043), (10, 0.001), (11, 0.034), (12, -0.009), (13, -0.046), (14, 0.025), (15, 0.012), (16, -0.042), (17, -0.051), (18, 0.006), (19, -0.046), (20, 0.002), (21, -0.034), (22, -0.036), (23, 0.035), (24, -0.065), (25, -0.071), (26, -0.009), (27, -0.023), (28, 0.045), (29, -0.013), (30, 0.034), (31, 0.003), (32, 0.056), (33, -0.03), (34, -0.034), (35, 0.024), (36, 0.026), (37, -0.02), (38, 0.035), (39, 0.008), (40, 0.009), (41, 0.046), (42, -0.023), (43, -0.011), (44, -0.045), (45, -0.025), (46, 0.017), (47, -0.009), (48, -0.044), (49, -0.11)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9576478 <a title="524-lsi-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-19-Data_exploration_and_multiple_comparisons.html">524 andrew gelman stats-2011-01-19-Data exploration and multiple comparisons</a></p>
<p>Introduction: Bill Harris writes:
  
I’ve read your  paper  and  presentation  showing why you don’t usually worry about multiple comparisons.  I see how that applies when you are comparing results across multiple settings (states, etc.).


Does the same principle hold when you are exploring data to find interesting relationships?  For example, you have some data, and you’re trying a series of models to see which gives you the most useful insight.  Do you try your models on a subset of the data so you have another subset for confirmatory analysis later, or do you simply throw all the data against your models?
  
My reply:  I’d like to estimate all the relationships at once and use a multilevel model to do partial pooling to handle the mutiplicity issues.  That said, in practice, in my applied work I’m always bouncing back and forth between different hypotheses and different datasets, and often I learn a lot when next year’s data come in and I can modify my hypotheses. The trouble with the classical</p><p>2 0.77554286 <a title="524-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>Introduction: James O’Brien writes:
  
How would you explain, to a “classically-trained” hypothesis-tester, that “It’s OK to fit a multilevel model even if some groups have only one observation each”?


I [O'Brien] think I understand the logic and the statistical principles at work in this, but I’ve having trouble being clear and persuasive. I also feel like I’m contending with some methodological conventional wisdom here. 
  
My reply:  I’m so used to this idea that I find it difficult to defend it in some sort of general conceptual way.  So let me retreat to a more functional defense, which is that multilevel modeling gives good estimates,  especially  when the number of observations per group is small.
 
One way to see this in any particular example in through cross-validation.  Another way is to consider the alternatives.   If you try really hard you can come up with a “classical hypothesis testing” approach which will do as well as the multilevel model.  It would just take a lot of work.  I’d r</p><p>3 0.75105476 <a title="524-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>Introduction: Some things I respect 
 
When it comes to meta-models of statistics, here are two philosophies that I respect:
 
1.  (My) Bayesian approach, which I associate with E. T. Jaynes, in which you construct models with strong assumptions, ride your models hard, check their fit to data, and then scrap them and improve them as necessary.
 
2.  At the other extreme, model-free statistical procedures that are designed to work well under very weak assumptions—for example, instead of assuming a distribution is Gaussian, you would just want the procedure to work well under some conditions on the smoothness of the second derivative of the log density function.
 
Both the above philosophies recognize that (almost) all important assumptions will be wrong, and they resolve this concern via aggressive model checking or via robustness.  And of course there are intermediate positions, such as working with Bayesian models that have been shown to be robust, and then still checking them.  Or, to flip it arou</p><p>4 0.74613506 <a title="524-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>Introduction: Robert Bloomfield writes:
  
Most of the people in my field (accounting, which is basically applied economics and finance, leavened with psychology and organizational behavior) use ‘positive research methods’, which are typically described as coming to the data with a predefined theory, and using hypothesis testing to accept or reject the theory’s predictions.  But a substantial minority use ‘interpretive research methods’ (sometimes called qualitative methods, for those that call positive research ‘quantitative’).  No one seems entirely happy with the definition of this method, but I’ve found it useful to think of it as an attempt to see the world through the eyes of your subjects, much as Jane Goodall lived with gorillas and tried to see the world through their eyes.)


Interpretive researchers often criticize positive researchers by noting that the latter don’t make the best use of their data, because they come to the data with a predetermined theory, and only test a narrow set of h</p><p>5 0.74573237 <a title="524-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>Introduction: Robert Birkelbach:
  
I am writing my Bachelor Thesis in which I want to assess the reading competencies of German elementary school children using the PIRLS2006 data. My levels are classrooms and the individuals. However, my dependent variable is a multiple imputed (m=5) reading test. The problem I have is, that I do not know, whether I can just calculate 5 linear multilevel models and then average all the results (the coefficients, standard deviation, bic, intra class correlation, R2, t-statistics, p-values etc) or if I need different formulas for integrating the results of the five models into one because it is a multilevel analysis? Do you think there’s a better way in solving my problem? I would greatly appreciate if you could help me with a problem regarding my analysis — I am quite a newbie to multilevel modeling and especially to multiple imputation. Also: Is it okay to use frequentist models when the multiple imputation was done bayesian? Would the different philosophies of sc</p><p>6 0.74095792 <a title="524-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-10-Combining_data_from_many_sources.html">948 andrew gelman stats-2011-10-10-Combining data from many sources</a></p>
<p>7 0.73474693 <a title="524-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>8 0.73213667 <a title="524-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-19-Demystifying_Blup.html">1270 andrew gelman stats-2012-04-19-Demystifying Blup</a></p>
<p>9 0.73189294 <a title="524-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>10 0.72976398 <a title="524-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-23-Examples_of_the_use_of_hierarchical_modeling_to_generalize_to_new_settings.html">1425 andrew gelman stats-2012-07-23-Examples of the use of hierarchical modeling to generalize to new settings</a></p>
<p>11 0.72966242 <a title="524-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Toward_a_framework_for_automatic_model_building.html">1718 andrew gelman stats-2013-02-11-Toward a framework for automatic model building</a></p>
<p>12 0.72851455 <a title="524-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multiple_comparisons_dispute_in_the_tabloids.html">1195 andrew gelman stats-2012-03-04-Multiple comparisons dispute in the tabloids</a></p>
<p>13 0.72418445 <a title="524-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>14 0.7208119 <a title="524-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-23-When_are_complicated_models_helpful_in_psychology_research_and_when_are_they_overkill%3F.html">1690 andrew gelman stats-2013-01-23-When are complicated models helpful in psychology research and when are they overkill?</a></p>
<p>15 0.71817493 <a title="524-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-19-Just_chaid.html">421 andrew gelman stats-2010-11-19-Just chaid</a></p>
<p>16 0.71373689 <a title="524-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-17-Ripley_on_model_selection%2C_and_some_links_on_exploratory_model_analysis.html">1066 andrew gelman stats-2011-12-17-Ripley on model selection, and some links on exploratory model analysis</a></p>
<p>17 0.70586473 <a title="524-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-18-Hierarchical_modeling_as_a_framework_for_extrapolation.html">1383 andrew gelman stats-2012-06-18-Hierarchical modeling as a framework for extrapolation</a></p>
<p>18 0.70316958 <a title="524-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-21-Data_cleaning_tool%21.html">424 andrew gelman stats-2010-11-21-Data cleaning tool!</a></p>
<p>19 0.70292729 <a title="524-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-01-Peter_Huber%E2%80%99s_reflections_on_data_analysis.html">690 andrew gelman stats-2011-05-01-Peter Huber’s reflections on data analysis</a></p>
<p>20 0.70224506 <a title="524-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.102), (17, 0.032), (21, 0.026), (24, 0.123), (25, 0.057), (30, 0.019), (36, 0.017), (42, 0.019), (63, 0.03), (76, 0.015), (86, 0.038), (99, 0.422)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98453343 <a title="524-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-19-Data_exploration_and_multiple_comparisons.html">524 andrew gelman stats-2011-01-19-Data exploration and multiple comparisons</a></p>
<p>Introduction: Bill Harris writes:
  
I’ve read your  paper  and  presentation  showing why you don’t usually worry about multiple comparisons.  I see how that applies when you are comparing results across multiple settings (states, etc.).


Does the same principle hold when you are exploring data to find interesting relationships?  For example, you have some data, and you’re trying a series of models to see which gives you the most useful insight.  Do you try your models on a subset of the data so you have another subset for confirmatory analysis later, or do you simply throw all the data against your models?
  
My reply:  I’d like to estimate all the relationships at once and use a multilevel model to do partial pooling to handle the mutiplicity issues.  That said, in practice, in my applied work I’m always bouncing back and forth between different hypotheses and different datasets, and often I learn a lot when next year’s data come in and I can modify my hypotheses. The trouble with the classical</p><p>2 0.98048115 <a title="524-lda-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-06-How_much_time_%28if_any%29_should_we_spend_criticizing_research_that%E2%80%99s_fraudulent%2C_crappy%2C_or_just_plain_pointless%3F.html">2235 andrew gelman stats-2014-03-06-How much time (if any) should we spend criticizing research that’s fraudulent, crappy, or just plain pointless?</a></p>
<p>Introduction: I had a brief email exchange with Jeff Leek regarding our recent  discussions  of replication, criticism, and the self-correcting process of science.
 
Jeff writes:
  
(1) I can see the problem with serious, evidence-based criticisms not being published in the same journal (and linked to) studies that are shown to be incorrect. I have been mostly seeing these sorts of things show up in blogs. But I’m not sure that is a bad thing. I think people read blogs more than they read the literature. I wonder if this means that blogs will eventually be a sort of “shadow literature”? 


(2) I think there is a ton of bad literature out there, just like there is a ton of bad stuff on Google. If we focus too much on the bad stuff we will be paralyzed. I still manage to find good papers despite all the bad papers. 


(3) I think one positive solution to this problem is to incentivize/publish referee reports and give people credit for a good referee report just like they get credit for a good paper. T</p><p>3 0.97985333 <a title="524-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-18-Misunderstanding_analysis_of_covariance.html">859 andrew gelman stats-2011-08-18-Misunderstanding analysis of covariance</a></p>
<p>Introduction: Jeremy Miles writes:
  
Are you familiar with Miller and Chapman’s (2001)  article : Misunderstanding Analysis of Covariance saying that ANCOVA (and therefore, I suppose regression) should not be used when groups differ on a covariate.    It has caused a moderate splash in psychology circles.  I wondered if you had any thoughts on it.
  
I had not heard of the article so I followed the link . . . ugh!  Already on the very first column of the very first page they confuse nonadditivity with nonlinearity.  I could probably continue with, “and it gets worse,” but since nobody’s paying me to read this one, I’ll stop reading right there on the first page!
 
I prefer when people point me to good papers to read. . . .</p><p>4 0.97947353 <a title="524-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-18-Should_we_always_be_using_the_t_and_robit_instead_of_the_normal_and_logit%3F.html">773 andrew gelman stats-2011-06-18-Should we always be using the t and robit instead of the normal and logit?</a></p>
<p>Introduction: My (coauthored) books on Bayesian data analysis and applied regression are like almost all the other statistics textbooks out there, in that we spend most of our time on the basic distributions such as normal and logistic and then, only as an aside, discuss robust models such as t and robit.
 
Why aren’t the t and robit front and center?  Sure, I can see starting with the normal (at least in the Bayesian book, where we actually work out all the algebra), but then why don’t we move on immediately to the real stuff?
 
This isn’t just (or mainly) a question of textbooks or teaching; I’m really thinking here about statistical practice.  My statistical practice.  Should t and robit be the default?  If not, why not?
 
Some possible answers:
  
10.  Estimating the degrees of freedom in the error distribution isn’t so easy, and throwing this extra parameter into the model could make inference unstable.


9.  Real data usually don’t have outliers.  In practice, fitting a robust model costs you</p><p>5 0.97904032 <a title="524-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-14-Richer_people_continue_to_vote_Republican.html">1577 andrew gelman stats-2012-11-14-Richer people continue to vote Republican</a></p>
<p>Introduction: From the exit polls:
 
 
 
This is all pretty obvious but it seemed worth posting because some people still don’t seem to get it.  For example, Jay Cost,  writing  in the Weekly Standard:
  
The Democratic party now dominates the Upper East Side of Manhattan, as well as the wealthiest neighborhoods in the most powerful cities. And yet Republicans are still effectively castigated as the party of the rich. They are not — at least not any more than the Democratic party is.
  
Arguably,  both  the Democrats and the Republicans are “the party of the rich.”  But Republicans more so than Democrats (see above graph, also consider the debates over the estate tax and upper-income tax rates).  Cost writes:
  
Sure, the GOP favors tax rate reductions to generate economic growth, but the Democratic party has proven itself ready, willing, and able to dole out benefits to the well-heeled rent-seekers who swarm Washington, D.C. looking for favors from Uncle Sam.
  
But he’s missing the point.  The par</p><p>6 0.9790262 <a title="524-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>7 0.978944 <a title="524-lda-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-19-How_Americans_vote.html">2255 andrew gelman stats-2014-03-19-How Americans vote</a></p>
<p>8 0.97892874 <a title="524-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<p>9 0.97803152 <a title="524-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-05-Freakonomics%3A__Why_ask_%E2%80%9CWhat_went_wrong%3F%E2%80%9D.html">1100 andrew gelman stats-2012-01-05-Freakonomics:  Why ask “What went wrong?”</a></p>
<p>10 0.97748768 <a title="524-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-05-What_do_practitioners_need_to_know_about_regression%3F.html">451 andrew gelman stats-2010-12-05-What do practitioners need to know about regression?</a></p>
<p>11 0.97740483 <a title="524-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-03-He_doesn%E2%80%99t_trust_the_fit_._._._r%3D.999.html">315 andrew gelman stats-2010-10-03-He doesn’t trust the fit . . . r=.999</a></p>
<p>12 0.9772979 <a title="524-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>13 0.97723997 <a title="524-lda-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-03-Booze%3A_Been_There._Done_That..html">2158 andrew gelman stats-2014-01-03-Booze: Been There. Done That.</a></p>
<p>14 0.97723776 <a title="524-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-01-Doing_Data_Science%3A__What%E2%80%99s_it_all_about%3F.html">2084 andrew gelman stats-2013-11-01-Doing Data Science:  What’s it all about?</a></p>
<p>15 0.97716713 <a title="524-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-29-We_go_to_war_with_the_data_we_have%2C_not_the_data_we_want.html">1289 andrew gelman stats-2012-04-29-We go to war with the data we have, not the data we want</a></p>
<p>16 0.97701377 <a title="524-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-03-This_post_does_not_mention_Wegman.html">989 andrew gelman stats-2011-11-03-This post does not mention Wegman</a></p>
<p>17 0.97693115 <a title="524-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-02-Am_I_too_negative%3F.html">2279 andrew gelman stats-2014-04-02-Am I too negative?</a></p>
<p>18 0.97669053 <a title="524-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-18-Predictive_checks_for_hierarchical_models.html">154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</a></p>
<p>19 0.97667348 <a title="524-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>20 0.97650576 <a title="524-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-01-Peter_Huber%E2%80%99s_reflections_on_data_analysis.html">690 andrew gelman stats-2011-05-01-Peter Huber’s reflections on data analysis</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
