<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2014" href="../home/andrew_gelman_stats-2014_home.html">andrew_gelman_stats-2014</a> <a title="andrew_gelman_stats-2014-2357" href="#">andrew_gelman_stats-2014-2357</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2014-2357-html" href="http://andrewgelman.com/2014/06/02/hate-stepwise-regression/">html</a></p><p>Introduction: Haynes Goddard writes:
  
I have been slowly working my way through the grad program in stats here, and the latest course was a biostats course on categorical and survival analysis.  I noticed in the semi-parametric  and parametric material (Wang and Lee is the text) that they use stepwise regression a lot.


I learned in econometrics that stepwise is poor practice, as it defaults to the “theory of the regression line”, that is no theory at all, just the variation in the data.


I don’t find the topic on your blog, and wonder if you have addressed the issue.
  
My reply:
 
Stepwise regression is one of these things, like outlier detection and pie charts, which appear to be popular among non-statisticans but are considered by statisticians to be a bit of a joke.  For example, Jennifer and I don’t mention stepwise regression in our book, not even once.
 
To address the issue more directly:  the motivation behind stepwise regression is that you have a lot of potential predictors but not e</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Haynes Goddard writes:    I have been slowly working my way through the grad program in stats here, and the latest course was a biostats course on categorical and survival analysis. [sent-1, score-0.881]
</p><p>2 I noticed in the semi-parametric  and parametric material (Wang and Lee is the text) that they use stepwise regression a lot. [sent-2, score-1.215]
</p><p>3 I learned in econometrics that stepwise is poor practice, as it defaults to the “theory of the regression line”, that is no theory at all, just the variation in the data. [sent-3, score-1.467]
</p><p>4 I don’t find the topic on your blog, and wonder if you have addressed the issue. [sent-4, score-0.097]
</p><p>5 My reply:   Stepwise regression is one of these things, like outlier detection and pie charts, which appear to be popular among non-statisticans but are considered by statisticians to be a bit of a joke. [sent-5, score-0.818]
</p><p>6 For example, Jennifer and I don’t mention stepwise regression in our book, not even once. [sent-6, score-1.056]
</p><p>7 To address the issue more directly:  the motivation behind stepwise regression is that you have a lot of potential predictors but not enough data to estimate their coefficients in any meaningful way. [sent-7, score-1.422]
</p><p>8 This sort of problem comes up all the time, for example  here’s an example  from my research, a meta-analysis of the effects of incentives in sample surveys. [sent-8, score-0.218]
</p><p>9 The trouble with stepwise regression is that, at any given step, the model is fit using unconstrained least squares. [sent-9, score-1.161]
</p><p>10 I prefer methods such as factor analysis or lasso that group or constrain the coefficient estimates in some way. [sent-10, score-0.415]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('stepwise', 0.721), ('regression', 0.265), ('biostats', 0.138), ('goddard', 0.138), ('constrain', 0.12), ('outlier', 0.114), ('defaults', 0.111), ('detection', 0.109), ('unconstrained', 0.109), ('categorical', 0.107), ('parametric', 0.102), ('pie', 0.102), ('wang', 0.102), ('lasso', 0.1), ('survival', 0.097), ('addressed', 0.097), ('theory', 0.094), ('slowly', 0.09), ('charts', 0.088), ('meaningful', 0.085), ('econometrics', 0.085), ('grad', 0.083), ('lee', 0.082), ('incentives', 0.08), ('stats', 0.08), ('course', 0.078), ('motivation', 0.075), ('coefficient', 0.074), ('jennifer', 0.073), ('text', 0.071), ('address', 0.071), ('latest', 0.07), ('behind', 0.07), ('mention', 0.07), ('coefficients', 0.07), ('example', 0.069), ('trouble', 0.066), ('predictors', 0.065), ('factor', 0.065), ('poor', 0.065), ('noticed', 0.064), ('learned', 0.064), ('material', 0.063), ('variation', 0.062), ('program', 0.06), ('popular', 0.058), ('appear', 0.058), ('statisticians', 0.056), ('considered', 0.056), ('prefer', 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="2357-tfidf-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-Why_we_hate_stepwise_regression.html">2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</a></p>
<p>Introduction: Haynes Goddard writes:
  
I have been slowly working my way through the grad program in stats here, and the latest course was a biostats course on categorical and survival analysis.  I noticed in the semi-parametric  and parametric material (Wang and Lee is the text) that they use stepwise regression a lot.


I learned in econometrics that stepwise is poor practice, as it defaults to the “theory of the regression line”, that is no theory at all, just the variation in the data.


I don’t find the topic on your blog, and wonder if you have addressed the issue.
  
My reply:
 
Stepwise regression is one of these things, like outlier detection and pie charts, which appear to be popular among non-statisticans but are considered by statisticians to be a bit of a joke.  For example, Jennifer and I don’t mention stepwise regression in our book, not even once.
 
To address the issue more directly:  the motivation behind stepwise regression is that you have a lot of potential predictors but not e</p><p>2 0.39441055 <a title="2357-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>Introduction: Bill Harris writes:
  
On pp. 250-251 of BDA second edition, you write about multiple comparisons, and you write about stepwise regression on p. 405.  How would you look at stepwise regression analyses in light of the multiple comparisons problem?  Is there an issue?
  
My reply:
 
In this case I think the right approach is to keep all the coefs but partially pool them toward 0 (after suitable transformation).  But then the challenge is coming up with a general way to construct good prior distributions.  Iâ&euro;&trade;m still thinking about that one!  Yet another approach is to put something together purely nonparametrically as with Bart.</p><p>3 0.21129006 <a title="2357-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-26-On_deck_this_week.html">2348 andrew gelman stats-2014-05-26-On deck this week</a></p>
<p>Introduction: Mon:   WAIC and cross-validation in Stan!
 
 Tues:   A whole fleet of gremlins:  Looking more carefully at Richard Tol’s twice-corrected paper, “The Economic Effects of Climate Change”
 
 Wed:   Just wondering
 
 Thurs:   When you believe in things that you don’t understand
 
 Fri:   I posted this as a comment on a sociology blog
 
 Sat:   “Building on theories used to describe magnets, scientists have put together a model that captures something very different . . .”
 
 Sun:   Why we hate stepwise regression</p><p>4 0.18337865 <a title="2357-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-On_deck_this_week.html">2356 andrew gelman stats-2014-06-02-On deck this week</a></p>
<p>Introduction: Mon:   Why we hate stepwise regression
 
 Tues:   Did you buy laundry detergent on their most recent trip to the store? Also comments on scientific publication and yet another suggestion to do a study that allows within-person comparisons
 
 Wed:   All the Assumptions That Are My Life
 
 Thurs:   Identifying pathways for managing multiple disturbances to limit plant invasions
 
 Fri:   Statistically savvy journalism
 
 Sat:   “Does researching casual marijuana use cause brain abnormalities?”
 
 Sun:   Regression and causality and variable ordering</p><p>5 0.1362469 <a title="2357-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-18-Tibshirani_announces_new_research_result%3A__A_significance_test_for_the_lasso.html">1769 andrew gelman stats-2013-03-18-Tibshirani announces new research result:  A significance test for the lasso</a></p>
<p>Introduction: Lasso and me 
 
For a long time I was wrong about lasso.
 
Lasso (“least absolute shrinkage and selection operator”) is a regularization procedure that shrinks regression coefficients toward zero, and in its basic form is equivalent to maximum penalized likelihood estimation with a penalty function that is proportional to the sum of the absolute values of the regression coefficients.
 
I first heard about lasso from a talk that  Trevor Hastie  Rob Tibshirani gave at Berkeley in 1994 or 1995.  He demonstrated that it shrunk regression coefficients to zero.  I wasn’t impressed, first because it seemed like no big deal (if that’s the prior you use, that’s the shrinkage you get) and second because, from a Bayesian perspective, I don’t  want  to shrink things all the way to zero.  In the sorts of social and environmental science problems I’ve worked on, just about nothing is zero.  I’d like to control my noisy estimates but there’s nothing special about zero.  At the end of the talk I stood</p><p>6 0.11825454 <a title="2357-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Matching_and_regression%3A__two_great_tastes_etc_etc.html">796 andrew gelman stats-2011-07-10-Matching and regression:  two great tastes etc etc</a></p>
<p>7 0.11418616 <a title="2357-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<p>8 0.11404345 <a title="2357-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>9 0.10643578 <a title="2357-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Toward_a_framework_for_automatic_model_building.html">1718 andrew gelman stats-2013-02-11-Toward a framework for automatic model building</a></p>
<p>10 0.10176391 <a title="2357-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-05-What_do_practitioners_need_to_know_about_regression%3F.html">451 andrew gelman stats-2010-12-05-What do practitioners need to know about regression?</a></p>
<p>11 0.089351542 <a title="2357-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-09-Same_old_same_old.html">1849 andrew gelman stats-2013-05-09-Same old same old</a></p>
<p>12 0.087345935 <a title="2357-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-21-Building_a_regression_model_._._._with_only_27_data_points.html">1506 andrew gelman stats-2012-09-21-Building a regression model . . . with only 27 data points</a></p>
<p>13 0.083821215 <a title="2357-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-13-Hey%21__Here%E2%80%99s_a_referee_report_for_you%21.html">144 andrew gelman stats-2010-07-13-Hey!  Here’s a referee report for you!</a></p>
<p>14 0.081724837 <a title="2357-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-31-Using_factor_analysis_or_principal_components_analysis_or_measurement-error_models_for_biological_measurements_in_archaeology%3F.html">1094 andrew gelman stats-2011-12-31-Using factor analysis or principal components analysis or measurement-error models for biological measurements in archaeology?</a></p>
<p>15 0.080091529 <a title="2357-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-How_does_Bayes_do_it%3F.html">247 andrew gelman stats-2010-09-01-How does Bayes do it?</a></p>
<p>16 0.076325804 <a title="2357-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>17 0.075041294 <a title="2357-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-26-How_to_understand_coefficients_that_reverse_sign_when_you_start_controlling_for_things%3F.html">1870 andrew gelman stats-2013-05-26-How to understand coefficients that reverse sign when you start controlling for things?</a></p>
<p>18 0.074206822 <a title="2357-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>19 0.073809944 <a title="2357-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>20 0.073633432 <a title="2357-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.131), (1, 0.06), (2, 0.025), (3, -0.015), (4, 0.07), (5, 0.031), (6, -0.007), (7, -0.024), (8, 0.054), (9, 0.067), (10, 0.027), (11, 0.046), (12, 0.045), (13, 0.017), (14, 0.049), (15, 0.02), (16, -0.048), (17, 0.009), (18, 0.014), (19, -0.004), (20, 0.014), (21, 0.045), (22, 0.001), (23, 0.026), (24, 0.008), (25, 0.011), (26, 0.063), (27, -0.082), (28, -0.048), (29, -0.032), (30, 0.055), (31, 0.048), (32, 0.008), (33, 0.008), (34, 0.006), (35, -0.036), (36, 0.009), (37, 0.018), (38, -0.039), (39, -0.013), (40, 0.025), (41, 0.049), (42, -0.021), (43, -0.054), (44, 0.086), (45, 0.024), (46, -0.025), (47, 0.024), (48, 0.04), (49, -0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96863693 <a title="2357-lsi-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-Why_we_hate_stepwise_regression.html">2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</a></p>
<p>Introduction: Haynes Goddard writes:
  
I have been slowly working my way through the grad program in stats here, and the latest course was a biostats course on categorical and survival analysis.  I noticed in the semi-parametric  and parametric material (Wang and Lee is the text) that they use stepwise regression a lot.


I learned in econometrics that stepwise is poor practice, as it defaults to the “theory of the regression line”, that is no theory at all, just the variation in the data.


I don’t find the topic on your blog, and wonder if you have addressed the issue.
  
My reply:
 
Stepwise regression is one of these things, like outlier detection and pie charts, which appear to be popular among non-statisticans but are considered by statisticians to be a bit of a joke.  For example, Jennifer and I don’t mention stepwise regression in our book, not even once.
 
To address the issue more directly:  the motivation behind stepwise regression is that you have a lot of potential predictors but not e</p><p>2 0.85374063 <a title="2357-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Matching_and_regression%3A__two_great_tastes_etc_etc.html">796 andrew gelman stats-2011-07-10-Matching and regression:  two great tastes etc etc</a></p>
<p>Introduction: Matthew Bogard writes:
  
Regarding the book Mostly Harmless Econometrics, you  state :

 
A casual reader of the book might be left with the unfortunate impression that matching is a competitor to regression rather than a tool for making regression more effective.
 

But in fact isn’t that what they are arguing, that, in a  ‘mostly harmless way’ regression is in fact a matching estimator itself?


“Our view is that regression can be motivated as a particular sort of weighted matching estimator, and therefore the differences between regression and matching estimates are unlikely to be of major empirical importance” (Chapter 3 p. 70)


They seem to be distinguishing regression (without prior matching) from all other types of matching techniques, and therefore implying that regression can be a ‘mostly harmless’ substitute or competitor to matching. My previous understanding, before starting this book was as you say, that matching is a tool that makes regression more effective.


I have n</p><p>3 0.84229422 <a title="2357-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>Introduction: Bill Harris writes:
  
On pp. 250-251 of BDA second edition, you write about multiple comparisons, and you write about stepwise regression on p. 405.  How would you look at stepwise regression analyses in light of the multiple comparisons problem?  Is there an issue?
  
My reply:
 
In this case I think the right approach is to keep all the coefs but partially pool them toward 0 (after suitable transformation).  But then the challenge is coming up with a general way to construct good prior distributions.  Iâ&euro;&trade;m still thinking about that one!  Yet another approach is to put something together purely nonparametrically as with Bart.</p><p>4 0.81029165 <a title="2357-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>Introduction: David Hoaglin writes:
  
After seeing it cited, I just read  your paper  in Technometrics.  The home radon levels provide an interesting and instructive example.


I [Hoaglin] have a different take on the difficulty of interpreting the estimated coefficient of the county-level basement proportion (gamma-sub-2) on page 434.  An important part of the difficulty involves “other things being equal.”  That sounds like the widespread interpretation of a regression coefficient as telling how the dependent variable responds to change in that predictor when the other predictors are held constant.  Unfortunately, as a general interpretation, that language is oversimplified; it doesn’t reflect how regression actually works.  The appropriate general interpretation is that the coefficient tells how the dependent variable responds to change in that predictor after allowing for simultaneous change in the other predictors in the data at hand.  Thus, in the county-level regression gamma-sub-2 summarize</p><p>5 0.80448139 <a title="2357-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-31-Using_factor_analysis_or_principal_components_analysis_or_measurement-error_models_for_biological_measurements_in_archaeology%3F.html">1094 andrew gelman stats-2011-12-31-Using factor analysis or principal components analysis or measurement-error models for biological measurements in archaeology?</a></p>
<p>Introduction: Greg Campbell writes:
  
I am a Canadian archaeologist (BSc in Chemistry) researching the past human use of European Atlantic shellfish. After two decades of practice I am finally getting a MA in archaeology at Reading. I am seeing if the habitat or size of harvested mussels (Mytilus edulis) can be reconstructed from measurements of the umbo (the pointy end, and the only bit that survives well in archaeological deposits) using log-transformed measurements (or allometry; relationships between dimensions are more likely exponential than linear). 
Of course multivariate regressions in most statistics packages (Minitab, SPSS, SAS) assume you are trying to predict one variable from all the others (a Model I regression), and use ordinary least squares to fit the regression line. For organismal dimensions this makes little sense, since all the dimensions are (at least in theory) free to change their mutual proportions during growth. So there is no predictor and predicted, mutual variation of</p><p>6 0.79732734 <a title="2357-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-05-What_do_practitioners_need_to_know_about_regression%3F.html">451 andrew gelman stats-2010-12-05-What do practitioners need to know about regression?</a></p>
<p>7 0.79715925 <a title="2357-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-13-Hey%21__Here%E2%80%99s_a_referee_report_for_you%21.html">144 andrew gelman stats-2010-07-13-Hey!  Here’s a referee report for you!</a></p>
<p>8 0.77611601 <a title="2357-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-26-How_to_understand_coefficients_that_reverse_sign_when_you_start_controlling_for_things%3F.html">1870 andrew gelman stats-2013-05-26-How to understand coefficients that reverse sign when you start controlling for things?</a></p>
<p>9 0.74405277 <a title="2357-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>10 0.74387467 <a title="2357-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>11 0.72659904 <a title="2357-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-15-Still_more_Mr._P_in_public_health.html">770 andrew gelman stats-2011-06-15-Still more Mr. P in public health</a></p>
<p>12 0.70278084 <a title="2357-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-09-Same_old_same_old.html">1849 andrew gelman stats-2013-05-09-Same old same old</a></p>
<p>13 0.7021327 <a title="2357-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-29-Alternatives_to_regression_for_social_science_predictions.html">10 andrew gelman stats-2010-04-29-Alternatives to regression for social science predictions</a></p>
<p>14 0.69858634 <a title="2357-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-28-Matching_for_preprocessing_data_for_causal_inference.html">375 andrew gelman stats-2010-10-28-Matching for preprocessing data for causal inference</a></p>
<p>15 0.69021952 <a title="2357-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-Displaying_inferences_from_complex_models.html">1815 andrew gelman stats-2013-04-20-Displaying inferences from complex models</a></p>
<p>16 0.68832731 <a title="2357-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Multilevel_quantile_regression.html">397 andrew gelman stats-2010-11-06-Multilevel quantile regression</a></p>
<p>17 0.68226802 <a title="2357-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-There_are_never_70_distinct_parameters.html">327 andrew gelman stats-2010-10-07-There are never 70 distinct parameters</a></p>
<p>18 0.67741877 <a title="2357-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>19 0.65811592 <a title="2357-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<p>20 0.65746492 <a title="2357-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-14-The_statistics_and_the_science.html">146 andrew gelman stats-2010-07-14-The statistics and the science</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.015), (6, 0.014), (16, 0.038), (21, 0.077), (24, 0.146), (38, 0.016), (40, 0.013), (42, 0.117), (49, 0.017), (62, 0.03), (69, 0.069), (90, 0.025), (99, 0.305)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95565844 <a title="2357-lda-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-Why_we_hate_stepwise_regression.html">2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</a></p>
<p>Introduction: Haynes Goddard writes:
  
I have been slowly working my way through the grad program in stats here, and the latest course was a biostats course on categorical and survival analysis.  I noticed in the semi-parametric  and parametric material (Wang and Lee is the text) that they use stepwise regression a lot.


I learned in econometrics that stepwise is poor practice, as it defaults to the “theory of the regression line”, that is no theory at all, just the variation in the data.


I don’t find the topic on your blog, and wonder if you have addressed the issue.
  
My reply:
 
Stepwise regression is one of these things, like outlier detection and pie charts, which appear to be popular among non-statisticans but are considered by statisticians to be a bit of a joke.  For example, Jennifer and I don’t mention stepwise regression in our book, not even once.
 
To address the issue more directly:  the motivation behind stepwise regression is that you have a lot of potential predictors but not e</p><p>2 0.95478404 <a title="2357-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-30-What_Auteur_Theory_and_Freshwater_Economics_have_in_common.html">60 andrew gelman stats-2010-05-30-What Auteur Theory and Freshwater Economics have in common</a></p>
<p>Introduction: Mark Palko  writes :
  
 
We’ll define freshwater economics as the theory that economic behavior (and perhaps most non-economic behavior) can be explained using the concepts of rational actors and efficient markets and auteur theory as the idea that most films (particularly great films) represent the artistic vision of a single author (almost always the director) and the best way to approach one of those films is through the body of work of its author. Both of these definitions are oversimplified and a bit unfair but they will get the discussion started. . . .


Compared to their nearest neighbors, film criticism and economics (particularly macroeconomics) are both difficult, messy fields. Films are collaborative efforts where individual contributions defy attribution and creative decisions often can’t be distinguished from accidents of filming. Worse yet, most films are the product of large corporations which means that dozens of VPs and executives might have played a role (sometimes</p><p>3 0.95141494 <a title="2357-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Freakonomics_Experiments.html">1692 andrew gelman stats-2013-01-25-Freakonomics Experiments</a></p>
<p>Introduction: Stephen Dubner  writes :
  
Freakonomics Experiments is a set of simple experiments about complex issues—whether to break up with your significant other, quit your job, or start a diet, just to name a few. . . . a collaboration between researchers at the University of Chicago, Freakonomics, and—we hope!—you. Steve Levitt and John List, of the University of Chicago, run the experimental and statistical side of things. Stephen Dubner, Steve Levitt, and the Freakonomics staff have given these experiments the Freakonomics twist you’re used to. Once you flip the coin, you become a member of the most important part of the collaboration, the Freakonomics Experiments team. Without your participation, we couldn’t complete any of this research. . . .


You’ll choose a question that you are facing today, such as whether to quit your job or buy a house. Then you’ll provide us some background information about yourself. After that, you’ll flip the coin to find out what you should do in your situati</p><p>4 0.94410402 <a title="2357-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>Introduction: Bill Harris writes:
  
On pp. 250-251 of BDA second edition, you write about multiple comparisons, and you write about stepwise regression on p. 405.  How would you look at stepwise regression analyses in light of the multiple comparisons problem?  Is there an issue?
  
My reply:
 
In this case I think the right approach is to keep all the coefs but partially pool them toward 0 (after suitable transformation).  But then the challenge is coming up with a general way to construct good prior distributions.  Iâ&euro;&trade;m still thinking about that one!  Yet another approach is to put something together purely nonparametrically as with Bart.</p><p>5 0.94169104 <a title="2357-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-18-The_estimated_effect_size_is_implausibly_large.__Under_what_models_is_this_a_piece_of_evidence_that_the_true_effect_is_small%3F.html">808 andrew gelman stats-2011-07-18-The estimated effect size is implausibly large.  Under what models is this a piece of evidence that the true effect is small?</a></p>
<p>Introduction: Paul Pudaite writes in response to  my discussion with Bartels  regarding effect sizes and measurement error models:
  
You [Gelman] wrote: “I actually think there will be some (non-Gaussian) models for which, as y gets larger, E(x|y) can actually go back toward zero.”


I [Pudaite] encountered this phenomenon some time in the ’90s. See this graph which shows the conditional expectation of X given Z, when Z = X + Y and the probability density functions of X and Y are, respectively, exp(-x^2) and 1/(y^2+1) (times appropriate constants). As the magnitude of Z increases, E[X|Z] shrinks to zero.


 


I wasn’t sure it was worth the effort to try to publish a two paragraph paper.


I suspect that this is true whenever the tail of one distribution is ‘sufficiently heavy’ with respect to the tail of the other. Hmm, I suppose there might be enough substance in a paper that attempted to characterize this outcome for, say, unimodal symmetric distributions.
  
Maybe someone can do this? I think i</p><p>6 0.93757439 <a title="2357-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-07-A_compelling_reason_to_go_to_London%2C_Ontario%3F%3F.html">1104 andrew gelman stats-2012-01-07-A compelling reason to go to London, Ontario??</a></p>
<p>7 0.93734759 <a title="2357-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-15-1-2_social_scientist_%2B_1-2_politician_%3D_%3F%3F%3F.html">713 andrew gelman stats-2011-05-15-1-2 social scientist + 1-2 politician = ???</a></p>
<p>8 0.93719214 <a title="2357-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-25-Good_introductory_book_for_statistical_computation%3F.html">590 andrew gelman stats-2011-02-25-Good introductory book for statistical computation?</a></p>
<p>9 0.93694901 <a title="2357-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>10 0.93674099 <a title="2357-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-20-A_kaleidoscope_of_responses_to_Dubner%E2%80%99s_criticisms_of_our_criticisms_of_Freaknomics.html">1223 andrew gelman stats-2012-03-20-A kaleidoscope of responses to Dubner’s criticisms of our criticisms of Freaknomics</a></p>
<p>11 0.93643904 <a title="2357-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-13-Economic_policy_does_not_occur_in_a_political_vacuum.html">1936 andrew gelman stats-2013-07-13-Economic policy does not occur in a political vacuum</a></p>
<p>12 0.93519342 <a title="2357-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-25-Chris_Schmid_on_Evidence_Based_Medicine.html">1138 andrew gelman stats-2012-01-25-Chris Schmid on Evidence Based Medicine</a></p>
<p>13 0.93395776 <a title="2357-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-09-How_to_model_distributions_that_have_outliers_in_one_direction.html">2128 andrew gelman stats-2013-12-09-How to model distributions that have outliers in one direction</a></p>
<p>14 0.93305367 <a title="2357-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-30-That_puzzle-solving_feeling.html">492 andrew gelman stats-2010-12-30-That puzzle-solving feeling</a></p>
<p>15 0.93303072 <a title="2357-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-23-Science%2C_ideology%2C_and_human_origins.html">483 andrew gelman stats-2010-12-23-Science, ideology, and human origins</a></p>
<p>16 0.93039382 <a title="2357-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>17 0.92753863 <a title="2357-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-18-What_to_read_to_catch_up_on_multivariate_statistics%3F.html">1726 andrew gelman stats-2013-02-18-What to read to catch up on multivariate statistics?</a></p>
<p>18 0.92749447 <a title="2357-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-01-Going_meta_on_Niall_Ferguson.html">1921 andrew gelman stats-2013-07-01-Going meta on Niall Ferguson</a></p>
<p>19 0.92628312 <a title="2357-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-10-The_ethics_of_lying%2C_cheating%2C_and_stealing_with_data%3A__A_case_study.html">2015 andrew gelman stats-2013-09-10-The ethics of lying, cheating, and stealing with data:  A case study</a></p>
<p>20 0.92592841 <a title="2357-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-06-Against_optimism_about_social_science.html">1844 andrew gelman stats-2013-05-06-Against optimism about social science</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
