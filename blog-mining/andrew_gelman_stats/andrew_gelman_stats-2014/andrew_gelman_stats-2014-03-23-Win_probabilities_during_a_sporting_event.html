<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2262 andrew gelman stats-2014-03-23-Win probabilities during a sporting event</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2014" href="../home/andrew_gelman_stats-2014_home.html">andrew_gelman_stats-2014</a> <a title="andrew_gelman_stats-2014-2262" href="#">andrew_gelman_stats-2014-2262</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2262 andrew gelman stats-2014-03-23-Win probabilities during a sporting event</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2014-2262-html" href="http://andrewgelman.com/2014/03/23/23074/">html</a></p><p>Introduction: Todd Schneider writes: 
   
 
 Apropos of your recent  blog post about modeling score differential of basketball games , I thought you might enjoy a site I built, gambletron2000.com , that gathers real-time win probabilities from betting markets for most major sports (including NBA and college basketball). 
  
 My original goal was to use the variance of changes in win probabilities to quantify which games were the most exciting, but I got a bit carried away and ended up pursuing a bunch of other ideas, whichÂ  you can read about in the full writeup here  
  
 This particular passage from the anonymous someone in your post: 
  

My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.

  
 reminded me of a graph I made, which shows the mean-reverting tendency of N</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Todd Schneider writes:         Apropos of your recent  blog post about modeling score differential of basketball games , I thought you might enjoy a site I built, gambletron2000. [sent-1, score-1.115]
</p><p>2 com , that gathers real-time win probabilities from betting markets for most major sports (including NBA and college basketball). [sent-2, score-1.137]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nba', 0.295), ('win', 0.257), ('probabilities', 0.255), ('differential', 0.234), ('basketball', 0.231), ('games', 0.205), ('score', 0.18), ('schneider', 0.169), ('timestep', 0.169), ('vegas', 0.16), ('todd', 0.153), ('writeup', 0.153), ('possessions', 0.153), ('gathers', 0.153), ('nfl', 0.143), ('pace', 0.133), ('betting', 0.131), ('pursuing', 0.123), ('quantify', 0.123), ('seconds', 0.12), ('carried', 0.12), ('minute', 0.118), ('ball', 0.114), ('anonymous', 0.108), ('passage', 0.106), ('played', 0.105), ('markets', 0.102), ('tendency', 0.102), ('built', 0.099), ('sports', 0.096), ('ended', 0.095), ('exciting', 0.095), ('intervals', 0.09), ('enjoy', 0.09), ('site', 0.088), ('post', 0.087), ('reminded', 0.085), ('game', 0.084), ('account', 0.084), ('home', 0.082), ('create', 0.081), ('team', 0.078), ('variance', 0.077), ('changes', 0.075), ('shows', 0.073), ('major', 0.072), ('etc', 0.072), ('college', 0.071), ('differences', 0.067), ('bunch', 0.067)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="2262-tfidf-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-23-Win_probabilities_during_a_sporting_event.html">2262 andrew gelman stats-2014-03-23-Win probabilities during a sporting event</a></p>
<p>Introduction: Todd Schneider writes: 
   
 
 Apropos of your recent  blog post about modeling score differential of basketball games , I thought you might enjoy a site I built, gambletron2000.com , that gathers real-time win probabilities from betting markets for most major sports (including NBA and college basketball). 
  
 My original goal was to use the variance of changes in win probabilities to quantify which games were the most exciting, but I got a bit carried away and ended up pursuing a bunch of other ideas, whichÂ  you can read about in the full writeup here  
  
 This particular passage from the anonymous someone in your post: 
  

My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.

  
 reminded me of a graph I made, which shows the mean-reverting tendency of N</p><p>2 0.48445839 <a title="2262-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-25-Basketball_Stats%3A__Don%E2%80%99t_model_the_probability_of_win%2C_model_the_expected_score_differential..html">2224 andrew gelman stats-2014-02-25-Basketball Stats:  Don’t model the probability of win, model the expected score differential.</a></p>
<p>Introduction: Someone who wants to remain anonymous writes:
  
I am working to create a more accurate in-game win probability model for basketball games. My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.


This problem would seem to fit a multi-level model structure well. It seems silly to estimate 2,000 regressions (one for each timestep), but the coefficients should vary at each timestep. Do you have suggestions for what type of model this could/would be? Additionally, I believe this needs to be some form of logit/probit given the binary dependent variable (win or loss).


Finally, do you have suggestions for what package could accomplish this in Stata or R?
  
To answer the questions in reverse order: 
3.  I’d hope this could be done in Stan (which can be run from R)</p><p>3 0.25839853 <a title="2262-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-26-Econometrics%2C_political_science%2C_epidemiology%2C_etc.%3A__Don%E2%80%99t_model_the_probability_of_a_discrete_outcome%2C_model_the_underlying_continuous_variable.html">2226 andrew gelman stats-2014-02-26-Econometrics, political science, epidemiology, etc.:  Don’t model the probability of a discrete outcome, model the underlying continuous variable</a></p>
<p>Introduction: This is an echo of yesterday’s post,  Basketball Stats: Don’t model the probability of win, model the expected score differential .
 
As with basketball, so with baseball:  as the great Bill James wrote, if you want to predict a pitcher’s win-loss record, it’s better to use last year’s ERA than last year’s W-L.
 
As with basketball and baseball, so with epidemiology:  as Joseph Delaney  points out  in my favorite blog that nobody reads, you will see much better prediction if you first model change in the parameter (e.g. blood pressure) and then convert that to the binary disease state (e.g. hypertension) then if you just develop a logistic model for prob(hypertension).
 
As with basketball, baseball, and epidemiology, so with political science:  instead of modeling election winners, better to model vote differential, a point that I made back in 1993 (see page 120  here ) but which seems to continually need  repeating .  A forecasting method should get essentially no credit for correctl</p><p>4 0.19823514 <a title="2262-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-15-Of_forecasts_and_graph_theory_and_characterizing_a_statistical_method_by_the_information_it_uses.html">1214 andrew gelman stats-2012-03-15-Of forecasts and graph theory and characterizing a statistical method by the information it uses</a></p>
<p>Introduction: Wayne Folta points me to  “EigenBracket 2012: Using Graph Theory to Predict NCAA March Madness Basketball”  and writes, “I [Folta] have got to believe that he’s simply re-invented a statistical method in a graph-ish context, but don’t know enough to judge.”
 
I have not looked in detail at the method being presented here—I’m not much of college basketball fan—but I’d like to use this as an excuse to make one of my favorite general point, which is that a good way to characterize any statistical method is by what information it uses. 
   
The basketball ranking method here uses score differentials between teams in the past season.  On the plus side, that is better than simply using one-loss records (which (a) discards score differentials and (b) discards information on who played whom).  On the minus side, the method appears to be discretizing the scores (thus throwing away information on the exact score differential) and doesn’t use any external information such as external ratings.
 
A</p><p>5 0.1424157 <a title="2262-tfidf-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-24-On_deck_this_week.html">2222 andrew gelman stats-2014-02-24-On deck this week</a></p>
<p>Introduction: Mon:   “Edlin’s rule” for routinely scaling down published estimates
 
 Tues:   Basketball Stats: Don’t model the probability of win, model the expected score differential
 
 Wed:   A good comment on one of my papers
 
 Thurs:   “What Can we Learn from the Many Labs Replication Project?”
 
 Fri:   God/leaf/tree
 
 Sat:   “We are moving from an era of private data and public analyses to one of public data and private analyses. Just as we have learned to be cautious about data that are missing, we may have to be cautious about missing analyses also.”</p><p>6 0.13439566 <a title="2262-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-03-Best_lottery_story_ever.html">1242 andrew gelman stats-2012-04-03-Best lottery story ever</a></p>
<p>7 0.13258211 <a title="2262-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-03-Bayes_pays%21.html">1923 andrew gelman stats-2013-07-03-Bayes pays!</a></p>
<p>8 0.12348156 <a title="2262-tfidf-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Bayesian_Uncertainty_Quantification_for_Differential_Equations%21.html">2311 andrew gelman stats-2014-04-29-Bayesian Uncertainty Quantification for Differential Equations!</a></p>
<p>9 0.11489145 <a title="2262-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-08-Of_parsing_and_chess.html">1847 andrew gelman stats-2013-05-08-Of parsing and chess</a></p>
<p>10 0.1120773 <a title="2262-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-30-Silly_baseball_example_illustrates_a_couple_of_key_ideas_they_don%E2%80%99t_usually_teach_you_in_statistics_class.html">171 andrew gelman stats-2010-07-30-Silly baseball example illustrates a couple of key ideas they don’t usually teach you in statistics class</a></p>
<p>11 0.10561018 <a title="2262-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-21-Will_Tiger_Woods_catch_Jack_Nicklaus%3F__And_a_discussion_of_the_virtues_of_using_continuous_data_even_if_your_goal_is_discrete_prediction.html">1387 andrew gelman stats-2012-06-21-Will Tiger Woods catch Jack Nicklaus?  And a discussion of the virtues of using continuous data even if your goal is discrete prediction</a></p>
<p>12 0.10453079 <a title="2262-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-20-I_think_you_knew_this_already.html">218 andrew gelman stats-2010-08-20-I think you knew this already</a></p>
<p>13 0.099898674 <a title="2262-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-18-%E2%80%9CIntrade_to_the_57th_power%E2%80%9D.html">1540 andrew gelman stats-2012-10-18-“Intrade to the 57th power”</a></p>
<p>14 0.099854611 <a title="2262-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-22-Is_it_meaningful_to_talk_about_a_probability_of_%E2%80%9C65.7%25%E2%80%9D_that_Obama_will_win_the_election%3F.html">1544 andrew gelman stats-2012-10-22-Is it meaningful to talk about a probability of “65.7%” that Obama will win the election?</a></p>
<p>15 0.094845966 <a title="2262-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-17-Sports_examples_in_class.html">1173 andrew gelman stats-2012-02-17-Sports examples in class</a></p>
<p>16 0.088423163 <a title="2262-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-12-Probability_of_successive_wins_in_baseball.html">29 andrew gelman stats-2010-05-12-Probability of successive wins in baseball</a></p>
<p>17 0.080675066 <a title="2262-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-19-Paired_comparisons.html">99 andrew gelman stats-2010-06-19-Paired comparisons</a></p>
<p>18 0.07647334 <a title="2262-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-03-Gladwell_vs_Pinker.html">253 andrew gelman stats-2010-09-03-Gladwell vs Pinker</a></p>
<p>19 0.075862572 <a title="2262-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-05-Let%E2%80%99s_try_this%3A__Instead_of_saying%2C_%E2%80%9CThe_probability_is_75%25%2C%E2%80%9D_say_%E2%80%9CThere%E2%80%99s_a_25%25_chance_I%E2%80%99m_wrong%E2%80%9D.html">1562 andrew gelman stats-2012-11-05-Let’s try this:  Instead of saying, “The probability is 75%,” say “There’s a 25% chance I’m wrong”</a></p>
<p>20 0.074716493 <a title="2262-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-11-Hunger_Games_survival_analysis.html">1260 andrew gelman stats-2012-04-11-Hunger Games survival analysis</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.107), (1, -0.002), (2, 0.033), (3, 0.034), (4, 0.046), (5, -0.009), (6, 0.013), (7, -0.01), (8, 0.014), (9, -0.052), (10, 0.013), (11, 0.037), (12, -0.019), (13, -0.026), (14, -0.073), (15, 0.01), (16, 0.032), (17, -0.013), (18, 0.044), (19, -0.02), (20, -0.021), (21, 0.095), (22, 0.002), (23, 0.051), (24, 0.074), (25, 0.03), (26, 0.037), (27, 0.085), (28, -0.066), (29, -0.181), (30, 0.034), (31, -0.08), (32, -0.003), (33, -0.003), (34, -0.001), (35, -0.009), (36, 0.061), (37, 0.008), (38, -0.006), (39, 0.036), (40, -0.03), (41, -0.083), (42, 0.052), (43, -0.04), (44, -0.008), (45, 0.02), (46, 0.018), (47, 0.04), (48, -0.14), (49, -0.002)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98004365 <a title="2262-lsi-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-23-Win_probabilities_during_a_sporting_event.html">2262 andrew gelman stats-2014-03-23-Win probabilities during a sporting event</a></p>
<p>Introduction: Todd Schneider writes: 
   
 
 Apropos of your recent  blog post about modeling score differential of basketball games , I thought you might enjoy a site I built, gambletron2000.com , that gathers real-time win probabilities from betting markets for most major sports (including NBA and college basketball). 
  
 My original goal was to use the variance of changes in win probabilities to quantify which games were the most exciting, but I got a bit carried away and ended up pursuing a bunch of other ideas, whichÂ  you can read about in the full writeup here  
  
 This particular passage from the anonymous someone in your post: 
  

My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.

  
 reminded me of a graph I made, which shows the mean-reverting tendency of N</p><p>2 0.6685341 <a title="2262-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-03-Best_lottery_story_ever.html">1242 andrew gelman stats-2012-04-03-Best lottery story ever</a></p>
<p>Introduction: Kansas Man Does Not Win Lottery, Is Struck By Lightning .
 
Finally, a  story  that gets the probabilities right.</p><p>3 0.66394049 <a title="2262-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Bidding_for_the_kickoff.html">559 andrew gelman stats-2011-02-06-Bidding for the kickoff</a></p>
<p>Introduction: Steven Brams and James Jorash propose  a system  for reducing the advantage that comes from winning the coin flip in overtime:
  
Dispensing with a coin toss, the teams would bid on where the ball is kicked from by the kicking team. In the NFL, it’s now the 30-yard line. Under Brams and Jorasch’s rule, the kicking team would be the team that bids the lower number, because it is willing to put itself at a disadvantage by kicking from farther back. However, it would not kick from the number it bids, but from the average of the two bids.


To illustrate, assume team A bids to kick from the 38-yard line, while team B bids its 32-yard line.  Team B would win the bidding and, therefore, be designated as the kick-off team. But B wouldn’t kick from 32, but instead from the average of 38 and 32–its 35-yard line. 


This is better for B by 3 yards than the 32-yard line that it proposed, because it’s closer to the end zone it is kicking towards. It’s also better for A by 3 yards to have B kick fr</p><p>4 0.65302217 <a title="2262-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-25-Basketball_Stats%3A__Don%E2%80%99t_model_the_probability_of_win%2C_model_the_expected_score_differential..html">2224 andrew gelman stats-2014-02-25-Basketball Stats:  Don’t model the probability of win, model the expected score differential.</a></p>
<p>Introduction: Someone who wants to remain anonymous writes:
  
I am working to create a more accurate in-game win probability model for basketball games. My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.


This problem would seem to fit a multi-level model structure well. It seems silly to estimate 2,000 regressions (one for each timestep), but the coefficients should vary at each timestep. Do you have suggestions for what type of model this could/would be? Additionally, I believe this needs to be some form of logit/probit given the binary dependent variable (win or loss).


Finally, do you have suggestions for what package could accomplish this in Stata or R?
  
To answer the questions in reverse order: 
3.  I’d hope this could be done in Stan (which can be run from R)</p><p>5 0.64338601 <a title="2262-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-12-Probability_of_successive_wins_in_baseball.html">29 andrew gelman stats-2010-05-12-Probability of successive wins in baseball</a></p>
<p>Introduction: Dan Goldstein did an  informal study  asking people the following question:
  
When two baseball teams play each other on two consecutive days, what is the probability that the winner of the first game will be the winner of the second game?
  
You can make your own guess and the continue reading below.
    
Dan writes:
  
We asked two colleagues knowledgeable in baseball and the mathematics of forecasting. The answers came in between 65% and 70%.






The true answer [based on Dan's analysis of a database of baseball games]: 51.3%, a little better than a coin toss.
  
I have to say, I’m surprised his colleagues gave such extreme guesses.  I was guessing something like 50%, myself, based on the following very crude reasoning:
 
Suppose two unequal teams are playing, and the chance of team A beating team B is 55%.  (This seems like a reasonable average of all matchups, which will include some more extreme disparities but also many more equal contests.)  Then the chance of the same team</p><p>6 0.64326847 <a title="2262-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Statistician_cracks_Toronto_lottery.html">562 andrew gelman stats-2011-02-06-Statistician cracks Toronto lottery</a></p>
<p>7 0.6308254 <a title="2262-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-23-The_pinch-hitter_syndrome_again.html">1467 andrew gelman stats-2012-08-23-The pinch-hitter syndrome again</a></p>
<p>8 0.62386912 <a title="2262-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-21-Scrabble%21.html">813 andrew gelman stats-2011-07-21-Scrabble!</a></p>
<p>9 0.62257791 <a title="2262-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-18-What%E2%80%99s_my_Kasparov_number%3F.html">2105 andrew gelman stats-2013-11-18-What’s my Kasparov number?</a></p>
<p>10 0.61407977 <a title="2262-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-18-%E2%80%9CIntrade_to_the_57th_power%E2%80%9D.html">1540 andrew gelman stats-2012-10-18-“Intrade to the 57th power”</a></p>
<p>11 0.61212891 <a title="2262-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-21-Will_Tiger_Woods_catch_Jack_Nicklaus%3F__And_a_discussion_of_the_virtues_of_using_continuous_data_even_if_your_goal_is_discrete_prediction.html">1387 andrew gelman stats-2012-06-21-Will Tiger Woods catch Jack Nicklaus?  And a discussion of the virtues of using continuous data even if your goal is discrete prediction</a></p>
<p>12 0.59872699 <a title="2262-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-20-I_think_you_knew_this_already.html">218 andrew gelman stats-2010-08-20-I think you knew this already</a></p>
<p>13 0.59642327 <a title="2262-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-08-Of_parsing_and_chess.html">1847 andrew gelman stats-2013-05-08-Of parsing and chess</a></p>
<p>14 0.57451338 <a title="2262-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-30-Silly_baseball_example_illustrates_a_couple_of_key_ideas_they_don%E2%80%99t_usually_teach_you_in_statistics_class.html">171 andrew gelman stats-2010-07-30-Silly baseball example illustrates a couple of key ideas they don’t usually teach you in statistics class</a></p>
<p>15 0.55945057 <a title="2262-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-10-Creating_a_good_wager_based_on_probability_estimates.html">138 andrew gelman stats-2010-07-10-Creating a good wager based on probability estimates</a></p>
<p>16 0.55335265 <a title="2262-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-15-Of_forecasts_and_graph_theory_and_characterizing_a_statistical_method_by_the_information_it_uses.html">1214 andrew gelman stats-2012-03-15-Of forecasts and graph theory and characterizing a statistical method by the information it uses</a></p>
<p>17 0.54776353 <a title="2262-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-04-45%25_hitting%2C_25%25_fielding%2C_25%25_pitching%2C_and_100%25_not_telling_us_how_they_did_it.html">942 andrew gelman stats-2011-10-04-45% hitting, 25% fielding, 25% pitching, and 100% not telling us how they did it</a></p>
<p>18 0.54154384 <a title="2262-lsi-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-26-Econometrics%2C_political_science%2C_epidemiology%2C_etc.%3A__Don%E2%80%99t_model_the_probability_of_a_discrete_outcome%2C_model_the_underlying_continuous_variable.html">2226 andrew gelman stats-2014-02-26-Econometrics, political science, epidemiology, etc.:  Don’t model the probability of a discrete outcome, model the underlying continuous variable</a></p>
<p>19 0.53008682 <a title="2262-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-13-And_now%2C_here%E2%80%99s_something_that_would_make_Ed_Tufte_spin_in_his_._._._ummm%2C_Tufte%E2%80%99s_still_around%2C_actually%2C_so_let%E2%80%99s_just_say_I_don%E2%80%99t_think_he%E2%80%99d_like_it%21.html">2132 andrew gelman stats-2013-12-13-And now, here’s something that would make Ed Tufte spin in his . . . ummm, Tufte’s still around, actually, so let’s just say I don’t think he’d like it!</a></p>
<p>20 0.52760398 <a title="2262-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-03-Gladwell_vs_Pinker.html">253 andrew gelman stats-2010-09-03-Gladwell vs Pinker</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.071), (11, 0.026), (16, 0.081), (24, 0.194), (28, 0.015), (30, 0.058), (40, 0.015), (41, 0.097), (49, 0.015), (51, 0.037), (60, 0.029), (66, 0.033), (86, 0.037), (89, 0.013), (99, 0.18)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97394645 <a title="2262-lda-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-23-Win_probabilities_during_a_sporting_event.html">2262 andrew gelman stats-2014-03-23-Win probabilities during a sporting event</a></p>
<p>Introduction: Todd Schneider writes: 
   
 
 Apropos of your recent  blog post about modeling score differential of basketball games , I thought you might enjoy a site I built, gambletron2000.com , that gathers real-time win probabilities from betting markets for most major sports (including NBA and college basketball). 
  
 My original goal was to use the variance of changes in win probabilities to quantify which games were the most exciting, but I got a bit carried away and ended up pursuing a bunch of other ideas, whichÂ  you can read about in the full writeup here  
  
 This particular passage from the anonymous someone in your post: 
  

My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.

  
 reminded me of a graph I made, which shows the mean-reverting tendency of N</p><p>2 0.89313734 <a title="2262-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-16-Mr._Pearson%2C_meet_Mr._Mandelbrot%3A__Detecting_Novel_Associations_in_Large_Data_Sets.html">1062 andrew gelman stats-2011-12-16-Mr. Pearson, meet Mr. Mandelbrot:  Detecting Novel Associations in Large Data Sets</a></p>
<p>Introduction: Jeremy Fox asks what I think about  this paper  by David N. Reshef, Yakir Reshef, Hilary Finucane, Sharon  Grossman, Gilean McVean, Peter Turnbaugh, Eric Lander, Michael Mitzenmacher, and Pardis Sabeti which proposes a new nonlinear R-squared-like measure.
 
My quick answer is that it looks really cool!
 
From my quick reading of the paper, it appears that the method reduces on average to the usual R-squared when fit to data of the form y = a + bx + error, and that it also has a similar interpretation when “a + bx” is replaced by other continuous functions.
 
Unlike R-squared, the method of Reshef et al. depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way.  The dependence on scale is inevitable for such a general method.  Just consider:  if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data.  So the sca</p><p>3 0.89297885 <a title="2262-lda-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-25-Basketball_Stats%3A__Don%E2%80%99t_model_the_probability_of_win%2C_model_the_expected_score_differential..html">2224 andrew gelman stats-2014-02-25-Basketball Stats:  Don’t model the probability of win, model the expected score differential.</a></p>
<p>Introduction: Someone who wants to remain anonymous writes:
  
I am working to create a more accurate in-game win probability model for basketball games. My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.


This problem would seem to fit a multi-level model structure well. It seems silly to estimate 2,000 regressions (one for each timestep), but the coefficients should vary at each timestep. Do you have suggestions for what type of model this could/would be? Additionally, I believe this needs to be some form of logit/probit given the binary dependent variable (win or loss).


Finally, do you have suggestions for what package could accomplish this in Stata or R?
  
To answer the questions in reverse order: 
3.  I’d hope this could be done in Stan (which can be run from R)</p><p>4 0.88741571 <a title="2262-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-03-Bayes_pays%21.html">1923 andrew gelman stats-2013-07-03-Bayes pays!</a></p>
<p>Introduction: Jason Rosenfeld, who has the amazing title of “Manager of Basketball Analytics” at the Charlotte Bobcats, announces the following  jobs :
  
Basketball Operations: Statistics

  Basketball Operations Systems Developer – Charlotte Bobcats (Charlotte, NC)  

   


POSITION OVERVIEW 
The Basketball Operations System Developer will collect and import data to our database, check data, and field requests from the Basketball Operations staff.  This position will be instrumental in molding and improving our database to assist the staff in player personnel and coaching efforts. 
   
ESSENTIAL DUTIES AND RESPONSIBILITIES 
• Respond to data and database requests from the front office. 
• Build user-friendly software tools for use by the basketball operations staff. 
• Accumulate data from various sources to input and organize into our system to assist the basketball operations staff with decisions. 
• Check and clean data for accuracy and import to our database. 
• Provide ideas and play a key ro</p><p>5 0.88540328 <a title="2262-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-28-Simplify_until_your_fake-data_check_works%2C_then_add_complications_until_you_can_figure_out_where_the_problem_is_coming_from.html">1875 andrew gelman stats-2013-05-28-Simplify until your fake-data check works, then add complications until you can figure out where the problem is coming from</a></p>
<p>Introduction: I received the following email: 
  
  
I am trying to develop a Bayesian model to represent the process through which individual consumers make online product rating decisions. In my model each individual faces total J product options and for each product option (j) each individual (i) needs to make three sequential decisions: 


- First he decides whether to consume a specific product option (j) or not (choice decision)


- If he decides to consume a product option j, then after consumption he decides whether to rate it or not (incidence decision) 


- If he decides to rate product j then what finally he decides what rating (k) to assign to it (evaluation decision)


We  model this decision sequence in terms of three equations. A binary response variable in the first equation represents the choice decision. Another binary response variable in the second equation represents the incidence decision that is observable only when first selection decision is 1. Finally, an ordered response v</p><p>6 0.8828038 <a title="2262-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-15-Of_forecasts_and_graph_theory_and_characterizing_a_statistical_method_by_the_information_it_uses.html">1214 andrew gelman stats-2012-03-15-Of forecasts and graph theory and characterizing a statistical method by the information it uses</a></p>
<p>7 0.88181686 <a title="2262-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-19-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1019 andrew gelman stats-2011-11-19-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>8 0.88090986 <a title="2262-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-11-Steve_Jobs%E2%80%99s_cancer_and_science-based_medicine.html">953 andrew gelman stats-2011-10-11-Steve Jobs’s cancer and science-based medicine</a></p>
<p>9 0.8729437 <a title="2262-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-06-Question_27_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1368 andrew gelman stats-2012-06-06-Question 27 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>10 0.87226355 <a title="2262-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<p>11 0.86583573 <a title="2262-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-Hypothesis_testing_with_multiple_imputations.html">799 andrew gelman stats-2011-07-13-Hypothesis testing with multiple imputations</a></p>
<p>12 0.86388552 <a title="2262-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-21-Will_Tiger_Woods_catch_Jack_Nicklaus%3F__And_a_discussion_of_the_virtues_of_using_continuous_data_even_if_your_goal_is_discrete_prediction.html">1387 andrew gelman stats-2012-06-21-Will Tiger Woods catch Jack Nicklaus?  And a discussion of the virtues of using continuous data even if your goal is discrete prediction</a></p>
<p>13 0.86384606 <a title="2262-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-03-Setting_aside_the_politics%2C_the_debate_over_the_new_health-care_study_reveals_that_we%E2%80%99re_moving_to_a_new_high_standard_of_statistical_journalism.html">1838 andrew gelman stats-2013-05-03-Setting aside the politics, the debate over the new health-care study reveals that we’re moving to a new high standard of statistical journalism</a></p>
<p>14 0.86339545 <a title="2262-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-05-Question_26_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1367 andrew gelman stats-2012-06-05-Question 26 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>15 0.86289328 <a title="2262-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-24-Latest_in_blog_advertising.html">1080 andrew gelman stats-2011-12-24-Latest in blog advertising</a></p>
<p>16 0.86278963 <a title="2262-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-19-Tradeoffs_in_information_graphics.html">1584 andrew gelman stats-2012-11-19-Tradeoffs in information graphics</a></p>
<p>17 0.86142457 <a title="2262-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-10-95%25_intervals_that_I_don%E2%80%99t_believe%2C_because_they%E2%80%99re_from_a_flat_prior_I_don%E2%80%99t_believe.html">1206 andrew gelman stats-2012-03-10-95% intervals that I don’t believe, because they’re from a flat prior I don’t believe</a></p>
<p>18 0.86091161 <a title="2262-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-03-Reinventing_the_wheel%2C_only_more_so..html">447 andrew gelman stats-2010-12-03-Reinventing the wheel, only more so.</a></p>
<p>19 0.86072123 <a title="2262-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-10-Using_a_%E2%80%9Cpure_infographic%E2%80%9D_to_explore_differences_between_information_visualization_and_statistical_graphics.html">847 andrew gelman stats-2011-08-10-Using a “pure infographic” to explore differences between information visualization and statistical graphics</a></p>
<p>20 0.86045074 <a title="2262-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-12-Probabilistic_screening_to_get_an_approximate_self-weighted_sample.html">1455 andrew gelman stats-2012-08-12-Probabilistic screening to get an approximate self-weighted sample</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
