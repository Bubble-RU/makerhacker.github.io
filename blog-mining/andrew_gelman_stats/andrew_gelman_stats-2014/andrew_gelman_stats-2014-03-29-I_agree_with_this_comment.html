<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2272 andrew gelman stats-2014-03-29-I agree with this comment</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2014" href="../home/andrew_gelman_stats-2014_home.html">andrew_gelman_stats-2014</a> <a title="andrew_gelman_stats-2014-2272" href="#">andrew_gelman_stats-2014-2272</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2272 andrew gelman stats-2014-03-29-I agree with this comment</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2014-2272-html" href="http://andrewgelman.com/2014/03/29/agree-comment/">html</a></p><p>Introduction: The anonymous commenter  puts it well :
  
The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The anonymous commenter  puts it well :    The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct. [sent-1, score-3.591]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('disproving', 0.422), ('disproof', 0.404), ('proof', 0.291), ('anonymous', 0.286), ('hypotheses', 0.257), ('null', 0.252), ('puts', 0.242), ('commenter', 0.242), ('near', 0.233), ('false', 0.206), ('correct', 0.177), ('taking', 0.161), ('theory', 0.152), ('simple', 0.139), ('researchers', 0.136), ('always', 0.116), ('problem', 0.098), ('well', 0.093)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="2272-tfidf-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>Introduction: The anonymous commenter  puts it well :
  
The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct.</p><p>2 0.39817345 <a title="2272-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>Introduction: A recent  discussion  between commenters Question and Fernando captured one of the recurrent themes here from the past year.
 
 Question:   The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct.
 
 Fernando:   Whereas it is probably true that researchers misuse NHT, the problem with tabloid science is broader and deeper. It is systemic.
 
 Question:   I do not see how anything can be deeper than replacing careful description, prediction, falsification, and independent replication with dynamite plots, p-values, affirming the consequent, and peer review. From my own experience I am confident in saying that confusion caused by NHST is at the root of this problem.
 
 Fernando:   Incentives? Impact factors? Publish or die? “Interesting” and “new” above quality and reliability, or actually answering a research question, and a silly and unbecoming obsession with being quoted in NYT, etc. . . . Giv</p><p>3 0.16442236 <a title="2272-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>Introduction: Erin Jonaitis points us to  this article  by Christopher Ferguson and Moritz Heene, who write:
  
Publication bias remains a controversial issue in psychological science. . . . that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. Given that science is dependent on the process of falsification, we argue that these problems reduce psychological science’s capability to have a proper mechanism for theory falsification, thus resulting in the promulgation of numerous “undead” theories that are ideologically popular but have little basis in fact.
  
They mention the infamous Daryl Bem article.  It is pretty much only because Bem’s claims are (presumably) false that they got published in a major research journal.  Had the claims been true—that is, had Bem run identical experiments, analyzed his data more carefully and objectively, and reported that the r</p><p>4 0.15392223 <a title="2272-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>Introduction: Masanao sends  this one  in, under the heading, “another incident of misunderstood p-value”:
  
Warren Davies, a positive psychology MSc student at UEL, provides the latest in our ongoing series of guest features for students. Warren has just released a Psychology Study Guide, which covers information on statistics, research methods and study skills for psychology students.

 
Despite the myriad rules and procedures of science, some research findings are pure flukes. Perhaps you’re testing a new drug, and by chance alone, a large number of people spontaneously get better. The better your study is conducted, the lower the chance that your result was a fluke – but still, there is always a certain probability that it was.


Statistical significance testing gives you an idea of what this probability is.


In science we’re always testing hypotheses. We never conduct a study to ‘see what happens’, because there’s always at least one way to make any useless set of data look important. We take</p><p>5 0.14354087 <a title="2272-tfidf-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>Introduction: Robert Bloomfield writes:
  
Most of the people in my field (accounting, which is basically applied economics and finance, leavened with psychology and organizational behavior) use ‘positive research methods’, which are typically described as coming to the data with a predefined theory, and using hypothesis testing to accept or reject the theory’s predictions.  But a substantial minority use ‘interpretive research methods’ (sometimes called qualitative methods, for those that call positive research ‘quantitative’).  No one seems entirely happy with the definition of this method, but I’ve found it useful to think of it as an attempt to see the world through the eyes of your subjects, much as Jane Goodall lived with gorillas and tried to see the world through their eyes.)


Interpretive researchers often criticize positive researchers by noting that the latter don’t make the best use of their data, because they come to the data with a predetermined theory, and only test a narrow set of h</p><p>6 0.11267326 <a title="2272-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-26-Statistical_evidence_for_revised_standards.html">2149 andrew gelman stats-2013-12-26-Statistical evidence for revised standards</a></p>
<p>7 0.10782488 <a title="2272-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-14-The_tabloids_strike_again.html">1168 andrew gelman stats-2012-02-14-The tabloids strike again</a></p>
<p>8 0.10678594 <a title="2272-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-28-More_on_Bayesian_deduction-induction.html">114 andrew gelman stats-2010-06-28-More on Bayesian deduction-induction</a></p>
<p>9 0.10172868 <a title="2272-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-16-The_lamest%2C_grudgingest%2C_non-retraction_retraction_ever.html">1626 andrew gelman stats-2012-12-16-The lamest, grudgingest, non-retraction retraction ever</a></p>
<p>10 0.099563435 <a title="2272-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-19-Data_exploration_and_multiple_comparisons.html">524 andrew gelman stats-2011-01-19-Data exploration and multiple comparisons</a></p>
<p>11 0.096815832 <a title="2272-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>12 0.094357654 <a title="2272-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>13 0.091529146 <a title="2272-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-08-The_never-ending_%28and_often_productive%29_race_between_theory_and_practice.html">2127 andrew gelman stats-2013-12-08-The never-ending (and often productive) race between theory and practice</a></p>
<p>14 0.090382755 <a title="2272-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-08-Discussion_with_Steven_Pinker_on_research_that_is_attached_to_data_that_are_so_noisy_as_to_be_essentially_uninformative.html">2326 andrew gelman stats-2014-05-08-Discussion with Steven Pinker on research that is attached to data that are so noisy as to be essentially uninformative</a></p>
<p>15 0.085806355 <a title="2272-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-12-Misunderstanding_the_p-value.html">1760 andrew gelman stats-2013-03-12-Misunderstanding the p-value</a></p>
<p>16 0.085279815 <a title="2272-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>17 0.081796765 <a title="2272-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-30-Silly_baseball_example_illustrates_a_couple_of_key_ideas_they_don%E2%80%99t_usually_teach_you_in_statistics_class.html">171 andrew gelman stats-2010-07-30-Silly baseball example illustrates a couple of key ideas they don’t usually teach you in statistics class</a></p>
<p>18 0.080111094 <a title="2272-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>19 0.078274399 <a title="2272-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-04-Whassup_with_glm%28%29%3F.html">696 andrew gelman stats-2011-05-04-Whassup with glm()?</a></p>
<p>20 0.076651856 <a title="2272-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.063), (1, 0.011), (2, -0.011), (3, -0.062), (4, -0.052), (5, -0.036), (6, -0.003), (7, 0.022), (8, 0.034), (9, -0.062), (10, -0.066), (11, 0.016), (12, -0.005), (13, -0.079), (14, -0.02), (15, 0.004), (16, -0.018), (17, -0.061), (18, -0.014), (19, -0.041), (20, 0.024), (21, -0.013), (22, -0.051), (23, -0.006), (24, -0.08), (25, -0.025), (26, 0.073), (27, 0.036), (28, 0.035), (29, -0.037), (30, 0.02), (31, 0.022), (32, 0.067), (33, 0.012), (34, -0.068), (35, -0.049), (36, 0.06), (37, -0.032), (38, 0.013), (39, -0.033), (40, -0.069), (41, 0.022), (42, 0.031), (43, -0.003), (44, -0.004), (45, 0.018), (46, 0.015), (47, -0.026), (48, 0.054), (49, -0.008)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98929334 <a title="2272-lsi-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>Introduction: The anonymous commenter  puts it well :
  
The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct.</p><p>2 0.76688206 <a title="2272-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>Introduction: A recent  discussion  between commenters Question and Fernando captured one of the recurrent themes here from the past year.
 
 Question:   The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct.
 
 Fernando:   Whereas it is probably true that researchers misuse NHT, the problem with tabloid science is broader and deeper. It is systemic.
 
 Question:   I do not see how anything can be deeper than replacing careful description, prediction, falsification, and independent replication with dynamite plots, p-values, affirming the consequent, and peer review. From my own experience I am confident in saying that confusion caused by NHST is at the root of this problem.
 
 Fernando:   Incentives? Impact factors? Publish or die? “Interesting” and “new” above quality and reliability, or actually answering a research question, and a silly and unbecoming obsession with being quoted in NYT, etc. . . . Giv</p><p>3 0.71657705 <a title="2272-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>Introduction: Xian, Judith, and I read this line in a book by statistician Murray Aitkin in which he considered the following hypothetical example:
  
A survey of 100 individuals expressing support (Yes/No) for the president, before and after a presidential address . . . The question of interest is whether there has been a change in support between the surveys . . . We want to assess the evidence for the hypothesis of equality H1 against the alternative hypothesis H2 of a change.
  
Here is  our response :
  
Based on our experience in public opinion research, this is not a real question. Support for any political position is always changing. The real question is how much the support has changed, or perhaps how this change is distributed across the population.


A defender of Aitkin (and of classical hypothesis testing) might respond at this point that, yes, everybody knows that changes are never exactly zero and that we should take a more “grown-up” view of the null hypothesis, not that the change</p><p>4 0.70694083 <a title="2272-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>Introduction: Masanao sends  this one  in, under the heading, “another incident of misunderstood p-value”:
  
Warren Davies, a positive psychology MSc student at UEL, provides the latest in our ongoing series of guest features for students. Warren has just released a Psychology Study Guide, which covers information on statistics, research methods and study skills for psychology students.

 
Despite the myriad rules and procedures of science, some research findings are pure flukes. Perhaps you’re testing a new drug, and by chance alone, a large number of people spontaneously get better. The better your study is conducted, the lower the chance that your result was a fluke – but still, there is always a certain probability that it was.


Statistical significance testing gives you an idea of what this probability is.


In science we’re always testing hypotheses. We never conduct a study to ‘see what happens’, because there’s always at least one way to make any useless set of data look important. We take</p><p>5 0.69771677 <a title="2272-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>Introduction: Someone writes:
  
Suppose I have two groups of people, A and B, which differ on some characteristic of interest to me;  and for each person I measure a single real-valued quantity X.  I have a theory that group A has a higher mean value of X than group B.  I test this theory by using a t-test.  Am I entitled to use a *one-tailed* t-test?  Or should I use a *two-tailed* one (thereby giving a p-value that is twice as large)?


I know you will probably answer:  Forget the t-test; you should use Bayesian methods instead.


But what is the standard frequentist answer to this question?
  
My reply:
 
The quick answer here is that different people will do different things here.  I would say the 2-tailed p-value is more standard but some people will insist on the one-tailed version, and itâ&euro;&trade;s hard to make a big stand on this one, given all the other problems with p-values in practice:
 
http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf
 
http://www.stat.columbia.edu/~gelm</p><p>6 0.67330259 <a title="2272-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>7 0.66860402 <a title="2272-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>8 0.65790027 <a title="2272-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-26-Statistical_evidence_for_revised_standards.html">2149 andrew gelman stats-2013-12-26-Statistical evidence for revised standards</a></p>
<p>9 0.63543379 <a title="2272-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>10 0.62611759 <a title="2272-lsi-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>11 0.61673242 <a title="2272-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-15-%E2%80%9CAre_all_significant_p-values_created_equal%3F%E2%80%9D.html">2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</a></p>
<p>12 0.60251135 <a title="2272-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>13 0.59203142 <a title="2272-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>14 0.58874887 <a title="2272-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-10-Bayes_jumps_the_shark.html">331 andrew gelman stats-2010-10-10-Bayes jumps the shark</a></p>
<p>15 0.58728045 <a title="2272-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-12-Misunderstanding_the_p-value.html">1760 andrew gelman stats-2013-03-12-Misunderstanding the p-value</a></p>
<p>16 0.57663774 <a title="2272-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-08-Discussion_with_Steven_Pinker_on_research_that_is_attached_to_data_that_are_so_noisy_as_to_be_essentially_uninformative.html">2326 andrew gelman stats-2014-05-08-Discussion with Steven Pinker on research that is attached to data that are so noisy as to be essentially uninformative</a></p>
<p>17 0.55715883 <a title="2272-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>18 0.55605078 <a title="2272-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-05-What_are_the_standards_for_reliability_in_experimental_psychology%3F.html">1101 andrew gelman stats-2012-01-05-What are the standards for reliability in experimental psychology?</a></p>
<p>19 0.54726046 <a title="2272-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-08-The_never-ending_%28and_often_productive%29_race_between_theory_and_practice.html">2127 andrew gelman stats-2013-12-08-The never-ending (and often productive) race between theory and practice</a></p>
<p>20 0.52854055 <a title="2272-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-17-Where_do_theories_come_from%3F.html">1861 andrew gelman stats-2013-05-17-Where do theories come from?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.155), (16, 0.123), (21, 0.215), (76, 0.051), (86, 0.13), (99, 0.134)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93960124 <a title="2272-lda-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>Introduction: The anonymous commenter  puts it well :
  
The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct.</p><p>2 0.73694193 <a title="2272-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-27-Banned_in_NYC_school_tests.html">1232 andrew gelman stats-2012-03-27-Banned in NYC school tests</a></p>
<p>Introduction: The list  includes “hunting” but not “fishing,” so that’s cool.  I wonder how they’d feel about a question involving different cuts of meat.  In any case, I’m happy to see that  “Bayes”  is not on the banned list.
 
P.S.  Russell  explains .</p><p>3 0.73224878 <a title="2272-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-16-Wanted%3A__Probability_distributions_for_rank_orderings.html">151 andrew gelman stats-2010-07-16-Wanted:  Probability distributions for rank orderings</a></p>
<p>Introduction: Dietrich Stoyan writes:
  
 
I asked the IMS people for an expert in statistics of voting/elections and they wrote me your name. I am a statistician, but never worked in the field voting/elections. It was my son-in-law who asked me for statistical theories in that field.


He posed in particular the following problem:


The aim of the voting is to come to a ranking of c candidates. Every vote is a permutation of these c candidates. The problem is to have probability distributions in the set of all permutations of c elements.


Are there theories for such distributions?


I should be very grateful for a fast answer with hints to literature. (I confess that I do not know your books.) 
 

 
My reply:  Rather than trying to model the ranks directly, Iâ&euro;&trade;d recommend modeling a latent continuous outcome which then implies a distribution on ranks, if the ranks are of interest. There are lots of distributions of c-dimensional continuous outcomes.  In political science, the usual way to start is</p><p>4 0.71963507 <a title="2272-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-The_R_code_for_those_time-use_graphs.html">672 andrew gelman stats-2011-04-20-The R code for those time-use graphs</a></p>
<p>Introduction: By popular demand, hereâ&euro;&trade;s my R script for the  time-use graphs :
  

 
 
# The data
a1 <- c(4.2,3.2,11.1,1.3,2.2,2.0)
a2 <- c(3.9,3.2,10.0,0.8,3.1,3.1)
a3 <- c(6.3,2.5,9.8,0.9,2.2,2.4)
a4 <- c(4.4,3.1,9.8,0.8,3.3,2.7)
a5 <- c(4.8,3.0,9.9,0.7,3.3,2.4)
a6 <- c(4.0,3.4,10.5,0.7,3.3,2.1)
a <- rbind(a1,a2,a3,a4,a5,a6)
avg <- colMeans (a)
avg.array <- t (array (avg, rev(dim(a))))
diff <- a - avg.array
country.name <- c("France", "Germany", "Japan", "Britain", "USA", "Turkey")

# The line plots

par (mfrow=c(2,3), mar=c(4,4,2,.5), mgp=c(2,.7,0), tck=-.02, oma=c(3,0,4,0),
  bg="gray96", fg="gray30")
for (i in 1:6){
  plot (c(1,6), c(-1,1.7), xlab="", ylab="", xaxt="n", yaxt="n",
    bty="l", type="n")
  lines (1:6, diff[i,], col="blue")
  points (1:6, diff[i,], pch=19, col="black")
  if (i>3){
    axis (1, c(1,3,5), c ("Work,\nstudy", "Eat,\nsleep",
      "Leisure"), mgp=c(2,1.5,0), tck=0, cex.axis=1.2)
    axis (1, c(2,4,6), c ("Unpaid\nwork",
      "Personal\nCare", "Other"), mgp=c(2,1.5,0),</p><p>5 0.68027616 <a title="2272-lda-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-21-The_world%E2%80%99s_most_popular_languages_that_the_Mac_documentation_hasn%E2%80%99t_been_translated_into.html">2219 andrew gelman stats-2014-02-21-The world’s most popular languages that the Mac documentation hasn’t been translated into</a></p>
<p>Introduction: I was updating my Mac and noticed the following:
 
 
 
Lots of obscure European languages there.  That got me wondering:  what’s the least obscure language  not  on the above list?  Igbo?  Swahili?  Or maybe Tagalog?
 
I did a quick google and found  this  list of languages by number of native speakers.  Once you see the list, the answer is obvious:  Hindi, first language of 295 million people, is not on Apple’s list.  The next most popular languages not included:  Bengali, Punjabi, Javanese, Wu, Telegu, Marathi, Tamil, Urdu.  Wow:  most of these are Indian!  Then comes Persian and a bunch of others.
 
It turns out that Tagalog, Igbo, and Swahili, are way down on this list with 28 million, 24 million, and 26 million native speakers, respectively.
 
Only 26 million for Swahili?  This made me want to check the  list of languages by total number of speakers .  The ranking of most of the languages isn’t much different, but Swahili is now #10, at 140 million.  Hindi and Bengali are still th</p><p>6 0.67350852 <a title="2272-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-15-Does_quantum_uncertainty_have_a_place_in_everyday_applied_statistics%3F.html">1857 andrew gelman stats-2013-05-15-Does quantum uncertainty have a place in everyday applied statistics?</a></p>
<p>7 0.67160559 <a title="2272-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-07-Hipmunk_FAIL%3A__Graphics_without_content_is_not_enough.html">894 andrew gelman stats-2011-09-07-Hipmunk FAIL:  Graphics without content is not enough</a></p>
<p>8 0.66668749 <a title="2272-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-22-Please_stop_me_before_I_barf_again.html">1275 andrew gelman stats-2012-04-22-Please stop me before I barf again</a></p>
<p>9 0.66538811 <a title="2272-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-21-%E2%80%9CCity_Opens_Inquiry_on_Grading_Practices_at_a_Top-Scoring_Bronx_School%E2%80%9D.html">529 andrew gelman stats-2011-01-21-“City Opens Inquiry on Grading Practices at a Top-Scoring Bronx School”</a></p>
<p>10 0.66446882 <a title="2272-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-01-Two_Postdoc_Positions_Available_on_Bayesian_Hierarchical_Modeling.html">62 andrew gelman stats-2010-06-01-Two Postdoc Positions Available on Bayesian Hierarchical Modeling</a></p>
<p>11 0.66202682 <a title="2272-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-12-Probability_of_successive_wins_in_baseball.html">29 andrew gelman stats-2010-05-12-Probability of successive wins in baseball</a></p>
<p>12 0.66150343 <a title="2272-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-30-Systematic_review_of_publication_bias_in_studies_on_publication_bias.html">1291 andrew gelman stats-2012-04-30-Systematic review of publication bias in studies on publication bias</a></p>
<p>13 0.6571058 <a title="2272-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>14 0.65190911 <a title="2272-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-16-Annals_of_really_really_stupid_spam.html">577 andrew gelman stats-2011-02-16-Annals of really really stupid spam</a></p>
<p>15 0.65041006 <a title="2272-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-20-I_think_you_knew_this_already.html">218 andrew gelman stats-2010-08-20-I think you knew this already</a></p>
<p>16 0.64360839 <a title="2272-lda-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-26-Sleazy_sock_puppet_can%E2%80%99t_stop_spamming_our_discussion_of_compressed_sensing_and_promoting_the_work_of_Xiteng_Liu.html">2306 andrew gelman stats-2014-04-26-Sleazy sock puppet can’t stop spamming our discussion of compressed sensing and promoting the work of Xiteng Liu</a></p>
<p>17 0.64143342 <a title="2272-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-21-On_deck_this_week.html">2298 andrew gelman stats-2014-04-21-On deck this week</a></p>
<p>18 0.63848394 <a title="2272-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-29-Postdocs_in_probabilistic_modeling%21__With_David_Blei%21__And_Stan%21.html">1961 andrew gelman stats-2013-07-29-Postdocs in probabilistic modeling!  With David Blei!  And Stan!</a></p>
<p>19 0.63667548 <a title="2272-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-27-Neumann_update.html">432 andrew gelman stats-2010-11-27-Neumann update</a></p>
<p>20 0.63256049 <a title="2272-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-09-Today_in_the_sister_blog.html">1049 andrew gelman stats-2011-12-09-Today in the sister blog</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
