<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2014" href="../home/andrew_gelman_stats-2014_home.html">andrew_gelman_stats-2014</a> <a title="andrew_gelman_stats-2014-2277" href="#">andrew_gelman_stats-2014-2277</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2014-2277-html" href="http://andrewgelman.com/2014/03/31/cited-statistics-papers-ever/">html</a></p><p>Introduction: Robert Grant has a  list .  I’ll just give the ones with more than 10,000 Google Scholar cites:
  

Cox (1972) Regression and life tables: 35,512 citations. 


Dempster, Laird, Rubin (1977) Maximum likelihood from incomplete data via the EM algorithm: 34,988


Bland & Altman (1986) Statistical methods for assessing agreement between two methods of clinical measurement: 27,181


Geman & Geman (1984) Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images: 15,106
  
We can find some more via searching Google scholar for familiar names and topics; thus:
  

Metropolis et al. (1953) Equation of state calculations by fast computing machines: 26,000


Benjamini and Hochberg (1995) Controlling the false discovery rate: a practical and powerful approach to multiple testing: 21,000


White (1980) A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity: 18,000


Heckman (1977) Sample selection bias as a specification error:</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 But I’m guessing there are some biggies I’m missing. [sent-5, score-0.084]
</p><p>2 I say this because Grant’s original list included one paper, by Bland and Altman, with over 27,000 cites, that I’d never heard of! [sent-6, score-0.133]
</p><p>3 I agree with Grant that using Google Scholar favors newer papers. [sent-9, score-0.068]
</p><p>4 For example, Cooley and Tukey (1965), “An algorithm for the machine calculation of complex Fourier series,” does  not  make the list, amazingly enough, with only 9300 cites. [sent-10, score-0.167]
</p><p>5 And the hugely influential book by Snedecor and Cochran has very few cites, I guess cos nobody cites it anymore. [sent-11, score-0.419]
</p><p>6 And, of course, the most influential researchers such as Laplace, Gauss, Fisher, Neyman, Pearson, etc. [sent-12, score-0.104]
</p><p>7 If Pearson got a cite for every chi-squared test, Neyman for every rejection region, Fisher for every maximum-likelihood estimate, etc. [sent-14, score-0.234]
</p><p>8 , their citations would run into the mid to high zillions each. [sent-15, score-0.197]
</p><p>9 I wrote this post a few months ago so all the citations have gone up. [sent-19, score-0.113]
</p><p>10 For example, the fuzzy sets paper is now listed at 49,000, and Zadeh has a second paper, “Outline of a new approach to the analysis of complex systems and decision processes,” with 16,000 cites. [sent-20, score-0.385]
</p><p>11 On the upside, Efron’s 1979 paper, “Bootstrap methods: another look at the jackknife,” has just pulled itself over the 10,000 cites mark. [sent-22, score-0.315]
</p><p>12 Also, I just checked and Tibshirani’s paper on lasso is at 9873, so in the not too distant future it will make the list too. [sent-24, score-0.221]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cites', 0.315), ('altman', 0.186), ('breiman', 0.186), ('zadeh', 0.186), ('heteroskedasticity', 0.159), ('geman', 0.159), ('scholar', 0.159), ('grant', 0.159), ('bland', 0.152), ('fuzzy', 0.136), ('list', 0.133), ('pearson', 0.123), ('specification', 0.121), ('neyman', 0.119), ('google', 0.114), ('citations', 0.113), ('covariance', 0.112), ('influential', 0.104), ('fisher', 0.104), ('matrix', 0.1), ('methods', 0.098), ('maximum', 0.096), ('rubin', 0.089), ('algorithm', 0.089), ('paper', 0.088), ('laird', 0.084), ('jackknife', 0.084), ('mid', 0.084), ('mediator', 0.084), ('biggies', 0.084), ('forests', 0.084), ('hausman', 0.084), ('sets', 0.083), ('granger', 0.08), ('gauss', 0.08), ('restoration', 0.08), ('every', 0.078), ('complex', 0.078), ('rosenbaum', 0.076), ('autoregressive', 0.076), ('relaxation', 0.076), ('moderator', 0.076), ('via', 0.074), ('likelihood', 0.074), ('dempster', 0.074), ('snedecor', 0.074), ('fourier', 0.074), ('series', 0.071), ('cochran', 0.07), ('newer', 0.068)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="2277-tfidf-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-The_most-cited_statistics_papers_ever.html">2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</a></p>
<p>Introduction: Robert Grant has a  list .  I’ll just give the ones with more than 10,000 Google Scholar cites:
  

Cox (1972) Regression and life tables: 35,512 citations. 


Dempster, Laird, Rubin (1977) Maximum likelihood from incomplete data via the EM algorithm: 34,988


Bland & Altman (1986) Statistical methods for assessing agreement between two methods of clinical measurement: 27,181


Geman & Geman (1984) Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images: 15,106
  
We can find some more via searching Google scholar for familiar names and topics; thus:
  

Metropolis et al. (1953) Equation of state calculations by fast computing machines: 26,000


Benjamini and Hochberg (1995) Controlling the false discovery rate: a practical and powerful approach to multiple testing: 21,000


White (1980) A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity: 18,000


Heckman (1977) Sample selection bias as a specification error:</p><p>2 0.18123402 <a title="2277-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-25-Classics_of_statistics.html">109 andrew gelman stats-2010-06-25-Classics of statistics</a></p>
<p>Introduction: Christian Robert is  planning  a graduate seminar in which students read 15 classic articles of statistics.  (See  here  for more details and a slightly different list.)
 
Actually, he just writes “classics,” but based on his list, I assume he only wants articles, not books.  If he wanted to include classic books, I’d nominate the following, just for starters: 
- Fisher’s Statistical Methods for Research Workers 
- Snedecor and Cochran’s Statistical Methods 
- Kish’s Survey Sampling 
- Box, Hunter, and Hunter’s Statistics for Experimenters 
- Tukey’s Exploratory Data Analysis 
- Cleveland’s The Elements of Graphing Data 
- Mosteller and Wallace’s book on the Federalist Papers. 
Probably Cox and Hinkley, too.  That’s a book that I don’t think has aged well, but it seems to have had a big influence.
 
I think there’s a lot more good and accessible material in these classic books than in the equivalent volume of classic articles.  Journal articles can be difficult to read and are typicall</p><p>3 0.13582365 <a title="2277-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-02-Flame_bait.html">1880 andrew gelman stats-2013-06-02-Flame bait</a></p>
<p>Introduction: Mark Palko asks what I think of  this article  by Francisco Louca, who writes about “‘hybridization’, a synthesis between Fisherian and Neyman-Pearsonian precepts, defined as a number of practical proceedings for statistical testing and inference that were developed notwithstanding the original authors, as an eventual convergence between what they considered to be radically irreconcilable.”
 
To me, the statistical ideas in this paper are too old-fashioned.  The issue is not that the Neyman-Pearson and Fisher approaches are “irreconcilable” but rather that neither does the job in the sort of hard problems that face statistical science today.  I’m thinking of technically difficult models such as hierarchical Gaussian processes and also challenges that arise with small sample size and multiple testing. Neyman, Pearson, and Fisher all were brilliant, and they all developed statistical methods that remain useful today, but I think their foundations are out of date.  Yes, we currently use m</p><p>4 0.12932058 <a title="2277-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>Introduction: As a data analyst and a scientist, Fisher > Neyman, no question.  But as a theorist, Fisher came up with ideas that worked just fine in his applications but can fall apart when people try to apply them too generally.
 
Here’s an example that recently came up.
 
Deborah Mayo pointed me to a  comment  by Stephen Senn on the so-called Fisher and Neyman null hypotheses.  In an experiment with n participants (or, as we used to say, subjects or experimental units), the Fisher null hypothesis is that the treatment effect is exactly 0 for every one of the n units, while the Neyman null hypothesis is that the individual treatment effects can be negative or positive but have an average of zero.
 
Senn explains why Neyman’s hypothesis in general makes no sense—the short story is that Fisher’s hypothesis seems relevant in some problems (sometimes we really are studying effects that are zero or close enough for all practical purposes), whereas Neyman’s hypothesis just seems weird (it’s implausible</p><p>5 0.12436163 <a title="2277-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-08-I_Am_Too_Absolutely_Heteroskedastic_for_This_Probit_Model.html">1047 andrew gelman stats-2011-12-08-I Am Too Absolutely Heteroskedastic for This Probit Model</a></p>
<p>Introduction: Soren Lorensen wrote:
  
I’m working on a project that uses a binary choice model on panel data. Since I have panel data and am using MLE, I’m concerned about heteroskedasticity making my estimates inconsistent and biased. 


Are you familiar with any statistical packages with pre-built tests for heteroskedasticity in binary choice ML models? If not, is there value in cutting my data into groups over which I guess the error variance might vary and eyeballing residual plots? Have you other suggestions about how I might resolve this concern?
  
I replied that I wouldn’t worry so much about heteroskedasticity.  Breaking up the data into pieces might make sense, but for the purpose of estimating how the coefficients might vary—that is, nonlinearity and interactions.
 
Soren shot back:
  
I’m somewhat puzzled however: homoskedasticity is an identifying assumption in estimating a probit model: if we don’t have it all sorts of bad things can happen to our parameter estimates. Do you suggest n</p><p>6 0.12291903 <a title="2277-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-The_first_version_of_my_%E2%80%9Cinference_from_iterative_simulation_using_parallel_sequences%E2%80%9D_paper%21.html">1309 andrew gelman stats-2012-05-09-The first version of my “inference from iterative simulation using parallel sequences” paper!</a></p>
<p>7 0.1145271 <a title="2277-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-18-Tibshirani_announces_new_research_result%3A__A_significance_test_for_the_lasso.html">1769 andrew gelman stats-2013-03-18-Tibshirani announces new research result:  A significance test for the lasso</a></p>
<p>8 0.10460306 <a title="2277-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-20-The_pervasive_twoishness_of_statistics%3B_in_particular%2C_the_%E2%80%9Csampling_distribution%E2%80%9D_and_the_%E2%80%9Clikelihood%E2%80%9D_are_two_different_models%2C_and_that%E2%80%99s_a_good_thing.html">774 andrew gelman stats-2011-06-20-The pervasive twoishness of statistics; in particular, the “sampling distribution” and the “likelihood” are two different models, and that’s a good thing</a></p>
<p>9 0.10262702 <a title="2277-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-30-The_Roy_causal_model%3F.html">1962 andrew gelman stats-2013-07-30-The Roy causal model?</a></p>
<p>10 0.099896237 <a title="2277-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Visualizing_Distributions_of_Covariance_Matrices.html">1477 andrew gelman stats-2012-08-30-Visualizing Distributions of Covariance Matrices</a></p>
<p>11 0.099137001 <a title="2277-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-03-Statistical_methods_that_work_in_some_settings_but_not_others.html">1560 andrew gelman stats-2012-11-03-Statistical methods that work in some settings but not others</a></p>
<p>12 0.096469872 <a title="2277-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>13 0.09590359 <a title="2277-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-22-Top_5_stat_papers_since_2000%3F.html">1951 andrew gelman stats-2013-07-22-Top 5 stat papers since 2000?</a></p>
<p>14 0.094968624 <a title="2277-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-30-Works_well_versus_well_understood.html">738 andrew gelman stats-2011-05-30-Works well versus well understood</a></p>
<p>15 0.092171527 <a title="2277-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-01-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Cox_and_Mayo.html">1149 andrew gelman stats-2012-02-01-Philosophy of Bayesian statistics:  my reactions to Cox and Mayo</a></p>
<p>16 0.090048075 <a title="2277-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>17 0.086087346 <a title="2277-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>18 0.084993131 <a title="2277-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-13-Judea_Pearl_overview_on_causal_inference%2C_and_more_general_thoughts_on_the_reexpression_of_existing_methods_by_considering_their_implicit_assumptions.html">2170 andrew gelman stats-2014-01-13-Judea Pearl overview on causal inference, and more general thoughts on the reexpression of existing methods by considering their implicit assumptions</a></p>
<p>19 0.083542183 <a title="2277-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-23-When_are_complicated_models_helpful_in_psychology_research_and_when_are_they_overkill%3F.html">1690 andrew gelman stats-2013-01-23-When are complicated models helpful in psychology research and when are they overkill?</a></p>
<p>20 0.083468191 <a title="2277-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.163), (1, 0.073), (2, -0.027), (3, -0.038), (4, 0.01), (5, 0.013), (6, -0.048), (7, -0.047), (8, 0.018), (9, -0.005), (10, -0.008), (11, 0.005), (12, 0.001), (13, -0.021), (14, 0.04), (15, 0.004), (16, -0.007), (17, -0.008), (18, -0.024), (19, -0.043), (20, 0.014), (21, -0.007), (22, 0.076), (23, 0.028), (24, 0.039), (25, 0.028), (26, -0.033), (27, 0.044), (28, 0.057), (29, 0.032), (30, 0.012), (31, 0.019), (32, 0.041), (33, 0.028), (34, 0.016), (35, -0.028), (36, -0.024), (37, -0.008), (38, -0.008), (39, 0.023), (40, -0.07), (41, 0.047), (42, 0.035), (43, 0.015), (44, -0.008), (45, 0.035), (46, -0.022), (47, -0.047), (48, 0.024), (49, -0.079)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96543002 <a title="2277-lsi-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-The_most-cited_statistics_papers_ever.html">2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</a></p>
<p>Introduction: Robert Grant has a  list .  I’ll just give the ones with more than 10,000 Google Scholar cites:
  

Cox (1972) Regression and life tables: 35,512 citations. 


Dempster, Laird, Rubin (1977) Maximum likelihood from incomplete data via the EM algorithm: 34,988


Bland & Altman (1986) Statistical methods for assessing agreement between two methods of clinical measurement: 27,181


Geman & Geman (1984) Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images: 15,106
  
We can find some more via searching Google scholar for familiar names and topics; thus:
  

Metropolis et al. (1953) Equation of state calculations by fast computing machines: 26,000


Benjamini and Hochberg (1995) Controlling the false discovery rate: a practical and powerful approach to multiple testing: 21,000


White (1980) A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity: 18,000


Heckman (1977) Sample selection bias as a specification error:</p><p>2 0.77952152 <a title="2277-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-02-Flame_bait.html">1880 andrew gelman stats-2013-06-02-Flame bait</a></p>
<p>Introduction: Mark Palko asks what I think of  this article  by Francisco Louca, who writes about “‘hybridization’, a synthesis between Fisherian and Neyman-Pearsonian precepts, defined as a number of practical proceedings for statistical testing and inference that were developed notwithstanding the original authors, as an eventual convergence between what they considered to be radically irreconcilable.”
 
To me, the statistical ideas in this paper are too old-fashioned.  The issue is not that the Neyman-Pearson and Fisher approaches are “irreconcilable” but rather that neither does the job in the sort of hard problems that face statistical science today.  I’m thinking of technically difficult models such as hierarchical Gaussian processes and also challenges that arise with small sample size and multiple testing. Neyman, Pearson, and Fisher all were brilliant, and they all developed statistical methods that remain useful today, but I think their foundations are out of date.  Yes, we currently use m</p><p>3 0.72068709 <a title="2277-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-The_first_version_of_my_%E2%80%9Cinference_from_iterative_simulation_using_parallel_sequences%E2%80%9D_paper%21.html">1309 andrew gelman stats-2012-05-09-The first version of my “inference from iterative simulation using parallel sequences” paper!</a></p>
<p>Introduction: From August 1990.  It was in the form of a note sent to all the people in the statistics group of Bell Labs, where I’d worked that summer.
  
To all:


Here’s the abstract of the work I’ve done this summer.  It’s stored in the file, 
/fs5/gelman/abstract.bell, and copies of the Figures 1-3 are on Trevor’s desk. 
Any comments are of course appreciated; I’m at gelman@stat.berkeley.edu.


On the Routine Use of Markov Chains for Simulation


Andrew Gelman and Donald Rubin, 6 August 1990


corrected version:  8 August 1990
  
  
  
1.  Simulation


In probability and statistics we can often specify multivariate distributions 
many of whose properties we do not fully understand–perhaps, as in the 
Ising model of statistical physics, we can write the joint density function, up 
to a multiplicative constant that cannot be expressed in closed form. 
For an example in statistics, consider the Normal random 
effects model in the analysis of variance, which can be 
easily placed in a Bayesian fram</p><p>4 0.68440181 <a title="2277-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<p>Introduction: Burak Bayramli writes:
  
In  this paper  by Sunjin Ahn, Anoop Korattikara, and Max Welling and  this paper  by Welling and Yee Whye The, there are some arguments on big data and the use of MCMC. Both papers have suggested improvements to speed up MCMC computations. I was wondering what your thoughts were, especially on this paragraph:

 
When a dataset has a billion data-cases (as is not uncommon these days) MCMC algorithms will not even have generated a single (burn-in) sample when a clever learning algorithm based on stochastic gradients may already be making fairly good predictions. In fact, the intriguing results of Bottou and Bousquet (2008) seem to indicate that in terms of “number of bits learned per unit of computation”, an algorithm as simple as stochastic gradient descent is almost optimally efficient. We therefore argue that for Bayesian methods to remain useful in an age when the datasets grow at an exponential rate, they need to embrace the ideas of the stochastic optimiz</p><p>5 0.66911274 <a title="2277-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>Introduction: In response to our  recent posting  of Amazon’s offer of Bayesian Data Analysis 3rd edition at 40% off, some people asked what was in this new edition, with more information beyond the beautiful cover image and the  brief paragraph  I’d posted earlier.
 
 Here’s  the table of contents.  The following sections have all-new material:
 
1.4 New introduction of BDA principles using a simple spell checking example 
2.9 Weakly informative prior distributions 
5.7 Weakly informative priors for hierarchical variance parameters 
7.1-7.4 Predictive accuracy for model evaluation and comparison 
10.6 Computing environments 
11.4 Split R-hat 
11.5 New measure of effective number of simulation draws 
13.7 Variational inference 
13.8 Expectation propagation 
13.9 Other approximations 
14.6 Regularization for regression models 
C.1 Getting started with R and Stan 
C.2 Fitting a hierarchical model in Stan 
C.4 Programming Hamiltonian Monte Carlo in R
 
And the new chapters: 
20 Basis function models 
2</p><p>6 0.66799694 <a title="2277-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<p>7 0.66771221 <a title="2277-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Visualizing_Distributions_of_Covariance_Matrices.html">1477 andrew gelman stats-2012-08-30-Visualizing Distributions of Covariance Matrices</a></p>
<p>8 0.64866263 <a title="2277-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-21-Handbook_of_Markov_Chain_Monte_Carlo.html">674 andrew gelman stats-2011-04-21-Handbook of Markov Chain Monte Carlo</a></p>
<p>9 0.64432567 <a title="2277-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-23-Learning_Differential_Geometry_for_Hamiltonian_Monte_Carlo.html">1339 andrew gelman stats-2012-05-23-Learning Differential Geometry for Hamiltonian Monte Carlo</a></p>
<p>10 0.64129573 <a title="2277-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-01-Martin_and_Liu%3A__Probabilistic_inference_based_on_consistency_of_model_with_data.html">1095 andrew gelman stats-2012-01-01-Martin and Liu:  Probabilistic inference based on consistency of model with data</a></p>
<p>11 0.63967508 <a title="2277-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-03-Statistical_methods_for_healthcare_regulation%3A_rating%2C_screening_and_surveillance.html">744 andrew gelman stats-2011-06-03-Statistical methods for healthcare regulation: rating, screening and surveillance</a></p>
<p>12 0.63519317 <a title="2277-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>13 0.63515854 <a title="2277-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-A_new_R_package_for_fititng_multilevel_models.html">501 andrew gelman stats-2011-01-04-A new R package for fititng multilevel models</a></p>
<p>14 0.63268232 <a title="2277-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-04-Handy_Matrix_Cheat_Sheet%2C_with_Gradients.html">555 andrew gelman stats-2011-02-04-Handy Matrix Cheat Sheet, with Gradients</a></p>
<p>15 0.62947708 <a title="2277-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-14-Causal_inference_in_economics.html">32 andrew gelman stats-2010-05-14-Causal inference in economics</a></p>
<p>16 0.62753248 <a title="2277-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-13-Judea_Pearl_overview_on_causal_inference%2C_and_more_general_thoughts_on_the_reexpression_of_existing_methods_by_considering_their_implicit_assumptions.html">2170 andrew gelman stats-2014-01-13-Judea Pearl overview on causal inference, and more general thoughts on the reexpression of existing methods by considering their implicit assumptions</a></p>
<p>17 0.62206423 <a title="2277-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-21-Random_matrices_in_the_news.html">2258 andrew gelman stats-2014-03-21-Random matrices in the news</a></p>
<p>18 0.61643434 <a title="2277-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-19-Demystifying_Blup.html">1270 andrew gelman stats-2012-04-19-Demystifying Blup</a></p>
<p>19 0.61611199 <a title="2277-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-29-The_gradual_transition_to_replicable_science.html">2117 andrew gelman stats-2013-11-29-The gradual transition to replicable science</a></p>
<p>20 0.61108214 <a title="2277-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-28-What_Zombies_see_in_Scatterplots.html">595 andrew gelman stats-2011-02-28-What Zombies see in Scatterplots</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.117), (16, 0.064), (24, 0.116), (27, 0.057), (30, 0.053), (31, 0.032), (35, 0.015), (43, 0.018), (53, 0.02), (55, 0.038), (57, 0.023), (68, 0.027), (69, 0.019), (72, 0.016), (75, 0.017), (83, 0.012), (86, 0.07), (99, 0.18)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94524819 <a title="2277-lda-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-The_most-cited_statistics_papers_ever.html">2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</a></p>
<p>Introduction: Robert Grant has a  list .  I’ll just give the ones with more than 10,000 Google Scholar cites:
  

Cox (1972) Regression and life tables: 35,512 citations. 


Dempster, Laird, Rubin (1977) Maximum likelihood from incomplete data via the EM algorithm: 34,988


Bland & Altman (1986) Statistical methods for assessing agreement between two methods of clinical measurement: 27,181


Geman & Geman (1984) Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images: 15,106
  
We can find some more via searching Google scholar for familiar names and topics; thus:
  

Metropolis et al. (1953) Equation of state calculations by fast computing machines: 26,000


Benjamini and Hochberg (1995) Controlling the false discovery rate: a practical and powerful approach to multiple testing: 21,000


White (1980) A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity: 18,000


Heckman (1977) Sample selection bias as a specification error:</p><p>2 0.87758338 <a title="2277-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-06-W%E2%80%99man_%3C_W%E2%80%99pedia%2C_again.html">945 andrew gelman stats-2011-10-06-W’man < W’pedia, again</a></p>
<p>Introduction: Blogger Deep Climate  looks at  another paper by the 2002 recipient of the American Statistical Association’s Founders award. This time it’s not funny, it’s just sad. 
   
Here’s Wikipedia on simulated annealing:
  
By analogy with this physical process, each step of the SA algorithm replaces the current solution by a random “nearby” solution, chosen with a probability that depends on the difference between the corresponding function values and on a global parameter T (called the temperature), that is gradually decreased during the process. The dependency is such that the current solution changes almost randomly when T is large, but increasingly “downhill” as T goes to zero. The allowance for “uphill” moves saves the method from becoming stuck at local minima—which are the bane of greedier methods.
  
And here’s Wegman:
  
During each step of the algorithm, the variable that will eventually represent the minimum is replaced by a random solution that is chosen according to a temperature</p><p>3 0.87729281 <a title="2277-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-08-Gratuitous_use_of_%E2%80%9CBayesian_Statistics%2C%E2%80%9D_a_branding_issue%3F.html">133 andrew gelman stats-2010-07-08-Gratuitous use of “Bayesian Statistics,” a branding issue?</a></p>
<p>Introduction: I’m on an island in Maine for a few weeks (big shout out for North Haven!)  This morning I picked up a copy of “Working Waterfront,” a newspaper that focuses on issues of coastal fishing communities.  I came across  an article  about modeling “fish” populations — actually lobsters, I guess they’re considered “fish” for regulatory purposes.  When I read it, I thought “wow, this article is really well-written, not dumbed down like articles in most newspapers.” I think it’s great that a small coastal newspaper carries reporting like this. (The online version has a few things that I don’t recall in the print version, too, so it’s even better).  But in addition to being struck by finding such a good article in a small newspaper, I was struck by this:
  
According to [University of Maine scientist Yong] Chen, there are four main areas where his model improved on the prior version. “We included the inshore trawl data from Maine and other state surveys, in addition to federal survey data; we h</p><p>4 0.87250614 <a title="2277-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-24-Statistical_ethics_violation.html">1081 andrew gelman stats-2011-12-24-Statistical ethics violation</a></p>
<p>Introduction: A colleague writes:
  
When I was in NYC I went to this party by group of Japanese bio-scientists. There, one guy told me about how the biggest pharmaceutical company in Japan did their statistics. They ran 100 different tests and reported the most significant one. (This was in 2006 and he said they stopped doing this few years back so they were doing this until pretty recently…) I’m not sure if this was 100 multiple comparison or 100 different kinds of test but I’m sure they wouldn’t want to disclose their data…
  
Ouch!</p><p>5 0.86873531 <a title="2277-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-19-Statistical_discrimination_again.html">1541 andrew gelman stats-2012-10-19-Statistical discrimination again</a></p>
<p>Introduction: Mark Johnstone writes:
  
I’ve recently been investigating a new European Court of Justice ruling on insurance calculations (on behalf of MoneySuperMarket) and I found something related to statistics that caught my attention. . . . The ruling (which comes into effect in December 2012) states that insurers in Europe can no longer provide different premiums based on gender.  Despite the fact that women are statistically safer drivers, unless it’s biologically proven there is a causal relationship between being female and being a safer driver, this is now seen as an act of discrimination (more on this from the Wall Street Journal).


However, where do you stop with this?  What about age?  What about other factors?  And what does this mean for the application of statistics in general?  Is it inherently unjust in this context?


One proposal has been to fit ‘black boxes’ into cars so more individual data can be collected, as opposed to relying heavily on aggregates.


For fans of data and s</p><p>6 0.86507833 <a title="2277-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-12-Too_tired_to_mock.html">1800 andrew gelman stats-2013-04-12-Too tired to mock</a></p>
<p>7 0.86167127 <a title="2277-lda-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-%E2%80%9CThe_British_amateur_who_debunked_the_mathematics_of_happiness%E2%80%9D.html">2177 andrew gelman stats-2014-01-19-“The British amateur who debunked the mathematics of happiness”</a></p>
<p>8 0.86165667 <a title="2277-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-More_on_those_dudes_who_will_pay_your_professor_%248000_to_assign_a_book_to_your_class%2C_and_related_stories_about_small-time_sleazoids.html">329 andrew gelman stats-2010-10-08-More on those dudes who will pay your professor $8000 to assign a book to your class, and related stories about small-time sleazoids</a></p>
<p>9 0.85786963 <a title="2277-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-With_a_bit_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_again_on_this_topic%2C_and_with_a_lot_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_today.html">576 andrew gelman stats-2011-02-15-With a bit of precognition, you’d have known I was going to post again on this topic, and with a lot of precognition, you’d have known I was going to post today</a></p>
<p>10 0.85552621 <a title="2277-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>11 0.8540951 <a title="2277-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-21-Interpreting_interactions_in_discrete-data_regression.html">1908 andrew gelman stats-2013-06-21-Interpreting interactions in discrete-data regression</a></p>
<p>12 0.85377896 <a title="2277-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-01-I_owe_it_all_to_the_haters.html">834 andrew gelman stats-2011-08-01-I owe it all to the haters</a></p>
<p>13 0.8527689 <a title="2277-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-06-Josh_Tenenbaum_presents_._._._a_model_of_folk_physics%21.html">994 andrew gelman stats-2011-11-06-Josh Tenenbaum presents . . . a model of folk physics!</a></p>
<p>14 0.85189617 <a title="2277-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-09-My_talks_in_DC_and_Baltimore_this_week.html">1794 andrew gelman stats-2013-04-09-My talks in DC and Baltimore this week</a></p>
<p>15 0.85048634 <a title="2277-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-The_importance_of_style_in_academic_writing.html">902 andrew gelman stats-2011-09-12-The importance of style in academic writing</a></p>
<p>16 0.84853745 <a title="2277-lda-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>17 0.84664953 <a title="2277-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>18 0.84401369 <a title="2277-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-30-You_can%E2%80%99t_put_Pandora_back_in_the_box.html">120 andrew gelman stats-2010-06-30-You can’t put Pandora back in the box</a></p>
<p>19 0.84396023 <a title="2277-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>20 0.84385252 <a title="2277-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
