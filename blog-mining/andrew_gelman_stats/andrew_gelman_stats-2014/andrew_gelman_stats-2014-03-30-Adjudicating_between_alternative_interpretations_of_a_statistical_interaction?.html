<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2274 andrew gelman stats-2014-03-30-Adjudicating between alternative interpretations of a statistical interaction?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2014" href="../home/andrew_gelman_stats-2014_home.html">andrew_gelman_stats-2014</a> <a title="andrew_gelman_stats-2014-2274" href="#">andrew_gelman_stats-2014-2274</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2274 andrew gelman stats-2014-03-30-Adjudicating between alternative interpretations of a statistical interaction?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2014-2274-html" href="http://andrewgelman.com/2014/03/30/adjudicating-alternate-interpretations-statistical-interaction/">html</a></p><p>Introduction: Jacob Felson writes:
  
Say we have a statistically significant interaction in non-experimental data between two continuous predictors, X and Z and it is unclear which variable is primarily a cause and which variable is primarily a moderator.  One person might find it more plausible to think of X as a cause and Z as a moderator and another person may think the reverse more plausible.  My question then is whether there is are any set of rules or heuristics you could recommend to help adjudicate between alternate perspectives on such an interaction term.
  
My reply:
 
I think in this setting, it would make sense to think about different interventions, some of which affect X, others of which affect Z, others of which affect both, and go from there.  Rather than trying to isolate a single causal path, consider different cases of forward casual inference.  My guess is that the different stories regarding moderators etc. could motivate different thought experiments (and, ultimately, differe</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Jacob Felson writes:    Say we have a statistically significant interaction in non-experimental data between two continuous predictors, X and Z and it is unclear which variable is primarily a cause and which variable is primarily a moderator. [sent-1, score-1.578]
</p><p>2 One person might find it more plausible to think of X as a cause and Z as a moderator and another person may think the reverse more plausible. [sent-2, score-0.968]
</p><p>3 My question then is whether there is are any set of rules or heuristics you could recommend to help adjudicate between alternate perspectives on such an interaction term. [sent-3, score-1.184]
</p><p>4 My reply:   I think in this setting, it would make sense to think about different interventions, some of which affect X, others of which affect Z, others of which affect both, and go from there. [sent-4, score-1.584]
</p><p>5 Rather than trying to isolate a single causal path, consider different cases of forward casual inference. [sent-5, score-0.702]
</p><p>6 My guess is that the different stories regarding moderators etc. [sent-6, score-0.764]
</p><p>7 could motivate different thought experiments (and, ultimately, different observational studies) regarding different potential interventions. [sent-7, score-1.46]
</p><p>8 So I would not try to â&euro;&oelig;adjudicateâ&euro;? [sent-8, score-0.08]
</p><p>9 between different stories; rather, Iâ&euro;&trade;d recognize that they could all be appropriate, just corresponding to different interventions. [sent-9, score-0.85]
</p><p>10 Also, all the above would hold even if there are only main effects, no interactions needed. [sent-10, score-0.336]
</p><p>11 And, for that matter, statistical significance would not be needed either for you to look at these questions. [sent-11, score-0.248]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('adjudicate', 0.318), ('different', 0.289), ('affect', 0.283), ('primarily', 0.258), ('interaction', 0.203), ('cause', 0.188), ('moderators', 0.172), ('moderator', 0.165), ('stories', 0.162), ('alternate', 0.15), ('heuristics', 0.15), ('variable', 0.149), ('isolate', 0.141), ('regarding', 0.141), ('unclear', 0.136), ('jacob', 0.131), ('interventions', 0.129), ('person', 0.127), ('perspectives', 0.118), ('motivate', 0.116), ('casual', 0.114), ('reverse', 0.109), ('path', 0.107), ('others', 0.104), ('corresponding', 0.103), ('observational', 0.103), ('interactions', 0.094), ('plausible', 0.094), ('continuous', 0.092), ('hold', 0.091), ('recognize', 0.09), ('rules', 0.087), ('needed', 0.087), ('predictors', 0.086), ('forward', 0.085), ('ultimately', 0.082), ('experiments', 0.081), ('significance', 0.081), ('would', 0.08), ('setting', 0.08), ('could', 0.079), ('recommend', 0.079), ('think', 0.079), ('appropriate', 0.076), ('statistically', 0.076), ('rather', 0.075), ('causal', 0.073), ('potential', 0.073), ('main', 0.071), ('significant', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="2274-tfidf-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-30-Adjudicating_between_alternative_interpretations_of_a_statistical_interaction%3F.html">2274 andrew gelman stats-2014-03-30-Adjudicating between alternative interpretations of a statistical interaction?</a></p>
<p>Introduction: Jacob Felson writes:
  
Say we have a statistically significant interaction in non-experimental data between two continuous predictors, X and Z and it is unclear which variable is primarily a cause and which variable is primarily a moderator.  One person might find it more plausible to think of X as a cause and Z as a moderator and another person may think the reverse more plausible.  My question then is whether there is are any set of rules or heuristics you could recommend to help adjudicate between alternate perspectives on such an interaction term.
  
My reply:
 
I think in this setting, it would make sense to think about different interventions, some of which affect X, others of which affect Z, others of which affect both, and go from there.  Rather than trying to isolate a single causal path, consider different cases of forward casual inference.  My guess is that the different stories regarding moderators etc. could motivate different thought experiments (and, ultimately, differe</p><p>2 0.17932488 <a title="2274-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>Introduction: A research psychologist writes in with a question that’s so long that I’ll put my answer first, then put the question itself below the fold.
 
Here’s my reply:
 
As I wrote in my Anova paper and in my book with Jennifer Hill, I do think that multilevel models can completely replace Anova.  At the same time, I think the central idea of Anova should persist in our understanding of these models.  To me the central idea of Anova is not F-tests or p-values or sums of squares, but rather the idea of predicting an outcome based on factors with discrete levels, and understanding these factors using variance components.
 
The continuous or categorical response thing doesn’t really matter so much to me.  I have no problem using a normal linear model for continuous outcomes (perhaps suitably transformed) and a logistic model for binary outcomes.
 
I don’t want to throw away interactions just because they’re not statistically significant.  I’d rather partially pool them toward zero using an inform</p><p>3 0.17552154 <a title="2274-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-15-Forward_causal_reasoning_statements_are_about_estimation%3B_reverse_causal_questions_are_about_model_checking_and_hypothesis_generation.html">1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</a></p>
<p>Introduction: Consider two broad classes of inferential  questions :
  
1.  Forward causal inference . What might happen if we do X? What are the effects of smoking on health, the effects of schooling on knowledge, the effect of campaigns on election outcomes, and so forth?


2.  Reverse causal inference . What causes Y? Why do more attractive people earn more money? Why do many poor people vote for Republicans and rich people vote for Democrats? Why did the economy collapse?
  
When statisticians and econometricians write about causal inference, they focus on forward causal questions.  Rubin always told us:  Never ask Why?  Only ask What if?  And, from the econ perspective, causation is typically framed in terms of manipulations:  if x had changed by 1, how much would y be expected to change, holding all else constant?
 
But reverse causal questions are important too.  They’re a natural way to think (consider the importance of the word “Why”) and are arguably more important than forward questions.</p><p>4 0.14223346 <a title="2274-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-11-Using_the_%E2%80%9Cinstrumental_variables%E2%80%9D_or_%E2%80%9Cpotential_outcomes%E2%80%9D_approach_to_clarify_causal_thinking.html">1492 andrew gelman stats-2012-09-11-Using the “instrumental variables” or “potential outcomes” approach to clarify causal thinking</a></p>
<p>Introduction: As I’ve written here many times, my experiences in social science and public health research have left me skeptical of statistical methods that hypothesize or try to detect zero relationships between observational data (see, for example, the discussion starting at the bottom of page 960 in  my review of causal inference  in the American Journal of Sociology).  In short, I have a taste for continuous rather than discrete models.
 
As discussed in the above-linked article (with respect to the writings of cognitive scientist Steven Sloman), I think that common-sense thinking about causal inference can often mislead.
 
In many cases, I have found that that the theoretical frameworks of instrumental variables and potential outcomes (for a review see, for example, chapters 9 and 10 of my book with Jennifer) help clarify my thinking.
 
Here is an example that came up in a recent blog discussion.  Computer science student Elias Bareinboim gave the following example:  “suppose we know nothing a</p><p>5 0.14132255 <a title="2274-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-17-Macro_causality.html">807 andrew gelman stats-2011-07-17-Macro causality</a></p>
<p>Introduction: David Backus writes:
  
 This  is from my area of work, macroeconomics.  The suggestion here is that the economy is growing slowly because consumers aren’t spending money.  But how do we know it’s not the reverse:  that consumers are spending less because the economy isn’t doing well.  As a teacher, I can tell you that it’s almost impossible to get students to understand that the first statement isn’t obviously true.  What I’d call the demand-side story (more spending leads to more output) is everywhere, including this piece, from the usually reliable David Leonhardt.
  
This whole situation reminds me of the story of the village whose inhabitants support themselves by taking in each others’ laundry.  I guess we’re rich enough in the U.S. that we can stay afloat for a few decades just buying things from each other?
 
Regarding the causal question, I’d like to move away from the idea of “Does A causes B or does B cause A” and toward a more intervention-based framework (Rubin’s model for</p><p>6 0.13114859 <a title="2274-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-15-%E2%80%9C10_Things_You_Need_to_Know_About_Causal_Effects%E2%80%9D.html">1675 andrew gelman stats-2013-01-15-“10 Things You Need to Know About Causal Effects”</a></p>
<p>7 0.11915234 <a title="2274-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-21-Interpreting_interactions_in_discrete-data_regression.html">1908 andrew gelman stats-2013-06-21-Interpreting interactions in discrete-data regression</a></p>
<p>8 0.11108525 <a title="2274-tfidf-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-07-How_literature_is_like_statistical_reasoning%3A__Kosara_on_stories.__Gelman_and_Basb%C3%B8ll_on_stories..html">2284 andrew gelman stats-2014-04-07-How literature is like statistical reasoning:  Kosara on stories.  Gelman and Basbøll on stories.</a></p>
<p>9 0.10904559 <a title="2274-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-22-Handling_multiple_versions_of_an_outcome_variable.html">726 andrew gelman stats-2011-05-22-Handling multiple versions of an outcome variable</a></p>
<p>10 0.10733988 <a title="2274-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>11 0.10477448 <a title="2274-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>12 0.10359462 <a title="2274-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>13 0.10221543 <a title="2274-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Including_interactions_or_not.html">823 andrew gelman stats-2011-07-26-Including interactions or not</a></p>
<p>14 0.10018904 <a title="2274-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-26-New_research_journal_on_observational_studies.html">2268 andrew gelman stats-2014-03-26-New research journal on observational studies</a></p>
<p>15 0.098271862 <a title="2274-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-01-Why_big_effects_are_more_important_than_small_effects.html">1744 andrew gelman stats-2013-03-01-Why big effects are more important than small effects</a></p>
<p>16 0.096671917 <a title="2274-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>17 0.093780577 <a title="2274-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-How_does_multilevel_modeling_affect_the_estimate_of_the_grand_mean%3F.html">255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</a></p>
<p>18 0.092534855 <a title="2274-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-16-Infovis_and_statgraphics_update_update.html">855 andrew gelman stats-2011-08-16-Infovis and statgraphics update update</a></p>
<p>19 0.090915151 <a title="2274-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-29-Another_one_of_those_%E2%80%9CPsychological_Science%E2%80%9D_papers_%28this_time_on_biceps_size_and_political_attitudes_among_college_students%29.html">1876 andrew gelman stats-2013-05-29-Another one of those “Psychological Science” papers (this time on biceps size and political attitudes among college students)</a></p>
<p>20 0.08876887 <a title="2274-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-The_scope_for_snooping.html">1070 andrew gelman stats-2011-12-19-The scope for snooping</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.174), (1, 0.022), (2, 0.036), (3, -0.083), (4, 0.03), (5, -0.029), (6, -0.021), (7, 0.0), (8, 0.066), (9, 0.069), (10, -0.038), (11, 0.041), (12, 0.029), (13, -0.056), (14, 0.051), (15, 0.009), (16, -0.034), (17, -0.024), (18, -0.018), (19, 0.077), (20, -0.022), (21, -0.03), (22, 0.043), (23, 0.02), (24, 0.005), (25, 0.063), (26, 0.048), (27, -0.023), (28, -0.042), (29, 0.01), (30, 0.033), (31, 0.01), (32, -0.02), (33, 0.035), (34, -0.004), (35, 0.001), (36, -0.016), (37, 0.026), (38, -0.017), (39, 0.025), (40, -0.031), (41, -0.041), (42, 0.02), (43, 0.012), (44, -0.027), (45, -0.027), (46, 0.041), (47, 0.037), (48, -0.008), (49, 0.008)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96506119 <a title="2274-lsi-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-30-Adjudicating_between_alternative_interpretations_of_a_statistical_interaction%3F.html">2274 andrew gelman stats-2014-03-30-Adjudicating between alternative interpretations of a statistical interaction?</a></p>
<p>Introduction: Jacob Felson writes:
  
Say we have a statistically significant interaction in non-experimental data between two continuous predictors, X and Z and it is unclear which variable is primarily a cause and which variable is primarily a moderator.  One person might find it more plausible to think of X as a cause and Z as a moderator and another person may think the reverse more plausible.  My question then is whether there is are any set of rules or heuristics you could recommend to help adjudicate between alternate perspectives on such an interaction term.
  
My reply:
 
I think in this setting, it would make sense to think about different interventions, some of which affect X, others of which affect Z, others of which affect both, and go from there.  Rather than trying to isolate a single causal path, consider different cases of forward casual inference.  My guess is that the different stories regarding moderators etc. could motivate different thought experiments (and, ultimately, differe</p><p>2 0.84240782 <a title="2274-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-11-Using_the_%E2%80%9Cinstrumental_variables%E2%80%9D_or_%E2%80%9Cpotential_outcomes%E2%80%9D_approach_to_clarify_causal_thinking.html">1492 andrew gelman stats-2012-09-11-Using the “instrumental variables” or “potential outcomes” approach to clarify causal thinking</a></p>
<p>Introduction: As I’ve written here many times, my experiences in social science and public health research have left me skeptical of statistical methods that hypothesize or try to detect zero relationships between observational data (see, for example, the discussion starting at the bottom of page 960 in  my review of causal inference  in the American Journal of Sociology).  In short, I have a taste for continuous rather than discrete models.
 
As discussed in the above-linked article (with respect to the writings of cognitive scientist Steven Sloman), I think that common-sense thinking about causal inference can often mislead.
 
In many cases, I have found that that the theoretical frameworks of instrumental variables and potential outcomes (for a review see, for example, chapters 9 and 10 of my book with Jennifer) help clarify my thinking.
 
Here is an example that came up in a recent blog discussion.  Computer science student Elias Bareinboim gave the following example:  “suppose we know nothing a</p><p>3 0.79042798 <a title="2274-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-04-Estimating_the_effect_of_A_on_B%2C_and_also_the_effect_of_B_on_A.html">393 andrew gelman stats-2010-11-04-Estimating the effect of A on B, and also the effect of B on A</a></p>
<p>Introduction: Lei Liu writes:
  
 
I am working with clinicians in infectious disease and international health to study the (possible causal) relation between malnutrition and virus infection episodes (e.g., diarrhea) in babies in developing countries.


Basically the clinicians are interested in two questions: does malnutrition cause more diarrhea episodes? does diarrhea lead to malnutrition? The malnutrition status is indicated by height and weight (adjusted, HAZ and WAZ measures) observed every 3 months from birth to 1 year. They also recorded the time of each diarrhea episode during the 1 year follow-up period. They have very solid datasets for analysis.


As you can see, this is almost like a chicken and egg problem. I am a layman to causal inference. The method I use is just to do some simple regression. For example, to study the causal relation from malnutrition to diarrhea episodes, I use binary variable (diarrhea yes/no during months 0-3) as response, and use the HAZ at month 0 as covariate</p><p>4 0.78340518 <a title="2274-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-09-Keli_Liu_and_Xiao-Li_Meng_on_Simpson%E2%80%99s_paradox.html">2204 andrew gelman stats-2014-02-09-Keli Liu and Xiao-Li Meng on Simpson’s paradox</a></p>
<p>Introduction: XL sent me  this paper , “A Fruitful Resolution to Simpson’s Paradox via Multi-Resolution Inference.”
 
I told Keli and Xiao-Li that I wasn’t sure I fully understood the paper—as usual, XL is subtle and sophisticated, also I only get about half of his jokes—but I sent along these thoughts:
  
1.  I do not think counterfactuals or potential outcomes are necessary for Simpson’s paradox.  I say this because one can set up Simpson’s paradox with variables that cannot be manipulated, or for which manipulations are not directly of interest.


2.  Simpson’s paradox is part of a more general issue that regression coefs change if you add more predictors, the flipping of sign is not really necessary.


Here’s an example that I use in my teaching that illustrates both points:


I can run a regression predicting income from sex and height.  I find that the coef of sex is $10,000 (i.e., comparing a man and woman of the same height, on average the man will make $10,000 more) and the coefficient of h</p><p>5 0.77682972 <a title="2274-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>Introduction: Elias Bareinboim asked what I thought about  his comment  on selection bias in which he referred to a  paper  by himself and Judea Pearl, “Controlling Selection Bias in Causal Inference.”
 
I replied that I have no problem with what he wrote, but that from my perspective I find it easier to conceptualize such problems in terms of multilevel models. I elaborated on that point in a  recent post , “Hierarchical modeling as a framework for extrapolation,” which I think was read by only a few people (I say this because it received only two comments).
 
I don’t think Bareinboim objected to anything I wrote, but like me he is comfortable working within his own framework.  He wrote the following to me: 
  
  
In some sense, “not ad hoc” could mean logically consistent. In other words, if one agrees with the assumptions encoded in the model, one must also agree with the conclusions entailed by these assumptions. I am not aware of any other way of doing mathematics. As it turns out, to get causa</p><p>6 0.76648134 <a title="2274-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-03-is_it_possible_to_%E2%80%9Coverstratify%E2%80%9D_when_assigning_a_treatment_in_a_randomized_control_trial%3F.html">553 andrew gelman stats-2011-02-03-is it possible to “overstratify” when assigning a treatment in a randomized control trial?</a></p>
<p>7 0.76227826 <a title="2274-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-All_inference_is_about_generalizing_from_sample_to_population.html">1996 andrew gelman stats-2013-08-24-All inference is about generalizing from sample to population</a></p>
<p>8 0.76068974 <a title="2274-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-22-Evaluating_the_impacts_of_welfare_reform%3F.html">1732 andrew gelman stats-2013-02-22-Evaluating the impacts of welfare reform?</a></p>
<p>9 0.75526464 <a title="2274-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-20-Paul_Rosenbaum_on_those_annoying_pre-treatment_variables_that_are_sort-of_instruments_and_sort-of_covariates.html">287 andrew gelman stats-2010-09-20-Paul Rosenbaum on those annoying pre-treatment variables that are sort-of instruments and sort-of covariates</a></p>
<p>10 0.75135577 <a title="2274-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-15-%E2%80%9C10_Things_You_Need_to_Know_About_Causal_Effects%E2%80%9D.html">1675 andrew gelman stats-2013-01-15-“10 Things You Need to Know About Causal Effects”</a></p>
<p>11 0.74993318 <a title="2274-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-23-Fight%21__%28also_a_bit_of_reminiscence_at_the_end%29.html">1136 andrew gelman stats-2012-01-23-Fight!  (also a bit of reminiscence at the end)</a></p>
<p>12 0.74390602 <a title="2274-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>13 0.74310392 <a title="2274-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Education_and_Poverty.html">560 andrew gelman stats-2011-02-06-Education and Poverty</a></p>
<p>14 0.73724699 <a title="2274-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-09-The_effects_of_fiscal_consolidation.html">1663 andrew gelman stats-2013-01-09-The effects of fiscal consolidation</a></p>
<p>15 0.73708421 <a title="2274-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-14-%E2%80%9CToo_much_data%E2%80%9D%3F.html">86 andrew gelman stats-2010-06-14-“Too much data”?</a></p>
<p>16 0.72807139 <a title="2274-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-22-Struggles_over_the_criticism_of_the_%E2%80%9Ccannabis_users_and_IQ_change%E2%80%9D_paper.html">1910 andrew gelman stats-2013-06-22-Struggles over the criticism of the “cannabis users and IQ change” paper</a></p>
<p>17 0.72363561 <a title="2274-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-02-An_IV_won%E2%80%99t_save_your_life_if_the_line_is_tangled.html">550 andrew gelman stats-2011-02-02-An IV won’t save your life if the line is tangled</a></p>
<p>18 0.71514374 <a title="2274-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-The_scope_for_snooping.html">1070 andrew gelman stats-2011-12-19-The scope for snooping</a></p>
<p>19 0.71496129 <a title="2274-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-15-Forward_causal_reasoning_statements_are_about_estimation%3B_reverse_causal_questions_are_about_model_checking_and_hypothesis_generation.html">1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</a></p>
<p>20 0.7108134 <a title="2274-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-16-How_much_can_we_learn_about_individual-level_causal_claims_from_state-level_correlations%3F.html">2336 andrew gelman stats-2014-05-16-How much can we learn about individual-level causal claims from state-level correlations?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.042), (21, 0.015), (24, 0.157), (35, 0.086), (53, 0.041), (56, 0.021), (68, 0.031), (79, 0.048), (82, 0.017), (88, 0.017), (89, 0.047), (99, 0.376)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98356718 <a title="2274-lda-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-30-Adjudicating_between_alternative_interpretations_of_a_statistical_interaction%3F.html">2274 andrew gelman stats-2014-03-30-Adjudicating between alternative interpretations of a statistical interaction?</a></p>
<p>Introduction: Jacob Felson writes:
  
Say we have a statistically significant interaction in non-experimental data between two continuous predictors, X and Z and it is unclear which variable is primarily a cause and which variable is primarily a moderator.  One person might find it more plausible to think of X as a cause and Z as a moderator and another person may think the reverse more plausible.  My question then is whether there is are any set of rules or heuristics you could recommend to help adjudicate between alternate perspectives on such an interaction term.
  
My reply:
 
I think in this setting, it would make sense to think about different interventions, some of which affect X, others of which affect Z, others of which affect both, and go from there.  Rather than trying to isolate a single causal path, consider different cases of forward casual inference.  My guess is that the different stories regarding moderators etc. could motivate different thought experiments (and, ultimately, differe</p><p>2 0.97569925 <a title="2274-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-25-Quantitative_Methods_in_the_Social_Sciences_M.A.%3A_Innovative%2C_interdisciplinary_social_science_research_program_for_a_data-rich_world.html">591 andrew gelman stats-2011-02-25-Quantitative Methods in the Social Sciences M.A.: Innovative, interdisciplinary social science research program for a data-rich world</a></p>
<p>Introduction: About 12 years ago Greg Wawro, Sy Spilerman, and I started a M.A. program here in Quantitative Methods in Social Sciences, jointly between the departments of history, economics, political science, sociology, psychology, and statistics.  We created a bunch of new features for the program, including an interdisciplinary course based on  this book .
  

 
And here’s their new logo:
 
 
 
Don’t blame me for the pie-chart motif!  Seriously, though, the program is great.  I’m proud to have gotten it started, and I’m impressed by the progress that Chris Weiss and others have made in expanding the program during the past decade.</p><p>3 0.9745366 <a title="2274-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-05-More_plain_old_everyday_Bayesianism.html">1926 andrew gelman stats-2013-07-05-More plain old everyday Bayesianism</a></p>
<p>Introduction: Following up on  this story , Bob Goodman writes:
  
A most recent issue of the New England Journal of Medicine published a study entitled  “Biventricular Pacing for Atrioventricular Block and Systolic Dysfunction,” (N Engl J Med 2013; 368:1585-1593), whereby “A hierarchical Bayesian proportional-hazards model was used for analysis of the primary outcome.” It is the first study I can recall in this journal that has reported on Table 2 (primary outcomes) “The Posterior Probability of Hazard Ratio < 1" (which in this case was .9978).
  
This is ok, but to be really picky I will say that there’s typically not so much reason to care about the posterior probability that the effect is greater than 1; I’d rather have an estimate of the effect.  Also we  should  be using informative priors.</p><p>4 0.97043794 <a title="2274-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<p>Introduction: Burak Bayramli writes:
  
In  this paper  by Sunjin Ahn, Anoop Korattikara, and Max Welling and  this paper  by Welling and Yee Whye The, there are some arguments on big data and the use of MCMC. Both papers have suggested improvements to speed up MCMC computations. I was wondering what your thoughts were, especially on this paragraph:

 
When a dataset has a billion data-cases (as is not uncommon these days) MCMC algorithms will not even have generated a single (burn-in) sample when a clever learning algorithm based on stochastic gradients may already be making fairly good predictions. In fact, the intriguing results of Bottou and Bousquet (2008) seem to indicate that in terms of “number of bits learned per unit of computation”, an algorithm as simple as stochastic gradient descent is almost optimally efficient. We therefore argue that for Bayesian methods to remain useful in an age when the datasets grow at an exponential rate, they need to embrace the ideas of the stochastic optimiz</p><p>5 0.96698666 <a title="2274-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-30-Computational_problems_with_glm_etc..html">1516 andrew gelman stats-2012-09-30-Computational problems with glm etc.</a></p>
<p>Introduction: John Mount  provides some useful background and follow-up  on our discussion  from last year  on computational instability of the usual logistic regression solver.
 
Just to refresh your memory, here’s a simple logistic regression with only a constant term and no separation, nothing pathological at all:
 
 > y <- rep (c(1,0),c(10,5)) 
> display (glm (y ~ 1, family=binomial(link="logit"))) 
glm(formula = y ~ 1, family = binomial(link = "logit")) 
            coef.est coef.se 
(Intercept) 0.69     0.55 
--- 
  n = 15, k = 1 
  residual deviance = 19.1, null deviance = 19.1 (difference = 0.0) 
 
And here’s what happens when we give it the not-outrageous starting value of -2:
 
 > display (glm (y ~ 1, family=binomial(link="logit"), start=-2)) 
glm(formula = y ~ 1, family = binomial(link = "logit"), start = -2) 
            coef.est    coef.se 
(Intercept)       71.97 17327434.18 
--- 
  n = 15, k = 1 
  residual deviance = 360.4, null deviance = 19.1 (difference = -341.3) 
Warning message:</p><p>6 0.96439278 <a title="2274-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-26-A_simple_semigraphic_display.html">296 andrew gelman stats-2010-09-26-A simple semigraphic display</a></p>
<p>7 0.96234524 <a title="2274-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-03-Taleb_%2B_3.5_years.html">392 andrew gelman stats-2010-11-03-Taleb + 3.5 years</a></p>
<p>8 0.96201158 <a title="2274-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>9 0.95963669 <a title="2274-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-04-All_the_Assumptions_That_Are_My_Life.html">2359 andrew gelman stats-2014-06-04-All the Assumptions That Are My Life</a></p>
<p>10 0.95942914 <a title="2274-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-08-Software_is_as_software_does.html">1661 andrew gelman stats-2013-01-08-Software is as software does</a></p>
<p>11 0.95802814 <a title="2274-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>12 0.95730436 <a title="2274-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-09-The_boxer%2C_the_wrestler%2C_and_the_coin_flip%2C_again.html">566 andrew gelman stats-2011-02-09-The boxer, the wrestler, and the coin flip, again</a></p>
<p>13 0.95719278 <a title="2274-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-15-Forward_causal_reasoning_statements_are_about_estimation%3B_reverse_causal_questions_are_about_model_checking_and_hypothesis_generation.html">1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</a></p>
<p>14 0.9571591 <a title="2274-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>15 0.95699954 <a title="2274-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-13-Stopping_rules_and_Bayesian_analysis.html">2210 andrew gelman stats-2014-02-13-Stopping rules and Bayesian analysis</a></p>
<p>16 0.95632035 <a title="2274-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-20-The_pervasive_twoishness_of_statistics%3B_in_particular%2C_the_%E2%80%9Csampling_distribution%E2%80%9D_and_the_%E2%80%9Clikelihood%E2%80%9D_are_two_different_models%2C_and_that%E2%80%99s_a_good_thing.html">774 andrew gelman stats-2011-06-20-The pervasive twoishness of statistics; in particular, the “sampling distribution” and the “likelihood” are two different models, and that’s a good thing</a></p>
<p>17 0.95630258 <a title="2274-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-How_do_you_interpret_standard_errors_from_a_regression_fit_to_the_entire_population%3F.html">972 andrew gelman stats-2011-10-25-How do you interpret standard errors from a regression fit to the entire population?</a></p>
<p>18 0.95629048 <a title="2274-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-21-Chasing_the_noise.html">2142 andrew gelman stats-2013-12-21-Chasing the noise</a></p>
<p>19 0.95627522 <a title="2274-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>20 0.95622671 <a title="2274-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-19-Slick_time_series_decomposition_of_the_birthdays_data.html">1384 andrew gelman stats-2012-06-19-Slick time series decomposition of the birthdays data</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
