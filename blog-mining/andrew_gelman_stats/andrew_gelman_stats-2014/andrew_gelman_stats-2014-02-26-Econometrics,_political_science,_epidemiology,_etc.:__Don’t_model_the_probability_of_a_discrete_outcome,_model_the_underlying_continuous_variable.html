<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2226 andrew gelman stats-2014-02-26-Econometrics, political science, epidemiology, etc.:  Don’t model the probability of a discrete outcome, model the underlying continuous variable</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2014" href="../home/andrew_gelman_stats-2014_home.html">andrew_gelman_stats-2014</a> <a title="andrew_gelman_stats-2014-2226" href="#">andrew_gelman_stats-2014-2226</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2226 andrew gelman stats-2014-02-26-Econometrics, political science, epidemiology, etc.:  Don’t model the probability of a discrete outcome, model the underlying continuous variable</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2014-2226-html" href="http://andrewgelman.com/2014/02/26/econometrics-political-science-epidemiology-etc-dont-model-probability-discrete-outcome-model-underlying-continuous-variable/">html</a></p><p>Introduction: This is an echo of yesterday’s post,  Basketball Stats: Don’t model the probability of win, model the expected score differential .
 
As with basketball, so with baseball:  as the great Bill James wrote, if you want to predict a pitcher’s win-loss record, it’s better to use last year’s ERA than last year’s W-L.
 
As with basketball and baseball, so with epidemiology:  as Joseph Delaney  points out  in my favorite blog that nobody reads, you will see much better prediction if you first model change in the parameter (e.g. blood pressure) and then convert that to the binary disease state (e.g. hypertension) then if you just develop a logistic model for prob(hypertension).
 
As with basketball, baseball, and epidemiology, so with political science:  instead of modeling election winners, better to model vote differential, a point that I made back in 1993 (see page 120  here ) but which seems to continually need  repeating .  A forecasting method should get essentially no credit for correctl</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This is an echo of yesterday’s post,  Basketball Stats: Don’t model the probability of win, model the expected score differential . [sent-1, score-0.978]
</p><p>2 As with basketball, so with baseball:  as the great Bill James wrote, if you want to predict a pitcher’s win-loss record, it’s better to use last year’s ERA than last year’s W-L. [sent-2, score-0.138]
</p><p>3 As with basketball and baseball, so with epidemiology:  as Joseph Delaney  points out  in my favorite blog that nobody reads, you will see much better prediction if you first model change in the parameter (e. [sent-3, score-0.564]
</p><p>4 blood pressure) and then convert that to the binary disease state (e. [sent-5, score-0.226]
</p><p>5 hypertension) then if you just develop a logistic model for prob(hypertension). [sent-7, score-0.243]
</p><p>6 As with basketball, baseball, and epidemiology, so with political science:  instead of modeling election winners, better to model vote differential, a point that I made back in 1993 (see page 120  here ) but which seems to continually need  repeating . [sent-8, score-0.71]
</p><p>7 A forecasting method should get essentially no credit for correctly predicting the winner in 1960, 1968, or 2000 and very little for predicting the winner in 1964 or 1964, but there’s information in vote differential, all the same. [sent-9, score-0.606]
</p><p>8 As with basketball, baseball, and epidemiology, and political science, so with econometrics:  Even in recent years, with all the sophistication in economic statistics, you’ll still see people fitting logistic models for binary outcomes even when the continuous variable is readily available. [sent-10, score-0.601]
</p><p>9 (See, for example, the second-to-last paragraph  here , which is actually an economist doing political science, but I’m pretty sure there are lots of examples of this sort of thing in econ too. [sent-11, score-0.07]
</p><p>10 Why do people keep modeling the discrete variable? [sent-14, score-0.09]
</p><p>11 Some of the answer is statistical naivety, a simple “like goes with like” attitude that it makes sense to predict W-L from W-L rather than ERA. [sent-15, score-0.166]
</p><p>12 More generally there’s the attitude that we should be modeling what we ultimately care about. [sent-16, score-0.175]
</p><p>13 If the objective is to learn about wins, we should study wins directly. [sent-17, score-0.381]
</p><p>14 To which I reply, sure, study wins, but it will be more statistically efficient to do this in a two-stage process:  first study vote differential given X, then study wins given vote differential and X. [sent-18, score-1.797]
</p><p>15 The key is that vote differential is available, and a simply performing a logit model for wins alone is implicitly taking this differential as latent or missing data, thus throwing away information. [sent-19, score-1.468]
</p><p>16 Finally, from the econometrics direction, I see a bias or robustness argument. [sent-20, score-0.367]
</p><p>17 The idea is that it’s safer, in some way, to model the outcome of interest, as this model will not be sensitive to assumptions about the distribution of the intermediate variable. [sent-21, score-0.365]
</p><p>18 For example, a linear model for score differentials could be inappropriate for games where one team runs up the score (or, conversely, for those games where the team that’s winning sends in the subs so that the score is less lopsided than it would be if both teams were playing their hardest). [sent-22, score-1.301]
</p><p>19 In response to this, I would make my usual argument that your models  already  have bias and robustness issues in that, to do your regression at all, you’re already pooling data from many years, many places, many different situations, etc. [sent-23, score-0.427]
</p><p>20 If the use of continuous data can increase your statistical efficiency—and it will—this in turn will allow you to do less pooling of data to construct estimates that are reliable enough for you to work with. [sent-24, score-0.314]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('differential', 0.419), ('basketball', 0.296), ('wins', 0.284), ('baseball', 0.21), ('epidemiology', 0.198), ('vote', 0.192), ('score', 0.185), ('hypertension', 0.174), ('model', 0.154), ('robustness', 0.126), ('winner', 0.116), ('pooling', 0.113), ('econometrics', 0.106), ('games', 0.105), ('binary', 0.097), ('study', 0.097), ('predicting', 0.091), ('modeling', 0.09), ('logistic', 0.089), ('continuous', 0.087), ('lopsided', 0.087), ('attitude', 0.085), ('pitcher', 0.082), ('prob', 0.082), ('differentials', 0.082), ('predict', 0.081), ('team', 0.079), ('bias', 0.078), ('continually', 0.076), ('repeating', 0.071), ('variable', 0.071), ('political', 0.07), ('hardest', 0.07), ('safer', 0.068), ('delaney', 0.066), ('echo', 0.066), ('blood', 0.066), ('readily', 0.065), ('sophistication', 0.065), ('science', 0.063), ('convert', 0.063), ('winners', 0.06), ('ok', 0.059), ('reliable', 0.059), ('intermediate', 0.057), ('see', 0.057), ('better', 0.057), ('construct', 0.055), ('inappropriate', 0.055), ('already', 0.055)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="2226-tfidf-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-26-Econometrics%2C_political_science%2C_epidemiology%2C_etc.%3A__Don%E2%80%99t_model_the_probability_of_a_discrete_outcome%2C_model_the_underlying_continuous_variable.html">2226 andrew gelman stats-2014-02-26-Econometrics, political science, epidemiology, etc.:  Don’t model the probability of a discrete outcome, model the underlying continuous variable</a></p>
<p>Introduction: This is an echo of yesterday’s post,  Basketball Stats: Don’t model the probability of win, model the expected score differential .
 
As with basketball, so with baseball:  as the great Bill James wrote, if you want to predict a pitcher’s win-loss record, it’s better to use last year’s ERA than last year’s W-L.
 
As with basketball and baseball, so with epidemiology:  as Joseph Delaney  points out  in my favorite blog that nobody reads, you will see much better prediction if you first model change in the parameter (e.g. blood pressure) and then convert that to the binary disease state (e.g. hypertension) then if you just develop a logistic model for prob(hypertension).
 
As with basketball, baseball, and epidemiology, so with political science:  instead of modeling election winners, better to model vote differential, a point that I made back in 1993 (see page 120  here ) but which seems to continually need  repeating .  A forecasting method should get essentially no credit for correctl</p><p>2 0.38022134 <a title="2226-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-25-Basketball_Stats%3A__Don%E2%80%99t_model_the_probability_of_win%2C_model_the_expected_score_differential..html">2224 andrew gelman stats-2014-02-25-Basketball Stats:  Don’t model the probability of win, model the expected score differential.</a></p>
<p>Introduction: Someone who wants to remain anonymous writes:
  
I am working to create a more accurate in-game win probability model for basketball games. My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.


This problem would seem to fit a multi-level model structure well. It seems silly to estimate 2,000 regressions (one for each timestep), but the coefficients should vary at each timestep. Do you have suggestions for what type of model this could/would be? Additionally, I believe this needs to be some form of logit/probit given the binary dependent variable (win or loss).


Finally, do you have suggestions for what package could accomplish this in Stata or R?
  
To answer the questions in reverse order: 
3.  I’d hope this could be done in Stan (which can be run from R)</p><p>3 0.27673355 <a title="2226-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-15-Of_forecasts_and_graph_theory_and_characterizing_a_statistical_method_by_the_information_it_uses.html">1214 andrew gelman stats-2012-03-15-Of forecasts and graph theory and characterizing a statistical method by the information it uses</a></p>
<p>Introduction: Wayne Folta points me to  “EigenBracket 2012: Using Graph Theory to Predict NCAA March Madness Basketball”  and writes, “I [Folta] have got to believe that he’s simply re-invented a statistical method in a graph-ish context, but don’t know enough to judge.”
 
I have not looked in detail at the method being presented here—I’m not much of college basketball fan—but I’d like to use this as an excuse to make one of my favorite general point, which is that a good way to characterize any statistical method is by what information it uses. 
   
The basketball ranking method here uses score differentials between teams in the past season.  On the plus side, that is better than simply using one-loss records (which (a) discards score differentials and (b) discards information on who played whom).  On the minus side, the method appears to be discretizing the scores (thus throwing away information on the exact score differential) and doesn’t use any external information such as external ratings.
 
A</p><p>4 0.25839853 <a title="2226-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-23-Win_probabilities_during_a_sporting_event.html">2262 andrew gelman stats-2014-03-23-Win probabilities during a sporting event</a></p>
<p>Introduction: Todd Schneider writes: 
   
 
 Apropos of your recent  blog post about modeling score differential of basketball games , I thought you might enjoy a site I built, gambletron2000.com , that gathers real-time win probabilities from betting markets for most major sports (including NBA and college basketball). 
  
 My original goal was to use the variance of changes in win probabilities to quantify which games were the most exciting, but I got a bit carried away and ended up pursuing a bunch of other ideas, whichÂ  you can read about in the full writeup here  
  
 This particular passage from the anonymous someone in your post: 
  

My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.

  
 reminded me of a graph I made, which shows the mean-reverting tendency of N</p><p>5 0.22720867 <a title="2226-tfidf-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Bayesian_Uncertainty_Quantification_for_Differential_Equations%21.html">2311 andrew gelman stats-2014-04-29-Bayesian Uncertainty Quantification for Differential Equations!</a></p>
<p>Introduction: Mark Girolami points us to  this paper and software  (with Oksana Chkrebtii, David Campbell, and Ben Calderhead).  They write:
  
We develop a general methodology for the probabilistic integration of differential equations via model based updating of a joint prior measure on the space of functions and their temporal and spatial derivatives. This results in a posterior measure over functions reflecting how well they satisfy the system of differential equations and corresponding initial and boundary values. We show how this posterior measure can be naturally incorporated within the Kennedy and O’Hagan framework for uncertainty quantification and provides a fully Bayesian approach to model calibration. . . . A broad variety of examples are provided to illustrate the potential of this framework for characterising discretization uncertainty, including initial value, delay, and boundary value differential equations, as well as partial differential equations. We also demonstrate our methodolo</p><p>6 0.21340743 <a title="2226-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-24-On_deck_this_week.html">2222 andrew gelman stats-2014-02-24-On deck this week</a></p>
<p>7 0.17134978 <a title="2226-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-12-Probability_of_successive_wins_in_baseball.html">29 andrew gelman stats-2010-05-12-Probability of successive wins in baseball</a></p>
<p>8 0.15837249 <a title="2226-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-03-Bayes_pays%21.html">1923 andrew gelman stats-2013-07-03-Bayes pays!</a></p>
<p>9 0.15615445 <a title="2226-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-07-Minor-league_Stats_Predict_Major-league_Performance%2C_Sarah_Palin%2C_and_Some_Differences_Between_Baseball_and_Politics.html">652 andrew gelman stats-2011-04-07-Minor-league Stats Predict Major-league Performance, Sarah Palin, and Some Differences Between Baseball and Politics</a></p>
<p>10 0.15556006 <a title="2226-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-05-A_statistician_rereads_Bill_James.html">697 andrew gelman stats-2011-05-05-A statistician rereads Bill James</a></p>
<p>11 0.13953438 <a title="2226-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-22-Is_it_meaningful_to_talk_about_a_probability_of_%E2%80%9C65.7%25%E2%80%9D_that_Obama_will_win_the_election%3F.html">1544 andrew gelman stats-2012-10-22-Is it meaningful to talk about a probability of “65.7%” that Obama will win the election?</a></p>
<p>12 0.13866228 <a title="2226-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-27-Why_can%E2%80%99t_I_be_more_like_Bill_James%2C_or%2C_The_use_of_default_and_default-like_models.html">541 andrew gelman stats-2011-01-27-Why can’t I be more like Bill James, or, The use of default and default-like models</a></p>
<p>13 0.13092698 <a title="2226-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>14 0.13051143 <a title="2226-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>15 0.12888753 <a title="2226-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>16 0.12704466 <a title="2226-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-05-Let%E2%80%99s_try_this%3A__Instead_of_saying%2C_%E2%80%9CThe_probability_is_75%25%2C%E2%80%9D_say_%E2%80%9CThere%E2%80%99s_a_25%25_chance_I%E2%80%99m_wrong%E2%80%9D.html">1562 andrew gelman stats-2012-11-05-Let’s try this:  Instead of saying, “The probability is 75%,” say “There’s a 25% chance I’m wrong”</a></p>
<p>17 0.12215078 <a title="2226-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-19-How_Americans_vote.html">2255 andrew gelman stats-2014-03-19-How Americans vote</a></p>
<p>18 0.11512344 <a title="2226-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-23-Learning_Differential_Geometry_for_Hamiltonian_Monte_Carlo.html">1339 andrew gelman stats-2012-05-23-Learning Differential Geometry for Hamiltonian Monte Carlo</a></p>
<p>19 0.11326864 <a title="2226-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-27-Overfitting.html">1431 andrew gelman stats-2012-07-27-Overfitting</a></p>
<p>20 0.11315741 <a title="2226-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-21-Will_Tiger_Woods_catch_Jack_Nicklaus%3F__And_a_discussion_of_the_virtues_of_using_continuous_data_even_if_your_goal_is_discrete_prediction.html">1387 andrew gelman stats-2012-06-21-Will Tiger Woods catch Jack Nicklaus?  And a discussion of the virtues of using continuous data even if your goal is discrete prediction</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.221), (1, 0.065), (2, 0.103), (3, 0.07), (4, 0.002), (5, 0.025), (6, -0.039), (7, -0.044), (8, 0.076), (9, 0.008), (10, 0.057), (11, 0.082), (12, -0.032), (13, -0.088), (14, -0.123), (15, 0.017), (16, 0.051), (17, -0.025), (18, 0.044), (19, -0.049), (20, -0.03), (21, 0.05), (22, 0.014), (23, -0.014), (24, 0.01), (25, 0.067), (26, 0.021), (27, -0.0), (28, -0.066), (29, -0.207), (30, -0.032), (31, -0.025), (32, 0.021), (33, -0.005), (34, 0.016), (35, 0.045), (36, 0.07), (37, 0.0), (38, -0.07), (39, 0.015), (40, 0.042), (41, -0.038), (42, -0.014), (43, -0.02), (44, -0.012), (45, 0.03), (46, -0.022), (47, 0.024), (48, -0.113), (49, 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93333805 <a title="2226-lsi-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-26-Econometrics%2C_political_science%2C_epidemiology%2C_etc.%3A__Don%E2%80%99t_model_the_probability_of_a_discrete_outcome%2C_model_the_underlying_continuous_variable.html">2226 andrew gelman stats-2014-02-26-Econometrics, political science, epidemiology, etc.:  Don’t model the probability of a discrete outcome, model the underlying continuous variable</a></p>
<p>Introduction: This is an echo of yesterday’s post,  Basketball Stats: Don’t model the probability of win, model the expected score differential .
 
As with basketball, so with baseball:  as the great Bill James wrote, if you want to predict a pitcher’s win-loss record, it’s better to use last year’s ERA than last year’s W-L.
 
As with basketball and baseball, so with epidemiology:  as Joseph Delaney  points out  in my favorite blog that nobody reads, you will see much better prediction if you first model change in the parameter (e.g. blood pressure) and then convert that to the binary disease state (e.g. hypertension) then if you just develop a logistic model for prob(hypertension).
 
As with basketball, baseball, and epidemiology, so with political science:  instead of modeling election winners, better to model vote differential, a point that I made back in 1993 (see page 120  here ) but which seems to continually need  repeating .  A forecasting method should get essentially no credit for correctl</p><p>2 0.87693805 <a title="2226-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-25-Basketball_Stats%3A__Don%E2%80%99t_model_the_probability_of_win%2C_model_the_expected_score_differential..html">2224 andrew gelman stats-2014-02-25-Basketball Stats:  Don’t model the probability of win, model the expected score differential.</a></p>
<p>Introduction: Someone who wants to remain anonymous writes:
  
I am working to create a more accurate in-game win probability model for basketball games. My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.


This problem would seem to fit a multi-level model structure well. It seems silly to estimate 2,000 regressions (one for each timestep), but the coefficients should vary at each timestep. Do you have suggestions for what type of model this could/would be? Additionally, I believe this needs to be some form of logit/probit given the binary dependent variable (win or loss).


Finally, do you have suggestions for what package could accomplish this in Stata or R?
  
To answer the questions in reverse order: 
3.  I’d hope this could be done in Stan (which can be run from R)</p><p>3 0.74911523 <a title="2226-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-21-Will_Tiger_Woods_catch_Jack_Nicklaus%3F__And_a_discussion_of_the_virtues_of_using_continuous_data_even_if_your_goal_is_discrete_prediction.html">1387 andrew gelman stats-2012-06-21-Will Tiger Woods catch Jack Nicklaus?  And a discussion of the virtues of using continuous data even if your goal is discrete prediction</a></p>
<p>Introduction: I know next to nothing about golf.  My mini-golf scores typically approach the maximum of 7 per hole, and I’ve never actually played macro-golf.  I did publish a paper on golf once ( A Probability Model for Golf Putting , with Deb Nolan), but it’s not so rare for people to publish papers on topics they know nothing about.  Those who can’t, research.
 
But I certainly have the ability to post other people’s ideas.  Charles Murray writes:
  
I [Murray] am playing around with the likelihood of Tiger Woods breaking Nicklaus’s record in the Majors. I’ve already gone on record  two years ago  with the reason why he won’t, but now I’m looking at it from a non-psychological perspective. Given the history of the majors, what how far above the average _for other great golfers_ does Tiger have to perform?


Here’s the procedure I’ve been working on:


1. For all golfers who have won at at least one major since 1934 (the year the Masters began), create 120 lines: one for each Major for each year f</p><p>4 0.71819353 <a title="2226-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-20-Andy_vs._the_Ideal_Point_Model_of_Voting.html">355 andrew gelman stats-2010-10-20-Andy vs. the Ideal Point Model of Voting</a></p>
<p>Introduction: Last week, as I walked into Andrew’s office for a meeting, he was 
formulating some misgivings about applying an ideal-point model to 
budgetary bills in the U.S. Senate.  Andrew didn’t like that the model 
of a senator’s position was an indifference point rather than at their 
optimal point, and that the effect of moving away from a position was 
automatically modeled as increasing in one direction and decreasing in 
the other.
 
 Executive Summary 
 
The monotonicity of inverse logit entails that the expected vote 
for a bill among any fixed collection of senators’ ideal points is 
monotonically increasing (or decreasing) with the bill’s position, 
with direction determined by the outcome coding.
 
 The Ideal-Point Model 
 

The ideal-point model’s easy to write down, but hard to reason about 
because of all the polarity shifting going on.  To recapitulate from 
Gelman and Hill’s 
  Regression   
book (p. 317), using the U.S. Senate instead of the Supreme Court, and 
ignoring the dis</p><p>5 0.71204048 <a title="2226-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-23-Win_probabilities_during_a_sporting_event.html">2262 andrew gelman stats-2014-03-23-Win probabilities during a sporting event</a></p>
<p>Introduction: Todd Schneider writes: 
   
 
 Apropos of your recent  blog post about modeling score differential of basketball games , I thought you might enjoy a site I built, gambletron2000.com , that gathers real-time win probabilities from betting markets for most major sports (including NBA and college basketball). 
  
 My original goal was to use the variance of changes in win probabilities to quantify which games were the most exciting, but I got a bit carried away and ended up pursuing a bunch of other ideas, whichÂ  you can read about in the full writeup here  
  
 This particular passage from the anonymous someone in your post: 
  

My idea is for each timestep in a game (a second, 5 seconds, etc), use the Vegas line, the current score differential, who has the ball, and the number of possessions played already (to account for differences in pace) to create a point estimate probability of the home team winning.

  
 reminded me of a graph I made, which shows the mean-reverting tendency of N</p><p>6 0.7068181 <a title="2226-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-16-Wanted%3A__Probability_distributions_for_rank_orderings.html">151 andrew gelman stats-2010-07-16-Wanted:  Probability distributions for rank orderings</a></p>
<p>7 0.68886882 <a title="2226-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-27-Why_can%E2%80%99t_I_be_more_like_Bill_James%2C_or%2C_The_use_of_default_and_default-like_models.html">541 andrew gelman stats-2011-01-27-Why can’t I be more like Bill James, or, The use of default and default-like models</a></p>
<p>8 0.68148661 <a title="2226-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-30-Nooooooooooooooooooo%21.html">934 andrew gelman stats-2011-09-30-Nooooooooooooooooooo!</a></p>
<p>9 0.66890538 <a title="2226-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-30-Silly_baseball_example_illustrates_a_couple_of_key_ideas_they_don%E2%80%99t_usually_teach_you_in_statistics_class.html">171 andrew gelman stats-2010-07-30-Silly baseball example illustrates a couple of key ideas they don’t usually teach you in statistics class</a></p>
<p>10 0.65953881 <a title="2226-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Modeling_probability_data.html">1284 andrew gelman stats-2012-04-26-Modeling probability data</a></p>
<p>11 0.64549941 <a title="2226-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-03-Some_thoughts_on_election_forecasting.html">391 andrew gelman stats-2010-11-03-Some thoughts on election forecasting</a></p>
<p>12 0.64042914 <a title="2226-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-12-Probability_of_successive_wins_in_baseball.html">29 andrew gelman stats-2010-05-12-Probability of successive wins in baseball</a></p>
<p>13 0.63792437 <a title="2226-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-04-45%25_hitting%2C_25%25_fielding%2C_25%25_pitching%2C_and_100%25_not_telling_us_how_they_did_it.html">942 andrew gelman stats-2011-10-04-45% hitting, 25% fielding, 25% pitching, and 100% not telling us how they did it</a></p>
<p>14 0.63116193 <a title="2226-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-21-Baseball%E2%80%99s_greatest_fielders.html">623 andrew gelman stats-2011-03-21-Baseball’s greatest fielders</a></p>
<p>15 0.63053 <a title="2226-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-19-The_%E2%80%9Ceither-or%E2%80%9D_fallacy_of_believing_in_discrete_models%3A__an_example_of_folk_statistics.html">217 andrew gelman stats-2010-08-19-The “either-or” fallacy of believing in discrete models:  an example of folk statistics</a></p>
<p>16 0.62524545 <a title="2226-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Cross-validation_%28What_is_it_good_for%3F%29.html">1395 andrew gelman stats-2012-06-27-Cross-validation (What is it good for?)</a></p>
<p>17 0.62448949 <a title="2226-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-22-Is_it_meaningful_to_talk_about_a_probability_of_%E2%80%9C65.7%25%E2%80%9D_that_Obama_will_win_the_election%3F.html">1544 andrew gelman stats-2012-10-22-Is it meaningful to talk about a probability of “65.7%” that Obama will win the election?</a></p>
<p>18 0.62272322 <a title="2226-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-29-Putting_together_multinomial_discrete_regressions_by_combining_simple_logits.html">782 andrew gelman stats-2011-06-29-Putting together multinomial discrete regressions by combining simple logits</a></p>
<p>19 0.61065298 <a title="2226-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-15-Of_forecasts_and_graph_theory_and_characterizing_a_statistical_method_by_the_information_it_uses.html">1214 andrew gelman stats-2012-03-15-Of forecasts and graph theory and characterizing a statistical method by the information it uses</a></p>
<p>20 0.60728663 <a title="2226-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-Displaying_a_fitted_multilevel_model.html">328 andrew gelman stats-2010-10-08-Displaying a fitted multilevel model</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.11), (15, 0.025), (16, 0.058), (24, 0.092), (27, 0.018), (36, 0.037), (41, 0.098), (59, 0.013), (86, 0.082), (94, 0.032), (99, 0.316)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96671337 <a title="2226-lda-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-26-Econometrics%2C_political_science%2C_epidemiology%2C_etc.%3A__Don%E2%80%99t_model_the_probability_of_a_discrete_outcome%2C_model_the_underlying_continuous_variable.html">2226 andrew gelman stats-2014-02-26-Econometrics, political science, epidemiology, etc.:  Don’t model the probability of a discrete outcome, model the underlying continuous variable</a></p>
<p>Introduction: This is an echo of yesterday’s post,  Basketball Stats: Don’t model the probability of win, model the expected score differential .
 
As with basketball, so with baseball:  as the great Bill James wrote, if you want to predict a pitcher’s win-loss record, it’s better to use last year’s ERA than last year’s W-L.
 
As with basketball and baseball, so with epidemiology:  as Joseph Delaney  points out  in my favorite blog that nobody reads, you will see much better prediction if you first model change in the parameter (e.g. blood pressure) and then convert that to the binary disease state (e.g. hypertension) then if you just develop a logistic model for prob(hypertension).
 
As with basketball, baseball, and epidemiology, so with political science:  instead of modeling election winners, better to model vote differential, a point that I made back in 1993 (see page 120  here ) but which seems to continually need  repeating .  A forecasting method should get essentially no credit for correctl</p><p>2 0.9408015 <a title="2226-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-12-Probability_of_successive_wins_in_baseball.html">29 andrew gelman stats-2010-05-12-Probability of successive wins in baseball</a></p>
<p>Introduction: Dan Goldstein did an  informal study  asking people the following question:
  
When two baseball teams play each other on two consecutive days, what is the probability that the winner of the first game will be the winner of the second game?
  
You can make your own guess and the continue reading below.
    
Dan writes:
  
We asked two colleagues knowledgeable in baseball and the mathematics of forecasting. The answers came in between 65% and 70%.






The true answer [based on Dan's analysis of a database of baseball games]: 51.3%, a little better than a coin toss.
  
I have to say, I’m surprised his colleagues gave such extreme guesses.  I was guessing something like 50%, myself, based on the following very crude reasoning:
 
Suppose two unequal teams are playing, and the chance of team A beating team B is 55%.  (This seems like a reasonable average of all matchups, which will include some more extreme disparities but also many more equal contests.)  Then the chance of the same team</p><p>3 0.93498677 <a title="2226-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-07-Diabetes_stops_at_the_state_line%3F.html">454 andrew gelman stats-2010-12-07-Diabetes stops at the state line?</a></p>
<p>Introduction: From  Discover :
 
 
 
 Razib Khan  asks:
  
But follow the gradient from El Paso to the Illinois-Missouri border. The differences are small across state lines, but the consistent differences along the borders really don’t make. Are there state-level policies or regulations causing this? Or, are there state-level differences in measurement? This weird pattern shows up in other CDC data I’ve seen.

  
Turns out that CDC isn’t providing  data , they’re providing  model . Frank Howland answered: 
  

I suspect the answer has to do with the manner in which the county estimates are produced. I went to the original data source, the CDC, and then to the  relevant FAQ .


There they say that the diabetes prevalence estimates come from the “CDC’s Behavioral Risk Factor Surveillance System (BRFSS) and data from the U.S. Census Bureau’s Population Estimates Program. The BRFSS is an ongoing, monthly, state-based telephone survey of the adult population. The survey provides state-specific informati</p><p>4 0.93446702 <a title="2226-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-Difficulties_with_the_1-4-power_transformation.html">1142 andrew gelman stats-2012-01-29-Difficulties with the 1-4-power transformation</a></p>
<p>Introduction: John Hayes writes:
  
I am a fan of the quarter root transform ever since reading about it on your  blog .  However, today my student and I hit a wall that I’m hoping you might have some insight on.


By training, I am a psychophysicist (think SS Stevens), and people in my field often log transform data prior to analysis. However, this data frequently contains zeros, so I’ve tried using quarter root transforms to get around this. But until today, I had never tried to back transform the plot axis for readability. I assumed this would be straightforward – alas it is not.


Specifically, we quarter root transformed our data, performed an ANOVA, got what we thought was a reasonable effect, and then plotted the data. So far so good. However, the LS means in question are below 1, meaning that raising them to the 4th power just makes them smaller, and uninterpretable in the original metric.


Do you have any thoughts or insights you might share?
  
My reply:
 
I don’t see the problem with pre</p><p>5 0.93354464 <a title="2226-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-31-Why_Edit_Wikipedia%3F.html">640 andrew gelman stats-2011-03-31-Why Edit Wikipedia?</a></p>
<p>Introduction: Zoe Corbyn’s article for  The Guardian  (UK), titled  Wikipedia wants more contributions from academics , and the followup  discussion on Slashdot  got me thinking about my own Wikipedia edits.  
 
The article quotes Dario Taraborelli, a research analyst for the Wikimedia Foundation, as saying “Academics are trapped in this paradox of using Wikipedia but not contributing,”  Huh?  I’m really wondering what man-in-the-street wrote all the great stats stuff out there.  And what’s the paradox?  I use lots of things without contributing to them.  
 
Taraborelli is further quoted as saying “The Wikimedia Foundation is looking at how it might capture expert conversation about Wikipedia content happening on other websites and feed it back to the community as a way of providing pointers for improvement.”
 
This struck home.  I recently went through the entry for  latent Dirichlet allocation  and found a bug in their derivation.  I wrote up a revised derivation and  posted it on my own blog .</p><p>6 0.93290454 <a title="2226-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-21-Exponential_increase_in_the_number_of_stat_majors.html">1816 andrew gelman stats-2013-04-21-Exponential increase in the number of stat majors</a></p>
<p>7 0.9327994 <a title="2226-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-10-Jobs_in_statistics_research%21__In_New_Jersey%21.html">1110 andrew gelman stats-2012-01-10-Jobs in statistics research!  In New Jersey!</a></p>
<p>8 0.93145621 <a title="2226-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-22-Story_time_meets_the_all-else-equal_fallacy_and_the_fallacy_of_measurement.html">1226 andrew gelman stats-2012-03-22-Story time meets the all-else-equal fallacy and the fallacy of measurement</a></p>
<p>9 0.93044221 <a title="2226-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-29-Postdocs_in_probabilistic_modeling%21__With_David_Blei%21__And_Stan%21.html">1961 andrew gelman stats-2013-07-29-Postdocs in probabilistic modeling!  With David Blei!  And Stan!</a></p>
<p>10 0.92962396 <a title="2226-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-06-Why_it_can_be_rational_to_vote.html">1565 andrew gelman stats-2012-11-06-Why it can be rational to vote</a></p>
<p>11 0.92961895 <a title="2226-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-01-Why_it_can_be_rational_to_vote.html">389 andrew gelman stats-2010-11-01-Why it can be rational to vote</a></p>
<p>12 0.92765158 <a title="2226-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-14-A_new_idea_for_a_science_core_course_based_entirely_on_computer_simulation.html">516 andrew gelman stats-2011-01-14-A new idea for a science core course based entirely on computer simulation</a></p>
<p>13 0.9268145 <a title="2226-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-13-A_departmental_wiki_page%3F.html">571 andrew gelman stats-2011-02-13-A departmental wiki page?</a></p>
<p>14 0.92601871 <a title="2226-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-22-Question_12_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1337 andrew gelman stats-2012-05-22-Question 12 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>15 0.92431784 <a title="2226-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-09-Thomas_Hobbes_would_be_spinning_in_his_grave.html">1715 andrew gelman stats-2013-02-09-Thomas Hobbes would be spinning in his grave</a></p>
<p>16 0.92405611 <a title="2226-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-13-Duke_postdoctoral_fellowships_in_nonparametric_Bayes_%26_high-dimensional_data.html">903 andrew gelman stats-2011-09-13-Duke postdoctoral fellowships in nonparametric Bayes & high-dimensional data</a></p>
<p>17 0.92119205 <a title="2226-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-12-The_power_of_the_puzzlegraph.html">1669 andrew gelman stats-2013-01-12-The power of the puzzlegraph</a></p>
<p>18 0.92060018 <a title="2226-lda-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-22-Postdoc_at_Rennes_on_multilevel_missing_data_imputation.html">2260 andrew gelman stats-2014-03-22-Postdoc at Rennes on multilevel missing data imputation</a></p>
<p>19 0.91992337 <a title="2226-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-14-Wickham_R_short_course.html">1009 andrew gelman stats-2011-11-14-Wickham R short course</a></p>
<p>20 0.91863966 <a title="2226-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
