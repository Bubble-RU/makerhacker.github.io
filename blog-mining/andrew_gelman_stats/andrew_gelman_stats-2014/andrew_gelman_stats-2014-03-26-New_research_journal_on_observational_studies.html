<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2268 andrew gelman stats-2014-03-26-New research journal on observational studies</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2014" href="../home/andrew_gelman_stats-2014_home.html">andrew_gelman_stats-2014</a> <a title="andrew_gelman_stats-2014-2268" href="#">andrew_gelman_stats-2014-2268</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2268 andrew gelman stats-2014-03-26-New research journal on observational studies</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2014-2268-html" href="http://andrewgelman.com/2014/03/26/new-research-journal-observational-studies/">html</a></p><p>Introduction: Dylan Small writes:
  
I am starting an  observational studies journal  that aims to publish papers on all aspects of observational studies, including study protocols for observational studies, methodologies for observational studies, descriptions of data sets for observational studies, software for observational studies and analyses of observational studies.  One of the goals of the journal is to promote the planning of observational studies and to publish study plans for observational studies, like study plans are published for major clinical trials.
  
Regular readers will know my suggestion that scientific journals move away from the idea of being unique publishers of new material and move toward a “newsletter” approach, recommending papers from Arxiv, SSRN, etc.  So, instead of going through exhausting review and revision processes, the journal editors would read and review recent preprints on observational studies and then, each month or quarter or whatever, produce a list of pap</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 One of the goals of the journal is to promote the planning of observational studies and to publish study plans for observational studies, like study plans are published for major clinical trials. [sent-2, score-2.824]
</p><p>2 Regular readers will know my suggestion that scientific journals move away from the idea of being unique publishers of new material and move toward a “newsletter” approach, recommending papers from Arxiv, SSRN, etc. [sent-3, score-0.661]
</p><p>3 So, instead of going through exhausting review and revision processes, the journal editors would read and review recent preprints on observational studies and then, each month or quarter or whatever, produce a list of papers they recommend. [sent-4, score-2.138]
</p><p>4 That said, given that Dylan and his co-editors are going the conventional route, I like how they’re doing it. [sent-5, score-0.112]
</p><p>5 In particular, “The journal is open access and has no publication charges. [sent-6, score-0.245]
</p><p>6 Indeed, our  most recent post  discussed an (informal) observational study about basketball. [sent-9, score-0.905]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('observational', 0.73), ('studies', 0.366), ('dylan', 0.177), ('plans', 0.141), ('journal', 0.138), ('study', 0.12), ('papers', 0.109), ('preprints', 0.101), ('ssrn', 0.097), ('newsletter', 0.097), ('methodologies', 0.093), ('publish', 0.092), ('exhausting', 0.091), ('move', 0.09), ('protocols', 0.085), ('revision', 0.085), ('recommending', 0.082), ('descriptions', 0.08), ('review', 0.08), ('aims', 0.078), ('quarter', 0.078), ('route', 0.077), ('publishers', 0.076), ('basketball', 0.073), ('promote', 0.072), ('arxiv', 0.07), ('informal', 0.07), ('clinical', 0.061), ('planning', 0.06), ('processes', 0.06), ('access', 0.06), ('suggestion', 0.059), ('editors', 0.059), ('produce', 0.059), ('unique', 0.057), ('conventional', 0.057), ('recent', 0.055), ('going', 0.055), ('regular', 0.055), ('goals', 0.053), ('sets', 0.053), ('aspects', 0.052), ('month', 0.052), ('software', 0.052), ('starting', 0.05), ('journals', 0.049), ('material', 0.049), ('publication', 0.047), ('statement', 0.047), ('analyses', 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="2268-tfidf-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-26-New_research_journal_on_observational_studies.html">2268 andrew gelman stats-2014-03-26-New research journal on observational studies</a></p>
<p>Introduction: Dylan Small writes:
  
I am starting an  observational studies journal  that aims to publish papers on all aspects of observational studies, including study protocols for observational studies, methodologies for observational studies, descriptions of data sets for observational studies, software for observational studies and analyses of observational studies.  One of the goals of the journal is to promote the planning of observational studies and to publish study plans for observational studies, like study plans are published for major clinical trials.
  
Regular readers will know my suggestion that scientific journals move away from the idea of being unique publishers of new material and move toward a “newsletter” approach, recommending papers from Arxiv, SSRN, etc.  So, instead of going through exhausting review and revision processes, the journal editors would read and review recent preprints on observational studies and then, each month or quarter or whatever, produce a list of pap</p><p>2 0.17818524 <a title="2268-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-02-Experimental_reasoning_in_social_science.html">785 andrew gelman stats-2011-07-02-Experimental reasoning in social science</a></p>
<p>Introduction: As a statistician, I was trained to think of randomized experimentation as representing the gold standard of knowledge in the social sciences, and, despite having seen occasional arguments to the contrary, I still hold that view, expressed pithily by Box, Hunter, and Hunter (1978) that “To find out what happens when you change something, it is necessary to change it.”
 
At the same time, in my capacity as a social scientist, I’ve published many applied research papers, almost none of which have used experimental data.
 
In the present article, I’ll address the following questions:
 
1.  Why do I agree with the consensus characterization of randomized experimentation as a gold standard?
 
2.  Given point 1 above, why does almost all my research use observational data?
 
In confronting these issues, we must consider some general issues in the strategy of social science research. We also take from the psychology methods literature a more nuanced perspective that considers several differen</p><p>3 0.1712938 <a title="2268-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>Introduction: This seems to be the topic of the week.  Yesterday I posted on the sister blog  some further thoughts  on those “Psychological Science” papers on menstrual cycles, biceps size, and political attitudes, tied to a horrible press release from the journal Psychological Science hyping the biceps and politics study.
 
Then I was pointed to these  suggestions  from Richard Lucas and M. Brent Donnellan have on improving the replicability and reproducibility of research published in the Journal of Research in Personality:
  
It goes without saying that editors of scientific journals strive to publish research that is not only theoretically interesting but also methodologically rigorous. The goal is to select papers that advance the field. Accordingly, editors want to publish findings that can be reproduced and replicated by other scientists. Unfortunately, there has been a recent “crisis in confidence” among psychologists about the quality of psychological research (Pashler & Wagenmakers, 2012)</p><p>4 0.15763602 <a title="2268-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-12-As_a_Bayesian_I_want_scientists_to_report_their_data_non-Bayesianly.html">1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</a></p>
<p>Introduction: Philipp Doebler writes: 
  
  
I was quite happy that recently you shared some thoughts of yours and others on meta-analysis. I especially liked the  slides by Chris Schmid  that you linked from your blog. A large portion of my work deals with meta-analysis and I am also fond of using Bayesian methods (actually two of the projects I am working on are very Bayesian), though I can not say I have opinions with respect to the underlying philosophy. I would say though, that I do share your view that there are good reasons to use informative priors.


The reason I am writing to you is that this leads to the following dilemma, which is puzzling me. Say a number of scientists conduct similar studies over the years and all of them did this in a Bayesian fashion. If each of the groups used informative priors based on the research of existing groups the priors could become more and more informative over the years, since more and more is known over the subject. At least in smallish studies these p</p><p>5 0.15178926 <a title="2268-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-All_inference_is_about_generalizing_from_sample_to_population.html">1996 andrew gelman stats-2013-08-24-All inference is about generalizing from sample to population</a></p>
<p>Introduction: Jeff Walker writes:
  
Your blog has skirted around the value of observational studies and chided folks for using causal language when they only have associations but I sense that you ultimately find value in these associations. I would love for you to expand this thought in a blog. Specifically:


Does a measured association “suggest” a causal relationship? Are measured associations a good and efficient way to narrow the field of things that should be studied? Of all the things we should pursue, should we start with the stuff that has some largish measured association? Certainly many associations are not directly causal but due to joint association. Similarly, there must be many variables that are directly causally associated ( A -> B) but the effect, measured as an association, is masked by confounders. So if we took the “measured associations are worthwhile” approach, we’d never or rarely find the masked effects. But I’d also like to know if one is more likely to find a large causal</p><p>6 0.13998936 <a title="2268-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-13-Preregistration_of_Studies_and_Mock_Reports.html">1671 andrew gelman stats-2013-01-13-Preregistration of Studies and Mock Reports</a></p>
<p>7 0.13671082 <a title="2268-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>8 0.13387905 <a title="2268-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-13-Randomized_experiments%2C_non-randomized_experiments%2C_and_observational_studies.html">340 andrew gelman stats-2010-10-13-Randomized experiments, non-randomized experiments, and observational studies</a></p>
<p>9 0.12261765 <a title="2268-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>10 0.12145786 <a title="2268-tfidf-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-12-More_on_publishing_in_journals.html">2245 andrew gelman stats-2014-03-12-More on publishing in journals</a></p>
<p>11 0.11309974 <a title="2268-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-10-Christakis-Fowler_update.html">756 andrew gelman stats-2011-06-10-Christakis-Fowler update</a></p>
<p>12 0.11288883 <a title="2268-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-23-Christakis_response_to_my_comment_on_his_comments_on_social_science_%28or_just_skip_to_the_P.P.P.S._at_the_end%29.html">1952 andrew gelman stats-2013-07-23-Christakis response to my comment on his comments on social science (or just skip to the P.P.P.S. at the end)</a></p>
<p>13 0.11153118 <a title="2268-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-06-How_to_think_about_papers_published_in_low-grade_journals%3F.html">1928 andrew gelman stats-2013-07-06-How to think about papers published in low-grade journals?</a></p>
<p>14 0.1106545 <a title="2268-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-18-A_lot_of_statistical_methods_have_this_flavor%2C_that_they_are_a_solution_to_a_mathematical_problem_that_has_been_posed_without_a_careful_enough_sense_of_whether_the_problem_is_worth_solving_in_the_first_place.html">1987 andrew gelman stats-2013-08-18-A lot of statistical methods have this flavor, that they are a solution to a mathematical problem that has been posed without a careful enough sense of whether the problem is worth solving in the first place</a></p>
<p>15 0.10820887 <a title="2268-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-The_scope_for_snooping.html">1070 andrew gelman stats-2011-12-19-The scope for snooping</a></p>
<p>16 0.10405768 <a title="2268-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-30-Systematic_review_of_publication_bias_in_studies_on_publication_bias.html">1291 andrew gelman stats-2012-04-30-Systematic review of publication bias in studies on publication bias</a></p>
<p>17 0.10319577 <a title="2268-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-26-%E2%80%9CPlease_make_fun_of_this_claim%E2%80%9D.html">2114 andrew gelman stats-2013-11-26-“Please make fun of this claim”</a></p>
<p>18 0.10073925 <a title="2268-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-14-Detecting_predictability_in_complex_ecosystems.html">1802 andrew gelman stats-2013-04-14-Detecting predictability in complex ecosystems</a></p>
<p>19 0.10018904 <a title="2268-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-30-Adjudicating_between_alternative_interpretations_of_a_statistical_interaction%3F.html">2274 andrew gelman stats-2014-03-30-Adjudicating between alternative interpretations of a statistical interaction?</a></p>
<p>20 0.099463418 <a title="2268-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-My_talk_at_the_University_of_Michigan_today_4pm.html">1778 andrew gelman stats-2013-03-27-My talk at the University of Michigan today 4pm</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.105), (1, -0.034), (2, -0.053), (3, -0.155), (4, -0.048), (5, -0.045), (6, -0.019), (7, -0.076), (8, -0.053), (9, 0.011), (10, 0.073), (11, 0.029), (12, -0.001), (13, 0.01), (14, 0.017), (15, -0.013), (16, 0.012), (17, 0.017), (18, -0.03), (19, 0.018), (20, -0.013), (21, 0.013), (22, 0.013), (23, 0.031), (24, 0.013), (25, 0.079), (26, 0.022), (27, -0.01), (28, 0.014), (29, -0.006), (30, -0.068), (31, -0.095), (32, 0.005), (33, 0.011), (34, -0.02), (35, 0.062), (36, -0.007), (37, 0.024), (38, 0.007), (39, 0.034), (40, 0.006), (41, 0.007), (42, 0.025), (43, 0.03), (44, 0.029), (45, -0.024), (46, 0.004), (47, 0.047), (48, -0.023), (49, -0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99120033 <a title="2268-lsi-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-26-New_research_journal_on_observational_studies.html">2268 andrew gelman stats-2014-03-26-New research journal on observational studies</a></p>
<p>Introduction: Dylan Small writes:
  
I am starting an  observational studies journal  that aims to publish papers on all aspects of observational studies, including study protocols for observational studies, methodologies for observational studies, descriptions of data sets for observational studies, software for observational studies and analyses of observational studies.  One of the goals of the journal is to promote the planning of observational studies and to publish study plans for observational studies, like study plans are published for major clinical trials.
  
Regular readers will know my suggestion that scientific journals move away from the idea of being unique publishers of new material and move toward a “newsletter” approach, recommending papers from Arxiv, SSRN, etc.  So, instead of going through exhausting review and revision processes, the journal editors would read and review recent preprints on observational studies and then, each month or quarter or whatever, produce a list of pap</p><p>2 0.8188861 <a title="2268-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-13-Preregistration_of_Studies_and_Mock_Reports.html">1671 andrew gelman stats-2013-01-13-Preregistration of Studies and Mock Reports</a></p>
<p>Introduction: The traditional system of scientific and scholarly publishing is breaking down in two different directions.
 
On one hand, we are moving away from relying on a small set of journals as gatekeepers: the number of papers and research projects is increasing, the number of publication outlets is increasing, and important manuscripts are being posted on SSRN, Arxiv, and other nonrefereed sites.
 
At the same time, many researchers are worried about the profusion of published claims that turn out to not replicate or in plain language, to be false. This concern is not new–some prominent discussions include Rosenthal (1979), Ioannidis (2005), and Vul et al. (2009)–but there is a growing sense that the scientific signal is being swamped by noise.
 
I recently had the opportunity to comment in the journal Political Analysis on two papers, one by Humphreys, Sierra, and Windt, and one by Monogan, on the preregistration of studies and mock reports.   Here’s  the issue of the journal.
 
Given the hi</p><p>3 0.81505173 <a title="2268-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-30-Systematic_review_of_publication_bias_in_studies_on_publication_bias.html">1291 andrew gelman stats-2012-04-30-Systematic review of publication bias in studies on publication bias</a></p>
<p>Introduction: Via  Yalda Afshar ,  a 2005 paper  by Hans-Hermann Dubben and Hans-Peter Beck-Bornholdt:
  
Publication bias is a well known phenomenon in clinical literature, in which positive results have a better chance of being published, are published earlier, and are published in journals with higher impact factors. Conclusions exclusively based on published studies, therefore, can be misleading. Selective under-reporting of research might be more widespread and more likely to have adverse consequences for patients than publication of deliberately falsified data. We investigated whether there is preferential publication of positive papers on publication bias.
  
They conclude, “We found no evidence of publication bias in reports on publication bias.”  But of course that’s the sort of finding regarding publication bias of findings on publication bias that you’d expect would get published.  What we really need is a careful meta-analysis to estimate the level of publication bias in studies of publi</p><p>4 0.8145923 <a title="2268-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>Introduction: Dan Kahan  writes :
  
The basic idea . . . is to promote identification of study designs that scholars who disagree about a proposition would agree would generate evidence relevant to their competing conjectures—regardless of what studies based on such designs actually find. Articles proposing designs of this sort would be selected for publication and only then be carried out, by the proposing researchers with funding from the journal, which would publish the results too.


Now I [Kahan] am aware of a set of real journals that have a similar motivation.


One is the  Journal of Articles in Support of the Null Hypothesis, which as its title implies publishes papers reporting studies that fail to “reject” the null. Like JASNH, LR ≠1J would try to offset the “file drawer” bias and like bad consequences associated with the convention of publishing only findings that are “significant at p < 0.05."


But it would try to do more. By publishing studies that are deemed to have valid designs an</p><p>5 0.7715627 <a title="2268-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-16-%E2%80%9CGroundbreaking_or_Definitive%3F_Journals_Need_to_Pick_One%E2%80%9D.html">1122 andrew gelman stats-2012-01-16-“Groundbreaking or Definitive? Journals Need to Pick One”</a></p>
<p>Introduction: Sanjay Srivastava  writes :
  
As long as a journal pursues a strategy of publishing “wow” studies, it will inevitably contain more unreplicable findings and unsupportable conclusions than equally rigorous but more “boring” journals. Groundbreaking will always be higher-risk. And definitive will be the territory of journals that publish meta-analyses and reviews. . . .


Most conclusions, even those in peer-reviewed papers in rigorous journals, should be regarded as tentative at best; but press releases and other public communication rarely convey that. . . .
  
His message to all of us:
  
Our standard response to a paper in Science, Nature, or Psychological Science should be “wow, that’ll be really interesting if it replicates.” And in our teaching and our engagement with the press and public, we need to make clear why that is the most enthusiastic response we can justify.</p><p>6 0.75063872 <a title="2268-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>7 0.73289526 <a title="2268-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-15-A_statistical_research_project%3A__Weeding_out_the_fraudulent_citations.html">1321 andrew gelman stats-2012-05-15-A statistical research project:  Weeding out the fraudulent citations</a></p>
<p>8 0.72372544 <a title="2268-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-13-Data_sharing_update.html">1055 andrew gelman stats-2011-12-13-Data sharing update</a></p>
<p>9 0.70966136 <a title="2268-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-24-Too_Good_To_Be_True%3A__The_Scientific_Mass_Production_of_Spurious_Statistical_Significance.html">1954 andrew gelman stats-2013-07-24-Too Good To Be True:  The Scientific Mass Production of Spurious Statistical Significance</a></p>
<p>10 0.70734239 <a title="2268-lsi-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-01-Association_for_Psychological_Science_announces_a_new_journal.html">2278 andrew gelman stats-2014-04-01-Association for Psychological Science announces a new journal</a></p>
<p>11 0.701949 <a title="2268-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-14-Type_M_errors_in_the_lab.html">908 andrew gelman stats-2011-09-14-Type M errors in the lab</a></p>
<p>12 0.69040519 <a title="2268-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>13 0.68999565 <a title="2268-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-24-Difficulties_in_publishing_non-replications_of_implausible_findings.html">1137 andrew gelman stats-2012-01-24-Difficulties in publishing non-replications of implausible findings</a></p>
<p>14 0.68806767 <a title="2268-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-14-A_model_rejection_letter.html">1118 andrew gelman stats-2012-01-14-A model rejection letter</a></p>
<p>15 0.68151802 <a title="2268-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-01-I_owe_it_all_to_the_haters.html">834 andrew gelman stats-2011-08-01-I owe it all to the haters</a></p>
<p>16 0.68039316 <a title="2268-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>17 0.68008113 <a title="2268-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>18 0.67923582 <a title="2268-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<p>19 0.67384732 <a title="2268-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-13-How_should_journals_handle_replication_studies%3F.html">762 andrew gelman stats-2011-06-13-How should journals handle replication studies?</a></p>
<p>20 0.6706562 <a title="2268-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-06-How_to_think_about_papers_published_in_low-grade_journals%3F.html">1928 andrew gelman stats-2013-07-06-How to think about papers published in low-grade journals?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.013), (9, 0.052), (10, 0.022), (15, 0.139), (16, 0.045), (24, 0.057), (41, 0.013), (47, 0.014), (52, 0.04), (69, 0.028), (76, 0.024), (95, 0.013), (99, 0.408)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98948669 <a title="2268-lda-1" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-26-New_research_journal_on_observational_studies.html">2268 andrew gelman stats-2014-03-26-New research journal on observational studies</a></p>
<p>Introduction: Dylan Small writes:
  
I am starting an  observational studies journal  that aims to publish papers on all aspects of observational studies, including study protocols for observational studies, methodologies for observational studies, descriptions of data sets for observational studies, software for observational studies and analyses of observational studies.  One of the goals of the journal is to promote the planning of observational studies and to publish study plans for observational studies, like study plans are published for major clinical trials.
  
Regular readers will know my suggestion that scientific journals move away from the idea of being unique publishers of new material and move toward a “newsletter” approach, recommending papers from Arxiv, SSRN, etc.  So, instead of going through exhausting review and revision processes, the journal editors would read and review recent preprints on observational studies and then, each month or quarter or whatever, produce a list of pap</p><p>2 0.9771927 <a title="2268-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-17-Wanted%3A__365_stories_of_statistics.html">1678 andrew gelman stats-2013-01-17-Wanted:  365 stories of statistics</a></p>
<p>Introduction: The American Statistical Association has a blog called the Statistics Forum that I edit but haven’t been doing much with.  Originally I thought we’d get a bunch of bloggers and have a topic each week or each month and get discussions from lots of perspectives.  But it was hard to get people to keep contributing, and the blog+comments approach didn’t seem to be working as a way to get wide-ranging discussion.  I did organize a good  roundtable discussion  at one point, but it took a lot of work on my part.
 
Recently I had another idea for the blog, based on something that Kaiser Fung wrote on  three hours in the life of a statistician , along with a similar (if a bit more impressionistic)  piece  I wrote awhile back describing my experiences on a typical workday.
 
So here’s the plan.  365 of you write vignettes about your statistical lives.  Get into the nitty gritty—tell me what you do, and why you’re doing it.  I’ll collect these and then post them at the Statistics Forum, one a day</p><p>3 0.97289306 <a title="2268-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-30-%E2%80%9CTragedy_of_the_science-communication_commons%E2%80%9D.html">1833 andrew gelman stats-2013-04-30-“Tragedy of the science-communication commons”</a></p>
<p>Introduction: I’ve earlier written that  science is science communication —that is, the act of communicating scientific ideas and findings to ourselves and others is itself a central part of science.  My point was to push against a conventional separation between the act of science and the act of communication, the idea that science is done by scientists and communication is done by communicators.  It’s a rare bit of science that does not include communication as part of it.  As a scientist and science communicator myself, I’m particularly sensitive to devaluing of communication.  (For example, Bayesian Data Analysis is full of original research that was done in order to communicate; or, to put it another way, we often think we understand a scientific idea, but once we try to communicate it, we recognize gaps in our understanding that motivate further research.)
 
I once saw the following on one of those inspirational-sayings-for-every-day desk calendars: “To have ideas is to gather flowers. To thin</p><p>4 0.97264415 <a title="2268-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<p>Introduction: The other day I was talking with someone who knows Daryl Bem a bit, and he was sharing his thoughts on that  notorious  ESP paper that was published in a leading journal in the field but then was mocked, shot down, and was repeatedly replicated with no success.  My friend said that overall the Bem paper had positive effects in forcing psychologists to think more carefully about what sorts of research results should or should not be published in top journals, the role of replications, and other things.
 
I expressed agreement and shared my thought that, at some level, I don’t think Bem himself fully believes his ESP effects are real.  Why do I say this?  Because he seemed oddly content to publish results that were not quite conclusive.  He ran a bunch of experiments, looked at the data, and computed some post-hoc p-values in the .01 to .05 range.  If he really were confident that the phenomenon was real (that is, that the results would apply to new data), then he could’ve easily run the</p><p>5 0.96961898 <a title="2268-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-20-%E2%80%9CSix_red_flags_for_suspect_work%E2%80%9D.html">2032 andrew gelman stats-2013-09-20-“Six red flags for suspect work”</a></p>
<p>Introduction: Raghu Parthasarathy sends along  this article  by C. Glenn Begley listing six questions to ask when worried about unreplicable work in biology:
  
Were experiments performed blinded?  (Even animal studies should be blinded when it comes to the recording and interpretation of the data—do you hear that, Mark Hauser?)


Were basic experiments repeated?  (“If reports fail to state that experiments were repeated, be sceptical.”)


Were all the results presented?  (That one’s a  biggie .)


Were there positive and negative controls?  (He offers some details from lab experiments.)


Were reagents validated?  (Whatever.)


Were statistical tests appropriate?  (I don’t like the idea of statistical “tests” at all, but I agree with his general point.)</p><p>6 0.9682529 <a title="2268-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-20-Reconciling_different_claims_about_working-class_voters.html">1385 andrew gelman stats-2012-06-20-Reconciling different claims about working-class voters</a></p>
<p>7 0.96656704 <a title="2268-lda-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-13-Postdoc_with_Liz_Stuart_on_propensity_score_methods_when_the_covariates_are_measured_with_error.html">2171 andrew gelman stats-2014-01-13-Postdoc with Liz Stuart on propensity score methods when the covariates are measured with error</a></p>
<p>8 0.96653086 <a title="2268-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-09-False_memories_and_statistical_analysis.html">2014 andrew gelman stats-2013-09-09-False memories and statistical analysis</a></p>
<p>9 0.96571565 <a title="2268-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-15-New_prize_on_causality_in_statstistics_education.html">1624 andrew gelman stats-2012-12-15-New prize on causality in statstistics education</a></p>
<p>10 0.96393174 <a title="2268-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-The_reverse-journal-submission_system.html">1393 andrew gelman stats-2012-06-26-The reverse-journal-submission system</a></p>
<p>11 0.96370983 <a title="2268-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-14-Battle_of_the_Americans%3A__Writer_at_the_American_Enterprise_Institute_disparages_the_American_Political_Science_Association.html">274 andrew gelman stats-2010-09-14-Battle of the Americans:  Writer at the American Enterprise Institute disparages the American Political Science Association</a></p>
<p>12 0.96237153 <a title="2268-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-04-Retraction_Watch.html">838 andrew gelman stats-2011-08-04-Retraction Watch</a></p>
<p>13 0.96120626 <a title="2268-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-21-Interpreting_interactions_in_discrete-data_regression.html">1908 andrew gelman stats-2013-06-21-Interpreting interactions in discrete-data regression</a></p>
<p>14 0.96033084 <a title="2268-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-23-Larry_Wasserman%E2%80%99s_statistics_blog.html">1389 andrew gelman stats-2012-06-23-Larry Wasserman’s statistics blog</a></p>
<p>15 0.95920163 <a title="2268-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-02-%E2%80%9CBased_on_my_experiences%2C_I_think_you_could_make_general_progress_by_constructing_a_solution_to_your_specific_problem.%E2%80%9D.html">1441 andrew gelman stats-2012-08-02-“Based on my experiences, I think you could make general progress by constructing a solution to your specific problem.”</a></p>
<p>16 0.95753789 <a title="2268-lda-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>17 0.95613861 <a title="2268-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-05-What_predicts_whether_a_school_district_will_participate_in_a_large-scale_evaluation%3F.html">2125 andrew gelman stats-2013-12-05-What predicts whether a school district will participate in a large-scale evaluation?</a></p>
<p>18 0.95612991 <a title="2268-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-More_proposals_to_reform_the_peer-review_system.html">1272 andrew gelman stats-2012-04-20-More proposals to reform the peer-review system</a></p>
<p>19 0.95610482 <a title="2268-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-29-%E2%80%9CQuestioning_The_Lancet%2C_PLOS%2C_And_Other_Surveys_On_Iraqi_Deaths%2C_An_Interview_With_Univ._of_London_Professor_Michael_Spagat%E2%80%9D.html">2191 andrew gelman stats-2014-01-29-“Questioning The Lancet, PLOS, And Other Surveys On Iraqi Deaths, An Interview With Univ. of London Professor Michael Spagat”</a></p>
<p>20 0.95527041 <a title="2268-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Cross-validation_%28What_is_it_good_for%3F%29.html">1395 andrew gelman stats-2012-06-27-Cross-validation (What is it good for?)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
