<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>3 andrew gelman stats-2010-04-26-Bayes in the news…in a somewhat frustrating way</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-3" href="#">andrew_gelman_stats-2010-3</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>3 andrew gelman stats-2010-04-26-Bayes in the news…in a somewhat frustrating way</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-3-html" href="http://andrewgelman.com/2010/04/26/bayes_in_the_ne/">html</a></p><p>Introduction: I’m not sure how the New York Times defines a blog versus an article, so perhaps this post should be called “Bayes in the blogs.”  Whatever.  A  recent NY Times article/blog post  discusses a classic Bayes’ Theorem application — probability that the patient has cancer, given a “positive” mammogram — and purports to give a solution that is easy for students to understand because it doesn’t require Bayes’ Theorem, which is of course complicated and confusing.  You can see  my comment (#17) here.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I’m not sure how the New York Times defines a blog versus an article, so perhaps this post should be called “Bayes in the blogs. [sent-1, score-0.918]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bayes', 0.419), ('theorem', 0.359), ('purports', 0.317), ('defines', 0.233), ('ny', 0.23), ('patient', 0.21), ('times', 0.203), ('versus', 0.184), ('cancer', 0.182), ('discusses', 0.171), ('post', 0.163), ('require', 0.162), ('complicated', 0.159), ('classic', 0.158), ('application', 0.154), ('solution', 0.143), ('york', 0.132), ('positive', 0.125), ('called', 0.113), ('easy', 0.111), ('comment', 0.107), ('students', 0.105), ('probability', 0.1), ('understand', 0.093), ('course', 0.09), ('give', 0.084), ('recent', 0.082), ('doesn', 0.08), ('perhaps', 0.08), ('given', 0.076), ('sure', 0.075), ('blog', 0.07), ('article', 0.062), ('new', 0.057), ('see', 0.042)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="3-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-26-Bayes_in_the_news%E2%80%A6in_a_somewhat_frustrating_way.html">3 andrew gelman stats-2010-04-26-Bayes in the news…in a somewhat frustrating way</a></p>
<p>Introduction: I’m not sure how the New York Times defines a blog versus an article, so perhaps this post should be called “Bayes in the blogs.”  Whatever.  A  recent NY Times article/blog post  discusses a classic Bayes’ Theorem application — probability that the patient has cancer, given a “positive” mammogram — and purports to give a solution that is easy for students to understand because it doesn’t require Bayes’ Theorem, which is of course complicated and confusing.  You can see  my comment (#17) here.</p><p>2 0.13437688 <a title="3-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-07-Environmentally_induced_cancer_%E2%80%9Cgrossly_underestimated%E2%80%9D%3F__Doubtful..html">21 andrew gelman stats-2010-05-07-Environmentally induced cancer “grossly underestimated”?  Doubtful.</a></p>
<p>Introduction: The (U.S.) “President’s Cancer Panel” has released its 2008-2009 annual report, which includes a cover letter that says “the true burden of environmentally induced cancer has been grossly underestimated.”  The report itself discusses exposures to various types of industrial chemicals, some of which are known carcinogens, in some detail, but gives nearly no data or analysis to suggest that these exposures are contributing to significant numbers of cancers.  In fact, there is pretty good evidence that they are not. 
 
 
  

 
The plot above shows age-adjusted cancer mortality for men, by cancer type, in the U.S.  The plot below shows the same for women.  In both cases, the cancers with the highest mortality rates are shown, but not all cancers (e.g. brain cancer is not shown).  For what it’s worth, I’m not sure how trustworthy the rates are from the 1930s — it seems possible that reporting, autopsies, or both, were less careful during the Great Depression — so I suggest focusing on the r</p><p>3 0.11435505 <a title="3-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-Another_reason_why_you_can_get_good_inferences_from_a_bad_model.html">1527 andrew gelman stats-2012-10-10-Another reason why you can get good inferences from a bad model</a></p>
<p>Introduction: John Cook  considers  how people justify probability distribution assumptions:
  
Sometimes distribution assumptions are not justified.


Sometimes distributions can be derived from fundamental principles [or] . . . on theoretical grounds. For example, large samples and the central limit theorem together may justify assuming that something is normally distributed.


Often the choice of distribution is somewhat arbitrary, chosen by intuition or for convenience, and then empirically shown to work well enough.


Sometimes a distribution can be a bad fit and still work well, depending on what you’re asking of it.
  
Cook continues:
  
The last point is particularly interesting. It’s not hard to imagine that a poor fit would produce poor results. It’s surprising when a poor fit produces good results.
  
And then he gives an example of an effective but inaccurate model used to model survival times in a clinical trial.  Cook explains:
  
The [poorly-fitting] method works well because of the q</p><p>4 0.11396686 <a title="3-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-10-Bayes_jumps_the_shark.html">331 andrew gelman stats-2010-10-10-Bayes jumps the shark</a></p>
<p>Introduction: John Goldin sends in this, from  an interview  with Alan Dershowitz:
  
 
Q:  The lawyerly obligation to not change your mind, to defend a position right or wrong–do you find that it seeps over into the rest of your life?





A:  No, it doesn’t because I’m a professor first, and as a professor I’m always changing my mind. I mean, my students go crazy in my class because I’m the most orthodox Bayesian in the world. [Bayesian probability theory is a way of modeling how the human mind reasons about the world. It assumes that people have prior beliefs about the probability of a given hypothesis and also beliefs about the probability that the hypothesis, if true, would generate the evidence they see. Taken together, these beliefs determine how people update their faith in a hypothesis in light of new evidence.] I do everything based on Bayes analysis, and Bayes analysis is always based on shifting probabilities and constantly changing and being adaptive and fluid.
 

 
Although, who am I t</p><p>5 0.11113585 <a title="3-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-19-Revised_evidence_for_statistical_standards.html">2140 andrew gelman stats-2013-12-19-Revised evidence for statistical standards</a></p>
<p>Introduction: X  and I heard about  this  much-publicized recent paper by Val Johnson, who suggests changing the default level of statistical significance from z=2 to z=3 (or, as he puts it, going from p=.05 to p=.005 or .001).  Val argues that you need to go out to 3 standard errors to get a Bayes factor of 25 or 50 in favor of the alternative hypothesis.  I don’t really buy this, first because Val’s model is a weird (to me) mixture of two point masses, which he creates in order to make a minimax argument, and second because I don’t see why you need a Bayes factor of 25 to 50 in order to make a claim.  I’d think that a factor of 5:1, say, provides strong information already—if you really believe those odds.  The real issue, as I see it, is that we’re getting Bayes factors and posterior probabilities we don’t believe, because we’re assuming flat priors that don’t really make sense.  This is a topic that’s come up over and over in recent months on this blog, for example in this discussion of why I  d</p><p>6 0.11077324 <a title="3-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-07-Feedback_on_my_Bayesian_Data_Analysis_class_at_Columbia.html">1611 andrew gelman stats-2012-12-07-Feedback on my Bayesian Data Analysis class at Columbia</a></p>
<p>7 0.1003086 <a title="3-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-03-Statistical_methods_that_work_in_some_settings_but_not_others.html">1560 andrew gelman stats-2012-11-03-Statistical methods that work in some settings but not others</a></p>
<p>8 0.098409645 <a title="3-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-04-The_Folk_Theorem_of_Statistical_Computing.html">1841 andrew gelman stats-2013-05-04-The Folk Theorem of Statistical Computing</a></p>
<p>9 0.098006122 <a title="3-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-R_package_for_Bayes_factors.html">1682 andrew gelman stats-2013-01-19-R package for Bayes factors</a></p>
<p>10 0.096621349 <a title="3-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-17-%E2%80%9CStop_and_frisk%E2%80%9D_statistics.html">1942 andrew gelman stats-2013-07-17-“Stop and frisk” statistics</a></p>
<p>11 0.096382149 <a title="3-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>12 0.095520601 <a title="3-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-08-Belief_aggregation.html">2162 andrew gelman stats-2014-01-08-Belief aggregation</a></p>
<p>13 0.091849811 <a title="3-tfidf-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-21-Random_matrices_in_the_news.html">2258 andrew gelman stats-2014-03-21-Random matrices in the news</a></p>
<p>14 0.091424808 <a title="3-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-16-Zero_Dark_Thirty_and_Bayes%E2%80%99_theorem.html">1724 andrew gelman stats-2013-02-16-Zero Dark Thirty and Bayes’ theorem</a></p>
<p>15 0.089726254 <a title="3-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<p>16 0.089378387 <a title="3-tfidf-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>17 0.089366734 <a title="3-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-25-Classics_of_statistics.html">109 andrew gelman stats-2010-06-25-Classics of statistics</a></p>
<p>18 0.089088701 <a title="3-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-16-%E2%80%9CNightshifts_Linked_to_Increased_Risk_for_Ovarian_Cancer%E2%80%9D.html">1766 andrew gelman stats-2013-03-16-“Nightshifts Linked to Increased Risk for Ovarian Cancer”</a></p>
<p>19 0.0879509 <a title="3-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-It_depends_upon_what_the_meaning_of_the_word_%E2%80%9Cfirm%E2%80%9D_is..html">940 andrew gelman stats-2011-10-03-It depends upon what the meaning of the word “firm” is.</a></p>
<p>20 0.08637692 <a title="3-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-27-Banned_in_NYC_school_tests.html">1232 andrew gelman stats-2012-03-27-Banned in NYC school tests</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.114), (1, -0.001), (2, -0.021), (3, -0.003), (4, -0.004), (5, 0.04), (6, 0.044), (7, 0.053), (8, -0.005), (9, -0.088), (10, 0.006), (11, 0.025), (12, 0.009), (13, 0.016), (14, -0.02), (15, 0.02), (16, -0.007), (17, 0.021), (18, -0.033), (19, 0.013), (20, 0.04), (21, -0.001), (22, -0.039), (23, -0.009), (24, 0.025), (25, -0.011), (26, -0.018), (27, 0.03), (28, 0.036), (29, -0.049), (30, -0.033), (31, 0.02), (32, 0.014), (33, -0.035), (34, -0.002), (35, -0.039), (36, 0.019), (37, -0.001), (38, -0.016), (39, -0.028), (40, -0.07), (41, -0.044), (42, 0.031), (43, -0.008), (44, 0.047), (45, 0.035), (46, 0.012), (47, 0.025), (48, -0.04), (49, -0.048)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98039478 <a title="3-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-26-Bayes_in_the_news%E2%80%A6in_a_somewhat_frustrating_way.html">3 andrew gelman stats-2010-04-26-Bayes in the news…in a somewhat frustrating way</a></p>
<p>Introduction: I’m not sure how the New York Times defines a blog versus an article, so perhaps this post should be called “Bayes in the blogs.”  Whatever.  A  recent NY Times article/blog post  discusses a classic Bayes’ Theorem application — probability that the patient has cancer, given a “positive” mammogram — and purports to give a solution that is easy for students to understand because it doesn’t require Bayes’ Theorem, which is of course complicated and confusing.  You can see  my comment (#17) here.</p><p>2 0.65729338 <a title="3-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-09-Popper%E2%80%99s_great%2C_but_don%E2%80%99t_bother_with_his_theory_of_probability.html">23 andrew gelman stats-2010-05-09-Popper’s great, but don’t bother with his theory of probability</a></p>
<p>Introduction: Adam Gurri writes:
  
Any chance you could do a post explaining Popper’s propensity theory of probability?  I have never understood it.
  
My reply:  I’m a big fan of Popper (search this blog for details), especially as interpreted by Lakatos, but as far as I can tell, Popper’s theory of probability is hopeless.  We’ve made a lot of progress on probability in the past 75 years, and I don’t see any real need to go back to the bad old days.</p><p>3 0.62862676 <a title="3-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-26-Blog_on_applied_probability_modeling.html">872 andrew gelman stats-2011-08-26-Blog on applied probability modeling</a></p>
<p>Introduction: Joseph Wilson points me to  this blog  on applied probability modeling.  He sent me the link a couple months ago.  If heâ&euro;&trade;s still adding new entries, then his blog is probably already longer-lasting than most!</p><p>4 0.6238721 <a title="3-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-26-Lottery_probability_update.html">731 andrew gelman stats-2011-05-26-Lottery probability update</a></p>
<p>Introduction: It was reported  last year  that the national lottery of Israel featured the exact same 6 numbers (out of 45) twice in the same month, and statistics professor Isaac Meilijson of Tel Aviv University was quoted as saying that “the incident of six numbers repeating themselves within a month is an event of once in 10,000 years.”
 
I shouldn’t mock when it comes to mathematics–after all, I proved a false theorem once!  (Or, to be precise, my collaborator and I published a false claim which we thought we’d proved, thus we thought was a theorem.)
 
So let me retract the mockery and move, first to the mathematics and then to the statistics.
  

 
First, how many possibilities are there in pick 6 out of 45?  It’s (45*44*43*42*41*40)/6! = 8,145,060.  Let’s call this number N.
 
Second, what’s the probability that the same numbers repeat in a single calendar month?  I’ve been told that the Israeli lottery has 2 draws per week,  That’s 104/12=8.67 draws per month.  Or maybe they skip some holiday</p><p>5 0.62301606 <a title="3-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-26-Be_careful_what_you_control_for_._._._you_just_might_get_it%21.html">871 andrew gelman stats-2011-08-26-Be careful what you control for . . . you just might get it!</a></p>
<p>Introduction: Robert Bell points me to  this blog  by Austin Frakt explaining problems in interpreting regressions that control for intermediate outcomes.  As Robert notes, we discuss these issues in chapters 9 and 10.  But Fraktâ&euro;&trade;s example is a good one.</p><p>6 0.60622543 <a title="3-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-10-Bayes_jumps_the_shark.html">331 andrew gelman stats-2010-10-10-Bayes jumps the shark</a></p>
<p>7 0.60210711 <a title="3-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-27-Hype_about_conditional_probability_puzzles.html">54 andrew gelman stats-2010-05-27-Hype about conditional probability puzzles</a></p>
<p>8 0.59123856 <a title="3-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-04-Questions_about_quantum_computing.html">786 andrew gelman stats-2011-07-04-Questions about quantum computing</a></p>
<p>9 0.58052677 <a title="3-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-13-You_heard_it_here_first%3A_Intense_exercise_can_suppress_appetite.html">2022 andrew gelman stats-2013-09-13-You heard it here first: Intense exercise can suppress appetite</a></p>
<p>10 0.57439864 <a title="3-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-02-I%E2%80%99ve_already_written_next_year%E2%80%99s_April_Fools_post%21.html">2085 andrew gelman stats-2013-11-02-I’ve already written next year’s April Fools post!</a></p>
<p>11 0.57101178 <a title="3-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-17-Sports_examples_in_class.html">1173 andrew gelman stats-2012-02-17-Sports examples in class</a></p>
<p>12 0.56716889 <a title="3-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-22-Seeking_balance.html">104 andrew gelman stats-2010-06-22-Seeking balance</a></p>
<p>13 0.56117088 <a title="3-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-13-Hey%2C_you%21__Don%E2%80%99t_take_that_class%21.html">956 andrew gelman stats-2011-10-13-Hey, you!  Don’t take that class!</a></p>
<p>14 0.56074303 <a title="3-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-17-Big_bad_education_bureaucracy_does_big_bad_things.html">2104 andrew gelman stats-2013-11-17-Big bad education bureaucracy does big bad things</a></p>
<p>15 0.55773747 <a title="3-lsi-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-06-Priors_I_don%E2%80%99t_believe.html">2322 andrew gelman stats-2014-05-06-Priors I don’t believe</a></p>
<p>16 0.54955661 <a title="3-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-10-What_property_is_important_in_a_risk_prediction_model%3F_Discrimination_or_calibration%3F.html">2328 andrew gelman stats-2014-05-10-What property is important in a risk prediction model? Discrimination or calibration?</a></p>
<p>17 0.54913568 <a title="3-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-16-RSS_mess.html">91 andrew gelman stats-2010-06-16-RSS mess</a></p>
<p>18 0.54848361 <a title="3-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-30-Nano-project_qualifying_exam_process%3A__An_intensified_dialogue_between_students_and_faculty.html">308 andrew gelman stats-2010-09-30-Nano-project qualifying exam process:  An intensified dialogue between students and faculty</a></p>
<p>19 0.54165596 <a title="3-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-14-Confusion_about_continuous_probability_densities.html">341 andrew gelman stats-2010-10-14-Confusion about continuous probability densities</a></p>
<p>20 0.54128426 <a title="3-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-19-Revised_evidence_for_statistical_standards.html">2140 andrew gelman stats-2013-12-19-Revised evidence for statistical standards</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.047), (27, 0.231), (57, 0.039), (84, 0.036), (86, 0.072), (99, 0.422)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96925974 <a title="3-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-19-Beef_with_data.html">1727 andrew gelman stats-2013-02-19-Beef with data</a></p>
<p>Introduction: Louis Mittel writes:
  
Do you know why David Brooks has such a  beef  with data?
  
My reply:
 
I have no idea, but I’m happy that we’re now considered the establishment that he has to rebel against!</p><p>same-blog 2 0.95463979 <a title="3-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-26-Bayes_in_the_news%E2%80%A6in_a_somewhat_frustrating_way.html">3 andrew gelman stats-2010-04-26-Bayes in the news…in a somewhat frustrating way</a></p>
<p>Introduction: I’m not sure how the New York Times defines a blog versus an article, so perhaps this post should be called “Bayes in the blogs.”  Whatever.  A  recent NY Times article/blog post  discusses a classic Bayes’ Theorem application — probability that the patient has cancer, given a “positive” mammogram — and purports to give a solution that is easy for students to understand because it doesn’t require Bayes’ Theorem, which is of course complicated and confusing.  You can see  my comment (#17) here.</p><p>3 0.93132108 <a title="3-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-28-Wiley_Wegman_chutzpah_update%3A__Now_you_too_can_buy_a_selection_of_garbled_Wikipedia_articles%2C_for_a_mere_%241400-%242800_per_year%21.html">930 andrew gelman stats-2011-09-28-Wiley Wegman chutzpah update:  Now you too can buy a selection of garbled Wikipedia articles, for a mere $1400-$2800 per year!</a></p>
<p>Introduction: Someone passed on to a message from his university library announcing that the journal “Wiley Interdisciplinary Reviews:  Computational Statistics” is no longer free.
 
Librarians have to decide what to do, so I thought I’d offer the following consumer guide:
  
 
  
 Wiley Computational Statistics journal 
 Wikipedia 
 
 
 Frequency 
 6 issues per year 
 Continuously updated 
 
 
 Includes articles from Wikipedia? 
  Yes  
 Yes 
 
 
 Cites the Wikipedia sources it uses? 
  No  
 Yes 
 
 
 Edited by recipient of ASA Founders Award? 
 Yes 
 No 
 
 
 Articles are subject to rigorous review? 
 No 
 Yes 
 
 
 Errors, when discovered, get fixed? 
 No 
 Yes 
 
 
 Number of vertices in n-dimensional hypercube? 
 2n 
 2  n   
 
 
 Easy access to Brady Bunch trivia? 
 No 
 Yes 
 
 
 Cost (North America) 
 $1400-$2800 
 $0 
 
 
 Cost (UK) 
 £986-£1972 
 £0 
 
 
 Cost (Europe) 
 €1213-€2426 
 €0 
 
  
The choice seems pretty clear to me!
 
It’s funny for the Wiley journal to start charging  now</p><p>4 0.92756879 <a title="3-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-31-Editing_and_clutch_hitting.html">173 andrew gelman stats-2010-07-31-Editing and clutch hitting</a></p>
<p>Introduction: Regarding  editing :  The only serious editing I’ve ever received has been for my New York Times op-eds and my article in the American Scientist.  My book editors have all been nice people, and they’ve helped me with many things (including suggestions of what my priorities should be in communicating with readers)–they’ve been great–but they’ve not given (nor have I expected or asked for) serious editing.  Maybe I should’ve asked for it, I don’t know.  I’ve had time-wasting experiences with copy editors and a particularly annoying experience with a production editor (who was so difficult that my coauthors and I actually contacted our agent and a lawyer about the possibility of getting out of our contract), but that’s another story.
 
Regarding  clutch hitting , Bill James once noted that it’s great when a Bucky Dent hits an unexpected home run, but what’s really special is being able to get the big hit when it’s expected of you.  The best players can do their best every time they come t</p><p>5 0.9268533 <a title="3-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-Super_Sam_Fuld_Needs_Your_Help_%28with_Foul_Ball_stats%29.html">802 andrew gelman stats-2011-07-13-Super Sam Fuld Needs Your Help (with Foul Ball stats)</a></p>
<p>Introduction: I was pleasantly surprised to have my recreational reading about baseball in the  New Yorker  interrupted by a digression on statistics.   Sam Fuld  of the Tampa Bay Rays, was the subjet of a Ben McGrath profile in the 4 July 2011 issue of the  New Yorker , in an article titled  Super Sam .  After quoting a minor-league trainer who described Fuld as “a bit of a geek” (who isn’t these days?), McGrath gets into that lovely  New Yorker  detail:
  

One could have pointed out the more persuasive and telling examples, such as the fact that in 2005, after his first pro season, with the Class-A Peoria Chiefs, Fuld applied for a fall internship with Stats, Inc., the research firm that supplies broadcasters with much of the data anad analysis that you hear in sports telecasts.

  
After a description of what they had him doing, reviewing footage of games and cataloguing, he said
  

“I thought, They have a stat for everything, but they don’t have any stats regarding foul balls.”

     
 Fuld’s</p><p>6 0.92148799 <a title="3-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-10-Amtrak_sucks.html">1255 andrew gelman stats-2012-04-10-Amtrak sucks</a></p>
<p>7 0.91212875 <a title="3-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-12-Improvement_of_5_MPG%3A_how_many_more_auto_deaths%3F.html">708 andrew gelman stats-2011-05-12-Improvement of 5 MPG: how many more auto deaths?</a></p>
<p>8 0.9120034 <a title="3-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-27-Uncompressing_the_concept_of_compressed_sensing.html">2079 andrew gelman stats-2013-10-27-Uncompressing the concept of compressed sensing</a></p>
<p>9 0.90769809 <a title="3-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-15-Blaming_scientific_fraud_on_the_Kuhnians.html">1982 andrew gelman stats-2013-08-15-Blaming scientific fraud on the Kuhnians</a></p>
<p>10 0.90592909 <a title="3-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-09-I%E2%80%99m_still_wondering_._._..html">1490 andrew gelman stats-2012-09-09-I’m still wondering . . .</a></p>
<p>11 0.90159327 <a title="3-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-13-%243M_health_care_prediction_challenge.html">465 andrew gelman stats-2010-12-13-$3M health care prediction challenge</a></p>
<p>12 0.90027916 <a title="3-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-08-%E2%80%9CWhat_do_you_think_about_curved_lines_connecting_discrete_data-points%3F%E2%80%9D.html">134 andrew gelman stats-2010-07-08-“What do you think about curved lines connecting discrete data-points?”</a></p>
<p>13 0.89060223 <a title="3-lda-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-19-On_deck_this_week.html">2339 andrew gelman stats-2014-05-19-On deck this week</a></p>
<p>14 0.88730919 <a title="3-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-07-Minor-league_Stats_Predict_Major-league_Performance%2C_Sarah_Palin%2C_and_Some_Differences_Between_Baseball_and_Politics.html">652 andrew gelman stats-2011-04-07-Minor-league Stats Predict Major-league Performance, Sarah Palin, and Some Differences Between Baseball and Politics</a></p>
<p>15 0.88393795 <a title="3-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-17-Getting_arm_and_lme4_running_on_the_Mac.html">347 andrew gelman stats-2010-10-17-Getting arm and lme4 running on the Mac</a></p>
<p>16 0.88102692 <a title="3-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-02-Flame_bait.html">1880 andrew gelman stats-2013-06-02-Flame bait</a></p>
<p>17 0.88017511 <a title="3-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-15-%3F.html">343 andrew gelman stats-2010-10-15-?</a></p>
<p>18 0.87975717 <a title="3-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-28-Migrating_from_dot_to_underscore.html">1472 andrew gelman stats-2012-08-28-Migrating from dot to underscore</a></p>
<p>19 0.87560678 <a title="3-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-20-Picking_on_Gregg_Easterbrook.html">967 andrew gelman stats-2011-10-20-Picking on Gregg Easterbrook</a></p>
<p>20 0.87101573 <a title="3-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-23-Learning_Differential_Geometry_for_Hamiltonian_Monte_Carlo.html">1339 andrew gelman stats-2012-05-23-Learning Differential Geometry for Hamiltonian Monte Carlo</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
