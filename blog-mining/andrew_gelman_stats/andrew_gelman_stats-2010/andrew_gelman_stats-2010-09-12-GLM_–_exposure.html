<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>271 andrew gelman stats-2010-09-12-GLM – exposure</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-271" href="#">andrew_gelman_stats-2010-271</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>271 andrew gelman stats-2010-09-12-GLM – exposure</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-271-html" href="http://andrewgelman.com/2010/09/12/glm_-_exposure/">html</a></p><p>Introduction: Bernard Phiri writes:
  
 
I am relatively new to glm models, anyhow, I am currently using your book “Data analysis using regression and multilevel/hierarchical models” (pages 109-115). I am using a Poisson GLM model to analyse an aerial census dataset of wild herbivores on a ranch in Kenya. In my analysis I have the following variables:


 1. Outcome variable: count of wild herbivores sighted at a given location


 2. Explanatory variable1: vegetation type i.e. type of vegetation of the grid in which animals were sighted (the ranch is divided into 1x1km grids)


 3. Explanatory variable2: animal species e.g. eland, elephant, zebra etc


 4. Exposure: proximity to water i.e. distance (km) to the nearest water point


My questions are as follows:


1. Am I correct to include proximity to water point as an offset? I notice that in the example in your book the offset is a count, does this matter?


2. By including proximity to water in the model as an exposure am I correct to interpret th</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Bernard Phiri writes:      I am relatively new to glm models, anyhow, I am currently using your book “Data analysis using regression and multilevel/hierarchical models” (pages 109-115). [sent-1, score-0.514]
</p><p>2 I am using a Poisson GLM model to analyse an aerial census dataset of wild herbivores on a ranch in Kenya. [sent-2, score-0.909]
</p><p>3 In my analysis I have the following variables:    1. [sent-3, score-0.044]
</p><p>4 Outcome variable: count of wild herbivores sighted at a given location    2. [sent-4, score-0.796]
</p><p>5 type of vegetation of the grid in which animals were sighted (the ranch is divided into 1x1km grids)    3. [sent-7, score-0.942]
</p><p>6 distance (km) to the nearest water point   My questions are as follows:   1. [sent-13, score-0.711]
</p><p>7 Am I correct to include proximity to water point as an offset? [sent-14, score-1.032]
</p><p>8 I notice that in the example in your book the offset is a count, does this matter? [sent-15, score-0.407]
</p><p>9 By including proximity to water in the model as an exposure am I correct to interpret this as “the chances of sighting an animal is the same for every kilometre away from the water point”? [sent-17, score-1.841]
</p><p>10 My reply:   I would use proximity to water as a predictor, not an offset, just as, in the wells example in chapter 5 of our book, we use proximity to the nearest well as a predictor. [sent-18, score-1.75]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('proximity', 0.468), ('water', 0.425), ('offset', 0.271), ('herbivores', 0.228), ('sighted', 0.228), ('vegetation', 0.208), ('ranch', 0.208), ('nearest', 0.167), ('wild', 0.16), ('glm', 0.155), ('explanatory', 0.153), ('animal', 0.148), ('exposure', 0.129), ('predictor', 0.119), ('count', 0.115), ('anyhow', 0.098), ('wells', 0.098), ('analyse', 0.09), ('type', 0.088), ('elephant', 0.088), ('grids', 0.088), ('bernard', 0.083), ('correct', 0.082), ('book', 0.081), ('grid', 0.073), ('animals', 0.073), ('species', 0.072), ('poisson', 0.071), ('chances', 0.069), ('location', 0.065), ('using', 0.065), ('divided', 0.064), ('census', 0.063), ('distance', 0.062), ('point', 0.057), ('relatively', 0.056), ('notice', 0.055), ('dataset', 0.054), ('interpret', 0.054), ('pages', 0.052), ('models', 0.052), ('follows', 0.049), ('outcome', 0.048), ('currently', 0.048), ('analysis', 0.044), ('etc', 0.044), ('chapter', 0.044), ('variable', 0.042), ('model', 0.041), ('use', 0.04)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="271-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-12-GLM_%E2%80%93_exposure.html">271 andrew gelman stats-2010-09-12-GLM – exposure</a></p>
<p>Introduction: Bernard Phiri writes:
  
 
I am relatively new to glm models, anyhow, I am currently using your book “Data analysis using regression and multilevel/hierarchical models” (pages 109-115). I am using a Poisson GLM model to analyse an aerial census dataset of wild herbivores on a ranch in Kenya. In my analysis I have the following variables:


 1. Outcome variable: count of wild herbivores sighted at a given location


 2. Explanatory variable1: vegetation type i.e. type of vegetation of the grid in which animals were sighted (the ranch is divided into 1x1km grids)


 3. Explanatory variable2: animal species e.g. eland, elephant, zebra etc


 4. Exposure: proximity to water i.e. distance (km) to the nearest water point


My questions are as follows:


1. Am I correct to include proximity to water point as an offset? I notice that in the example in your book the offset is a count, does this matter?


2. By including proximity to water in the model as an exposure am I correct to interpret th</p><p>2 0.2834661 <a title="271-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-27-No_radon_lobby.html">238 andrew gelman stats-2010-08-27-No radon lobby</a></p>
<p>Introduction: Kaiser writes  thoughtfully  about the costs, benefits, and incentives for different policy recommendation options regarding a recent water crisis.  Good stuff:  it’s solid “freakonomics”–and I mean this in positive way:  a mix of economic and statistical analysis, with assumptions stated clearly.  Kaiser writes: 
  
Using the framework from Chapter 4, we should think about the incentives facing the Mass. Water Resources Authority:


A false positive error (people asked to throw out water when water is clean) means people stop drinking tap water temporarily, perhaps switching to bottled water, and the officials claim victory when no one falls sick, and businesses that produce bottled water experience a jump in sales. It is also very difficult to prove a “false positive” when people have stopped drinking the water. So this type of error is easy to hide behind.


A false negative error (people told it’s safe to drink water when water is polluted) becomes apparent when someone falls sick</p><p>3 0.15652673 <a title="271-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-03-An_Olympic_size_swimming_pool_full_of_lithium_water.html">179 andrew gelman stats-2010-08-03-An Olympic size swimming pool full of lithium water</a></p>
<p>Introduction: As part of his continuing plan to sap etc etc., Aleks pointed me to  an article  by Max Miller reporting on a recommendation from Jacob Appel:
  
Adding trace amounts of lithium to the drinking water could limit suicides. . . . Communities with higher than average amounts of lithium in their drinking water had significantly lower suicide rates than communities with lower levels. Regions of Texas with lower lithium concentrations had an average suicide rate of 14.2 per 100,000 people, whereas those areas with naturally higher lithium levels had a dramatically lower suicide rate of 8.7 per 100,000.  The highest levels in Texas (150 micrograms of lithium per liter of water) are only a thousandth of the minimum pharmaceutical dose, and have no known deleterious effects.
  
I don’t know anything about this and am offering no judgment on it; I’m just passing it on.  The research studies are  here  and  here .  I am skeptical, though, about this part of the argument:
  
 
We are not talking a</p><p>4 0.14232951 <a title="271-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-14-Statistics_of_food_consumption.html">413 andrew gelman stats-2010-11-14-Statistics of food consumption</a></p>
<p>Introduction: Visual Economics  shows statistics on average food consumption in America:
 
   
 
My brief feedback is that water is confounded with these results. They should have subtracted water content from the weight of all dietary items, as it inflates the proportion of milk, vegetable and fruit items that contain more water. They did that for soda (which is represented as sugar/corn syrup), amplifying the inconsistency.
 
Time Magazine had a  beautiful gallery  that visualizes diets around the world in a more appealing way.</p><p>5 0.070691966 <a title="271-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-04-Whassup_with_glm%28%29%3F.html">696 andrew gelman stats-2011-05-04-Whassup with glm()?</a></p>
<p>Introduction: We’re having problem with starting values in glm().  A very simple logistic regression with just an intercept with a very simple starting value (beta=5) blows up.
  

 

Here’s the R code:
 
 
> y <- rep (c(1,0),c(10,5))
> glm (y ~ 1, family=binomial(link="logit"))

Call:  glm(formula = y ~ 1, family = binomial(link = "logit"))

Coefficients:
(Intercept)  
     0.6931  

Degrees of Freedom: 14 Total (i.e. Null);  14 Residual
Null Deviance:      19.1 
Residual Deviance: 19.1         AIC: 21.1 
> glm (y ~ 1, family=binomial(link="logit"), start=2)

Call:  glm(formula = y ~ 1, family = binomial(link = "logit"), start = 2)

Coefficients:
(Intercept)  
     0.6931  

Degrees of Freedom: 14 Total (i.e. Null);  14 Residual
Null Deviance:      19.1 
Residual Deviance: 19.1         AIC: 21.1 
> glm (y ~ 1, family=binomial(link="logit"), start=5)

Call:  glm(formula = y ~ 1, family = binomial(link = "logit"), start = 5)

Coefficients:
(Intercept)  
  1.501e+15  

Degrees of Freedom: 14 Total (i.</p><p>6 0.067481108 <a title="271-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-04-Models%2C_assumptions%2C_and_data_summaries.html">1299 andrew gelman stats-2012-05-04-Models, assumptions, and data summaries</a></p>
<p>7 0.065810919 <a title="271-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>8 0.064740591 <a title="271-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Modeling_y_%3D_a_%2B_b_%2B_c.html">1294 andrew gelman stats-2012-05-01-Modeling y = a + b + c</a></p>
<p>9 0.063509896 <a title="271-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-05-Question_26_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1367 andrew gelman stats-2012-06-05-Question 26 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>10 0.063466899 <a title="271-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>11 0.063422576 <a title="271-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-06-Bayesian_Anova_found_useful_in_ecology.html">1102 andrew gelman stats-2012-01-06-Bayesian Anova found useful in ecology</a></p>
<p>12 0.059682757 <a title="271-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>13 0.059387237 <a title="271-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<p>14 0.05678637 <a title="271-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-12-year_%2B_%281%7Cyear%29.html">851 andrew gelman stats-2011-08-12-year + (1|year)</a></p>
<p>15 0.056027871 <a title="271-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-30-Computational_problems_with_glm_etc..html">1516 andrew gelman stats-2012-09-30-Computational problems with glm etc.</a></p>
<p>16 0.055380043 <a title="271-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-03-This_is_a_footnote_in_one_of_my_papers.html">448 andrew gelman stats-2010-12-03-This is a footnote in one of my papers</a></p>
<p>17 0.053775042 <a title="271-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>18 0.053108685 <a title="271-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>19 0.051891573 <a title="271-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-01-An_%28almost%29_testable_assumption_on_dogmatism%2C_and_my_guess_of_the_answer%2C_based_on_psychometric_principles.html">121 andrew gelman stats-2010-07-01-An (almost) testable assumption on dogmatism, and my guess of the answer, based on psychometric principles</a></p>
<p>20 0.051432837 <a title="271-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-01-A_randomized_trial_of_the_set-point_diet.html">1239 andrew gelman stats-2012-04-01-A randomized trial of the set-point diet</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.073), (1, 0.042), (2, 0.024), (3, 0.008), (4, 0.042), (5, 0.019), (6, -0.001), (7, -0.013), (8, 0.06), (9, 0.036), (10, 0.013), (11, -0.001), (12, -0.001), (13, -0.024), (14, 0.022), (15, 0.014), (16, -0.0), (17, 0.003), (18, 0.015), (19, -0.037), (20, -0.003), (21, 0.028), (22, -0.009), (23, -0.013), (24, -0.009), (25, 0.008), (26, 0.029), (27, -0.026), (28, 0.037), (29, 0.012), (30, -0.013), (31, 0.001), (32, 0.009), (33, 0.025), (34, -0.0), (35, -0.0), (36, 0.02), (37, -0.001), (38, 0.012), (39, -0.001), (40, -0.025), (41, -0.014), (42, -0.021), (43, 0.017), (44, 0.024), (45, 0.015), (46, 0.013), (47, 0.072), (48, -0.005), (49, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9472385 <a title="271-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-12-GLM_%E2%80%93_exposure.html">271 andrew gelman stats-2010-09-12-GLM – exposure</a></p>
<p>Introduction: Bernard Phiri writes:
  
 
I am relatively new to glm models, anyhow, I am currently using your book “Data analysis using regression and multilevel/hierarchical models” (pages 109-115). I am using a Poisson GLM model to analyse an aerial census dataset of wild herbivores on a ranch in Kenya. In my analysis I have the following variables:


 1. Outcome variable: count of wild herbivores sighted at a given location


 2. Explanatory variable1: vegetation type i.e. type of vegetation of the grid in which animals were sighted (the ranch is divided into 1x1km grids)


 3. Explanatory variable2: animal species e.g. eland, elephant, zebra etc


 4. Exposure: proximity to water i.e. distance (km) to the nearest water point


My questions are as follows:


1. Am I correct to include proximity to water point as an offset? I notice that in the example in your book the offset is a count, does this matter?


2. By including proximity to water in the model as an exposure am I correct to interpret th</p><p>2 0.75608081 <a title="271-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>Introduction: Fred Schiff writes: 
  
  
I’m writing to you to ask about the “R-squared” approximation procedure you suggest in your 2004 book with Dr. Hill.  [See also  this paper  with Pardoe---ed.]


I’m a media sociologist at the University of Houston.  I’ve been using HLM3 for about two years.  


Briefly about my data.  It’s a content analysis of news stories with a continuous scale dependent variable, story prominence.  I have 6090 news stories, 114 newspapers, and 59 newspaper group owners.  All the Level-1, Level-2 and dependent variables have been standardized. Since the means were zero anyway, we left the variables uncentered.  All the Level-3 ownership groups and characteristics are dichotomous scales that were left uncentered.  


PROBLEM:  The single most important result I am looking for is to compare the strength of nine competing Level-1 variables in their ability to predict and explain the outcome variable, story prominence.  We are trying to use the residuals to calculate a “R-squ</p><p>3 0.69638181 <a title="271-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<p>Introduction: Guy asks:
  
I am analyzing an original survey of farmers in Uganda. I am hoping to use a battery of welfare proxy variables to create a single welfare index using PCA. I have quick question which I hope you can find time to address:


How do you recommend treating count data? (for example # of rooms, # of chickens, # of cows, # of radios)? In my dataset these variables are highly skewed with many responses at zero (which makes taking the natural log problematic). In the case of # of cows or chickens several obs have values in the hundreds.
  
My response:  Hereâ&euro;&trade;s what we do in our mi package in R.  We split a variable into two parts:  an indicator for whether it is positive, and the positive part.  That is, y = u*v.  Then u is binary and can be modeled using logisitc regression, and v can be modeled on the log scale.  At the end you can round to the nearest integer  if you want to avoid fractional values.</p><p>4 0.68297815 <a title="271-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-31-Using_factor_analysis_or_principal_components_analysis_or_measurement-error_models_for_biological_measurements_in_archaeology%3F.html">1094 andrew gelman stats-2011-12-31-Using factor analysis or principal components analysis or measurement-error models for biological measurements in archaeology?</a></p>
<p>Introduction: Greg Campbell writes:
  
I am a Canadian archaeologist (BSc in Chemistry) researching the past human use of European Atlantic shellfish. After two decades of practice I am finally getting a MA in archaeology at Reading. I am seeing if the habitat or size of harvested mussels (Mytilus edulis) can be reconstructed from measurements of the umbo (the pointy end, and the only bit that survives well in archaeological deposits) using log-transformed measurements (or allometry; relationships between dimensions are more likely exponential than linear). 
Of course multivariate regressions in most statistics packages (Minitab, SPSS, SAS) assume you are trying to predict one variable from all the others (a Model I regression), and use ordinary least squares to fit the regression line. For organismal dimensions this makes little sense, since all the dimensions are (at least in theory) free to change their mutual proportions during growth. So there is no predictor and predicted, mutual variation of</p><p>5 0.67650747 <a title="271-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-18-Lack_of_complete_overlap.html">1017 andrew gelman stats-2011-11-18-Lack of complete overlap</a></p>
<p>Introduction: Evens Salies writes:
  
I have a question regarding a randomizing constraint in my current funded electricity experiment. 


After elimination of missing data we have 110 voluntary households from a larger population (resource constraints do not allow us to have more households!). I randomly assign them to threated and non treated where the treatment variable is some ICT that allows the treated to track their electricity consumption in real tim. The ICT is made of two devices, one that is plugged on the household’s modem and the other on the electric meter. A necessary condition for being treated is that the distance between the box and the meter be below some threshold (d), the value of which is 20 meters approximately. 


50 ICTs can be installed. 
60 households will be in the control group.


But, I can only assign 6 households in the control group for whom d is less than 20. Therefore, I have only 6 households in the control group who have a counterfactual in the group of treated.</p><p>6 0.66284102 <a title="271-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>7 0.66224277 <a title="271-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Matching_and_regression%3A__two_great_tastes_etc_etc.html">796 andrew gelman stats-2011-07-10-Matching and regression:  two great tastes etc etc</a></p>
<p>8 0.66070396 <a title="271-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-Good_examples_of_lurking_variables%3F.html">1015 andrew gelman stats-2011-11-17-Good examples of lurking variables?</a></p>
<p>9 0.6586839 <a title="271-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-Displaying_inferences_from_complex_models.html">1815 andrew gelman stats-2013-04-20-Displaying inferences from complex models</a></p>
<p>10 0.64772153 <a title="271-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>11 0.64327502 <a title="271-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>12 0.64314812 <a title="271-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-18-Predictive_checks_for_hierarchical_models.html">154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</a></p>
<p>13 0.64168054 <a title="271-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-11-Multilevel_modeling_in_R_on_a_Mac.html">198 andrew gelman stats-2010-08-11-Multilevel modeling in R on a Mac</a></p>
<p>14 0.63509822 <a title="271-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-10-Combining_data_from_many_sources.html">948 andrew gelman stats-2011-10-10-Combining data from many sources</a></p>
<p>15 0.63234913 <a title="271-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-24-Multilevel_modeling_and_instrumental_variables.html">1468 andrew gelman stats-2012-08-24-Multilevel modeling and instrumental variables</a></p>
<p>16 0.62987262 <a title="271-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-18-Check_your_missing-data_imputations_using_cross-validation.html">1218 andrew gelman stats-2012-03-18-Check your missing-data imputations using cross-validation</a></p>
<p>17 0.62820435 <a title="271-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>18 0.61711961 <a title="271-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-01-When_should_you_worry_about_imputed_data%3F.html">935 andrew gelman stats-2011-10-01-When should you worry about imputed data?</a></p>
<p>19 0.61680287 <a title="271-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>20 0.61000186 <a title="271-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-15-Still_more_Mr._P_in_public_health.html">770 andrew gelman stats-2011-06-15-Still more Mr. P in public health</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.011), (2, 0.07), (9, 0.011), (14, 0.014), (16, 0.064), (22, 0.044), (24, 0.056), (53, 0.136), (54, 0.024), (67, 0.272), (69, 0.014), (76, 0.016), (95, 0.022), (99, 0.115)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.85222566 <a title="271-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-12-GLM_%E2%80%93_exposure.html">271 andrew gelman stats-2010-09-12-GLM – exposure</a></p>
<p>Introduction: Bernard Phiri writes:
  
 
I am relatively new to glm models, anyhow, I am currently using your book “Data analysis using regression and multilevel/hierarchical models” (pages 109-115). I am using a Poisson GLM model to analyse an aerial census dataset of wild herbivores on a ranch in Kenya. In my analysis I have the following variables:


 1. Outcome variable: count of wild herbivores sighted at a given location


 2. Explanatory variable1: vegetation type i.e. type of vegetation of the grid in which animals were sighted (the ranch is divided into 1x1km grids)


 3. Explanatory variable2: animal species e.g. eland, elephant, zebra etc


 4. Exposure: proximity to water i.e. distance (km) to the nearest water point


My questions are as follows:


1. Am I correct to include proximity to water point as an offset? I notice that in the example in your book the offset is a count, does this matter?


2. By including proximity to water in the model as an exposure am I correct to interpret th</p><p>2 0.67369008 <a title="271-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-13-Retro_ethnic_slurs.html">1457 andrew gelman stats-2012-08-13-Retro ethnic slurs</a></p>
<p>Introduction: From Watership Down:
  
There is a rabbit saying, ‘In the warren, more stories than passages’; and a rabbit can no more refuse to tell a story than an Irishman can refuse to fight.
  
Wow. OK, if someone made a joke about New Yorkers being argumentative or people from Iowa being boring (sorry, Tom!), I wouldn’t see it as being in poor taste.  But somehow, to this non-U.K. reader, Adams’s remark about “Irishmen” seems a bit over the top.  I’m not criticizing it as offensive, exactly; it just is a bit jarring, and it’s kind of hard for me to believe someone would just write that as a throwaway line anymore.  Things have changed a lot since 1971, I guess, or maybe in England an Irish joke is no more offensive/awkward than a joke about corrupt Chicagoans, loopy Californians, or crazy Floridians would be here.</p><p>3 0.6546939 <a title="271-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-24-Hey%E2%80%94has_anybody_done_this_study_yet%3F.html">1546 andrew gelman stats-2012-10-24-Hey—has anybody done this study yet?</a></p>
<p>Introduction: A few years ago I  suggested  a research project to study how Americans define themselves in terms of regional identity.  For example, if you grew up in South Dakota but live in Washington, D.C., do you you call yourself a midwesterner, a westerner, a southerner, or what?  The analogy is to the paper by Michael Hout on “How 4 million Irish immigrants became 40 million Irish Americans.” Contrary to expectations, it wasn’t about prolific breeding, it was about how people of mixed background choose to classify themselves.</p><p>4 0.56893051 <a title="271-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-05-Unrelated_to_all_else.html">129 andrew gelman stats-2010-07-05-Unrelated to all else</a></p>
<p>Introduction: Another stereotype is affirmed when I go on the U.K. rail system webpage and it repeatedly times out on me.  At one point I have a browser open with the itinerary I’m interested in, and then awhile later I reopen the window (not clicking on anything on the page, just bringing the window up on the screen) but it’s timed out again.
 
P.S.  Yes, yes, I know that Amtrak is worse.  Still, it’s amusing to see a confirmation that, at least in one respect, the British trains are as bad as they say.</p><p>5 0.55369282 <a title="271-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-29-I%E2%80%99m_looking_for_a_quadrille_notebook_with_faint_lines.html">1235 andrew gelman stats-2012-03-29-I’m looking for a quadrille notebook with faint lines</a></p>
<p>Introduction: I want a graph-paper-style notebook, ideally something lightweight—I’m looking to make notes, not art drawings—and not too large.  I’m currently using a 17 x 22 cm notebook, which is a fine size.  It also has pretty small squares, which I like.
 
My problem with the notebook I have now is that the ink is too heavy—that is, the lines are too dark.  I want very faint lines, just visible enough to be used as guides but not so heavy that to be overwhelming.
 
The notebooks I see in the stores all have pretty dark lines.  Any suggestions?</p><p>6 0.54744446 <a title="271-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-25-Life_as_a_blogger%3A__the_emails_just_get_weirder_and_weirder.html">1589 andrew gelman stats-2012-11-25-Life as a blogger:  the emails just get weirder and weirder</a></p>
<p>7 0.53658307 <a title="271-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-27-Who_is_that_masked_person%3A_The_use_of_face_masks_on_Mexico_City_public_transportation_during_the_Influenza_A_%28H1N1%29_outbreak.html">298 andrew gelman stats-2010-09-27-Who is that masked person: The use of face masks on Mexico City public transportation during the Influenza A (H1N1) outbreak</a></p>
<p>8 0.53029478 <a title="271-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-16-Greenland_is_one_tough_town.html">1677 andrew gelman stats-2013-01-16-Greenland is one tough town</a></p>
<p>9 0.52867639 <a title="271-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-16-%E2%80%9CNightshifts_Linked_to_Increased_Risk_for_Ovarian_Cancer%E2%80%9D.html">1766 andrew gelman stats-2013-03-16-“Nightshifts Linked to Increased Risk for Ovarian Cancer”</a></p>
<p>10 0.52617407 <a title="271-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-14-Statistics_of_food_consumption.html">413 andrew gelman stats-2010-11-14-Statistics of food consumption</a></p>
<p>11 0.52327943 <a title="271-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-14-GPstuff%3A_Bayesian_Modeling_with_Gaussian_Processes.html">1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</a></p>
<p>12 0.5216676 <a title="271-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-24-Multilevel_modeling_and_instrumental_variables.html">1468 andrew gelman stats-2012-08-24-Multilevel modeling and instrumental variables</a></p>
<p>13 0.51001942 <a title="271-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-18-There_are_no_fat_sprinters.html">1905 andrew gelman stats-2013-06-18-There are no fat sprinters</a></p>
<p>14 0.5098412 <a title="271-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-21-Careers%2C_one-hit_wonders%2C_and_an_offer_of_a_free_book.html">46 andrew gelman stats-2010-05-21-Careers, one-hit wonders, and an offer of a free book</a></p>
<p>15 0.50885063 <a title="271-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-27-Graph_of_the_year.html">488 andrew gelman stats-2010-12-27-Graph of the year</a></p>
<p>16 0.5014888 <a title="271-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-06-%E2%80%9CAnd_will_pardon_Paul_Claudel%2C_Pardons_him_for_writing_well%E2%80%9D.html">1446 andrew gelman stats-2012-08-06-“And will pardon Paul Claudel, Pardons him for writing well”</a></p>
<p>17 0.49946588 <a title="271-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-14-Detecting_predictability_in_complex_ecosystems.html">1802 andrew gelman stats-2013-04-14-Detecting predictability in complex ecosystems</a></p>
<p>18 0.49755836 <a title="271-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-27-Another_silly_graph.html">733 andrew gelman stats-2011-05-27-Another silly graph</a></p>
<p>19 0.49681801 <a title="271-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-17-Job_opening_at_new_%E2%80%9Cbig_data%E2%80%9D_consulting_firm%21.html">1902 andrew gelman stats-2013-06-17-Job opening at new “big data” consulting firm!</a></p>
<p>20 0.49374092 <a title="271-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-13-You_heard_it_here_first%3A_Intense_exercise_can_suppress_appetite.html">2022 andrew gelman stats-2013-09-13-You heard it here first: Intense exercise can suppress appetite</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
