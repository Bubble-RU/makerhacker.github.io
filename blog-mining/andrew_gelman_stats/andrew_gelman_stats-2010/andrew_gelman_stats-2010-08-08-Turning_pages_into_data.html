<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>192 andrew gelman stats-2010-08-08-Turning pages into data</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-192" href="#">andrew_gelman_stats-2010-192</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>192 andrew gelman stats-2010-08-08-Turning pages into data</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-192-html" href="http://andrewgelman.com/2010/08/08/turning_pages_i/">html</a></p><p>Introduction: There is a lot of data on the web, meant to be looked at by people, but how do you turn it into a spreadsheet people could actually  analyze  statistically? 
 
The technique to turn web pages intended for people into structured data sets intended for computers is called “screen scraping.” It has just been made easier with a wiki/community  http://scraperwiki.com/ . 
 
They provide libraries to extract information from PDF, Excel files, to automatically fill in forms and similar. Moreover, the community aspect of it should allow researchers doing similar things to get connected. It’s very good. Here’s an example of scraping  road accident data  or  port of London ship arrivals .
 
You can already find collections of structured data online, examples are  Infochimps  (“find the world’s data”), and  Freebase  (“An entity graph of people, places and things, built by a community that loves open data.”). There’s also a repository system for data,  TheData  (“An open-source application for pub</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 There is a lot of data on the web, meant to be looked at by people, but how do you turn it into a spreadsheet people could actually  analyze  statistically? [sent-1, score-0.675]
</p><p>2 The technique to turn web pages intended for people into structured data sets intended for computers is called “screen scraping. [sent-2, score-1.321]
</p><p>3 They provide libraries to extract information from PDF, Excel files, to automatically fill in forms and similar. [sent-5, score-0.525]
</p><p>4 Moreover, the community aspect of it should allow researchers doing similar things to get connected. [sent-6, score-0.24]
</p><p>5 Here’s an example of scraping  road accident data  or  port of London ship arrivals . [sent-8, score-0.845]
</p><p>6 You can already find collections of structured data online, examples are  Infochimps  (“find the world’s data”), and  Freebase  (“An entity graph of people, places and things, built by a community that loves open data. [sent-9, score-0.996]
</p><p>7 There’s also a repository system for data,  TheData  (“An open-source application for publishing, citing and discovering research data”). [sent-11, score-0.374]
</p><p>8 The challenge is how to keep these efforts alive and active. [sent-12, score-0.279]
</p><p>9 One early company helping people screen-scrape was  Dapper  that’s now helping retailers advertise by scraping their own websites. [sent-13, score-1.097]
</p><p>10 Perhaps the library funding should be used towards tools like that rather than piling up physical copies of expensive journals everyone reads just online. [sent-14, score-0.748]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('scraping', 0.312), ('structured', 0.203), ('helping', 0.193), ('intended', 0.176), ('community', 0.158), ('retailers', 0.156), ('piling', 0.156), ('port', 0.156), ('repository', 0.156), ('web', 0.15), ('data', 0.148), ('freebase', 0.147), ('turn', 0.143), ('entity', 0.141), ('infochimps', 0.141), ('advertise', 0.136), ('collections', 0.132), ('libraries', 0.126), ('loves', 0.123), ('computers', 0.117), ('accident', 0.117), ('alive', 0.113), ('road', 0.112), ('extract', 0.112), ('discovering', 0.11), ('spreadsheet', 0.11), ('fill', 0.109), ('copies', 0.109), ('files', 0.108), ('citing', 0.108), ('people', 0.107), ('excel', 0.107), ('moreover', 0.105), ('pdf', 0.105), ('london', 0.104), ('screen', 0.103), ('technique', 0.101), ('towards', 0.1), ('reads', 0.099), ('library', 0.098), ('funding', 0.096), ('built', 0.091), ('expensive', 0.09), ('forms', 0.09), ('automatically', 0.088), ('analyze', 0.086), ('efforts', 0.084), ('aspect', 0.082), ('challenge', 0.082), ('meant', 0.081)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="192-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-08-Turning_pages_into_data.html">192 andrew gelman stats-2010-08-08-Turning pages into data</a></p>
<p>Introduction: There is a lot of data on the web, meant to be looked at by people, but how do you turn it into a spreadsheet people could actually  analyze  statistically? 
 
The technique to turn web pages intended for people into structured data sets intended for computers is called “screen scraping.” It has just been made easier with a wiki/community  http://scraperwiki.com/ . 
 
They provide libraries to extract information from PDF, Excel files, to automatically fill in forms and similar. Moreover, the community aspect of it should allow researchers doing similar things to get connected. It’s very good. Here’s an example of scraping  road accident data  or  port of London ship arrivals .
 
You can already find collections of structured data online, examples are  Infochimps  (“find the world’s data”), and  Freebase  (“An entity graph of people, places and things, built by a community that loves open data.”). There’s also a repository system for data,  TheData  (“An open-source application for pub</p><p>2 0.15927851 <a title="192-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-15-Google_Refine.html">910 andrew gelman stats-2011-09-15-Google Refine</a></p>
<p>Introduction: Tools worth knowing about: 
  
  Google Refine  is a power tool for working with messy data, cleaning it up, transforming it from one format into another, extending it with web services, and linking it to databases like Freebase.
  
A recent  discussion on the Polmeth list  about the  ANES Cumulative File  is a setting where I think Refine might help (admittedly 49760×951 is bigger than I’d really like to deal with in the browser with js… but on a subset yes). [I might write this example up later.]
 
Go watch the screencast videos for Refine. Data-entry problems are rampant in stuff we all use — leading or trailing spaces; mixed decimal-indicators; different units or transformations used in the same column; mixed lettercase leading to false duplicates; that’s only the beginning. Refine certainly would help find duplicates, and it counts things for you too. Just counting rows is too much for researchers sometimes (see  yesterday’s post )!
 
Refine 2.0 adds some data-collection tools for</p><p>3 0.14981672 <a title="192-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-12-OpenData_Latinoamerica.html">1853 andrew gelman stats-2013-05-12-OpenData Latinoamerica</a></p>
<p>Introduction: Miguel Paz  writes :
  
Poderomedia Foundation and PinLatam are launching OpenDataLatinoamerica.org, a regional data repository to free data and use it on Hackathons and other activities by HacksHackers chapters and other organizations.


We are doing this because the road to the future of news has been littered with lost datasets. A day or so after every hackathon and meeting where a group has come together to analyze, compare and understand a particular set of data, someone tries to remember where the successful files were stored. Too often, no one is certain. Therefore with Mariano Blejman we realized that we need a central repository where you can share the data that you have proved to be reliable: OpenData Latinoamerica, which we are leading as ICFJ Knight International Journalism Fellows.


If you work in Latin America or Central America your organization can take part in OpenDataLatinoamerica.org. To apply, go to the website and answer a simple form agreeing to meet the standard</p><p>4 0.13444602 <a title="192-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-07-Reproducible_science_FAIL_%28so_far%29%3A__What%E2%80%99s_stoppin_people_from_sharin_data_and_code%3F.html">1447 andrew gelman stats-2012-08-07-Reproducible science FAIL (so far):  What’s stoppin people from sharin data and code?</a></p>
<p>Introduction: David Karger writes:
  
Your  recent post  on sharing data was of great interest to me, as my own research in computer science asks how to incentivize and lower barriers to data sharing.   I was particularly curious about your highlighting of effort as the major dis-incentive to sharing.  I would love to hear more, as this question of effort is on we specifically target in our development of tools for data authoring and publishing.


As a straw man, let me point out that sharing data technically requires no more than posting an excel spreadsheet online.  And that you likely already produced that spreadsheet during your own analytic work.   So, in what way does such low-tech publishing fail to meet your data sharing objectives?


Our own hypothesis has been that the effort is really quite low, with the problem being a lack of *immediate/tangible* benefits (as opposed to the long-term values you accurately describe).  To attack this problem, we’re developing  tools  (and, since it appear</p><p>5 0.10975315 <a title="192-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-15-More_data_tools_worth_using_from_Google.html">911 andrew gelman stats-2011-09-15-More data tools worth using from Google</a></p>
<p>Introduction: Speaking of open data and google tools, see this post from Revolution R:  How to use a Google Spreadsheet as data in R .</p><p>6 0.10841244 <a title="192-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-19-Factual_%E2%80%93_a_new_place_to_find_data.html">1175 andrew gelman stats-2012-02-19-Factual – a new place to find data</a></p>
<p>7 0.10740842 <a title="192-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-04-To_commenters_who_are_trying_to_sell_something.html">839 andrew gelman stats-2011-08-04-To commenters who are trying to sell something</a></p>
<p>8 0.097875148 <a title="192-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-12-Get_the_Data.html">569 andrew gelman stats-2011-02-12-Get the Data</a></p>
<p>9 0.08596278 <a title="192-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-24-An_interesting_mosaic_of_a_data_programming_course.html">2345 andrew gelman stats-2014-05-24-An interesting mosaic of a data programming course</a></p>
<p>10 0.076135486 <a title="192-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-07-Analysis_of_Power_Law_of_Participation.html">946 andrew gelman stats-2011-10-07-Analysis of Power Law of Participation</a></p>
<p>11 0.071414679 <a title="192-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-Infovis%2C_infographics%2C_and_data_visualization%3A__Where_I%E2%80%99m_coming_from%2C_and_where_I%E2%80%99d_like_to_go.html">878 andrew gelman stats-2011-08-29-Infovis, infographics, and data visualization:  Where I’m coming from, and where I’d like to go</a></p>
<p>12 0.071334504 <a title="192-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-21-Bayes_related.html">1948 andrew gelman stats-2013-07-21-Bayes related</a></p>
<p>13 0.070335835 <a title="192-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Excel-bashing.html">1808 andrew gelman stats-2013-04-17-Excel-bashing</a></p>
<p>14 0.069264151 <a title="192-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Job_opening_at_an_organization_that_promotes_reproducible_research%21.html">1990 andrew gelman stats-2013-08-20-Job opening at an organization that promotes reproducible research!</a></p>
<p>15 0.068758115 <a title="192-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-08-Software_is_as_software_does.html">1661 andrew gelman stats-2013-01-08-Software is as software does</a></p>
<p>16 0.068594493 <a title="192-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-27-Overfitting.html">1431 andrew gelman stats-2012-07-27-Overfitting</a></p>
<p>17 0.067229114 <a title="192-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-12-Things_that_I_like_that_almost_nobody_else_is_interested_in.html">2168 andrew gelman stats-2014-01-12-Things that I like that almost nobody else is interested in</a></p>
<p>18 0.067048594 <a title="192-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>19 0.066447504 <a title="192-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-21-Statoverflow.html">223 andrew gelman stats-2010-08-21-Statoverflow</a></p>
<p>20 0.066317223 <a title="192-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-30-%E2%80%9CNon-statistical%E2%80%9D_statistics_tools.html">1920 andrew gelman stats-2013-06-30-“Non-statistical” statistics tools</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.127), (1, -0.029), (2, -0.05), (3, -0.002), (4, 0.049), (5, -0.01), (6, -0.035), (7, -0.033), (8, -0.027), (9, 0.014), (10, -0.011), (11, -0.02), (12, -0.01), (13, -0.005), (14, -0.021), (15, 0.03), (16, 0.034), (17, -0.028), (18, 0.03), (19, -0.01), (20, 0.032), (21, 0.032), (22, -0.023), (23, -0.005), (24, -0.055), (25, -0.003), (26, 0.054), (27, -0.006), (28, 0.027), (29, 0.038), (30, 0.006), (31, -0.035), (32, 0.008), (33, 0.019), (34, 0.012), (35, 0.052), (36, -0.021), (37, 0.021), (38, -0.017), (39, 0.046), (40, 0.021), (41, 0.016), (42, 0.002), (43, 0.056), (44, -0.049), (45, 0.049), (46, 0.042), (47, -0.041), (48, 0.002), (49, -0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95803511 <a title="192-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-08-Turning_pages_into_data.html">192 andrew gelman stats-2010-08-08-Turning pages into data</a></p>
<p>Introduction: There is a lot of data on the web, meant to be looked at by people, but how do you turn it into a spreadsheet people could actually  analyze  statistically? 
 
The technique to turn web pages intended for people into structured data sets intended for computers is called “screen scraping.” It has just been made easier with a wiki/community  http://scraperwiki.com/ . 
 
They provide libraries to extract information from PDF, Excel files, to automatically fill in forms and similar. Moreover, the community aspect of it should allow researchers doing similar things to get connected. It’s very good. Here’s an example of scraping  road accident data  or  port of London ship arrivals .
 
You can already find collections of structured data online, examples are  Infochimps  (“find the world’s data”), and  Freebase  (“An entity graph of people, places and things, built by a community that loves open data.”). There’s also a repository system for data,  TheData  (“An open-source application for pub</p><p>2 0.84796762 <a title="192-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-19-Factual_%E2%80%93_a_new_place_to_find_data.html">1175 andrew gelman stats-2012-02-19-Factual – a new place to find data</a></p>
<p>Introduction: Factual  collects data on a variety of topics, organizes them, and allows easy access. If you ever wanted to do a histogram of calorie content in  Starbucks coffees  or plot warnings with a  live feed of earthquake data  – your life should be a bit simpler now.
 
Also see  DataMarket ,  InfoChimps , and a few older links in  The Future of Data Analysis .
 
If you access the data through the API, you can build live visualizations like this: 
   
 
Of course, you could just go to the source.  Roy Mendelssohn  writes (with minor edits):
  
Since you are both interested in data access, please look at our service ERDDAP:


 http://coastwatch.pfel.noaa.gov/erddap/index.html 


 http://upwell.pfeg.noaa.gov/erddap/index.html 


Please do not be fooled by the web pages. Everything is a service (including search and graphics) and the URL completely defines the request, and response formats are easily changed just by changing the “file extension”. The web pages are just html and javascript that u</p><p>3 0.84671533 <a title="192-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-12-OpenData_Latinoamerica.html">1853 andrew gelman stats-2013-05-12-OpenData Latinoamerica</a></p>
<p>Introduction: Miguel Paz  writes :
  
Poderomedia Foundation and PinLatam are launching OpenDataLatinoamerica.org, a regional data repository to free data and use it on Hackathons and other activities by HacksHackers chapters and other organizations.


We are doing this because the road to the future of news has been littered with lost datasets. A day or so after every hackathon and meeting where a group has come together to analyze, compare and understand a particular set of data, someone tries to remember where the successful files were stored. Too often, no one is certain. Therefore with Mariano Blejman we realized that we need a central repository where you can share the data that you have proved to be reliable: OpenData Latinoamerica, which we are leading as ICFJ Knight International Journalism Fellows.


If you work in Latin America or Central America your organization can take part in OpenDataLatinoamerica.org. To apply, go to the website and answer a simple form agreeing to meet the standard</p><p>4 0.83960736 <a title="192-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-07-Reproducible_science_FAIL_%28so_far%29%3A__What%E2%80%99s_stoppin_people_from_sharin_data_and_code%3F.html">1447 andrew gelman stats-2012-08-07-Reproducible science FAIL (so far):  What’s stoppin people from sharin data and code?</a></p>
<p>Introduction: David Karger writes:
  
Your  recent post  on sharing data was of great interest to me, as my own research in computer science asks how to incentivize and lower barriers to data sharing.   I was particularly curious about your highlighting of effort as the major dis-incentive to sharing.  I would love to hear more, as this question of effort is on we specifically target in our development of tools for data authoring and publishing.


As a straw man, let me point out that sharing data technically requires no more than posting an excel spreadsheet online.  And that you likely already produced that spreadsheet during your own analytic work.   So, in what way does such low-tech publishing fail to meet your data sharing objectives?


Our own hypothesis has been that the effort is really quite low, with the problem being a lack of *immediate/tangible* benefits (as opposed to the long-term values you accurately describe).  To attack this problem, we’re developing  tools  (and, since it appear</p><p>5 0.83079773 <a title="192-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-16-NYT_Labs_releases_Openpaths%2C_a_utility_for_saving_your_iphone_data.html">714 andrew gelman stats-2011-05-16-NYT Labs releases Openpaths, a utility for saving your iphone data</a></p>
<p>Introduction: Jake Porway writes:
  
 We launched Openpaths  the other week.  It’s a site where people can privately upload and view their iPhone location data (at least until an Apple update wipes it out) and also download their data for their own use.  More than just giving people a neat tool to view their data with, however, we’re also creating an option for them to donate their data to research projects at varying levels of anonymity.  We’re still working out the terms for that, but we’d love any input and to get in touch with anyone who might want to use the data.
  
I don’t have any use for this personally but maybe it will interest some of you.
 
From the webpage:
  
 
Openpaths is an anonymous, user-contributed database for the personal location data files recorded by iOS devices. Users securely store, explore, and manage their personal location data, and grant researchers access to portions of that data as they choose.


All location data stored in openpaths is kept separate from user profi</p><p>6 0.80827099 <a title="192-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-14-Controversy_about_a_ranking_of_philosophy_departments%2C_or_How_should_we_think_about_statistical_results_when_we_can%E2%80%99t_see_the_raw_data%3F.html">1212 andrew gelman stats-2012-03-14-Controversy about a ranking of philosophy departments, or How should we think about statistical results when we can’t see the raw data?</a></p>
<p>7 0.80475664 <a title="192-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-19-Updated_R_code_and_data_for_ARM.html">41 andrew gelman stats-2010-05-19-Updated R code and data for ARM</a></p>
<p>8 0.79309601 <a title="192-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-27-Big_Data%E2%80%A6Big_Deal%3F_Maybe%2C_if_Used_with_Caution..html">2307 andrew gelman stats-2014-04-27-Big Data…Big Deal? Maybe, if Used with Caution.</a></p>
<p>9 0.77805853 <a title="192-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-15-Google_Refine.html">910 andrew gelman stats-2011-09-15-Google Refine</a></p>
<p>10 0.77782524 <a title="192-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-15-More_data_tools_worth_using_from_Google.html">911 andrew gelman stats-2011-09-15-More data tools worth using from Google</a></p>
<p>11 0.77403486 <a title="192-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-30-%E2%80%9CNon-statistical%E2%80%9D_statistics_tools.html">1920 andrew gelman stats-2013-06-30-“Non-statistical” statistics tools</a></p>
<p>12 0.77105385 <a title="192-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-03-NYC_Data_Skeptics_Meetup.html">1837 andrew gelman stats-2013-05-03-NYC Data Skeptics Meetup</a></p>
<p>13 0.769517 <a title="192-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-11-Migrating_your_blog_from_Movable_Type_to_WordPress.html">1530 andrew gelman stats-2012-10-11-Migrating your blog from Movable Type to WordPress</a></p>
<p>14 0.76836509 <a title="192-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-29-FindTheData.org.html">1434 andrew gelman stats-2012-07-29-FindTheData.org</a></p>
<p>15 0.76701432 <a title="192-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-12-Get_the_Data.html">569 andrew gelman stats-2011-02-12-Get the Data</a></p>
<p>16 0.76562768 <a title="192-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-08-Traffic_Prediction.html">752 andrew gelman stats-2011-06-08-Traffic Prediction</a></p>
<p>17 0.76400042 <a title="192-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-24-An_interesting_mosaic_of_a_data_programming_course.html">2345 andrew gelman stats-2014-05-24-An interesting mosaic of a data programming course</a></p>
<p>18 0.76164401 <a title="192-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Job_opening_at_an_organization_that_promotes_reproducible_research%21.html">1990 andrew gelman stats-2013-08-20-Job opening at an organization that promotes reproducible research!</a></p>
<p>19 0.75899482 <a title="192-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-11-Data_mining_efforts_for_Obama%E2%80%99s_campaign.html">951 andrew gelman stats-2011-10-11-Data mining efforts for Obama’s campaign</a></p>
<p>20 0.74445057 <a title="192-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-07-Analysis_of_Power_Law_of_Participation.html">946 andrew gelman stats-2011-10-07-Analysis of Power Law of Participation</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.013), (6, 0.024), (15, 0.067), (16, 0.073), (24, 0.053), (27, 0.054), (45, 0.264), (54, 0.015), (55, 0.015), (73, 0.014), (86, 0.034), (89, 0.011), (95, 0.013), (99, 0.255)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94186389 <a title="192-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-28-NYT_shills_for_personal_DNA_tests.html">543 andrew gelman stats-2011-01-28-NYT shills for personal DNA tests</a></p>
<p>Introduction: Kaiser  nails it .  The offending  article , by John Tierney, somehow ended up in the Science section rather than the Opinion section.  As an opinion piece (or, for that matter, a blog), Tierney’s article would be nothing special.  But I agree with Kaiser that it doesn’t work as a newspaper article.  As Kaiser notes, this story involves a bunch of statistical and empirical claims that are not well resolved by P.R. and rhetoric.</p><p>2 0.93097115 <a title="192-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-06-Statistical_inference_and_the_secret_ballot.html">1407 andrew gelman stats-2012-07-06-Statistical inference and the secret ballot</a></p>
<p>Introduction: Ring Lardner, Jr.:
  
[In 1936] I was already settled in Southern California, and it may have been that first exercise of the franchise that triggered the FBI surveillance of me that would last for decades.  I had assumed, of course, that I was enjoying the vaunted American privilege of the secret ballot.  On a wall outside my polling place on Wilshire Boulevard, however, was a compilation of the district’s registered voters:  Democrats, a long list of names; Republicans, a somewhat lesser number; and “Declines to State,” one, “Ring W. Lardner, Jr.”  The day after the election, alongside those lists were published the results:  Roosevelt, so many; Landon, so many; Browder, one.</p><p>3 0.90828347 <a title="192-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-09-I_was_at_a_meeting_a_couple_months_ago_._._..html">999 andrew gelman stats-2011-11-09-I was at a meeting a couple months ago . . .</a></p>
<p>Introduction: . . . and I decided to amuse myself by writing down all the management-speak words I heard:
 
“grappling” 
“early prototypes” 
“technology platform” 
“building block” 
“machine learning” 
“your team” 
“workspace” 
“tagging” 
“data exhaust” 
“monitoring a particular population” 
“collective intelligence” 
“communities of practice” 
“hackathon” 
“human resources . . . technologies”
 
Any one or two or three of these phrases might be fine, but put them all together and what you have is a festival of jargon.  A hackathon, indeed.</p><p>same-blog 4 0.8782326 <a title="192-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-08-Turning_pages_into_data.html">192 andrew gelman stats-2010-08-08-Turning pages into data</a></p>
<p>Introduction: There is a lot of data on the web, meant to be looked at by people, but how do you turn it into a spreadsheet people could actually  analyze  statistically? 
 
The technique to turn web pages intended for people into structured data sets intended for computers is called “screen scraping.” It has just been made easier with a wiki/community  http://scraperwiki.com/ . 
 
They provide libraries to extract information from PDF, Excel files, to automatically fill in forms and similar. Moreover, the community aspect of it should allow researchers doing similar things to get connected. It’s very good. Here’s an example of scraping  road accident data  or  port of London ship arrivals .
 
You can already find collections of structured data online, examples are  Infochimps  (“find the world’s data”), and  Freebase  (“An entity graph of people, places and things, built by a community that loves open data.”). There’s also a repository system for data,  TheData  (“An open-source application for pub</p><p>5 0.873034 <a title="192-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-27-Richard_Stallman_and_John_McCarthy.html">1031 andrew gelman stats-2011-11-27-Richard Stallman and John McCarthy</a></p>
<p>Introduction: After blogging on quirky software pioneer  Richard Stallman , I thought it appropriate to write something about recently deceased quirky software pioneer John McCarthy, who, with the exception of being bearded, seems like he was the personal and political opposite of Stallman.
 
 Here’s  a page I found of  Stallman  McCarthy quotes (compiled by Neil Craig).  It’s a mixture of the reasonable and the unreasonable (ok, I suppose the same could be said of this blog!).
 
I wonder if he and Stallman ever met and, if so, whether they had an extended conversation.  It would be like matter and anti-matter! 
   
P.S.  I flipped through McCarthy’s pages and found one of my pet peeves.  See item 3  here , which sounds so plausible but is in fact  not true  (at least, not according to the National Election Study).  As McCarthy’s Stanford colleague Mo Fiorina can tell you, otherwise well-informed people believe all sorts of things about polarization that aren’t so.  Labeling groups of Americans as “</p><p>6 0.86734354 <a title="192-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-17-More_on_the_difficulty_of_%E2%80%9Cpreaching_what_you_practice%E2%80%9D.html">1325 andrew gelman stats-2012-05-17-More on the difficulty of “preaching what you practice”</a></p>
<p>7 0.85703421 <a title="192-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-13-Indiemapper_makes_thematic_mapping_easy.html">206 andrew gelman stats-2010-08-13-Indiemapper makes thematic mapping easy</a></p>
<p>8 0.85691416 <a title="192-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-04-A_Wikipedia_whitewash.html">69 andrew gelman stats-2010-06-04-A Wikipedia whitewash</a></p>
<p>9 0.85496449 <a title="192-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-20-Could_someone_please_lock_this_guy_and_Niall_Ferguson_in_a_room_together%3F.html">1504 andrew gelman stats-2012-09-20-Could someone please lock this guy and Niall Ferguson in a room together?</a></p>
<p>10 0.84908849 <a title="192-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-08-Censoring_on_one_end%2C_%E2%80%9Coutliers%E2%80%9D_on_the_other%2C_what_can_we_do_with_the_middle%3F.html">791 andrew gelman stats-2011-07-08-Censoring on one end, “outliers” on the other, what can we do with the middle?</a></p>
<p>11 0.84505385 <a title="192-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-Upper-income_people_still_don%E2%80%99t_realize_they%E2%80%99re_upper-income.html">673 andrew gelman stats-2011-04-20-Upper-income people still don’t realize they’re upper-income</a></p>
<p>12 0.83951789 <a title="192-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-22-A_redrawing_of_the_Red-Blue_map_in_November_2010%3F.html">362 andrew gelman stats-2010-10-22-A redrawing of the Red-Blue map in November 2010?</a></p>
<p>13 0.83716309 <a title="192-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-02-The_winner%E2%80%99s_curse.html">310 andrew gelman stats-2010-10-02-The winner’s curse</a></p>
<p>14 0.82620591 <a title="192-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-Good_examples_of_lurking_variables%3F.html">1015 andrew gelman stats-2011-11-17-Good examples of lurking variables?</a></p>
<p>15 0.82444811 <a title="192-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-16-Blog_bribes%21.html">1012 andrew gelman stats-2011-11-16-Blog bribes!</a></p>
<p>16 0.81525105 <a title="192-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-28-New_app_for_learning_intro_statistics.html">735 andrew gelman stats-2011-05-28-New app for learning intro statistics</a></p>
<p>17 0.81431627 <a title="192-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-28-History_is_too_important_to_be_left_to_the_history_professors.html">2189 andrew gelman stats-2014-01-28-History is too important to be left to the history professors</a></p>
<p>18 0.81171679 <a title="192-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-14-Hipmunk_%3C_Expedia%2C_again.html">573 andrew gelman stats-2011-02-14-Hipmunk < Expedia, again</a></p>
<p>19 0.80938089 <a title="192-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-17-The_disappearing_or_non-disappearing_middle_class.html">1767 andrew gelman stats-2013-03-17-The disappearing or non-disappearing middle class</a></p>
<p>20 0.8089872 <a title="192-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-24-A_%28not_quite%29_grand_unified_theory_of_plagiarism%2C_as_applied_to_the_Wegman_case.html">728 andrew gelman stats-2011-05-24-A (not quite) grand unified theory of plagiarism, as applied to the Wegman case</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
