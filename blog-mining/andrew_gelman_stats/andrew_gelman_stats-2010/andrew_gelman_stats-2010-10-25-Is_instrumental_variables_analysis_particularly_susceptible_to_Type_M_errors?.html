<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>368 andrew gelman stats-2010-10-25-Is instrumental variables analysis particularly susceptible to Type M errors?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-368" href="#">andrew_gelman_stats-2010-368</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>368 andrew gelman stats-2010-10-25-Is instrumental variables analysis particularly susceptible to Type M errors?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-368-html" href="http://andrewgelman.com/2010/10/25/is_instrumental/">html</a></p><p>Introduction: Hendrik Juerges writes:
  
I am an applied econometrician. The reason I am writing is that I am pondering a question for some time now and I am curious whether you have any views on it.


One problem the practitioner of instrumental variables estimation faces is large standard errors even with very large samples. Part of the problem is of course that one estimates a ratio. Anyhow, more often than not, I and many other researchers I know end up with large point estimates and standard errors when trying IV on a problem. Sometimes some of us are lucky and get a statistically significant result. Those estimates that make it beyond the 2 standard error threshold are often ridiculously large (one famous example in my line of research being Lleras-Muney’s estimates of the 10% effect of one year of schooling on mortality). The standard defense here is that IV estimates the complier-specific causal effect (which is mathematically correct). But still, I find many of the IV results (including my</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The reason I am writing is that I am pondering a question for some time now and I am curious whether you have any views on it. [sent-2, score-0.321]
</p><p>2 One problem the practitioner of instrumental variables estimation faces is large standard errors even with very large samples. [sent-3, score-1.51]
</p><p>3 Part of the problem is of course that one estimates a ratio. [sent-4, score-0.37]
</p><p>4 Anyhow, more often than not, I and many other researchers I know end up with large point estimates and standard errors when trying IV on a problem. [sent-5, score-1.004]
</p><p>5 Sometimes some of us are lucky and get a statistically significant result. [sent-6, score-0.094]
</p><p>6 Those estimates that make it beyond the 2 standard error threshold are often ridiculously large (one famous example in my line of research being Lleras-Muney’s estimates of the 10% effect of one year of schooling on mortality). [sent-7, score-1.599]
</p><p>7 The standard defense here is that IV estimates the complier-specific causal effect (which is mathematically correct). [sent-8, score-0.759]
</p><p>8 Now comes my question: Could it be that IV is particularly prone to “type M” errors? [sent-10, score-0.11]
</p><p>9 My reply:   I’ve never actually done any instrumental variables analysis, Bayesian or otherwise. [sent-14, score-0.37]
</p><p>10 But I do recall that Imbens and Rubin discuss Bayesian solutions in one of their articles, and I think they made the point that the inclusion of a little bit of prior information can help a lot. [sent-15, score-0.425]
</p><p>11 In any case, I agree that if standard errors are large, then you’ll be subject to Type M errors. [sent-16, score-0.444]
</p><p>12 My own way of understanding IV  is to think of the instrument has having a joint effect on the intermediate and final outcomes. [sent-18, score-0.471]
</p><p>13 Often this can be clear enough, and you don’t need to actually divide the coefficients. [sent-19, score-0.091]
</p><p>14 And  here  are my more general thoughts on the difficulty of estimating ratios. [sent-20, score-0.13]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('iv', 0.514), ('estimates', 0.24), ('errors', 0.224), ('standard', 0.22), ('large', 0.209), ('instrumental', 0.183), ('anyhow', 0.132), ('practitioner', 0.132), ('effect', 0.124), ('ironclad', 0.122), ('type', 0.119), ('ridiculously', 0.118), ('schooling', 0.118), ('pondering', 0.115), ('imbens', 0.112), ('often', 0.111), ('prone', 0.11), ('inclusion', 0.11), ('bayesian', 0.109), ('faces', 0.104), ('variables', 0.102), ('instrument', 0.1), ('mortality', 0.099), ('lucky', 0.094), ('solutions', 0.093), ('beauty', 0.093), ('intermediate', 0.092), ('help', 0.091), ('divide', 0.091), ('mathematically', 0.091), ('ratios', 0.09), ('threshold', 0.086), ('done', 0.085), ('defense', 0.084), ('joint', 0.079), ('final', 0.076), ('rubin', 0.074), ('sex', 0.071), ('views', 0.07), ('curious', 0.07), ('one', 0.069), ('difficulty', 0.067), ('question', 0.066), ('estimation', 0.066), ('rule', 0.065), ('basically', 0.065), ('famous', 0.064), ('estimating', 0.063), ('recall', 0.062), ('problem', 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="368-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Is_instrumental_variables_analysis_particularly_susceptible_to_Type_M_errors%3F.html">368 andrew gelman stats-2010-10-25-Is instrumental variables analysis particularly susceptible to Type M errors?</a></p>
<p>Introduction: Hendrik Juerges writes:
  
I am an applied econometrician. The reason I am writing is that I am pondering a question for some time now and I am curious whether you have any views on it.


One problem the practitioner of instrumental variables estimation faces is large standard errors even with very large samples. Part of the problem is of course that one estimates a ratio. Anyhow, more often than not, I and many other researchers I know end up with large point estimates and standard errors when trying IV on a problem. Sometimes some of us are lucky and get a statistically significant result. Those estimates that make it beyond the 2 standard error threshold are often ridiculously large (one famous example in my line of research being Lleras-Muney’s estimates of the 10% effect of one year of schooling on mortality). The standard defense here is that IV estimates the complier-specific causal effect (which is mathematically correct). But still, I find many of the IV results (including my</p><p>2 0.18403108 <a title="368-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-23-Combining_survey_data_obtained_using_different_modes_of_sampling.html">777 andrew gelman stats-2011-06-23-Combining survey data obtained using different modes of sampling</a></p>
<p>Introduction: I’m involved (with Irv Garfinkel and others) in a planned survey of New York City residents.  It’s hard to reach people in the city–not everyone will answer their mail or phone, and you can’t send an interviewer door-to-door in a locked apartment building.  (I think it violates IRB to have a plan of pushing all the buzzers by the entrance and hoping someone will let you in.)  So the plan is to use multiple modes, including phone, in person household, random street intercepts and mail.
 
The question then is how to combine these samples.  My suggested approach is to divide the population into poststrata based on various factors (age, ethnicity, family type, housing type, etc), then to pool responses within each poststratum, then to runs some regressions including postratsta and also indicators for mode, to understand how respondents from different modes differ, after controlling for the demographic/geographic adjustments.
 
Maybe this has already been done and written up somewhere?
 
P.</p><p>3 0.18210606 <a title="368-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-02-An_IV_won%E2%80%99t_save_your_life_if_the_line_is_tangled.html">550 andrew gelman stats-2011-02-02-An IV won’t save your life if the line is tangled</a></p>
<p>Introduction: Alex Tabarrok  quotes  Randall Morck and Bernard Yeung on difficulties with instrumental variables.  This reminded me of some related things I’ve written.
 
In the official story the causal question comes first and then the clever researcher comes up with an IV.  I suspect that often it’s the other way around:  you find a natural experiment and look at the consequences that flow from it.  And maybe that’s not such a bad thing.  See section 4 of  this article .
 
More generally, I think economists and political scientists are currently a bit overinvested in identification strategies.  I agree with Heckman’s point (as I understand it) that ultimately we should be building models that work for us rather than always thinking we can get causal inference on the cheap, as it were, by some trick or another.  (This is a point I briefly discuss in a couple places  here  and also in my recent paper for the causality volume that Don Green etc are involved with.)
 
I recently had this discussion wi</p><p>4 0.14835873 <a title="368-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>Introduction: David Hsu writes: 
   
 I have a (perhaps) simple question about uncertainty in parameter estimates using multilevel models — what is an appropriate threshold for measure parameter uncertainty in a multilevel model? 
 
The reason why I ask is that I set out to do a crossed two-way model with two varying intercepts, similar to your flight simulator example in your 2007 book.  The difference is that I have a lot of predictors specific to each cell (I think equivalent to airport and pilot in your example), and I find after modeling this in JAGS, I happily find that the predictors are much less important than the variability by cell (airport and pilot effects).  Happily because this is what I am writing a paper about.
 
However, I then went to check subsets of predictors using lm() and lmer().  I understand that they all use different estimation methods, but what I can’t figure out is why the errors on all of the coefficient estimates are *so* different.  
 
For example, using JAGS, and th</p><p>5 0.13777621 <a title="368-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>Introduction: Nick Firoozye writes:
  
While I am absolutely sympathetic to the Bayesian agenda I am often troubled by the requirement of having priors. We must have priors on the parameter of an infinite number of model we have never seen before and I find this troubling. There is a similarly troubling problem in economics of utility theory. Utility is on consumables. To be complete a consumer must assign utility to all sorts of things they never would have encountered. More recent versions of utility theory instead make consumption goods a portfolio of attributes. Cadillacs are x many units of luxury y of transport etc etc. And we can automatically have personal utilities to all these attributes.  


I don’t ever see parameters. Some model have few and some have hundreds. Instead, I see data. So I don’t know how to have an opinion on parameters themselves. Rather I think it far more natural to have opinions on the behavior of models. The prior predictive density is a good and sensible notion. Also</p><p>6 0.13399239 <a title="368-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>7 0.12916201 <a title="368-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-14-Subtleties_with_measurement-error_models_for_the_evaluation_of_wacky_claims.html">803 andrew gelman stats-2011-07-14-Subtleties with measurement-error models for the evaluation of wacky claims</a></p>
<p>8 0.12510408 <a title="368-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>9 0.12132566 <a title="368-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-Write_This_Book.html">1605 andrew gelman stats-2012-12-04-Write This Book</a></p>
<p>10 0.11756741 <a title="368-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>11 0.1115354 <a title="368-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>12 0.11011319 <a title="368-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-17-Is_the_internet_causing_half_the_rapes_in_Norway%3F__I_wanna_see_the_scatterplot..html">716 andrew gelman stats-2011-05-17-Is the internet causing half the rapes in Norway?  I wanna see the scatterplot.</a></p>
<p>13 0.10654887 <a title="368-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>14 0.1054461 <a title="368-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-14-Questions_about_a_study_of_charter_schools.html">957 andrew gelman stats-2011-10-14-Questions about a study of charter schools</a></p>
<p>15 0.10473032 <a title="368-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>16 0.1035753 <a title="368-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-15-The_UN_Plot_to_Force_Bayesianism_on_Unsuspecting_Americans_%28penalized_B-Spline_edition%29.html">2135 andrew gelman stats-2013-12-15-The UN Plot to Force Bayesianism on Unsuspecting Americans (penalized B-Spline edition)</a></p>
<p>17 0.10299367 <a title="368-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-01-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Cox_and_Mayo.html">1149 andrew gelman stats-2012-02-01-Philosophy of Bayesian statistics:  my reactions to Cox and Mayo</a></p>
<p>18 0.098503068 <a title="368-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>19 0.098317072 <a title="368-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-09-My_homework_success.html">896 andrew gelman stats-2011-09-09-My homework success</a></p>
<p>20 0.098107524 <a title="368-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-How_do_you_interpret_standard_errors_from_a_regression_fit_to_the_entire_population%3F.html">972 andrew gelman stats-2011-10-25-How do you interpret standard errors from a regression fit to the entire population?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.214), (1, 0.088), (2, 0.04), (3, -0.094), (4, 0.004), (5, -0.012), (6, 0.014), (7, 0.039), (8, 0.027), (9, -0.023), (10, 0.01), (11, -0.037), (12, 0.054), (13, 0.011), (14, 0.05), (15, 0.003), (16, -0.035), (17, 0.016), (18, -0.013), (19, 0.059), (20, -0.037), (21, 0.018), (22, 0.033), (23, 0.021), (24, 0.025), (25, 0.001), (26, 0.027), (27, -0.053), (28, -0.025), (29, -0.021), (30, 0.065), (31, -0.005), (32, -0.026), (33, -0.007), (34, 0.035), (35, -0.0), (36, -0.014), (37, -0.01), (38, 0.002), (39, -0.014), (40, -0.013), (41, -0.029), (42, -0.063), (43, 0.024), (44, -0.003), (45, -0.022), (46, 0.018), (47, 0.025), (48, 0.017), (49, 0.034)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98200679 <a title="368-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Is_instrumental_variables_analysis_particularly_susceptible_to_Type_M_errors%3F.html">368 andrew gelman stats-2010-10-25-Is instrumental variables analysis particularly susceptible to Type M errors?</a></p>
<p>Introduction: Hendrik Juerges writes:
  
I am an applied econometrician. The reason I am writing is that I am pondering a question for some time now and I am curious whether you have any views on it.


One problem the practitioner of instrumental variables estimation faces is large standard errors even with very large samples. Part of the problem is of course that one estimates a ratio. Anyhow, more often than not, I and many other researchers I know end up with large point estimates and standard errors when trying IV on a problem. Sometimes some of us are lucky and get a statistically significant result. Those estimates that make it beyond the 2 standard error threshold are often ridiculously large (one famous example in my line of research being Lleras-Muney’s estimates of the 10% effect of one year of schooling on mortality). The standard defense here is that IV estimates the complier-specific causal effect (which is mathematically correct). But still, I find many of the IV results (including my</p><p>2 0.81405449 <a title="368-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>Introduction: Joshua Vogelstein asks for my thoughts as  a Bayesian on the above topic.  So here they are (briefly):
 
The concept of the bias-variance tradeoff can be useful if you don’t take it too seriously.  The basic idea is as follows:  if you’re estimating something, you can slice your data finer and finer, or perform more and more adjustments, each time getting a purer—and less biased—estimate.  But each subdivision or each adjustment reduces your sample size or increases potential estimation error, hence the variance of your estimate goes up.
 
That story is real.  In lots and lots of examples, there’s a continuum between a completely unadjusted general estimate (high bias, low variance) and a specific, focused, adjusted estimate (low bias, high variance).
 
Suppose, for example, you’re using data from a large experiment to estimate the effect of a treatment on a fairly narrow group, say, white men between the ages of 45 and 50.  At one extreme, you could just take the estimated treatment e</p><p>3 0.79882944 <a title="368-lsi-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-21-Everything_I_need_to_know_about_Bayesian_statistics%2C_I_learned_in_eight_schools..html">2180 andrew gelman stats-2014-01-21-Everything I need to know about Bayesian statistics, I learned in eight schools.</a></p>
<p>Introduction: This post is by Phil.
 
I’m aware that there  are  some people who use a Bayesian approach largely because it allows them to provide a highly informative prior distribution based subjective judgment, but that is not the appeal of Bayesian methods for a lot of us practitioners. It’s disappointing and surprising, twenty years after my initial experiences, to still hear highly informed professional statisticians who think that what distinguishes Bayesian statistics from Frequentist statistics is “subjectivity” ( as seen in  a recent blog post and its comments ).
 
 My first encounter with Bayesian statistics was just over 20 years ago. I was a postdoc at Lawrence Berkeley National Laboratory, with a new PhD in theoretical atomic physics but working on various problems related to the geographical and statistical distribution of indoor radon (a naturally occurring radioactive gas that can be dangerous if present at high concentrations). One of the issues I ran into right at the start was th</p><p>4 0.79035288 <a title="368-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-08-Is_linear_regression_unethical_in_that_it_gives_more_weight_to_cases_that_are_far_from_the_average%3F.html">1409 andrew gelman stats-2012-07-08-Is linear regression unethical in that it gives more weight to cases that are far from the average?</a></p>
<p>Introduction: I received the following note from someone who’d like to remain anonymous: 
  
  
I read  your post  on ethics and statistics, and the comments therein, with much interest.


I did notice, however, that most of the dialogue was about ethical behavior of scientists.  Herein I’d like to suggest a different take, one that focuses on the statistical methods of scientists.


For example, fitting a line to a scatter plot of data using OLS [linear regression] gives more weight to outliers.  If each data point represents a person we are weighting people differently.  And surely the ethical implications are different if we use a least absolute deviation estimator.


Recently I reviewed a paper where the authors claimed one advantage of non-parametric rank-based tests is their robustness to outliers.  Again, maybe that outlier is the 10th person who dies from an otherwise beneficial medicine.  Should we ignore him in assessing the effect of the medicine?


I guess this gets me partly into loss f</p><p>5 0.77771062 <a title="368-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-Ratios_where_the_numerator_and_denominator_both_change_signs.html">248 andrew gelman stats-2010-09-01-Ratios where the numerator and denominator both change signs</a></p>
<p>Introduction: A couple years ago, I used a question by Benjamin Kay as  an excuse  to write that it’s usually a bad idea to study a ratio whose denominator has uncertain sign.  As I wrote then:
  
Similar problems arise with marginal cost-benefit ratios, LD50 in logistic regression (see chapter 3 of Bayesian Data Analysis for an example), instrumental variables, and the Fieller-Creasy problem in theoretical statistics. . . . In general, the story is that the ratio completely changes in interpretation when the denominator changes sign.
  
More recently, Kay sent in a related question:
  
 
I [Kay] wondered if you have any advice on handling ratios when the signs change as a result of a parameter.


I have three functions, one C * x^a, another D * x^a, and a third f(x,a) in my paper such that:


C * x^a, < f(x,a) < D * x^a


C,D and a all have the same signs. 
We can divide through by C * x^a but the results depend on the sign of C either


1< f(x,a) /  C * x^a < D * x^a /  C * x^a,


or


1  /  f(x,a</p><p>6 0.77497762 <a title="368-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-02-So-called_Bayesian_hypothesis_testing_is_just_as_bad_as_regular_hypothesis_testing.html">643 andrew gelman stats-2011-04-02-So-called Bayesian hypothesis testing is just as bad as regular hypothesis testing</a></p>
<p>7 0.76443148 <a title="368-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-13-%E2%80%9CWhat_are_some_situations_in_which_the_classical_approach_%28or_a_naive_implementation_of_it%2C_based_on_cookbook_recipes%29_gives_worse_results_than_a_Bayesian_approach%2C_results_that_actually_impeded_the_science%3F%E2%80%9D.html">2099 andrew gelman stats-2013-11-13-“What are some situations in which the classical approach (or a naive implementation of it, based on cookbook recipes) gives worse results than a Bayesian approach, results that actually impeded the science?”</a></p>
<p>8 0.75678784 <a title="368-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-21-Fundamental_difficulty_of_inference_for_a_ratio_when_the_denominator_could_be_positive_or_negative.html">775 andrew gelman stats-2011-06-21-Fundamental difficulty of inference for a ratio when the denominator could be positive or negative</a></p>
<p>9 0.75223279 <a title="368-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-24-%E2%80%9CEdlin%E2%80%99s_rule%E2%80%9D_for_routinely_scaling_down_published_estimates.html">2223 andrew gelman stats-2014-02-24-“Edlin’s rule” for routinely scaling down published estimates</a></p>
<p>10 0.75199395 <a title="368-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-03-is_it_possible_to_%E2%80%9Coverstratify%E2%80%9D_when_assigning_a_treatment_in_a_randomized_control_trial%3F.html">553 andrew gelman stats-2011-02-03-is it possible to “overstratify” when assigning a treatment in a randomized control trial?</a></p>
<p>11 0.75031388 <a title="368-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-13-%E2%80%9CThe_truth_wears_off%3A__Is_there_something_wrong_with_the_scientific_method%3F%E2%80%9D.html">466 andrew gelman stats-2010-12-13-“The truth wears off:  Is there something wrong with the scientific method?”</a></p>
<p>12 0.7492488 <a title="368-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-15-Regression_discontinuity_designs%3A__looking_for_the_keys_under_the_lamppost%3F.html">518 andrew gelman stats-2011-01-15-Regression discontinuity designs:  looking for the keys under the lamppost?</a></p>
<p>13 0.74778873 <a title="368-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-02-The_winner%E2%80%99s_curse.html">310 andrew gelman stats-2010-10-02-The winner’s curse</a></p>
<p>14 0.73279548 <a title="368-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-23-Combining_survey_data_obtained_using_different_modes_of_sampling.html">777 andrew gelman stats-2011-06-23-Combining survey data obtained using different modes of sampling</a></p>
<p>15 0.73132676 <a title="368-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-I_doubt_they_cheated.html">1971 andrew gelman stats-2013-08-07-I doubt they cheated</a></p>
<p>16 0.73022729 <a title="368-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>17 0.72753108 <a title="368-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-02-%E2%80%9CBased_on_my_experiences%2C_I_think_you_could_make_general_progress_by_constructing_a_solution_to_your_specific_problem.%E2%80%9D.html">1441 andrew gelman stats-2012-08-02-“Based on my experiences, I think you could make general progress by constructing a solution to your specific problem.”</a></p>
<p>18 0.72529536 <a title="368-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-23-Scientists_can_read_your_mind_._._._as_long_as_the%E2%80%99re_allowed_to_look_at_more_than_one_place_in_your_brain_and_then_make_a_prediction_after_seeing_what_you_actually_did.html">106 andrew gelman stats-2010-06-23-Scientists can read your mind . . . as long as the’re allowed to look at more than one place in your brain and then make a prediction after seeing what you actually did</a></p>
<p>19 0.72497916 <a title="368-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<p>20 0.72476083 <a title="368-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-09-Keli_Liu_and_Xiao-Li_Meng_on_Simpson%E2%80%99s_paradox.html">2204 andrew gelman stats-2014-02-09-Keli Liu and Xiao-Li Meng on Simpson’s paradox</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.014), (16, 0.038), (24, 0.142), (53, 0.02), (64, 0.013), (72, 0.021), (76, 0.205), (86, 0.05), (95, 0.029), (99, 0.362)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97976625 <a title="368-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-28-A_calibrated_Cook_gives_Dems_the_edge_in_Nov%2C_sez_Sandy.html">300 andrew gelman stats-2010-09-28-A calibrated Cook gives Dems the edge in Nov, sez Sandy</a></p>
<p>Introduction: Sandy Gordon sends along this  fun little paper  forecasting the 2010 midterm election using expert predictions (the Cook and Rothenberg Political Reports).  Gordon’s gimmick is that he uses past performance to calibrate the reports’ judgments based on “solid,” “likely,” “leaning,” and “toss-up” categories, and then he uses the calibrated versions of the current predictions to make his forecast.
 
As I wrote a  few weeks ago  in response to Nate’s forecasts, I think the right way to go, if you really want to forecast the election outcome, is to use national information to predict the national swing and then do regional, state, and district-level adjustments using whatever local information is available.  I don’t see the point of using  only  the expert forecasts and no other data.
 
Still, Gordon is bringing new information (his calibrations) to the table, so I wanted to share it with you.  Ultimately I like the throw-in-everything approach that Nate uses (although I think Nate’s descr</p><p>2 0.97474623 <a title="368-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-02-Roads%2C_traffic%2C_and_the_importance_in_decision_analysis_of_carefully_examining_your_goals.html">988 andrew gelman stats-2011-11-02-Roads, traffic, and the importance in decision analysis of carefully examining your goals</a></p>
<p>Introduction: Sandeep Baliga  writes : 
  
  
[In a  recent study , Gilles Duranton and Matthew Turner write:]

 
For interstate highways in metropolitan areas we [Duranton and Turner] ﬁnd that VKT (vehicle kilometers traveled) increases one for one with interstate highways, conﬁrming the fundamental law of highway congestion.’
 

Provision of public transit also simply leads to the people taking public transport being replaced by drivers on the road.  Therefore:

 
These ﬁndings suggest that both road capacity expansions and extensions to public transit are not appropriate policies with which to combat trafﬁc congestion. This leaves congestion pricing as the main candidate tool to curb trafﬁc congestion.
 
  
To which I reply:  Sure,  if your goal is to curb traffic congestion .  But what sort of goal is that?  Thinking like a microeconomist, my policy goal is to increase people’s utility.  Sure, traffic congestion is annoying, but there must be some advantages to driving on that crowded road or pe</p><p>3 0.972408 <a title="368-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-28-A_convenience_sample_and_selected_treatments.html">1551 andrew gelman stats-2012-10-28-A convenience sample and selected treatments</a></p>
<p>Introduction: Charlie Saunders writes:
  
A study has recently been  published  in the New England Journal of Medicine (NEJM) which uses survival analysis to examine long-acting reversible contraception (e.g. intrauterine devices [IUDs]) vs. short-term commonly prescribed methods of contraception (e.g. oral contraceptive pills) on unintended pregnancies.


The authors use a convenience sample of over 7,000 women.  I am not well versed-enough in sampling theory to determine the appropriateness of this but it would seem that the use of a non-probability sampling would be a significant drawback.  If you could give me your opinion on this, I would appreciate it.


The NEJM is one of the top medical journals in the country.  Could this type of sampling method coupled with this method of analysis be published in a journal like JASA?
  
My reply:  There are two concerns, first that it is a convenience sample and thus not representative of the population, and second that the treatments are chosen rather tha</p><p>4 0.96250588 <a title="368-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-29-A_Ph.D._thesis_is_not_really_a_marathon.html">1351 andrew gelman stats-2012-05-29-A Ph.D. thesis is not really a marathon</a></p>
<p>Introduction: Thomas Basbøll  writes :
  
A blog called The Thesis Whisperer was recently pointed out to me. I [Basbøll] haven’t looked at it closely, but I’ll be reading it regularly for a while before I recommend it. I’m sure it’s a good place to go to discover that you’re not alone, especially when you’re struggling with your dissertation.  One post  caught my eye immediately. It suggested that writing a thesis is not a sprint, it’s a marathon.


As a metaphorical adjustment to a particular attitude about writing, it’s probably going to help some people. But if we think it through, it’s not really a very good analogy. No one is really a “sprinter”; and writing a dissertation is nothing like running a marathon. . . .


Here’s Ben’s explication of the analogy at the Thesis Whisperer, which seems initially plausible.

 
…writing a dissertation is a lot like running a marathon. They are both endurance events, they last a long time and they require a consistent and carefully calculated amount of effor</p><p>same-blog 5 0.95213151 <a title="368-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Is_instrumental_variables_analysis_particularly_susceptible_to_Type_M_errors%3F.html">368 andrew gelman stats-2010-10-25-Is instrumental variables analysis particularly susceptible to Type M errors?</a></p>
<p>Introduction: Hendrik Juerges writes:
  
I am an applied econometrician. The reason I am writing is that I am pondering a question for some time now and I am curious whether you have any views on it.


One problem the practitioner of instrumental variables estimation faces is large standard errors even with very large samples. Part of the problem is of course that one estimates a ratio. Anyhow, more often than not, I and many other researchers I know end up with large point estimates and standard errors when trying IV on a problem. Sometimes some of us are lucky and get a statistically significant result. Those estimates that make it beyond the 2 standard error threshold are often ridiculously large (one famous example in my line of research being Lleras-Muney’s estimates of the 10% effect of one year of schooling on mortality). The standard defense here is that IV estimates the complier-specific causal effect (which is mathematically correct). But still, I find many of the IV results (including my</p><p>6 0.95034558 <a title="368-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-17-Vote_Buying%3A_Evidence_from_a_List_Experiment_in_Lebanon.html">283 andrew gelman stats-2010-09-17-Vote Buying: Evidence from a List Experiment in Lebanon</a></p>
<p>7 0.95015568 <a title="368-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-26-If_statistics_is_so_significantly_great%2C_why_don%E2%80%99t_statisticians_use_statistics%3F.html">51 andrew gelman stats-2010-05-26-If statistics is so significantly great, why don’t statisticians use statistics?</a></p>
<p>8 0.94826984 <a title="368-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-10-The_recursion_of_pop-econ.html">1850 andrew gelman stats-2013-05-10-The recursion of pop-econ</a></p>
<p>9 0.94403362 <a title="368-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-02-7_ways_to_separate_errors_from_statistics.html">1835 andrew gelman stats-2013-05-02-7 ways to separate errors from statistics</a></p>
<p>10 0.94339216 <a title="368-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Stephen_Kosslyn%E2%80%99s_principles_of_graphics_and_one_more%3A__There%E2%80%99s_no_need_to_cram_everything_into_a_single_plot.html">1609 andrew gelman stats-2012-12-06-Stephen Kosslyn’s principles of graphics and one more:  There’s no need to cram everything into a single plot</a></p>
<p>11 0.9432615 <a title="368-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-12-Election_symposium_at_Columbia_Journalism_School.html">337 andrew gelman stats-2010-10-12-Election symposium at Columbia Journalism School</a></p>
<p>12 0.94220877 <a title="368-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>13 0.92762148 <a title="368-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-01-%24241%2C364.83_%E2%80%93_%2413%2C000_%3D_%24228%2C364.83.html">1600 andrew gelman stats-2012-12-01-$241,364.83 – $13,000 = $228,364.83</a></p>
<p>14 0.92404902 <a title="368-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-14-Causal_inference_in_economics.html">32 andrew gelman stats-2010-05-14-Causal inference in economics</a></p>
<p>15 0.92226291 <a title="368-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-22-Goal%3A__Rules_for_Turing_chess.html">1818 andrew gelman stats-2013-04-22-Goal:  Rules for Turing chess</a></p>
<p>16 0.91721642 <a title="368-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-08-Econ_debate_about_prices_at_a_fancy_restaurant.html">1105 andrew gelman stats-2012-01-08-Econ debate about prices at a fancy restaurant</a></p>
<p>17 0.91144997 <a title="368-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-24-Economists_don%E2%80%99t_think_like_accountants%E2%80%94but_maybe_they_should.html">922 andrew gelman stats-2011-09-24-Economists don’t think like accountants—but maybe they should</a></p>
<p>18 0.90892839 <a title="368-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-26-Tweeting_the_Hits%3F.html">1084 andrew gelman stats-2011-12-26-Tweeting the Hits?</a></p>
<p>19 0.90865022 <a title="368-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-13-An_Economist%E2%80%99s_Guide_to_Visualizing_Data.html">2246 andrew gelman stats-2014-03-13-An Economist’s Guide to Visualizing Data</a></p>
<p>20 0.90772855 <a title="368-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-14-Do_we_need_an_integrated_Bayesian-likelihood_inference%3F.html">467 andrew gelman stats-2010-12-14-Do we need an integrated Bayesian-likelihood inference?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
