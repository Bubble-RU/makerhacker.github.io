<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>433 andrew gelman stats-2010-11-27-One way that psychology research is different than medical research</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-433" href="#">andrew_gelman_stats-2010-433</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>433 andrew gelman stats-2010-11-27-One way that psychology research is different than medical research</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-433-html" href="http://andrewgelman.com/2010/11/27/one_way_that_ps/">html</a></p><p>Introduction: Medical researchers care about main effects, psychologists care about interactions.  In psychology, the main effects are typically obvious, and itâ&euro;&trade;s only the interactions that are worth studying.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Medical researchers care about main effects, psychologists care about interactions. [sent-1, score-1.755]
</p><p>2 In psychology, the main effects are typically obvious, and itâ&euro;&trade;s only the interactions that are worth studying. [sent-2, score-1.455]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('care', 0.427), ('main', 0.425), ('effects', 0.339), ('psychologists', 0.311), ('interactions', 0.282), ('studying', 0.265), ('medical', 0.252), ('obvious', 0.239), ('psychology', 0.211), ('typically', 0.209), ('worth', 0.2), ('researchers', 0.165)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="433-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-27-One_way_that_psychology_research_is_different_than_medical_research.html">433 andrew gelman stats-2010-11-27-One way that psychology research is different than medical research</a></p>
<p>Introduction: Medical researchers care about main effects, psychologists care about interactions.  In psychology, the main effects are typically obvious, and itâ&euro;&trade;s only the interactions that are worth studying.</p><p>2 0.15406922 <a title="433-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-10-95%25_intervals_that_I_don%E2%80%99t_believe%2C_because_they%E2%80%99re_from_a_flat_prior_I_don%E2%80%99t_believe.html">1206 andrew gelman stats-2012-03-10-95% intervals that I don’t believe, because they’re from a flat prior I don’t believe</a></p>
<p>Introduction: Arnaud Trolle (no  relation ) writes:
  
I have a question about the interpretation of (non-)overlapping of 95% credibility intervals. In a Bayesian ANOVA (a within-subjects one), I computed 95% credibility intervals about the main effects of a factor. I’d like to compare two by two the main effects across the different conditions of the factor. Can I directly interpret the (non-)overlapping of these credibility intervals and make the following statements: “As the 95% credibility intervals do not overlap, both conditions have significantly different main effects” or conversely “As the 95% credibility intervals overlap, the main effects of both conditions are not significantly different, i.e. equivalent”? 
I heard that, in the case of classical confidence intervals, the second statement is false, but what happens when working within a Bayesian framework?
  
My reply:
 
I think it makes more sense to directly look at inference for the difference.  Also, your statements about equivalence</p><p>3 0.14973705 <a title="433-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>Introduction: Stuart Buck writes:
  
I have a question about  fixed effects vs. random effects . Amongst economists who study teacher value-added, it has become common to see people saying that they estimated teacher fixed effects (via least squares dummy variables, so that there is a parameter for each teacher), but that they then applied empirical Bayes shrinkage so that the teacher effects are brought closer to the mean.  (See  this paper  by Jacob and Lefgren, for example.)


Can that really be what they are doing? Why wouldn’t they just run random (modeled) effects in the first place? I feel like there’s something I’m missing.
  
My reply:  I don’t know the full story here, but I’m thinking there are two goals, first to get an unbiased estimate of an overall treatment effect (and there the econometricians prefer so-called fixed effects; I disagree with them on this but I know where they’re coming from) and second to estimate individual teacher effects (and there it makes sense to use so-called</p><p>4 0.12661627 <a title="433-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-18-Question_on_Type_M_errors.html">963 andrew gelman stats-2011-10-18-Question on Type M errors</a></p>
<p>Introduction: Inti Pedroso writes:
  
Today during the group meeting at my new job we were revising a paper whose main conclusions were sustained by an ANOVA.


One of the first observations is that the experiment had a small sample size. Interestingly (may not so), some of the reported effects (most of them interactions) were quite large. One of the experience group members said that “there is a common wisdom that one should not believe effects from small sample sizes but [he thinks] if they [the effects] are large enough to be picked on a small study they must be real large effects”. I argued that if the sample size is small one could incur on a M-type error in which the magnitude of the effect is being over-estimated and that if larger samples are evaluated the magnitude may become smaller and also the confidence intervals. The concept of M-type error is completely new to all other members of the group (on which I am in my second week) and I was given the job of finding a suitable ref to explain</p><p>5 0.12564585 <a title="433-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>Introduction: Alexander Volfovsky and Peter Hoff  write :
  
ANOVA decompositions are a standard method for describing and estimating heterogeneity among the means of a response variable across levels of multiple categorical factors. In such a decomposition, the complete set of main effects and interaction terms can be viewed as a collection of vectors, matrices and arrays that share various index sets defined by the factor levels. For many types of categorical factors, it is plausible that an ANOVA decomposition exhibits some consistency across orders of effects, in that the levels of a factor that have similar main-effect coefficients may also have similar coefficients in higher-order interaction terms. In such a case, estimation of the higher-order interactions should be improved by borrowing information from the main effects and lower-order interactions. To take advantage of such patterns, this article introduces a class of hierarchical prior distributions for collections of interaction arrays t</p><p>6 0.1208159 <a title="433-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>7 0.11615954 <a title="433-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>8 0.11571577 <a title="433-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-21-Discussion_of_the_paper_by_Girolami_and_Calderhead_on_Bayesian_computation.html">288 andrew gelman stats-2010-09-21-Discussion of the paper by Girolami and Calderhead on Bayesian computation</a></p>
<p>9 0.11519179 <a title="433-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-17-How_can_statisticians_help_psychologists_do_their_research_better%3F.html">1860 andrew gelman stats-2013-05-17-How can statisticians help psychologists do their research better?</a></p>
<p>10 0.11439022 <a title="433-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-01-Why_big_effects_are_more_important_than_small_effects.html">1744 andrew gelman stats-2013-03-01-Why big effects are more important than small effects</a></p>
<p>11 0.11189224 <a title="433-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>12 0.11056186 <a title="433-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Fixed_effects_and_identification.html">1241 andrew gelman stats-2012-04-02-Fixed effects and identification</a></p>
<p>13 0.10216115 <a title="433-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>14 0.10191616 <a title="433-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-Varying_treatment_effects%2C_again.html">1310 andrew gelman stats-2012-05-09-Varying treatment effects, again</a></p>
<p>15 0.10159124 <a title="433-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-06-That_silly_ESP_paper_and_some_silliness_in_a_rebuttal_as_well.html">506 andrew gelman stats-2011-01-06-That silly ESP paper and some silliness in a rebuttal as well</a></p>
<p>16 0.097664572 <a title="433-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-11-Compare_p-values_from_privately_funded_medical_trials_to_those_in_publicly_funded_research%3F.html">463 andrew gelman stats-2010-12-11-Compare p-values from privately funded medical trials to those in publicly funded research?</a></p>
<p>17 0.097566217 <a title="433-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-27-Why_don%E2%80%99t_more_medical_discoveries_become_cures%3F.html">167 andrew gelman stats-2010-07-27-Why don’t more medical discoveries become cures?</a></p>
<p>18 0.093333885 <a title="433-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-04-Does_it_matter_that_a_sample_is_unrepresentative%3F__It_depends_on_the_size_of_the_treatment_interactions.html">2008 andrew gelman stats-2013-09-04-Does it matter that a sample is unrepresentative?  It depends on the size of the treatment interactions</a></p>
<p>19 0.091213338 <a title="433-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-13-A_Structural_Comparison_of_Conspicuous_Consumption_in_China_and_the_United_States.html">1854 andrew gelman stats-2013-05-13-A Structural Comparison of Conspicuous Consumption in China and the United States</a></p>
<p>20 0.091153227 <a title="433-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-26-Age_and_happiness%3A__The_pattern_isn%E2%80%99t_as_clear_as_you_might_think.html">486 andrew gelman stats-2010-12-26-Age and happiness:  The pattern isn’t as clear as you might think</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.078), (1, 0.001), (2, 0.036), (3, -0.121), (4, -0.011), (5, -0.019), (6, -0.02), (7, -0.014), (8, -0.008), (9, 0.04), (10, -0.051), (11, 0.003), (12, 0.053), (13, -0.04), (14, 0.064), (15, 0.0), (16, -0.057), (17, -0.009), (18, -0.028), (19, 0.047), (20, -0.02), (21, -0.007), (22, 0.0), (23, -0.013), (24, -0.039), (25, -0.036), (26, -0.053), (27, 0.076), (28, -0.06), (29, -0.008), (30, -0.058), (31, -0.009), (32, -0.04), (33, -0.041), (34, 0.045), (35, -0.043), (36, -0.035), (37, 0.013), (38, -0.009), (39, -0.048), (40, 0.039), (41, -0.011), (42, 0.057), (43, 0.01), (44, 0.028), (45, 0.024), (46, 0.018), (47, -0.033), (48, 0.014), (49, 0.034)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99794227 <a title="433-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-27-One_way_that_psychology_research_is_different_than_medical_research.html">433 andrew gelman stats-2010-11-27-One way that psychology research is different than medical research</a></p>
<p>Introduction: Medical researchers care about main effects, psychologists care about interactions.  In psychology, the main effects are typically obvious, and itâ&euro;&trade;s only the interactions that are worth studying.</p><p>2 0.78363729 <a title="433-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-Varying_treatment_effects%2C_again.html">1310 andrew gelman stats-2012-05-09-Varying treatment effects, again</a></p>
<p>Introduction: This time  from  Bernard Fraga and Eitan Hersh.  Once you think about it, it’s hard to imagine any nonzero treatment effects that don’t vary.  I’m glad to see this area of research becoming more prominent.  ( Here ‘s a discussion of another political science example, also of voter turnout, from a few years ago, from Avi Feller and Chris Holmes.)
 
Some of my fragmentary work on varying treatment effects is  here  (Treatment Effects in Before-After Data) and  here  (Estimating Incumbency Advantage and Its Variation, as an Example of a Before–After Study).</p><p>3 0.75964886 <a title="433-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>Introduction: Stuart Buck writes:
  
I have a question about  fixed effects vs. random effects . Amongst economists who study teacher value-added, it has become common to see people saying that they estimated teacher fixed effects (via least squares dummy variables, so that there is a parameter for each teacher), but that they then applied empirical Bayes shrinkage so that the teacher effects are brought closer to the mean.  (See  this paper  by Jacob and Lefgren, for example.)


Can that really be what they are doing? Why wouldn’t they just run random (modeled) effects in the first place? I feel like there’s something I’m missing.
  
My reply:  I don’t know the full story here, but I’m thinking there are two goals, first to get an unbiased estimate of an overall treatment effect (and there the econometricians prefer so-called fixed effects; I disagree with them on this but I know where they’re coming from) and second to estimate individual teacher effects (and there it makes sense to use so-called</p><p>4 0.71865672 <a title="433-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-29-Decline_Effect_in_Linguistics%3F.html">1400 andrew gelman stats-2012-06-29-Decline Effect in Linguistics?</a></p>
<p>Introduction: Josef Fruehwald  writes :
  
In the past few years, the empirical foundations of the social sciences, especially Psychology, have been coming under increased scrutiny and criticism. For example, there was the New Yorker piece from 2010 called “The Truth Wears Off” about the “decline effect,” or how the effect size of a phenomenon appears to decrease over time. . . .


I [Fruehwald] am a linguist. Do the problems facing psychology face me? To really answer that, I first have to decide which explanation for the decline effect I think is most likely, and I think Andrew Gelman’s proposal is a good candidate:

 
The short story is that if you screen for statistical significance when estimating small effects, you will necessarily overestimate the magnitudes of effects, sometimes by a huge amount.
 

I’ve put together some R code to demonstrate this point. Let’s say I’m looking at two populations, and unknown to me as a researcher, there is a small difference between the two, even though they</p><p>5 0.71286923 <a title="433-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-18-Question_on_Type_M_errors.html">963 andrew gelman stats-2011-10-18-Question on Type M errors</a></p>
<p>Introduction: Inti Pedroso writes:
  
Today during the group meeting at my new job we were revising a paper whose main conclusions were sustained by an ANOVA.


One of the first observations is that the experiment had a small sample size. Interestingly (may not so), some of the reported effects (most of them interactions) were quite large. One of the experience group members said that “there is a common wisdom that one should not believe effects from small sample sizes but [he thinks] if they [the effects] are large enough to be picked on a small study they must be real large effects”. I argued that if the sample size is small one could incur on a M-type error in which the magnitude of the effect is being over-estimated and that if larger samples are evaluated the magnitude may become smaller and also the confidence intervals. The concept of M-type error is completely new to all other members of the group (on which I am in my second week) and I was given the job of finding a suitable ref to explain</p><p>6 0.71250093 <a title="433-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-01-Why_big_effects_are_more_important_than_small_effects.html">1744 andrew gelman stats-2013-03-01-Why big effects are more important than small effects</a></p>
<p>7 0.69984311 <a title="433-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>8 0.6797576 <a title="433-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-09-San_Fernando_Valley_cityscapes%3A__An_example_of_the_benefits_of_fractal_devastation%3F.html">2165 andrew gelman stats-2014-01-09-San Fernando Valley cityscapes:  An example of the benefits of fractal devastation?</a></p>
<p>9 0.66443354 <a title="433-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-27-%E2%80%9CWhat_Can_we_Learn_from_the_Many_Labs_Replication_Project%3F%E2%80%9D.html">2227 andrew gelman stats-2014-02-27-“What Can we Learn from the Many Labs Replication Project?”</a></p>
<p>10 0.65489513 <a title="433-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-27-Confusion_from_illusory_precision.html">1186 andrew gelman stats-2012-02-27-Confusion from illusory precision</a></p>
<p>11 0.65037745 <a title="433-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Fixed_effects_and_identification.html">1241 andrew gelman stats-2012-04-02-Fixed effects and identification</a></p>
<p>12 0.64223087 <a title="433-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-07-Stereotype_threat%21.html">1929 andrew gelman stats-2013-07-07-Stereotype threat!</a></p>
<p>13 0.63706565 <a title="433-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-25-Xihong_Lin_on_sparsity_and_density.html">2185 andrew gelman stats-2014-01-25-Xihong Lin on sparsity and density</a></p>
<p>14 0.63658637 <a title="433-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-27-Should_Mister_P_be_allowed-encouraged_to_reside_in_counter-factual_populations%3F.html">7 andrew gelman stats-2010-04-27-Should Mister P be allowed-encouraged to reside in counter-factual populations?</a></p>
<p>15 0.62920165 <a title="433-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-02-The_inevitable_problems_with_statistical_significance_and_95%25_intervals.html">1150 andrew gelman stats-2012-02-02-The inevitable problems with statistical significance and 95% intervals</a></p>
<p>16 0.60228634 <a title="433-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-23-Modeling_heterogenous_treatment_effects.html">2 andrew gelman stats-2010-04-23-Modeling heterogenous treatment effects</a></p>
<p>17 0.59716475 <a title="433-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>18 0.56987768 <a title="433-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-Fourteen_magic_words%3A_an_update.html">898 andrew gelman stats-2011-09-10-Fourteen magic words: an update</a></p>
<p>19 0.56315005 <a title="433-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-14-Subtleties_with_measurement-error_models_for_the_evaluation_of_wacky_claims.html">803 andrew gelman stats-2011-07-14-Subtleties with measurement-error models for the evaluation of wacky claims</a></p>
<p>20 0.56253964 <a title="433-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-11-How_do_we_evaluate_a_new_and_wacky_claim%3F.html">797 andrew gelman stats-2011-07-11-How do we evaluate a new and wacky claim?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.058), (16, 0.05), (21, 0.113), (24, 0.284), (99, 0.275)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99683499 <a title="433-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-27-One_way_that_psychology_research_is_different_than_medical_research.html">433 andrew gelman stats-2010-11-27-One way that psychology research is different than medical research</a></p>
<p>Introduction: Medical researchers care about main effects, psychologists care about interactions.  In psychology, the main effects are typically obvious, and itâ&euro;&trade;s only the interactions that are worth studying.</p><p>2 0.97986782 <a title="433-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>Introduction: From a recent email exchange:
 
I agree that you should never compare p-values directly.  The p-value is a strange nonlinear transformation of data that is only interpretable under the null hypothesis. Once you abandon the null (as we do when we observe something with a very low p-value), the p-value itself becomes irrelevant.  To put it another way, the p-value is a measure of evidence, it is not an estimate of effect size (as it is often treated, with the idea that a p=.001 effect is larger than a p=.01 effect, etc).  Even conditional on sample size, the p-value is not a measure of effect size.</p><p>3 0.97755742 <a title="433-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-09-My_homework_success.html">896 andrew gelman stats-2011-09-09-My homework success</a></p>
<p>Introduction: A friend writes to me:
  
You will be amused to know that students in our Bayesian Inference paper at 4th year found solutions to exercises from your book on-line.  The amazing thing was that some of them were dumb enough to copy out solutions verbatim.   However, I thought you might like to know you have done well in this class!
  
Iâ&euro;&trade;m happy to hear this.  I worked hard on those solutions!</p><p>4 0.97574449 <a title="433-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-18-Understanding_posterior_p-values.html">2029 andrew gelman stats-2013-09-18-Understanding posterior p-values</a></p>
<p>Introduction: David Kaplan writes:
  
I came across your  paper  “Understanding Posterior Predictive P-values”, and I have a question regarding your statement “If a posterior predictive p-value is 0.4, say, that means that, if we believe the model, we think there is a 40% chance that tomorrow’s value of T(y_rep) will exceed today’s T(y).” This is perfectly understandable to me and represents the idea of calibration.  However, I am unsure how this relates to statements about fit.  If T is the LR chi-square or Pearson chi-square, then your statement that there is a 40% chance that tomorrows value exceeds today’s value indicates bad fit, I think.  Yet, some literature indicates that high p-values suggest good fit.  Could you clarify this?
  
My reply:
 
I think that “fit” depends on the question being asked.  In this case, I’d say the model fits for this particular purpose, even though it might not fit for other purposes.
 
And here’s the abstract of the paper:
  
Posterior predictive p-values do not i</p><p>5 0.97454607 <a title="433-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-11-My_problem_with_the_Lindley_paradox.html">1757 andrew gelman stats-2013-03-11-My problem with the Lindley paradox</a></p>
<p>Introduction: From  a couple years ago but still relevant, I think:
  
To me, the Lindley paradox falls apart because of its noninformative prior distribution on the parameter of interest. If you really think there’s a high probability the parameter is nearly exactly zero, I don’t see the point of the model saying that you have no prior information at all on the parameter. In short: my criticism of so-called Bayesian hypothesis testing is that it’s insufficiently Bayesian.
  
P.S.  To clarify (in response to Bill’s comment below):  I’m speaking of all the examples I’ve ever worked on in social and environmental science, where in some settings I can imagine a parameter being very close to zero and in other settings I can imagine a parameter taking on just about any value in a wide range, but where I’ve never seen an example where a parameter could be  either  right at zero  or  taking on any possible value.  But such examples might occur in areas of application that I haven’t worked on.</p><p>6 0.97173715 <a title="433-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-24-Latest_in_blog_advertising.html">1080 andrew gelman stats-2011-12-24-Latest in blog advertising</a></p>
<p>7 0.9675746 <a title="433-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-19-Tradeoffs_in_information_graphics.html">1584 andrew gelman stats-2012-11-19-Tradeoffs in information graphics</a></p>
<p>8 0.96616149 <a title="433-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-22-The_kluges_of_today_are_the_textbook_solutions_of_tomorrow..html">2143 andrew gelman stats-2013-12-22-The kluges of today are the textbook solutions of tomorrow.</a></p>
<p>9 0.96575445 <a title="433-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>10 0.96258569 <a title="433-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-14-%E2%80%9CThe_best_data_visualizations_should_stand_on_their_own%E2%80%9D%3F__I_don%E2%80%99t_think_so..html">574 andrew gelman stats-2011-02-14-“The best data visualizations should stand on their own”?  I don’t think so.</a></p>
<p>11 0.96254325 <a title="433-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Adding_more_information_can_make_the_variance_go_up_%28depending_on_your_model%29.html">810 andrew gelman stats-2011-07-20-Adding more information can make the variance go up (depending on your model)</a></p>
<p>12 0.96160728 <a title="433-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>13 0.96151888 <a title="433-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-03-Setting_aside_the_politics%2C_the_debate_over_the_new_health-care_study_reveals_that_we%E2%80%99re_moving_to_a_new_high_standard_of_statistical_journalism.html">1838 andrew gelman stats-2013-05-03-Setting aside the politics, the debate over the new health-care study reveals that we’re moving to a new high standard of statistical journalism</a></p>
<p>14 0.96035177 <a title="433-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-20-Prior_beliefs_about_locations_of_decision_boundaries.html">1130 andrew gelman stats-2012-01-20-Prior beliefs about locations of decision boundaries</a></p>
<p>15 0.95985949 <a title="433-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-15-Advice_that_might_make_sense_for_individuals_but_is_negative-sum_overall.html">278 andrew gelman stats-2010-09-15-Advice that might make sense for individuals but is negative-sum overall</a></p>
<p>16 0.95935357 <a title="433-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-11-Steve_Jobs%E2%80%99s_cancer_and_science-based_medicine.html">953 andrew gelman stats-2011-10-11-Steve Jobs’s cancer and science-based medicine</a></p>
<p>17 0.95786089 <a title="433-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-10-A_defense_of_Tom_Wolfe_based_on_the_impossibility_of_the_law_of_small_numbers_in_network_structure.html">1615 andrew gelman stats-2012-12-10-A defense of Tom Wolfe based on the impossibility of the law of small numbers in network structure</a></p>
<p>18 0.95763695 <a title="433-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-21-D._Buggin.html">1465 andrew gelman stats-2012-08-21-D. Buggin</a></p>
<p>19 0.95750642 <a title="433-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-12-Probabilistic_screening_to_get_an_approximate_self-weighted_sample.html">1455 andrew gelman stats-2012-08-12-Probabilistic screening to get an approximate self-weighted sample</a></p>
<p>20 0.95738304 <a title="433-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Blogads_update.html">1240 andrew gelman stats-2012-04-02-Blogads update</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
