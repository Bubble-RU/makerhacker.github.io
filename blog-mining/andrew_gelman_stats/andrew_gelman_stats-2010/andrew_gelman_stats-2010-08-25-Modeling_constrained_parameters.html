<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>234 andrew gelman stats-2010-08-25-Modeling constrained parameters</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-234" href="#">andrew_gelman_stats-2010-234</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>234 andrew gelman stats-2010-08-25-Modeling constrained parameters</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-234-html" href="http://andrewgelman.com/2010/08/25/modeling_constr/">html</a></p><p>Introduction: Mike McLaughlin writes:
  
In general, is there any way to do MCMC with a fixed constraint?


E.g., suppose I measure the three internal angles of a triangle with errors ~dnorm(0, tau) where tau might be different for the three measurements.  This would be an easy BUGS/WinBUGS/JAGS exercise but suppose, in addition, I wanted to include prior information to the effect that the three angles had to total 180 degrees exactly.


Is this feasible? Could you point me to any BUGS model in which a constraint of this type is implemented?


Note: Even in my own (non-hierarchical) code which tends to be component-wise, random-walk Metropolis with tuned Laplacian proposals, I cannot see how I could incorporate such a constraint.
  
My reply:  See page 508 of Bayesian Data Analysis (2nd edition).  We have an example of such a model there (from  this paper  with Bois and Jiang).</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Mike McLaughlin writes:    In general, is there any way to do MCMC with a fixed constraint? [sent-1, score-0.094]
</p><p>2 , suppose I measure the three internal angles of a triangle with errors ~dnorm(0, tau) where tau might be different for the three measurements. [sent-4, score-1.875]
</p><p>3 This would be an easy BUGS/WinBUGS/JAGS exercise but suppose, in addition, I wanted to include prior information to the effect that the three angles had to total 180 degrees exactly. [sent-5, score-1.36]
</p><p>4 Could you point me to any BUGS model in which a constraint of this type is implemented? [sent-7, score-0.509]
</p><p>5 Note: Even in my own (non-hierarchical) code which tends to be component-wise, random-walk Metropolis with tuned Laplacian proposals, I cannot see how I could incorporate such a constraint. [sent-8, score-0.647]
</p><p>6 My reply:  See page 508 of Bayesian Data Analysis (2nd edition). [sent-9, score-0.075]
</p><p>7 We have an example of such a model there (from  this paper  with Bois and Jiang). [sent-10, score-0.121]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('angles', 0.439), ('tau', 0.338), ('constraint', 0.309), ('three', 0.194), ('jiang', 0.189), ('triangle', 0.189), ('mclaughlin', 0.181), ('tuned', 0.181), ('dnorm', 0.169), ('feasible', 0.169), ('bois', 0.161), ('suppose', 0.148), ('metropolis', 0.14), ('tends', 0.134), ('internal', 0.134), ('incorporate', 0.134), ('proposals', 0.132), ('implemented', 0.125), ('bugs', 0.12), ('exercise', 0.12), ('mcmc', 0.12), ('edition', 0.118), ('mike', 0.118), ('degrees', 0.116), ('fixed', 0.094), ('addition', 0.093), ('total', 0.093), ('code', 0.087), ('type', 0.085), ('note', 0.083), ('measure', 0.083), ('errors', 0.08), ('model', 0.079), ('wanted', 0.077), ('page', 0.075), ('include', 0.071), ('easy', 0.07), ('prior', 0.068), ('effect', 0.059), ('could', 0.058), ('reply', 0.058), ('see', 0.053), ('information', 0.053), ('bayesian', 0.052), ('general', 0.051), ('analysis', 0.043), ('paper', 0.042), ('different', 0.04), ('point', 0.036), ('might', 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="234-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-25-Modeling_constrained_parameters.html">234 andrew gelman stats-2010-08-25-Modeling constrained parameters</a></p>
<p>Introduction: Mike McLaughlin writes:
  
In general, is there any way to do MCMC with a fixed constraint?


E.g., suppose I measure the three internal angles of a triangle with errors ~dnorm(0, tau) where tau might be different for the three measurements.  This would be an easy BUGS/WinBUGS/JAGS exercise but suppose, in addition, I wanted to include prior information to the effect that the three angles had to total 180 degrees exactly.


Is this feasible? Could you point me to any BUGS model in which a constraint of this type is implemented?


Note: Even in my own (non-hierarchical) code which tends to be component-wise, random-walk Metropolis with tuned Laplacian proposals, I cannot see how I could incorporate such a constraint.
  
My reply:  See page 508 of Bayesian Data Analysis (2nd edition).  We have an example of such a model there (from  this paper  with Bois and Jiang).</p><p>2 0.13449201 <a title="234-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-21-Models_with_constraints.html">2342 andrew gelman stats-2014-05-21-Models with constraints</a></p>
<p>Introduction: I had an interesting conversation with Aki about monotonicity constraints.  We were discussing a particular set of Gaussian processes that we were fitting to the arsenic well-switching data (the example from the logistic regression chapter in my book with Jennifer) but some more general issues arose that I thought might interest you.
 
The idea was to fit a model where the response (the logit probability of switching wells) was constrained to be monotonically increasing in your current arsenic level and monotonically decreasing in your current distance to the closest safe well.  These constraints seem reasonable enough, but when we actually fit the model we found that doing Bayesian inference with the constraint pulled the estimate, not just toward monotonicity, but to a strong increase (for the increasing relation) or a strong decrease (for the decreasing relation).  This makes sense from a statistical standpoint because if you restrict a parameter to be nonnegative, any posterior dis</p><p>3 0.11419167 <a title="234-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Modeling_probability_data.html">1284 andrew gelman stats-2012-04-26-Modeling probability data</a></p>
<p>Introduction: Rafael Huber writes: 
  
  
I conducted an experiment in which subjects where asked to estimate the probability of a certain event given a number of information (like a wheater forecaster or a stockmarket trader). These probability estimates are the dependent variable of my experiment. My goal is to model the data with a (hierarchical) Bayesian regression. A linear equation with all the presented information (quantified as log odds) defines the mu of a normal likelihood. The tau as precision is another free parameter.


y[r] ~ dnorm( mu[r] , tau[ subj[r] ] ) 
mu[r] <- b0[ subj[r] ] + b1[ subj[r] ] * x1[r] + b2[ subj[r] ] * x2[r] + b3[ subj[r] ] * x3[r]


My problem is that I do not believe that the normal is the correct probability distribution to model probability data (â&euro;Ś because the error is limited). However, until now nobody was able to tell me how I can correctly model probability data.
  
My reply:  You can take the logit of the data before analyzing them.  That is assuming there</p><p>4 0.11373033 <a title="234-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-20-%E2%80%9CPeople_with_an_itch_to_scratch%E2%80%9D.html">101 andrew gelman stats-2010-06-20-“People with an itch to scratch”</a></p>
<p>Introduction: Derek Sonderegger writes:
  
I have just finished my Ph.D. in statistics and am currently working in applied statistics (plant ecology) using Bayesian statistics.  As the statistician in the group I only ever get the ‘hard analysis’ problems that don’t readily fit into standard models.  As I delve into the computational aspects of Bayesian analysis, I find myself increasingly frustrated with the current set of tools.  I was delighted to see  JAGS 2.0  just came out and spent yesterday happily playing with it.


My question is, where do you see the short-term future of Bayesian computing going and what can we do to steer it in a particular direction?
      
In your book with Dr Hill, you mention that you expect BUGS (or its successor) to become increasingly sophisticated and, for example, re-parameterizations that increase convergence rates would be handled automatically.  Just as R has been successful because users can extend it, I think progress here also will be made by input from ‘p</p><p>5 0.11106409 <a title="234-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-31-Using_sample_size_in_the_prior_distribution.html">547 andrew gelman stats-2011-01-31-Using sample size in the prior distribution</a></p>
<p>Introduction: Mike McLaughlin writes:
  
Consider the Seeds example in vol. 1 of the BUGS examples.  There, a binomial likelihood has a p parameter constructed, via logit, from two covariates.  What I am wondering is: Would it be legitimate, in a binomial + logit problem like this, to allow binomial p[i] to be a function of the corresponding n[i] or would that amount to using the data in the prior?  In other words, in the context of the Seeds example, is r[] the only data or is n[] data as well and therefore not permissible in a prior formulation?


I [McLaughlin] currently have a model with a common beta prior for all p[i] but would like to mitigate this commonality (a kind of James-Stein effect) when there are lots of observations for some i.  But this seems to feed the data back into the prior.  Does it really?


It also occurs to me [McLaughlin] that, perhaps, a binomial likelihood is not the one to use here (not flexible enough).
  
My reply:
 
Strictly speaking, “n” is data, and so what you wa</p><p>6 0.10800377 <a title="234-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-22-Spell-checking_example_demonstrates_key_aspects_of_Bayesian_data_analysis.html">2182 andrew gelman stats-2014-01-22-Spell-checking example demonstrates key aspects of Bayesian data analysis</a></p>
<p>7 0.095946051 <a title="234-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>8 0.089318573 <a title="234-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-18-Should_we_always_be_using_the_t_and_robit_instead_of_the_normal_and_logit%3F.html">773 andrew gelman stats-2011-06-18-Should we always be using the t and robit instead of the normal and logit?</a></p>
<p>9 0.088999793 <a title="234-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-13-You_heard_it_here_first%3A_Intense_exercise_can_suppress_appetite.html">2022 andrew gelman stats-2013-09-13-You heard it here first: Intense exercise can suppress appetite</a></p>
<p>10 0.085577913 <a title="234-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<p>11 0.085188806 <a title="234-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>12 0.085115224 <a title="234-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>13 0.084902301 <a title="234-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Cross-validation_%28What_is_it_good_for%3F%29.html">1395 andrew gelman stats-2012-06-27-Cross-validation (What is it good for?)</a></p>
<p>14 0.080712549 <a title="234-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-14-Trying_to_be_precise_about_vagueness.html">342 andrew gelman stats-2010-10-14-Trying to be precise about vagueness</a></p>
<p>15 0.080642521 <a title="234-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>16 0.07810168 <a title="234-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-08-Intro_to_splines%E2%80%94with_cool_graphs.html">1106 andrew gelman stats-2012-01-08-Intro to splines—with cool graphs</a></p>
<p>17 0.077150747 <a title="234-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>18 0.074866213 <a title="234-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-References_%28with_code%29_for_Bayesian_hierarchical_%28multilevel%29_modeling_and_structural_equation_modeling.html">2273 andrew gelman stats-2014-03-29-References (with code) for Bayesian hierarchical (multilevel) modeling and structural equation modeling</a></p>
<p>19 0.074451268 <a title="234-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-19-Updated_R_code_and_data_for_ARM.html">41 andrew gelman stats-2010-05-19-Updated R code and data for ARM</a></p>
<p>20 0.071784601 <a title="234-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.111), (1, 0.092), (2, 0.014), (3, 0.013), (4, 0.026), (5, -0.016), (6, 0.024), (7, -0.029), (8, -0.004), (9, 0.0), (10, 0.004), (11, -0.006), (12, -0.009), (13, -0.022), (14, 0.03), (15, 0.036), (16, 0.018), (17, 0.022), (18, -0.006), (19, 0.009), (20, 0.001), (21, 0.055), (22, -0.005), (23, -0.05), (24, -0.042), (25, 0.01), (26, -0.009), (27, -0.027), (28, 0.024), (29, -0.02), (30, -0.027), (31, 0.014), (32, -0.033), (33, -0.002), (34, 0.025), (35, -0.011), (36, -0.017), (37, -0.063), (38, -0.026), (39, 0.032), (40, 0.024), (41, -0.003), (42, -0.004), (43, 0.024), (44, -0.002), (45, -0.01), (46, 0.03), (47, -0.028), (48, -0.016), (49, 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96045303 <a title="234-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-25-Modeling_constrained_parameters.html">234 andrew gelman stats-2010-08-25-Modeling constrained parameters</a></p>
<p>Introduction: Mike McLaughlin writes:
  
In general, is there any way to do MCMC with a fixed constraint?


E.g., suppose I measure the three internal angles of a triangle with errors ~dnorm(0, tau) where tau might be different for the three measurements.  This would be an easy BUGS/WinBUGS/JAGS exercise but suppose, in addition, I wanted to include prior information to the effect that the three angles had to total 180 degrees exactly.


Is this feasible? Could you point me to any BUGS model in which a constraint of this type is implemented?


Note: Even in my own (non-hierarchical) code which tends to be component-wise, random-walk Metropolis with tuned Laplacian proposals, I cannot see how I could incorporate such a constraint.
  
My reply:  See page 508 of Bayesian Data Analysis (2nd edition).  We have an example of such a model there (from  this paper  with Bois and Jiang).</p><p>2 0.7514829 <a title="234-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-21-Models_with_constraints.html">2342 andrew gelman stats-2014-05-21-Models with constraints</a></p>
<p>Introduction: I had an interesting conversation with Aki about monotonicity constraints.  We were discussing a particular set of Gaussian processes that we were fitting to the arsenic well-switching data (the example from the logistic regression chapter in my book with Jennifer) but some more general issues arose that I thought might interest you.
 
The idea was to fit a model where the response (the logit probability of switching wells) was constrained to be monotonically increasing in your current arsenic level and monotonically decreasing in your current distance to the closest safe well.  These constraints seem reasonable enough, but when we actually fit the model we found that doing Bayesian inference with the constraint pulled the estimate, not just toward monotonicity, but to a strong increase (for the increasing relation) or a strong decrease (for the decreasing relation).  This makes sense from a statistical standpoint because if you restrict a parameter to be nonnegative, any posterior dis</p><p>3 0.70458776 <a title="234-lsi-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-22-Spell-checking_example_demonstrates_key_aspects_of_Bayesian_data_analysis.html">2182 andrew gelman stats-2014-01-22-Spell-checking example demonstrates key aspects of Bayesian data analysis</a></p>
<p>Introduction: One of the new examples for the third edition of Bayesian Data Analysis is a spell-checking story.   Here it is  (just start at 2/3 down on the first page, with “Spelling correction”).
 
I like this example—it demonstrates the Bayesian algebra, also gives a sense of the way that probability models (both “likelihood” and “prior”) are constructed from existing assumptions and data.  The models aren’t just specified as a mathematical exercise, they represent some statement about reality.  And the problem is close enough to our experience that we can consider ways in which the model can be criticized and improved, all in a simple example that has only three possibilities.</p><p>4 0.69803101 <a title="234-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Adding_more_information_can_make_the_variance_go_up_%28depending_on_your_model%29.html">810 andrew gelman stats-2011-07-20-Adding more information can make the variance go up (depending on your model)</a></p>
<p>Introduction: Andy McKenzie writes:
  
In their March 9 “ counterpoint ” in nature biotech to the prospect that we should try to integrate more sources of data in clinical practice (see “ point ” arguing for this), Isaac Kohane and David Margulies claim that,


“Finally, how much better is our new knowledge than older knowledge? When is the incremental benefit of a genomic variant(s) or gene expression profile relative to a family history or classic histopathology insufficient and when does it add rather than subtract variance?”  


Perhaps I am mistaken (thus this email), but it seems that this claim runs contra to the definition of conditional probability. That is, if you have a hierarchical model, and the family history / classical histopathology already suggests a parameter estimate with some variance, how could the new genomic info possibly increase the variance of that parameter estimate? Surely the question is how much variance the new genomic info reduces and whether it therefore justifies t</p><p>5 0.69192058 <a title="234-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-16-%E2%80%9CReal_data_can_be_a_pain%E2%80%9D.html">1460 andrew gelman stats-2012-08-16-“Real data can be a pain”</a></p>
<p>Introduction: Michael McLaughlin sent me the following query with the above title.
  
Some time ago, I [McLaughlin] was handed a dataset that needed to be modeled.  It was generated as follows:


1. Random navigation errors, historically a binary mixture of normal and Laplace with a common mean, were collected by observation.


2. Sadly, these data were recorded with too few decimal places so that the resulting quantization is clearly visible in a scatterplot.


3. The quantized data were then interpolated (to an unobserved location).


The final result looks like fuzzy points (small scale jitter) at quantized intervals spanning a much larger scale (the parent mixture distribution).  This fuzziness, likely ~normal or ~Laplace, results from the interpolation.  Otherwise, the data would look like a discrete analogue of the normal/Laplace mixture.


I would like to characterize the latent normal/Laplace mixture distribution but the quantization is “getting in the way”.  When I tried MCMC on this proble</p><p>6 0.68853581 <a title="234-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-14-Trying_to_be_precise_about_vagueness.html">342 andrew gelman stats-2010-10-14-Trying to be precise about vagueness</a></p>
<p>7 0.68847132 <a title="234-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-23-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1868 andrew gelman stats-2013-05-23-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>8 0.68755358 <a title="234-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-07-Bayesian_hierarchical_model_for_the_prediction_of_soccer_results.html">20 andrew gelman stats-2010-05-07-Bayesian hierarchical model for the prediction of soccer results</a></p>
<p>9 0.6868338 <a title="234-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-18-Multimodality_in_hierarchical_models.html">916 andrew gelman stats-2011-09-18-Multimodality in hierarchical models</a></p>
<p>10 0.68532175 <a title="234-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-15-Wacky_priors_can_work_well%3F.html">1723 andrew gelman stats-2013-02-15-Wacky priors can work well?</a></p>
<p>11 0.67882866 <a title="234-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-11-Convergence_Monitoring_for_Non-Identifiable_and_Non-Parametric_Models.html">1374 andrew gelman stats-2012-06-11-Convergence Monitoring for Non-Identifiable and Non-Parametric Models</a></p>
<p>12 0.67854095 <a title="234-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-20-Likelihood_thresholds_and_decisions.html">1422 andrew gelman stats-2012-07-20-Likelihood thresholds and decisions</a></p>
<p>13 0.67804956 <a title="234-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-27-Bayesian_model_averaging_or_fitting_a_larger_model.html">1999 andrew gelman stats-2013-08-27-Bayesian model averaging or fitting a larger model</a></p>
<p>14 0.67636555 <a title="234-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-05-An_example_of_Bayesian_model_averaging.html">840 andrew gelman stats-2011-08-05-An example of Bayesian model averaging</a></p>
<p>15 0.67596918 <a title="234-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Modeling_probability_data.html">1284 andrew gelman stats-2012-04-26-Modeling probability data</a></p>
<p>16 0.67059571 <a title="234-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<p>17 0.67055887 <a title="234-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-04-Bayesian_Page_Rank%3F.html">1098 andrew gelman stats-2012-01-04-Bayesian Page Rank?</a></p>
<p>18 0.66265064 <a title="234-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-08-I_Am_Too_Absolutely_Heteroskedastic_for_This_Probit_Model.html">1047 andrew gelman stats-2011-12-08-I Am Too Absolutely Heteroskedastic for This Probit Model</a></p>
<p>19 0.65438575 <a title="234-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-Transformations_for_non-normal_data.html">2176 andrew gelman stats-2014-01-19-Transformations for non-normal data</a></p>
<p>20 0.65180987 <a title="234-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-21-Finite-population_Anova_calculations_for_models_with_interactions.html">1686 andrew gelman stats-2013-01-21-Finite-population Anova calculations for models with interactions</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.02), (13, 0.318), (16, 0.055), (24, 0.112), (36, 0.039), (53, 0.056), (57, 0.021), (65, 0.042), (99, 0.208)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93472588 <a title="234-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-28-AdviseStat_47%25_Campaign_Ad.html">1514 andrew gelman stats-2012-09-28-AdviseStat 47% Campaign Ad</a></p>
<p>Introduction: Lee Wilkinson sends me this amusing ad for his new software, AdviseStat:
 
  
 
The ad is a parody, but the software is  real !</p><p>2 0.91807491 <a title="234-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-15-Things_we_do_on_sabbatical_instead_of_actually_working.html">345 andrew gelman stats-2010-10-15-Things we do on sabbatical instead of actually working</a></p>
<p>Introduction: Frank Fischer, a political scientist at Rutgers U., says his alleged plagiarism was mere sloppiness and not all that uncommon in scholarship. 
 
Iâ&euro;&trade;ve heard about plagiarism but I had no idea it occurred in political science.</p><p>3 0.89435375 <a title="234-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-I_like_lineplots.html">800 andrew gelman stats-2011-07-13-I like lineplots</a></p>
<p>Introduction: These particular lineplots  are called parallel coordinate plots.</p><p>same-blog 4 0.87086308 <a title="234-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-25-Modeling_constrained_parameters.html">234 andrew gelman stats-2010-08-25-Modeling constrained parameters</a></p>
<p>Introduction: Mike McLaughlin writes:
  
In general, is there any way to do MCMC with a fixed constraint?


E.g., suppose I measure the three internal angles of a triangle with errors ~dnorm(0, tau) where tau might be different for the three measurements.  This would be an easy BUGS/WinBUGS/JAGS exercise but suppose, in addition, I wanted to include prior information to the effect that the three angles had to total 180 degrees exactly.


Is this feasible? Could you point me to any BUGS model in which a constraint of this type is implemented?


Note: Even in my own (non-hierarchical) code which tends to be component-wise, random-walk Metropolis with tuned Laplacian proposals, I cannot see how I could incorporate such a constraint.
  
My reply:  See page 508 of Bayesian Data Analysis (2nd edition).  We have an example of such a model there (from  this paper  with Bois and Jiang).</p><p>5 0.85861427 <a title="234-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-02-The_blog_is_back.html">1559 andrew gelman stats-2012-11-02-The blog is back</a></p>
<p>Introduction: We had some security problem:  not an actual virus or anything, but a potential leak which caused Google to blacklist us.   Cord  fixed us and now weâ&euro;&trade;re fine.  Good job, Google!  Better to find the potential problem  before  there is any harm!</p><p>6 0.82134521 <a title="234-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-05-Elites_have_alcohol_problems_too%21.html">1789 andrew gelman stats-2013-04-05-Elites have alcohol problems too!</a></p>
<p>7 0.81488812 <a title="234-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-30-Why_don%E2%80%99t_we_have_peer_reviewing_for_oral_presentations%3F.html">172 andrew gelman stats-2010-07-30-Why don’t we have peer reviewing for oral presentations?</a></p>
<p>8 0.77228439 <a title="234-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-29-The_mystery_of_the_U-shaped_relationship_between_happiness_and_age.html">437 andrew gelman stats-2010-11-29-The mystery of the U-shaped relationship between happiness and age</a></p>
<p>9 0.76535976 <a title="234-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-24-Analyzing_photon_counts.html">1509 andrew gelman stats-2012-09-24-Analyzing photon counts</a></p>
<p>10 0.76289964 <a title="234-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-12-Crime_novels_for_economists.html">1852 andrew gelman stats-2013-05-12-Crime novels for economists</a></p>
<p>11 0.75434077 <a title="234-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-Apply_now_for_Earth_Institute_postdoctoral_fellowships_at_Columbia_University.html">971 andrew gelman stats-2011-10-25-Apply now for Earth Institute postdoctoral fellowships at Columbia University</a></p>
<p>12 0.75026023 <a title="234-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-24-Difficulties_in_publishing_non-replications_of_implausible_findings.html">1137 andrew gelman stats-2012-01-24-Difficulties in publishing non-replications of implausible findings</a></p>
<p>13 0.74978274 <a title="234-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-21-Data_cleaning_tool%21.html">424 andrew gelman stats-2010-11-21-Data cleaning tool!</a></p>
<p>14 0.74775207 <a title="234-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-02-RStudio_%E2%80%93_new_cross-platform_IDE_for_R.html">597 andrew gelman stats-2011-03-02-RStudio – new cross-platform IDE for R</a></p>
<p>15 0.74418378 <a title="234-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-29-When_people_meet_this_guy%2C_can_they_resist_the_temptation_to_ask_him_what_he%E2%80%99s_doing_for_breakfast%3F%3F.html">980 andrew gelman stats-2011-10-29-When people meet this guy, can they resist the temptation to ask him what he’s doing for breakfast??</a></p>
<p>16 0.74188095 <a title="234-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-07-Here%E2%80%99s_what_happened_when_I_finished_my_PhD_thesis.html">2011 andrew gelman stats-2013-09-07-Here’s what happened when I finished my PhD thesis</a></p>
<p>17 0.73891997 <a title="234-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-02-Job%21.html">1519 andrew gelman stats-2012-10-02-Job!</a></p>
<p>18 0.73617959 <a title="234-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-23-New_blog_home.html">817 andrew gelman stats-2011-07-23-New blog home</a></p>
<p>19 0.73492229 <a title="234-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-27-The_weirdest_thing_about_the_AJPH_story.html">1916 andrew gelman stats-2013-06-27-The weirdest thing about the AJPH story</a></p>
<p>20 0.73163801 <a title="234-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-02-A_important_new_survey_of_Bayesian_predictive_methods_for_model_assessment%2C_selection_and_comparison.html">1648 andrew gelman stats-2013-01-02-A important new survey of Bayesian predictive methods for model assessment, selection and comparison</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
