<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-464" href="#">andrew_gelman_stats-2010-464</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-464-html" href="http://andrewgelman.com/2010/12/12/finite-populati/">html</a></p><p>Introduction: Karri Seppa writes:
  
My topic is regional variation in the cause-specific survival of breast cancer patients across the 21 hospital districts in Finland, this component being modeled by random effects. I am interested mainly in the district-specific effects, and with a hierarchical model I can get reasonable estimates also for sparsely populated districts.


Based on the recommendation given in the book by yourself and Dr. Hill (2007) I tend to think that the finite-population variance would be an appropriate measure to summarize the overall variation across the 21 districts. However, I feel it is somewhat incoherent first to assume a Normal distribution for the district effects, involving a “superpopulation” variance parameter, and then to compute the finite-population variance from the estimated district-specific parameters. I wonder whether the finite-population variance were more appropriate in the context of a model with fixed district effects?
  
My reply:
  

 
I agree that th</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Karri Seppa writes:    My topic is regional variation in the cause-specific survival of breast cancer patients across the 21 hospital districts in Finland, this component being modeled by random effects. [sent-1, score-1.264]
</p><p>2 I am interested mainly in the district-specific effects, and with a hierarchical model I can get reasonable estimates also for sparsely populated districts. [sent-2, score-0.463]
</p><p>3 Hill (2007) I tend to think that the finite-population variance would be an appropriate measure to summarize the overall variation across the 21 districts. [sent-4, score-0.682]
</p><p>4 However, I feel it is somewhat incoherent first to assume a Normal distribution for the district effects, involving a “superpopulation” variance parameter, and then to compute the finite-population variance from the estimated district-specific parameters. [sent-5, score-0.931]
</p><p>5 I wonder whether the finite-population variance were more appropriate in the context of a model with fixed district effects? [sent-6, score-0.506]
</p><p>6 My reply:       I agree that these points can be confusing, as can be seen by the 5 different definitions of fixed/random effects that I discuss in the Anova paper. [sent-7, score-0.256]
</p><p>7 Here’s what I would say:  Your goal is to estimate what’s going on in these 21 districts. [sent-9, score-0.18]
</p><p>8 To the extent there is a “true” superpopulation, it could be thought of as representing variation over time as well as space. [sent-10, score-0.256]
</p><p>9 But, mathematically, the superpop and the associated normal (or whatever) distribution can be viewed as a tool for getting statistically efficient estimates for the 21 districts that you have. [sent-11, score-1.244]
</p><p>10 Now that you have simultaneously estimated parameters for these 21 districts, you might also be interested in ensemble properties, for example the maximum, minimum, interquartile range, or even–gasp–standard deviation of these 21 numbers. [sent-12, score-0.723]
</p><p>11 It’s well known that no point estimate in high-dimensional space can capture ensemble properties–the key paper here is a 1984 article by Tom Louis, which is referred to in one of my books (BDA or ARM). [sent-13, score-0.48]
</p><p>12 I guess what I’m saying is that you make it clear that your goal is the 21 districts and that the Bayesian inference and superpop is a tool for getting there. [sent-14, score-0.967]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('districts', 0.377), ('superpop', 0.281), ('ensemble', 0.242), ('superpopulation', 0.242), ('variance', 0.231), ('variation', 0.173), ('district', 0.168), ('properties', 0.162), ('effects', 0.159), ('tool', 0.132), ('interquartile', 0.128), ('normal', 0.119), ('sparsely', 0.116), ('estimated', 0.113), ('appropriate', 0.107), ('breast', 0.101), ('goal', 0.1), ('incoherent', 0.099), ('populated', 0.097), ('finland', 0.097), ('definitions', 0.097), ('louis', 0.096), ('hospital', 0.093), ('anova', 0.092), ('across', 0.091), ('survival', 0.091), ('distribution', 0.089), ('simultaneously', 0.088), ('regional', 0.088), ('estimates', 0.088), ('mainly', 0.086), ('patients', 0.085), ('minimum', 0.084), ('confusing', 0.084), ('component', 0.083), ('mathematically', 0.083), ('representing', 0.083), ('modeled', 0.082), ('viewed', 0.081), ('estimate', 0.08), ('summarize', 0.08), ('bda', 0.08), ('referred', 0.079), ('hill', 0.079), ('capture', 0.079), ('getting', 0.077), ('deviation', 0.076), ('interested', 0.076), ('arm', 0.075), ('tom', 0.075)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="464-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>Introduction: Karri Seppa writes:
  
My topic is regional variation in the cause-specific survival of breast cancer patients across the 21 hospital districts in Finland, this component being modeled by random effects. I am interested mainly in the district-specific effects, and with a hierarchical model I can get reasonable estimates also for sparsely populated districts.


Based on the recommendation given in the book by yourself and Dr. Hill (2007) I tend to think that the finite-population variance would be an appropriate measure to summarize the overall variation across the 21 districts. However, I feel it is somewhat incoherent first to assume a Normal distribution for the district effects, involving a “superpopulation” variance parameter, and then to compute the finite-population variance from the estimated district-specific parameters. I wonder whether the finite-population variance were more appropriate in the context of a model with fixed district effects?
  
My reply:
  

 
I agree that th</p><p>2 0.17543837 <a title="464-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-02-The_problem_of_overestimation_of_group-level_variance_parameters.html">63 andrew gelman stats-2010-06-02-The problem of overestimation of group-level variance parameters</a></p>
<p>Introduction: John Lawson writes:
  
I have been experimenting using Bayesian Methods to estimate variance components, and I have noticed that even when I use a noninformative prior, my estimates are never close to the method of moments or REML estimates. In every case I have tried, the sum of the Bayesian estimated variance components is always larger than the sum of the estimates obtained by method of moments or REML.
      
For data sets I have used that arise from a simple one-way random effects model, the Bayesian estimates of the between groups variance component is usually larger than the method of moments or REML estimates. When I use a uniform prior on the between standard deviation (as you recommended in  your 2006 paper ) rather than an inverse gamma prior on the between variance component, the between variance component is usually reduced.  However, for the dyestuff data in Davies(1949, p74), the opposite appears to be the case.


I am a worried that the Bayesian estimators of the varian</p><p>3 0.161919 <a title="464-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>Introduction: Chris Che-Castaldo writes:
  
I am trying to compute variance components for a hierarchical model where the group level has two binary predictors and their interaction. When I model each of these three predictors as N(0, tau) the model will not converge, perhaps because the number of coefficients in each batch is so small (2 for the main effects and 4 for the interaction). Although I could simply leave all these as predictors as unmodeled fixed effects, the last sentence of section 21.2 on page 462 of Gelman and Hill (2007) suggests this would not be a wise course of action:

 
For example, it is not clear how to define the (finite) standard deviation of variables that are included in interactions.
 

I am curious – is there still no clear cut way to directly compute the finite standard deviation for binary unmodeled variables that are also part of an interaction as well as the interaction itself?
  
My reply:  I’d recommend including these in your model (it’s probably easiest to do so</p><p>4 0.15020739 <a title="464-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>Introduction: Stuart Buck writes:
  
I have a question about  fixed effects vs. random effects . Amongst economists who study teacher value-added, it has become common to see people saying that they estimated teacher fixed effects (via least squares dummy variables, so that there is a parameter for each teacher), but that they then applied empirical Bayes shrinkage so that the teacher effects are brought closer to the mean.  (See  this paper  by Jacob and Lefgren, for example.)


Can that really be what they are doing? Why wouldn’t they just run random (modeled) effects in the first place? I feel like there’s something I’m missing.
  
My reply:  I don’t know the full story here, but I’m thinking there are two goals, first to get an unbiased estimate of an overall treatment effect (and there the econometricians prefer so-called fixed effects; I disagree with them on this but I know where they’re coming from) and second to estimate individual teacher effects (and there it makes sense to use so-called</p><p>5 0.14635079 <a title="464-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Adding_more_information_can_make_the_variance_go_up_%28depending_on_your_model%29.html">810 andrew gelman stats-2011-07-20-Adding more information can make the variance go up (depending on your model)</a></p>
<p>Introduction: Andy McKenzie writes:
  
In their March 9 “ counterpoint ” in nature biotech to the prospect that we should try to integrate more sources of data in clinical practice (see “ point ” arguing for this), Isaac Kohane and David Margulies claim that,


“Finally, how much better is our new knowledge than older knowledge? When is the incremental benefit of a genomic variant(s) or gene expression profile relative to a family history or classic histopathology insufficient and when does it add rather than subtract variance?”  


Perhaps I am mistaken (thus this email), but it seems that this claim runs contra to the definition of conditional probability. That is, if you have a hierarchical model, and the family history / classical histopathology already suggests a parameter estimate with some variance, how could the new genomic info possibly increase the variance of that parameter estimate? Surely the question is how much variance the new genomic info reduces and whether it therefore justifies t</p><p>6 0.13648428 <a title="464-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-28-The_incoming_moderate_Republican_congressmembers.html">377 andrew gelman stats-2010-10-28-The incoming moderate Republican congressmembers</a></p>
<p>7 0.13431656 <a title="464-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>8 0.12981232 <a title="464-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>9 0.12942354 <a title="464-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>10 0.12876923 <a title="464-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>11 0.12818645 <a title="464-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>12 0.12689057 <a title="464-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-How_do_you_interpret_standard_errors_from_a_regression_fit_to_the_entire_population%3F.html">972 andrew gelman stats-2011-10-25-How do you interpret standard errors from a regression fit to the entire population?</a></p>
<p>13 0.12462052 <a title="464-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-25-Avoiding_boundary_estimates_using_a_prior_distribution_as_regularization.html">779 andrew gelman stats-2011-06-25-Avoiding boundary estimates using a prior distribution as regularization</a></p>
<p>14 0.12270335 <a title="464-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>15 0.12256307 <a title="464-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Fixed_effects_and_identification.html">1241 andrew gelman stats-2012-04-02-Fixed effects and identification</a></p>
<p>16 0.11482206 <a title="464-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-18-Should_we_always_be_using_the_t_and_robit_instead_of_the_normal_and_logit%3F.html">773 andrew gelman stats-2011-06-18-Should we always be using the t and robit instead of the normal and logit?</a></p>
<p>17 0.1136221 <a title="464-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<p>18 0.11354622 <a title="464-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>19 0.10728025 <a title="464-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>20 0.10632322 <a title="464-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-19-The_mysterious_Gamma_%281.4%2C_0.4%29.html">669 andrew gelman stats-2011-04-19-The mysterious Gamma (1.4, 0.4)</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.173), (1, 0.121), (2, 0.091), (3, -0.04), (4, 0.023), (5, -0.007), (6, 0.047), (7, -0.023), (8, 0.002), (9, 0.041), (10, 0.015), (11, -0.011), (12, 0.046), (13, -0.034), (14, 0.054), (15, 0.004), (16, -0.058), (17, 0.031), (18, -0.008), (19, 0.032), (20, -0.02), (21, -0.006), (22, 0.045), (23, 0.008), (24, 0.031), (25, -0.026), (26, -0.083), (27, 0.092), (28, -0.017), (29, 0.016), (30, -0.022), (31, 0.008), (32, -0.028), (33, -0.056), (34, 0.036), (35, -0.001), (36, -0.013), (37, -0.039), (38, -0.009), (39, -0.005), (40, 0.015), (41, -0.01), (42, -0.038), (43, 0.05), (44, -0.055), (45, 0.021), (46, 0.049), (47, -0.011), (48, 0.006), (49, 0.005)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97308803 <a title="464-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>Introduction: Karri Seppa writes:
  
My topic is regional variation in the cause-specific survival of breast cancer patients across the 21 hospital districts in Finland, this component being modeled by random effects. I am interested mainly in the district-specific effects, and with a hierarchical model I can get reasonable estimates also for sparsely populated districts.


Based on the recommendation given in the book by yourself and Dr. Hill (2007) I tend to think that the finite-population variance would be an appropriate measure to summarize the overall variation across the 21 districts. However, I feel it is somewhat incoherent first to assume a Normal distribution for the district effects, involving a “superpopulation” variance parameter, and then to compute the finite-population variance from the estimated district-specific parameters. I wonder whether the finite-population variance were more appropriate in the context of a model with fixed district effects?
  
My reply:
  

 
I agree that th</p><p>2 0.83382261 <a title="464-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>Introduction: Stuart Buck writes:
  
I have a question about  fixed effects vs. random effects . Amongst economists who study teacher value-added, it has become common to see people saying that they estimated teacher fixed effects (via least squares dummy variables, so that there is a parameter for each teacher), but that they then applied empirical Bayes shrinkage so that the teacher effects are brought closer to the mean.  (See  this paper  by Jacob and Lefgren, for example.)


Can that really be what they are doing? Why wouldn’t they just run random (modeled) effects in the first place? I feel like there’s something I’m missing.
  
My reply:  I don’t know the full story here, but I’m thinking there are two goals, first to get an unbiased estimate of an overall treatment effect (and there the econometricians prefer so-called fixed effects; I disagree with them on this but I know where they’re coming from) and second to estimate individual teacher effects (and there it makes sense to use so-called</p><p>3 0.81586748 <a title="464-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-10-R_vs._Stata%2C_or%2C_Different_ways_to_estimate_multilevel_models.html">269 andrew gelman stats-2010-09-10-R vs. Stata, or, Different ways to estimate multilevel models</a></p>
<p>Introduction: Cyrus writes:
  
I [Cyrus] was teaching a class on multilevel modeling, and we were playing around with different method to fit a random effects logit model with 2 random intercepts—one corresponding to “family” and another corresponding to “community” (labeled “mom” and “cluster” in the data, respectively).  There are also a few regressors at the individual, family, and community level.  We were replicating in part some of the results from the  following paper :  Improved estimation procedures for multilevel models with binary response: a case-study, by G Rodriguez, N Goldman.


(I say “replicating in part” because we didn’t include all the regressors that they use, only a subset.)  We were looking at the performance of estimation via glmer in R’s lme4 package, glmmPQL in R’s MASS package, and Stata’s xtmelogit.  We wanted to study the performance of various estimation methods, including adaptive quadrature methods and penalized quasi-likelihood.


I was shocked to discover that glmer</p><p>4 0.80711514 <a title="464-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>Introduction: Fred Wu writes: 
  
  
I work at National Prescribing Services in Australia.  I have a database representing say, antidiabetic drug utilisation for the entire Australia in the past few years. I planned to do a longitudinal analysis across GP Division Network (112 divisions in AUS) using mixed-effects models (or as you called in your book varying intercept and varying slope) on this data. 


The problem here is: as data actually represent the population who use antidiabetic drugs in AUS, should I use 112 fixed dummy variables to capture the random variations or use varying intercept and varying slope for the model ? Because some one may aruge, like divisions in AUS or states in USA can hardly be considered from a “superpopulation”, then fixed dummies should be used.  What I think is the population are those who use the drugs, what will happen when the rest need to use them? In terms of exchangeability, using varying intercept and varying slopes can be justified.


Also you provided in y</p><p>5 0.80558681 <a title="464-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>Introduction: I received the following email from someone who wishes to remain anonymous:
  
My colleague and I are trying to understand the best way to approach a problem involving measuring a group of individuals’ abilities across time, and are hoping you can offer some guidance.


We are trying to analyze the combined effect of two distinct groups of people (A and B, with no overlap between A and B) who collaborate to produce a binary outcome, using a mixed logistic regression along the lines of the following.


Outcome ~ (1 | A) + (1 | B) + Other variables


What we’re interested in testing was whether the observed A random effects in period  1 are predictive of the A random effects in the following period 2.  Our idea being create two models, each using a different period’s worth of data, to create two sets of A coefficients, then observe the relationship between the two.  If the A’s have a persistent ability across periods, the coefficients should be correlated or show a linear-ish relationshi</p><p>6 0.77987361 <a title="464-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>7 0.76749629 <a title="464-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>8 0.76246017 <a title="464-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>9 0.76020002 <a title="464-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Adding_more_information_can_make_the_variance_go_up_%28depending_on_your_model%29.html">810 andrew gelman stats-2011-07-20-Adding more information can make the variance go up (depending on your model)</a></p>
<p>10 0.75729448 <a title="464-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>11 0.75106287 <a title="464-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>12 0.7489661 <a title="464-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-21-Finite-population_Anova_calculations_for_models_with_interactions.html">1686 andrew gelman stats-2013-01-21-Finite-population Anova calculations for models with interactions</a></p>
<p>13 0.74553436 <a title="464-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Fixed_effects_and_identification.html">1241 andrew gelman stats-2012-04-02-Fixed effects and identification</a></p>
<p>14 0.73412931 <a title="464-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-06-Bayesian_Anova_found_useful_in_ecology.html">1102 andrew gelman stats-2012-01-06-Bayesian Anova found useful in ecology</a></p>
<p>15 0.72429603 <a title="464-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>16 0.72037965 <a title="464-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>17 0.71850145 <a title="464-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<p>18 0.71430331 <a title="464-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>19 0.70739543 <a title="464-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-02-The_problem_of_overestimation_of_group-level_variance_parameters.html">63 andrew gelman stats-2010-06-02-The problem of overestimation of group-level variance parameters</a></p>
<p>20 0.70259959 <a title="464-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-That_half-Cauchy_prior.html">184 andrew gelman stats-2010-08-04-That half-Cauchy prior</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.011), (2, 0.045), (9, 0.028), (16, 0.039), (20, 0.02), (21, 0.012), (24, 0.182), (27, 0.028), (42, 0.017), (43, 0.022), (48, 0.143), (53, 0.019), (76, 0.019), (79, 0.014), (86, 0.026), (89, 0.017), (99, 0.264)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95738292 <a title="464-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Futures_contracts%2C_Granger_causality%2C_and_my_preference_for_estimation_to_testing.html">212 andrew gelman stats-2010-08-17-Futures contracts, Granger causality, and my preference for estimation to testing</a></p>
<p>Introduction: José Iparraguirre writes:
  
There’s  a letter  in the latest issue of The Economist (July 31st) signed by Sir Richard Branson (Virgin), Michael Masters (Masters Capital Management) and David Frenk (Better Markets) about an    “>OECD report  on speculation and the prices of commodities, which includes the following: “The report uses a Granger causality test to measure the relationship between the level of commodities futures contracts held by swap dealers, and the prices of those commodities. Granger tests, however, are of dubious applicability to extremely volatile variables like commodities prices.”
  
The report says:
  
Granger causality is a standard statistical technique for determining whether one time series is useful in forecasting another. It is important to bear in mind that the term causality is used in a statistical sense, and not in a philosophical one of structural causation. More precisely a variable A is said to Granger cause B if knowing the time paths of B and A toge</p><p>2 0.95372462 <a title="464-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-That_xkcd_cartoon_on_multiple_comparisons_that_all_of_you_were_sending_me_a_couple_months_ago.html">848 andrew gelman stats-2011-08-11-That xkcd cartoon on multiple comparisons that all of you were sending me a couple months ago</a></p>
<p>Introduction: John Transue  sent it in  with the following thoughtful comment:
  
I’d imagine you’ve already received this, but just in case, here’s a cartoon you’d like. At first blush it seems to go against your advice (more nuanced than what I’m about to say by quoting the paper title) to not worry about multiple comparisons.


However, if I understand correctly your argument about multiple comparisons in multilevel models, the situation in this comic might have been avoided if shrinkage toward the grand mean (of all colors) had prevented the greens from clearing the .05 threshold. Is that right?</p><p>same-blog 3 0.94980466 <a title="464-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>Introduction: Karri Seppa writes:
  
My topic is regional variation in the cause-specific survival of breast cancer patients across the 21 hospital districts in Finland, this component being modeled by random effects. I am interested mainly in the district-specific effects, and with a hierarchical model I can get reasonable estimates also for sparsely populated districts.


Based on the recommendation given in the book by yourself and Dr. Hill (2007) I tend to think that the finite-population variance would be an appropriate measure to summarize the overall variation across the 21 districts. However, I feel it is somewhat incoherent first to assume a Normal distribution for the district effects, involving a “superpopulation” variance parameter, and then to compute the finite-population variance from the estimated district-specific parameters. I wonder whether the finite-population variance were more appropriate in the context of a model with fixed district effects?
  
My reply:
  

 
I agree that th</p><p>4 0.94979239 <a title="464-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-10-Proposed_new_section_of_the_American_Statistical_Association_on_Imaging_Sciences.html">332 andrew gelman stats-2010-10-10-Proposed new section of the American Statistical Association on Imaging Sciences</a></p>
<p>Introduction: Martin Lindquist writes that he and others are trying to start a new ASA section on statistics in imaging. If youâ&euro;&trade;re interested in being a signatory to its formation, please  send him  an email.</p><p>5 0.93849397 <a title="464-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-03-MCMC_in_Python.html">181 andrew gelman stats-2010-08-03-MCMC in Python</a></p>
<p>Introduction: John Salvatier forwards a note from Anand Patil that  a paper on PyMC  has appeared in the Journal of Statistical Software,  Weâ&euro;&trade;ll have to check this out.</p><p>6 0.91814989 <a title="464-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-26-Worst_statistical_graphic_I_have_seen_this_year.html">681 andrew gelman stats-2011-04-26-Worst statistical graphic I have seen this year</a></p>
<p>7 0.91576385 <a title="464-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-09-Does_it_feel_like_cheating_when_I_do_this%3F__Variation_in_ethical_standards_and_expectations.html">605 andrew gelman stats-2011-03-09-Does it feel like cheating when I do this?  Variation in ethical standards and expectations</a></p>
<p>8 0.91553938 <a title="464-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Including_interactions_or_not.html">823 andrew gelman stats-2011-07-26-Including interactions or not</a></p>
<p>9 0.91549838 <a title="464-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-28-Argument_in_favor_of_Ddulites.html">1088 andrew gelman stats-2011-12-28-Argument in favor of Ddulites</a></p>
<p>10 0.90815175 <a title="464-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Blogads_update.html">1240 andrew gelman stats-2012-04-02-Blogads update</a></p>
<p>11 0.90695018 <a title="464-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-25-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">870 andrew gelman stats-2011-08-25-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>12 0.90610641 <a title="464-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-02-Fighting_a_losing_battle.html">1518 andrew gelman stats-2012-10-02-Fighting a losing battle</a></p>
<p>13 0.90582919 <a title="464-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-24-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">1913 andrew gelman stats-2013-06-24-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>14 0.90190846 <a title="464-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-28-The_Supreme_Court%E2%80%99s_Many_Median_Justices.html">1234 andrew gelman stats-2012-03-28-The Supreme Court’s Many Median Justices</a></p>
<p>15 0.90053326 <a title="464-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-14-Sides_and_Vavreck_on_the_2012_election.html">1496 andrew gelman stats-2012-09-14-Sides and Vavreck on the 2012 election</a></p>
<p>16 0.89686763 <a title="464-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-30-%3F%3F%3F.html">2118 andrew gelman stats-2013-11-30-???</a></p>
<p>17 0.89609593 <a title="464-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>18 0.89600903 <a title="464-lda-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-20-Thermodynamic_Monte_Carlo%3A__Michael_Betancourt%E2%80%99s_new_method_for_simulating_from_difficult_distributions_and_evaluating_normalizing_constants.html">2340 andrew gelman stats-2014-05-20-Thermodynamic Monte Carlo:  Michael Betancourt’s new method for simulating from difficult distributions and evaluating normalizing constants</a></p>
<p>19 0.89567471 <a title="464-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-03-Did_you_buy_laundry_detergent_on_their_most_recent_trip_to_the_store%3F__Also_comments_on_scientific_publication_and_yet_another_suggestion_to_do_a_study_that_allows_within-person_comparisons.html">2358 andrew gelman stats-2014-06-03-Did you buy laundry detergent on their most recent trip to the store?  Also comments on scientific publication and yet another suggestion to do a study that allows within-person comparisons</a></p>
<p>20 0.8955844 <a title="464-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-18-Understanding_posterior_p-values.html">2029 andrew gelman stats-2013-09-18-Understanding posterior p-values</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
