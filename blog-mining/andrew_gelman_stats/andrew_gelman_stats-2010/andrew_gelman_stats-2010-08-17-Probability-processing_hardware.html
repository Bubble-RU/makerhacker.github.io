<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>214 andrew gelman stats-2010-08-17-Probability-processing hardware</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-214" href="#">andrew_gelman_stats-2010-214</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>214 andrew gelman stats-2010-08-17-Probability-processing hardware</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-214-html" href="http://andrewgelman.com/2010/08/17/probability-pro_1/">html</a></p><p>Introduction: Lyric Semiconductor   posted:
  

For over 60 years, computers have been based on digital computing principles. Data is represented as bits (0s and 1s). Boolean logic gates perform operations on these bits. A processor steps through many of these operations serially in order to perform a function. However, today’s most interesting problems are not at all suited to this approach.


Here at Lyric Semiconductor, we are redesigning information processing circuits from the ground up to natively process probabilities: from the gate circuits to the processor architecture to the programming language.  As a result, many applications that today require a thousand conventional processors will soon run in just one Lyric processor, providing 1,000x efficiencies in cost, power, and size.

  
 Om Malik  has some more information, also relating to the team and the business.
 
The fundamental idea is that computing architectures work deterministically, even though the world is fundamentally stochastic.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Lyric Semiconductor   posted:     For over 60 years, computers have been based on digital computing principles. [sent-1, score-0.265]
</p><p>2 A processor steps through many of these operations serially in order to perform a function. [sent-4, score-0.514]
</p><p>3 However, today’s most interesting problems are not at all suited to this approach. [sent-5, score-0.084]
</p><p>4 Here at Lyric Semiconductor, we are redesigning information processing circuits from the ground up to natively process probabilities: from the gate circuits to the processor architecture to the programming language. [sent-6, score-1.338]
</p><p>5 As a result, many applications that today require a thousand conventional processors will soon run in just one Lyric processor, providing 1,000x efficiencies in cost, power, and size. [sent-7, score-0.333]
</p><p>6 Om Malik  has some more information, also relating to the team and the business. [sent-8, score-0.066]
</p><p>7 The fundamental idea is that computing architectures work deterministically, even though the world is fundamentally stochastic. [sent-9, score-0.358]
</p><p>8 In a lot of statistical processing, especially in Bayesian statistics, we take stochastic world, force it into determinism, simulate stochastic world by computationally generating deterministic pseudo-random numbers, and simulate stochastic matching by deterministic likelihood computations. [sent-10, score-1.62]
</p><p>9 What Lyric could do is to bypass this highly inefficient intermediate deterministic step. [sent-11, score-0.448]
</p><p>10 They’re also working on a programming language: PSBL (Probability Synthesis for Bayesian Logic), but there are no details. [sent-13, score-0.11]
</p><p>11 Here is their patent for  Analog Logic Automata , indicating applications for images (filtering, recognition, etc. [sent-14, score-0.448]
</p><p>12 Hayes  points to a  US Patent  indicating that one of the circuits optimizes the  sum-product belief propagation algorithm . [sent-18, score-0.61]
</p><p>13 This type of algorithms is popular in machine learning for various recognition and denoising problems. [sent-19, score-0.127]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lyric', 0.436), ('circuits', 0.298), ('processor', 0.269), ('semiconductor', 0.218), ('deterministic', 0.213), ('stochastic', 0.201), ('logic', 0.192), ('patent', 0.156), ('operations', 0.142), ('simulate', 0.142), ('indicating', 0.135), ('recognition', 0.127), ('processing', 0.126), ('programming', 0.11), ('computing', 0.107), ('perform', 0.103), ('analog', 0.099), ('architectures', 0.099), ('automata', 0.099), ('determinism', 0.099), ('efficiencies', 0.099), ('optimizes', 0.099), ('applications', 0.094), ('boolean', 0.094), ('bypass', 0.094), ('deterministically', 0.094), ('world', 0.09), ('gate', 0.09), ('hayes', 0.09), ('filtering', 0.086), ('synthesis', 0.084), ('architecture', 0.084), ('digital', 0.084), ('suited', 0.084), ('computationally', 0.078), ('propagation', 0.078), ('today', 0.078), ('generating', 0.077), ('inefficient', 0.075), ('computers', 0.074), ('gates', 0.073), ('relating', 0.066), ('intermediate', 0.066), ('bits', 0.065), ('represented', 0.063), ('ground', 0.063), ('images', 0.063), ('fundamentally', 0.062), ('matching', 0.062), ('thousand', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="214-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Probability-processing_hardware.html">214 andrew gelman stats-2010-08-17-Probability-processing hardware</a></p>
<p>Introduction: Lyric Semiconductor   posted:
  

For over 60 years, computers have been based on digital computing principles. Data is represented as bits (0s and 1s). Boolean logic gates perform operations on these bits. A processor steps through many of these operations serially in order to perform a function. However, today’s most interesting problems are not at all suited to this approach.


Here at Lyric Semiconductor, we are redesigning information processing circuits from the ground up to natively process probabilities: from the gate circuits to the processor architecture to the programming language.  As a result, many applications that today require a thousand conventional processors will soon run in just one Lyric processor, providing 1,000x efficiencies in cost, power, and size.

  
 Om Malik  has some more information, also relating to the team and the business.
 
The fundamental idea is that computing architectures work deterministically, even though the world is fundamentally stochastic.</p><p>2 0.19894508 <a title="214-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-27-Bridges_between_deterministic_and_probabilistic_models_for_binary_data.html">780 andrew gelman stats-2011-06-27-Bridges between deterministic and probabilistic models for binary data</a></p>
<p>Introduction: For the analysis of binary data, various deterministic models have been proposed, which are generally simpler to fit and easier to understand than probabilistic models. We claim that corresponding to any deterministic model is an implicit stochastic model in which the deterministic model fits imperfectly, with errors occurring at random. In the context of binary data, we consider a model in which the probability of error depends on the model prediction. We show how to fit this model using a stochastic modification of deterministic optimization schemes.
 
The advantages of fitting the stochastic model explicitly (rather than implicitly, by simply fitting a deterministic model and accepting the occurrence of errors) include quantification of uncertainty in the deterministic model’s parameter estimates, better estimation of the true model error rate, and the ability to check the fit of the model nontrivially. We illustrate this with a simple theoretical example of item response data and w</p><p>3 0.1798256 <a title="214-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-09-Special_journal_issue_on_statistical_methods_for_the_social_sciences.html">24 andrew gelman stats-2010-05-09-Special journal issue on statistical methods for the social sciences</a></p>
<p>Introduction: Last year I  spoke at  a conference celebrating the 10th anniversary of the University of Washington’s Center for Statistics and the Social Sciences, and just today a  special issue  of the journal Statistical Methodology came out in honor of the center’s anniversary.   My article  in the special issue actually has nothing to do with my talk at the conference; rather, it’s an exploration of an idea that Iven Van Mechelen and I had for understanding deterministic models probabilistically:
  
 
For the analysis of binary data, various deterministic models have been proposed, which are generally simpler to fit and easier to understand than probabilistic models. We claim that corresponding to any deterministic model is an implicit stochastic model in which the deterministic model fits imperfectly, with errors occurring at random. In the context of binary data, we consider a model in which the probability of error depends on the model prediction. We show how to fit this model using a stocha</p><p>4 0.11729473 <a title="214-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>Introduction: Daniel Lakeland  asks , “Where do likelihoods come from?”  He describes a class of problems where you have a deterministic dynamic model that you want to fit to data.  The data won’t fit perfectly so, if you want to do Bayesian inference, you need to introduce an error model.  This looks a little bit different from the usual way that models are presented in statistics textbooks, where the focus is typically on the random error process, not on the deterministic part of the model.  A focus on the error process makes sense in some applications that have inherent randomness or variation (for example, genetics, psychology, and survey sampling) but not so much in the physical sciences, where the deterministic model can be complicated and is typically the essence of the study.  Often in these sorts of studies, the staring point (and sometimes the ending point) is what the physicists call “nonlinear least squares” or what we would call normally-distributed errors.  That’s what we did for our</p><p>5 0.10222546 <a title="214-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-18-Trolls%21.html">860 andrew gelman stats-2011-08-18-Trolls!</a></p>
<p>Introduction: Christian Robert points to  this  absurd patent of the Monte Carlo method (which, as Christian notes, was actually invented by Stanislaw Ulam and others in the 1940s).
 
The whole thing is pretty unreadable.  I wonder if they first wrote it as a journal article and then it got rejected everywhere, so they decided to submit it as a patent instead.
 
What’s even worse is this bit:
  
This invention was made with government support under Grant Numbers 0612170 and 0347408 awarded by the National Science Foundation.
  
So our tax dollars are being given to IBM so they can try to bring statistics to a halt by patenting one of our most basic tools?  I’d say this is just a waste of money, but given that our country is run by lawyers, there must be some outside chance that this patent could actually succeed?
 
Perhaps there’s room for an improvement in the patent that involves  albedo  in some way?</p><p>6 0.10102275 <a title="214-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-15-Postdoc_involving_pathbreaking_work_in_MRP%2C_Stan%2C_and_the_2014_election%21.html">2173 andrew gelman stats-2014-01-15-Postdoc involving pathbreaking work in MRP, Stan, and the 2014 election!</a></p>
<p>7 0.10018 <a title="214-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<p>8 0.098337956 <a title="214-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-28-Every_time_you_take_a_sample%2C_you%E2%80%99ll_have_to_pay_this_guy_a_quarter.html">1398 andrew gelman stats-2012-06-28-Every time you take a sample, you’ll have to pay this guy a quarter</a></p>
<p>9 0.086080238 <a title="214-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-26-A_statistician%E2%80%99s_rants_and_raves.html">1185 andrew gelman stats-2012-02-26-A statistician’s rants and raves</a></p>
<p>10 0.085439689 <a title="214-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-13-Lame_Statistics_Patents.html">1761 andrew gelman stats-2013-03-13-Lame Statistics Patents</a></p>
<p>11 0.08156047 <a title="214-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Toward_a_framework_for_automatic_model_building.html">1718 andrew gelman stats-2013-02-11-Toward a framework for automatic model building</a></p>
<p>12 0.081441224 <a title="214-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-23-My_last_post_on_albedo%2C_I_promise.html">625 andrew gelman stats-2011-03-23-My last post on albedo, I promise</a></p>
<p>13 0.07584662 <a title="214-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-06-Leahy_Versus_Albedoman_and_the_Moneygoround%2C_Part_One.html">1885 andrew gelman stats-2013-06-06-Leahy Versus Albedoman and the Moneygoround, Part One</a></p>
<p>14 0.072390139 <a title="214-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-21-The_future_%28and_past%29_of_statistical_sciences.html">2072 andrew gelman stats-2013-10-21-The future (and past) of statistical sciences</a></p>
<p>15 0.069089331 <a title="214-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-10-Jobs_in_statistics_research%21__In_New_Jersey%21.html">1110 andrew gelman stats-2012-01-10-Jobs in statistics research!  In New Jersey!</a></p>
<p>16 0.068494894 <a title="214-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-13-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Wasserman.html">1165 andrew gelman stats-2012-02-13-Philosophy of Bayesian statistics:  my reactions to Wasserman</a></p>
<p>17 0.067176133 <a title="214-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-06-Info_on_patent_trolls.html">892 andrew gelman stats-2011-09-06-Info on patent trolls</a></p>
<p>18 0.067045338 <a title="214-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-03-Bayes_pays%21.html">1923 andrew gelman stats-2013-07-03-Bayes pays!</a></p>
<p>19 0.065066777 <a title="214-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-F-f-f-fake_data.html">1735 andrew gelman stats-2013-02-24-F-f-f-fake data</a></p>
<p>20 0.062893465 <a title="214-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-%E2%80%9CIs_machine_learning_a_subset_of_statistics%3F%E2%80%9D.html">1740 andrew gelman stats-2013-02-26-“Is machine learning a subset of statistics?”</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.097), (1, 0.041), (2, -0.035), (3, 0.026), (4, -0.002), (5, 0.036), (6, -0.037), (7, -0.012), (8, -0.002), (9, 0.004), (10, -0.022), (11, -0.01), (12, -0.039), (13, -0.014), (14, -0.046), (15, 0.008), (16, 0.033), (17, -0.013), (18, -0.005), (19, -0.029), (20, 0.003), (21, 0.019), (22, -0.016), (23, -0.003), (24, -0.006), (25, 0.022), (26, -0.021), (27, 0.027), (28, 0.035), (29, -0.028), (30, 0.009), (31, 0.011), (32, -0.0), (33, 0.003), (34, 0.007), (35, -0.006), (36, -0.023), (37, -0.014), (38, 0.015), (39, -0.008), (40, -0.01), (41, -0.012), (42, -0.009), (43, 0.031), (44, 0.018), (45, 0.033), (46, -0.001), (47, 0.001), (48, -0.021), (49, 0.004)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92692542 <a title="214-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Probability-processing_hardware.html">214 andrew gelman stats-2010-08-17-Probability-processing hardware</a></p>
<p>Introduction: Lyric Semiconductor   posted:
  

For over 60 years, computers have been based on digital computing principles. Data is represented as bits (0s and 1s). Boolean logic gates perform operations on these bits. A processor steps through many of these operations serially in order to perform a function. However, today’s most interesting problems are not at all suited to this approach.


Here at Lyric Semiconductor, we are redesigning information processing circuits from the ground up to natively process probabilities: from the gate circuits to the processor architecture to the programming language.  As a result, many applications that today require a thousand conventional processors will soon run in just one Lyric processor, providing 1,000x efficiencies in cost, power, and size.

  
 Om Malik  has some more information, also relating to the team and the business.
 
The fundamental idea is that computing architectures work deterministically, even though the world is fundamentally stochastic.</p><p>2 0.74457282 <a title="214-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>Introduction: Last month I  wrote :
  
Computer scientists are often brilliant but they can be unfamiliar with what is done in the worlds of data collection and analysis. This goes the other way too: statisticians such as myself can look pretty awkward, reinventing (or failing to reinvent) various wheels when we write computer programs or, even worse, try to design software.Andrew MacNamara writes:
  
Andrew MacNamara followed up with some thoughts:
  
I [MacNamara] had some basic statistics training through my MBA program, after having completed an undergrad degree in computer science. Since then I’ve been very interested in learning more about statistical techniques, including things like GLM and censored data analyses as well as machine learning topics like neural nets, SVMs, etc. I began following your blog after some research into Bayesian analysis topics and I am trying to dig deeper on that side of things.


One thing I have noticed is that there seems to be a distinction between data analysi</p><p>3 0.72920191 <a title="214-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>Introduction: David Duvenaud writes:
  
I’ve been following  your recent discussions  about how an AI could do statistics [see also  here ].  I was especially excited about your suggestion for new statistical methods using “a language-like approach to recursively creating new models from a specified list of distributions and transformations, and an automatic approach to checking model fit.”


Your discussion of these ideas was exciting to me and my colleagues because we recently  did some work  taking a step in this direction, automatically searching through a grammar over Gaussian process regression models.


Roger Grosse previously  did the same thing , but over matrix decomposition models using held-out predictive likelihood to check model fit.


These are both examples of automatic Bayesian model-building by a search over more and more complex models, as you suggested.  One nice thing is that both grammars include lots of standard models for free, and they seem to work pretty well, although the</p><p>4 0.70419455 <a title="214-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-29-Postdocs_in_probabilistic_modeling%21__With_David_Blei%21__And_Stan%21.html">1961 andrew gelman stats-2013-07-29-Postdocs in probabilistic modeling!  With David Blei!  And Stan!</a></p>
<p>Introduction: David Blei writes:
  
I have  two postdoc openings for basic research in probabilistic modeling .


The thrusts are (a) scalable inference and (b) model checking.  We 
will be developing new methods and implementing them in probabilistic 
programming systems.  I am open to applicants interested in many kinds 
of applications and from any field.
  
“Scalable inference” means black-box VB and related ideas, and “probabilistic programming systems” means Stan!  (You might be familiar with Stan as an implementation of Nuts for posterior sampling, but Stan is also an efficient program for computing probability densities and their gradients, and as such is an ideal platform for developing scalable implementations of variational inference and related algorithms.)
 
And you know I like model checking.
 
Here’s the full ad: 
  
  
===== POSTDOC POSITIONS IN PROBABILISTIC MODELING =====


We expect to have two postdoctoral positions available for January 2014 (or later).  These positions are in D</p><p>5 0.70307857 <a title="214-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Bayesian_Uncertainty_Quantification_for_Differential_Equations%21.html">2311 andrew gelman stats-2014-04-29-Bayesian Uncertainty Quantification for Differential Equations!</a></p>
<p>Introduction: Mark Girolami points us to  this paper and software  (with Oksana Chkrebtii, David Campbell, and Ben Calderhead).  They write:
  
We develop a general methodology for the probabilistic integration of differential equations via model based updating of a joint prior measure on the space of functions and their temporal and spatial derivatives. This results in a posterior measure over functions reflecting how well they satisfy the system of differential equations and corresponding initial and boundary values. We show how this posterior measure can be naturally incorporated within the Kennedy and O’Hagan framework for uncertainty quantification and provides a fully Bayesian approach to model calibration. . . . A broad variety of examples are provided to illustrate the potential of this framework for characterising discretization uncertainty, including initial value, delay, and boundary value differential equations, as well as partial differential equations. We also demonstrate our methodolo</p><p>6 0.69114506 <a title="214-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-06-Josh_Tenenbaum_presents_._._._a_model_of_folk_physics%21.html">994 andrew gelman stats-2011-11-06-Josh Tenenbaum presents . . . a model of folk physics!</a></p>
<p>7 0.68061841 <a title="214-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-19-An_interweaving-transformation_strategy_for_boosting_MCMC_efficiency.html">964 andrew gelman stats-2011-10-19-An interweaving-transformation strategy for boosting MCMC efficiency</a></p>
<p>8 0.67198056 <a title="214-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-14-GPstuff%3A_Bayesian_Modeling_with_Gaussian_Processes.html">1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</a></p>
<p>9 0.6715582 <a title="214-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-01-Tukey%E2%80%99s_philosophy.html">496 andrew gelman stats-2011-01-01-Tukey’s philosophy</a></p>
<p>10 0.66554946 <a title="214-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>11 0.66458964 <a title="214-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-03-Bayes_pays%21.html">1923 andrew gelman stats-2013-07-03-Bayes pays!</a></p>
<p>12 0.6612615 <a title="214-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-17-Job_opening_at_new_%E2%80%9Cbig_data%E2%80%9D_consulting_firm%21.html">1902 andrew gelman stats-2013-06-17-Job opening at new “big data” consulting firm!</a></p>
<p>13 0.66072941 <a title="214-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<p>14 0.66038066 <a title="214-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>15 0.65584642 <a title="214-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-04-When_is_there_%E2%80%9Chidden_structure_in_data%E2%80%9D_to_be_discovered%3F.html">1788 andrew gelman stats-2013-04-04-When is there “hidden structure in data” to be discovered?</a></p>
<p>16 0.64518452 <a title="214-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>17 0.64453828 <a title="214-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-30-David_Hogg_on_statistics.html">1401 andrew gelman stats-2012-06-30-David Hogg on statistics</a></p>
<p>18 0.64396125 <a title="214-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-11-Convergence_Monitoring_for_Non-Identifiable_and_Non-Parametric_Models.html">1374 andrew gelman stats-2012-06-11-Convergence Monitoring for Non-Identifiable and Non-Parametric Models</a></p>
<p>19 0.6395877 <a title="214-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-21-The_future_%28and_past%29_of_statistical_sciences.html">2072 andrew gelman stats-2013-10-21-The future (and past) of statistical sciences</a></p>
<p>20 0.63889372 <a title="214-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-09-Removing_the_blindfold%3A_visualising_statistical_models.html">265 andrew gelman stats-2010-09-09-Removing the blindfold: visualising statistical models</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.021), (16, 0.051), (21, 0.034), (24, 0.104), (49, 0.01), (52, 0.01), (56, 0.046), (59, 0.305), (77, 0.017), (86, 0.072), (99, 0.173)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9493373 <a title="214-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-19-Weather_visualization_with_WeatherSpark.html">580 andrew gelman stats-2011-02-19-Weather visualization with WeatherSpark</a></p>
<p>Introduction: WeatherSpark : prediction and observation quantiles, historic data, multiple predictors, zoomable, draggable, colorful, wonderful:
 
   
 
   
 
Via  Jure Cuhalev .</p><p>2 0.93485332 <a title="214-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-09-Society_for_Industrial_and_Applied_Mathematics_startup-math_meetup.html">403 andrew gelman stats-2010-11-09-Society for Industrial and Applied Mathematics startup-math meetup</a></p>
<p>Introduction: Chris Wiggins sends along  this .
 
It’s a meetup at Davis Auditorium, CEPSR Bldg, Columbia University, on Wed 10 Nov (that’s tomorrow!  or maybe today! depending on when you’re reading this), 6-8pm.</p><p>same-blog 3 0.88193262 <a title="214-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Probability-processing_hardware.html">214 andrew gelman stats-2010-08-17-Probability-processing hardware</a></p>
<p>Introduction: Lyric Semiconductor   posted:
  

For over 60 years, computers have been based on digital computing principles. Data is represented as bits (0s and 1s). Boolean logic gates perform operations on these bits. A processor steps through many of these operations serially in order to perform a function. However, today’s most interesting problems are not at all suited to this approach.


Here at Lyric Semiconductor, we are redesigning information processing circuits from the ground up to natively process probabilities: from the gate circuits to the processor architecture to the programming language.  As a result, many applications that today require a thousand conventional processors will soon run in just one Lyric processor, providing 1,000x efficiencies in cost, power, and size.

  
 Om Malik  has some more information, also relating to the team and the business.
 
The fundamental idea is that computing architectures work deterministically, even though the world is fundamentally stochastic.</p><p>4 0.87343967 <a title="214-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-09-iPython_Notebook.html">1716 andrew gelman stats-2013-02-09-iPython Notebook</a></p>
<p>Introduction: Burak Bayramli writes:
  
I wanted to inform you on iPython Notebook technology – allowing markup, Python code to reside in one document. Someone ported  one of your examples from ARM .


iPynb file is actually a live document, can be downloaded and reran locally, hence change of code on document means change of images, results. Graphs (as well as text output) which are generated by the code, are placed inside the document automatically. No more referencing image files seperately. 


For now running notebooks locally require a notebook server, but that part can live “on the cloud” as part of an educational software. Viewers, such as nbviewer.ipython.org, do not even need that much, since all recent results of a notebook are embedded in the notebook itself. 


A lot of people are excited about this; Also out of nowhere, Alfred P. Sloan Foundation dropped a $1.15 million grant on the developers of ipython which provided some extra energy on the project.
  
Cool.  We’ll have to do that ex</p><p>5 0.76710838 <a title="214-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-14-Preferential_admissions_for_children_of_elite_colleges.html">853 andrew gelman stats-2011-08-14-Preferential admissions for children of elite colleges</a></p>
<p>Introduction: Jenny Anderson  reports  on a discussion of the practice of colleges preferential admission of children of alumni:
  
 
[Richard] Kahlenberg citing research from his book “Affirmative Action for the Rich: Legacy Preferences in College Admissions” made the case that getting into good schools matters — 12 institutions making up less than 1 percent of the U.S. population produced 42 percent of government leaders and 54 percent of corporate leaders.


And being a legacy helps improve an applicant’s chances of getting in, with one study finding that being a primary legacy — the son or daughter of an undergraduate alumnus or alumna — increases one’s chance of admission by 45.1 percent.
 

 
I’d call that 45 percent but I get the basic idea.
 
But then Jeffrey Brenzel of the Yale admissions office replied:
  
“We turn away 80 percent of our legacies, and we feel it every day,” Mr. Brenzel said, adding that he rejected more offspring of the school’s Sterling donors than he accepted this year (</p><p>6 0.75567102 <a title="214-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-19-Web-friendly_visualizations_in_R.html">965 andrew gelman stats-2011-10-19-Web-friendly visualizations in R</a></p>
<p>7 0.75125599 <a title="214-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-30-%E2%80%9CThe_scientific_literature_must_be_cleansed_of_everything_that_is_fraudulent%2C_especially_if_it_involves_the_work_of_a_leading_academic%E2%80%9D.html">1599 andrew gelman stats-2012-11-30-“The scientific literature must be cleansed of everything that is fraudulent, especially if it involves the work of a leading academic”</a></p>
<p>8 0.74604547 <a title="214-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-13-Inventor_of_Connect_Four_dies_at_91.html">763 andrew gelman stats-2011-06-13-Inventor of Connect Four dies at 91</a></p>
<p>9 0.70832062 <a title="214-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-14-Non-academic_writings_on_literature.html">34 andrew gelman stats-2010-05-14-Non-academic writings on literature</a></p>
<p>10 0.69850993 <a title="214-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-10-Forecasting_2012%3A_How_much_does_ideology_matter%3F.html">1000 andrew gelman stats-2011-11-10-Forecasting 2012: How much does ideology matter?</a></p>
<p>11 0.69649768 <a title="214-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-24-Bizarre_twisty_argument_about_medical_diagnostic_tests.html">229 andrew gelman stats-2010-08-24-Bizarre twisty argument about medical diagnostic tests</a></p>
<p>12 0.68997604 <a title="214-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-07-Not_much_difference_between_communicating_to_self_and_communicating_to_others.html">1408 andrew gelman stats-2012-07-07-Not much difference between communicating to self and communicating to others</a></p>
<p>13 0.68914425 <a title="214-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-15-How_do_I_make_my_graphs%3F.html">1764 andrew gelman stats-2013-03-15-How do I make my graphs?</a></p>
<p>14 0.68626666 <a title="214-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-26-A_statistician%E2%80%99s_rants_and_raves.html">1185 andrew gelman stats-2012-02-26-A statistician’s rants and raves</a></p>
<p>15 0.67749107 <a title="214-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-15-Coaching%2C_teaching%2C_and_writing.html">1380 andrew gelman stats-2012-06-15-Coaching, teaching, and writing</a></p>
<p>16 0.67393994 <a title="214-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-14-Bayes_in_China_update.html">517 andrew gelman stats-2011-01-14-Bayes in China update</a></p>
<p>17 0.66380352 <a title="214-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-13-A_question_about_AIC.html">1377 andrew gelman stats-2012-06-13-A question about AIC</a></p>
<p>18 0.66220599 <a title="214-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-11-Note_to_semi-spammers.html">199 andrew gelman stats-2010-08-11-Note to semi-spammers</a></p>
<p>19 0.65782976 <a title="214-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-13-Retractions%2C_retractions%3A__%E2%80%9Cleft-wing_enough_to_not_care_about_truth_if_it_confirms_their_social_theories%2C_right-wing_enough_to_not_care_as_long_as_they%E2%80%99re_getting_paid_enough%E2%80%9D.html">1415 andrew gelman stats-2012-07-13-Retractions, retractions:  “left-wing enough to not care about truth if it confirms their social theories, right-wing enough to not care as long as they’re getting paid enough”</a></p>
<p>20 0.65527153 <a title="214-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-16-30_days_of_statistics.html">771 andrew gelman stats-2011-06-16-30 days of statistics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
