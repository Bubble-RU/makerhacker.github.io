<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>10 andrew gelman stats-2010-04-29-Alternatives to regression for social science predictions</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-10" href="#">andrew_gelman_stats-2010-10</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>10 andrew gelman stats-2010-04-29-Alternatives to regression for social science predictions</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-10-html" href="http://andrewgelman.com/2010/04/29/alternatives_to/">html</a></p><p>Introduction: Somebody named David writes:
  
I [David] thought you might be interested or have an opinion on the paper referenced below. I am largely skeptical on the techniques presented and thought you might have some insight because you work with datasets more similar to those in ‘social science’ than myself.


Dana and Dawes. The superiority of simple alternatives to regression for social science predictions. Journal of Educational and Behavioral Statistics (2004) vol. 29 (3) pp. 317.
  
My reply:  I read the abstract (available online) and it seemed reasonable to me.  They prefer simple averages or weights based on correlations rather than regressions.  From a Bayesian perspective, what they’re saying is that least-squares regression and similar methods are noisy, and they can do better via massive simplification.  
 
 I’ve been a big fan of Robyn Dawes ever since reading his article in the classic Kahneman, Slovic, and Tversky volume.  I have no idea how much Dawes knows about modern Bayesian</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Somebody named David writes:    I [David] thought you might be interested or have an opinion on the paper referenced below. [sent-1, score-0.438]
</p><p>2 I am largely skeptical on the techniques presented and thought you might have some insight because you work with datasets more similar to those in ‘social science’ than myself. [sent-2, score-0.865]
</p><p>3 The superiority of simple alternatives to regression for social science predictions. [sent-4, score-0.864]
</p><p>4 My reply:  I read the abstract (available online) and it seemed reasonable to me. [sent-8, score-0.093]
</p><p>5 They prefer simple averages or weights based on correlations rather than regressions. [sent-9, score-0.725]
</p><p>6 From a Bayesian perspective, what they’re saying is that least-squares regression and similar methods are noisy, and they can do better via massive simplification. [sent-10, score-0.525]
</p><p>7 I’ve been a big fan of Robyn Dawes ever since reading his article in the classic Kahneman, Slovic, and Tversky volume. [sent-11, score-0.206]
</p><p>8 I have no idea how much Dawes knows about modern Bayesian statistics (that is, multilevel models), but if he does, I assume he’d support a partial-pooling approach that makes use of data information in determining weights while keeping stability in the estimates. [sent-12, score-0.98]
</p><p>9 To put it another way, least squares regression won’t help you make maps like  these , but simple averaging won’t either. [sent-13, score-0.719]
</p><p>10 At some point you have to step things up to the next level. [sent-14, score-0.078]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dawes', 0.349), ('weights', 0.243), ('regression', 0.186), ('robyn', 0.182), ('slovic', 0.182), ('simple', 0.181), ('superiority', 0.168), ('referenced', 0.159), ('determining', 0.142), ('david', 0.142), ('won', 0.141), ('tversky', 0.14), ('kahneman', 0.138), ('stability', 0.137), ('similar', 0.13), ('behavioral', 0.126), ('alternatives', 0.124), ('massive', 0.124), ('averaging', 0.12), ('squares', 0.12), ('averages', 0.119), ('educational', 0.115), ('insight', 0.115), ('datasets', 0.114), ('maps', 0.112), ('keeping', 0.112), ('noisy', 0.112), ('social', 0.111), ('fan', 0.109), ('largely', 0.108), ('skeptical', 0.107), ('techniques', 0.106), ('named', 0.105), ('correlations', 0.103), ('bayesian', 0.101), ('modern', 0.097), ('classic', 0.097), ('thought', 0.096), ('somebody', 0.095), ('science', 0.094), ('abstract', 0.093), ('presented', 0.089), ('knows', 0.088), ('online', 0.086), ('via', 0.085), ('statistics', 0.081), ('multilevel', 0.08), ('prefer', 0.079), ('opinion', 0.078), ('step', 0.078)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="10-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-29-Alternatives_to_regression_for_social_science_predictions.html">10 andrew gelman stats-2010-04-29-Alternatives to regression for social science predictions</a></p>
<p>Introduction: Somebody named David writes:
  
I [David] thought you might be interested or have an opinion on the paper referenced below. I am largely skeptical on the techniques presented and thought you might have some insight because you work with datasets more similar to those in ‘social science’ than myself.


Dana and Dawes. The superiority of simple alternatives to regression for social science predictions. Journal of Educational and Behavioral Statistics (2004) vol. 29 (3) pp. 317.
  
My reply:  I read the abstract (available online) and it seemed reasonable to me.  They prefer simple averages or weights based on correlations rather than regressions.  From a Bayesian perspective, what they’re saying is that least-squares regression and similar methods are noisy, and they can do better via massive simplification.  
 
 I’ve been a big fan of Robyn Dawes ever since reading his article in the classic Kahneman, Slovic, and Tversky volume.  I have no idea how much Dawes knows about modern Bayesian</p><p>2 0.14458077 <a title="10-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-01-Weighting_and_prediction_in_sample_surveys.html">784 andrew gelman stats-2011-07-01-Weighting and prediction in sample surveys</a></p>
<p>Introduction: A couple years ago Rod Little was invited to write an article for the diamond jubilee of the Calcutta Statistical Association Bulletin.  His article was published with discussions from Danny Pfefferman, J. N. K. Rao, Don Rubin, and myself. 
 Here it all is .
 
I’ll paste my discussion below, but it’s worth reading the others’ perspectives too.  Especially the part in Rod’s rejoinder where he points out a mistake I made.
  

 
Survey weights, like sausage and legislation, are designed and best appreciated by those who are placed a respectable distance from their manufacture. For those of us working inside the factory, vigorous discussion of methods is appreciated. I enjoyed Rod Little’s review of the connections between modeling and survey weighting and have just a few comments.
 
I like Little’s discussion of model-based shrinkage of post-stratum averages, which, as he notes, can be seen to correspond to shrinkage of weights. I would only add one thing to his formula at the end of his</p><p>3 0.11514848 <a title="10-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-03-How_best_to_learn_R%3F.html">65 andrew gelman stats-2010-06-03-How best to learn R?</a></p>
<p>Introduction: Alban Zeber writes:
  
I am wondering whether there is a reference (online or book) that you would recommend to someone who is interested in learning how to program in R.
  
Any thoughts?
 
P.S.  If I had a name like that, my books would be named, “Bayesian Statistics from A to Z,” “Teaching Statistics from A to Z,” “Regression and Multilevel Modeling from A to Z,” and so forth.</p><p>4 0.11121464 <a title="10-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-More_on_Bayesian_methods_and_multilevel_modeling.html">2033 andrew gelman stats-2013-09-23-More on Bayesian methods and multilevel modeling</a></p>
<p>Introduction: Ban Chuan Cheah writes: 
  
  
In a previous post, http://andrewgelman.com/2013/07/30/the-roy-causal-model/ you pointed to a paper on Bayesian methods by Heckman. At around the same time I came across another one of his papers, “The Effects of Cognitive and Noncognitive Abilities on Labor Market Outcomes and Social Behavior (2006)” (http://www.nber.org/papers/w12006 or published version http://www.jstor.org/stable/10.1086/504455). In this paper they implement their model as follows:

 
We use Bayesian Markov chain Monte Carlo methods to compute the sample likelihood. Our use of Bayesian methods is only a computational convenience. Our identification analysis is strictly classical. Under our assumptions, the priors we use are asymptotically irrelevant.
 

Some of the authors have also done something similar earlier in: 
Hansen, Karsten T. & Heckman, James J. & Mullen, K.J.Kathleen J., 2004. “The effect of schooling and ability on achievement test scores,” Journal of Econometrics, Elsevi</p><p>5 0.11040634 <a title="10-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-24-Analyzing_photon_counts.html">1509 andrew gelman stats-2012-09-24-Analyzing photon counts</a></p>
<p>Introduction: Via Tom LaGatta, Boris Glebov writes:
  
My labmates have statistics problem. We are all experimentalists, but need an input on a fine statistics point.


The problem is as follows. The data set consists of photon counts measured at a series of coordinates. The number of input photons is known, but the system transmission (T) is not known and needs to be estimated. The number of transmitted photons at each coordinate follows a binomial distribution, not a Gaussian one.


The spatial distribution of T values it then fit using a Levenberg-Marquart method modified to use weights for each data point.


At present, my labmates are not sure how to properly calculate and use the weights. The equations are designed for Gaussian distributions, not binomial ones, and this is a problem because in many cases the photon counts are near the edge (say, zero), where a Gaussian width is nonsensical.


Could you recommend a source they could use to guide their calculations?
  
My reply:
 
I donâ&euro;&trade;t know a</p><p>6 0.10899056 <a title="10-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<p>7 0.10803925 <a title="10-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-28-Bayesian_nonparametric_weighted_sampling_inference.html">2351 andrew gelman stats-2014-05-28-Bayesian nonparametric weighted sampling inference</a></p>
<p>8 0.10689449 <a title="10-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>9 0.1058605 <a title="10-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-19-Analysis_of_survey_data%3A_Design_based_models_vs._hierarchical_modeling%3F.html">352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</a></p>
<p>10 0.10254651 <a title="10-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>11 0.10137497 <a title="10-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-15-Mr._P_by_another_name_._._._is_still_great%21.html">769 andrew gelman stats-2011-06-15-Mr. P by another name . . . is still great!</a></p>
<p>12 0.098520711 <a title="10-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-22-Battle_of_the_Repo_Man_quotes%3A__Reid_Hastie%E2%80%99s_turn.html">1336 andrew gelman stats-2012-05-22-Battle of the Repo Man quotes:  Reid Hastie’s turn</a></p>
<p>13 0.096418887 <a title="10-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>14 0.095764816 <a title="10-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-06-Slow_progress.html">1445 andrew gelman stats-2012-08-06-Slow progress</a></p>
<p>15 0.095530428 <a title="10-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>16 0.093710467 <a title="10-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>17 0.093455851 <a title="10-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-Transformations_for_non-normal_data.html">2176 andrew gelman stats-2014-01-19-Transformations for non-normal data</a></p>
<p>18 0.092885844 <a title="10-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>19 0.092838384 <a title="10-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>20 0.09219759 <a title="10-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.2), (1, 0.066), (2, -0.03), (3, -0.001), (4, -0.009), (5, 0.045), (6, -0.059), (7, -0.018), (8, 0.046), (9, 0.068), (10, 0.065), (11, -0.044), (12, 0.004), (13, 0.047), (14, 0.021), (15, 0.019), (16, -0.022), (17, 0.011), (18, 0.0), (19, -0.022), (20, 0.011), (21, 0.047), (22, -0.004), (23, 0.022), (24, -0.007), (25, -0.024), (26, 0.048), (27, -0.057), (28, -0.056), (29, 0.005), (30, 0.054), (31, 0.03), (32, 0.009), (33, -0.02), (34, 0.001), (35, -0.008), (36, 0.003), (37, 0.021), (38, 0.005), (39, -0.001), (40, 0.017), (41, 0.063), (42, 0.02), (43, -0.042), (44, 0.018), (45, 0.039), (46, 0.01), (47, 0.041), (48, 0.03), (49, -0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98129994 <a title="10-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-29-Alternatives_to_regression_for_social_science_predictions.html">10 andrew gelman stats-2010-04-29-Alternatives to regression for social science predictions</a></p>
<p>Introduction: Somebody named David writes:
  
I [David] thought you might be interested or have an opinion on the paper referenced below. I am largely skeptical on the techniques presented and thought you might have some insight because you work with datasets more similar to those in ‘social science’ than myself.


Dana and Dawes. The superiority of simple alternatives to regression for social science predictions. Journal of Educational and Behavioral Statistics (2004) vol. 29 (3) pp. 317.
  
My reply:  I read the abstract (available online) and it seemed reasonable to me.  They prefer simple averages or weights based on correlations rather than regressions.  From a Bayesian perspective, what they’re saying is that least-squares regression and similar methods are noisy, and they can do better via massive simplification.  
 
 I’ve been a big fan of Robyn Dawes ever since reading his article in the classic Kahneman, Slovic, and Tversky volume.  I have no idea how much Dawes knows about modern Bayesian</p><p>2 0.79362452 <a title="10-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-Why_we_hate_stepwise_regression.html">2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</a></p>
<p>Introduction: Haynes Goddard writes:
  
I have been slowly working my way through the grad program in stats here, and the latest course was a biostats course on categorical and survival analysis.  I noticed in the semi-parametric  and parametric material (Wang and Lee is the text) that they use stepwise regression a lot.


I learned in econometrics that stepwise is poor practice, as it defaults to the “theory of the regression line”, that is no theory at all, just the variation in the data.


I don’t find the topic on your blog, and wonder if you have addressed the issue.
  
My reply:
 
Stepwise regression is one of these things, like outlier detection and pie charts, which appear to be popular among non-statisticans but are considered by statisticians to be a bit of a joke.  For example, Jennifer and I don’t mention stepwise regression in our book, not even once.
 
To address the issue more directly:  the motivation behind stepwise regression is that you have a lot of potential predictors but not e</p><p>3 0.76345718 <a title="10-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>Introduction: Having established that survey weighting is a mess, I should also acknowledge that, by this standard, regression modeling is also a mess, involving many arbitrary choices of variable selection, transformations and modeling of interaction. Nonetheless, regression modeling is a mess with which I am comfortable and, perhaps more relevant to the discussion, can be extended using multilevel models to get inference for small cross-classifications or small areas. 
  
Weâ&euro;&trade;re working on it.</p><p>4 0.75923449 <a title="10-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-31-Using_factor_analysis_or_principal_components_analysis_or_measurement-error_models_for_biological_measurements_in_archaeology%3F.html">1094 andrew gelman stats-2011-12-31-Using factor analysis or principal components analysis or measurement-error models for biological measurements in archaeology?</a></p>
<p>Introduction: Greg Campbell writes:
  
I am a Canadian archaeologist (BSc in Chemistry) researching the past human use of European Atlantic shellfish. After two decades of practice I am finally getting a MA in archaeology at Reading. I am seeing if the habitat or size of harvested mussels (Mytilus edulis) can be reconstructed from measurements of the umbo (the pointy end, and the only bit that survives well in archaeological deposits) using log-transformed measurements (or allometry; relationships between dimensions are more likely exponential than linear). 
Of course multivariate regressions in most statistics packages (Minitab, SPSS, SAS) assume you are trying to predict one variable from all the others (a Model I regression), and use ordinary least squares to fit the regression line. For organismal dimensions this makes little sense, since all the dimensions are (at least in theory) free to change their mutual proportions during growth. So there is no predictor and predicted, mutual variation of</p><p>5 0.75007695 <a title="10-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>Introduction: Steve Miller writes: 
  
  
Much of what I do is cross-national analyses of survey data (largely World Values Survey). . . . My big question pertains to (what I would call) exploratory analysis of multilevel data, especially when the group-level predictors are of theoretical importance. A lot of what I do involves analyzing cross-national survey items of citizen attitudes, typically of political leadership. These survey items are usually yes/no responses, or four-part responses indicating a level of agreement (strongly agree, agree, disagree, strongly disagree) that can be condensed into a binary variable. I believe these can be explained by reference to country-level factors. Much of the group-level variables of interest are count variables with a modal value of 0, which can be quite messy.


How would you recommend exploring the variation in the dependent variable as it could be explained by the group-level count variable of interest, before fitting the multilevel model itself? When</p><p>6 0.74010801 <a title="10-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-18-Tibshirani_announces_new_research_result%3A__A_significance_test_for_the_lasso.html">1769 andrew gelman stats-2013-03-18-Tibshirani announces new research result:  A significance test for the lasso</a></p>
<p>7 0.73993599 <a title="10-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Matching_and_regression%3A__two_great_tastes_etc_etc.html">796 andrew gelman stats-2011-07-10-Matching and regression:  two great tastes etc etc</a></p>
<p>8 0.7340126 <a title="10-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-06-Slow_progress.html">1445 andrew gelman stats-2012-08-06-Slow progress</a></p>
<p>9 0.7274313 <a title="10-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-05-What_do_practitioners_need_to_know_about_regression%3F.html">451 andrew gelman stats-2010-12-05-What do practitioners need to know about regression?</a></p>
<p>10 0.72525454 <a title="10-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-26-How_to_understand_coefficients_that_reverse_sign_when_you_start_controlling_for_things%3F.html">1870 andrew gelman stats-2013-05-26-How to understand coefficients that reverse sign when you start controlling for things?</a></p>
<p>11 0.72147441 <a title="10-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-09-Same_old_same_old.html">1849 andrew gelman stats-2013-05-09-Same old same old</a></p>
<p>12 0.71476722 <a title="10-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>13 0.7078222 <a title="10-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>14 0.70326358 <a title="10-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>15 0.70148635 <a title="10-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-Displaying_inferences_from_complex_models.html">1815 andrew gelman stats-2013-04-20-Displaying inferences from complex models</a></p>
<p>16 0.70070881 <a title="10-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-15-Still_more_Mr._P_in_public_health.html">770 andrew gelman stats-2011-06-15-Still more Mr. P in public health</a></p>
<p>17 0.69515443 <a title="10-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-19-Just_chaid.html">421 andrew gelman stats-2010-11-19-Just chaid</a></p>
<p>18 0.68787795 <a title="10-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-There_are_never_70_distinct_parameters.html">327 andrew gelman stats-2010-10-07-There are never 70 distinct parameters</a></p>
<p>19 0.68661404 <a title="10-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-20-%E2%80%9CPeople_with_an_itch_to_scratch%E2%80%9D.html">101 andrew gelman stats-2010-06-20-“People with an itch to scratch”</a></p>
<p>20 0.68468291 <a title="10-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-08-Gratuitous_use_of_%E2%80%9CBayesian_Statistics%2C%E2%80%9D_a_branding_issue%3F.html">133 andrew gelman stats-2010-07-08-Gratuitous use of “Bayesian Statistics,” a branding issue?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.013), (5, 0.142), (16, 0.061), (21, 0.034), (24, 0.168), (53, 0.016), (61, 0.013), (76, 0.024), (88, 0.027), (89, 0.033), (99, 0.375)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98043466 <a title="10-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-15-Statistical_analysis_and_visualization_of_the_drug_war_in_Mexico.html">87 andrew gelman stats-2010-06-15-Statistical analysis and visualization of the drug war in Mexico</a></p>
<p>Introduction: Christian points me to this  interesting (but sad) analysis  by Diego Valle with an impressive series of graphs.  There are a few things I’d change (notably the R default settings which result in ridiculously over-indexed y-axes, as well as axes for homicide rates which should (but do not) go town to zero (and sometimes, bizarrely, go negative), and a lack of coherent ordering of the 32 states (including D.F.),
 
I’m no expert on Mexico (despite having coauthored a paper on Mexican politics) so I’ll leave it to others to evaluate the substantive claims in Valle’s blog.  Just looking at what he’s done, though, it seems impressive to me.  To put it another way, it’s like something Nate Silver might do.</p><p>2 0.97972107 <a title="10-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-06-Unconvincing_defense_of_the_recent_Russian_elections%2C_and_a_problem_when_an_official_organ_of_an_academic_society_has_low_standards_for_publication.html">1103 andrew gelman stats-2012-01-06-Unconvincing defense of the recent Russian elections, and a problem when an official organ of an academic society has low standards for publication</a></p>
<p>Introduction: Last month we  reported  on some claims of irregularities in the recent Russian elections.  Just as a reminder, here are a couple graphs:
 
   
 
   
 
Yesterday someone pointed me to two online articles:  Mathematical proof of fraud in Russian elections unsound  and  US elections are as ‘non-normal’ as Russian elections .
 
I know nothing about Russian elections and will defer to the author and his commenters on the details.  That said, I don’t find the arguments to be at all persuasive.  The protesters show drastic differences between the patterns of votes of Putin’s party and the others, and the linked articles seem a bit too eager to debunk.
 
I wouldn’t necessarily blog on this but I was unhappy to see this material on the website of Significance, which is an official publication of the American Statistical Association and the Royal Statistical Society.
 
The quality control at this site seems low.  I clicked through the links and found  this :
  
Barring the revelation of a hoax</p><p>same-blog 3 0.97706211 <a title="10-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-29-Alternatives_to_regression_for_social_science_predictions.html">10 andrew gelman stats-2010-04-29-Alternatives to regression for social science predictions</a></p>
<p>Introduction: Somebody named David writes:
  
I [David] thought you might be interested or have an opinion on the paper referenced below. I am largely skeptical on the techniques presented and thought you might have some insight because you work with datasets more similar to those in ‘social science’ than myself.


Dana and Dawes. The superiority of simple alternatives to regression for social science predictions. Journal of Educational and Behavioral Statistics (2004) vol. 29 (3) pp. 317.
  
My reply:  I read the abstract (available online) and it seemed reasonable to me.  They prefer simple averages or weights based on correlations rather than regressions.  From a Bayesian perspective, what they’re saying is that least-squares regression and similar methods are noisy, and they can do better via massive simplification.  
 
 I’ve been a big fan of Robyn Dawes ever since reading his article in the classic Kahneman, Slovic, and Tversky volume.  I have no idea how much Dawes knows about modern Bayesian</p><p>4 0.97679377 <a title="10-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-12-How_to_best_graph_the_Beveridge_curve%2C_relating_the_vacancy_rate_in_jobs_to_the_unemployment_rate%3F.html">1894 andrew gelman stats-2013-06-12-How to best graph the Beveridge curve, relating the vacancy rate in jobs to the unemployment rate?</a></p>
<p>Introduction: Jonathan Robinson writes:
  
I’m a survey researcher who mostly does political work, but I also have a strong interest in economics.  I have a question about this graph you commonly see in the economics literature. It is of a concept called the Beveridge Curve [recently in the newspaper  here ]. It is one of the more interesting concepts in labor economics, relating the vacancy rate in jobs to the unemployment rate. A  good primer is  here .


However, despite being one of the more interesting concepts in economics, the way it is displayed visually is nothing short of atrocious:


 


These graphs are nothing short of unreadable and pretty much the standard (Brad Delong has linked to this graph above and it can appear like this in publication as well). I’ve only really seen one representation of the curve that is more clear than this and it is at  this link :


 


 


Do you have any ideas of any way of making these graphs more readable? I like the second Cleveland Fed graph, but I ha</p><p>5 0.97598147 <a title="10-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-27-A_Non-random_Walk_Down_Campaign_Street.html">1512 andrew gelman stats-2012-09-27-A Non-random Walk Down Campaign Street</a></p>
<p>Introduction: Political campaigns are commonly understood as random walks, during which, at any point in time, the level of support for any party or candidate is equally likely to go up or down. Each shift in the polls is then interpreted as the result of some combination of news and campaign strategies.
 
A completely different story of campaigns is the mean reversion model in which the elections are determined by fundamental factors of the economy and partisanship; the role of the campaign is to give voters a chance to reach their predetermined positions.
 
The popularity of the random walk model for polls may be partially explained via analogy to the widespread idea that stock prices reflect all available information, as popularized in Burton Malkiel’s book, A Random Walk Down Wall Street.  Once the idea has sunk in that short-term changes in the stock market are inherently unpredictable, it is natural for journalists to think the same of polls.  For example, political analyst Nate Silver  wrote</p><p>6 0.97466791 <a title="10-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-25-Is_there_too_much_coauthorship_in_economics_%28and_science_more_generally%29%3F__Or_too_little%3F.html">1914 andrew gelman stats-2013-06-25-Is there too much coauthorship in economics (and science more generally)?  Or too little?</a></p>
<p>7 0.97330856 <a title="10-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-12-%E2%80%9CTied_for_Warmest_Year_On_Record%E2%80%9D.html">513 andrew gelman stats-2011-01-12-“Tied for Warmest Year On Record”</a></p>
<p>8 0.97120082 <a title="10-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-07-A_note_to_John.html">131 andrew gelman stats-2010-07-07-A note to John</a></p>
<p>9 0.96813011 <a title="10-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-03-Some_thoughts_on_election_forecasting.html">391 andrew gelman stats-2010-11-03-Some thoughts on election forecasting</a></p>
<p>10 0.96357596 <a title="10-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-22-Politics_is_not_a_random_walk%3A__Momentum_and_mean_reversion_in_polling.html">364 andrew gelman stats-2010-10-22-Politics is not a random walk:  Momentum and mean reversion in polling</a></p>
<p>11 0.96296549 <a title="10-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_Grinch_Comes_Back.html">1606 andrew gelman stats-2012-12-05-The Grinch Comes Back</a></p>
<p>12 0.9605583 <a title="10-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-11-Rational_Turbulence.html">1052 andrew gelman stats-2011-12-11-Rational Turbulence</a></p>
<p>13 0.95729607 <a title="10-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-21-Two_reviews_of_Nate_Silver%E2%80%99s_new_book%2C_from_Kaiser_Fung_and_Cathy_O%E2%80%99Neil.html">1634 andrew gelman stats-2012-12-21-Two reviews of Nate Silver’s new book, from Kaiser Fung and Cathy O’Neil</a></p>
<p>14 0.95523846 <a title="10-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-28-Agreement_Groups_in_US_Senate_and_Dynamic_Clustering.html">1286 andrew gelman stats-2012-04-28-Agreement Groups in US Senate and Dynamic Clustering</a></p>
<p>15 0.9550817 <a title="10-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-07-Hangman_tips.html">1250 andrew gelman stats-2012-04-07-Hangman tips</a></p>
<p>16 0.95228481 <a title="10-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-02-%E2%80%9CIl_y_a_beaucoup_de_candidats_d%C3%A9mocrates%2C_et_leurs_id%C3%A9ologies_ne_sont_pas_tr%C3%A8s_diff%C3%A9rentes._Et_la_participation_est_impr%C3%A9visible.%E2%80%9D.html">2005 andrew gelman stats-2013-09-02-“Il y a beaucoup de candidats démocrates, et leurs idéologies ne sont pas très différentes. Et la participation est imprévisible.”</a></p>
<p>17 0.95142794 <a title="10-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-25-Why_I_decided_not_to_be_a_physicist.html">2347 andrew gelman stats-2014-05-25-Why I decided not to be a physicist</a></p>
<p>18 0.95140576 <a title="10-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>19 0.95104033 <a title="10-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-31-A_data_visualization_manifesto.html">61 andrew gelman stats-2010-05-31-A data visualization manifesto</a></p>
<p>20 0.94940877 <a title="10-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-16-Infovis_and_statgraphics_update_update.html">855 andrew gelman stats-2011-08-16-Infovis and statgraphics update update</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
