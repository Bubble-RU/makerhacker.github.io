<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>472 andrew gelman stats-2010-12-17-So-called fixed and random effects</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-472" href="#">andrew_gelman_stats-2010-472</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>472 andrew gelman stats-2010-12-17-So-called fixed and random effects</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-472-html" href="http://andrewgelman.com/2010/12/17/so-called_fixed/">html</a></p><p>Introduction: Someone writes:
  
I am hoping you can give me some advice about when to use fixed and random effects model. I am currently working on a paper that examines the effect of . . . by comparing states . . .


It got reviewed . . . by three economists and all suggest that we run a fixed effects model.  We ran a hierarchial model in the paper that allow the intercept and slope to vary before and after . . . My question is which is correct? We have ran it both ways and really it makes no difference which model you run, the results are very similar. But for my own learning, I would really like to understand which to use under what circumstances.  Is the fact that we use the whole population reason enough to just run a fixed effect model?


Perhaps you can suggest a good reference to this question of when to run a fixed vs. random effects model.
  
I’m not always sure what is meant by a “fixed effects model”; see my paper on Anova for discussion of the problems with this terminology:
 
http://w</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Someone writes:    I am hoping you can give me some advice about when to use fixed and random effects model. [sent-1, score-1.078]
</p><p>2 I am currently working on a paper that examines the effect of . [sent-2, score-0.538]
</p><p>3 by three economists and all suggest that we run a fixed effects model. [sent-11, score-1.091]
</p><p>4 We ran a hierarchial model in the paper that allow the intercept and slope to vary before and after . [sent-12, score-1.017]
</p><p>5 We have ran it both ways and really it makes no difference which model you run, the results are very similar. [sent-16, score-0.385]
</p><p>6 But for my own learning, I would really like to understand which to use under what circumstances. [sent-17, score-0.165]
</p><p>7 Is the fact that we use the whole population reason enough to just run a fixed effect model? [sent-18, score-1.397]
</p><p>8 Perhaps you can suggest a good reference to this question of when to run a fixed vs. [sent-19, score-1.013]
</p><p>9 I’m not always sure what is meant by a “fixed effects model”; see my paper on Anova for discussion of the problems with this terminology:   http://www. [sent-21, score-0.665]
</p><p>10 pdf   Sometimes there is a concern about fitting multilevel models when there are correlations; see this paper for discussion of how to deal with this:   http://www. [sent-25, score-0.676]
</p><p>11 pdf   The short answer to your question is that, no, the fact that you use the whole population should not determine the model you fit. [sent-29, score-1.01]
</p><p>12 In particular, there is no reason for you to use a model with group-level variance equal to infinity. [sent-30, score-0.641]
</p><p>13 There is various literature with conflicting recommendations on the topic (see my Anova paper for references), but, as I discuss in that paper, a lot of these recommendations are less coherent than they might seem at first. [sent-31, score-0.921]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fixed', 0.402), ('run', 0.26), ('anova', 0.244), ('paper', 0.213), ('effects', 0.212), ('model', 0.202), ('recommendations', 0.2), ('ran', 0.183), ('use', 0.165), ('http', 0.154), ('examines', 0.144), ('suggest', 0.144), ('conflicting', 0.141), ('random', 0.13), ('population', 0.129), ('terminology', 0.128), ('intercept', 0.126), ('whole', 0.125), ('question', 0.121), ('slope', 0.121), ('fact', 0.111), ('reviewed', 0.106), ('reason', 0.104), ('coherent', 0.102), ('effect', 0.101), ('hoping', 0.096), ('equal', 0.093), ('references', 0.093), ('vary', 0.092), ('correlations', 0.091), ('determine', 0.091), ('meant', 0.088), ('concern', 0.087), ('reference', 0.086), ('discussion', 0.084), ('comparing', 0.081), ('fitting', 0.08), ('currently', 0.08), ('allow', 0.08), ('variance', 0.077), ('advice', 0.073), ('economists', 0.073), ('learning', 0.073), ('deal', 0.073), ('multilevel', 0.071), ('see', 0.068), ('states', 0.067), ('correct', 0.067), ('short', 0.066), ('discuss', 0.065)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="472-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>Introduction: Someone writes:
  
I am hoping you can give me some advice about when to use fixed and random effects model. I am currently working on a paper that examines the effect of . . . by comparing states . . .


It got reviewed . . . by three economists and all suggest that we run a fixed effects model.  We ran a hierarchial model in the paper that allow the intercept and slope to vary before and after . . . My question is which is correct? We have ran it both ways and really it makes no difference which model you run, the results are very similar. But for my own learning, I would really like to understand which to use under what circumstances.  Is the fact that we use the whole population reason enough to just run a fixed effect model?


Perhaps you can suggest a good reference to this question of when to run a fixed vs. random effects model.
  
I’m not always sure what is meant by a “fixed effects model”; see my paper on Anova for discussion of the problems with this terminology:
 
http://w</p><p>2 0.29945976 <a title="472-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Fixed_effects_and_identification.html">1241 andrew gelman stats-2012-04-02-Fixed effects and identification</a></p>
<p>Introduction: Tom Clark writes:
  
Drew Linzer and I [Tom] have been working on a paper about the use of modeled (“random”) and unmodeled (“fixed”) effects. Not directly in response to the paper, but in conversations about the topic over the past few months, several people have said to us things to the effect of “I prefer fixed effects over random effects because I care about identification.” Neither Drew nor I has any idea what this comment is supposed to mean. Have you come across someone saying something like this? Do you have any thoughts about what these people could possibly mean? I want to respond to this concern when people raise it, but I have failed thus far to inquire what is meant and so do not know what to say.
  
My reply:
 
I have a “cultural” reply, which is that so-called fixed effects are thought to make fewer assumptions, and making fewer assumptions is considered a generally good thing that serious people do, and identification is considered a concern of serious people, so they g</p><p>3 0.28568819 <a title="472-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>Introduction: Stuart Buck writes:
  
I have a question about  fixed effects vs. random effects . Amongst economists who study teacher value-added, it has become common to see people saying that they estimated teacher fixed effects (via least squares dummy variables, so that there is a parameter for each teacher), but that they then applied empirical Bayes shrinkage so that the teacher effects are brought closer to the mean.  (See  this paper  by Jacob and Lefgren, for example.)


Can that really be what they are doing? Why wouldn’t they just run random (modeled) effects in the first place? I feel like there’s something I’m missing.
  
My reply:  I don’t know the full story here, but I’m thinking there are two goals, first to get an unbiased estimate of an overall treatment effect (and there the econometricians prefer so-called fixed effects; I disagree with them on this but I know where they’re coming from) and second to estimate individual teacher effects (and there it makes sense to use so-called</p><p>4 0.28141224 <a title="472-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>Introduction: A research psychologist writes in with a question that’s so long that I’ll put my answer first, then put the question itself below the fold.
 
Here’s my reply:
 
As I wrote in my Anova paper and in my book with Jennifer Hill, I do think that multilevel models can completely replace Anova.  At the same time, I think the central idea of Anova should persist in our understanding of these models.  To me the central idea of Anova is not F-tests or p-values or sums of squares, but rather the idea of predicting an outcome based on factors with discrete levels, and understanding these factors using variance components.
 
The continuous or categorical response thing doesn’t really matter so much to me.  I have no problem using a normal linear model for continuous outcomes (perhaps suitably transformed) and a logistic model for binary outcomes.
 
I don’t want to throw away interactions just because they’re not statistically significant.  I’d rather partially pool them toward zero using an inform</p><p>5 0.25873703 <a title="472-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>Introduction: Fred Wu writes: 
  
  
I work at National Prescribing Services in Australia.  I have a database representing say, antidiabetic drug utilisation for the entire Australia in the past few years. I planned to do a longitudinal analysis across GP Division Network (112 divisions in AUS) using mixed-effects models (or as you called in your book varying intercept and varying slope) on this data. 


The problem here is: as data actually represent the population who use antidiabetic drugs in AUS, should I use 112 fixed dummy variables to capture the random variations or use varying intercept and varying slope for the model ? Because some one may aruge, like divisions in AUS or states in USA can hardly be considered from a “superpopulation”, then fixed dummies should be used.  What I think is the population are those who use the drugs, what will happen when the rest need to use them? In terms of exchangeability, using varying intercept and varying slopes can be justified.


Also you provided in y</p><p>6 0.19095907 <a title="472-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>7 0.18695271 <a title="472-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-14-Trying_to_be_precise_about_vagueness.html">342 andrew gelman stats-2010-10-14-Trying to be precise about vagueness</a></p>
<p>8 0.18390471 <a title="472-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>9 0.1834217 <a title="472-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>10 0.16709195 <a title="472-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>11 0.16484305 <a title="472-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>12 0.15948689 <a title="472-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>13 0.15418218 <a title="472-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>14 0.1490286 <a title="472-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>15 0.14132926 <a title="472-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>16 0.13932472 <a title="472-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-How_do_you_interpret_standard_errors_from_a_regression_fit_to_the_entire_population%3F.html">972 andrew gelman stats-2011-10-25-How do you interpret standard errors from a regression fit to the entire population?</a></p>
<p>17 0.13762057 <a title="472-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-Clutering_and_variance_components.html">417 andrew gelman stats-2010-11-17-Clutering and variance components</a></p>
<p>18 0.13431656 <a title="472-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>19 0.13024877 <a title="472-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>20 0.12934805 <a title="472-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-Fun_fight_over_the_Grover_search_algorithm.html">1120 andrew gelman stats-2012-01-15-Fun fight over the Grover search algorithm</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.227), (1, 0.134), (2, 0.075), (3, -0.089), (4, 0.077), (5, 0.005), (6, 0.022), (7, -0.105), (8, 0.125), (9, 0.065), (10, 0.019), (11, 0.048), (12, 0.014), (13, -0.045), (14, 0.062), (15, 0.009), (16, -0.054), (17, 0.045), (18, -0.078), (19, 0.065), (20, -0.017), (21, -0.017), (22, -0.019), (23, -0.027), (24, -0.084), (25, -0.086), (26, -0.13), (27, 0.132), (28, -0.01), (29, 0.002), (30, -0.03), (31, -0.035), (32, -0.052), (33, -0.037), (34, 0.017), (35, -0.041), (36, -0.048), (37, -0.021), (38, -0.007), (39, 0.033), (40, 0.049), (41, -0.057), (42, 0.052), (43, 0.058), (44, -0.057), (45, 0.013), (46, 0.044), (47, -0.097), (48, -0.038), (49, 0.052)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97289449 <a title="472-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>Introduction: Someone writes:
  
I am hoping you can give me some advice about when to use fixed and random effects model. I am currently working on a paper that examines the effect of . . . by comparing states . . .


It got reviewed . . . by three economists and all suggest that we run a fixed effects model.  We ran a hierarchial model in the paper that allow the intercept and slope to vary before and after . . . My question is which is correct? We have ran it both ways and really it makes no difference which model you run, the results are very similar. But for my own learning, I would really like to understand which to use under what circumstances.  Is the fact that we use the whole population reason enough to just run a fixed effect model?


Perhaps you can suggest a good reference to this question of when to run a fixed vs. random effects model.
  
I’m not always sure what is meant by a “fixed effects model”; see my paper on Anova for discussion of the problems with this terminology:
 
http://w</p><p>2 0.8885836 <a title="472-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Fixed_effects_and_identification.html">1241 andrew gelman stats-2012-04-02-Fixed effects and identification</a></p>
<p>Introduction: Tom Clark writes:
  
Drew Linzer and I [Tom] have been working on a paper about the use of modeled (“random”) and unmodeled (“fixed”) effects. Not directly in response to the paper, but in conversations about the topic over the past few months, several people have said to us things to the effect of “I prefer fixed effects over random effects because I care about identification.” Neither Drew nor I has any idea what this comment is supposed to mean. Have you come across someone saying something like this? Do you have any thoughts about what these people could possibly mean? I want to respond to this concern when people raise it, but I have failed thus far to inquire what is meant and so do not know what to say.
  
My reply:
 
I have a “cultural” reply, which is that so-called fixed effects are thought to make fewer assumptions, and making fewer assumptions is considered a generally good thing that serious people do, and identification is considered a concern of serious people, so they g</p><p>3 0.85323876 <a title="472-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>Introduction: Fred Wu writes: 
  
  
I work at National Prescribing Services in Australia.  I have a database representing say, antidiabetic drug utilisation for the entire Australia in the past few years. I planned to do a longitudinal analysis across GP Division Network (112 divisions in AUS) using mixed-effects models (or as you called in your book varying intercept and varying slope) on this data. 


The problem here is: as data actually represent the population who use antidiabetic drugs in AUS, should I use 112 fixed dummy variables to capture the random variations or use varying intercept and varying slope for the model ? Because some one may aruge, like divisions in AUS or states in USA can hardly be considered from a “superpopulation”, then fixed dummies should be used.  What I think is the population are those who use the drugs, what will happen when the rest need to use them? In terms of exchangeability, using varying intercept and varying slopes can be justified.


Also you provided in y</p><p>4 0.83682919 <a title="472-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>Introduction: Stuart Buck writes:
  
I have a question about  fixed effects vs. random effects . Amongst economists who study teacher value-added, it has become common to see people saying that they estimated teacher fixed effects (via least squares dummy variables, so that there is a parameter for each teacher), but that they then applied empirical Bayes shrinkage so that the teacher effects are brought closer to the mean.  (See  this paper  by Jacob and Lefgren, for example.)


Can that really be what they are doing? Why wouldn’t they just run random (modeled) effects in the first place? I feel like there’s something I’m missing.
  
My reply:  I don’t know the full story here, but I’m thinking there are two goals, first to get an unbiased estimate of an overall treatment effect (and there the econometricians prefer so-called fixed effects; I disagree with them on this but I know where they’re coming from) and second to estimate individual teacher effects (and there it makes sense to use so-called</p><p>5 0.82638431 <a title="472-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>Introduction: I received the following email from someone who wishes to remain anonymous:
  
My colleague and I are trying to understand the best way to approach a problem involving measuring a group of individuals’ abilities across time, and are hoping you can offer some guidance.


We are trying to analyze the combined effect of two distinct groups of people (A and B, with no overlap between A and B) who collaborate to produce a binary outcome, using a mixed logistic regression along the lines of the following.


Outcome ~ (1 | A) + (1 | B) + Other variables


What we’re interested in testing was whether the observed A random effects in period  1 are predictive of the A random effects in the following period 2.  Our idea being create two models, each using a different period’s worth of data, to create two sets of A coefficients, then observe the relationship between the two.  If the A’s have a persistent ability across periods, the coefficients should be correlated or show a linear-ish relationshi</p><p>6 0.81854039 <a title="472-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>7 0.80570734 <a title="472-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>8 0.80501556 <a title="472-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>9 0.79776108 <a title="472-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-21-Finite-population_Anova_calculations_for_models_with_interactions.html">1686 andrew gelman stats-2013-01-21-Finite-population Anova calculations for models with interactions</a></p>
<p>10 0.79360378 <a title="472-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>11 0.77122372 <a title="472-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>12 0.75882131 <a title="472-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-Clutering_and_variance_components.html">417 andrew gelman stats-2010-11-17-Clutering and variance components</a></p>
<p>13 0.7536723 <a title="472-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>14 0.74802864 <a title="472-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>15 0.74596632 <a title="472-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Sof%5Bt%5D.html">77 andrew gelman stats-2010-06-09-Sof[t]</a></p>
<p>16 0.73708105 <a title="472-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>17 0.733441 <a title="472-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-12-year_%2B_%281%7Cyear%29.html">851 andrew gelman stats-2011-08-12-year + (1|year)</a></p>
<p>18 0.7311461 <a title="472-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-10-R_vs._Stata%2C_or%2C_Different_ways_to_estimate_multilevel_models.html">269 andrew gelman stats-2010-09-10-R vs. Stata, or, Different ways to estimate multilevel models</a></p>
<p>19 0.71390229 <a title="472-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>20 0.71057314 <a title="472-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Including_interactions_or_not.html">823 andrew gelman stats-2011-07-26-Including interactions or not</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(7, 0.036), (15, 0.026), (16, 0.076), (24, 0.125), (64, 0.023), (76, 0.012), (79, 0.045), (84, 0.044), (95, 0.049), (99, 0.458)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99020147 <a title="472-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>Introduction: Someone writes:
  
I am hoping you can give me some advice about when to use fixed and random effects model. I am currently working on a paper that examines the effect of . . . by comparing states . . .


It got reviewed . . . by three economists and all suggest that we run a fixed effects model.  We ran a hierarchial model in the paper that allow the intercept and slope to vary before and after . . . My question is which is correct? We have ran it both ways and really it makes no difference which model you run, the results are very similar. But for my own learning, I would really like to understand which to use under what circumstances.  Is the fact that we use the whole population reason enough to just run a fixed effect model?


Perhaps you can suggest a good reference to this question of when to run a fixed vs. random effects model.
  
I’m not always sure what is meant by a “fixed effects model”; see my paper on Anova for discussion of the problems with this terminology:
 
http://w</p><p>2 0.98230672 <a title="472-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Data_problems%2C_coding_errors%E2%80%A6what_can_be_done%3F.html">1807 andrew gelman stats-2013-04-17-Data problems, coding errors…what can be done?</a></p>
<p>Introduction: This post is by Phil
 
A  recent post on this blog  discusses a prominent case of an Excel error leading to substantially wrong results from a statistical analysis. Excel is notorious for this because it is easy to add a row or column of data (or intermediate results) but forget to update equations so that they correctly use the new data. That particular error is less common in a language like R because R programmers usually refer to data by variable name (or by applying functions to a named variable), so the same code works even if you add or remove data.
 
Still, there is plenty of opportunity for errors no matter what language one uses. Andrew  ran into problems  fairly recently, and also blogged about  another instance.  I’ve never had to retract a paper, but that’s partly because I haven’t published a whole lot of papers. Certainly I have found plenty of substantial errors pretty late in some of my data analyses, and I obviously don’t have sufficient mechanisms in place to be sure</p><p>3 0.98224497 <a title="472-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-15-Economics_now_%3D_Freudian_psychology_in_the_1950s%3A__More_on_the_incoherence_of_%E2%80%9Ceconomics_exceptionalism%E2%80%9D.html">1213 andrew gelman stats-2012-03-15-Economics now = Freudian psychology in the 1950s:  More on the incoherence of “economics exceptionalism”</a></p>
<p>Introduction: What follows is a long response to a comment on  someone else’s blog .  The quote is, “Thinking like an economist simply means that you scientifically approach human social behavior. . . .”
 
I’ll give the context in a bit, but first let me say that I thought this topic might be worth one more discussion because I suspect that the sort of economics exceptionalism that I will discuss is widely disseminated in college econ courses as well as in books such as the Freakonomics series.
 
It’s great to have pride in human achievements but at some point too much group self-regard can be distorting.
 
My best analogy to economics exceptionalism is Freudianism in the 1950s:  Back then, Freudian psychiatrists were on the top of the world.  Not only were they well paid, well respected, and secure in their theoretical foundations, they were also at the center of many important conversations.  Even those people who disagreed with them felt the need to explain why the Freudians were wrong.  Freudian</p><p>4 0.9818393 <a title="472-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-02-Experimental_reasoning_in_social_science.html">785 andrew gelman stats-2011-07-02-Experimental reasoning in social science</a></p>
<p>Introduction: As a statistician, I was trained to think of randomized experimentation as representing the gold standard of knowledge in the social sciences, and, despite having seen occasional arguments to the contrary, I still hold that view, expressed pithily by Box, Hunter, and Hunter (1978) that “To find out what happens when you change something, it is necessary to change it.”
 
At the same time, in my capacity as a social scientist, I’ve published many applied research papers, almost none of which have used experimental data.
 
In the present article, I’ll address the following questions:
 
1.  Why do I agree with the consensus characterization of randomized experimentation as a gold standard?
 
2.  Given point 1 above, why does almost all my research use observational data?
 
In confronting these issues, we must consider some general issues in the strategy of social science research. We also take from the psychology methods literature a more nuanced perspective that considers several differen</p><p>5 0.98101723 <a title="472-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-26-Any_good_articles_on_the_use_of_error_bars%3F.html">822 andrew gelman stats-2011-07-26-Any good articles on the use of error bars?</a></p>
<p>Introduction: Hadley Wickham asks:
  
I was wondering if you knew of any good articles on the use of error bars.  I’m particularly looking for articles that discuss the difference between error of means and error of difference in the context of models (e.g. mixed models) where they are very different.  I suspect every applied field has a couple of good articles, but it’s really hard to search for them.
  
Can anyone help on this?  My only advice is to get rid of those horrible crossbars at the ends of the error bars.  The crossbars draw attention to the error bars’ endpoints, which are generally not important at all.  See, for example,  my Anova paper , for some examples of how I like error bars to look.</p><p>6 0.98066324 <a title="472-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-26-Teaching_yourself_mathematics.html">236 andrew gelman stats-2010-08-26-Teaching yourself mathematics</a></p>
<p>7 0.97981358 <a title="472-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-14-In_an_introductory_course%2C_when_does_learning_occur%3F.html">277 andrew gelman stats-2010-09-14-In an introductory course, when does learning occur?</a></p>
<p>8 0.97973537 <a title="472-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-13-Lame_Statistics_Patents.html">1761 andrew gelman stats-2013-03-13-Lame Statistics Patents</a></p>
<p>9 0.97968704 <a title="472-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-22-Battle_of_the_Repo_Man_quotes%3A__Reid_Hastie%E2%80%99s_turn.html">1336 andrew gelman stats-2012-05-22-Battle of the Repo Man quotes:  Reid Hastie’s turn</a></p>
<p>10 0.97966647 <a title="472-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-10-Controversy_over_the_Christakis-Fowler_findings_on_the_contagion_of_obesity.html">757 andrew gelman stats-2011-06-10-Controversy over the Christakis-Fowler findings on the contagion of obesity</a></p>
<p>11 0.97933233 <a title="472-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-07-Looking_for_a_purpose_in_life%3A__Update_on_that_underworked_and_overpaid_sociologist_whose_%E2%80%9Cmain_task_as_a_university_professor_was_self-cultivation%E2%80%9D.html">750 andrew gelman stats-2011-06-07-Looking for a purpose in life:  Update on that underworked and overpaid sociologist whose “main task as a university professor was self-cultivation”</a></p>
<p>12 0.97906792 <a title="472-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>13 0.97901058 <a title="472-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-08-Stop_me_before_I_aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">1372 andrew gelman stats-2012-06-08-Stop me before I aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>14 0.97882926 <a title="472-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-02-Am_I_too_negative%3F.html">2279 andrew gelman stats-2014-04-02-Am I too negative?</a></p>
<p>15 0.97851628 <a title="472-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-19-Is_coffee_a_killer%3F__I_don%E2%80%99t_think_the_effect_is_as_high_as_was_estimated_from_the_highest_number_that_came_out_of_a_noisy_study.html">2030 andrew gelman stats-2013-09-19-Is coffee a killer?  I don’t think the effect is as high as was estimated from the highest number that came out of a noisy study</a></p>
<p>16 0.9783501 <a title="472-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-29-We_go_to_war_with_the_data_we_have%2C_not_the_data_we_want.html">1289 andrew gelman stats-2012-04-29-We go to war with the data we have, not the data we want</a></p>
<p>17 0.97814023 <a title="472-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-%E2%80%9CTo_find_out_what_happens_when_you_change_something%2C_it_is_necessary_to_change_it.%E2%80%9D.html">186 andrew gelman stats-2010-08-04-“To find out what happens when you change something, it is necessary to change it.”</a></p>
<p>18 0.9780426 <a title="472-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-04-Does_it_matter_that_a_sample_is_unrepresentative%3F__It_depends_on_the_size_of_the_treatment_interactions.html">2008 andrew gelman stats-2013-09-04-Does it matter that a sample is unrepresentative?  It depends on the size of the treatment interactions</a></p>
<p>19 0.97804183 <a title="472-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-27-Should_statistics_have_a_Nobel_prize%3F.html">2151 andrew gelman stats-2013-12-27-Should statistics have a Nobel prize?</a></p>
<p>20 0.97792292 <a title="472-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-Another_reason_why_you_can_get_good_inferences_from_a_bad_model.html">1527 andrew gelman stats-2012-10-10-Another reason why you can get good inferences from a bad model</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
