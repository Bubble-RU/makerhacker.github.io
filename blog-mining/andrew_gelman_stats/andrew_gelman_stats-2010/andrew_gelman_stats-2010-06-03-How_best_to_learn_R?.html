<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>65 andrew gelman stats-2010-06-03-How best to learn R?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-65" href="#">andrew_gelman_stats-2010-65</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>65 andrew gelman stats-2010-06-03-How best to learn R?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-65-html" href="http://andrewgelman.com/2010/06/03/how_best_to_lea/">html</a></p><p>Introduction: Alban Zeber writes:
  
I am wondering whether there is a reference (online or book) that you would recommend to someone who is interested in learning how to program in R.
  
Any thoughts?
 
P.S.  If I had a name like that, my books would be named, “Bayesian Statistics from A to Z,” “Teaching Statistics from A to Z,” “Regression and Multilevel Modeling from A to Z,” and so forth.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Alban Zeber writes:    I am wondering whether there is a reference (online or book) that you would recommend to someone who is interested in learning how to program in R. [sent-1, score-1.419]
</p><p>2 If I had a name like that, my books would be named, “Bayesian Statistics from A to Z,” “Teaching Statistics from A to Z,” “Regression and Multilevel Modeling from A to Z,” and so forth. [sent-5, score-0.478]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('alban', 0.424), ('zeber', 0.424), ('forth', 0.251), ('named', 0.23), ('reference', 0.214), ('wondering', 0.199), ('online', 0.188), ('recommend', 0.184), ('program', 0.183), ('teaching', 0.182), ('learning', 0.18), ('statistics', 0.177), ('multilevel', 0.176), ('name', 0.17), ('books', 0.169), ('thoughts', 0.164), ('modeling', 0.147), ('regression', 0.136), ('interested', 0.125), ('whether', 0.121), ('someone', 0.12), ('book', 0.111), ('bayesian', 0.11), ('would', 0.093), ('writes', 0.064), ('like', 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="65-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-03-How_best_to_learn_R%3F.html">65 andrew gelman stats-2010-06-03-How best to learn R?</a></p>
<p>Introduction: Alban Zeber writes:
  
I am wondering whether there is a reference (online or book) that you would recommend to someone who is interested in learning how to program in R.
  
Any thoughts?
 
P.S.  If I had a name like that, my books would be named, “Bayesian Statistics from A to Z,” “Teaching Statistics from A to Z,” “Regression and Multilevel Modeling from A to Z,” and so forth.</p><p>2 0.16940984 <a title="65-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-05-A_locally_organized_online_BDA_course_on_G%2B_hangout%3F.html">2009 andrew gelman stats-2013-09-05-A locally organized online BDA course on G+ hangout?</a></p>
<p>Introduction: Eoin Lawless wrote me:
  
I’ve been reading your blog (and  John Kruschke ‘s) for several months now, as a result of starting to learn Bayesian methods from Doing Bayesian Data Analysis [I love the title of that book! --- ed.]. More recently I completed a Coursera course on Data Science. 


I found learning through the medium of a online course to be an amazing experience. It does not replace books, but learning new material at the same time as other people and discussing it in the forums is very motivational. Additionally it is much easier to work through exercises and projects when there is a deadline and some element of competition than to plow through the end of chapter exercises in a book. This is especially true, I believe, when the learning is for a long term goal, rather than to be used immediately in work, for example.


My question: you are obviously evangelical about the benefits that Bayesian statistics brings, have you ever considered producing a Coursera (or similar) cour</p><p>3 0.14754042 <a title="65-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-19-Analysis_of_survey_data%3A_Design_based_models_vs._hierarchical_modeling%3F.html">352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</a></p>
<p>Introduction: Alban Zeber writes:
  
 
Suppose I have survey data from  say 10 countries where by each country collected the data based on different sampling routines –  the results of this being that  each country has its own weights for the data that can be used in the analyses. If I analyse the data of each country separately then I can incorporate the survey design in the analyses e.g in Stata once can use svyset …..


But what happens when I want to do a pooled analysis of the all the data from the 10 countries:


Presumably either 


1.  I analyse the data from each country separately (using multiple or logistic regression, …) accounting for the survey design and then combine the estimates using a meta analysis (fixed or random)


  OR


2.  Assume that the data from each country is a simple random sample from the population, combine the data from the 10 countries and then use multilevel or hierarchical models


My question is which of the methods is likely to give better estimates?  Or is the</p><p>4 0.13607965 <a title="65-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-References_%28with_code%29_for_Bayesian_hierarchical_%28multilevel%29_modeling_and_structural_equation_modeling.html">2273 andrew gelman stats-2014-03-29-References (with code) for Bayesian hierarchical (multilevel) modeling and structural equation modeling</a></p>
<p>Introduction: A student writes:
  
I am new to Bayesian methods.  While I am reading your book, I have some questions for you.  I am interested in doing Bayesian hierarchical (multi-level) linear regression (e.g., random-intercept model) and Bayesian structural equation modeling (SEM)—for causality.  Do you happen to know if I could find some articles, where authors could provide data w/ R and/or BUGS codes that I could replicate them?
  
My reply:  For Bayesian hierarchical (multi-level) linear regression and causal inference, see my book with Jennifer Hill.  For Bayesian structural equation modeling, try google and you’ll find some good stuff.  Also, I recommend Stan (http://mc-stan.org/) rather than Bugs.</p><p>5 0.12601978 <a title="65-tfidf-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>Introduction: James O’Brien writes:
  
How would you explain, to a “classically-trained” hypothesis-tester, that “It’s OK to fit a multilevel model even if some groups have only one observation each”?


I [O'Brien] think I understand the logic and the statistical principles at work in this, but I’ve having trouble being clear and persuasive. I also feel like I’m contending with some methodological conventional wisdom here. 
  
My reply:  I’m so used to this idea that I find it difficult to defend it in some sort of general conceptual way.  So let me retreat to a more functional defense, which is that multilevel modeling gives good estimates,  especially  when the number of observations per group is small.
 
One way to see this in any particular example in through cross-validation.  Another way is to consider the alternatives.   If you try really hard you can come up with a “classical hypothesis testing” approach which will do as well as the multilevel model.  It would just take a lot of work.  I’d r</p><p>6 0.12522167 <a title="65-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-%E2%80%9CIs_machine_learning_a_subset_of_statistics%3F%E2%80%9D.html">1740 andrew gelman stats-2013-02-26-“Is machine learning a subset of statistics?”</a></p>
<p>7 0.12399966 <a title="65-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-03-5_books.html">499 andrew gelman stats-2011-01-03-5 books</a></p>
<p>8 0.11514848 <a title="65-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-29-Alternatives_to_regression_for_social_science_predictions.html">10 andrew gelman stats-2010-04-29-Alternatives to regression for social science predictions</a></p>
<p>9 0.10763057 <a title="65-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>10 0.10395713 <a title="65-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Both_R_and_Stata.html">76 andrew gelman stats-2010-06-09-Both R and Stata</a></p>
<p>11 0.10310107 <a title="65-tfidf-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-24-An_interesting_mosaic_of_a_data_programming_course.html">2345 andrew gelman stats-2014-05-24-An interesting mosaic of a data programming course</a></p>
<p>12 0.10201251 <a title="65-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>13 0.10153066 <a title="65-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>14 0.10031297 <a title="65-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Multilevel_quantile_regression.html">397 andrew gelman stats-2010-11-06-Multilevel quantile regression</a></p>
<p>15 0.09882082 <a title="65-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-19-Grad_students%3A__Participate_in_an_online_survey_on_statistics_education.html">1813 andrew gelman stats-2013-04-19-Grad students:  Participate in an online survey on statistics education</a></p>
<p>16 0.098285928 <a title="65-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-06-Slow_progress.html">1445 andrew gelman stats-2012-08-06-Slow progress</a></p>
<p>17 0.096957885 <a title="65-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>18 0.096779861 <a title="65-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<p>19 0.095839813 <a title="65-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>20 0.094024569 <a title="65-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.127), (1, 0.048), (2, -0.082), (3, 0.051), (4, 0.044), (5, 0.139), (6, -0.043), (7, 0.03), (8, 0.059), (9, 0.082), (10, 0.066), (11, -0.037), (12, 0.093), (13, 0.027), (14, 0.132), (15, 0.026), (16, -0.084), (17, 0.032), (18, 0.039), (19, -0.041), (20, 0.031), (21, 0.073), (22, 0.034), (23, 0.04), (24, -0.058), (25, -0.069), (26, 0.001), (27, -0.03), (28, -0.069), (29, -0.018), (30, 0.024), (31, 0.026), (32, -0.035), (33, 0.004), (34, -0.055), (35, 0.038), (36, 0.001), (37, -0.003), (38, -0.034), (39, 0.013), (40, -0.025), (41, -0.038), (42, 0.008), (43, -0.02), (44, 0.008), (45, 0.035), (46, 0.042), (47, 0.065), (48, 0.011), (49, 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98182899 <a title="65-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-03-How_best_to_learn_R%3F.html">65 andrew gelman stats-2010-06-03-How best to learn R?</a></p>
<p>Introduction: Alban Zeber writes:
  
I am wondering whether there is a reference (online or book) that you would recommend to someone who is interested in learning how to program in R.
  
Any thoughts?
 
P.S.  If I had a name like that, my books would be named, “Bayesian Statistics from A to Z,” “Teaching Statistics from A to Z,” “Regression and Multilevel Modeling from A to Z,” and so forth.</p><p>2 0.7414726 <a title="65-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Both_R_and_Stata.html">76 andrew gelman stats-2010-06-09-Both R and Stata</a></p>
<p>Introduction: A student I’m working with writes:
  
I was planning on getting a applied stat text as a desk reference, and for that I’m assuming you’d recommend your own book. Also, being an economics student, I was initially planning on doing my analysis in STATA, but I noticed on your blog that you use R, and apparently so does the rest of the statistics profession. Would you rather I do my programming in R this summer, or does it not matter? It doesn’t look too hard to learn, so just let me know what’s most convenient for you.
  
My reply:  Yes, I recommend my book with Jennifer Hill.  Also the book by John Fox, An R and S-plus Companion to Applied Regression, is a good way to get into R.  I recommend you use both Stata and R.  If you’re already familiar with Stata, then stick with it–it’s a great system for working with big datasets.  You can grab your data in Stata, do some basic manipulations, then save a smaller dataset to read into R (using R’s read.dta() function).  Once you want to make fu</p><p>3 0.69030643 <a title="65-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-05-A_locally_organized_online_BDA_course_on_G%2B_hangout%3F.html">2009 andrew gelman stats-2013-09-05-A locally organized online BDA course on G+ hangout?</a></p>
<p>Introduction: Eoin Lawless wrote me:
  
I’ve been reading your blog (and  John Kruschke ‘s) for several months now, as a result of starting to learn Bayesian methods from Doing Bayesian Data Analysis [I love the title of that book! --- ed.]. More recently I completed a Coursera course on Data Science. 


I found learning through the medium of a online course to be an amazing experience. It does not replace books, but learning new material at the same time as other people and discussing it in the forums is very motivational. Additionally it is much easier to work through exercises and projects when there is a deadline and some element of competition than to plow through the end of chapter exercises in a book. This is especially true, I believe, when the learning is for a long term goal, rather than to be used immediately in work, for example.


My question: you are obviously evangelical about the benefits that Bayesian statistics brings, have you ever considered producing a Coursera (or similar) cour</p><p>4 0.68191344 <a title="65-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-Good_examples_of_lurking_variables%3F.html">1015 andrew gelman stats-2011-11-17-Good examples of lurking variables?</a></p>
<p>Introduction: Rama Ganesan writes:
  
I have been using many of your demos from the Teaching Stats book . . . Do you by any chance have a nice easy dataset that I can use to show students how ‘lurking variables’ work using regression? For instance, in your book you talk about the relationship between height and salaries – where gender is the hidden variable.
  
Any suggestions?</p><p>5 0.68018782 <a title="65-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-19-Sorry%2C_no_ARM_solutions.html">1220 andrew gelman stats-2012-03-19-Sorry, no ARM solutions</a></p>
<p>Introduction: Daniel Gerlanc asks:
  
I’ve been reading your Regression and Multilevel Modeling book. Do you have a set of example solutions for the problems in the book?
  
Henning Piezunka, Adam Lynton, and others have asked the same question.
 
My universal response:
 
I’m glad you like our book.  Unfortunately, we have no solution sets.  I made a bunch of solutions for my earlier book but it was so much work that I decided not to do it a second time!</p><p>6 0.66970646 <a title="65-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-28-Reference_on_longitudinal_models%3F.html">1188 andrew gelman stats-2012-02-28-Reference on longitudinal models?</a></p>
<p>7 0.65966761 <a title="65-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-References_%28with_code%29_for_Bayesian_hierarchical_%28multilevel%29_modeling_and_structural_equation_modeling.html">2273 andrew gelman stats-2014-03-29-References (with code) for Bayesian hierarchical (multilevel) modeling and structural equation modeling</a></p>
<p>8 0.65422767 <a title="65-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-18-What_to_read_to_catch_up_on_multivariate_statistics%3F.html">1726 andrew gelman stats-2013-02-18-What to read to catch up on multivariate statistics?</a></p>
<p>9 0.65304106 <a title="65-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-29-Alternatives_to_regression_for_social_science_predictions.html">10 andrew gelman stats-2010-04-29-Alternatives to regression for social science predictions</a></p>
<p>10 0.6520828 <a title="65-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-05-Any_available_cookbooks_on_Bayesian_designs%3F.html">1199 andrew gelman stats-2012-03-05-Any available cookbooks on Bayesian designs?</a></p>
<p>11 0.64261329 <a title="65-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-25-Good_introductory_book_for_statistical_computation%3F.html">590 andrew gelman stats-2011-02-25-Good introductory book for statistical computation?</a></p>
<p>12 0.63768685 <a title="65-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-Displaying_inferences_from_complex_models.html">1815 andrew gelman stats-2013-04-20-Displaying inferences from complex models</a></p>
<p>13 0.63374144 <a title="65-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>14 0.63070995 <a title="65-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>15 0.6254546 <a title="65-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-11-Free_online_course_in_multilevel_modeling.html">80 andrew gelman stats-2010-06-11-Free online course in multilevel modeling</a></p>
<p>16 0.61962271 <a title="65-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>17 0.61341596 <a title="65-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-26-I_need_a_title_for_my_book_on_ethics_and_statistics%21%21.html">1590 andrew gelman stats-2012-11-26-I need a title for my book on ethics and statistics!!</a></p>
<p>18 0.6113857 <a title="65-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-01-Looking_for_a_textbook_for_a_two-semester_course_in_probability_and_%28theoretical%29_statistics.html">596 andrew gelman stats-2011-03-01-Looking for a textbook for a two-semester course in probability and (theoretical) statistics</a></p>
<p>19 0.61025077 <a title="65-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-21-Bayes_related.html">1948 andrew gelman stats-2013-07-21-Bayes related</a></p>
<p>20 0.60835099 <a title="65-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(24, 0.2), (29, 0.153), (63, 0.037), (86, 0.04), (99, 0.399)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97225982 <a title="65-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-03-How_best_to_learn_R%3F.html">65 andrew gelman stats-2010-06-03-How best to learn R?</a></p>
<p>Introduction: Alban Zeber writes:
  
I am wondering whether there is a reference (online or book) that you would recommend to someone who is interested in learning how to program in R.
  
Any thoughts?
 
P.S.  If I had a name like that, my books would be named, “Bayesian Statistics from A to Z,” “Teaching Statistics from A to Z,” “Regression and Multilevel Modeling from A to Z,” and so forth.</p><p>2 0.96855778 <a title="65-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-21-Workshop_on_science_communication_for_graduate_students.html">1687 andrew gelman stats-2013-01-21-Workshop on science communication for graduate students</a></p>
<p>Introduction: Nathan Sanders writes: 
  
  
Applications are now open for the Communicating Science 2013 workshop (http://workshop.astrobites.com/), to be held in Cambridge, MA on June 13-15th, 2013.  Graduate students at US institutions in all fields of science and engineering are encouraged to apply â&euro;&ldquo; funding is available for travel expenses and accommodations.


The application can be found here: http://workshop.astrobites.org/application


Participants will build the communication skills that technical professionals need to express complex ideas to their peers, experts in other fields, and the general public.  There will be panel discussions on the following topics:


* Engaging Non-Scientific Audiences 
* Science Writing for a Cause 
* Communicating Science Through Fiction 
* Sharing Science with Scientists 
* The World of Non-Academic Publishing 
* Communicating using Multimedia and the Web


In addition to these discussions, ample time is allotted for interacting with the experts and with att</p><p>3 0.96467036 <a title="65-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-10-Update_on_Levitt_paper_on_child_car_seats.html">1491 andrew gelman stats-2012-09-10-Update on Levitt paper on child car seats</a></p>
<p>Introduction: A few years ago I  noted  the following quote from applied microeconomist Steven Levitt:
  
Is it surprising that scientists would try to keep work that disagrees with their findings out of journals? When I told my father that I [Levitt] was sending my work saying car seats are not that effective to medical journals, he laughed and said they would never publish it because of the result, no matter how well done the analysis was. (As is so often the case, he was right, and I eventually published it in an economics journal.)


Within the field of economics, academics work behind the scenes constantly trying to undermine each other. I’ve seen economists do far worse things than pulling tricks in figures. When economists get mixed up in public policy, things get messier.
  
At the time, I expressed dismay about Levitt’s air of (as I read it) amused, world-weary tolerance of scientists behaving against the interest of science.  But I took his story about the car seats at face value.
 
But no</p><p>4 0.96430111 <a title="65-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-A_poll_that_throws_away_data%3F%3F%3F.html">1940 andrew gelman stats-2013-07-16-A poll that throws away data???</a></p>
<p>Introduction: Mark Blumenthal writes: 
  
  
What do you think about the “random rejection” method used by PPP that was attacked at some length today by a Republican pollster.  Our just published post on the debate  includes all the details as I know them. The  Storify of Martino’s tweets  has some additional data tables linked to toward the end.  


Also, more specifically, setting aside Martino’s suggestion of manipulation (which is also quite possible with post-stratification weights), would the PPP method introduce more potential random error than weighting? 
  
From Blumenthal’s blog:
  
B.J. Martino, a senior vice president at the Republican polling firm The Tarrance Group, went on an 30-minute Twitter rant on Tuesday questioning the unorthodox method used by PPP [Public Policy Polling] to select samples and weight data: “Looking at @ppppolls new VA SW. Wondering how many interviews they discarded to get down to 601 completes? Because @ppppolls discards a LOT of interviews. Of 64,811 conducted</p><p>5 0.96193808 <a title="65-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>Introduction: Cosma Shalizi  and  Larry Wasserman  discuss some papers from a conference on Ockham’s Razor.  I don’t have anything new to add on this so let me link to  past blog entries  on the topic and repost the following  from 2004 :
  
A lot has been written in statistics about “parsimony”—that is, the desire to explain phenomena using fewer parameters–but I’ve never seen any good general justification for parsimony.  (I don’t count “Occam’s Razor,” or “Ockham’s Razor,” or whatever, as a justification.  You gotta do better than digging up a 700-year-old quote.)


Maybe it’s because I work in social science, but my feeling is:  if you can approximate reality with just a few parameters, fine.  If you can use more parameters to fold in more information, that’s even better.


In practice, I often use simple models—because they are less effort to fit and, especially, to understand.  But I don’t kid myself that they’re better than more complicated efforts!


My favorite quote on this comes from  Rad</p><p>6 0.96071661 <a title="65-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>7 0.95978862 <a title="65-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-18-You%E2%80%99ll_get_a_high_Type_S_error_rate_if_you_use_classical_statistical_methods_to_analyze_data_from_underpowered_studies.html">1944 andrew gelman stats-2013-07-18-You’ll get a high Type S error rate if you use classical statistical methods to analyze data from underpowered studies</a></p>
<p>8 0.95486045 <a title="65-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-13-Flexibility_is_good.html">2133 andrew gelman stats-2013-12-13-Flexibility is good</a></p>
<p>9 0.95191997 <a title="65-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-13-%E2%80%9CThe_truth_wears_off%3A__Is_there_something_wrong_with_the_scientific_method%3F%E2%80%9D.html">466 andrew gelman stats-2010-12-13-“The truth wears off:  Is there something wrong with the scientific method?”</a></p>
<p>10 0.95007586 <a title="65-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-10-Chris_Chabris_is_irritated_by_Malcolm_Gladwell.html">2057 andrew gelman stats-2013-10-10-Chris Chabris is irritated by Malcolm Gladwell</a></p>
<p>11 0.94954979 <a title="65-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>12 0.94728869 <a title="65-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-24-Blogs_vs._real_journalism.html">868 andrew gelman stats-2011-08-24-Blogs vs. real journalism</a></p>
<p>13 0.94634271 <a title="65-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-25-Question_15_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1344 andrew gelman stats-2012-05-25-Question 15 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>14 0.94506705 <a title="65-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-27-What_is_%E2%80%9Cexplanation%E2%80%9D%3F.html">1742 andrew gelman stats-2013-02-27-What is “explanation”?</a></p>
<p>15 0.94251901 <a title="65-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-06-My_talk_at_Northwestern_University_tomorrow_%28Thursday%29.html">651 andrew gelman stats-2011-04-06-My talk at Northwestern University tomorrow (Thursday)</a></p>
<p>16 0.94190359 <a title="65-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-18-IRB_nightmares.html">1539 andrew gelman stats-2012-10-18-IRB nightmares</a></p>
<p>17 0.93995655 <a title="65-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-22-A_Bayesian_model_for_an_increasing_function%2C_in_Stan%21.html">2110 andrew gelman stats-2013-11-22-A Bayesian model for an increasing function, in Stan!</a></p>
<p>18 0.93955171 <a title="65-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>19 0.93941402 <a title="65-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-%E2%80%9CIt_was_the_opinion_of_the_hearing_that_the_publication_of_the_article_had_brought_the_School_into_disrepute.%E2%80%9D.html">941 andrew gelman stats-2011-10-03-“It was the opinion of the hearing that the publication of the article had brought the School into disrepute.”</a></p>
<p>20 0.93939018 <a title="65-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-11-Incumbency_advantage_in_2010.html">408 andrew gelman stats-2010-11-11-Incumbency advantage in 2010</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
