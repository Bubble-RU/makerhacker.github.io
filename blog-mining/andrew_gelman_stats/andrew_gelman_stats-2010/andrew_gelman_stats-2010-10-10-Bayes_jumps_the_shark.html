<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>331 andrew gelman stats-2010-10-10-Bayes jumps the shark</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-331" href="#">andrew_gelman_stats-2010-331</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>331 andrew gelman stats-2010-10-10-Bayes jumps the shark</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-331-html" href="http://andrewgelman.com/2010/10/10/bayes_jumps_the/">html</a></p><p>Introduction: John Goldin sends in this, from  an interview  with Alan Dershowitz:
  
 
Q:  The lawyerly obligation to not change your mind, to defend a position right or wrong–do you find that it seeps over into the rest of your life?





A:  No, it doesn’t because I’m a professor first, and as a professor I’m always changing my mind. I mean, my students go crazy in my class because I’m the most orthodox Bayesian in the world. [Bayesian probability theory is a way of modeling how the human mind reasons about the world. It assumes that people have prior beliefs about the probability of a given hypothesis and also beliefs about the probability that the hypothesis, if true, would generate the evidence they see. Taken together, these beliefs determine how people update their faith in a hypothesis in light of new evidence.] I do everything based on Bayes analysis, and Bayes analysis is always based on shifting probabilities and constantly changing and being adaptive and fluid.
 

 
Although, who am I t</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 John Goldin sends in this, from  an interview  with Alan Dershowitz:      Q:  The lawyerly obligation to not change your mind, to defend a position right or wrong–do you find that it seeps over into the rest of your life? [sent-1, score-0.745]
</p><p>2 A:  No, it doesn’t because I’m a professor first, and as a professor I’m always changing my mind. [sent-2, score-0.683]
</p><p>3 I mean, my students go crazy in my class because I’m the most orthodox Bayesian in the world. [sent-3, score-0.488]
</p><p>4 [Bayesian probability theory is a way of modeling how the human mind reasons about the world. [sent-4, score-0.7]
</p><p>5 It assumes that people have prior beliefs about the probability of a given hypothesis and also beliefs about the probability that the hypothesis, if true, would generate the evidence they see. [sent-5, score-1.741]
</p><p>6 Taken together, these beliefs determine how people update their faith in a hypothesis in light of new evidence. [sent-6, score-1.111]
</p><p>7 ] I do everything based on Bayes analysis, and Bayes analysis is always based on shifting probabilities and constantly changing and being adaptive and fluid. [sent-7, score-1.265]
</p><p>8 Although, who am I to argue with a guy who got Jeremy Irons off on a murder charge? [sent-8, score-0.323]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('beliefs', 0.369), ('hypothesis', 0.253), ('changing', 0.221), ('probability', 0.198), ('mind', 0.189), ('bayes', 0.183), ('orthodox', 0.181), ('professor', 0.177), ('dershowitz', 0.176), ('assumes', 0.164), ('crazy', 0.161), ('shifting', 0.161), ('faith', 0.158), ('constantly', 0.153), ('jeremy', 0.151), ('murder', 0.147), ('adaptive', 0.145), ('alan', 0.138), ('obligation', 0.136), ('charge', 0.129), ('defend', 0.126), ('generate', 0.119), ('interview', 0.115), ('update', 0.113), ('determine', 0.111), ('bayesian', 0.108), ('sends', 0.108), ('always', 0.108), ('light', 0.107), ('probabilities', 0.104), ('based', 0.103), ('rest', 0.097), ('argue', 0.092), ('position', 0.09), ('analysis', 0.089), ('reasons', 0.086), ('taken', 0.085), ('human', 0.084), ('guy', 0.084), ('together', 0.083), ('life', 0.083), ('everything', 0.078), ('class', 0.077), ('although', 0.074), ('john', 0.074), ('change', 0.073), ('modeling', 0.072), ('prior', 0.071), ('theory', 0.071), ('students', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="331-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-10-Bayes_jumps_the_shark.html">331 andrew gelman stats-2010-10-10-Bayes jumps the shark</a></p>
<p>Introduction: John Goldin sends in this, from  an interview  with Alan Dershowitz:
  
 
Q:  The lawyerly obligation to not change your mind, to defend a position right or wrong–do you find that it seeps over into the rest of your life?





A:  No, it doesn’t because I’m a professor first, and as a professor I’m always changing my mind. I mean, my students go crazy in my class because I’m the most orthodox Bayesian in the world. [Bayesian probability theory is a way of modeling how the human mind reasons about the world. It assumes that people have prior beliefs about the probability of a given hypothesis and also beliefs about the probability that the hypothesis, if true, would generate the evidence they see. Taken together, these beliefs determine how people update their faith in a hypothesis in light of new evidence.] I do everything based on Bayes analysis, and Bayes analysis is always based on shifting probabilities and constantly changing and being adaptive and fluid.
 

 
Although, who am I t</p><p>2 0.13597848 <a title="331-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>Introduction: Xian, Judith, and I read this line in a book by statistician Murray Aitkin in which he considered the following hypothetical example:
  
A survey of 100 individuals expressing support (Yes/No) for the president, before and after a presidential address . . . The question of interest is whether there has been a change in support between the surveys . . . We want to assess the evidence for the hypothesis of equality H1 against the alternative hypothesis H2 of a change.
  
Here is  our response :
  
Based on our experience in public opinion research, this is not a real question. Support for any political position is always changing. The real question is how much the support has changed, or perhaps how this change is distributed across the population.


A defender of Aitkin (and of classical hypothesis testing) might respond at this point that, yes, everybody knows that changes are never exactly zero and that we should take a more “grown-up” view of the null hypothesis, not that the change</p><p>3 0.12833747 <a title="331-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-05-Prior_distribution_for_a_predicted_probability.html">2200 andrew gelman stats-2014-02-05-Prior distribution for a predicted probability</a></p>
<p>Introduction: I received the following email:
  
I have an interesting thought on a prior for a logistic regression, and would love your input on how to make it “work.”


Some of my research, two published papers, are on mathematical models of **.  Along those lines, I’m interested in developing more models for **. . . .  Empirical studies show that the public is rather smart and that the wisdom-of-the-crowd is fairly accurate.


So, my thought would be to tread the public’s probability of the event as a prior, and then see how adding data, through a model, would change or perturb our inferred probability of **.  (Similarly, I could envision using previously published epidemiological research as a prior probability of a disease, and then seeing how the addition of new testing protocols would update that belief.)


However, everything I learned about hierarchical Bayesian models has a prior as a distribution on the coefficients.  I don’t know how to start with a prior point estimate for the probabili</p><p>4 0.12444279 <a title="331-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>Introduction: Robert Bloomfield writes:
  
Most of the people in my field (accounting, which is basically applied economics and finance, leavened with psychology and organizational behavior) use ‘positive research methods’, which are typically described as coming to the data with a predefined theory, and using hypothesis testing to accept or reject the theory’s predictions.  But a substantial minority use ‘interpretive research methods’ (sometimes called qualitative methods, for those that call positive research ‘quantitative’).  No one seems entirely happy with the definition of this method, but I’ve found it useful to think of it as an attempt to see the world through the eyes of your subjects, much as Jane Goodall lived with gorillas and tried to see the world through their eyes.)


Interpretive researchers often criticize positive researchers by noting that the latter don’t make the best use of their data, because they come to the data with a predetermined theory, and only test a narrow set of h</p><p>5 0.12426958 <a title="331-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>Introduction: My article with Cosma Shalizi has appeared in the British Journal of Mathematical and Statistical Psychology.  I’m so glad this paper has come out.  I’d been thinking about writing such a paper for almost 20 years.  What got me to actually do it was an invitation a few years ago to write a chapter on Bayesian statistics for a volume on the philosophy of social sciences.  Once I started doing that, I realized I had enough for a journal article.  I contacted Cosma because he, unlike me, was familiar with the post-1970 philosophy literature (my knowledge went only up to Popper, Kuhn, and Lakatos).  We submitted it to a couple statistics journals that didn’t want it (for reasons that weren’t always  clear ), but ultimately I think it ended up in the right place, as psychologists have been as serious as anyone in thinking about statistical foundations in recent years.
 
 Here’s the issue of the journal , which also includes an introduction, several discussions, and a rejoinder:
 
 Prior app</p><p>6 0.12380997 <a title="331-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>7 0.12164262 <a title="331-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-05-What_is_a_prior_distribution%3F.html">1155 andrew gelman stats-2012-02-05-What is a prior distribution?</a></p>
<p>8 0.11396686 <a title="331-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-26-Bayes_in_the_news%E2%80%A6in_a_somewhat_frustrating_way.html">3 andrew gelman stats-2010-04-26-Bayes in the news…in a somewhat frustrating way</a></p>
<p>9 0.11047692 <a title="331-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-26-Statistical_evidence_for_revised_standards.html">2149 andrew gelman stats-2013-12-26-Statistical evidence for revised standards</a></p>
<p>10 0.11018194 <a title="331-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>11 0.10726609 <a title="331-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-11-Rajiv_Sethi_on_the_interpretation_of_prediction_market_data.html">607 andrew gelman stats-2011-03-11-Rajiv Sethi on the interpretation of prediction market data</a></p>
<p>12 0.10715633 <a title="331-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-01-Martin_and_Liu%3A__Probabilistic_inference_based_on_consistency_of_model_with_data.html">1095 andrew gelman stats-2012-01-01-Martin and Liu:  Probabilistic inference based on consistency of model with data</a></p>
<p>13 0.10577519 <a title="331-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>14 0.10570591 <a title="331-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-20-How_to_schedule_projects_in_an_introductory_statistics_course%3F.html">423 andrew gelman stats-2010-11-20-How to schedule projects in an introductory statistics course?</a></p>
<p>15 0.1056525 <a title="331-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>16 0.10562212 <a title="331-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>17 0.10475914 <a title="331-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-06-That_silly_ESP_paper_and_some_silliness_in_a_rebuttal_as_well.html">506 andrew gelman stats-2011-01-06-That silly ESP paper and some silliness in a rebuttal as well</a></p>
<p>18 0.10414466 <a title="331-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>19 0.099333227 <a title="331-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>20 0.09916617 <a title="331-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-19-Revised_evidence_for_statistical_standards.html">2140 andrew gelman stats-2013-12-19-Revised evidence for statistical standards</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.156), (1, 0.062), (2, -0.03), (3, 0.01), (4, -0.101), (5, 0.02), (6, 0.034), (7, 0.104), (8, -0.02), (9, -0.09), (10, -0.057), (11, -0.004), (12, 0.006), (13, -0.037), (14, 0.006), (15, 0.011), (16, 0.014), (17, -0.016), (18, 0.003), (19, -0.043), (20, 0.004), (21, 0.031), (22, -0.037), (23, -0.021), (24, -0.02), (25, -0.053), (26, 0.056), (27, 0.008), (28, -0.008), (29, -0.048), (30, 0.016), (31, 0.033), (32, 0.007), (33, 0.02), (34, -0.085), (35, -0.076), (36, 0.06), (37, -0.045), (38, 0.007), (39, 0.005), (40, -0.061), (41, -0.022), (42, 0.006), (43, -0.035), (44, 0.005), (45, 0.013), (46, 0.003), (47, 0.035), (48, -0.008), (49, -0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98553228 <a title="331-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-10-Bayes_jumps_the_shark.html">331 andrew gelman stats-2010-10-10-Bayes jumps the shark</a></p>
<p>Introduction: John Goldin sends in this, from  an interview  with Alan Dershowitz:
  
 
Q:  The lawyerly obligation to not change your mind, to defend a position right or wrong–do you find that it seeps over into the rest of your life?





A:  No, it doesn’t because I’m a professor first, and as a professor I’m always changing my mind. I mean, my students go crazy in my class because I’m the most orthodox Bayesian in the world. [Bayesian probability theory is a way of modeling how the human mind reasons about the world. It assumes that people have prior beliefs about the probability of a given hypothesis and also beliefs about the probability that the hypothesis, if true, would generate the evidence they see. Taken together, these beliefs determine how people update their faith in a hypothesis in light of new evidence.] I do everything based on Bayes analysis, and Bayes analysis is always based on shifting probabilities and constantly changing and being adaptive and fluid.
 

 
Although, who am I t</p><p>2 0.78092235 <a title="331-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>Introduction: Sam Seaver writes:
  
I [Seaver] happened to be reading an ironic  article  by Karl Friston when I learned something new about frequentist vs bayesian, namely Lindley’s paradox, on page 12.  The text is as follows:

 
So why are we worried about trivial effects? They are important because the probability that the true effect size is exactly zero is itself zero and could cause us to reject the null hypothesis inappropriately. This is a fallacy of classical inference and is not unrelated to Lindley’s paradox (Lindley 1957). Lindley’s paradox describes a counterintuitive situation in which Bayesian and frequentist approaches to hypothesis testing give opposite results. It occurs when; (i) a result is significant by a frequentist test, indicating sufficient evidence to reject the null hypothesis d=0 and (ii) priors render the posterior probability of d=0 high, indicating strong evidence that the null hypothesis is true. In his original 
treatment, Lindley (1957) showed that – under a parti</p><p>3 0.77381623 <a title="331-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-26-Statistical_evidence_for_revised_standards.html">2149 andrew gelman stats-2013-12-26-Statistical evidence for revised standards</a></p>
<p>Introduction: In response to the  discussion  of X and me of his recent  paper , Val Johnson writes:
  
I would like to thank Andrew for forwarding his comments on uniformly most powerful Bayesian tests (UMPBTs) to me and his invitation to respond to them.  I think he  (and also Christian Robert) raise a number of interesting points concerning this new class of Bayesian tests, but I think that they may have confounded several issues that might more usefully be examined separately.


The first issue involves the choice of the Bayesian evidence threshold, gamma, used in rejecting a null hypothesis in favor of an alternative hypothesis.  Andrew objects to the higher values of gamma proposed in my recent PNAS article on grounds that too many important scientific effects would be missed if thresholds of 25-50 were routinely used.  These evidence thresholds correspond roughly to p-values of 0.005; Andrew suggests that evidence thresholds around 5 should continue to be used (gamma=5 corresponds approximate</p><p>4 0.72719347 <a title="331-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>Introduction: Ken Rice writes:
  
In the recent discussion on  stopping rules  I saw a comment that I wanted to chip in on, but thought it might get a bit lost, in the already long thread. Apologies in advance if I misinterpreted what you wrote, or am trying to tell you things you already know.


 The comment  was: “In Bayesian decision making, there is a utility function and you choose the decision with highest expected utility. Making a decision based on statistical significance does not correspond to any utility function.”


… which immediately suggests  this  little 2010 paper; A Decision-Theoretic Formulation of Fisher’s Approach to Testing, The American Statistician, 64(4) 345-349. It contains utilities that lead to decisions that very closely mimic classical Wald tests, and provides a rationale for why this utility is not totally unconnected from how some scientists think. Some (old) slides discussing it  are here .


A few notes, on things not in the paper:


* I know you don’t like squared-</p><p>5 0.70960569 <a title="331-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>Introduction: A recent  discussion  between commenters Question and Fernando captured one of the recurrent themes here from the past year.
 
 Question:   The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct.
 
 Fernando:   Whereas it is probably true that researchers misuse NHT, the problem with tabloid science is broader and deeper. It is systemic.
 
 Question:   I do not see how anything can be deeper than replacing careful description, prediction, falsification, and independent replication with dynamite plots, p-values, affirming the consequent, and peer review. From my own experience I am confident in saying that confusion caused by NHST is at the root of this problem.
 
 Fernando:   Incentives? Impact factors? Publish or die? “Interesting” and “new” above quality and reliability, or actually answering a research question, and a silly and unbecoming obsession with being quoted in NYT, etc. . . . Giv</p><p>6 0.70221859 <a title="331-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>7 0.70132351 <a title="331-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-25-Revised_statistical_standards_for_evidence_%28comments_to_Val_Johnson%E2%80%99s_comments_on_our_comments_on_Val%E2%80%99s_comments_on_p-values%29.html">2305 andrew gelman stats-2014-04-25-Revised statistical standards for evidence (comments to Val Johnson’s comments on our comments on Val’s comments on p-values)</a></p>
<p>8 0.70112795 <a title="331-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-15-%E2%80%9CAre_all_significant_p-values_created_equal%3F%E2%80%9D.html">2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</a></p>
<p>9 0.68470836 <a title="331-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>10 0.6741668 <a title="331-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-08-P-values_and_statistical_practice.html">1713 andrew gelman stats-2013-02-08-P-values and statistical practice</a></p>
<p>11 0.67290187 <a title="331-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-28-More_on_Bayesian_deduction-induction.html">114 andrew gelman stats-2010-06-28-More on Bayesian deduction-induction</a></p>
<p>12 0.66923797 <a title="331-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-10-I_don%E2%80%99t_like_this_cartoon.html">1572 andrew gelman stats-2012-11-10-I don’t like this cartoon</a></p>
<p>13 0.65757501 <a title="331-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-08-The_virtues_of_incoherence%3F.html">792 andrew gelman stats-2011-07-08-The virtues of incoherence?</a></p>
<p>14 0.65552956 <a title="331-lsi-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>15 0.6536954 <a title="331-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-26-%E2%80%9CThe_Bayesian_approach_to_forensic_evidence%E2%80%9D.html">2078 andrew gelman stats-2013-10-26-“The Bayesian approach to forensic evidence”</a></p>
<p>16 0.65280229 <a title="331-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-02-So-called_Bayesian_hypothesis_testing_is_just_as_bad_as_regular_hypothesis_testing.html">643 andrew gelman stats-2011-04-02-So-called Bayesian hypothesis testing is just as bad as regular hypothesis testing</a></p>
<p>17 0.64652491 <a title="331-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-Rob_Kass_on_statistical_pragmatism%2C_and_my_reactions.html">317 andrew gelman stats-2010-10-04-Rob Kass on statistical pragmatism, and my reactions</a></p>
<p>18 0.64348912 <a title="331-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>19 0.63396937 <a title="331-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-28-Plain_old_everyday_Bayesianism%21.html">1829 andrew gelman stats-2013-04-28-Plain old everyday Bayesianism!</a></p>
<p>20 0.63270444 <a title="331-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-06-Priors_I_don%E2%80%99t_believe.html">2322 andrew gelman stats-2014-05-06-Priors I don’t believe</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.046), (16, 0.034), (24, 0.106), (27, 0.031), (35, 0.097), (51, 0.019), (53, 0.02), (57, 0.019), (63, 0.017), (76, 0.015), (86, 0.061), (89, 0.017), (95, 0.023), (98, 0.023), (99, 0.367)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98119646 <a title="331-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-10-Bayes_jumps_the_shark.html">331 andrew gelman stats-2010-10-10-Bayes jumps the shark</a></p>
<p>Introduction: John Goldin sends in this, from  an interview  with Alan Dershowitz:
  
 
Q:  The lawyerly obligation to not change your mind, to defend a position right or wrong–do you find that it seeps over into the rest of your life?





A:  No, it doesn’t because I’m a professor first, and as a professor I’m always changing my mind. I mean, my students go crazy in my class because I’m the most orthodox Bayesian in the world. [Bayesian probability theory is a way of modeling how the human mind reasons about the world. It assumes that people have prior beliefs about the probability of a given hypothesis and also beliefs about the probability that the hypothesis, if true, would generate the evidence they see. Taken together, these beliefs determine how people update their faith in a hypothesis in light of new evidence.] I do everything based on Bayes analysis, and Bayes analysis is always based on shifting probabilities and constantly changing and being adaptive and fluid.
 

 
Although, who am I t</p><p>2 0.97874671 <a title="331-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-14-Learning_from_failure.html">1264 andrew gelman stats-2012-04-14-Learning from failure</a></p>
<p>Introduction: I was talking with education researcher Bob Boruch about my frustrations in teaching, the idea that as statisticians we tell people to do formal experimentation but in our own teaching practice we typically just try different things without even measuring outcomes, let alone performing any formal evaluation.  Boruch showed me  this article  with Alan Ruby about learning from failure.  Unfortunately I’ve forgotten all my other thoughts from our conversation but I’m posting the article here.</p><p>3 0.96818274 <a title="331-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-08-How_to_solve_the_Post_Office%E2%80%99s_problems%3F.html">895 andrew gelman stats-2011-09-08-How to solve the Post Office’s problems?</a></p>
<p>Introduction: Felix Salmon offers  some suggestions .  (For some background, see  this news article  by Steven Greenhouse.)
 
I have no management expertise but about fifteen years ago I did some work on a project for the Postal Service, and I remember noticing some structural problems back then:
 
Everyone would always get annoyed about the way the price of a first class stamp would go up in awkward increments, from 29 cents to 32 cents to 33 cents to 34 cents etc.  Why couldn’t they just jump to the next round number (for example, 35 cents) and keep it there for a few years?  The answer, I was told, was that the Postal Service was trapped by a bunch of rules.  They were required to price everything exactly at cost.  If they charged too much for first class mail,  then UPS and Fed-Ex would sue and say the PO was illegally cross-subsidizing their bulk mail.  If they charged too little, then the publishers and junk mailers would sue.  Maybe I’m getting the details wrong here but that was the basic id</p><p>4 0.96663189 <a title="331-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<p>Introduction: Burak Bayramli writes:
  
In  this paper  by Sunjin Ahn, Anoop Korattikara, and Max Welling and  this paper  by Welling and Yee Whye The, there are some arguments on big data and the use of MCMC. Both papers have suggested improvements to speed up MCMC computations. I was wondering what your thoughts were, especially on this paragraph:

 
When a dataset has a billion data-cases (as is not uncommon these days) MCMC algorithms will not even have generated a single (burn-in) sample when a clever learning algorithm based on stochastic gradients may already be making fairly good predictions. In fact, the intriguing results of Bottou and Bousquet (2008) seem to indicate that in terms of “number of bits learned per unit of computation”, an algorithm as simple as stochastic gradient descent is almost optimally efficient. We therefore argue that for Bayesian methods to remain useful in an age when the datasets grow at an exponential rate, they need to embrace the ideas of the stochastic optimiz</p><p>5 0.96375906 <a title="331-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-25-Quantitative_Methods_in_the_Social_Sciences_M.A.%3A_Innovative%2C_interdisciplinary_social_science_research_program_for_a_data-rich_world.html">591 andrew gelman stats-2011-02-25-Quantitative Methods in the Social Sciences M.A.: Innovative, interdisciplinary social science research program for a data-rich world</a></p>
<p>Introduction: About 12 years ago Greg Wawro, Sy Spilerman, and I started a M.A. program here in Quantitative Methods in Social Sciences, jointly between the departments of history, economics, political science, sociology, psychology, and statistics.  We created a bunch of new features for the program, including an interdisciplinary course based on  this book .
  

 
And here’s their new logo:
 
 
 
Don’t blame me for the pie-chart motif!  Seriously, though, the program is great.  I’m proud to have gotten it started, and I’m impressed by the progress that Chris Weiss and others have made in expanding the program during the past decade.</p><p>6 0.9625994 <a title="331-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-30-Computational_problems_with_glm_etc..html">1516 andrew gelman stats-2012-09-30-Computational problems with glm etc.</a></p>
<p>7 0.95710015 <a title="331-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-10-Who%E2%80%99s_holding_the_pen%3F%2C_The_split_screen%2C_and_other_ideas_for_one-on-one_instruction.html">462 andrew gelman stats-2010-12-10-Who’s holding the pen?, The split screen, and other ideas for one-on-one instruction</a></p>
<p>8 0.95641369 <a title="331-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-05-More_plain_old_everyday_Bayesianism.html">1926 andrew gelman stats-2013-07-05-More plain old everyday Bayesianism</a></p>
<p>9 0.9537406 <a title="331-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-30-Adjudicating_between_alternative_interpretations_of_a_statistical_interaction%3F.html">2274 andrew gelman stats-2014-03-30-Adjudicating between alternative interpretations of a statistical interaction?</a></p>
<p>10 0.95299017 <a title="331-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-03-Taleb_%2B_3.5_years.html">392 andrew gelman stats-2010-11-03-Taleb + 3.5 years</a></p>
<p>11 0.95295817 <a title="331-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>12 0.95295489 <a title="331-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Cross-validation_%28What_is_it_good_for%3F%29.html">1395 andrew gelman stats-2012-06-27-Cross-validation (What is it good for?)</a></p>
<p>13 0.95266742 <a title="331-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-03-Psychology_researchers_discuss_ESP.html">691 andrew gelman stats-2011-05-03-Psychology researchers discuss ESP</a></p>
<p>14 0.95253432 <a title="331-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-01-Martin_and_Liu%3A__Probabilistic_inference_based_on_consistency_of_model_with_data.html">1095 andrew gelman stats-2012-01-01-Martin and Liu:  Probabilistic inference based on consistency of model with data</a></p>
<p>15 0.95150352 <a title="331-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-21-Random_matrices_in_the_news.html">2258 andrew gelman stats-2014-03-21-Random matrices in the news</a></p>
<p>16 0.95094109 <a title="331-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-04-45%25_hitting%2C_25%25_fielding%2C_25%25_pitching%2C_and_100%25_not_telling_us_how_they_did_it.html">942 andrew gelman stats-2011-10-04-45% hitting, 25% fielding, 25% pitching, and 100% not telling us how they did it</a></p>
<p>17 0.95060921 <a title="331-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-02-Am_I_too_negative%3F.html">2279 andrew gelman stats-2014-04-02-Am I too negative?</a></p>
<p>18 0.95060021 <a title="331-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-08-Another_Wegman_plagiarism.html">751 andrew gelman stats-2011-06-08-Another Wegman plagiarism</a></p>
<p>19 0.95035714 <a title="331-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-20-An_illustrated_calculus_textbook.html">862 andrew gelman stats-2011-08-20-An illustrated calculus textbook</a></p>
<p>20 0.9503563 <a title="331-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-03-A_comment_on_a_post_at_the_Monkey_Cage.html">2048 andrew gelman stats-2013-10-03-A comment on a post at the Monkey Cage</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
