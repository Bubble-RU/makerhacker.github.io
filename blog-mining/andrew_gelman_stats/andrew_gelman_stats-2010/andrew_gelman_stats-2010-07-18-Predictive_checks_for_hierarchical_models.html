<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-154" href="#">andrew_gelman_stats-2010-154</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-154-html" href="http://andrewgelman.com/2010/07/18/predictive_chec/">html</a></p><p>Introduction: Daniel Corsi writes:
  
I was wondering if you could help me with some code to set up a posterior predictive check for an unordered multinomial multilevel model.  In this case the outcome is categories of bmi (underweight, nomral weight, and overweight) based on individuals from 360 different areas. What I would like to do is set up a replicated dataset  to see how the number of overweight/underweight/normal weight individuals based on the model compares to the actual data and some kind of a graphical summary. I am following along with chapter 24 of the arm book but I want to verify that the replicated data accounts for the multilevel structure of the data of people within areas. I am attaching the code I used to run a simple model with only 2 predictors (area wealth and urban/rural designation).
  
My reply:  The Bugs code is a bit much for me to look at–but I do recommend that you run it from R, which will give you more flexibility in preprocessing and postprocessing the data.  Beyon</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Daniel Corsi writes:    I was wondering if you could help me with some code to set up a posterior predictive check for an unordered multinomial multilevel model. [sent-1, score-1.205]
</p><p>2 In this case the outcome is categories of bmi (underweight, nomral weight, and overweight) based on individuals from 360 different areas. [sent-2, score-0.559]
</p><p>3 What I would like to do is set up a replicated dataset  to see how the number of overweight/underweight/normal weight individuals based on the model compares to the actual data and some kind of a graphical summary. [sent-3, score-1.44]
</p><p>4 I am following along with chapter 24 of the arm book but I want to verify that the replicated data accounts for the multilevel structure of the data of people within areas. [sent-4, score-1.374]
</p><p>5 I am attaching the code I used to run a simple model with only 2 predictors (area wealth and urban/rural designation). [sent-5, score-0.871]
</p><p>6 My reply:  The Bugs code is a bit much for me to look at–but I do recommend that you run it from R, which will give you more flexibility in preprocessing and postprocessing the data. [sent-6, score-0.821]
</p><p>7 Beyond this, there are different ways of doing replications. [sent-7, score-0.077]
</p><p>8 You can replicate new people in existing areas or new people in new areas. [sent-8, score-1.162]
</p><p>9 In a cluster sample, you’ll probably want new areas. [sent-10, score-0.422]
</p><p>10 In an exhaustive sample, there might not be any new areas and you’ll want to keep your existing group-level parameters. [sent-11, score-0.835]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('replicated', 0.274), ('code', 0.254), ('weight', 0.212), ('existing', 0.194), ('preprocessing', 0.194), ('individuals', 0.185), ('overweight', 0.183), ('attaching', 0.175), ('exhaustive', 0.175), ('unordered', 0.175), ('new', 0.173), ('areas', 0.173), ('multinomial', 0.169), ('multilevel', 0.161), ('verify', 0.156), ('run', 0.147), ('flexibility', 0.142), ('accounts', 0.135), ('sample', 0.131), ('cluster', 0.129), ('wealth', 0.128), ('compares', 0.127), ('want', 0.12), ('replicate', 0.118), ('bugs', 0.116), ('arm', 0.113), ('categories', 0.111), ('set', 0.11), ('daniel', 0.107), ('graphical', 0.102), ('dataset', 0.101), ('depends', 0.1), ('based', 0.096), ('structure', 0.096), ('predictors', 0.091), ('wondering', 0.091), ('outcome', 0.09), ('ll', 0.088), ('predictive', 0.088), ('area', 0.084), ('recommend', 0.084), ('chapter', 0.082), ('posterior', 0.08), ('people', 0.079), ('data', 0.079), ('parameters', 0.078), ('actual', 0.078), ('check', 0.077), ('different', 0.077), ('model', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="154-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-18-Predictive_checks_for_hierarchical_models.html">154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</a></p>
<p>Introduction: Daniel Corsi writes:
  
I was wondering if you could help me with some code to set up a posterior predictive check for an unordered multinomial multilevel model.  In this case the outcome is categories of bmi (underweight, nomral weight, and overweight) based on individuals from 360 different areas. What I would like to do is set up a replicated dataset  to see how the number of overweight/underweight/normal weight individuals based on the model compares to the actual data and some kind of a graphical summary. I am following along with chapter 24 of the arm book but I want to verify that the replicated data accounts for the multilevel structure of the data of people within areas. I am attaching the code I used to run a simple model with only 2 predictors (area wealth and urban/rural designation).
  
My reply:  The Bugs code is a bit much for me to look at–but I do recommend that you run it from R, which will give you more flexibility in preprocessing and postprocessing the data.  Beyon</p><p>2 0.16260427 <a title="154-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-29-Putting_together_multinomial_discrete_regressions_by_combining_simple_logits.html">782 andrew gelman stats-2011-06-29-Putting together multinomial discrete regressions by combining simple logits</a></p>
<p>Introduction: When predicting 0/1 data we can use logit (or probit or robit or some other robust model such as invlogit (0.01 + 0.98*X*beta)).  Logit is simple enough and we can use  bayesglm  to regularize and avoid the problem of separation.
 
What if there are more than 2 categories?  If they’re ordered (1, 2, 3, etc), we can do ordered logit (and use bayespolr() to avoid separation).  If the categories are unordered (vanilla, chocolate, strawberry), there are unordered multinomial logit and probit models out there.
 
But it’s not so easy to fit these multinomial model in a multilevel setting (with coefficients that vary by group), especially if the computation is embedded in an iterative routine such as mi where you have real time constraints at each step.
 
So this got me wondering whether we could kluge it with logits.  Here’s the basic idea (in the ordered and unordered forms):
 
- If you have a variable that goes 1, 2, 3, etc., set up a series of logits:  1 vs. 2,3,…; 2 vs. 3,…; and so forth</p><p>3 0.16244975 <a title="154-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-Displaying_a_fitted_multilevel_model.html">328 andrew gelman stats-2010-10-08-Displaying a fitted multilevel model</a></p>
<p>Introduction: Elissa Brown writes:
  
I’m working on some data using a multinomial model (3 categories for the response &  2 predictors-1 continuous and 1 binary), and I’ve been looking and looking for some sort of nice graphical way to show my model at work. Something like a predicted probabilities plot. I know you can do this for the levels of Y with just one covariate, but is this still a valid way to describe the multinomial model (just doing a pred plot for each covariate)? What’s the deal, is there really no way to graphically represent a successful multinomial model? Also, is it unreasonable to break down your model into a binary response just to get some ROC curves? This seems like cheating. From what I’ve found so far, it seems that people just avoid graphical support when discussing their fitted multinomial models.
  
My reply:
 
It’s hard for me to think about this sort of thing in the abstract with no context.  We do have one example in chapter 6 of ARM where we display data and fitted m</p><p>4 0.14462307 <a title="154-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-19-Updated_R_code_and_data_for_ARM.html">41 andrew gelman stats-2010-05-19-Updated R code and data for ARM</a></p>
<p>Introduction: Patricia and I have cleaned up some of the R and Bugs code and collected the data for almost all the examples in ARM.   See here  for links to zip files with the code and data.</p><p>5 0.13427809 <a title="154-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-03-Question_about_predictive_checks.html">1363 andrew gelman stats-2012-06-03-Question about predictive checks</a></p>
<p>Introduction: Klaas Metselaar writes: 
  
  
I [Metselaar] am currently involved in a discussion about the use of the notion “predictive” as used in “posterior predictive check”. I would argue that the notion “predictive” should be reserved for posterior checks using information not used in the determination of the posterior. 
I quote from the discussion: 
“However, the predictive uncertainty in a Bayesian calculation requires sampling from all the random variables, and this includes both the model parameters and the residual error”.


My [Metselaar's] comment:


This may be exactly the point I am worried about: shouldn’t the predictive uncertainty be defined as sampling from the posterior parameter distribution +  residual error + sampling from the prediction error distribution? 
Residual error reduces to measurement error in the case of a  model which is perfect for the sample of experiments. Measurement error could be reduced to almost zero by ideal and perfect measurement instruments. 
I would h</p><p>6 0.12752342 <a title="154-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-07-Reproducible_science_FAIL_%28so_far%29%3A__What%E2%80%99s_stoppin_people_from_sharin_data_and_code%3F.html">1447 andrew gelman stats-2012-08-07-Reproducible science FAIL (so far):  What’s stoppin people from sharin data and code?</a></p>
<p>7 0.12747532 <a title="154-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-13-Checking_your_model_using_fake_data.html">852 andrew gelman stats-2011-08-13-Checking your model using fake data</a></p>
<p>8 0.11928952 <a title="154-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>9 0.11222261 <a title="154-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-08-How_to_display_multinominal_logit_results_graphically%3F.html">2163 andrew gelman stats-2014-01-08-How to display multinominal logit results graphically?</a></p>
<p>10 0.11001211 <a title="154-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-18-There_are_no_fat_sprinters.html">1905 andrew gelman stats-2013-06-18-There are no fat sprinters</a></p>
<p>11 0.10965392 <a title="154-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>12 0.10589455 <a title="154-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<p>13 0.1055316 <a title="154-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>14 0.10349515 <a title="154-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>15 0.10216249 <a title="154-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>16 0.10194766 <a title="154-tfidf-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-References_%28with_code%29_for_Bayesian_hierarchical_%28multilevel%29_modeling_and_structural_equation_modeling.html">2273 andrew gelman stats-2014-03-29-References (with code) for Bayesian hierarchical (multilevel) modeling and structural equation modeling</a></p>
<p>17 0.10121761 <a title="154-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-Participate_in_a_short_survey_about_the_weight_of_evidence_provided_by_statistics.html">1681 andrew gelman stats-2013-01-19-Participate in a short survey about the weight of evidence provided by statistics</a></p>
<p>18 0.10089171 <a title="154-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>19 0.099326745 <a title="154-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-18-Understanding_posterior_p-values.html">2029 andrew gelman stats-2013-09-18-Understanding posterior p-values</a></p>
<p>20 0.099167354 <a title="154-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.179), (1, 0.074), (2, 0.03), (3, 0.031), (4, 0.11), (5, 0.036), (6, 0.0), (7, -0.064), (8, 0.062), (9, 0.031), (10, 0.026), (11, -0.025), (12, 0.004), (13, -0.005), (14, 0.023), (15, 0.021), (16, -0.009), (17, -0.026), (18, 0.018), (19, -0.007), (20, 0.012), (21, 0.008), (22, -0.02), (23, -0.014), (24, -0.084), (25, -0.026), (26, 0.018), (27, 0.005), (28, 0.059), (29, 0.003), (30, -0.032), (31, -0.045), (32, 0.011), (33, 0.035), (34, 0.021), (35, 0.023), (36, -0.006), (37, 0.029), (38, -0.003), (39, 0.029), (40, 0.005), (41, -0.047), (42, 0.038), (43, -0.014), (44, -0.003), (45, 0.023), (46, 0.003), (47, 0.028), (48, -0.011), (49, 0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96703094 <a title="154-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-18-Predictive_checks_for_hierarchical_models.html">154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</a></p>
<p>Introduction: Daniel Corsi writes:
  
I was wondering if you could help me with some code to set up a posterior predictive check for an unordered multinomial multilevel model.  In this case the outcome is categories of bmi (underweight, nomral weight, and overweight) based on individuals from 360 different areas. What I would like to do is set up a replicated dataset  to see how the number of overweight/underweight/normal weight individuals based on the model compares to the actual data and some kind of a graphical summary. I am following along with chapter 24 of the arm book but I want to verify that the replicated data accounts for the multilevel structure of the data of people within areas. I am attaching the code I used to run a simple model with only 2 predictors (area wealth and urban/rural designation).
  
My reply:  The Bugs code is a bit much for me to look at–but I do recommend that you run it from R, which will give you more flexibility in preprocessing and postprocessing the data.  Beyon</p><p>2 0.81221068 <a title="154-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-10-Combining_data_from_many_sources.html">948 andrew gelman stats-2011-10-10-Combining data from many sources</a></p>
<p>Introduction: Mark Grote writes: 
  
  
I’d like to request general feedback and references for a problem of combining disparate data sources in a regression model. We’d like to model log crop yield as a function of environmental predictors, but the observations come from many data sources and are peculiarly structured. Among the issues are:


1. Measurement precision in predictors and outcome varies widely with data sources. Some observations are in very coarse units of measurement, due to rounding or even observer guesswork. 


2. There are obvious clusters of observations arising from studies in which crop yields were monitored over successive years in spatially proximate communities. Thus some variables may be constant within clusters–this is true even for log yield, probably due to rounding of similar yields. 


3. Cluster size and intra-cluster association structure (temporal, spatial or both) vary widely across the dataset. 


My [Grote's] intuition is that we can learn about central tendency</p><p>3 0.8010965 <a title="154-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>Introduction: Yi-Chun Ou writes: 
  
  
I am using a multilevel model with three levels. I read that you wrote a book about multilevel models, and wonder if you can solve the following question.  


The data structure is like this: 


Level one: customer (8444 customers) 
Level two: companys (90 companies) 
Level three: industry (17 industries) 


I use 6 level-three variables (i.e. industry characteristics) to explain the variance of the level-one effect across industries. The question here is whether there is an over-fitting problem since there are only 17 industries. I understand that this must be a problem for non-multilevel models, but is it also a problem for multilevel models?
  
My reply:  Yes, this could be a problem.  I’d suggest combining some of your variables into a common score, or using only some of the variables, or using strong priors to control the inferences.  This is an interesting and important area of statistics research, to do this sort of thing systematically.  There’s lots o</p><p>4 0.7947216 <a title="154-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>Introduction: Fred Schiff writes: 
  
  
I’m writing to you to ask about the “R-squared” approximation procedure you suggest in your 2004 book with Dr. Hill.  [See also  this paper  with Pardoe---ed.]


I’m a media sociologist at the University of Houston.  I’ve been using HLM3 for about two years.  


Briefly about my data.  It’s a content analysis of news stories with a continuous scale dependent variable, story prominence.  I have 6090 news stories, 114 newspapers, and 59 newspaper group owners.  All the Level-1, Level-2 and dependent variables have been standardized. Since the means were zero anyway, we left the variables uncentered.  All the Level-3 ownership groups and characteristics are dichotomous scales that were left uncentered.  


PROBLEM:  The single most important result I am looking for is to compare the strength of nine competing Level-1 variables in their ability to predict and explain the outcome variable, story prominence.  We are trying to use the residuals to calculate a “R-squ</p><p>5 0.78864652 <a title="154-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-12-GLM_%E2%80%93_exposure.html">271 andrew gelman stats-2010-09-12-GLM – exposure</a></p>
<p>Introduction: Bernard Phiri writes:
  
 
I am relatively new to glm models, anyhow, I am currently using your book “Data analysis using regression and multilevel/hierarchical models” (pages 109-115). I am using a Poisson GLM model to analyse an aerial census dataset of wild herbivores on a ranch in Kenya. In my analysis I have the following variables:


 1. Outcome variable: count of wild herbivores sighted at a given location


 2. Explanatory variable1: vegetation type i.e. type of vegetation of the grid in which animals were sighted (the ranch is divided into 1x1km grids)


 3. Explanatory variable2: animal species e.g. eland, elephant, zebra etc


 4. Exposure: proximity to water i.e. distance (km) to the nearest water point


My questions are as follows:


1. Am I correct to include proximity to water point as an offset? I notice that in the example in your book the offset is a count, does this matter?


2. By including proximity to water in the model as an exposure am I correct to interpret th</p><p>6 0.77580005 <a title="154-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Modeling_y_%3D_a_%2B_b_%2B_c.html">1294 andrew gelman stats-2012-05-01-Modeling y = a + b + c</a></p>
<p>7 0.7663756 <a title="154-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-19-Index_or_indicator_variables.html">2296 andrew gelman stats-2014-04-19-Index or indicator variables</a></p>
<p>8 0.76100111 <a title="154-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>9 0.76001948 <a title="154-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-18-Lack_of_complete_overlap.html">1017 andrew gelman stats-2011-11-18-Lack of complete overlap</a></p>
<p>10 0.74973834 <a title="154-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>11 0.74839485 <a title="154-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-19-Paired_comparisons.html">99 andrew gelman stats-2010-06-19-Paired comparisons</a></p>
<p>12 0.74555355 <a title="154-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-24-Multilevel_modeling_and_instrumental_variables.html">1468 andrew gelman stats-2012-08-24-Multilevel modeling and instrumental variables</a></p>
<p>13 0.73910135 <a title="154-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>14 0.73904842 <a title="154-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-07-Analysis_of_Power_Law_of_Participation.html">946 andrew gelman stats-2011-10-07-Analysis of Power Law of Participation</a></p>
<p>15 0.73783386 <a title="154-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>16 0.73663914 <a title="154-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-19-Analysis_of_survey_data%3A_Design_based_models_vs._hierarchical_modeling%3F.html">352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</a></p>
<p>17 0.73557514 <a title="154-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-23-Parallel_JAGS_RNGs.html">818 andrew gelman stats-2011-07-23-Parallel JAGS RNGs</a></p>
<p>18 0.73310608 <a title="154-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-Clutering_and_variance_components.html">417 andrew gelman stats-2010-11-17-Clutering and variance components</a></p>
<p>19 0.7316677 <a title="154-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-08-I_Am_Too_Absolutely_Heteroskedastic_for_This_Probit_Model.html">1047 andrew gelman stats-2011-12-08-I Am Too Absolutely Heteroskedastic for This Probit Model</a></p>
<p>20 0.72601563 <a title="154-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.027), (9, 0.016), (16, 0.218), (24, 0.115), (31, 0.014), (50, 0.021), (53, 0.039), (58, 0.021), (63, 0.046), (65, 0.033), (77, 0.012), (86, 0.045), (99, 0.292)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97177041 <a title="154-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-13-Coauthorship_norms.html">609 andrew gelman stats-2011-03-13-Coauthorship norms</a></p>
<p>Introduction: I followed  this link  from Chris Blattman to  an article  by economist Roland Fryer, who writes:
  
I [Fryer] find no evidence that teacher incentives increase student performance, attendance, or graduation, nor do I find any evidence that the incentives change student or teacher behavior.
  
What struck me were not the findings (which, as Fryer notes in his article, are plausible enough) but the use of the word “I” rather than “we.”  A field experiment is a big deal, and I was surprised to read that Fryer did it all by himself!
 
Here’s the note of acknowledgments (on the first page of the article):
  
This project would not have been possible without the leadership and support of Joel Klein. I am also grateful to Jennifer Bell-Ellwanger, Joanna Cannon, and Dominique West for their cooperation in collecting the data necessary for this project, and to my colleagues Edward Glaeser, Richard Holden, and Lawrence Katz for helpful comments and discussions. Vilsa E. Curto, Meghan L. Howard,</p><p>2 0.97108507 <a title="154-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-13-Ethical_concerns_in_medical_trials.html">411 andrew gelman stats-2010-11-13-Ethical concerns in medical trials</a></p>
<p>Introduction: I just read  this article  on the treatment of medical volunteers, written by doctor and bioethicist Carl Ellliott.
 
As a statistician who has done a small amount of consulting for pharmaceutical companies, I have a slightly different perspective.  As a doctor, Elliott focuses on individual patients, whereas, as a statistician, I’ve been trained to focus on the goal of accurately estimate treatment effects.
 
I’ll go through Elliott’s article and give my reactions.
  

 
Elliott:
  
In Miami, investigative reporters for Bloomberg Markets magazine discovered that a contract research organisation called SFBC International was testing drugs on undocumented immigrants in a rundown motel; since that report, the motel has been demolished for fire and safety violations. . . . SFBC had recently been named one of the best small businesses in America by Forbes magazine. The Holiday Inn testing facility was the largest in North America, and had been operating for nearly ten years before inspecto</p><p>3 0.97088969 <a title="154-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-23-Popular_governor%2C_small_state.html">159 andrew gelman stats-2010-07-23-Popular governor, small state</a></p>
<p>Introduction: A couple years ago, upon the selection of Sarah Palin as vice-presidential nominee, I made some graphs of the popularity of governors of different-sized states:
 
 
 
As I wrote  at the time :
 
It seems to be easier to maintain high approval in a small state. What’s going on? Some theories: in a large state, there will be more ambitious politicians on the other side, eager to knock off the incumbent governor; small states often have part-time legislatures and thus the governor is involved in less political conflict; small states (notably Alaska) tend to get more funds per capita from the federal government, and it’s easier to be popular when you can disburse more funds; large states tend to be more heterogeneous and so it’s harder to keep all the voters happy.
 
I was curious how things have been going more recently, and Hanfei made an updated graph using data from  this archive .  Here’s the story:
 
   
 
There’s lots of variation–clearly there are many other factors than state popu</p><p>4 0.96811879 <a title="154-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Racism%21.html">321 andrew gelman stats-2010-10-05-Racism!</a></p>
<p>Introduction: Last night I spoke at the Columbia Club of New York, along with some of my political science colleagues, in a  panel  about politics, the economy, and the forthcoming election.  The discussion was fine . . . until one guy in the audience accused us of bias based on what he imputed as our ethnicity.  One of the panelists replied by asking the questioner what of all the things we had said was biased, and the questioner couldn’t actually supply any examples.
 
It makes sense that the questioner couldn’t come up with a single example of bias on our part, considering that we were actually presenting  facts .
 
At some level, the questioner’s imputation of our ethnicity and accusation of bias isn’t so horrible.  When talking with my friends, I engage in casual ethnic stereotyping all the time–hey, it’s a free country!–and one can certainly make the  statistical  argument that you can guess people’s ethnicities from their names, appearance, and speech patterns, and in turn you can infer a lot</p><p>5 0.96810031 <a title="154-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-08-Different_attitudes_about_parenting%2C_possibly_deriving_from_different_attitudes_about_self.html">564 andrew gelman stats-2011-02-08-Different attitudes about parenting, possibly deriving from different attitudes about self</a></p>
<p>Introduction: Tyler Cowen  discusses  his and Bryan Caplan’s reaction to that notorious book by Amy Chua, the Yale law professor who boasts of screaming at her children, calling them “garbage,” not letting them go to the bathroom when they were studying piano, etc.  Caplan thinks Chua is deluded (in the sense of not being aware of research showing minimal effects of parenting on children’s intelligence and personality), foolish (in writing a book and making recommendations without trying to lean about the abundant research on child-rearing), and cruel.  Cowen takes a middle view in that he doesn’t subscribe to Chua’s parenting strategies but he does think that his friends’ kids will do well (and partly because of his friends’ parenting styles, not just from their genes).
 
 Do you view yourself as special? 
 
I have a somewhat different take on the matter, an idea that’s been stewing in my mind for awhile, ever since I  heard about  the Wall Street Journal article that started this all.  My story is</p><p>6 0.96805084 <a title="154-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>7 0.96709979 <a title="154-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-28-The_incoming_moderate_Republican_congressmembers.html">377 andrew gelman stats-2010-10-28-The incoming moderate Republican congressmembers</a></p>
<p>8 0.9660511 <a title="154-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-23-Modeling_heterogenous_treatment_effects.html">2 andrew gelman stats-2010-04-23-Modeling heterogenous treatment effects</a></p>
<p>9 0.96456599 <a title="154-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-06-Suspicious_pattern_of_too-strong_replications_of_medical_research.html">700 andrew gelman stats-2011-05-06-Suspicious pattern of too-strong replications of medical research</a></p>
<p>10 0.96400869 <a title="154-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-02-Reintegrating_rebels_into_civilian_life%3A_Quasi-experimental_evidence_from_Burundi.html">177 andrew gelman stats-2010-08-02-Reintegrating rebels into civilian life: Quasi-experimental evidence from Burundi</a></p>
<p>11 0.96371686 <a title="154-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-06-Bayesian_model-building_by_pure_thought%3A__Some_principles_and_examples.html">1156 andrew gelman stats-2012-02-06-Bayesian model-building by pure thought:  Some principles and examples</a></p>
<p>12 0.96170545 <a title="154-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>13 0.95859236 <a title="154-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-21-Progress_for_the_Poor.html">1022 andrew gelman stats-2011-11-21-Progress for the Poor</a></p>
<p>14 0.95781958 <a title="154-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-06-How_to_think_about_papers_published_in_low-grade_journals%3F.html">1928 andrew gelman stats-2013-07-06-How to think about papers published in low-grade journals?</a></p>
<p>15 0.95409191 <a title="154-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-20-Why_no_Wegmania%3F.html">722 andrew gelman stats-2011-05-20-Why no Wegmania?</a></p>
<p>16 0.95293581 <a title="154-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-30-A_graphics_talk_with_no_visuals%21.html">1598 andrew gelman stats-2012-11-30-A graphics talk with no visuals!</a></p>
<p>17 0.95241451 <a title="154-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-24-Always_check_your_evidence.html">1025 andrew gelman stats-2011-11-24-Always check your evidence</a></p>
<p>18 0.95101327 <a title="154-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-13-Win_%245000_in_the_Economist%E2%80%99s_data_visualization_competition.html">1495 andrew gelman stats-2012-09-13-Win $5000 in the Economist’s data visualization competition</a></p>
<p>19 0.94943774 <a title="154-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-Clarity_on_my_email_policy.html">503 andrew gelman stats-2011-01-04-Clarity on my email policy</a></p>
<p>20 0.94788253 <a title="154-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-Why_does_anyone_support_private_macroeconomic_forecasts%3F.html">185 andrew gelman stats-2010-08-04-Why does anyone support private macroeconomic forecasts?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
