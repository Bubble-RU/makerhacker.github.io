<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>480 andrew gelman stats-2010-12-21-Instead of “confidence interval,” let’s say “uncertainty interval”</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-480" href="#">andrew_gelman_stats-2010-480</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>480 andrew gelman stats-2010-12-21-Instead of “confidence interval,” let’s say “uncertainty interval”</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-480-html" href="http://andrewgelman.com/2010/12/21/lets_say_uncert/">html</a></p><p>Introduction: I’ve become increasingly uncomfortable with the term “confidence interval,” for several reasons:
 
- The well-known difficulties in interpretation (officially the confidence statement can be interpreted only on average, but people typically implicitly give the Bayesian interpretation to each case),
 
- The ambiguity between confidence intervals and predictive intervals.  (See the footnote in BDA where we discuss the difference between “inference” and “prediction” in the classical framework.)
 
- The awkwardness of explaining that confidence intervals are big in noisy situations where you have  less  confidence, and confidence intervals are small when you have  more  confidence.
 
So here’s my proposal.  Let’s use the term “uncertainty interval” instead.  The uncertainty interval tells you how much uncertainty you have.  That works pretty well, I think.
 
P.S.  As of this writing, “confidence interval” outGoogles “uncertainty interval” by the huge margin of 9.5 million to 54000.  So we</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 (See the footnote in BDA where we discuss the difference between “inference” and “prediction” in the classical framework. [sent-2, score-0.311]
</p><p>2 )   - The awkwardness of explaining that confidence intervals are big in noisy situations where you have  less  confidence, and confidence intervals are small when you have  more  confidence. [sent-3, score-2.199]
</p><p>3 The uncertainty interval tells you how much uncertainty you have. [sent-6, score-1.14]
</p><p>4 As of this writing, “confidence interval” outGoogles “uncertainty interval” by the huge margin of 9. [sent-10, score-0.184]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('confidence', 0.555), ('interval', 0.472), ('uncertainty', 0.291), ('intervals', 0.264), ('interpretation', 0.157), ('awkwardness', 0.144), ('term', 0.142), ('ambiguity', 0.133), ('officially', 0.13), ('footnote', 0.114), ('margin', 0.113), ('uncomfortable', 0.111), ('increasingly', 0.107), ('bda', 0.103), ('interpreted', 0.099), ('noisy', 0.095), ('implicitly', 0.094), ('situations', 0.094), ('explaining', 0.092), ('difficulties', 0.086), ('tells', 0.086), ('million', 0.08), ('prediction', 0.08), ('classical', 0.077), ('predictive', 0.075), ('statement', 0.072), ('huge', 0.071), ('reasons', 0.069), ('become', 0.067), ('works', 0.067), ('typically', 0.063), ('discuss', 0.063), ('ways', 0.059), ('difference', 0.057), ('average', 0.056), ('inference', 0.053), ('several', 0.052), ('writing', 0.05), ('small', 0.049), ('let', 0.047), ('big', 0.044), ('give', 0.044), ('bayesian', 0.043), ('less', 0.043), ('pretty', 0.041), ('go', 0.037), ('case', 0.036), ('well', 0.035), ('use', 0.032), ('ve', 0.028)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="480-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-21-Instead_of_%E2%80%9Cconfidence_interval%2C%E2%80%9D_let%E2%80%99s_say_%E2%80%9Cuncertainty_interval%E2%80%9D.html">480 andrew gelman stats-2010-12-21-Instead of “confidence interval,” let’s say “uncertainty interval”</a></p>
<p>Introduction: I’ve become increasingly uncomfortable with the term “confidence interval,” for several reasons:
 
- The well-known difficulties in interpretation (officially the confidence statement can be interpreted only on average, but people typically implicitly give the Bayesian interpretation to each case),
 
- The ambiguity between confidence intervals and predictive intervals.  (See the footnote in BDA where we discuss the difference between “inference” and “prediction” in the classical framework.)
 
- The awkwardness of explaining that confidence intervals are big in noisy situations where you have  less  confidence, and confidence intervals are small when you have  more  confidence.
 
So here’s my proposal.  Let’s use the term “uncertainty interval” instead.  The uncertainty interval tells you how much uncertainty you have.  That works pretty well, I think.
 
P.S.  As of this writing, “confidence interval” outGoogles “uncertainty interval” by the huge margin of 9.5 million to 54000.  So we</p><p>2 0.49544179 <a title="480-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-24-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">1913 andrew gelman stats-2013-06-24-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>Introduction: I’m reposing  this  classic from 2011 . . . Peter Bergman pointed me to  this discussion  from Cyrus of  a presentation  by Guido Imbens on design of randomized experiments.
 
Cyrus writes:
  
The standard analysis that Imbens proposes includes (1) a Fisher-type permutation test of the sharp null hypothesis–what Imbens referred to as “testing”–along with a (2) Neyman-type point estimate of the sample average treatment effect and confidence interval–what Imbens referred to as “estimation.” . . .


Imbens claimed that testing and estimation are separate enterprises with separate goals and that the two should not be confused. I [Cyrus] took it as a warning against proposals that use “inverted” tests in order to produce point estimates and confidence intervals. There is no reason that such confidence intervals will have accurate coverage except under rather dire assumptions, meaning that they are not “confidence intervals” in the way that we usually think of them.
  
I agree completely.  T</p><p>3 0.47029862 <a title="480-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-25-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">870 andrew gelman stats-2011-08-25-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>Introduction: Peter Bergman points me to  this discussion  from Cyrus of  a presentation  by Guido Imbens on design of randomized experiments.
 
Cyrus writes:
  
The standard analysis that Imbens proposes includes (1) a Fisher-type permutation test of the sharp null hypothesis–what Imbens referred to as “testing”–along with a (2) Neyman-type point estimate of the sample average treatment effect and confidence interval–what Imbens referred to as “estimation.” . . .


Imbens claimed that testing and estimation are separate enterprises with separate goals and that the two should not be confused. I [Cyrus] took it as a warning against proposals that use “inverted” tests in order to produce point estimates and confidence intervals. There is no reason that such confidence intervals will have accurate coverage except under rather dire assumptions, meaning that they are not “confidence intervals” in the way that we usually think of them.
  
I agree completely.  This is something I’ve been saying for a long</p><p>4 0.41102442 <a title="480-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-14-How_do_you_think_about_the_values_in_a_confidence_interval%3F.html">1672 andrew gelman stats-2013-01-14-How do you think about the values in a confidence interval?</a></p>
<p>Introduction: Philip Jones writes:
  
As an interested reader of your blog, I wondered if you might consider a blog entry sometime on the following  question  I posed on CrossValidated (StackExchange).


I originally posed the question based on my uncertainty about 95% CIs: “Are all values within the 95% CI equally likely (probable), or are the values at the “tails” of the 95% CI less likely than those in the middle of the CI closer to the point estimate?”


I posed this question based on discordant information I found at a couple of different web sources (I posted these sources in the body of the question).


I received some interesting replies, and the replies were not unanimous, in fact there is some serious disagreement there! After seeing this disagreement, I naturally thought of you, and whether you might be able to clear this up.


Please note I am not referring to credible intervals, but rather to the common medical journal reporting standard of confidence intervals.
  
My response:
 
First</p><p>5 0.27510232 <a title="480-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-20-Question_10_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1333 andrew gelman stats-2012-05-20-Question 10 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>Introduction: 10. Out of a random sample of 100 Americans, zero report having ever held political office. From this information, give a 95% confidence interval for the proportion of Americans who have ever held political office.
 
 Solution to question 9 
 
From  yesterday :
  
9. Out of a population of 100 medical records, 40 are randomly sampled and then audited. 10 out of the 40 audits reveal fraud. From this information, give an estimate, standard error, and 95% confidence interval for the proportion of audits in the population with fraud.
  
Solution:  estimate is p.hat=10/40=0.25.  Se is sqrt(1-f)*sqrt(p.hat*(1-.hat)/n)=sqrt(1-0.4)*sqrt(0.25*0.75/40)=0.053.  95% interval is [0.25 +/- 2*0.053] = [0.14,0.36].</p><p>6 0.26955172 <a title="480-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-21-Question_11_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1334 andrew gelman stats-2012-05-21-Question 11 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>7 0.2278506 <a title="480-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Bayesian_inference_viewed_as_a_computational_approximation_to_classical_calculations.html">254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</a></p>
<p>8 0.21234578 <a title="480-tfidf-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-15-Problematic_interpretations_of_confidence_intervals.html">2248 andrew gelman stats-2014-03-15-Problematic interpretations of confidence intervals</a></p>
<p>9 0.18651359 <a title="480-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-06-Bootstrap_averaging%3A_Examples_where_it_works_and_where_it_doesn%E2%80%99t_work.html">2201 andrew gelman stats-2014-02-06-Bootstrap averaging: Examples where it works and where it doesn’t work</a></p>
<p>10 0.18127163 <a title="480-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>11 0.17766985 <a title="480-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-21-Don%E2%80%99t_judge_a_book_by_its_title.html">1021 andrew gelman stats-2011-11-21-Don’t judge a book by its title</a></p>
<p>12 0.16981894 <a title="480-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-10-95%25_intervals_that_I_don%E2%80%99t_believe%2C_because_they%E2%80%99re_from_a_flat_prior_I_don%E2%80%99t_believe.html">1206 andrew gelman stats-2012-03-10-95% intervals that I don’t believe, because they’re from a flat prior I don’t believe</a></p>
<p>13 0.16154593 <a title="480-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<p>14 0.15132017 <a title="480-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-09-Visually_weighting_regression_displays.html">1452 andrew gelman stats-2012-08-09-Visually weighting regression displays</a></p>
<p>15 0.1439178 <a title="480-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-Another_reason_why_you_can_get_good_inferences_from_a_bad_model.html">1527 andrew gelman stats-2012-10-10-Another reason why you can get good inferences from a bad model</a></p>
<p>16 0.13022685 <a title="480-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-05-Evidence_on_the_impact_of_sustained_use_of_polynomial_regression_on_causal_inference_%28a_claim_that_coal_heating_is_reducing_lifespan_by_5_years_for_half_a_billion_people%29.html">1968 andrew gelman stats-2013-08-05-Evidence on the impact of sustained use of polynomial regression on causal inference (a claim that coal heating is reducing lifespan by 5 years for half a billion people)</a></p>
<p>17 0.12927052 <a title="480-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-21-How_many_data_points_do_you_really_have%3F.html">1178 andrew gelman stats-2012-02-21-How many data points do you really have?</a></p>
<p>18 0.12905762 <a title="480-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-21-Chasing_the_noise.html">2142 andrew gelman stats-2013-12-21-Chasing the noise</a></p>
<p>19 0.12700593 <a title="480-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-10-On_deck_this_week%3A__Things_people_sent_me.html">2240 andrew gelman stats-2014-03-10-On deck this week:  Things people sent me</a></p>
<p>20 0.12368897 <a title="480-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-09-The_difference_between_%E2%80%9Csignificant%E2%80%9D_and_%E2%80%9Cnon-significant%E2%80%9D_is_not_itself_statistically_significant.html">1662 andrew gelman stats-2013-01-09-The difference between “significant” and “non-significant” is not itself statistically significant</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.101), (1, 0.065), (2, 0.048), (3, -0.047), (4, -0.031), (5, -0.042), (6, -0.014), (7, 0.06), (8, 0.049), (9, -0.189), (10, -0.071), (11, 0.012), (12, 0.02), (13, -0.046), (14, -0.049), (15, -0.049), (16, -0.066), (17, -0.058), (18, 0.067), (19, -0.132), (20, 0.187), (21, 0.059), (22, 0.156), (23, -0.035), (24, 0.224), (25, -0.136), (26, -0.074), (27, -0.156), (28, -0.057), (29, 0.106), (30, -0.032), (31, -0.135), (32, -0.082), (33, -0.099), (34, 0.096), (35, 0.089), (36, -0.03), (37, 0.189), (38, 0.054), (39, -0.023), (40, 0.028), (41, -0.008), (42, 0.155), (43, -0.048), (44, 0.038), (45, -0.024), (46, -0.061), (47, -0.002), (48, -0.002), (49, 0.006)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99452215 <a title="480-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-21-Instead_of_%E2%80%9Cconfidence_interval%2C%E2%80%9D_let%E2%80%99s_say_%E2%80%9Cuncertainty_interval%E2%80%9D.html">480 andrew gelman stats-2010-12-21-Instead of “confidence interval,” let’s say “uncertainty interval”</a></p>
<p>Introduction: I’ve become increasingly uncomfortable with the term “confidence interval,” for several reasons:
 
- The well-known difficulties in interpretation (officially the confidence statement can be interpreted only on average, but people typically implicitly give the Bayesian interpretation to each case),
 
- The ambiguity between confidence intervals and predictive intervals.  (See the footnote in BDA where we discuss the difference between “inference” and “prediction” in the classical framework.)
 
- The awkwardness of explaining that confidence intervals are big in noisy situations where you have  less  confidence, and confidence intervals are small when you have  more  confidence.
 
So here’s my proposal.  Let’s use the term “uncertainty interval” instead.  The uncertainty interval tells you how much uncertainty you have.  That works pretty well, I think.
 
P.S.  As of this writing, “confidence interval” outGoogles “uncertainty interval” by the huge margin of 9.5 million to 54000.  So we</p><p>2 0.84828734 <a title="480-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-14-How_do_you_think_about_the_values_in_a_confidence_interval%3F.html">1672 andrew gelman stats-2013-01-14-How do you think about the values in a confidence interval?</a></p>
<p>Introduction: Philip Jones writes:
  
As an interested reader of your blog, I wondered if you might consider a blog entry sometime on the following  question  I posed on CrossValidated (StackExchange).


I originally posed the question based on my uncertainty about 95% CIs: “Are all values within the 95% CI equally likely (probable), or are the values at the “tails” of the 95% CI less likely than those in the middle of the CI closer to the point estimate?”


I posed this question based on discordant information I found at a couple of different web sources (I posted these sources in the body of the question).


I received some interesting replies, and the replies were not unanimous, in fact there is some serious disagreement there! After seeing this disagreement, I naturally thought of you, and whether you might be able to clear this up.


Please note I am not referring to credible intervals, but rather to the common medical journal reporting standard of confidence intervals.
  
My response:
 
First</p><p>3 0.82027185 <a title="480-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-24-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">1913 andrew gelman stats-2013-06-24-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>Introduction: I’m reposing  this  classic from 2011 . . . Peter Bergman pointed me to  this discussion  from Cyrus of  a presentation  by Guido Imbens on design of randomized experiments.
 
Cyrus writes:
  
The standard analysis that Imbens proposes includes (1) a Fisher-type permutation test of the sharp null hypothesis–what Imbens referred to as “testing”–along with a (2) Neyman-type point estimate of the sample average treatment effect and confidence interval–what Imbens referred to as “estimation.” . . .


Imbens claimed that testing and estimation are separate enterprises with separate goals and that the two should not be confused. I [Cyrus] took it as a warning against proposals that use “inverted” tests in order to produce point estimates and confidence intervals. There is no reason that such confidence intervals will have accurate coverage except under rather dire assumptions, meaning that they are not “confidence intervals” in the way that we usually think of them.
  
I agree completely.  T</p><p>4 0.79793161 <a title="480-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-25-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">870 andrew gelman stats-2011-08-25-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>Introduction: Peter Bergman points me to  this discussion  from Cyrus of  a presentation  by Guido Imbens on design of randomized experiments.
 
Cyrus writes:
  
The standard analysis that Imbens proposes includes (1) a Fisher-type permutation test of the sharp null hypothesis–what Imbens referred to as “testing”–along with a (2) Neyman-type point estimate of the sample average treatment effect and confidence interval–what Imbens referred to as “estimation.” . . .


Imbens claimed that testing and estimation are separate enterprises with separate goals and that the two should not be confused. I [Cyrus] took it as a warning against proposals that use “inverted” tests in order to produce point estimates and confidence intervals. There is no reason that such confidence intervals will have accurate coverage except under rather dire assumptions, meaning that they are not “confidence intervals” in the way that we usually think of them.
  
I agree completely.  This is something I’ve been saying for a long</p><p>5 0.70395923 <a title="480-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-20-Question_10_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1333 andrew gelman stats-2012-05-20-Question 10 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>Introduction: 10. Out of a random sample of 100 Americans, zero report having ever held political office. From this information, give a 95% confidence interval for the proportion of Americans who have ever held political office.
 
 Solution to question 9 
 
From  yesterday :
  
9. Out of a population of 100 medical records, 40 are randomly sampled and then audited. 10 out of the 40 audits reveal fraud. From this information, give an estimate, standard error, and 95% confidence interval for the proportion of audits in the population with fraud.
  
Solution:  estimate is p.hat=10/40=0.25.  Se is sqrt(1-f)*sqrt(p.hat*(1-.hat)/n)=sqrt(1-0.4)*sqrt(0.25*0.75/40)=0.053.  95% interval is [0.25 +/- 2*0.053] = [0.14,0.36].</p><p>6 0.62542516 <a title="480-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-21-Question_11_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1334 andrew gelman stats-2012-05-21-Question 11 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>7 0.61522222 <a title="480-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-15-Problematic_interpretations_of_confidence_intervals.html">2248 andrew gelman stats-2014-03-15-Problematic interpretations of confidence intervals</a></p>
<p>8 0.5730207 <a title="480-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Bayesian_inference_viewed_as_a_computational_approximation_to_classical_calculations.html">254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</a></p>
<p>9 0.55602491 <a title="480-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>10 0.55131292 <a title="480-lsi-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-06-Bootstrap_averaging%3A_Examples_where_it_works_and_where_it_doesn%E2%80%99t_work.html">2201 andrew gelman stats-2014-02-06-Bootstrap averaging: Examples where it works and where it doesn’t work</a></p>
<p>11 0.52994788 <a title="480-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-10-95%25_intervals_that_I_don%E2%80%99t_believe%2C_because_they%E2%80%99re_from_a_flat_prior_I_don%E2%80%99t_believe.html">1206 andrew gelman stats-2012-03-10-95% intervals that I don’t believe, because they’re from a flat prior I don’t believe</a></p>
<p>12 0.52799451 <a title="480-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-19-Question_9_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1331 andrew gelman stats-2012-05-19-Question 9 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>13 0.49192247 <a title="480-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-03-Boot.html">1881 andrew gelman stats-2013-06-03-Boot</a></p>
<p>14 0.48432136 <a title="480-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-29-Statistics_and_the_end_of_time.html">306 andrew gelman stats-2010-09-29-Statistics and the end of time</a></p>
<p>15 0.4829275 <a title="480-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-21-Don%E2%80%99t_judge_a_book_by_its_title.html">1021 andrew gelman stats-2011-11-21-Don’t judge a book by its title</a></p>
<p>16 0.47724473 <a title="480-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>17 0.4613255 <a title="480-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-09-The_difference_between_%E2%80%9Csignificant%E2%80%9D_and_%E2%80%9Cnon-significant%E2%80%9D_is_not_itself_statistically_significant.html">1662 andrew gelman stats-2013-01-09-The difference between “significant” and “non-significant” is not itself statistically significant</a></p>
<p>18 0.45216939 <a title="480-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-12-The_Wald_method_has_been_the_subject_of_extensive_criticism_by_statisticians_for_exaggerating_results%E2%80%9D.html">410 andrew gelman stats-2010-11-12-The Wald method has been the subject of extensive criticism by statisticians for exaggerating results”</a></p>
<p>19 0.44003659 <a title="480-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-31-Watercolor_regression.html">1478 andrew gelman stats-2012-08-31-Watercolor regression</a></p>
<p>20 0.43936107 <a title="480-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-23-A_statistical_version_of_Arrow%E2%80%99s_paradox.html">586 andrew gelman stats-2011-02-23-A statistical version of Arrow’s paradox</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.012), (2, 0.013), (9, 0.015), (15, 0.022), (16, 0.036), (20, 0.164), (21, 0.041), (24, 0.081), (63, 0.02), (72, 0.023), (86, 0.029), (99, 0.4)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99368215 <a title="480-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-21-Instead_of_%E2%80%9Cconfidence_interval%2C%E2%80%9D_let%E2%80%99s_say_%E2%80%9Cuncertainty_interval%E2%80%9D.html">480 andrew gelman stats-2010-12-21-Instead of “confidence interval,” let’s say “uncertainty interval”</a></p>
<p>Introduction: I’ve become increasingly uncomfortable with the term “confidence interval,” for several reasons:
 
- The well-known difficulties in interpretation (officially the confidence statement can be interpreted only on average, but people typically implicitly give the Bayesian interpretation to each case),
 
- The ambiguity between confidence intervals and predictive intervals.  (See the footnote in BDA where we discuss the difference between “inference” and “prediction” in the classical framework.)
 
- The awkwardness of explaining that confidence intervals are big in noisy situations where you have  less  confidence, and confidence intervals are small when you have  more  confidence.
 
So here’s my proposal.  Let’s use the term “uncertainty interval” instead.  The uncertainty interval tells you how much uncertainty you have.  That works pretty well, I think.
 
P.S.  As of this writing, “confidence interval” outGoogles “uncertainty interval” by the huge margin of 9.5 million to 54000.  So we</p><p>2 0.97408646 <a title="480-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-15-Google_Refine.html">910 andrew gelman stats-2011-09-15-Google Refine</a></p>
<p>Introduction: Tools worth knowing about: 
  
  Google Refine  is a power tool for working with messy data, cleaning it up, transforming it from one format into another, extending it with web services, and linking it to databases like Freebase.
  
A recent  discussion on the Polmeth list  about the  ANES Cumulative File  is a setting where I think Refine might help (admittedly 49760×951 is bigger than I’d really like to deal with in the browser with js… but on a subset yes). [I might write this example up later.]
 
Go watch the screencast videos for Refine. Data-entry problems are rampant in stuff we all use — leading or trailing spaces; mixed decimal-indicators; different units or transformations used in the same column; mixed lettercase leading to false duplicates; that’s only the beginning. Refine certainly would help find duplicates, and it counts things for you too. Just counting rows is too much for researchers sometimes (see  yesterday’s post )!
 
Refine 2.0 adds some data-collection tools for</p><p>3 0.97407687 <a title="480-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-13-Meritocracy_rerun.html">1937 andrew gelman stats-2013-07-13-Meritocracy rerun</a></p>
<p>Introduction: Iâ&euro;&trade;ve said it here so often,  this time  I put it on the sister blog. . . .</p><p>4 0.95741183 <a title="480-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-18-It_happened_in_Connecticut.html">1629 andrew gelman stats-2012-12-18-It happened in Connecticut</a></p>
<p>Introduction: From the sister blog,  some reasons  why the political reaction might be different this time.</p><p>5 0.95715672 <a title="480-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-26-NYC_jobs_in_applied_statistics%2C_psychometrics%2C_and_causal_inference%21.html">974 andrew gelman stats-2011-10-26-NYC jobs in applied statistics, psychometrics, and causal inference!</a></p>
<p>Introduction: The Center for the Promotion of Research Involving Innovative Statistical Methodology at the Steinhardt School of Education has  two job openings !  One is for an assistant/associated tenure track position for an applied statistician or psychometrician.  The other is for a postdoc in causal inference and sensitivity analysis.
 
Jennifer Hill and Marc Scott at the Steinhardt school are just great!  Weâ&euro;&trade;re working together on various research projects so if you manage to get one of these jobs maybe you can collaborate with us here at Columbia too.  So I have every interest in encouraging the very best people to apply for these jobs.</p><p>6 0.95702934 <a title="480-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-18-The_treatment%2C_the_intermediate_outcome%2C_and_the_ultimate_outcome%3A__Leverage_and_the_financial_crisis.html">1420 andrew gelman stats-2012-07-18-The treatment, the intermediate outcome, and the ultimate outcome:  Leverage and the financial crisis</a></p>
<p>7 0.95652395 <a title="480-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-30-A_Wikipedia_riddle%21.html">831 andrew gelman stats-2011-07-30-A Wikipedia riddle!</a></p>
<p>8 0.9557091 <a title="480-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-26-%E2%80%9CDo_you_need_ideal_conditions_to_do_great_work%3F%E2%80%9D.html">592 andrew gelman stats-2011-02-26-“Do you need ideal conditions to do great work?”</a></p>
<p>9 0.95421523 <a title="480-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-14-NYC_1950.html">661 andrew gelman stats-2011-04-14-NYC 1950</a></p>
<p>10 0.95131326 <a title="480-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-20-WWJD%3F__U_can_find_out%21.html">479 andrew gelman stats-2010-12-20-WWJD?  U can find out!</a></p>
<p>11 0.94956112 <a title="480-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-12-Comparison_of_forecasts_for_the_2010_congressional_elections.html">270 andrew gelman stats-2010-09-12-Comparison of forecasts for the 2010 congressional elections</a></p>
<p>12 0.9493168 <a title="480-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Bayesian_inference_viewed_as_a_computational_approximation_to_classical_calculations.html">254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</a></p>
<p>13 0.94321251 <a title="480-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-19-Demystifying_Blup.html">1270 andrew gelman stats-2012-04-19-Demystifying Blup</a></p>
<p>14 0.93954718 <a title="480-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-24-Bayesian_quality_control%3F.html">1912 andrew gelman stats-2013-06-24-Bayesian quality control?</a></p>
<p>15 0.93942398 <a title="480-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-11-Symptomatic_innumeracy.html">900 andrew gelman stats-2011-09-11-Symptomatic innumeracy</a></p>
<p>16 0.93834782 <a title="480-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<p>17 0.93624884 <a title="480-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-09-Data_Visualization.html">194 andrew gelman stats-2010-08-09-Data Visualization</a></p>
<p>18 0.93517292 <a title="480-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-30-%E2%80%9CStatistical_Modeling%3A__A_Fresh_Approach%E2%80%9D.html">1782 andrew gelman stats-2013-03-30-“Statistical Modeling:  A Fresh Approach”</a></p>
<p>19 0.93268454 <a title="480-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-21-The_Commissar_for_Traffic_presents_the_latest_Five-Year_Plan.html">2181 andrew gelman stats-2014-01-21-The Commissar for Traffic presents the latest Five-Year Plan</a></p>
<p>20 0.93098199 <a title="480-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-14-As_the_saying_goes%2C_when_they_argue_that_you%E2%80%99re_taking_over%2C_that%E2%80%99s_when_you_know_you%E2%80%99ve_won.html">611 andrew gelman stats-2011-03-14-As the saying goes, when they argue that you’re taking over, that’s when you know you’ve won</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
