<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-352" href="#">andrew_gelman_stats-2010-352</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-352-html" href="http://andrewgelman.com/2010/10/19/analysis_of_sur/">html</a></p><p>Introduction: Alban Zeber writes:
  
 
Suppose I have survey data from  say 10 countries where by each country collected the data based on different sampling routines –  the results of this being that  each country has its own weights for the data that can be used in the analyses. If I analyse the data of each country separately then I can incorporate the survey design in the analyses e.g in Stata once can use svyset …..


But what happens when I want to do a pooled analysis of the all the data from the 10 countries:


Presumably either 


1.  I analyse the data from each country separately (using multiple or logistic regression, …) accounting for the survey design and then combine the estimates using a meta analysis (fixed or random)


  OR


2.  Assume that the data from each country is a simple random sample from the population, combine the data from the 10 countries and then use multilevel or hierarchical models


My question is which of the methods is likely to give better estimates?  Or is the</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Alban Zeber writes:      Suppose I have survey data from  say 10 countries where by each country collected the data based on different sampling routines –  the results of this being that  each country has its own weights for the data that can be used in the analyses. [sent-1, score-2.253]
</p><p>2 If I analyse the data of each country separately then I can incorporate the survey design in the analyses e. [sent-2, score-1.566]
</p><p>3 But what happens when I want to do a pooled analysis of the all the data from the 10 countries:   Presumably either    1. [sent-5, score-0.364]
</p><p>4 I analyse the data from each country separately (using multiple or logistic regression, …) accounting for the survey design and then combine the estimates using a meta analysis (fixed or random)     OR   2. [sent-6, score-2.136]
</p><p>5 Assume that the data from each country is a simple random sample from the population, combine the data from the 10 countries and then use multilevel or hierarchical models   My question is which of the methods is likely to give better estimates? [sent-7, score-1.542]
</p><p>6 Is there a method one can use to get the best of both worlds i. [sent-9, score-0.318]
</p><p>7 e accounting for the survey design within each country’s data as well as account for the fact that the data from each country is correlated and therefore accounting for the correlation via multilevel/hierarchical models. [sent-10, score-1.83]
</p><p>8 If such a method exists, is it implemented in any of the ‘common’ statistical programs? [sent-11, score-0.214]
</p><p>9 My reply:   Of your two choices above, I recommend your first option, the meta-analysis. [sent-12, score-0.064]
</p><p>10 You can take the estimate and standard error from each of your separate surveys and then put them together, including survey and country-level predictors as well. [sent-13, score-0.342]
</p><p>11 Your data are not simple random samples, or even close (it they were close, nobody would be doing weighting), and so you shouldn’t go around assuming they are. [sent-15, score-0.502]
</p><p>12 What you need to do is find out where the survey weights came from. [sent-17, score-0.515]
</p><p>13 Then, do your regression analysis conditional on all the variables used in the weighting, and all will be fine. [sent-18, score-0.341]
</p><p>14 Use a multilevel model with appropriate interactions to model what you need to model. [sent-19, score-0.264]
</p><p>15 Including the variables used in the weighting is as “design-based” as you need to be, and it’s the essence of Mister P. [sent-20, score-0.604]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('country', 0.4), ('survey', 0.263), ('accounting', 0.258), ('weighting', 0.231), ('analyse', 0.217), ('data', 0.186), ('countries', 0.186), ('combine', 0.164), ('weights', 0.157), ('separately', 0.157), ('design', 0.152), ('random', 0.142), ('method', 0.136), ('alban', 0.125), ('zeber', 0.125), ('routines', 0.125), ('meta', 0.109), ('analyses', 0.108), ('multilevel', 0.104), ('pooled', 0.098), ('essence', 0.097), ('use', 0.096), ('close', 0.096), ('need', 0.095), ('struggles', 0.092), ('variables', 0.091), ('used', 0.09), ('mister', 0.087), ('worlds', 0.086), ('estimates', 0.086), ('exists', 0.083), ('incorporate', 0.083), ('analysis', 0.08), ('regression', 0.08), ('including', 0.079), ('stata', 0.079), ('implemented', 0.078), ('simple', 0.078), ('collected', 0.074), ('programs', 0.072), ('option', 0.07), ('analyze', 0.069), ('raw', 0.069), ('presumably', 0.068), ('interactions', 0.065), ('samples', 0.065), ('choices', 0.064), ('logistic', 0.064), ('correlated', 0.064), ('therefore', 0.063)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="352-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-19-Analysis_of_survey_data%3A_Design_based_models_vs._hierarchical_modeling%3F.html">352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</a></p>
<p>Introduction: Alban Zeber writes:
  
 
Suppose I have survey data from  say 10 countries where by each country collected the data based on different sampling routines –  the results of this being that  each country has its own weights for the data that can be used in the analyses. If I analyse the data of each country separately then I can incorporate the survey design in the analyses e.g in Stata once can use svyset …..


But what happens when I want to do a pooled analysis of the all the data from the 10 countries:


Presumably either 


1.  I analyse the data from each country separately (using multiple or logistic regression, …) accounting for the survey design and then combine the estimates using a meta analysis (fixed or random)


  OR


2.  Assume that the data from each country is a simple random sample from the population, combine the data from the 10 countries and then use multilevel or hierarchical models


My question is which of the methods is likely to give better estimates?  Or is the</p><p>2 0.260382 <a title="352-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-26-Some_thoughts_on_survey_weighting.html">1430 andrew gelman stats-2012-07-26-Some thoughts on survey weighting</a></p>
<p>Introduction: From a comment I made in an email exchange:
 
My  work  on survey adjustments has very much been inspired by the ideas of Rod Little.  Much of my efforts have gone toward the goal of integrating hierarchical modeling (which is so helpful for small-area estimation) with post stratification (which adjusts for known differences between sample and population).  In the surveys I’ve dealt with, nonresponse/nonavailability can be a big issue, and I’ve always tried to emphasize that (a) the probability of a person being included in the sample is just about never known, and (b) even if this probability were known, I’d rather know the empirical n/N than the probability p (which is only valid in expectation).  Regarding nonparametric modeling:  I haven’t done much of that (although I hope to at some point) but Rod and his students have.
 
As I wrote in the first sentence of the above-linked paper, I do think the current theory and practice of survey weighting is a mess, in that much depends on so</p><p>3 0.20659065 <a title="352-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-01-Weighting_and_prediction_in_sample_surveys.html">784 andrew gelman stats-2011-07-01-Weighting and prediction in sample surveys</a></p>
<p>Introduction: A couple years ago Rod Little was invited to write an article for the diamond jubilee of the Calcutta Statistical Association Bulletin.  His article was published with discussions from Danny Pfefferman, J. N. K. Rao, Don Rubin, and myself. 
 Here it all is .
 
I’ll paste my discussion below, but it’s worth reading the others’ perspectives too.  Especially the part in Rod’s rejoinder where he points out a mistake I made.
  

 
Survey weights, like sausage and legislation, are designed and best appreciated by those who are placed a respectable distance from their manufacture. For those of us working inside the factory, vigorous discussion of methods is appreciated. I enjoyed Rod Little’s review of the connections between modeling and survey weighting and have just a few comments.
 
I like Little’s discussion of model-based shrinkage of post-stratum averages, which, as he notes, can be seen to correspond to shrinkage of weights. I would only add one thing to his formula at the end of his</p><p>4 0.20172344 <a title="352-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-07-Question_28_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1371 andrew gelman stats-2012-06-07-Question 28 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>Introduction: This is it, the last question on the exam!
 
28. A telephone survey was conducted several years ago, asking people how often they were polled in the past year. I can’t recall the responses, but suppose that 40% of the respondents said they participated in zero surveys in the previous year, 30% said they participated in one survey, 15% said two surveys, 10% said three, and 5% said four. From this it is easy to estimate an average, but there is a worry that this survey will itself overrepresent survey participants and thus overestimate the rate at which the average person is surveyed. Come up with a procedure to use these data to get an improved estimate of the average number of surveys that a randomly-sampled American is polled in a year.
 
 Solution to question 27 
 
From  yesterday :
  
27. Which of the following problems were identified with the Burnham et al. survey of Iraq mortality? (Indicate all that apply.)


(a) The survey used cluster sampling, which is inappropriate for estim</p><p>5 0.19479619 <a title="352-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>Introduction: Steve Miller writes: 
  
  
Much of what I do is cross-national analyses of survey data (largely World Values Survey). . . . My big question pertains to (what I would call) exploratory analysis of multilevel data, especially when the group-level predictors are of theoretical importance. A lot of what I do involves analyzing cross-national survey items of citizen attitudes, typically of political leadership. These survey items are usually yes/no responses, or four-part responses indicating a level of agreement (strongly agree, agree, disagree, strongly disagree) that can be condensed into a binary variable. I believe these can be explained by reference to country-level factors. Much of the group-level variables of interest are count variables with a modal value of 0, which can be quite messy.


How would you recommend exploring the variation in the dependent variable as it could be explained by the group-level count variable of interest, before fitting the multilevel model itself? When</p><p>6 0.19207671 <a title="352-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-10-Estimation_from_an_out-of-date_census.html">405 andrew gelman stats-2010-11-10-Estimation from an out-of-date census</a></p>
<p>7 0.16810474 <a title="352-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-28-Bayesian_nonparametric_weighted_sampling_inference.html">2351 andrew gelman stats-2014-05-28-Bayesian nonparametric weighted sampling inference</a></p>
<p>8 0.15365678 <a title="352-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-12-Probabilistic_screening_to_get_an_approximate_self-weighted_sample.html">1455 andrew gelman stats-2012-08-12-Probabilistic screening to get an approximate self-weighted sample</a></p>
<p>9 0.1521244 <a title="352-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>10 0.15179172 <a title="352-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-13-A_survey%E2%80%99s_not_a_survey_if_they_don%E2%80%99t_tell_you_how_they_did_it.html">761 andrew gelman stats-2011-06-13-A survey’s not a survey if they don’t tell you how they did it</a></p>
<p>11 0.14854448 <a title="352-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Some_interesting_unpublished_ideas_on_survey_weighting.html">705 andrew gelman stats-2011-05-10-Some interesting unpublished ideas on survey weighting</a></p>
<p>12 0.14754042 <a title="352-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-03-How_best_to_learn_R%3F.html">65 andrew gelman stats-2010-06-03-How best to learn R?</a></p>
<p>13 0.14631937 <a title="352-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>14 0.14529039 <a title="352-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-Blending_results_from_two_relatively_independent_multi-level_models.html">250 andrew gelman stats-2010-09-02-Blending results from two relatively independent multi-level models</a></p>
<p>15 0.14399891 <a title="352-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-28-Using_randomized_incentives_as_an_instrument_for_survey_nonresponse%3F.html">2152 andrew gelman stats-2013-12-28-Using randomized incentives as an instrument for survey nonresponse?</a></p>
<p>16 0.13863632 <a title="352-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-21-Building_a_regression_model_._._._with_only_27_data_points.html">1506 andrew gelman stats-2012-09-21-Building a regression model . . . with only 27 data points</a></p>
<p>17 0.13840181 <a title="352-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>18 0.13597405 <a title="352-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-Attractive_but_hard-to-read_graph_could_be_made_much_much_better.html">670 andrew gelman stats-2011-04-20-Attractive but hard-to-read graph could be made much much better</a></p>
<p>19 0.1347599 <a title="352-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>20 0.13447505 <a title="352-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-14-Prior_distribution_for_design_effects.html">85 andrew gelman stats-2010-06-14-Prior distribution for design effects</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.218), (1, 0.14), (2, 0.156), (3, -0.086), (4, 0.152), (5, 0.07), (6, -0.073), (7, -0.009), (8, 0.08), (9, 0.01), (10, 0.084), (11, -0.117), (12, -0.009), (13, 0.117), (14, -0.009), (15, -0.009), (16, -0.035), (17, -0.01), (18, 0.041), (19, -0.002), (20, -0.03), (21, 0.011), (22, -0.043), (23, 0.07), (24, -0.102), (25, -0.029), (26, 0.019), (27, -0.016), (28, 0.046), (29, 0.055), (30, 0.054), (31, 0.021), (32, 0.017), (33, 0.04), (34, -0.047), (35, 0.039), (36, -0.015), (37, 0.022), (38, -0.04), (39, 0.059), (40, 0.029), (41, 0.051), (42, 0.044), (43, -0.02), (44, -0.007), (45, 0.032), (46, 0.032), (47, -0.008), (48, -0.0), (49, -0.003)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95454085 <a title="352-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-19-Analysis_of_survey_data%3A_Design_based_models_vs._hierarchical_modeling%3F.html">352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</a></p>
<p>Introduction: Alban Zeber writes:
  
 
Suppose I have survey data from  say 10 countries where by each country collected the data based on different sampling routines –  the results of this being that  each country has its own weights for the data that can be used in the analyses. If I analyse the data of each country separately then I can incorporate the survey design in the analyses e.g in Stata once can use svyset …..


But what happens when I want to do a pooled analysis of the all the data from the 10 countries:


Presumably either 


1.  I analyse the data from each country separately (using multiple or logistic regression, …) accounting for the survey design and then combine the estimates using a meta analysis (fixed or random)


  OR


2.  Assume that the data from each country is a simple random sample from the population, combine the data from the 10 countries and then use multilevel or hierarchical models


My question is which of the methods is likely to give better estimates?  Or is the</p><p>2 0.84193295 <a title="352-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-10-Estimation_from_an_out-of-date_census.html">405 andrew gelman stats-2010-11-10-Estimation from an out-of-date census</a></p>
<p>Introduction: Suguru Mizunoya writes:
  
When we estimate the number of people from a national sampling survey (such as labor force survey) using sampling weights, don’t we obtain underestimated number of people, if the country’s population is growing and the sampling frame is based on an old census data?  In countries with increasing populations, the probability of inclusion changes over time, but the weights can’t be adjusted frequently because census takes place only once every five or ten years.


I am currently working for UNICEF for a project on estimating number of out-of-school children in developing countries. The project leader is comfortable to use estimates of number of people from DHS and other surveys.  But, I am concerned that we may need to adjust the estimated number of people by the population projection, otherwise the estimates will be underestimated.


I googled around on this issue, but I could not find a right article or paper on this.
  
My reply:  I don’t know if there’s a pa</p><p>3 0.83765864 <a title="352-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-01-Weighting_and_prediction_in_sample_surveys.html">784 andrew gelman stats-2011-07-01-Weighting and prediction in sample surveys</a></p>
<p>Introduction: A couple years ago Rod Little was invited to write an article for the diamond jubilee of the Calcutta Statistical Association Bulletin.  His article was published with discussions from Danny Pfefferman, J. N. K. Rao, Don Rubin, and myself. 
 Here it all is .
 
I’ll paste my discussion below, but it’s worth reading the others’ perspectives too.  Especially the part in Rod’s rejoinder where he points out a mistake I made.
  

 
Survey weights, like sausage and legislation, are designed and best appreciated by those who are placed a respectable distance from their manufacture. For those of us working inside the factory, vigorous discussion of methods is appreciated. I enjoyed Rod Little’s review of the connections between modeling and survey weighting and have just a few comments.
 
I like Little’s discussion of model-based shrinkage of post-stratum averages, which, as he notes, can be seen to correspond to shrinkage of weights. I would only add one thing to his formula at the end of his</p><p>4 0.8357994 <a title="352-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>Introduction: Steve Miller writes: 
  
  
Much of what I do is cross-national analyses of survey data (largely World Values Survey). . . . My big question pertains to (what I would call) exploratory analysis of multilevel data, especially when the group-level predictors are of theoretical importance. A lot of what I do involves analyzing cross-national survey items of citizen attitudes, typically of political leadership. These survey items are usually yes/no responses, or four-part responses indicating a level of agreement (strongly agree, agree, disagree, strongly disagree) that can be condensed into a binary variable. I believe these can be explained by reference to country-level factors. Much of the group-level variables of interest are count variables with a modal value of 0, which can be quite messy.


How would you recommend exploring the variation in the dependent variable as it could be explained by the group-level count variable of interest, before fitting the multilevel model itself? When</p><p>5 0.81918395 <a title="352-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-28-Using_randomized_incentives_as_an_instrument_for_survey_nonresponse%3F.html">2152 andrew gelman stats-2013-12-28-Using randomized incentives as an instrument for survey nonresponse?</a></p>
<p>Introduction: I received the following question:
  
Is there a classic paper on instrumenting for survey non-response?  some colleagues in public health are going to carry out a survey and I wonder about suggesting that they build in a randomization of response-encouragement (e.g. offering additional $ to a subset of those who don’t respond initially).  Can you recommend a basic treatment of this, and why it might or might not make sense compared to IPW using covariates (without an instrument)?
  
My reply:   Here’s  the best analysis I know of on the effects of incentives for survey response.  There have been several survey-experiments on the subject.  The short answer is that the effect on nonresponse is small and the outcome is highly variable, hence you can’t very well use it as an instrument in any particular survey.
 
My recommended approach to dealing with nonresponse is to use multilevel regression and poststratification; an example is  here .
 
Inverse-probability weighting doesn’t really w</p><p>6 0.81038141 <a title="352-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-26-Some_thoughts_on_survey_weighting.html">1430 andrew gelman stats-2012-07-26-Some thoughts on survey weighting</a></p>
<p>7 0.79483229 <a title="352-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-12-Probabilistic_screening_to_get_an_approximate_self-weighted_sample.html">1455 andrew gelman stats-2012-08-12-Probabilistic screening to get an approximate self-weighted sample</a></p>
<p>8 0.7754612 <a title="352-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-07-Diabetes_stops_at_the_state_line%3F.html">454 andrew gelman stats-2010-12-07-Diabetes stops at the state line?</a></p>
<p>9 0.77233726 <a title="352-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Modeling_y_%3D_a_%2B_b_%2B_c.html">1294 andrew gelman stats-2012-05-01-Modeling y = a + b + c</a></p>
<p>10 0.76435405 <a title="352-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Mister_P_goes_on_a_date.html">70 andrew gelman stats-2010-06-07-Mister P goes on a date</a></p>
<p>11 0.76378292 <a title="352-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-A_poll_that_throws_away_data%3F%3F%3F.html">1940 andrew gelman stats-2013-07-16-A poll that throws away data???</a></p>
<p>12 0.75307983 <a title="352-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>13 0.75063688 <a title="352-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-07-Question_28_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1371 andrew gelman stats-2012-06-07-Question 28 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>14 0.74372232 <a title="352-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<p>15 0.7351144 <a title="352-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>16 0.73216248 <a title="352-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-28-Bayesian_nonparametric_weighted_sampling_inference.html">2351 andrew gelman stats-2014-05-28-Bayesian nonparametric weighted sampling inference</a></p>
<p>17 0.73206353 <a title="352-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-18-Check_your_missing-data_imputations_using_cross-validation.html">1218 andrew gelman stats-2012-03-18-Check your missing-data imputations using cross-validation</a></p>
<p>18 0.72665292 <a title="352-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-14-Question_4_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1320 andrew gelman stats-2012-05-14-Question 4 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>19 0.72058666 <a title="352-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-10-Combining_data_from_many_sources.html">948 andrew gelman stats-2011-10-10-Combining data from many sources</a></p>
<p>20 0.71429098 <a title="352-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-21-People_kept_emailing_me_this_one_so_I_think_I_have_to_blog_something.html">725 andrew gelman stats-2011-05-21-People kept emailing me this one so I think I have to blog something</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.21), (15, 0.019), (16, 0.069), (24, 0.104), (29, 0.028), (35, 0.01), (36, 0.018), (86, 0.022), (99, 0.401)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99064136 <a title="352-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-23-Speaking_frankly.html">1508 andrew gelman stats-2012-09-23-Speaking frankly</a></p>
<p>Introduction: Even within the realm of writing-about-statistics, there are things I can say in a blog that are much more difficult to include in an academic article.  Blogging gives me freedom.
 
But I want to distinguish between two different sorts of frankness.
 
1.  Obnoxiousness:  In a blog I can write, “I hate X” as rudely as I’d like without needing to justify myself.
 
2.  Openness:  In a blog I can write about the limitations of my work.  It’s a real challenge to discuss limitations in a scholarly article, as we’re always looking over our shoulder at what referees might think.  Sure, sometimes I can get away with  writing  “Survey weighting is a mess,” but my impression is that most scholarly articles are relentlessly upbeat.  Sort of like how a magazine article typically will have a theme and just plug it over and over.  In a blog we can more easily admit uncertainty.
 
Overall, I think blogs are more celebrated for feature 1 above (the freedom to say what you  really  feel, to be rude, par</p><p>2 0.98843086 <a title="352-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-05-Taking_philosophical_arguments_literally.html">17 andrew gelman stats-2010-05-05-Taking philosophical arguments literally</a></p>
<p>Introduction: Aaron Swartz  writes  the following, as a lead-in to an argument in favor of vegetarianism:
  
 
Imagine you were an early settler of what is now the United States. It seems likely you would have killed native Americans. After all, your parents killed them, your siblings killed them, your friends killed them, the leaders of the community killed them, the President killed them. Chances are, you would have killed them too . . .


Or if you see nothing wrong with killing native Americans, take the example of slavery. Again, everyone had slaves and probably didn’t think too much about the morality of it. . . .
 

 
Are these statements true, though?  It’s hard for me to believe that most early settlers (from the context, it looks like Swartz is discussing the 1500s-1700s here) killed native Americans.  That is, if N is the number of early settlers, and Y is the number of these settlers who killed at least one Indian, I suspect Y/N is much closer to 0 than to 1.  Similarly, it’s not even cl</p><p>3 0.98773587 <a title="352-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-11-Folic_acid_and_autism.html">1893 andrew gelman stats-2013-06-11-Folic acid and autism</a></p>
<p>Introduction: Aurelian Muntean writes:
  
I have read an  article  on NPR and the  journal article  that spun this news.  


What draw my attention was the discussion in terms of causation implied by one of the authors of the article interviewed in the NPR news, and also by the conclusions of the article itself claiming large effects.


Although the total sample (self-selecting pregnant women) seems very large (85,176) the subsamples (270 out of which 114 were in the sub-subsample revealing statistically significant association) used to support the analysis seem to be too small. Or not?
  
My response:
 
The different sources of information do seem to be in some conflict:
 
- The JAMA article reports the autism rate of 1 per 1000 for children of mothers taking folic acid and 2 per 1000 for children of mothers not taking folic acid.  (They also report the adjusted odds ratio as 0.6 rather than 0.5, indicted that the two groups differ a bit in some background variables.)
 
- The NPR article has this q</p><p>4 0.98449612 <a title="352-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-28-Those_darn_physicists.html">1189 andrew gelman stats-2012-02-28-Those darn physicists</a></p>
<p>Introduction: X pointed me to  this  atrocity:
  
The data on obesity are pretty unequivocal: we’re fat, and we’re getting fatter. Explanations for this trend, however, vary widely, with the blame alternately pinned on individual behaviour, genetics and the environment. In other words, it’s a race between “we eat too much”, “we’re born that way” and “it’s society’s fault”. 
Now, research by Lazaros Gallos has come down strongly in favour of the third option. Gallos and his colleagues at City College of New York treated the obesity rates in some 3000 US counties as “particles” in a physical system, and calculated the correlation between pairs of “particles” as a function of the distance between them. . . . the data indicated that the size of the “obesity cities” – geographic regions with correlated obesity rates – was huge, up to 1000 km. . . .
  
Just to be clear:  I have no problem with people calculating spatial autocorrelations (or even with them using quaint terminology such as referring to coun</p><p>5 0.98352182 <a title="352-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-27-More_spam%21.html">1872 andrew gelman stats-2013-05-27-More spam!</a></p>
<p>Introduction: I just got this one today: 
  
  
Dear Dr. Gelman,


I am pleased to inform you that the ** team has identified your recent publication, “Philosophy and the practice of Bayesian statistics.” as being of special interest to the progress in the Psychology field. We would like to list your publication on our next edition of the ** series.


** alerts the scientific community to breaking journal articles considered to represent the best in Psychology research. For today’s edition, click here. ** is viewed almost 40,000 times each month and has an audience of academic and clinical personnel from a growing number of the top 20 major academic institutions.


Publications featured by ** gain extensive exposure. This exposure may benefit you and your organization since this provides a showcase for key research studies such as yours. This exposure has the added benefit of encouraging additional funding.


There is a small processing charge for listing publications on ** ($35). Please let us know</p><p>6 0.97993124 <a title="352-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-01-Needed%3A__A_Billionaire_Candidate_for_President_Who_Shares_the_Views_of_a_Washington_Post_Columnist.html">885 andrew gelman stats-2011-09-01-Needed:  A Billionaire Candidate for President Who Shares the Views of a Washington Post Columnist</a></p>
<p>7 0.97616637 <a title="352-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-09-The_effects_of_fiscal_consolidation.html">1663 andrew gelman stats-2013-01-09-The effects of fiscal consolidation</a></p>
<p>8 0.97599107 <a title="352-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-07-Election_reports.html">1567 andrew gelman stats-2012-11-07-Election reports</a></p>
<p>9 0.97366655 <a title="352-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-18-Economic_Disparities_and_Life_Satisfaction_in_European_Regions.html">97 andrew gelman stats-2010-06-18-Economic Disparities and Life Satisfaction in European Regions</a></p>
<p>10 0.97151029 <a title="352-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-18-Lack_of_complete_overlap.html">1017 andrew gelman stats-2011-11-18-Lack of complete overlap</a></p>
<p>11 0.96883023 <a title="352-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-24-Too_Good_To_Be_True%3A__The_Scientific_Mass_Production_of_Spurious_Statistical_Significance.html">1954 andrew gelman stats-2013-07-24-Too Good To Be True:  The Scientific Mass Production of Spurious Statistical Significance</a></p>
<p>12 0.96846831 <a title="352-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-11-Hunger_Games_survival_analysis.html">1260 andrew gelman stats-2012-04-11-Hunger Games survival analysis</a></p>
<p>13 0.96393883 <a title="352-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-01-%E2%80%9CRoughly_90%25_of_the_increase_in_._._.%E2%80%9D__Hey%2C_wait_a_minute%21.html">549 andrew gelman stats-2011-02-01-“Roughly 90% of the increase in . . .”  Hey, wait a minute!</a></p>
<p>14 0.96245724 <a title="352-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-09-In_the_future%2C_everyone_will_publish_everything..html">1254 andrew gelman stats-2012-04-09-In the future, everyone will publish everything.</a></p>
<p>same-blog 15 0.95655948 <a title="352-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-19-Analysis_of_survey_data%3A_Design_based_models_vs._hierarchical_modeling%3F.html">352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</a></p>
<p>16 0.95091838 <a title="352-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>17 0.95070976 <a title="352-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-28-Brow_inflation.html">489 andrew gelman stats-2010-12-28-Brow inflation</a></p>
<p>18 0.94449037 <a title="352-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-11-Update_on_the_spam_email_study.html">27 andrew gelman stats-2010-05-11-Update on the spam email study</a></p>
<p>19 0.9406786 <a title="352-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-16-How_much_can_we_learn_about_individual-level_causal_claims_from_state-level_correlations%3F.html">2336 andrew gelman stats-2014-05-16-How much can we learn about individual-level causal claims from state-level correlations?</a></p>
<p>20 0.93384993 <a title="352-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-16-%E2%80%9CFalse-positive_psychology%E2%80%9D.html">1171 andrew gelman stats-2012-02-16-“False-positive psychology”</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
