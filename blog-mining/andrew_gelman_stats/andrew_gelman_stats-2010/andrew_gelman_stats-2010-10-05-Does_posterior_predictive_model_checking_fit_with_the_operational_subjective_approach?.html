<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-320" href="#">andrew_gelman_stats-2010-320</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-320-html" href="http://andrewgelman.com/2010/10/05/do_posterior_pr/">html</a></p><p>Introduction: David Rohde writes:
  
 
I have been thinking a lot lately about your Bayesian model checking approach.  This is in part because I have been working on exploratory data analysis and wishing to avoid controversy and mathematical statistics we omitted model checking from our discussion.  This is something that the refereeing process picked us up on and we ultimately added a critical discussion of null-hypothesis testing to  our paper .  The exploratory technique we discussed was essentially a 2D histogram approach, but we used Polya models as a formal model for the histogram.  We are currently working on a new paper, and we are thinking through how or if we should do “confirmatory analysis” or model checking in the paper.


What I find most admirable about your statistical work is that you clearly use the Bayesian approach to do useful applied statistical analysis.  My own attempts at applied Bayesian analysis makes me greatly admire your applied successes.  On the other hand it may be t</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 David Rohde writes:      I have been thinking a lot lately about your Bayesian model checking approach. [sent-1, score-0.545]
</p><p>2 This is in part because I have been working on exploratory data analysis and wishing to avoid controversy and mathematical statistics we omitted model checking from our discussion. [sent-2, score-0.744]
</p><p>3 The exploratory technique we discussed was essentially a 2D histogram approach, but we used Polya models as a formal model for the histogram. [sent-4, score-0.459]
</p><p>4 We are currently working on a new paper, and we are thinking through how or if we should do “confirmatory analysis” or model checking in the paper. [sent-5, score-0.545]
</p><p>5 What I find most admirable about your statistical work is that you clearly use the Bayesian approach to do useful applied statistical analysis. [sent-6, score-0.316]
</p><p>6 On the other hand it may be that I am one of those naïve readers of Savage and Lindley that frustrated you in the 80s but it seems to me that your use of model checks, and discussion of “model fit” is a bit awkward from the strict Bayesian / Operational Subjective view point. [sent-8, score-0.291]
</p><p>7 The first makes a concession with frequentism and says that in the long run the histogram of data will not resemble any model within the parameterized family. [sent-11, score-0.615]
</p><p>8 The second says that my (or someone else’s) subjective probabilities are not perfectly reflected in the model-prior combination. [sent-12, score-0.395]
</p><p>9 My understanding of the Bayesian and in particular the operational subjective approach is that emphasis is placed upon conditional or posterior probabilities rather than a model fit. [sent-14, score-1.194]
</p><p>10 The concept of model selection seems to rest on the assumption that if the probability of the data is low conditional on a model is low then the model might be questionable. [sent-17, score-1.056]
</p><p>11 The analysis is more convincing if the analyst goes through real angst in specifying P(y^{rep},y) in particular by thinking about marginal distributions P(y^{rep},y) and maybe even checking if estimators that you expect to work roughly correspond with P(y^{rep}|y). [sent-21, score-0.701]
</p><p>12 we are checking if it is coherent to believe that some (perhapse many) samples of marginilizations of P(y^{rep}|y) should resemble marginilzations of y. [sent-25, score-0.45]
</p><p>13 As mentioned above, my interest in the operational subjective view of probability theory isn’t always useful in trying to do applied statistics. [sent-26, score-1.03]
</p><p>14 I am really interested if you distinguish your practical statistical thinking from the operational subjective approach. [sent-28, score-0.983]
</p><p>15 When you talk about model checking and your admiration for Popper it seems possible that you might. [sent-29, score-0.416]
</p><p>16 ” David Lane’s  review  of Frank Lad’s operational subjective statistical methods. [sent-31, score-0.797]
</p><p>17 I don’t quite get your point about an analysis being “more convincing if the analyst goes through real angst. [sent-42, score-0.282]
</p><p>18 I prefer thinking of model checks rather than trying to decide if you’re checking the prior or the likelihood. [sent-46, score-0.622]
</p><p>19 As I’ve written in various places, I don’t like thinking in terms of subjective probability. [sent-49, score-0.463]
</p><p>20 All of statistics is subjective, in the sense that choices have to be made in deciding what models to consider and what data to analyze, but I don’t see Bayesian inference as any more subjective than classical inference. [sent-50, score-0.597]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('operational', 0.404), ('rep', 0.353), ('subjective', 0.334), ('model', 0.217), ('checking', 0.199), ('analyst', 0.13), ('thinking', 0.129), ('resemble', 0.115), ('bayesian', 0.111), ('histogram', 0.095), ('estimators', 0.091), ('applied', 0.082), ('universal', 0.08), ('analysis', 0.079), ('probability', 0.078), ('checks', 0.077), ('models', 0.077), ('low', 0.074), ('view', 0.074), ('convincing', 0.073), ('coherent', 0.073), ('logical', 0.073), ('exploratory', 0.07), ('na', 0.068), ('david', 0.067), ('data', 0.066), ('samples', 0.063), ('choices', 0.063), ('upon', 0.063), ('probabilities', 0.061), ('polya', 0.061), ('frequentism', 0.061), ('concession', 0.061), ('protested', 0.061), ('reliant', 0.061), ('subjectivism', 0.061), ('statistical', 0.059), ('approach', 0.058), ('useful', 0.058), ('depart', 0.058), ('dilemmas', 0.058), ('optimality', 0.058), ('wishing', 0.058), ('conditional', 0.057), ('practical', 0.057), ('classical', 0.057), ('selection', 0.056), ('mathematical', 0.055), ('compromises', 0.055), ('refereeing', 0.055)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="320-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>Introduction: David Rohde writes:
  
 
I have been thinking a lot lately about your Bayesian model checking approach.  This is in part because I have been working on exploratory data analysis and wishing to avoid controversy and mathematical statistics we omitted model checking from our discussion.  This is something that the refereeing process picked us up on and we ultimately added a critical discussion of null-hypothesis testing to  our paper .  The exploratory technique we discussed was essentially a 2D histogram approach, but we used Polya models as a formal model for the histogram.  We are currently working on a new paper, and we are thinking through how or if we should do “confirmatory analysis” or model checking in the paper.


What I find most admirable about your statistical work is that you clearly use the Bayesian approach to do useful applied statistical analysis.  My own attempts at applied Bayesian analysis makes me greatly admire your applied successes.  On the other hand it may be t</p><p>2 0.25120941 <a title="320-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>Introduction: I’ve been writing a lot about my philosophy of Bayesian statistics and how it fits into Popper’s ideas about falsification and Kuhn’s ideas about scientific revolutions.
 
 Here’s  my long, somewhat technical paper with Cosma Shalizi. 
 Here’s  our shorter overview for the volume on the philosophy of social science. 
 Here’s  my latest try (for an online symposium), focusing on the key issues.
 
I’m pretty happy with my approach–the familiar idea that Bayesian data analysis iterates the three steps of model building, inference, and model checking–but it does have some unresolved (maybe unresolvable) problems.  Here are a couple mentioned in the third of the above links.
 
Consider a simple model with independent data y_1, y_2, .., y_10 ~ N(θ,σ^2), with a prior distribution θ ~ N(0,10^2) and σ known and taking on some value of approximately 10. Inference about μ is straightforward, as is model checking, whether based on graphs or numerical summaries such as the sample variance and skewn</p><p>3 0.22388805 <a title="320-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>Introduction: Konrad Scheffler writes:
  
I was interested by your  paper  “Induction and deduction in Bayesian data analysis” and was wondering if you would entertain a few questions:
  
  
  
 – Under the banner of objective Bayesianism, I would posit something like this as a description of Bayesian inference:


“Objective Bayesian probability is not a degree of belief (which would necessarily be subjective) but a measure of the plausibility of a hypothesis, conditional on a formally specified information state. One way of specifying a formal information state is to specify a model, which involves specifying both a prior distribution (typically for a set of unobserved variables) and a likelihood function (typically for a set of observed variables, conditioned on the values of the unobserved variables). Bayesian inference involves calculating the objective degree of plausibility of a hypothesis (typically the truth value of the hypothesis is a function of the variables mentioned above) given such a</p><p>4 0.22326781 <a title="320-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-05-What_is_a_prior_distribution%3F.html">1155 andrew gelman stats-2012-02-05-What is a prior distribution?</a></p>
<p>Introduction: Some recent blog discussion revealed some confusion that I’ll try to resolve here.
 
I  wrote  that I’m not a big fan of subjective priors.  Various commenters had difficulty with this point, and I think the issue was most clearly stated by Bill Jeff re erys, who  wrote :
  
It seems to me that your prior has to reflect your subjective information before you look at the data. How can it not?


But this does not mean that the (subjective) prior that you choose is irrefutable; Surely a prior that reflects prior information just does not have to be inconsistent with that information. But that still leaves a range of priors that are consistent with it, the sort of priors that one would use in a sensitivity analysis, for example.
  
I think I see what Bill is getting at.  A prior represents your subjective belief, or some approximation to your subjective belief, even if it’s not perfect.  That sounds reasonable but I don’t think it works.  Or, at least, it often doesn’t work.
 
Let’s start</p><p>5 0.22219865 <a title="320-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>Introduction: Prasanta Bandyopadhyay and Gordon Brittan  write :
  
We introduce a distinction, unnoticed in the literature, between four varieties of objective Bayesianism. What we call ‘strong objective Bayesianism’ is characterized by two claims, that all scientific inference is ‘logical’ and that, given the same background information two agents will ascribe a unique probability to their priors. We think that neither of these claims can be sustained; in this sense, they are ‘dogmatic’. The first fails to recognize that some scientific inference, in particular that concerning evidential relations, is not (in the appropriate sense) logical, the second fails to provide a non-question-begging account of ‘same background information’. We urge that a suitably objective Bayesian account of scientific inference does not require either of the claims. Finally, we argue that Bayesianism needs to be fine-grained in the same way that Bayesians fine-grain their beliefs.
  
I have not read their paper in detai</p><p>6 0.20155492 <a title="320-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>7 0.19833022 <a title="320-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>8 0.19828033 <a title="320-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>9 0.19732957 <a title="320-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>10 0.19069862 <a title="320-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-25-Incoherence_of_Bayesian_data_analysis.html">1510 andrew gelman stats-2012-09-25-Incoherence of Bayesian data analysis</a></p>
<p>11 0.18494409 <a title="320-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-03-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Senn.html">1151 andrew gelman stats-2012-02-03-Philosophy of Bayesian statistics:  my reactions to Senn</a></p>
<p>12 0.18459964 <a title="320-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>13 0.18451029 <a title="320-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<p>14 0.18353087 <a title="320-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>15 0.17744941 <a title="320-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>16 0.1724433 <a title="320-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>17 0.16524178 <a title="320-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-Rob_Kass_on_statistical_pragmatism%2C_and_my_reactions.html">317 andrew gelman stats-2010-10-04-Rob Kass on statistical pragmatism, and my reactions</a></p>
<p>18 0.16417155 <a title="320-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<p>19 0.16280705 <a title="320-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>20 0.16155145 <a title="320-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.273), (1, 0.211), (2, -0.067), (3, 0.073), (4, -0.097), (5, -0.014), (6, -0.038), (7, 0.053), (8, 0.074), (9, -0.001), (10, -0.003), (11, 0.019), (12, -0.07), (13, 0.0), (14, -0.061), (15, 0.009), (16, 0.051), (17, -0.006), (18, -0.001), (19, 0.017), (20, -0.01), (21, -0.026), (22, -0.033), (23, -0.034), (24, -0.055), (25, 0.021), (26, 0.002), (27, -0.007), (28, -0.015), (29, -0.009), (30, -0.008), (31, -0.012), (32, 0.008), (33, 0.023), (34, -0.015), (35, 0.032), (36, -0.003), (37, -0.017), (38, -0.012), (39, 0.005), (40, 0.01), (41, -0.036), (42, 0.012), (43, 0.017), (44, 0.025), (45, -0.016), (46, -0.049), (47, -0.021), (48, -0.026), (49, -0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98016983 <a title="320-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>Introduction: David Rohde writes:
  
 
I have been thinking a lot lately about your Bayesian model checking approach.  This is in part because I have been working on exploratory data analysis and wishing to avoid controversy and mathematical statistics we omitted model checking from our discussion.  This is something that the refereeing process picked us up on and we ultimately added a critical discussion of null-hypothesis testing to  our paper .  The exploratory technique we discussed was essentially a 2D histogram approach, but we used Polya models as a formal model for the histogram.  We are currently working on a new paper, and we are thinking through how or if we should do “confirmatory analysis” or model checking in the paper.


What I find most admirable about your statistical work is that you clearly use the Bayesian approach to do useful applied statistical analysis.  My own attempts at applied Bayesian analysis makes me greatly admire your applied successes.  On the other hand it may be t</p><p>2 0.94319409 <a title="320-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>Introduction: Astrophysicist Andrew Jaffe pointed me to  this and discussion  of my  philosophy  of statistics (which is, in turn, my rational reconstruction of the statistical practice of Bayesians such as Rubin and Jaynes).  Jaffe’s summary is fair enough and I only disagree in a few points: 
   
1.  Jaffe writes:
  
Subjective probability, at least the way it is actually used by practicing scientists, is a sort of “as-if” subjectivity — how would an agent reason if her beliefs were reflected in a certain set of probability distributions? This is why when I discuss probability I try to make the pedantic point that all probabilities are conditional, at least on some background prior information or context.
  
I agree, and my problem with the usual procedures used for Bayesian model comparison and Bayesian model averaging is not that these approaches are subjective but that the particular models being considered don’t make sense.  I’m thinking of the sorts of models that say the truth is either A or</p><p>3 0.94046015 <a title="320-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>Introduction: I’ve been writing a lot about my philosophy of Bayesian statistics and how it fits into Popper’s ideas about falsification and Kuhn’s ideas about scientific revolutions.
 
 Here’s  my long, somewhat technical paper with Cosma Shalizi. 
 Here’s  our shorter overview for the volume on the philosophy of social science. 
 Here’s  my latest try (for an online symposium), focusing on the key issues.
 
I’m pretty happy with my approach–the familiar idea that Bayesian data analysis iterates the three steps of model building, inference, and model checking–but it does have some unresolved (maybe unresolvable) problems.  Here are a couple mentioned in the third of the above links.
 
Consider a simple model with independent data y_1, y_2, .., y_10 ~ N(θ,σ^2), with a prior distribution θ ~ N(0,10^2) and σ known and taking on some value of approximately 10. Inference about μ is straightforward, as is model checking, whether based on graphs or numerical summaries such as the sample variance and skewn</p><p>4 0.92756867 <a title="320-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>Introduction: In response to  this article  by Cosma Shalizi and myself on the philosophy of Bayesian statistics, David Hogg writes:
  
I [Hogg] agree–even in physics and astronomy–that the models are not “True” in the God-like sense of being absolute reality (that is, I am not a realist); and I  have argued  (a philosophically very naive 
paper, but hey, I was new to all this) that for pretty fundamental reasons we could never arrive at the True (with a capital “T”) model of the Universe.  The goal of inference is to find the “best” model, where “best” might have something to do with prediction, or explanation, or message length, or (horror!) our utility.  Needless to say, most of my physics friends *are* realists, even in the face of “effective theories” as Newtonian mechanics is an effective theory of GR and GR is an effective theory of “quantum gravity” (this plays to your point, because if you think any theory is possibly an effective theory, how could you ever find Truth?).  I also liked the i</p><p>5 0.91981071 <a title="320-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-25-Incoherence_of_Bayesian_data_analysis.html">1510 andrew gelman stats-2012-09-25-Incoherence of Bayesian data analysis</a></p>
<p>Introduction: Hogg writes:
  
At the end  this article  you wonder about consistency.  Have you ever considered the possibility that utility might resolve some of the problems?  I have no idea if it 
would—I am not advocating that position—I just get some kind of intuition from phrases like “Judgment is required to decide…”. Perhaps there is a coherent and objective description of what is—or could be—done under a coherent “utility” model (like a utility that could be objectively agreed upon and computed).  Utilities are usually subjective—true—but priors are usually subjective too.
  
My reply:
 
I’m happy to think about utility, for some particular problem or class of problems going to the effort of assigning costs and benefits to different outcomes.  I agree that a utility analysis, even if (necessarily) imperfect, can usefully focus discussion.  For example, if a statistical method for selecting variables is justified on the basis of cost, I like the idea of attempting to quantify the costs of ga</p><p>6 0.91849524 <a title="320-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>7 0.91308564 <a title="320-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>8 0.90778416 <a title="320-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>9 0.90133417 <a title="320-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<p>10 0.90098011 <a title="320-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>11 0.87945116 <a title="320-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>12 0.87915802 <a title="320-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>13 0.87298417 <a title="320-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-15-Wacky_priors_can_work_well%3F.html">1723 andrew gelman stats-2013-02-15-Wacky priors can work well?</a></p>
<p>14 0.8726247 <a title="320-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>15 0.86994392 <a title="320-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-Rob_Kass_on_statistical_pragmatism%2C_and_my_reactions.html">317 andrew gelman stats-2010-10-04-Rob Kass on statistical pragmatism, and my reactions</a></p>
<p>16 0.86815584 <a title="320-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>17 0.86738372 <a title="320-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<p>18 0.86573845 <a title="320-lsi-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-22-Spell-checking_example_demonstrates_key_aspects_of_Bayesian_data_analysis.html">2182 andrew gelman stats-2014-01-22-Spell-checking example demonstrates key aspects of Bayesian data analysis</a></p>
<p>19 0.86419201 <a title="320-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>20 0.86242521 <a title="320-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Valencia%3A___Summer_of_1991.html">72 andrew gelman stats-2010-06-07-Valencia:   Summer of 1991</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.039), (16, 0.088), (24, 0.161), (45, 0.018), (51, 0.015), (55, 0.02), (56, 0.011), (63, 0.021), (73, 0.091), (86, 0.035), (88, 0.016), (95, 0.011), (99, 0.3)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97544193 <a title="320-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-04-PyStan%21.html">1748 andrew gelman stats-2013-03-04-PyStan!</a></p>
<p>Introduction: Stan  is written in C++ and can be run from the command line and from R.  We’d like for  Python  users to be able to run Stan as well.  If anyone is interested in doing this, please let us know and we’d be happy to work with you on it.
 
Stan, like Python, is completely free and open-source.
 
P.S.  Because Stan is open-source, it of course would also be possible for people to translate Stan into Python, or to take whatever features they like from Stan and incorporate them into a Python package.  That’s fine too.  But we think it would make sense in addition for users to be able to run Stan directly from Python, in the same way that it can be run from R.</p><p>same-blog 2 0.9718917 <a title="320-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>Introduction: David Rohde writes:
  
 
I have been thinking a lot lately about your Bayesian model checking approach.  This is in part because I have been working on exploratory data analysis and wishing to avoid controversy and mathematical statistics we omitted model checking from our discussion.  This is something that the refereeing process picked us up on and we ultimately added a critical discussion of null-hypothesis testing to  our paper .  The exploratory technique we discussed was essentially a 2D histogram approach, but we used Polya models as a formal model for the histogram.  We are currently working on a new paper, and we are thinking through how or if we should do “confirmatory analysis” or model checking in the paper.


What I find most admirable about your statistical work is that you clearly use the Bayesian approach to do useful applied statistical analysis.  My own attempts at applied Bayesian analysis makes me greatly admire your applied successes.  On the other hand it may be t</p><p>3 0.97071505 <a title="320-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-09-The_quest_for_the_holy_graph.html">794 andrew gelman stats-2011-07-09-The quest for the holy graph</a></p>
<p>Introduction: Eytan Adar writes:
  
I was just going through the latest draft of  your paper with Anthony Unwin . I heard part of it at  the talk  you gave (remotely) here at UMich.  I’m curious about your discussion of the  Baby Name Voyager .


The tool in itself is simple, attractive, and useful.  No argument from me there.  It’s an awesome demonstration of how subtle interactions can be very helpful (click and it zooms, type and it filters… falls perfectly into the Shneiderman visualization mantra). It satisfies a very common use case: finding appropriate names for children.


That said, I can’t help but feeling that what you are really excited about is  the very static analysis on last letters  (you spend most of your time on this).  This analysis, incidentally, is not possible to infer from the interactive application (which doesn’t support this type of filtering and pivoting).  In a sense, the two visualizations don’t have anything to do with each other (other than a shared context/dataset).</p><p>4 0.96833843 <a title="320-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-27-Should_Mister_P_be_allowed-encouraged_to_reside_in_counter-factual_populations%3F.html">7 andrew gelman stats-2010-04-27-Should Mister P be allowed-encouraged to reside in counter-factual populations?</a></p>
<p>Introduction: Lets say you are repeatedly going to recieve unselected sets of well done RCTs on various say medical treatments.
 
One reasonable assumption with all of these treatments is that they are monotonic – either helpful or harmful for all. The treatment effect will (as always) vary for subgroups in the population – these will not be explicitly identified in the studies – but each study very likely will enroll different percentages of the variuos patient subgroups. Being all randomized studies these subgroups will be balanced in the treatment versus control arms – but each study will (as always) be estimating a different – but exchangeable – treatment effect (Exhangeable due to the ignorance about the subgroup memberships of the enrolled patients.) 
 
That reasonable assumption – monotonicity – will be to some extent (as always) wrong, but given that it is a risk believed well worth taking – if the average effect in any population is positive (versus negative) the average effect in any other</p><p>5 0.96304286 <a title="320-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-12-Sometimes_a_graph_really_is_just_ugly.html">798 andrew gelman stats-2011-07-12-Sometimes a graph really is just ugly</a></p>
<p>Introduction: I’ve been talking a lot about how different graphical presentations serve different goals, and how we should avoid being so judgmental about graphs.  Instead of saying that a particular data visualization is bad, we should think about what goal it serves.
 
That’s all well and good, but sometimes a graph really is bad.
 
Let me draw an analogy to the popular media.  Books and videogames serve different goals.  I’m a reader and writer of books and have very little interest in videogames, but it would be silly for me to criticize a videogame on the grounds that it’s a bad book (or, for that matter, to criticize a book because it doesn’t yield a satisfying game-playing experience).  But . . . there are bad books and there are bad videogames.
 
To restrict our scope to books for a moment:  you could argue that Mickey Spillane’s books are terrible or you could argue that, given that they sold tens of millions of copies, they must have had something going for them.  I wouldn’t want to charac</p><p>6 0.95580828 <a title="320-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-02-Should_personal_genetic_testing_be_regulated%3F__Battle_of_the_blogroll.html">2121 andrew gelman stats-2013-12-02-Should personal genetic testing be regulated?  Battle of the blogroll</a></p>
<p>7 0.95560455 <a title="320-lda-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>8 0.95547783 <a title="320-lda-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-%E2%80%9CThe_British_amateur_who_debunked_the_mathematics_of_happiness%E2%80%9D.html">2177 andrew gelman stats-2014-01-19-“The British amateur who debunked the mathematics of happiness”</a></p>
<p>9 0.95488131 <a title="320-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-13-What_are_the_important_issues_in_ethics_and_statistics%3F__I%E2%80%99m_looking_for_your_input%21.html">1117 andrew gelman stats-2012-01-13-What are the important issues in ethics and statistics?  I’m looking for your input!</a></p>
<p>10 0.95421666 <a title="320-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>11 0.95396221 <a title="320-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-03-Statistical_methods_that_work_in_some_settings_but_not_others.html">1560 andrew gelman stats-2012-11-03-Statistical methods that work in some settings but not others</a></p>
<p>12 0.95395744 <a title="320-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>13 0.95389271 <a title="320-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>14 0.95343763 <a title="320-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>15 0.95265442 <a title="320-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-03-Reinventing_the_wheel%2C_only_more_so..html">447 andrew gelman stats-2010-12-03-Reinventing the wheel, only more so.</a></p>
<p>16 0.95251626 <a title="320-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-06-Early_stopping_and_penalized_likelihood.html">788 andrew gelman stats-2011-07-06-Early stopping and penalized likelihood</a></p>
<p>17 0.95230627 <a title="320-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-26-Difficulties_in_making_inferences_about_scientific_truth_from_distributions_of_published_p-values.html">2040 andrew gelman stats-2013-09-26-Difficulties in making inferences about scientific truth from distributions of published p-values</a></p>
<p>18 0.95223153 <a title="320-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-08-Software_is_as_software_does.html">1661 andrew gelman stats-2013-01-08-Software is as software does</a></p>
<p>19 0.95214212 <a title="320-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-18-Check_your_missing-data_imputations_using_cross-validation.html">1218 andrew gelman stats-2012-03-18-Check your missing-data imputations using cross-validation</a></p>
<p>20 0.95213127 <a title="320-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-02-Moving_beyond_hopeless_graphics.html">1403 andrew gelman stats-2012-07-02-Moving beyond hopeless graphics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
