<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>14 andrew gelman stats-2010-05-01-Imputing count data</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-14" href="#">andrew_gelman_stats-2010-14</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>14 andrew gelman stats-2010-05-01-Imputing count data</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-14-html" href="http://andrewgelman.com/2010/05/01/imputing_count/">html</a></p><p>Introduction: Guy asks:
  
I am analyzing an original survey of farmers in Uganda. I am hoping to use a battery of welfare proxy variables to create a single welfare index using PCA. I have quick question which I hope you can find time to address:


How do you recommend treating count data? (for example # of rooms, # of chickens, # of cows, # of radios)? In my dataset these variables are highly skewed with many responses at zero (which makes taking the natural log problematic). In the case of # of cows or chickens several obs have values in the hundreds.
  
My response:  Hereâ&euro;&trade;s what we do in our mi package in R.  We split a variable into two parts:  an indicator for whether it is positive, and the positive part.  That is, y = u*v.  Then u is binary and can be modeled using logisitc regression, and v can be modeled on the log scale.  At the end you can round to the nearest integer  if you want to avoid fractional values.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Guy asks:    I am analyzing an original survey of farmers in Uganda. [sent-1, score-0.39]
</p><p>2 I am hoping to use a battery of welfare proxy variables to create a single welfare index using PCA. [sent-2, score-1.398]
</p><p>3 I have quick question which I hope you can find time to address:   How do you recommend treating count data? [sent-3, score-0.465]
</p><p>4 In my dataset these variables are highly skewed with many responses at zero (which makes taking the natural log problematic). [sent-5, score-0.98]
</p><p>5 In the case of # of cows or chickens several obs have values in the hundreds. [sent-6, score-0.975]
</p><p>6 My response:  Hereâ&euro;&trade;s what we do in our mi package in R. [sent-7, score-0.244]
</p><p>7 We split a variable into two parts:  an indicator for whether it is positive, and the positive part. [sent-8, score-0.465]
</p><p>8 Then u is binary and can be modeled using logisitc regression, and v can be modeled on the log scale. [sent-10, score-0.863]
</p><p>9 At the end you can round to the nearest integer  if you want to avoid fractional values. [sent-11, score-0.755]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cows', 0.331), ('chickens', 0.319), ('welfare', 0.248), ('modeled', 0.234), ('log', 0.216), ('battery', 0.183), ('integer', 0.183), ('obs', 0.173), ('rooms', 0.173), ('farmers', 0.16), ('values', 0.152), ('fractional', 0.151), ('mi', 0.148), ('nearest', 0.148), ('positive', 0.144), ('proxy', 0.142), ('skewed', 0.142), ('treating', 0.137), ('variables', 0.134), ('problematic', 0.131), ('indicator', 0.127), ('round', 0.127), ('split', 0.119), ('index', 0.109), ('binary', 0.103), ('hoping', 0.103), ('count', 0.102), ('analyzing', 0.1), ('responses', 0.098), ('package', 0.096), ('dataset', 0.095), ('address', 0.095), ('parts', 0.093), ('asks', 0.089), ('create', 0.088), ('avoid', 0.084), ('recommend', 0.08), ('highly', 0.08), ('using', 0.076), ('natural', 0.076), ('quick', 0.075), ('variable', 0.075), ('guy', 0.074), ('zero', 0.073), ('hope', 0.071), ('single', 0.067), ('original', 0.066), ('taking', 0.066), ('survey', 0.064), ('end', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="14-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<p>Introduction: Guy asks:
  
I am analyzing an original survey of farmers in Uganda. I am hoping to use a battery of welfare proxy variables to create a single welfare index using PCA. I have quick question which I hope you can find time to address:


How do you recommend treating count data? (for example # of rooms, # of chickens, # of cows, # of radios)? In my dataset these variables are highly skewed with many responses at zero (which makes taking the natural log problematic). In the case of # of cows or chickens several obs have values in the hundreds.
  
My response:  Hereâ&euro;&trade;s what we do in our mi package in R.  We split a variable into two parts:  an indicator for whether it is positive, and the positive part.  That is, y = u*v.  Then u is binary and can be modeled using logisitc regression, and v can be modeled on the log scale.  At the end you can round to the nearest integer  if you want to avoid fractional values.</p><p>2 0.16352396 <a title="14-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-10-Recently_in_the_sister_blog%3A__Brussels_sprouts%2C_ugly_graphs%2C_and_switched_at_birth.html">1664 andrew gelman stats-2013-01-10-Recently in the sister blog:  Brussels sprouts, ugly graphs, and switched at birth</a></p>
<p>Introduction: 1.   Congress vs. Nickelback: The real action is in the cross tabs :  Conservatives are mean, liberals are big babies, and, if supporting an STD is what it takes to be a political moderate, I don’t want to be one.
 
2.   How 2012 stacks up: The worst graph on record? :  OK, not actually worse than  this one .
 
3.   Boys will be boys; cows will be cows :  Children’s essentialist reasoning about gender categories and animal species.</p><p>3 0.16058698 <a title="14-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>Introduction: Steve Miller writes: 
  
  
Much of what I do is cross-national analyses of survey data (largely World Values Survey). . . . My big question pertains to (what I would call) exploratory analysis of multilevel data, especially when the group-level predictors are of theoretical importance. A lot of what I do involves analyzing cross-national survey items of citizen attitudes, typically of political leadership. These survey items are usually yes/no responses, or four-part responses indicating a level of agreement (strongly agree, agree, disagree, strongly disagree) that can be condensed into a binary variable. I believe these can be explained by reference to country-level factors. Much of the group-level variables of interest are count variables with a modal value of 0, which can be quite messy.


How would you recommend exploring the variation in the dependent variable as it could be explained by the group-level count variable of interest, before fitting the multilevel model itself? When</p><p>4 0.12277327 <a title="14-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-19-Index_or_indicator_variables.html">2296 andrew gelman stats-2014-04-19-Index or indicator variables</a></p>
<p>Introduction: Someone who doesn’t want his name shared (for the perhaps reasonable reason that he’ll “one day not be confused, and would rather my confusion not live on online forever”) writes:
  
I’m exploring HLMs and stan, using your book with Jennifer Hill as my field guide to this new territory. I think I have a generally clear grasp on the material, but wanted to be sure I haven’t gone astray. 


The problem in working on involves a multi-nation survey of students, and I’m especially interested in understanding the effects of country, religion, and sex, and the interactions among those factors (using IRT to estimate individual-level ability, then estimating individual, school, and country effects).


Following the basic approach laid out in chapter 13 for such interactions between levels, I think I need to create a matrix of indicator variables for religion and sex. Elsewhere in the book, you recommend against indicator variables in favor of a single index variable. 


Am I right in thinking t</p><p>5 0.092588842 <a title="14-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-18-Check_your_missing-data_imputations_using_cross-validation.html">1218 andrew gelman stats-2012-03-18-Check your missing-data imputations using cross-validation</a></p>
<p>Introduction: Elena Grewal writes:
  
I am currently using the iterative regression imputation model as implemented in the Stata ICE package. I am using data from a survey of about 90,000 students in 142 schools and my variable of interest is parent level of education. I want only this variable to be imputed with as little bias as possible as I am not using any other variable. So I scoured the survey for every variable I thought could possibly predict parent education. The main variable I found is parent occupation, which explains about 35% of the variance in parent education for the students with complete data on both. I then include the 20 other variables I found in the survey in a regression predicting parent education, which explains about 40% of the variance in parent education for students with complete data on all the variables. 


My question is this: many of the other variables I found have more missing values than the parent education variable, and also, although statistically significant</p><p>6 0.086800158 <a title="14-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-10-The_U.S._as_welfare_state.html">196 andrew gelman stats-2010-08-10-The U.S. as welfare state</a></p>
<p>7 0.0866201 <a title="14-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>8 0.085405029 <a title="14-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-18-Standardizing_regression_inputs.html">1462 andrew gelman stats-2012-08-18-Standardizing regression inputs</a></p>
<p>9 0.081640624 <a title="14-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>10 0.080957025 <a title="14-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-31-Statistical_modeling%2C_causal_inference%2C_and_social_science.html">1645 andrew gelman stats-2012-12-31-Statistical modeling, causal inference, and social science</a></p>
<p>11 0.080750018 <a title="14-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>12 0.074595176 <a title="14-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-Another_reason_why_you_can_get_good_inferences_from_a_bad_model.html">1527 andrew gelman stats-2012-10-10-Another reason why you can get good inferences from a bad model</a></p>
<p>13 0.07344088 <a title="14-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-13-Lame_Statistics_Patents.html">1761 andrew gelman stats-2013-03-13-Lame Statistics Patents</a></p>
<p>14 0.071824625 <a title="14-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-R_package_for_Bayes_factors.html">1682 andrew gelman stats-2013-01-19-R package for Bayes factors</a></p>
<p>15 0.070805982 <a title="14-tfidf-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-Transformations_for_non-normal_data.html">2176 andrew gelman stats-2014-01-19-Transformations for non-normal data</a></p>
<p>16 0.068867758 <a title="14-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-05-What_do_practitioners_need_to_know_about_regression%3F.html">451 andrew gelman stats-2010-12-05-What do practitioners need to know about regression?</a></p>
<p>17 0.067582369 <a title="14-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-Difficulties_with_the_1-4-power_transformation.html">1142 andrew gelman stats-2012-01-29-Difficulties with the 1-4-power transformation</a></p>
<p>18 0.067078784 <a title="14-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-25-Continuous_variables_in_Bayesian_networks.html">1228 andrew gelman stats-2012-03-25-Continuous variables in Bayesian networks</a></p>
<p>19 0.064061947 <a title="14-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-14-On_deck_this_week.html">2290 andrew gelman stats-2014-04-14-On deck this week</a></p>
<p>20 0.063629277 <a title="14-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Lessons_learned_from_a_recent_R_package_submission.html">1134 andrew gelman stats-2012-01-21-Lessons learned from a recent R package submission</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.095), (1, 0.041), (2, 0.061), (3, -0.029), (4, 0.077), (5, 0.029), (6, 0.004), (7, -0.028), (8, 0.045), (9, 0.023), (10, 0.015), (11, -0.013), (12, 0.011), (13, 0.001), (14, 0.019), (15, 0.009), (16, -0.004), (17, -0.001), (18, 0.021), (19, -0.02), (20, -0.003), (21, 0.037), (22, 0.013), (23, 0.001), (24, -0.005), (25, 0.011), (26, 0.038), (27, -0.027), (28, 0.025), (29, 0.001), (30, 0.026), (31, 0.047), (32, 0.028), (33, 0.038), (34, -0.014), (35, -0.045), (36, -0.001), (37, 0.05), (38, -0.031), (39, -0.0), (40, -0.013), (41, -0.013), (42, 0.041), (43, 0.005), (44, 0.002), (45, 0.032), (46, 0.018), (47, 0.025), (48, 0.015), (49, 0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97625554 <a title="14-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<p>Introduction: Guy asks:
  
I am analyzing an original survey of farmers in Uganda. I am hoping to use a battery of welfare proxy variables to create a single welfare index using PCA. I have quick question which I hope you can find time to address:


How do you recommend treating count data? (for example # of rooms, # of chickens, # of cows, # of radios)? In my dataset these variables are highly skewed with many responses at zero (which makes taking the natural log problematic). In the case of # of cows or chickens several obs have values in the hundreds.
  
My response:  Hereâ&euro;&trade;s what we do in our mi package in R.  We split a variable into two parts:  an indicator for whether it is positive, and the positive part.  That is, y = u*v.  Then u is binary and can be modeled using logisitc regression, and v can be modeled on the log scale.  At the end you can round to the nearest integer  if you want to avoid fractional values.</p><p>2 0.83057922 <a title="14-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-18-Check_your_missing-data_imputations_using_cross-validation.html">1218 andrew gelman stats-2012-03-18-Check your missing-data imputations using cross-validation</a></p>
<p>Introduction: Elena Grewal writes:
  
I am currently using the iterative regression imputation model as implemented in the Stata ICE package. I am using data from a survey of about 90,000 students in 142 schools and my variable of interest is parent level of education. I want only this variable to be imputed with as little bias as possible as I am not using any other variable. So I scoured the survey for every variable I thought could possibly predict parent education. The main variable I found is parent occupation, which explains about 35% of the variance in parent education for the students with complete data on both. I then include the 20 other variables I found in the survey in a regression predicting parent education, which explains about 40% of the variance in parent education for students with complete data on all the variables. 


My question is this: many of the other variables I found have more missing values than the parent education variable, and also, although statistically significant</p><p>3 0.79808253 <a title="14-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>Introduction: Steve Miller writes: 
  
  
Much of what I do is cross-national analyses of survey data (largely World Values Survey). . . . My big question pertains to (what I would call) exploratory analysis of multilevel data, especially when the group-level predictors are of theoretical importance. A lot of what I do involves analyzing cross-national survey items of citizen attitudes, typically of political leadership. These survey items are usually yes/no responses, or four-part responses indicating a level of agreement (strongly agree, agree, disagree, strongly disagree) that can be condensed into a binary variable. I believe these can be explained by reference to country-level factors. Much of the group-level variables of interest are count variables with a modal value of 0, which can be quite messy.


How would you recommend exploring the variation in the dependent variable as it could be explained by the group-level count variable of interest, before fitting the multilevel model itself? When</p><p>4 0.78711241 <a title="14-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>Introduction: Fred Schiff writes: 
  
  
I’m writing to you to ask about the “R-squared” approximation procedure you suggest in your 2004 book with Dr. Hill.  [See also  this paper  with Pardoe---ed.]


I’m a media sociologist at the University of Houston.  I’ve been using HLM3 for about two years.  


Briefly about my data.  It’s a content analysis of news stories with a continuous scale dependent variable, story prominence.  I have 6090 news stories, 114 newspapers, and 59 newspaper group owners.  All the Level-1, Level-2 and dependent variables have been standardized. Since the means were zero anyway, we left the variables uncentered.  All the Level-3 ownership groups and characteristics are dichotomous scales that were left uncentered.  


PROBLEM:  The single most important result I am looking for is to compare the strength of nine competing Level-1 variables in their ability to predict and explain the outcome variable, story prominence.  We are trying to use the residuals to calculate a “R-squ</p><p>5 0.76688868 <a title="14-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-19-Cross-validation_to_check_missing-data_imputation.html">1330 andrew gelman stats-2012-05-19-Cross-validation to check missing-data imputation</a></p>
<p>Introduction: Aureliano Crameri writes: 
  
  
I have questions regarding one technique you and your colleagues described in your papers: the cross validation (Multiple Imputation with Diagnostics (mi) in R: Opening Windows into the Black Box, with reference to Gelman, King, and Liu, 1998). I think this is the technique I need for my purpose, but I am not sure I understand it right. I want to use the multiple imputation to estimate the outcome of psychotherapies based on longitudinal data. First I have to demonstrate that I am able to get unbiased estimates with the multiple imputation. The expected bias is the overestimation of the outcome of dropouts.


I will test my imputation strategies by means of a series of simulations (delete values, impute, compare with the original). Due to the complexity of the statistical analyses I think I need at least 200 cases. Now I don’t have so many cases without any missings. My data have missing values in different variables. The proportion of missing values is</p><p>6 0.75353146 <a title="14-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-18-Standardizing_regression_inputs.html">1462 andrew gelman stats-2012-08-18-Standardizing regression inputs</a></p>
<p>7 0.72770506 <a title="14-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Modeling_y_%3D_a_%2B_b_%2B_c.html">1294 andrew gelman stats-2012-05-01-Modeling y = a + b + c</a></p>
<p>8 0.72709769 <a title="14-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-03-is_it_possible_to_%E2%80%9Coverstratify%E2%80%9D_when_assigning_a_treatment_in_a_randomized_control_trial%3F.html">553 andrew gelman stats-2011-02-03-is it possible to “overstratify” when assigning a treatment in a randomized control trial?</a></p>
<p>9 0.72204238 <a title="14-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-31-Using_factor_analysis_or_principal_components_analysis_or_measurement-error_models_for_biological_measurements_in_archaeology%3F.html">1094 andrew gelman stats-2011-12-31-Using factor analysis or principal components analysis or measurement-error models for biological measurements in archaeology?</a></p>
<p>10 0.71992445 <a title="14-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-21-Interpreting_interactions_in_discrete-data_regression.html">1908 andrew gelman stats-2013-06-21-Interpreting interactions in discrete-data regression</a></p>
<p>11 0.71166271 <a title="14-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>12 0.70471287 <a title="14-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-02-Interaction-based_feature_selection_and_classification_for_high-dimensional_biological_data.html">1703 andrew gelman stats-2013-02-02-Interaction-based feature selection and classification for high-dimensional biological data</a></p>
<p>13 0.69893515 <a title="14-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-19-Index_or_indicator_variables.html">2296 andrew gelman stats-2014-04-19-Index or indicator variables</a></p>
<p>14 0.69727802 <a title="14-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-13-Lame_Statistics_Patents.html">1761 andrew gelman stats-2013-03-13-Lame Statistics Patents</a></p>
<p>15 0.69489789 <a title="14-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>16 0.6911369 <a title="14-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-28-Using_randomized_incentives_as_an_instrument_for_survey_nonresponse%3F.html">2152 andrew gelman stats-2013-12-28-Using randomized incentives as an instrument for survey nonresponse?</a></p>
<p>17 0.67395073 <a title="14-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-Interactions_of_predictors_in_a_causal_model.html">251 andrew gelman stats-2010-09-02-Interactions of predictors in a causal model</a></p>
<p>18 0.66687429 <a title="14-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>19 0.66393632 <a title="14-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-Why_we_hate_stepwise_regression.html">2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</a></p>
<p>20 0.66035503 <a title="14-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-15-Still_more_Mr._P_in_public_health.html">770 andrew gelman stats-2011-06-15-Still more Mr. P in public health</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.019), (9, 0.044), (11, 0.019), (16, 0.09), (21, 0.017), (24, 0.096), (37, 0.021), (53, 0.014), (56, 0.207), (64, 0.014), (82, 0.02), (89, 0.034), (94, 0.02), (98, 0.045), (99, 0.232)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93419528 <a title="14-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<p>Introduction: Guy asks:
  
I am analyzing an original survey of farmers in Uganda. I am hoping to use a battery of welfare proxy variables to create a single welfare index using PCA. I have quick question which I hope you can find time to address:


How do you recommend treating count data? (for example # of rooms, # of chickens, # of cows, # of radios)? In my dataset these variables are highly skewed with many responses at zero (which makes taking the natural log problematic). In the case of # of cows or chickens several obs have values in the hundreds.
  
My response:  Hereâ&euro;&trade;s what we do in our mi package in R.  We split a variable into two parts:  an indicator for whether it is positive, and the positive part.  That is, y = u*v.  Then u is binary and can be modeled using logisitc regression, and v can be modeled on the log scale.  At the end you can round to the nearest integer  if you want to avoid fractional values.</p><p>2 0.93217373 <a title="14-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-07-Martyn_Plummer%E2%80%99s_Secret_JAGS_Blog.html">1045 andrew gelman stats-2011-12-07-Martyn Plummer’s Secret JAGS Blog</a></p>
<p>Introduction: Martyn Plummer , the creator of the open-source, C++, graphical-model compiler  JAGS  (aka “Just Another Gibbs Sampler”), runs a forum on the JAGS site that has a very similar feel to the mail-bag posts on this blog.  Martyn answers general statistical computing questions (e.g., why slice sampling rather than Metropolis-Hastings?) and general modeling (e.g., why won’t my model converge with this prior?).
 
Here’s the link to the top-level JAGS site, and to the forum:
  
   JAGS Forum 
    JAGS Home Page 
   
The forum’s pretty active, with the stats page showing hundreds of views per day and very regular posts and answers.  Martyn’s last post was today.
 
Martyn also has a blog devoted to JAGS and other stats news:
  
  JAGS News Blog</p><p>3 0.91197848 <a title="14-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-15-World_record_running_times_vs._distance.html">1011 andrew gelman stats-2011-11-15-World record running times vs. distance</a></p>
<p>Introduction: Julyan Arbel  plots  world record running times vs. distance (on the log-log scale):
 
   
 
The line has a slope of 1.1.  I think it would be clearer to plot speed vs. distance—then you’d get a slope of -0.1, and the numbers would be more directly interpretable.
 
Indeed,  this paper  by Sandra Savaglio and Vincenzo Carbone (referred to in the comments on Julyan’s blog) plots speed vs. time.  Graphing by speed gives more resolution:
 
   
 
The upper-left graph in the grid corresponds to the human running records plotted by Arbel.  It’s funny that Arbel sees only one line whereas Savaglio and Carbone see two—but if you remove the 100m record at one end and the 100km at the other end, you can see two lines in Arbel’s graph as well.  The bottom two graphs show swimming records.   Knut  would probably have something to say about all this.</p><p>4 0.89073789 <a title="14-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-07-Stereotype_threat%21.html">1929 andrew gelman stats-2013-07-07-Stereotype threat!</a></p>
<p>Introduction: Colleen Ganley, Leigh Mingle, Allison Ryan, Katherine Ryan, Marian Vasilyeva, and Michelle Perry  write :
  
Stereotype threat has been proposed as 1 potential explanation for the gender difference in standardized mathematics test performance among high-performing students. At present, it is not entirely clear how susceptibility to stereotype threat develops, as empirical evidence for stereotype threat effects across the school years is inconsistent. In a series of 3 studies, with a total sample of 931 students, we investigated stereotype threat effects during childhood and adolescence. Three activation methods were used, ranging from implicit to explicit. Across studies, we found no evidence that the mathematics performance of school-age girls was impacted by stereotype threat. In 2 of the studies, there were gender differences on the mathematics assessment regardless of whether stereotype threat was activated. Potential reasons for these findings are discussed, including the possibil</p><p>5 0.88293815 <a title="14-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-30-More_bad_news%3A__The_%28mis%29reporting_of_statistical_results_in_psychology_journals.html">933 andrew gelman stats-2011-09-30-More bad news:  The (mis)reporting of statistical results in psychology journals</a></p>
<p>Introduction: Another entry in the growing literature on systematic flaws in the scientific research literature.
 
This time the bad tidings come from Marjan Bakker and Jelte Wicherts, who  write :
  
Around 18% of statistical results in the psychological literature are incorrectly reported. Inconsistencies were more common in low-impact journals than in high-impact journals. Moreover, around 15% of the articles contained at least one statistical conclusion that proved, upon recalculation, to be incorrect; that is, recalculation rendered the previously significant result insignificant, or vice versa. These errors were often in line with researchers’ expectations.
  
Their research also had a qualitative component:
  
To obtain a better understanding of the origins of the errors made in the reporting of statistics, we contacted the authors of the articles with errors in the second study and asked them to send us the raw data. Regrettably, only 24% of the authors shared their data, despite our request</p><p>6 0.87714469 <a title="14-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-07-The_more_likely_it_is_to_be_X%2C_the_more_likely_it_is_to_be_Not_X%3F.html">1158 andrew gelman stats-2012-02-07-The more likely it is to be X, the more likely it is to be Not X?</a></p>
<p>7 0.86201137 <a title="14-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-09-This_Friday_afternoon%3A__Applied_Statistics_Center_mini-conference_on_risk_perception.html">267 andrew gelman stats-2010-09-09-This Friday afternoon:  Applied Statistics Center mini-conference on risk perception</a></p>
<p>8 0.86147809 <a title="14-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-12-More_frustrations_trying_to_replicate_an_analysis_published_in_a_reputable_journal.html">1054 andrew gelman stats-2011-12-12-More frustrations trying to replicate an analysis published in a reputable journal</a></p>
<p>9 0.85301721 <a title="14-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-22-Americans_think_economy_isn%E2%80%99t_so_bad_in_their_city_but_is_crappy_nationally_and_globally.html">1388 andrew gelman stats-2012-06-22-Americans think economy isn’t so bad in their city but is crappy nationally and globally</a></p>
<p>10 0.84906816 <a title="14-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-27-Bridges_between_deterministic_and_probabilistic_models_for_binary_data.html">780 andrew gelman stats-2011-06-27-Bridges between deterministic and probabilistic models for binary data</a></p>
<p>11 0.83013964 <a title="14-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-01-David_MacKay_sez_._._._12%3F%3F.html">984 andrew gelman stats-2011-11-01-David MacKay sez . . . 12??</a></p>
<p>12 0.82401276 <a title="14-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-09-Special_journal_issue_on_statistical_methods_for_the_social_sciences.html">24 andrew gelman stats-2010-05-09-Special journal issue on statistical methods for the social sciences</a></p>
<p>13 0.79765713 <a title="14-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>14 0.79264724 <a title="14-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-15-Problematic_interpretations_of_confidence_intervals.html">2248 andrew gelman stats-2014-03-15-Problematic interpretations of confidence intervals</a></p>
<p>15 0.79255384 <a title="14-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-14-Oswald_evidence.html">2134 andrew gelman stats-2013-12-14-Oswald evidence</a></p>
<p>16 0.79102492 <a title="14-lda-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-10-On_deck_this_week%3A__Things_people_sent_me.html">2240 andrew gelman stats-2014-03-10-On deck this week:  Things people sent me</a></p>
<p>17 0.78452051 <a title="14-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-27-What_is_an_economic_%E2%80%9Cconspiracy_theory%E2%80%9D%3F.html">630 andrew gelman stats-2011-03-27-What is an economic “conspiracy theory”?</a></p>
<p>18 0.78081352 <a title="14-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-22-Postdoc_opportunity_here_at_Columbia_%E2%80%94_deadline_soon%21.html">426 andrew gelman stats-2010-11-22-Postdoc opportunity here at Columbia — deadline soon!</a></p>
<p>19 0.78003478 <a title="14-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>20 0.77130795 <a title="14-lda-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-05-Plagiarism%2C_Arizona_style.html">2234 andrew gelman stats-2014-03-05-Plagiarism, Arizona style</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
