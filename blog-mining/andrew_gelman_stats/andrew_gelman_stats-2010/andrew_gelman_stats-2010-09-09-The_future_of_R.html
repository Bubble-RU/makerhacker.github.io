<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>266 andrew gelman stats-2010-09-09-The future of R</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-266" href="#">andrew_gelman_stats-2010-266</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>266 andrew gelman stats-2010-09-09-The future of R</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-266-html" href="http://andrewgelman.com/2010/09/09/the_future_of_r/">html</a></p><p>Introduction: Some thoughts from Christian , including this bit:
  
We need to consider separately


1. R’s brilliant library


2. R’s not-so-brilliant language and/or interpreter.
  
I don’t know that R’s library is so brilliant as all that–if necessary, I don’t think it would be hard to reprogram the important packages in a new language.
 
I would say, though, that the problems with R are not just in the technical details of the language.  I think the culture of R has some problems too.  As I’ve written before, R functions used to be lean and mean, and now they’re full of exception-handling and calls to other packages.  R functions are spaghetti-like messes of connections in which I keep expecting to run into syntax like “GOTO 120.”
 
I learned about these problems a couple years ago when writing bayesglm(), which is a simple adaptation of glm().  But glm(), and its workhorse, glm.fit(), are a mess:  They’re about 10 lines of functioning code, plus about 20 lines of necessary front-end, plus a cou</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Some thoughts from Christian , including this bit:    We need to consider separately   1. [sent-1, score-0.174]
</p><p>2 I don’t know that R’s library is so brilliant as all that–if necessary, I don’t think it would be hard to reprogram the important packages in a new language. [sent-4, score-0.541]
</p><p>3 I would say, though, that the problems with R are not just in the technical details of the language. [sent-5, score-0.289]
</p><p>4 As I’ve written before, R functions used to be lean and mean, and now they’re full of exception-handling and calls to other packages. [sent-7, score-0.639]
</p><p>5 R functions are spaghetti-like messes of connections in which I keep expecting to run into syntax like “GOTO 120. [sent-8, score-0.981]
</p><p>6 ”   I learned about these problems a couple years ago when writing bayesglm(), which is a simple adaptation of glm(). [sent-9, score-0.482]
</p><p>7 fit(), are a mess:  They’re about 10 lines of functioning code, plus about 20 lines of necessary front-end, plus a couple hundred lines of naming, exception-handling, repetitions of chunks of code, pseudo-structured-programming-through-naming-of-variables, and general buck-passing. [sent-11, score-1.911]
</p><p>8 I still don’t know if my modifications are quite right–I did what was needed to the meat of the function but no way can I keep track of all the if-else possibilities. [sent-12, score-0.656]
</p><p>9 If R is redone, I hope its functions return to the lean-and-mean aesthetic of the original S (but with better graphics defaults). [sent-13, score-0.741]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('functions', 0.284), ('glm', 0.257), ('lines', 0.235), ('brilliant', 0.219), ('library', 0.216), ('plus', 0.18), ('redone', 0.172), ('workhorse', 0.172), ('aesthetic', 0.162), ('necessary', 0.162), ('messes', 0.155), ('modifications', 0.155), ('repetitions', 0.155), ('code', 0.15), ('chunks', 0.15), ('syntax', 0.145), ('adaptation', 0.145), ('functioning', 0.145), ('bayesglm', 0.141), ('naming', 0.141), ('problems', 0.141), ('defaults', 0.138), ('meat', 0.13), ('lean', 0.128), ('keep', 0.121), ('couple', 0.117), ('hundred', 0.117), ('mess', 0.116), ('expecting', 0.112), ('separately', 0.108), ('packages', 0.106), ('christian', 0.105), ('calls', 0.102), ('connections', 0.099), ('track', 0.093), ('culture', 0.092), ('return', 0.087), ('language', 0.082), ('needed', 0.082), ('technical', 0.081), ('learned', 0.079), ('graphics', 0.079), ('function', 0.075), ('details', 0.067), ('hope', 0.067), ('thoughts', 0.066), ('run', 0.065), ('written', 0.063), ('full', 0.062), ('original', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="266-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-09-The_future_of_R.html">266 andrew gelman stats-2010-09-09-The future of R</a></p>
<p>Introduction: Some thoughts from Christian , including this bit:
  
We need to consider separately


1. R’s brilliant library


2. R’s not-so-brilliant language and/or interpreter.
  
I don’t know that R’s library is so brilliant as all that–if necessary, I don’t think it would be hard to reprogram the important packages in a new language.
 
I would say, though, that the problems with R are not just in the technical details of the language.  I think the culture of R has some problems too.  As I’ve written before, R functions used to be lean and mean, and now they’re full of exception-handling and calls to other packages.  R functions are spaghetti-like messes of connections in which I keep expecting to run into syntax like “GOTO 120.”
 
I learned about these problems a couple years ago when writing bayesglm(), which is a simple adaptation of glm().  But glm(), and its workhorse, glm.fit(), are a mess:  They’re about 10 lines of functioning code, plus about 20 lines of necessary front-end, plus a cou</p><p>2 0.12737454 <a title="266-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-12-Stan_1.3.0_and_RStan_1.3.0_Ready_for_Action.html">1799 andrew gelman stats-2013-04-12-Stan 1.3.0 and RStan 1.3.0 Ready for Action</a></p>
<p>Introduction: The Stan Development Team is happy to announce that Stan 1.3.0 and RStan 1.3.0 are available for download. Follow the links on:
  
 Stan home page:   http://mc-stan.org/ 
   
Please let us know if you have problems updating.
 
Hereâ&euro;&trade;s the full set of release notes.
  
v1.3.0 (12 April 2013)
======================================================================
Enhancements
----------------------------------

Modeling Language
* forward sampling (random draws from distributions)
  in generated quantities
* better error messages in parser
* new distributions: 
    + exp_mod_normal
    + gumbel 
    + skew_normal
* new special functions: 
    + owenst
* new broadcast (repetition) functions for vectors, arrays, matrices
    + rep_arrray
    + rep_matrix
    + rep_row_vector
    + rep_vector    

Command-Line
* added option to display autocorrelations in the command-line program
  to print output
* changed default point estimation routine from the command line to</p><p>3 0.11992633 <a title="266-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-04-Whassup_with_glm%28%29%3F.html">696 andrew gelman stats-2011-05-04-Whassup with glm()?</a></p>
<p>Introduction: We’re having problem with starting values in glm().  A very simple logistic regression with just an intercept with a very simple starting value (beta=5) blows up.
  

 

Here’s the R code:
 
 
> y <- rep (c(1,0),c(10,5))
> glm (y ~ 1, family=binomial(link="logit"))

Call:  glm(formula = y ~ 1, family = binomial(link = "logit"))

Coefficients:
(Intercept)  
     0.6931  

Degrees of Freedom: 14 Total (i.e. Null);  14 Residual
Null Deviance:      19.1 
Residual Deviance: 19.1         AIC: 21.1 
> glm (y ~ 1, family=binomial(link="logit"), start=2)

Call:  glm(formula = y ~ 1, family = binomial(link = "logit"), start = 2)

Coefficients:
(Intercept)  
     0.6931  

Degrees of Freedom: 14 Total (i.e. Null);  14 Residual
Null Deviance:      19.1 
Residual Deviance: 19.1         AIC: 21.1 
> glm (y ~ 1, family=binomial(link="logit"), start=5)

Call:  glm(formula = y ~ 1, family = binomial(link = "logit"), start = 5)

Coefficients:
(Intercept)  
  1.501e+15  

Degrees of Freedom: 14 Total (i.</p><p>4 0.11097538 <a title="266-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Stan_1.2.0_and_RStan_1.2.0.html">1753 andrew gelman stats-2013-03-06-Stan 1.2.0 and RStan 1.2.0</a></p>
<p>Introduction: Stan 1.2.0 and RStan 1.2.0 are now available for download. See:
  
  http://mc-stan.org/ 
   
Here are the highlights.
  Full Mass Matrix Estimation during Warmup  
Yuanjun Gao, a first-year grad student here at Columbia (!), built a regularized mass-matrix estimator.   This helps for posteriors with high correlation among parameters and varying scales.  We’re still testing this ourselves, so the estimation procedure may change in the future (don’t worry — it satisfies detailed balance as is, but we might be able to make it more computationally efficient in terms of time per effective sample).
 
It’s not the default option.  The major reason is the matrix operations required are expensive, raising the algorithm cost to    , where   is the average number of leapfrog steps,   is the number of iterations, and   is the number of parameters.
 
Yuanjun did a great job with the Cholesky factorizations and implemented this about as efficiently as is possible. (His homework for Andrew’s class w</p><p>5 0.10230814 <a title="266-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-14-Wickham_R_short_course.html">1009 andrew gelman stats-2011-11-14-Wickham R short course</a></p>
<p>Introduction: Hadley  writes:
  
I [Hadley] am going to be teaching an R development master class in New York City on Dec 
12-13. The basic idea of the class is to help you write better code, 
focused on the mantra of “do not repeat yourself”. In day one you will 
learn powerful new tools of abstraction, allowing you to solve a wider 
range of problems with fewer lines of code. Day two will teach you how 
to make packages, the fundamental unit of code distribution in R, 
allowing others to save time by allowing them to use your code.


To get the most out of this course, you should have some experience 
programming in R already: you should be familiar with writing 
functions, and the basic data structures of R: vectors, matrices, 
arrays, lists and data frames. You will find the course particularly 
useful if you’re an experienced R user looking to take the next step, 
or if you’re moving to R from other programming languages and you want 
to quickly get up to speed with R’s unique features. A coupl</p><p>6 0.097172394 <a title="266-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-13-Ross_Ihaka_to_R%3A__Drop_Dead.html">272 andrew gelman stats-2010-09-13-Ross Ihaka to R:  Drop Dead</a></p>
<p>7 0.09264452 <a title="266-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-30-Computational_problems_with_glm_etc..html">1516 andrew gelman stats-2012-09-30-Computational problems with glm etc.</a></p>
<p>8 0.091482006 <a title="266-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-28-Life_imitates_blog.html">1399 andrew gelman stats-2012-06-28-Life imitates blog</a></p>
<p>9 0.091074333 <a title="266-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Data_problems%2C_coding_errors%E2%80%A6what_can_be_done%3F.html">1807 andrew gelman stats-2013-04-17-Data problems, coding errors…what can be done?</a></p>
<p>10 0.086079247 <a title="266-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-17-Stan_and_RStan_1.1.0.html">1627 andrew gelman stats-2012-12-17-Stan and RStan 1.1.0</a></p>
<p>11 0.084553517 <a title="266-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-07-Robust_logistic_regression.html">1886 andrew gelman stats-2013-06-07-Robust logistic regression</a></p>
<p>12 0.084245078 <a title="266-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-09-I_hate_polynomials.html">2365 andrew gelman stats-2014-06-09-I hate polynomials</a></p>
<p>13 0.08279781 <a title="266-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>14 0.081969127 <a title="266-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-11-Multilevel_modeling_in_R_on_a_Mac.html">198 andrew gelman stats-2010-08-11-Multilevel modeling in R on a Mac</a></p>
<p>15 0.076091602 <a title="266-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-The_statistics_software_signal.html">1655 andrew gelman stats-2013-01-05-The statistics software signal</a></p>
<p>16 0.076079741 <a title="266-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-04-Shlemiel_the_Software_Developer_and_Unknown_Unknowns.html">2089 andrew gelman stats-2013-11-04-Shlemiel the Software Developer and Unknown Unknowns</a></p>
<p>17 0.075308889 <a title="266-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-05-Different_goals%2C_different_looks%3A__Infovis_and_the_Chris_Rock_effect.html">787 andrew gelman stats-2011-07-05-Different goals, different looks:  Infovis and the Chris Rock effect</a></p>
<p>18 0.073651187 <a title="266-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>19 0.072207406 <a title="266-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>20 0.072029218 <a title="266-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-25-Revised_statistical_standards_for_evidence_%28comments_to_Val_Johnson%E2%80%99s_comments_on_our_comments_on_Val%E2%80%99s_comments_on_p-values%29.html">2305 andrew gelman stats-2014-04-25-Revised statistical standards for evidence (comments to Val Johnson’s comments on our comments on Val’s comments on p-values)</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.116), (1, -0.012), (2, -0.027), (3, 0.043), (4, 0.072), (5, -0.024), (6, 0.022), (7, -0.05), (8, 0.0), (9, -0.024), (10, -0.038), (11, -0.024), (12, -0.024), (13, -0.025), (14, -0.0), (15, 0.0), (16, -0.007), (17, 0.005), (18, -0.015), (19, 0.006), (20, 0.017), (21, 0.023), (22, -0.022), (23, 0.036), (24, -0.011), (25, 0.008), (26, 0.029), (27, 0.027), (28, 0.021), (29, 0.011), (30, 0.026), (31, 0.014), (32, 0.016), (33, -0.003), (34, 0.026), (35, -0.083), (36, -0.022), (37, 0.04), (38, -0.001), (39, -0.008), (40, -0.014), (41, 0.026), (42, 0.01), (43, -0.013), (44, 0.004), (45, 0.053), (46, -0.027), (47, 0.01), (48, 0.039), (49, 0.018)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95299286 <a title="266-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-09-The_future_of_R.html">266 andrew gelman stats-2010-09-09-The future of R</a></p>
<p>Introduction: Some thoughts from Christian , including this bit:
  
We need to consider separately


1. R’s brilliant library


2. R’s not-so-brilliant language and/or interpreter.
  
I don’t know that R’s library is so brilliant as all that–if necessary, I don’t think it would be hard to reprogram the important packages in a new language.
 
I would say, though, that the problems with R are not just in the technical details of the language.  I think the culture of R has some problems too.  As I’ve written before, R functions used to be lean and mean, and now they’re full of exception-handling and calls to other packages.  R functions are spaghetti-like messes of connections in which I keep expecting to run into syntax like “GOTO 120.”
 
I learned about these problems a couple years ago when writing bayesglm(), which is a simple adaptation of glm().  But glm(), and its workhorse, glm.fit(), are a mess:  They’re about 10 lines of functioning code, plus about 20 lines of necessary front-end, plus a cou</p><p>2 0.8269912 <a title="266-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-04-Shlemiel_the_Software_Developer_and_Unknown_Unknowns.html">2089 andrew gelman stats-2013-11-04-Shlemiel the Software Developer and Unknown Unknowns</a></p>
<p>Introduction: The Stan meeting today reminded me of Joel Spolsky’s recasting of the Yiddish joke about Shlemiel the Painter. Joel retold it on his blog,  Joel on Software , in the post  Back to Basics :
  

Shlemiel gets a job as a street painter, painting the dotted lines down the middle of the road. On the first day he takes a can of paint out to the road and finishes 300 yards of the road. “That’s pretty good!” says his boss, “you’re a fast worker!” and pays him a kopeck.


The next day Shlemiel only gets 150 yards done. “Well, that’s not nearly as good as yesterday, but you’re still a fast worker. 150 yards is respectable,” and pays him a kopeck.


The next day Shlemiel paints 30 yards of the road. “Only 30!” shouts his boss. “That’s unacceptable! On the first day you did ten times that much work! What’s going on?”


“I can’t help it,” says Shlemiel. “Every day I get farther and farther away from the paint can!”

  
Joel used it as an example of the kind of string processing naive programmers ar</p><p>3 0.78126574 <a title="266-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-09-iPython_Notebook.html">1716 andrew gelman stats-2013-02-09-iPython Notebook</a></p>
<p>Introduction: Burak Bayramli writes:
  
I wanted to inform you on iPython Notebook technology – allowing markup, Python code to reside in one document. Someone ported  one of your examples from ARM .


iPynb file is actually a live document, can be downloaded and reran locally, hence change of code on document means change of images, results. Graphs (as well as text output) which are generated by the code, are placed inside the document automatically. No more referencing image files seperately. 


For now running notebooks locally require a notebook server, but that part can live “on the cloud” as part of an educational software. Viewers, such as nbviewer.ipython.org, do not even need that much, since all recent results of a notebook are embedded in the notebook itself. 


A lot of people are excited about this; Also out of nowhere, Alfred P. Sloan Foundation dropped a $1.15 million grant on the developers of ipython which provided some extra energy on the project.
  
Cool.  We’ll have to do that ex</p><p>4 0.75719064 <a title="266-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>Introduction: We need help picking out an automatic differentiation package for Hamiltonian Monte Carlo sampling from the posterior of a  generalized linear model with deep interactions.  Specifically, we need to compute gradients for log probability functions with thousands of parameters that involve matrix (determinants, eigenvalues, inverses), stats (distributions), and math (log gamma) functions.  Any suggestions?
    
 The Application: Hybrid Monte Carlo for Posteriors 
 
We’re getting serious about implementing posterior sampling using Hamiltonian Monte Carlo.  HMC speeds up mixing by including gradient information to help guide the Metropolis proposals toward areas  high probability.  In practice, the algorithm requires a handful or  of gradient calculations per sample, but there are many dimensions and the functions are hairy enough we don’t want to compute derivaties by hand.
 

 Auto Diff: Perhaps not What you Think 
 
It may not have been clear to readers of this blog that automatic diffe</p><p>5 0.74855626 <a title="266-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Data_problems%2C_coding_errors%E2%80%A6what_can_be_done%3F.html">1807 andrew gelman stats-2013-04-17-Data problems, coding errors…what can be done?</a></p>
<p>Introduction: This post is by Phil
 
A  recent post on this blog  discusses a prominent case of an Excel error leading to substantially wrong results from a statistical analysis. Excel is notorious for this because it is easy to add a row or column of data (or intermediate results) but forget to update equations so that they correctly use the new data. That particular error is less common in a language like R because R programmers usually refer to data by variable name (or by applying functions to a named variable), so the same code works even if you add or remove data.
 
Still, there is plenty of opportunity for errors no matter what language one uses. Andrew  ran into problems  fairly recently, and also blogged about  another instance.  I’ve never had to retract a paper, but that’s partly because I haven’t published a whole lot of papers. Certainly I have found plenty of substantial errors pretty late in some of my data analyses, and I obviously don’t have sufficient mechanisms in place to be sure</p><p>6 0.74824411 <a title="266-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-13-Ross_Ihaka_to_R%3A__Drop_Dead.html">272 andrew gelman stats-2010-09-13-Ross Ihaka to R:  Drop Dead</a></p>
<p>7 0.73937362 <a title="266-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-29-Stupid_R_Tricks%3A__Random_Scope.html">2190 andrew gelman stats-2014-01-29-Stupid R Tricks:  Random Scope</a></p>
<p>8 0.71823937 <a title="266-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Lessons_learned_from_a_recent_R_package_submission.html">1134 andrew gelman stats-2012-01-21-Lessons learned from a recent R package submission</a></p>
<p>9 0.71424109 <a title="266-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-02-RStudio_%E2%80%93_new_cross-platform_IDE_for_R.html">597 andrew gelman stats-2011-03-02-RStudio – new cross-platform IDE for R</a></p>
<p>10 0.71101272 <a title="266-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Contest_for_developing_an_R_package_recommendation_system.html">324 andrew gelman stats-2010-10-07-Contest for developing an R package recommendation system</a></p>
<p>11 0.6981315 <a title="266-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-The_statistics_software_signal.html">1655 andrew gelman stats-2013-01-05-The statistics software signal</a></p>
<p>12 0.67027414 <a title="266-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-29-R_sucks.html">1919 andrew gelman stats-2013-06-29-R sucks</a></p>
<p>13 0.66432744 <a title="266-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-23-Parallel_JAGS_RNGs.html">818 andrew gelman stats-2011-07-23-Parallel JAGS RNGs</a></p>
<p>14 0.66382378 <a title="266-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-16-%E2%80%9CFor_individuals_with_wine_training%2C_however%2C_we_find__indications_of_a_positive_relationship_between_price_and_enjoyment%E2%80%9D.html">470 andrew gelman stats-2010-12-16-“For individuals with wine training, however, we find  indications of a positive relationship between price and enjoyment”</a></p>
<p>15 0.65788263 <a title="266-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-03-Advice_that%E2%80%99s_so_eminently_sensible_but_so_difficult_to_follow.html">1520 andrew gelman stats-2012-10-03-Advice that’s so eminently sensible but so difficult to follow</a></p>
<p>16 0.65079069 <a title="266-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-09-Maze_generation_algorithms%21.html">1048 andrew gelman stats-2011-12-09-Maze generation algorithms!</a></p>
<p>17 0.64870596 <a title="266-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Stan_1.2.0_and_RStan_1.2.0.html">1753 andrew gelman stats-2013-03-06-Stan 1.2.0 and RStan 1.2.0</a></p>
<p>18 0.64368951 <a title="266-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-24-Rcpp_class_in_Sat_9_Mar_in_NYC.html">1736 andrew gelman stats-2013-02-24-Rcpp class in Sat 9 Mar in NYC</a></p>
<p>19 0.64056146 <a title="266-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-23-Infographic_of_the_year.html">1277 andrew gelman stats-2012-04-23-Infographic of the year</a></p>
<p>20 0.63864654 <a title="266-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-ff.html">418 andrew gelman stats-2010-11-17-ff</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(10, 0.016), (16, 0.093), (24, 0.173), (42, 0.018), (45, 0.012), (54, 0.048), (65, 0.027), (74, 0.019), (86, 0.014), (90, 0.034), (95, 0.241), (99, 0.202)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96796805 <a title="266-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-31-Even_a_good_data_display_can_sometimes_be_improved.html">832 andrew gelman stats-2011-07-31-Even a good data display can sometimes be improved</a></p>
<p>Introduction: When I first saw this graphic, I thought “boy, that’s great, sometimes the graphic practically makes itself.” Normally it’s hard to use lots of different colors to differentiate items of interest, because there’s usually not an intuitive mapping between color and item (e.g. for countries, or states, or whatever). But the colors of crayons, what could be more perfect? So this graphic seemed awesome. But, as they discovered after some experimentation at  datapointed.net  there is an even BETTER possibility here. Click the link to see.
 
     Crayola Crayon colors by year</p><p>2 0.95512766 <a title="266-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-09-%E2%80%9CMuch_of_the_recent_reported_drop_in_interstate_migration_is_a_statistical_artifact%E2%80%9D.html">404 andrew gelman stats-2010-11-09-“Much of the recent reported drop in interstate migration is a statistical artifact”</a></p>
<p>Introduction: Greg Kaplan writes:
  
I noticed that you have blogged a little about interstate migration trends in the US, and thought  that you might be interested in  a new working paper  of mine (joint with Sam Schulhofer-Wohl from the Minneapolis Fed) which I have attached.


Briefly, we show that much of the recent reported drop in interstate migration is a statistical artifact: The Census Bureau made an undocumented change in its imputation procedures for missing data in 2006, and this change significantly reduced the number of imputed interstate moves. The change in imputation procedures — not any actual change in migration behavior — explains 90 percent of the reported decrease in interstate migration between the 2005 and 2006 Current Population Surveys, and 42 percent of the decrease between 2000 and 2010.
  
I haven’t had a chance to give a serious look so could only make the quick suggestion to make the graphs smaller and put multiple graphs on a page,  This would allow the reader to bett</p><p>3 0.95507199 <a title="266-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-23-Foundation_for_Open_Access_Statistics.html">1820 andrew gelman stats-2013-04-23-Foundation for Open Access Statistics</a></p>
<p>Introduction: Now here’s a foundation I (Bob) can get behind: 
  

 Foundation for Open Access Statistics  (FOAS)

  
Their  mission  is to “promote free software, open access publishing, and reproducible research in statistics.”  To me, that’s like supporting  motherhood and apple pie !
 
FOAS spun out of and is partially designed to support the   Journal of Statistical Software   (aka  JSS , aka  JStatSoft ). I adore  JSS  because it (a) is open access, (b) publishes systems papers on statistical software, (c) has fast reviewing turnaround times, and (d) is free for authors and readers.  One of the next items on my to-do list is to write up the  Stan  modeling language and submit it to  JSS .
 
As a not-for-profit with no visible source of income, they are quite sensibly  asking for donations  (don’t complain — it beats $3K author fees or not being able to read papers).</p><p>4 0.95419174 <a title="266-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-08-For_chrissake%2C_just_make_up_an_analysis_already%21__We_have_a_lab_here_to_run%2C_y%E2%80%99know%3F.html">1973 andrew gelman stats-2013-08-08-For chrissake, just make up an analysis already!  We have a lab here to run, y’know?</a></p>
<p>Introduction: Ben Hyde sends along  this :
  
Stuck in the middle of the supplemental data, reporting the total workup for their compounds, was this gem:

 
Emma, please insert NMR data here! where are they? and for this compound, just make up an elemental analysis . . .
 
  
I’m reminded of our recent  discussions  of coauthorship, where I argued that I see real advantages to having multiple people taking responsibility for the result.  Jay Verkuilen responded: “On the flipside of collaboration . . . is diffusion of responsibility, where everybody thinks someone else ‘has that problem’ and thus things don’t get solved.”  That’s what seems to have happened (hilariously) here.</p><p>5 0.90987158 <a title="266-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-18-uuuuuuuuuuuuugly.html">1862 andrew gelman stats-2013-05-18-uuuuuuuuuuuuugly</a></p>
<p>Introduction: Hamdan Azhar writes:
  
I came across this graphic of vaccine-attributed decreases in mortality and was curious if you found it as unattractive and unintuitive as I did. Hope all is well with you!
  
My reply:  All’s well with me.  And yes, that’s one horrible graph.  It has all the problems with a bad infographic with none of the virtues.  Compared to this monstrosity, the typical USA Today graph is a stunning, beautiful masterpiece.  I don’t think I want to soil this webpage with the image.  In fact, I don’t even want to link to it.</p><p>6 0.90764809 <a title="266-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-30-More_on_problems_with_surveys_estimating_deaths_in_war_zones.html">12 andrew gelman stats-2010-04-30-More on problems with surveys estimating deaths in war zones</a></p>
<p>same-blog 7 0.90550828 <a title="266-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-09-The_future_of_R.html">266 andrew gelman stats-2010-09-09-The future of R</a></p>
<p>8 0.90090579 <a title="266-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-13-Help_with_this_problem%2C_win_valuable_prizes.html">1164 andrew gelman stats-2012-02-13-Help with this problem, win valuable prizes</a></p>
<p>9 0.89044464 <a title="266-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-28-Vaguely_related_to_the_coke-dumping_story.html">876 andrew gelman stats-2011-08-28-Vaguely related to the coke-dumping story</a></p>
<p>10 0.87997705 <a title="266-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-27-The_most_dangerous_jobs_in_America.html">1086 andrew gelman stats-2011-12-27-The most dangerous jobs in America</a></p>
<p>11 0.87083715 <a title="266-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-08-chartsnthings_%21.html">1308 andrew gelman stats-2012-05-08-chartsnthings !</a></p>
<p>12 0.86919862 <a title="266-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-16-Update_on_the_generalized_method_of_moments.html">519 andrew gelman stats-2011-01-16-Update on the generalized method of moments</a></p>
<p>13 0.85978878 <a title="266-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-15-The_UN_Plot_to_Force_Bayesianism_on_Unsuspecting_Americans_%28penalized_B-Spline_edition%29.html">2135 andrew gelman stats-2013-12-15-The UN Plot to Force Bayesianism on Unsuspecting Americans (penalized B-Spline edition)</a></p>
<p>14 0.85725564 <a title="266-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-29-Infovis_vs._statgraphics%3A__A_clear_example_of_their_different_goals.html">829 andrew gelman stats-2011-07-29-Infovis vs. statgraphics:  A clear example of their different goals</a></p>
<p>15 0.84419298 <a title="266-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-24-How_few_respondents_are_reasonable_to_use_when_calculating_the_average_by_county%3F.html">627 andrew gelman stats-2011-03-24-How few respondents are reasonable to use when calculating the average by county?</a></p>
<p>16 0.83229208 <a title="266-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-01-A_graph_at_war_with_its_caption.__Also%2C_how_to_visualize_the_same_numbers_without_giving_the_display_a_misleading_causal_feel%3F.html">1834 andrew gelman stats-2013-05-01-A graph at war with its caption.  Also, how to visualize the same numbers without giving the display a misleading causal feel?</a></p>
<p>17 0.83066988 <a title="266-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-28-Should_Harvard_start_admitting_kids_at_random%3F.html">1595 andrew gelman stats-2012-11-28-Should Harvard start admitting kids at random?</a></p>
<p>18 0.8281284 <a title="266-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>19 0.82078063 <a title="266-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-The_scope_for_snooping.html">1070 andrew gelman stats-2011-12-19-The scope for snooping</a></p>
<p>20 0.82057405 <a title="266-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-30-Bill_Gates%E2%80%99s_favorite_graph_of_the_year.html">2154 andrew gelman stats-2013-12-30-Bill Gates’s favorite graph of the year</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
