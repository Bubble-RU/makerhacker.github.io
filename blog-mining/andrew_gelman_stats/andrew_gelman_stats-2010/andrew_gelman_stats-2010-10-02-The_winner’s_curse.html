<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>310 andrew gelman stats-2010-10-02-The winner’s curse</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-310" href="#">andrew_gelman_stats-2010-310</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>310 andrew gelman stats-2010-10-02-The winner’s curse</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-310-html" href="http://andrewgelman.com/2010/10/02/the_winners_cur/">html</a></p><p>Introduction: If an estimate is statistically significant, it’s probably an overestimate of the magnitude of your effect.
 
P.S.  I think youall know what I mean here.  But could someone rephrase it in a more pithy manner?  I’d like to include it in our statistical lexicon.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 If an estimate is statistically significant, it’s probably an overestimate of the magnitude of your effect. [sent-1, score-1.106]
</p><p>2 But could someone rephrase it in a more pithy manner? [sent-5, score-0.617]
</p><p>3 I’d like to include it in our statistical lexicon. [sent-6, score-0.318]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('youall', 0.438), ('rephrase', 0.41), ('lexicon', 0.39), ('overestimate', 0.331), ('manner', 0.304), ('magnitude', 0.269), ('statistically', 0.201), ('significant', 0.183), ('include', 0.172), ('probably', 0.154), ('estimate', 0.151), ('mean', 0.138), ('someone', 0.137), ('statistical', 0.093), ('know', 0.078), ('could', 0.07), ('like', 0.053), ('think', 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="310-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-02-The_winner%E2%80%99s_curse.html">310 andrew gelman stats-2010-10-02-The winner’s curse</a></p>
<p>Introduction: If an estimate is statistically significant, it’s probably an overestimate of the magnitude of your effect.
 
P.S.  I think youall know what I mean here.  But could someone rephrase it in a more pithy manner?  I’d like to include it in our statistical lexicon.</p><p>2 0.24066485 <a title="310-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<p>Introduction: I’ve talked about this a bit but it’s never had its own blog entry (until now).
 
Statistically significant findings tend to overestimate the magnitude of effects.  This holds in general (because E(|x|) > |E(x)|) but even more so if you restrict to statistically significant results.
 
Here’s an example.  Suppose a true effect of theta is unbiasedly estimated by y ~ N (theta, 1).  Further suppose that we will only consider statistically significant results, that is, cases in which |y| > 2.
 
The estimate “|y| conditional on |y|>2″ is clearly an overestimate of |theta|.  First off, if |theta|<2, the estimate |y| conditional on statistical significance is not only too high in expectation, it's  always  too high.  This is a problem, given that |theta| is in reality probably is less than 2.  (The low-hangning fruit have already been picked, remember?)
 
But even if |theta|>2, the estimate |y| conditional on statistical significance will still be too high in expectation.
 
For a discussion o</p><p>3 0.16159187 <a title="310-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-%E2%80%9CThe_difference_between_._._.%E2%80%9D%3A__It%E2%80%99s_not_just_p%3D.05_vs._p%3D.06.html">1072 andrew gelman stats-2011-12-19-“The difference between . . .”:  It’s not just p=.05 vs. p=.06</a></p>
<p>Introduction: The title of  this post  by Sanjay Srivastava illustrates an annoying misconception that’s crept into the (otherwise delightful) recent  publicity  related to my  article  with Hal Stern, he difference between “significant” and “not significant” is not itself statistically significant.
 
When people bring this up, they keep referring to the difference between p=0.05 and p=0.06, making the familiar (and correct) point about the arbitrariness of the conventional p-value threshold of 0.05.  And, sure, I agree with this, but everybody knows that already.
 
The point Hal and I were making was that even apparently large differences in p-values are not statistically significant. For example, if you have one study with z=2.5 (almost significant at the 1% level!) and another with z=1 (not statistically significant at all, only 1 se from zero!), then their difference has a z of about 1 (again, not statistically significant at all). So it’s not just a comparison of 0.05 vs. 0.06, even a differenc</p><p>4 0.11241823 <a title="310-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-Type_S_error_rates_for_classical_and_Bayesian_single_and_multiple_comparison_procedures.html">494 andrew gelman stats-2010-12-31-Type S error rates for classical and Bayesian single and multiple comparison procedures</a></p>
<p>Introduction: Type S error:  When your estimate is the wrong sign, compared to the true value of the parameter
 
Type M error:  When the magnitude of your estimate is far off, compared to the true value of the parameter 
  
More here.</p><p>5 0.11024877 <a title="310-tfidf-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-13-%E2%80%9CThe_truth_wears_off%3A__Is_there_something_wrong_with_the_scientific_method%3F%E2%80%9D.html">466 andrew gelman stats-2010-12-13-“The truth wears off:  Is there something wrong with the scientific method?”</a></p>
<p>Introduction: Gur Huberman asks what I think of  this magazine article  by Johah Lehrer (see also  here ).
 
My reply is that it reminds me a bit of what I wrote  here .  Or see  here  for the quick powerpoint version: The short story is that if you screen for statistical significance when estimating small effects, you will necessarily overestimate the magnitudes of effects, sometimes by a huge amount.  I know that Dave Krantz has thought about this issue for awhile; it came up when Francis Tuerlinckx and I wrote our paper on Type S errors, ten years ago.
 
My current thinking is that most (almost all?) research studies of the sort described by Lehrer should be accompanied by retrospective power analyses, or informative Bayesian inferences.  Either of these approaches–whether classical or Bayesian, the key is that they incorporate real prior information, just as is done in a classical prospective power analysis–would, I think, moderate the tendency to overestimate the magnitude of effects.
 
In answ</p><p>6 0.10716295 <a title="310-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-How_does_multilevel_modeling_affect_the_estimate_of_the_grand_mean%3F.html">255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</a></p>
<p>7 0.10179454 <a title="310-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-21-Recently_in_the_sister_blog.html">1866 andrew gelman stats-2013-05-21-Recently in the sister blog</a></p>
<p>8 0.096446976 <a title="310-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-14-The_statistics_and_the_science.html">146 andrew gelman stats-2010-07-14-The statistics and the science</a></p>
<p>9 0.090974644 <a title="310-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-01-Is_that_what_she_said%3F.html">689 andrew gelman stats-2011-05-01-Is that what she said?</a></p>
<p>10 0.082209595 <a title="310-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-22-Top_10_blog_obsessions.html">920 andrew gelman stats-2011-09-22-Top 10 blog obsessions</a></p>
<p>11 0.078987151 <a title="310-tfidf-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-The_myth_of_the_myth_of_the_myth_of_the_hot_hand.html">2243 andrew gelman stats-2014-03-11-The myth of the myth of the myth of the hot hand</a></p>
<p>12 0.078011714 <a title="310-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-08-Silly_old_chi-square%21.html">401 andrew gelman stats-2010-11-08-Silly old chi-square!</a></p>
<p>13 0.076489121 <a title="310-tfidf-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-20-Mailing_List_Degree-of-Difficulty_Difficulty.html">2178 andrew gelman stats-2014-01-20-Mailing List Degree-of-Difficulty Difficulty</a></p>
<p>14 0.076181367 <a title="310-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-14-Subtleties_with_measurement-error_models_for_the_evaluation_of_wacky_claims.html">803 andrew gelman stats-2011-07-14-Subtleties with measurement-error models for the evaluation of wacky claims</a></p>
<p>15 0.075343214 <a title="310-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>16 0.072457924 <a title="310-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-23-Scientists_can_read_your_mind_._._._as_long_as_the%E2%80%99re_allowed_to_look_at_more_than_one_place_in_your_brain_and_then_make_a_prediction_after_seeing_what_you_actually_did.html">106 andrew gelman stats-2010-06-23-Scientists can read your mind . . . as long as the’re allowed to look at more than one place in your brain and then make a prediction after seeing what you actually did</a></p>
<p>17 0.072027892 <a title="310-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-28-Difficulties_of_using_statistical_significance_%28or_lack_thereof%29_to_sift_through_and_compare_research_hypotheses.html">2042 andrew gelman stats-2013-09-28-Difficulties of using statistical significance (or lack thereof) to sift through and compare research hypotheses</a></p>
<p>18 0.067009203 <a title="310-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-02-The_problem_of_overestimation_of_group-level_variance_parameters.html">63 andrew gelman stats-2010-06-02-The problem of overestimation of group-level variance parameters</a></p>
<p>19 0.066534877 <a title="310-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-14-Looking_at_many_comparisons_may_increase_the_risk_of_finding_something_statistically_significant_by_epidemiologists%2C_a_population_with_relatively_low_multilevel_modeling_consumption.html">1059 andrew gelman stats-2011-12-14-Looking at many comparisons may increase the risk of finding something statistically significant by epidemiologists, a population with relatively low multilevel modeling consumption</a></p>
<p>20 0.065992087 <a title="310-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-02-The_inevitable_problems_with_statistical_significance_and_95%25_intervals.html">1150 andrew gelman stats-2012-02-02-The inevitable problems with statistical significance and 95% intervals</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.074), (1, 0.013), (2, 0.032), (3, -0.073), (4, 0.015), (5, -0.03), (6, 0.005), (7, 0.01), (8, 0.002), (9, -0.037), (10, -0.023), (11, -0.027), (12, 0.05), (13, -0.023), (14, 0.019), (15, 0.01), (16, -0.042), (17, 0.002), (18, 0.015), (19, 0.013), (20, 0.011), (21, 0.01), (22, 0.038), (23, 0.0), (24, 0.008), (25, 0.003), (26, 0.009), (27, -0.037), (28, -0.04), (29, -0.07), (30, 0.052), (31, 0.049), (32, -0.017), (33, -0.023), (34, 0.03), (35, 0.024), (36, -0.04), (37, -0.04), (38, -0.013), (39, -0.052), (40, -0.001), (41, -0.001), (42, -0.074), (43, 0.054), (44, 0.017), (45, -0.026), (46, -0.012), (47, -0.005), (48, -0.014), (49, -0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95878428 <a title="310-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-02-The_winner%E2%80%99s_curse.html">310 andrew gelman stats-2010-10-02-The winner’s curse</a></p>
<p>Introduction: If an estimate is statistically significant, it’s probably an overestimate of the magnitude of your effect.
 
P.S.  I think youall know what I mean here.  But could someone rephrase it in a more pithy manner?  I’d like to include it in our statistical lexicon.</p><p>2 0.78703475 <a title="310-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-%E2%80%9CThe_difference_between_._._.%E2%80%9D%3A__It%E2%80%99s_not_just_p%3D.05_vs._p%3D.06.html">1072 andrew gelman stats-2011-12-19-“The difference between . . .”:  It’s not just p=.05 vs. p=.06</a></p>
<p>Introduction: The title of  this post  by Sanjay Srivastava illustrates an annoying misconception that’s crept into the (otherwise delightful) recent  publicity  related to my  article  with Hal Stern, he difference between “significant” and “not significant” is not itself statistically significant.
 
When people bring this up, they keep referring to the difference between p=0.05 and p=0.06, making the familiar (and correct) point about the arbitrariness of the conventional p-value threshold of 0.05.  And, sure, I agree with this, but everybody knows that already.
 
The point Hal and I were making was that even apparently large differences in p-values are not statistically significant. For example, if you have one study with z=2.5 (almost significant at the 1% level!) and another with z=1 (not statistically significant at all, only 1 se from zero!), then their difference has a z of about 1 (again, not statistically significant at all). So it’s not just a comparison of 0.05 vs. 0.06, even a differenc</p><p>3 0.78102171 <a title="310-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<p>Introduction: I’ve talked about this a bit but it’s never had its own blog entry (until now).
 
Statistically significant findings tend to overestimate the magnitude of effects.  This holds in general (because E(|x|) > |E(x)|) but even more so if you restrict to statistically significant results.
 
Here’s an example.  Suppose a true effect of theta is unbiasedly estimated by y ~ N (theta, 1).  Further suppose that we will only consider statistically significant results, that is, cases in which |y| > 2.
 
The estimate “|y| conditional on |y|>2″ is clearly an overestimate of |theta|.  First off, if |theta|<2, the estimate |y| conditional on statistical significance is not only too high in expectation, it's  always  too high.  This is a problem, given that |theta| is in reality probably is less than 2.  (The low-hangning fruit have already been picked, remember?)
 
But even if |theta|>2, the estimate |y| conditional on statistical significance will still be too high in expectation.
 
For a discussion o</p><p>4 0.71496439 <a title="310-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-14-The_statistics_and_the_science.html">146 andrew gelman stats-2010-07-14-The statistics and the science</a></p>
<p>Introduction: Yesterday I  posted  a review of a submitted manuscript where I first wrote that I read the paper only shallowly and then followed up with some suggestions on the statistical analysis, recommending that overdispersion be added to a fitted Posson regression and that the table of regression results be supplemented with a graph showing data and fitted lines.
 
A commenter asked why I wrote such an apparently shallow review, and I realized that some of the implications of my review were not as clear as I’d thought.  So let me clarify.
 
There is a connection between my general reaction and my statistical comments.  My statistical advice here is relevant for (at least) two reasons.  First, a Poisson regression without overdispersion will give nearly-uninterpretable standard errors, which means that I have no sense if the results are statistically significant as claimed.  Second, with a time series plot and regression table, but no graph showing the estimated treatment effect, it is very dif</p><p>5 0.69108438 <a title="310-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-20-Burglars_are_local.html">156 andrew gelman stats-2010-07-20-Burglars are local</a></p>
<p>Introduction: This  makes sense:
 
In the land of fiction, it’s the criminal’s modus operandi – his method of entry, his taste for certain jewellery and so forth – that can be used by detectives to identify his handiwork. The reality according to a new analysis of solved burglaries in the Northamptonshire region of England is that these aspects of criminal behaviour are on their own unreliable as identifying markers, most likely because they are dictated by circumstances rather than the criminal’s taste and style. However, the geographical spread and timing of a burglar’s crimes are distinctive, and could help with police investigations.
 
And, as a bonus,  more  Tourette’s pride!
 
P.S.  On yet another unrelated topic from the same blog, I wonder if the researchers in  this study  are aware that  the difference between “significant” and “not significant” is not itself statistically significant .</p><p>6 0.6557765 <a title="310-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-18-You%E2%80%99ll_get_a_high_Type_S_error_rate_if_you_use_classical_statistical_methods_to_analyze_data_from_underpowered_studies.html">1944 andrew gelman stats-2013-07-18-You’ll get a high Type S error rate if you use classical statistical methods to analyze data from underpowered studies</a></p>
<p>7 0.65527964 <a title="310-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-21-Avoiding_boundary_estimates_in_linear_mixed_models.html">918 andrew gelman stats-2011-09-21-Avoiding boundary estimates in linear mixed models</a></p>
<p>8 0.63356578 <a title="310-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Is_instrumental_variables_analysis_particularly_susceptible_to_Type_M_errors%3F.html">368 andrew gelman stats-2010-10-25-Is instrumental variables analysis particularly susceptible to Type M errors?</a></p>
<p>9 0.63091326 <a title="310-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-02-%E2%80%9CBased_on_my_experiences%2C_I_think_you_could_make_general_progress_by_constructing_a_solution_to_your_specific_problem.%E2%80%9D.html">1441 andrew gelman stats-2012-08-02-“Based on my experiences, I think you could make general progress by constructing a solution to your specific problem.”</a></p>
<p>10 0.61847395 <a title="310-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-14-Subtleties_with_measurement-error_models_for_the_evaluation_of_wacky_claims.html">803 andrew gelman stats-2011-07-14-Subtleties with measurement-error models for the evaluation of wacky claims</a></p>
<p>11 0.6115976 <a title="310-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-13-%E2%80%9CThe_truth_wears_off%3A__Is_there_something_wrong_with_the_scientific_method%3F%E2%80%9D.html">466 andrew gelman stats-2010-12-13-“The truth wears off:  Is there something wrong with the scientific method?”</a></p>
<p>12 0.61143774 <a title="310-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-27-Heat_map.html">593 andrew gelman stats-2011-02-27-Heat map</a></p>
<p>13 0.60708404 <a title="310-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-I_doubt_they_cheated.html">1971 andrew gelman stats-2013-08-07-I doubt they cheated</a></p>
<p>14 0.59968114 <a title="310-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-16-%E2%80%9CFalse-positive_psychology%E2%80%9D.html">1171 andrew gelman stats-2012-02-16-“False-positive psychology”</a></p>
<p>15 0.59584421 <a title="310-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-02-So-called_Bayesian_hypothesis_testing_is_just_as_bad_as_regular_hypothesis_testing.html">643 andrew gelman stats-2011-04-02-So-called Bayesian hypothesis testing is just as bad as regular hypothesis testing</a></p>
<p>16 0.58750206 <a title="310-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-05-How_much_do_we_trust_a_new_claim_that_early_childhood_stimulation_raised_earnings_by_42%25%3F.html">2090 andrew gelman stats-2013-11-05-How much do we trust a new claim that early childhood stimulation raised earnings by 42%?</a></p>
<p>17 0.58539385 <a title="310-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-12-Question_2_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1315 andrew gelman stats-2012-05-12-Question 2 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>18 0.58500648 <a title="310-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-23-Scientists_can_read_your_mind_._._._as_long_as_the%E2%80%99re_allowed_to_look_at_more_than_one_place_in_your_brain_and_then_make_a_prediction_after_seeing_what_you_actually_did.html">106 andrew gelman stats-2010-06-23-Scientists can read your mind . . . as long as the’re allowed to look at more than one place in your brain and then make a prediction after seeing what you actually did</a></p>
<p>19 0.58207405 <a title="310-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-04-Statistics_ethics_question.html">695 andrew gelman stats-2011-05-04-Statistics ethics question</a></p>
<p>20 0.58084303 <a title="310-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-18-Question_on_Type_M_errors.html">963 andrew gelman stats-2011-10-18-Question on Type M errors</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.039), (24, 0.213), (45, 0.394), (99, 0.147)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.8744747 <a title="310-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-06-Statistical_inference_and_the_secret_ballot.html">1407 andrew gelman stats-2012-07-06-Statistical inference and the secret ballot</a></p>
<p>Introduction: Ring Lardner, Jr.:
  
[In 1936] I was already settled in Southern California, and it may have been that first exercise of the franchise that triggered the FBI surveillance of me that would last for decades.  I had assumed, of course, that I was enjoying the vaunted American privilege of the secret ballot.  On a wall outside my polling place on Wilshire Boulevard, however, was a compilation of the district’s registered voters:  Democrats, a long list of names; Republicans, a somewhat lesser number; and “Declines to State,” one, “Ring W. Lardner, Jr.”  The day after the election, alongside those lists were published the results:  Roosevelt, so many; Landon, so many; Browder, one.</p><p>2 0.83321732 <a title="310-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-28-Escalatingly_uncomfortable.html">1873 andrew gelman stats-2013-05-28-Escalatingly uncomfortable</a></p>
<p>Introduction: Aggressive, fizzing nonconformity .</p><p>3 0.82293582 <a title="310-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-09-I_was_at_a_meeting_a_couple_months_ago_._._..html">999 andrew gelman stats-2011-11-09-I was at a meeting a couple months ago . . .</a></p>
<p>Introduction: . . . and I decided to amuse myself by writing down all the management-speak words I heard:
 
“grappling” 
“early prototypes” 
“technology platform” 
“building block” 
“machine learning” 
“your team” 
“workspace” 
“tagging” 
“data exhaust” 
“monitoring a particular population” 
“collective intelligence” 
“communities of practice” 
“hackathon” 
“human resources . . . technologies”
 
Any one or two or three of these phrases might be fine, but put them all together and what you have is a festival of jargon.  A hackathon, indeed.</p><p>same-blog 4 0.75791442 <a title="310-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-02-The_winner%E2%80%99s_curse.html">310 andrew gelman stats-2010-10-02-The winner’s curse</a></p>
<p>Introduction: If an estimate is statistically significant, it’s probably an overestimate of the magnitude of your effect.
 
P.S.  I think youall know what I mean here.  But could someone rephrase it in a more pithy manner?  I’d like to include it in our statistical lexicon.</p><p>5 0.74542105 <a title="310-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-28-NYT_shills_for_personal_DNA_tests.html">543 andrew gelman stats-2011-01-28-NYT shills for personal DNA tests</a></p>
<p>Introduction: Kaiser  nails it .  The offending  article , by John Tierney, somehow ended up in the Science section rather than the Opinion section.  As an opinion piece (or, for that matter, a blog), Tierney’s article would be nothing special.  But I agree with Kaiser that it doesn’t work as a newspaper article.  As Kaiser notes, this story involves a bunch of statistical and empirical claims that are not well resolved by P.R. and rhetoric.</p><p>6 0.72988665 <a title="310-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-08-Censoring_on_one_end%2C_%E2%80%9Coutliers%E2%80%9D_on_the_other%2C_what_can_we_do_with_the_middle%3F.html">791 andrew gelman stats-2011-07-08-Censoring on one end, “outliers” on the other, what can we do with the middle?</a></p>
<p>7 0.69990933 <a title="310-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-17-More_on_the_difficulty_of_%E2%80%9Cpreaching_what_you_practice%E2%80%9D.html">1325 andrew gelman stats-2012-05-17-More on the difficulty of “preaching what you practice”</a></p>
<p>8 0.69323194 <a title="310-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-28-Path_sampling_for_models_of_varying_dimension.html">1089 andrew gelman stats-2011-12-28-Path sampling for models of varying dimension</a></p>
<p>9 0.69113195 <a title="310-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-26-A_good_comment_on_one_of_my_papers.html">2225 andrew gelman stats-2014-02-26-A good comment on one of my papers</a></p>
<p>10 0.69074935 <a title="310-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-14-Uh-oh.html">612 andrew gelman stats-2011-03-14-Uh-oh</a></p>
<p>11 0.68274736 <a title="310-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-13-Indiemapper_makes_thematic_mapping_easy.html">206 andrew gelman stats-2010-08-13-Indiemapper makes thematic mapping easy</a></p>
<p>12 0.67800188 <a title="310-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-27-Richard_Stallman_and_John_McCarthy.html">1031 andrew gelman stats-2011-11-27-Richard Stallman and John McCarthy</a></p>
<p>13 0.65427208 <a title="310-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-04-A_Wikipedia_whitewash.html">69 andrew gelman stats-2010-06-04-A Wikipedia whitewash</a></p>
<p>14 0.65328979 <a title="310-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>15 0.64778382 <a title="310-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-28-History_is_too_important_to_be_left_to_the_history_professors.html">2189 andrew gelman stats-2014-01-28-History is too important to be left to the history professors</a></p>
<p>16 0.6328851 <a title="310-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-20-Could_someone_please_lock_this_guy_and_Niall_Ferguson_in_a_room_together%3F.html">1504 andrew gelman stats-2012-09-20-Could someone please lock this guy and Niall Ferguson in a room together?</a></p>
<p>17 0.63042396 <a title="310-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-16-Blog_bribes%21.html">1012 andrew gelman stats-2011-11-16-Blog bribes!</a></p>
<p>18 0.62809861 <a title="310-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-07-Free_advice_from_an_academic_writing_coach%21.html">1658 andrew gelman stats-2013-01-07-Free advice from an academic writing coach!</a></p>
<p>19 0.62743032 <a title="310-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-14-Hipmunk_%3C_Expedia%2C_again.html">573 andrew gelman stats-2011-02-14-Hipmunk < Expedia, again</a></p>
<p>20 0.62408227 <a title="310-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-Upper-income_people_still_don%E2%80%99t_realize_they%E2%80%99re_upper-income.html">673 andrew gelman stats-2011-04-20-Upper-income people still don’t realize they’re upper-income</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
