<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-255" href="#">andrew_gelman_stats-2010-255</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-255-html" href="http://andrewgelman.com/2010/09/04/how_does_multil/">html</a></p><p>Introduction: Subhadeep Mukhopadhyay writes:
  
I am convinced of the power of hierarchical modeling and individual parameter pooling concept. I was wondering how could multi-level modeling could influence the estimate of grad mean (NOT individual label).
  
My reply:  Multilevel modeling will affect the estimate of the grand mean in two ways:
 
1.  If the group-level mean is correlated with group size, then the partial pooling will change the estimate of the grand mean (and, indeed, you might want to include group size or some similar variable as a group-level predictor.
 
2.  In any case, the extra error term(s) in a multilevel model will typically affect the standard error of everything, including the estimate of the grand mean.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Subhadeep Mukhopadhyay writes:    I am convinced of the power of hierarchical modeling and individual parameter pooling concept. [sent-1, score-1.138]
</p><p>2 I was wondering how could multi-level modeling could influence the estimate of grad mean (NOT individual label). [sent-2, score-1.511]
</p><p>3 My reply:  Multilevel modeling will affect the estimate of the grand mean in two ways:   1. [sent-3, score-1.58]
</p><p>4 If the group-level mean is correlated with group size, then the partial pooling will change the estimate of the grand mean (and, indeed, you might want to include group size or some similar variable as a group-level predictor. [sent-4, score-2.876]
</p><p>5 In any case, the extra error term(s) in a multilevel model will typically affect the standard error of everything, including the estimate of the grand mean. [sent-6, score-1.891]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('grand', 0.447), ('mean', 0.327), ('pooling', 0.298), ('estimate', 0.286), ('modeling', 0.239), ('affect', 0.238), ('multilevel', 0.191), ('size', 0.187), ('individual', 0.169), ('group', 0.166), ('error', 0.162), ('label', 0.143), ('convinced', 0.139), ('grad', 0.138), ('partial', 0.133), ('extra', 0.127), ('correlated', 0.118), ('influence', 0.11), ('wondering', 0.108), ('parameter', 0.099), ('hierarchical', 0.099), ('term', 0.098), ('power', 0.095), ('variable', 0.094), ('typically', 0.088), ('everything', 0.086), ('include', 0.082), ('ways', 0.082), ('change', 0.08), ('similar', 0.077), ('indeed', 0.074), ('including', 0.073), ('standard', 0.072), ('could', 0.067), ('reply', 0.067), ('case', 0.049), ('want', 0.047), ('model', 0.045), ('two', 0.043), ('might', 0.041), ('writes', 0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="255-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-How_does_multilevel_modeling_affect_the_estimate_of_the_grand_mean%3F.html">255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</a></p>
<p>Introduction: Subhadeep Mukhopadhyay writes:
  
I am convinced of the power of hierarchical modeling and individual parameter pooling concept. I was wondering how could multi-level modeling could influence the estimate of grad mean (NOT individual label).
  
My reply:  Multilevel modeling will affect the estimate of the grand mean in two ways:
 
1.  If the group-level mean is correlated with group size, then the partial pooling will change the estimate of the grand mean (and, indeed, you might want to include group size or some similar variable as a group-level predictor.
 
2.  In any case, the extra error term(s) in a multilevel model will typically affect the standard error of everything, including the estimate of the grand mean.</p><p>2 0.17473516 <a title="255-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-Type_S_error_rates_for_classical_and_Bayesian_single_and_multiple_comparison_procedures.html">494 andrew gelman stats-2010-12-31-Type S error rates for classical and Bayesian single and multiple comparison procedures</a></p>
<p>Introduction: Type S error:  When your estimate is the wrong sign, compared to the true value of the parameter
 
Type M error:  When the magnitude of your estimate is far off, compared to the true value of the parameter 
  
More here.</p><p>3 0.17363022 <a title="255-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>Introduction: Vlad Kogan writes:
  
I’ve using your book on regression and multilevel modeling and have a quick R question for you. Do you happen to know if there is any R package that can estimate a two-stage (instrumental variable) multi-level model?
  
My reply:  I don’t know.  I’ll post on blog and maybe there will be a response.  You could also try the R help list.</p><p>4 0.16854015 <a title="255-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>Introduction: James O’Brien writes:
  
How would you explain, to a “classically-trained” hypothesis-tester, that “It’s OK to fit a multilevel model even if some groups have only one observation each”?


I [O'Brien] think I understand the logic and the statistical principles at work in this, but I’ve having trouble being clear and persuasive. I also feel like I’m contending with some methodological conventional wisdom here. 
  
My reply:  I’m so used to this idea that I find it difficult to defend it in some sort of general conceptual way.  So let me retreat to a more functional defense, which is that multilevel modeling gives good estimates,  especially  when the number of observations per group is small.
 
One way to see this in any particular example in through cross-validation.  Another way is to consider the alternatives.   If you try really hard you can come up with a “classical hypothesis testing” approach which will do as well as the multilevel model.  It would just take a lot of work.  I’d r</p><p>5 0.16817093 <a title="255-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>Introduction: There are a few things I want to do:
 
1.  Understand a fitted model using tools such as  average predictive comparisons ,  R-squared, and partial pooling factors .  In defining these concepts, Iain and I came up with some clever tricks, including (but not limited to):
 
- Separating the inputs and averaging over all possible values of the input not being altered (for average predictive comparisons);
 
- Defining partial pooling  without  referring to a raw-data or maximum-likelihood or no-pooling estimate (these don’t necessarily exist when you’re fitting logistic regression with sparse data);
 
- Defining an R-squared for each level of a multilevel model.
 
The methods get pretty complicated, though, and they have some loose ends–in particular, for average predictive comparisons with continuous input variables.
 
So now we want to implement these in R and put them into arm along with bglmer etc.
 
2.  Setting up coefplot so it works more generally (that is, so the graphics look nice</p><p>6 0.1629688 <a title="255-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-23-Of_home_runs_and_grand_slams.html">47 andrew gelman stats-2010-05-23-Of home runs and grand slams</a></p>
<p>7 0.15670685 <a title="255-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>8 0.15466425 <a title="255-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>9 0.14518447 <a title="255-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>10 0.14350152 <a title="255-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-U-Haul_statistics.html">318 andrew gelman stats-2010-10-04-U-Haul statistics</a></p>
<p>11 0.14254722 <a title="255-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>12 0.14206243 <a title="255-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-11-That_xkcd_cartoon_on_multiple_comparisons_that_all_of_you_were_sending_me_a_couple_months_ago.html">848 andrew gelman stats-2011-08-11-That xkcd cartoon on multiple comparisons that all of you were sending me a couple months ago</a></p>
<p>13 0.13931665 <a title="255-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-23-Examples_of_the_use_of_hierarchical_modeling_to_generalize_to_new_settings.html">1425 andrew gelman stats-2012-07-23-Examples of the use of hierarchical modeling to generalize to new settings</a></p>
<p>14 0.12933406 <a title="255-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>15 0.12882829 <a title="255-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-That_half-Cauchy_prior.html">184 andrew gelman stats-2010-08-04-That half-Cauchy prior</a></p>
<p>16 0.12496674 <a title="255-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-02-%E2%80%9CBased_on_my_experiences%2C_I_think_you_could_make_general_progress_by_constructing_a_solution_to_your_specific_problem.%E2%80%9D.html">1441 andrew gelman stats-2012-08-02-“Based on my experiences, I think you could make general progress by constructing a solution to your specific problem.”</a></p>
<p>17 0.12489819 <a title="255-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>18 0.11986041 <a title="255-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<p>19 0.1144755 <a title="255-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>20 0.11084147 <a title="255-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-27-Question_17_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1348 andrew gelman stats-2012-05-27-Question 17 of my final exam for Design and Analysis of Sample Surveys</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.14), (1, 0.116), (2, 0.114), (3, -0.072), (4, 0.087), (5, 0.046), (6, 0.01), (7, -0.036), (8, 0.039), (9, 0.063), (10, 0.002), (11, -0.035), (12, 0.04), (13, 0.037), (14, 0.006), (15, 0.003), (16, -0.082), (17, -0.012), (18, 0.016), (19, -0.003), (20, 0.001), (21, -0.014), (22, 0.063), (23, 0.029), (24, -0.02), (25, -0.079), (26, -0.035), (27, 0.004), (28, -0.097), (29, -0.067), (30, -0.038), (31, 0.039), (32, -0.017), (33, -0.046), (34, 0.002), (35, 0.004), (36, -0.001), (37, -0.045), (38, 0.053), (39, -0.005), (40, -0.04), (41, 0.003), (42, -0.095), (43, -0.082), (44, -0.09), (45, 0.031), (46, 0.072), (47, 0.043), (48, -0.124), (49, -0.02)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99408168 <a title="255-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-How_does_multilevel_modeling_affect_the_estimate_of_the_grand_mean%3F.html">255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</a></p>
<p>Introduction: Subhadeep Mukhopadhyay writes:
  
I am convinced of the power of hierarchical modeling and individual parameter pooling concept. I was wondering how could multi-level modeling could influence the estimate of grad mean (NOT individual label).
  
My reply:  Multilevel modeling will affect the estimate of the grand mean in two ways:
 
1.  If the group-level mean is correlated with group size, then the partial pooling will change the estimate of the grand mean (and, indeed, you might want to include group size or some similar variable as a group-level predictor.
 
2.  In any case, the extra error term(s) in a multilevel model will typically affect the standard error of everything, including the estimate of the grand mean.</p><p>2 0.8173157 <a title="255-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>Introduction: Alex Hoffman points me to  this interview  by Dylan Matthews of education researcher Thomas Kane, who at one point says,
  
Once you corrected for measurement error, a teacher’s score on their chosen videos and on their unchosen videos were correlated at 1. They were perfectly correlated.
  
Hoffman asks, “What do you think? Do you think that just maybe, perhaps, it’s possible we aught to consider, I’m just throwing out the possibility that it might be that the procedure for correcting measurement error might, you now, be a little too strong?”
 
I don’t know exactly what’s happening here, but it might be something that I’ve seen on occasion when fitting multilevel models using a point estimate for the group-level variance.  It goes like this:  measurement-error models are multilevel models, they involve the estimation of a distribution of a latent variable.  When fitting multilevel models, it is possible to estimate the group-level variance to be zero, even though the group-level varia</p><p>3 0.70223379 <a title="255-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>Introduction: Lee Mobley writes:
  
I recently read what you posted on your blog  How does statistical analysis differ when analyzing the entire population rather than a sample? 


What you said in the blog accords with my training in econometrics.  However I am concerned about a new wrinkle on this problem that derives from multilevel modeling.
      
We are analyzing multilevel models of the probability of using cancer screening for the entire Medicare population. I argue that every state has different systems in place (politics, cancer control efforts, culture, insurance regulations, etc) so that essentially a different probability generating mechanism is in place for each state. Thus I estimate 50 separate regressions for the populations in each state, and then note and map the variability in the effect estimates (slope parameters) for each covariate.


Reviewers argue that I should be using random slopes modeling, pooling all individuals in all states together. I am familiar with this approach</p><p>4 0.66635895 <a title="255-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>Introduction: Joshua Vogelstein asks for my thoughts as  a Bayesian on the above topic.  So here they are (briefly):
 
The concept of the bias-variance tradeoff can be useful if you don’t take it too seriously.  The basic idea is as follows:  if you’re estimating something, you can slice your data finer and finer, or perform more and more adjustments, each time getting a purer—and less biased—estimate.  But each subdivision or each adjustment reduces your sample size or increases potential estimation error, hence the variance of your estimate goes up.
 
That story is real.  In lots and lots of examples, there’s a continuum between a completely unadjusted general estimate (high bias, low variance) and a specific, focused, adjusted estimate (low bias, high variance).
 
Suppose, for example, you’re using data from a large experiment to estimate the effect of a treatment on a fairly narrow group, say, white men between the ages of 45 and 50.  At one extreme, you could just take the estimated treatment e</p><p>5 0.66110623 <a title="255-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-A_mess_with_which_I_am_comfortable.html">1814 andrew gelman stats-2013-04-20-A mess with which I am comfortable</a></p>
<p>Introduction: Having established that survey weighting is a mess, I should also acknowledge that, by this standard, regression modeling is also a mess, involving many arbitrary choices of variable selection, transformations and modeling of interaction. Nonetheless, regression modeling is a mess with which I am comfortable and, perhaps more relevant to the discussion, can be extended using multilevel models to get inference for small cross-classifications or small areas. 
  
Weâ&euro;&trade;re working on it.</p><p>6 0.64486217 <a title="255-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Sof%5Bt%5D.html">77 andrew gelman stats-2010-06-09-Sof[t]</a></p>
<p>7 0.64025033 <a title="255-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-02-%E2%80%9CBased_on_my_experiences%2C_I_think_you_could_make_general_progress_by_constructing_a_solution_to_your_specific_problem.%E2%80%9D.html">1441 andrew gelman stats-2012-08-02-“Based on my experiences, I think you could make general progress by constructing a solution to your specific problem.”</a></p>
<p>8 0.64021605 <a title="255-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>9 0.63661325 <a title="255-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>10 0.62392443 <a title="255-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>11 0.62363219 <a title="255-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-10-Combining_data_from_many_sources.html">948 andrew gelman stats-2011-10-10-Combining data from many sources</a></p>
<p>12 0.62238532 <a title="255-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-Type_S_error_rates_for_classical_and_Bayesian_single_and_multiple_comparison_procedures.html">494 andrew gelman stats-2010-12-31-Type S error rates for classical and Bayesian single and multiple comparison procedures</a></p>
<p>13 0.62154871 <a title="255-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>14 0.61990762 <a title="255-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Multilevel_quantile_regression.html">397 andrew gelman stats-2010-11-06-Multilevel quantile regression</a></p>
<p>15 0.60960072 <a title="255-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>16 0.60544658 <a title="255-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>17 0.60469031 <a title="255-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>18 0.59477091 <a title="255-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>19 0.59286779 <a title="255-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>20 0.59119177 <a title="255-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.019), (16, 0.091), (24, 0.102), (65, 0.024), (68, 0.072), (69, 0.023), (89, 0.039), (99, 0.483)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99588734 <a title="255-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-How_does_multilevel_modeling_affect_the_estimate_of_the_grand_mean%3F.html">255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</a></p>
<p>Introduction: Subhadeep Mukhopadhyay writes:
  
I am convinced of the power of hierarchical modeling and individual parameter pooling concept. I was wondering how could multi-level modeling could influence the estimate of grad mean (NOT individual label).
  
My reply:  Multilevel modeling will affect the estimate of the grand mean in two ways:
 
1.  If the group-level mean is correlated with group size, then the partial pooling will change the estimate of the grand mean (and, indeed, you might want to include group size or some similar variable as a group-level predictor.
 
2.  In any case, the extra error term(s) in a multilevel model will typically affect the standard error of everything, including the estimate of the grand mean.</p><p>2 0.98870194 <a title="255-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-16-Female_Mass_Murderers%3A__Babes_Behind_Bars.html">36 andrew gelman stats-2010-05-16-Female Mass Murderers:  Babes Behind Bars</a></p>
<p>Introduction: Around the time I was finishing up my Ph.D. thesis, I was trying to come up with a good title–something more grabby than “Topics in Image Reconstruction for Emission Tomography”–and one of the other students said:  How about something iike, Female Mass Murderers:  Babes Behind Bars?  That sounded good to me, and I was all set to use it.  I had a plan:  I’d first submit the one the boring title–that’s how it would be recorded in all the official paperwork–but then at the last minute I’d substitute in the new title page before submitting to the library.  (This was in the days of hard copies.)  Nobody would look at the time, then later on, if anyone went into the library to find my thesis, they’d have a pleasant surprise.  Anyway, as I said, I was all set to do this, but a friend warned me off.  He said that at some point, someone might find it, and the rumor would spread that I’m a sexist pig.  So I didn’t.
 
I was thinking about this after hearing  this report  based on a reading of Sup</p><p>3 0.98480505 <a title="255-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-14-The_General_Social_Survey_is_a_great_resource.html">958 andrew gelman stats-2011-10-14-The General Social Survey is a great resource</a></p>
<p>Introduction: See, for example,  this report  by Deborah Carr on changing attitudes about marital infidelity:
 
   
 
Two great things about the General Social Survey are:  (1) the data are freely available  online , and (2) the same questions have been asked since 1972 so you get a nice long series.</p><p>4 0.98052388 <a title="255-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-18-How_to_teach_methods_we_don%E2%80%99t_like%3F.html">1582 andrew gelman stats-2012-11-18-How to teach methods we don’t like?</a></p>
<p>Introduction: April Galyardt writes:
  
I’m teaching my first graduate class this semester. It’s intro stats for graduate students in the college of education. Most of the students are first year PhD students. Though, there are a number of master’s students who are primarily in-service teachers. The difficulties with teaching an undergraduate intro stats course are still present, in that mathematical preparation and phobia vary widely across the class.


I’ve been enjoying the class and the students, but I’d like your take on an issue I’ve been thinking about. How do I balance teaching the standard methods, like hypothesis testing, that these future researchers have to know because they are so standard, with discussing the problems with those methods (e.g.  p-value as a measure of sample size , and  the decline effect , not to mention multiple testing and other common mistakes). It feels a bit like saying “Ok here’s what everybody does, but really it’s broken” and then there’s not enough time to tal</p><p>5 0.98035055 <a title="255-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-21-Estimating_and_reporting_teacher_effectivenss%3A__Newspaper_researchers_do_things_that_academic_researchers_never_could.html">222 andrew gelman stats-2010-08-21-Estimating and reporting teacher effectivenss:  Newspaper researchers do things that academic researchers never could</a></p>
<p>Introduction: Alex Tabarrok  reports  on  an analysis  from the Los Angeles Times of teacher performance (as measured by so-called value-added analysis, which is basically compares teachers based on their students’ average test scores at the end of the year, after controlling for pre-test scores.
 
It’s well known that some teachers are much better than others, but, as Alex points out, what’s striking about the L.A. Times study is that they are publishing the estimates for  individual teachers .  For example, this:
 
 
 
Nice graphics, too.
  

 
To me, this illustrates one of the big advantages of research in a non-academic environment.  If you’re writing an article for the L.A. Times, you can do what you want (within the limits of the law).  If you’re doing the same research study at a university, there are a million restrictions.  For example, from an  official documen t, “The primary purpose of an Institutional Review Board (IRB) is to protect the rights and welfare of human subjects participati</p><p>6 0.9803012 <a title="255-lda-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-19-How_Americans_vote.html">2255 andrew gelman stats-2014-03-19-How Americans vote</a></p>
<p>7 0.98013735 <a title="255-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-01-Doing_Data_Science%3A__What%E2%80%99s_it_all_about%3F.html">2084 andrew gelman stats-2013-11-01-Doing Data Science:  What’s it all about?</a></p>
<p>8 0.97971445 <a title="255-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-10-Controversy_over_the_Christakis-Fowler_findings_on_the_contagion_of_obesity.html">757 andrew gelman stats-2011-06-10-Controversy over the Christakis-Fowler findings on the contagion of obesity</a></p>
<p>9 0.97933817 <a title="255-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-19-Data_exploration_and_multiple_comparisons.html">524 andrew gelman stats-2011-01-19-Data exploration and multiple comparisons</a></p>
<p>10 0.97925103 <a title="255-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>11 0.97922498 <a title="255-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-07-Looking_for_a_purpose_in_life%3A__Update_on_that_underworked_and_overpaid_sociologist_whose_%E2%80%9Cmain_task_as_a_university_professor_was_self-cultivation%E2%80%9D.html">750 andrew gelman stats-2011-06-07-Looking for a purpose in life:  Update on that underworked and overpaid sociologist whose “main task as a university professor was self-cultivation”</a></p>
<p>12 0.97915977 <a title="255-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-28-Using_randomized_incentives_as_an_instrument_for_survey_nonresponse%3F.html">2152 andrew gelman stats-2013-12-28-Using randomized incentives as an instrument for survey nonresponse?</a></p>
<p>13 0.97872567 <a title="255-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Modeling_probability_data.html">1284 andrew gelman stats-2012-04-26-Modeling probability data</a></p>
<p>14 0.97871208 <a title="255-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-01-Looking_for_a_textbook_for_a_two-semester_course_in_probability_and_%28theoretical%29_statistics.html">596 andrew gelman stats-2011-03-01-Looking for a textbook for a two-semester course in probability and (theoretical) statistics</a></p>
<p>15 0.97853124 <a title="255-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-27-Historian_and_journalist_slug_it_out.html">1030 andrew gelman stats-2011-11-27-Historian and journalist slug it out</a></p>
<p>16 0.97838086 <a title="255-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-01-%E2%80%9COn_Inspiring_Students_and_Being_Human%E2%80%9D.html">1517 andrew gelman stats-2012-10-01-“On Inspiring Students and Being Human”</a></p>
<p>17 0.97813958 <a title="255-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-13-Lame_Statistics_Patents.html">1761 andrew gelman stats-2013-03-13-Lame Statistics Patents</a></p>
<p>18 0.97798836 <a title="255-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-02-Fragment_of_statistical_autobiography.html">390 andrew gelman stats-2010-11-02-Fragment of statistical autobiography</a></p>
<p>19 0.97795397 <a title="255-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Misunderstanding_of_divided_government.html">369 andrew gelman stats-2010-10-25-Misunderstanding of divided government</a></p>
<p>20 0.97783905 <a title="255-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-18-Should_we_always_be_using_the_t_and_robit_instead_of_the_normal_and_logit%3F.html">773 andrew gelman stats-2011-06-18-Should we always be using the t and robit instead of the normal and logit?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
