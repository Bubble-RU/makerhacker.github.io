<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-254" href="#">andrew_gelman_stats-2010-254</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-254-html" href="http://andrewgelman.com/2010/09/04/bayesian_infere_5/">html</a></p><p>Introduction: Dave Armstrong writes:
  
 
I have a hopefully quick question about Multilevel Models . . . While being Bayesian would make the attached question [having to do with calculating confidence intervals for linear combinations of fixed and varying coefficents] moot, and I am certainly sympathetic in my own work, I am looking to understand the Frequentist perspective as I need to explain how to do this in R to people without experience in WinBUGS and who are generally uninterested in gaining such experience.
 

 
My reply:
 
This sort of thing happens to me all the time, which is one reason I try to do these inferences using simulations, so I donâ&euro;&trade;t have to keep track of covariances.  The simulation-based Bayes inferences can be interpreted as classical freq inferences; to put it another way, the Bayesian inference can be thought of as a computational trick to work with the multivariate normal and t distributions that arise in classical confidence intervals.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Dave Armstrong writes:      I have a hopefully quick question about Multilevel Models . [sent-1, score-0.375]
</p><p>2 My reply:   This sort of thing happens to me all the time, which is one reason I try to do these inferences using simulations, so I donâ&euro;&trade;t have to keep track of covariances. [sent-5, score-0.784]
</p><p>3 The simulation-based Bayes inferences can be interpreted as classical freq inferences; to put it another way, the Bayesian inference can be thought of as a computational trick to work with the multivariate normal and t distributions that arise in classical confidence intervals. [sent-6, score-2.293]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('inferences', 0.338), ('intervals', 0.246), ('freq', 0.232), ('confidence', 0.222), ('classical', 0.215), ('uninterested', 0.202), ('winbugs', 0.196), ('gaining', 0.196), ('armstrong', 0.186), ('combinations', 0.17), ('hopefully', 0.17), ('calculating', 0.163), ('sympathetic', 0.148), ('dave', 0.148), ('trick', 0.14), ('interpreted', 0.138), ('multivariate', 0.137), ('attached', 0.136), ('simulations', 0.133), ('frequentist', 0.13), ('varying', 0.128), ('track', 0.126), ('bayesian', 0.12), ('arise', 0.118), ('computational', 0.117), ('question', 0.11), ('fixed', 0.109), ('normal', 0.107), ('distributions', 0.103), ('linear', 0.103), ('bayes', 0.102), ('happens', 0.099), ('multilevel', 0.096), ('quick', 0.095), ('explain', 0.093), ('experience', 0.091), ('perspective', 0.089), ('certainly', 0.087), ('keep', 0.082), ('generally', 0.081), ('work', 0.079), ('looking', 0.074), ('inference', 0.074), ('reason', 0.071), ('understand', 0.068), ('try', 0.068), ('reply', 0.067), ('without', 0.06), ('need', 0.059), ('put', 0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="254-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Bayesian_inference_viewed_as_a_computational_approximation_to_classical_calculations.html">254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</a></p>
<p>Introduction: Dave Armstrong writes:
  
 
I have a hopefully quick question about Multilevel Models . . . While being Bayesian would make the attached question [having to do with calculating confidence intervals for linear combinations of fixed and varying coefficents] moot, and I am certainly sympathetic in my own work, I am looking to understand the Frequentist perspective as I need to explain how to do this in R to people without experience in WinBUGS and who are generally uninterested in gaining such experience.
 

 
My reply:
 
This sort of thing happens to me all the time, which is one reason I try to do these inferences using simulations, so I donâ&euro;&trade;t have to keep track of covariances.  The simulation-based Bayes inferences can be interpreted as classical freq inferences; to put it another way, the Bayesian inference can be thought of as a computational trick to work with the multivariate normal and t distributions that arise in classical confidence intervals.</p><p>2 0.2278506 <a title="254-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-21-Instead_of_%E2%80%9Cconfidence_interval%2C%E2%80%9D_let%E2%80%99s_say_%E2%80%9Cuncertainty_interval%E2%80%9D.html">480 andrew gelman stats-2010-12-21-Instead of “confidence interval,” let’s say “uncertainty interval”</a></p>
<p>Introduction: I’ve become increasingly uncomfortable with the term “confidence interval,” for several reasons:
 
- The well-known difficulties in interpretation (officially the confidence statement can be interpreted only on average, but people typically implicitly give the Bayesian interpretation to each case),
 
- The ambiguity between confidence intervals and predictive intervals.  (See the footnote in BDA where we discuss the difference between “inference” and “prediction” in the classical framework.)
 
- The awkwardness of explaining that confidence intervals are big in noisy situations where you have  less  confidence, and confidence intervals are small when you have  more  confidence.
 
So here’s my proposal.  Let’s use the term “uncertainty interval” instead.  The uncertainty interval tells you how much uncertainty you have.  That works pretty well, I think.
 
P.S.  As of this writing, “confidence interval” outGoogles “uncertainty interval” by the huge margin of 9.5 million to 54000.  So we</p><p>3 0.17775686 <a title="254-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bayes_at_the_end.html">534 andrew gelman stats-2011-01-24-Bayes at the end</a></p>
<p>Introduction: John Cook  noticed something :
  
I [Cook] was looking at the preface of an old statistics book and read this:

 
The Bayesian techniques occur at the end of each chapter; therefore they can be omitted if time does not permit their inclusion.
 

This approach is typical. Many textbooks present frequentist statistics with a little Bayesian statistics at the end of each section or at the end of the book.


There are a couple ways to look at that. One is simply that Bayesian methods are optional. They must not be that important or theyâ&euro;&trade;d get more space. The author even recommends dropping them if pressed for time.


Another way to look at this is that Bayesian statistics must be simpler than frequentist statistics since the Bayesian approach to each task requires fewer pages.
  
My reaction:
 
Classical statistics is all about summarizing the data.
 
Bayesian statistics is data + prior information.
 
On those grounds alone, Bayes is more complicated, and it makes sense to do classical sta</p><p>4 0.16223335 <a title="254-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>Introduction: I sent Deborah Mayo a link to  my paper  with Cosma Shalizi on the philosophy of statistics, and she sent me the link to this conference which unfortunately already occurred.  (It’s too bad, because I’d have liked to have been there.)  I summarized my philosophy as follows:
  
I am highly sympathetic to the approach of Lakatos (or of Popper, if you consider Lakatos’s “Popper_2″ to be a reasonable simulation of the true Popperism), in that (a) I view statistical models as being built within theoretical structures, and (b) I see the checking and refutation of models to be a key part of scientific progress.  A big problem I have with mainstream Bayesianism is its “inductivist” view that science can operate completely smoothly with posterior updates:  the idea that new data causes us to increase the posterior probability of good models and decrease the posterior probability of bad models.  I don’t buy that:  I see models as ever-changing entities that are flexible and can be patched and ex</p><p>5 0.1591419 <a title="254-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-25-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">870 andrew gelman stats-2011-08-25-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>Introduction: Peter Bergman points me to  this discussion  from Cyrus of  a presentation  by Guido Imbens on design of randomized experiments.
 
Cyrus writes:
  
The standard analysis that Imbens proposes includes (1) a Fisher-type permutation test of the sharp null hypothesis–what Imbens referred to as “testing”–along with a (2) Neyman-type point estimate of the sample average treatment effect and confidence interval–what Imbens referred to as “estimation.” . . .


Imbens claimed that testing and estimation are separate enterprises with separate goals and that the two should not be confused. I [Cyrus] took it as a warning against proposals that use “inverted” tests in order to produce point estimates and confidence intervals. There is no reason that such confidence intervals will have accurate coverage except under rather dire assumptions, meaning that they are not “confidence intervals” in the way that we usually think of them.
  
I agree completely.  This is something I’ve been saying for a long</p><p>6 0.15812646 <a title="254-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-24-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">1913 andrew gelman stats-2013-06-24-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>7 0.14978528 <a title="254-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-10-95%25_intervals_that_I_don%E2%80%99t_believe%2C_because_they%E2%80%99re_from_a_flat_prior_I_don%E2%80%99t_believe.html">1206 andrew gelman stats-2012-03-10-95% intervals that I don’t believe, because they’re from a flat prior I don’t believe</a></p>
<p>8 0.14147067 <a title="254-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>9 0.13492493 <a title="254-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<p>10 0.12883532 <a title="254-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>11 0.11923523 <a title="254-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>12 0.11506462 <a title="254-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-Another_reason_why_you_can_get_good_inferences_from_a_bad_model.html">1527 andrew gelman stats-2012-10-10-Another reason why you can get good inferences from a bad model</a></p>
<p>13 0.11182671 <a title="254-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-How_does_Bayes_do_it%3F.html">247 andrew gelman stats-2010-09-01-How does Bayes do it?</a></p>
<p>14 0.1100655 <a title="254-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-18-What_to_read_to_catch_up_on_multivariate_statistics%3F.html">1726 andrew gelman stats-2013-02-18-What to read to catch up on multivariate statistics?</a></p>
<p>15 0.1085448 <a title="254-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-21-Don%E2%80%99t_judge_a_book_by_its_title.html">1021 andrew gelman stats-2011-11-21-Don’t judge a book by its title</a></p>
<p>16 0.1067775 <a title="254-tfidf-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>17 0.1067514 <a title="254-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-14-How_do_you_think_about_the_values_in_a_confidence_interval%3F.html">1672 andrew gelman stats-2013-01-14-How do you think about the values in a confidence interval?</a></p>
<p>18 0.10185798 <a title="254-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>19 0.10017977 <a title="254-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>20 0.098566502 <a title="254-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.148), (1, 0.134), (2, -0.022), (3, 0.018), (4, -0.035), (5, 0.012), (6, -0.016), (7, 0.03), (8, 0.065), (9, -0.069), (10, -0.045), (11, -0.018), (12, 0.02), (13, -0.023), (14, 0.041), (15, 0.007), (16, -0.044), (17, -0.013), (18, 0.025), (19, -0.0), (20, 0.074), (21, 0.065), (22, 0.041), (23, 0.001), (24, 0.095), (25, -0.152), (26, -0.059), (27, -0.03), (28, -0.035), (29, 0.076), (30, -0.004), (31, -0.07), (32, -0.007), (33, -0.008), (34, 0.048), (35, -0.018), (36, -0.028), (37, 0.071), (38, 0.003), (39, 0.048), (40, 0.038), (41, 0.009), (42, 0.054), (43, -0.026), (44, -0.023), (45, -0.015), (46, -0.001), (47, 0.028), (48, -0.016), (49, -0.067)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96680874 <a title="254-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Bayesian_inference_viewed_as_a_computational_approximation_to_classical_calculations.html">254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</a></p>
<p>Introduction: Dave Armstrong writes:
  
 
I have a hopefully quick question about Multilevel Models . . . While being Bayesian would make the attached question [having to do with calculating confidence intervals for linear combinations of fixed and varying coefficents] moot, and I am certainly sympathetic in my own work, I am looking to understand the Frequentist perspective as I need to explain how to do this in R to people without experience in WinBUGS and who are generally uninterested in gaining such experience.
 

 
My reply:
 
This sort of thing happens to me all the time, which is one reason I try to do these inferences using simulations, so I donâ&euro;&trade;t have to keep track of covariances.  The simulation-based Bayes inferences can be interpreted as classical freq inferences; to put it another way, the Bayesian inference can be thought of as a computational trick to work with the multivariate normal and t distributions that arise in classical confidence intervals.</p><p>2 0.74432588 <a title="254-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-21-Instead_of_%E2%80%9Cconfidence_interval%2C%E2%80%9D_let%E2%80%99s_say_%E2%80%9Cuncertainty_interval%E2%80%9D.html">480 andrew gelman stats-2010-12-21-Instead of “confidence interval,” let’s say “uncertainty interval”</a></p>
<p>Introduction: I’ve become increasingly uncomfortable with the term “confidence interval,” for several reasons:
 
- The well-known difficulties in interpretation (officially the confidence statement can be interpreted only on average, but people typically implicitly give the Bayesian interpretation to each case),
 
- The ambiguity between confidence intervals and predictive intervals.  (See the footnote in BDA where we discuss the difference between “inference” and “prediction” in the classical framework.)
 
- The awkwardness of explaining that confidence intervals are big in noisy situations where you have  less  confidence, and confidence intervals are small when you have  more  confidence.
 
So here’s my proposal.  Let’s use the term “uncertainty interval” instead.  The uncertainty interval tells you how much uncertainty you have.  That works pretty well, I think.
 
P.S.  As of this writing, “confidence interval” outGoogles “uncertainty interval” by the huge margin of 9.5 million to 54000.  So we</p><p>3 0.73283249 <a title="254-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>Introduction: After I gave  my talk  at an econ seminar on Why We (Usually) Don’t Care About Multiple Comparisons, I got the following comment:
  
One question that came up later was whether your argument is really with testing in general, rather than only with testing in multiple comparison settings.
  
My reply:
 
Yes, my argument is with testing in general.  But it arises with particular force in multiple comparisons.  With a single test, we can just say we dislike testing so we use confidence intervals or Bayesian inference instead, and it’s no problem—really more of a change in emphasis than a change in methods.  But with multiple tests, the classical advice is not simply to look at type 1 error rates but more specifically to make a multiplicity adjustment, for example to make confidence intervals wider to account for multiplicity.  I don’t want to do this!  So here there is a real battle to fight.
 
P.S.   Here’s  the article (with Jennifer and Masanao), to appear in the Journal of Research on</p><p>4 0.71069312 <a title="254-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-24-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">1913 andrew gelman stats-2013-06-24-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>Introduction: I’m reposing  this  classic from 2011 . . . Peter Bergman pointed me to  this discussion  from Cyrus of  a presentation  by Guido Imbens on design of randomized experiments.
 
Cyrus writes:
  
The standard analysis that Imbens proposes includes (1) a Fisher-type permutation test of the sharp null hypothesis–what Imbens referred to as “testing”–along with a (2) Neyman-type point estimate of the sample average treatment effect and confidence interval–what Imbens referred to as “estimation.” . . .


Imbens claimed that testing and estimation are separate enterprises with separate goals and that the two should not be confused. I [Cyrus] took it as a warning against proposals that use “inverted” tests in order to produce point estimates and confidence intervals. There is no reason that such confidence intervals will have accurate coverage except under rather dire assumptions, meaning that they are not “confidence intervals” in the way that we usually think of them.
  
I agree completely.  T</p><p>5 0.70949292 <a title="254-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-23-A_statistical_version_of_Arrow%E2%80%99s_paradox.html">586 andrew gelman stats-2011-02-23-A statistical version of Arrow’s paradox</a></p>
<p>Introduction: Unfortunately, when we deal with scientists, statisticians are often put in a setting reminiscent of Arrow’s paradox, where we are asked to provide estimates that are informative and unbiased and confidence statements that are correct conditional on the data and also on the underlying true parameter. [It's not generally possible for an estimate to do all these things at the same time -- ed.]  Larry Wasserman feels that scientists are truly frequentist, and Don Rubin has told me how he feels that scientists interpret all statistical estimates Bayesianly. I have no doubt that both Larry and Don are correct. Voters want lower taxes and more services, and scientists want both Bayesian and frequency coverage; as the saying goes, everybody wants to go to heaven but nobody wants to die.</p><p>6 0.70909685 <a title="254-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-10-95%25_intervals_that_I_don%E2%80%99t_believe%2C_because_they%E2%80%99re_from_a_flat_prior_I_don%E2%80%99t_believe.html">1206 andrew gelman stats-2012-03-10-95% intervals that I don’t believe, because they’re from a flat prior I don’t believe</a></p>
<p>7 0.70133841 <a title="254-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-25-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">870 andrew gelman stats-2011-08-25-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>8 0.62277341 <a title="254-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<p>9 0.60850227 <a title="254-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-14-How_do_you_think_about_the_values_in_a_confidence_interval%3F.html">1672 andrew gelman stats-2013-01-14-How do you think about the values in a confidence interval?</a></p>
<p>10 0.5956713 <a title="254-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-04-Rob_Kass_on_statistical_pragmatism%2C_and_my_reactions.html">317 andrew gelman stats-2010-10-04-Rob Kass on statistical pragmatism, and my reactions</a></p>
<p>11 0.58475357 <a title="254-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>12 0.57983458 <a title="254-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-03-Statistical_methods_that_work_in_some_settings_but_not_others.html">1560 andrew gelman stats-2012-11-03-Statistical methods that work in some settings but not others</a></p>
<p>13 0.57634318 <a title="254-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-What_is_a_Bayesian%3F.html">1438 andrew gelman stats-2012-07-31-What is a Bayesian?</a></p>
<p>14 0.57562876 <a title="254-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>15 0.56888247 <a title="254-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-23-Bayesian_adaptive_methods_for_clinical_trials.html">427 andrew gelman stats-2010-11-23-Bayesian adaptive methods for clinical trials</a></p>
<p>16 0.56757081 <a title="254-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-06-Bootstrap_averaging%3A_Examples_where_it_works_and_where_it_doesn%E2%80%99t_work.html">2201 andrew gelman stats-2014-02-06-Bootstrap averaging: Examples where it works and where it doesn’t work</a></p>
<p>17 0.56407803 <a title="254-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-29-Ya_don%E2%80%99t_know_Bayes%2C_Jack.html">117 andrew gelman stats-2010-06-29-Ya don’t know Bayes, Jack</a></p>
<p>18 0.56129664 <a title="254-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<p>19 0.5610522 <a title="254-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-24-Untangling_the_Jeffreys-Lindley_paradox.html">1182 andrew gelman stats-2012-02-24-Untangling the Jeffreys-Lindley paradox</a></p>
<p>20 0.55350786 <a title="254-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-16-Looking_for_Bayesian_expertise_in_India%2C_for_the_purpose_of_analysis_of_sarcoma_trials.html">2293 andrew gelman stats-2014-04-16-Looking for Bayesian expertise in India, for the purpose of analysis of sarcoma trials</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.064), (16, 0.051), (20, 0.06), (21, 0.013), (24, 0.132), (30, 0.023), (51, 0.027), (58, 0.026), (59, 0.018), (62, 0.02), (67, 0.055), (69, 0.025), (85, 0.019), (86, 0.042), (99, 0.318)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97632182 <a title="254-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Bayesian_inference_viewed_as_a_computational_approximation_to_classical_calculations.html">254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</a></p>
<p>Introduction: Dave Armstrong writes:
  
 
I have a hopefully quick question about Multilevel Models . . . While being Bayesian would make the attached question [having to do with calculating confidence intervals for linear combinations of fixed and varying coefficents] moot, and I am certainly sympathetic in my own work, I am looking to understand the Frequentist perspective as I need to explain how to do this in R to people without experience in WinBUGS and who are generally uninterested in gaining such experience.
 

 
My reply:
 
This sort of thing happens to me all the time, which is one reason I try to do these inferences using simulations, so I donâ&euro;&trade;t have to keep track of covariances.  The simulation-based Bayes inferences can be interpreted as classical freq inferences; to put it another way, the Bayesian inference can be thought of as a computational trick to work with the multivariate normal and t distributions that arise in classical confidence intervals.</p><p>2 0.95899743 <a title="254-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-09-A_tale_of_two_discussion_papers.html">1848 andrew gelman stats-2013-05-09-A tale of two discussion papers</a></p>
<p>Introduction: Over the years I’ve written a dozen or so journal articles that have appeared with discussions, and I’ve participated in many published discussions of others’ articles as well.  I get a lot out of these article-discussion-rejoinder packages, in all three of my roles as reader, writer, and discussant.
 
 Part 1:  The story of an unsuccessful discussion 
 
The first time I had a discussion article was the result of an unfortunate circumstance.  I had a research idea that resulted in an  article  with Don Rubin on monitoring the mixing of Markov chain simulations. I new the idea was great, but back then we worked pretty slowly so it was awhile before we had a final version to submit to a journal.  (In retrospect I wish I’d just submitted the  draft version  as it was.)  In the meantime I presented the paper at a conference.  Our idea was very well received (I had a sheet of paper so people could write their names and addresses to get preprints, and we got either 50 or 150 (I can’t remembe</p><p>3 0.95843875 <a title="254-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-18-The_treatment%2C_the_intermediate_outcome%2C_and_the_ultimate_outcome%3A__Leverage_and_the_financial_crisis.html">1420 andrew gelman stats-2012-07-18-The treatment, the intermediate outcome, and the ultimate outcome:  Leverage and the financial crisis</a></p>
<p>Introduction: Gur Huberman points to an article on the financial crisis by Bethany McLean, who  writes :
  
lthough our understanding of what instigated the 2008 global financial crisis remains at best incomplete, there are a few widely agreed upon contributing factors. One of them is a 2004 rule change by the U.S. Securities and Exchange Commission that allowed investment banks to load up on leverage.


This disastrous decision has been cited by a host of prominent economists, including Princeton professor and former Federal Reserve Vice-Chairman Alan Blinder and Nobel laureate Joseph Stiglitz. It has even been immortalized in Hollywood, figuring into the dark financial narrative that propelled the Academy Award-winning film Inside Job. . . .


Here’s just one problem with this story line: It’s not true. Nor is it hard to prove that. Look at the historical leverage of the big five investment banks — Bear Stearns, Lehman Brothers, Merrill Lynch, Goldman Sachs and Morgan Stanley. The Government Accou</p><p>4 0.95806968 <a title="254-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>Introduction: Stan Liebowitz writes:
  
Have you ever heard of an article being retracted in economics? I know you have only been doing this for a few years but I suspect that the answer is that none or very few are retracted. No economist would ever deceive another. There is virtually no interest in detecting cheating. And what good would that do if there is no form of punishment? I say this because I think I have found a case in one of our top journals but the editor allowed the authors of the original article to write an anonymous referee report defending themselves and used this report to reject my comment even though an independent referee recommended publication.
  
My reply:  I wonder how this sort of thing will change in the future as journals become less important.  My impression is that, on one side, researchers are increasingly citing NBER reports, Arxiv preprints, and the like; while, from the other direction, journals such as Science and Nature are developing the reputations of being “t</p><p>5 0.95752436 <a title="254-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-19-Demystifying_Blup.html">1270 andrew gelman stats-2012-04-19-Demystifying Blup</a></p>
<p>Introduction: In our recent thread on computing hierarchical models with big datasets, someone  brought up  Blup.  I thought it might be worth explaining what Blup is and how it relates to hierarchical models.
 
Blup stands for Best Linear Unbiased Prediction, but in my terminology it’s just hierarchical modeling.  Let me break it down: 
- “Best” doesn’t really matter.  What’s important is that our estimates and predictions make sense and are as accurate as possible. 
- “Linear” isn’t so important.  Statistical predictions are linear for Gaussian linear models, otherwise not.  We can and do perform hierarchical generalized linear models all the time. 
- “Unbiased” doesn’t really matter (see discussion of “Best,” above). 
- “Prediction” is the key word for relating Blup and hierarchical modeling to classical statistical terminology.  In classical statistics, “estimation” of a parameter theta is evaluated conditional on the true value of theta, whereas “prediction” of a predictive quantity phi is eval</p><p>6 0.95682317 <a title="254-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>7 0.95565975 <a title="254-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Cross-validation_%28What_is_it_good_for%3F%29.html">1395 andrew gelman stats-2012-06-27-Cross-validation (What is it good for?)</a></p>
<p>8 0.9552362 <a title="254-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-27-Why_don%E2%80%99t_more_medical_discoveries_become_cures%3F.html">167 andrew gelman stats-2010-07-27-Why don’t more medical discoveries become cures?</a></p>
<p>9 0.95485055 <a title="254-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-The_importance_of_style_in_academic_writing.html">902 andrew gelman stats-2011-09-12-The importance of style in academic writing</a></p>
<p>10 0.95483637 <a title="254-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-06-That_silly_ESP_paper_and_some_silliness_in_a_rebuttal_as_well.html">506 andrew gelman stats-2011-01-06-That silly ESP paper and some silliness in a rebuttal as well</a></p>
<p>11 0.95448029 <a title="254-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-29-Decline_Effect_in_Linguistics%3F.html">1400 andrew gelman stats-2012-06-29-Decline Effect in Linguistics?</a></p>
<p>12 0.95410573 <a title="254-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-18-Tibshirani_announces_new_research_result%3A__A_significance_test_for_the_lasso.html">1769 andrew gelman stats-2013-03-18-Tibshirani announces new research result:  A significance test for the lasso</a></p>
<p>13 0.95395595 <a title="254-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-25-The_problem_with_realistic_advice%3F.html">1428 andrew gelman stats-2012-07-25-The problem with realistic advice?</a></p>
<p>14 0.95353484 <a title="254-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-03-Statistical_methods_that_work_in_some_settings_but_not_others.html">1560 andrew gelman stats-2012-11-03-Statistical methods that work in some settings but not others</a></p>
<p>15 0.95334494 <a title="254-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>16 0.95326757 <a title="254-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-%E2%80%9CConfirmation%2C_on_the_other_hand%2C_is_not_sexy%E2%80%9D.html">1683 andrew gelman stats-2013-01-19-“Confirmation, on the other hand, is not sexy”</a></p>
<p>17 0.95324421 <a title="254-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>18 0.95282108 <a title="254-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<p>19 0.95275968 <a title="254-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-06-Yes%2C_checking_calibration_of_probability_forecasts_is_part_of_Bayesian_statistics.html">1610 andrew gelman stats-2012-12-06-Yes, checking calibration of probability forecasts is part of Bayesian statistics</a></p>
<p>20 0.9527365 <a title="254-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Evaluating_evidence_from_published_research.html">2006 andrew gelman stats-2013-09-03-Evaluating evidence from published research</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
