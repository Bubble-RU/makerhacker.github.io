<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>417 andrew gelman stats-2010-11-17-Clutering and variance components</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2010" href="../home/andrew_gelman_stats-2010_home.html">andrew_gelman_stats-2010</a> <a title="andrew_gelman_stats-2010-417" href="#">andrew_gelman_stats-2010-417</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>417 andrew gelman stats-2010-11-17-Clutering and variance components</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2010-417-html" href="http://andrewgelman.com/2010/11/17/clutering_and_v/">html</a></p><p>Introduction: Raymond Lim writes:
  
Do you have any recommendations on clustering and binary models? My particular problem is I’m running a firm fixed effect logit and want to cluster by industry-year (every combination of industry-year). My control variable of interest in measured by industry-year and when I cluster by industry-year, the standard errors are 300x larger than when I don’t cluster. Strangely, this problem only occurs when doing logit and not OLS (linear probability). Also, clustering just by field doesn’t blow up the errors. My hunch is it has something to do with the non-nested structure of year, but I don’t understand why this is only problematic under logit and not OLS.
  
My reply:
 
I’d recommend including four multilevel variance parameters, one for firm, one for industry, one for year, and one for industry-year.  (In lmer, that’s (1 | firm) + (1 | industry) + (1 | year) + (1 | industry.year)).  No need to include (1 | firm.year) since in your data this is the error term.  Try</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Raymond Lim writes:    Do you have any recommendations on clustering and binary models? [sent-1, score-0.409]
</p><p>2 My particular problem is I’m running a firm fixed effect logit and want to cluster by industry-year (every combination of industry-year). [sent-2, score-1.063]
</p><p>3 My control variable of interest in measured by industry-year and when I cluster by industry-year, the standard errors are 300x larger than when I don’t cluster. [sent-3, score-0.288]
</p><p>4 Strangely, this problem only occurs when doing logit and not OLS (linear probability). [sent-4, score-0.387]
</p><p>5 Also, clustering just by field doesn’t blow up the errors. [sent-5, score-0.348]
</p><p>6 My hunch is it has something to do with the non-nested structure of year, but I don’t understand why this is only problematic under logit and not OLS. [sent-6, score-0.597]
</p><p>7 My reply:   I’d recommend including four multilevel variance parameters, one for firm, one for industry, one for year, and one for industry-year. [sent-7, score-0.136]
</p><p>8 If you have a lot of firms, you might first try the secret weapon, fitting a model separately for each year. [sent-13, score-0.588]
</p><p>9 Or if you have a lot of years, break the data up into 5-year periods and do the above analysis separately for each half-decade. [sent-14, score-0.575]
</p><p>10 Things change over time, and I’m always wary of models with long time periods (decades or more). [sent-15, score-0.395]
</p><p>11 I see this a lot in political science, where people naively think that they can just solve all their problems with so-called “state fixed effects,” as if Vermont in 1952 is anything like Vermont in 2008. [sent-16, score-0.43]
</p><p>12 My other recommendation is to build up your model from simple parts and try to identify exactly where your procedure is blowing up. [sent-17, score-0.678]
</p><p>13 (Masanao and Yu-Sung know what graph I’m talking about. [sent-19, score-0.105]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('logit', 0.288), ('vermont', 0.286), ('firm', 0.283), ('clustering', 0.235), ('cluster', 0.203), ('periods', 0.199), ('separately', 0.19), ('industry', 0.19), ('blowing', 0.143), ('strangely', 0.143), ('fixed', 0.143), ('year', 0.141), ('try', 0.134), ('ols', 0.132), ('raymond', 0.125), ('hunch', 0.125), ('wary', 0.12), ('masanao', 0.117), ('weapon', 0.117), ('lmer', 0.115), ('slopes', 0.115), ('blow', 0.113), ('naively', 0.112), ('firms', 0.11), ('problematic', 0.109), ('graph', 0.105), ('lot', 0.101), ('occurs', 0.099), ('secret', 0.092), ('recommendations', 0.089), ('arm', 0.089), ('measured', 0.085), ('binary', 0.085), ('break', 0.085), ('build', 0.085), ('recommendation', 0.084), ('varying', 0.084), ('procedure', 0.079), ('combination', 0.079), ('parts', 0.077), ('identify', 0.076), ('models', 0.076), ('structure', 0.075), ('solve', 0.074), ('decades', 0.072), ('fitting', 0.071), ('variance', 0.069), ('linear', 0.067), ('four', 0.067), ('running', 0.067)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="417-tfidf-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-Clutering_and_variance_components.html">417 andrew gelman stats-2010-11-17-Clutering and variance components</a></p>
<p>Introduction: Raymond Lim writes:
  
Do you have any recommendations on clustering and binary models? My particular problem is I’m running a firm fixed effect logit and want to cluster by industry-year (every combination of industry-year). My control variable of interest in measured by industry-year and when I cluster by industry-year, the standard errors are 300x larger than when I don’t cluster. Strangely, this problem only occurs when doing logit and not OLS (linear probability). Also, clustering just by field doesn’t blow up the errors. My hunch is it has something to do with the non-nested structure of year, but I don’t understand why this is only problematic under logit and not OLS.
  
My reply:
 
I’d recommend including four multilevel variance parameters, one for firm, one for industry, one for year, and one for industry-year.  (In lmer, that’s (1 | firm) + (1 | industry) + (1 | year) + (1 | industry.year)).  No need to include (1 | firm.year) since in your data this is the error term.  Try</p><p>2 0.22195713 <a title="417-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-13-Secret_weapon_with_rare_events.html">610 andrew gelman stats-2011-03-13-Secret weapon with rare events</a></p>
<p>Introduction: Gregory Eady writes:
  
I’m working on a paper examining the effect of superpower alliance on a binary DV (war). I hypothesize that the size of the effect is much higher during the Cold War than it is afterwards. I’m going to run a Chow test to check whether this effect differs significantly between 1960-1989 and 1990-2007 (Scott Long also has a method using predicted probabilities), but I’d also like to show the trend graphically, and thought that your “Secret Weapon” would be useful here. I wonder if there is anything I should be concerned about when doing this with a (rare-events) logistic regression. I was thinking to graph the coefficients in 5-year periods, moving a single year at a time (1960-64, 1961-65, 1962-66, and so on), reporting the coefficient in the graph for the middle year of each 5-year range).
  
My reply:
 
I don’t know nuthin bout no Chow test but, sure, I’d think the secret weapon would work.  If you’re analyzing 5-year periods, it might be cleaner just to keep t</p><p>3 0.20678015 <a title="417-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>Introduction: A research psychologist writes in with a question that’s so long that I’ll put my answer first, then put the question itself below the fold.
 
Here’s my reply:
 
As I wrote in my Anova paper and in my book with Jennifer Hill, I do think that multilevel models can completely replace Anova.  At the same time, I think the central idea of Anova should persist in our understanding of these models.  To me the central idea of Anova is not F-tests or p-values or sums of squares, but rather the idea of predicting an outcome based on factors with discrete levels, and understanding these factors using variance components.
 
The continuous or categorical response thing doesn’t really matter so much to me.  I have no problem using a normal linear model for continuous outcomes (perhaps suitably transformed) and a logistic model for binary outcomes.
 
I don’t want to throw away interactions just because they’re not statistically significant.  I’d rather partially pool them toward zero using an inform</p><p>4 0.19167611 <a title="417-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-28-Hierarchical_ordered_logit_or_probit.html">684 andrew gelman stats-2011-04-28-Hierarchical ordered logit or probit</a></p>
<p>Introduction: Jeff writes:
  
How far off is bglmer and can it handle ordered logit or multinom logit?
  
My reply:
 
bglmer is very close.  No ordered logit but I was just talking about it with Sophia today.  My guess is that the easiest way to fit a hierarchical ordered logit or multinom logit will be to use stan.  For right now I’d recommend using glmer/bglmer to fit the ordered logits in order (e.g., 1 vs. 2,3,4, then 2 vs. 3,4, then 3 vs. 4).  Or maybe there’s already a hierarchical multinomial logit in mcmcpack or somewhere?</p><p>5 0.16049036 <a title="417-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>Introduction: Yi-Chun Ou writes: 
  
  
I am using a multilevel model with three levels. I read that you wrote a book about multilevel models, and wonder if you can solve the following question.  


The data structure is like this: 


Level one: customer (8444 customers) 
Level two: companys (90 companies) 
Level three: industry (17 industries) 


I use 6 level-three variables (i.e. industry characteristics) to explain the variance of the level-one effect across industries. The question here is whether there is an over-fitting problem since there are only 17 industries. I understand that this must be a problem for non-multilevel models, but is it also a problem for multilevel models?
  
My reply:  Yes, this could be a problem.  I’d suggest combining some of your variables into a common score, or using only some of the variables, or using strong priors to control the inferences.  This is an interesting and important area of statistics research, to do this sort of thing systematically.  There’s lots o</p><p>6 0.15570946 <a title="417-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-08-How_to_display_multinominal_logit_results_graphically%3F.html">2163 andrew gelman stats-2014-01-08-How to display multinominal logit results graphically?</a></p>
<p>7 0.14293373 <a title="417-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-29-Putting_together_multinomial_discrete_regressions_by_combining_simple_logits.html">782 andrew gelman stats-2011-06-29-Putting together multinomial discrete regressions by combining simple logits</a></p>
<p>8 0.14170422 <a title="417-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-19-Just_chaid.html">421 andrew gelman stats-2010-11-19-Just chaid</a></p>
<p>9 0.13762057 <a title="417-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>10 0.12803547 <a title="417-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>11 0.12067072 <a title="417-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-12-year_%2B_%281%7Cyear%29.html">851 andrew gelman stats-2011-08-12-year + (1|year)</a></p>
<p>12 0.11498205 <a title="417-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>13 0.11267287 <a title="417-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-18-The_1.6_rule.html">39 andrew gelman stats-2010-05-18-The 1.6 rule</a></p>
<p>14 0.10883431 <a title="417-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>15 0.10805716 <a title="417-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>16 0.098751932 <a title="417-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>17 0.098605663 <a title="417-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-30-Computational_problems_with_glm_etc..html">1516 andrew gelman stats-2012-09-30-Computational problems with glm etc.</a></p>
<p>18 0.096593335 <a title="417-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>19 0.095452532 <a title="417-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-24-PPS_in_Georgia.html">107 andrew gelman stats-2010-06-24-PPS in Georgia</a></p>
<p>20 0.094665639 <a title="417-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-A_new_R_package_for_fititng_multilevel_models.html">501 andrew gelman stats-2011-01-04-A new R package for fititng multilevel models</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.173), (1, 0.08), (2, 0.06), (3, 0.01), (4, 0.108), (5, -0.007), (6, -0.008), (7, -0.029), (8, 0.073), (9, 0.07), (10, 0.025), (11, 0.008), (12, 0.016), (13, -0.04), (14, 0.014), (15, 0.025), (16, -0.014), (17, -0.005), (18, -0.01), (19, 0.003), (20, 0.012), (21, 0.008), (22, -0.019), (23, -0.009), (24, -0.044), (25, -0.07), (26, -0.058), (27, 0.035), (28, -0.021), (29, -0.047), (30, -0.038), (31, 0.01), (32, -0.04), (33, -0.027), (34, 0.004), (35, -0.072), (36, -0.041), (37, -0.015), (38, 0.003), (39, 0.053), (40, -0.012), (41, -0.014), (42, -0.002), (43, -0.005), (44, -0.037), (45, 0.026), (46, 0.006), (47, 0.001), (48, -0.01), (49, 0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9572522 <a title="417-lsi-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-Clutering_and_variance_components.html">417 andrew gelman stats-2010-11-17-Clutering and variance components</a></p>
<p>Introduction: Raymond Lim writes:
  
Do you have any recommendations on clustering and binary models? My particular problem is I’m running a firm fixed effect logit and want to cluster by industry-year (every combination of industry-year). My control variable of interest in measured by industry-year and when I cluster by industry-year, the standard errors are 300x larger than when I don’t cluster. Strangely, this problem only occurs when doing logit and not OLS (linear probability). Also, clustering just by field doesn’t blow up the errors. My hunch is it has something to do with the non-nested structure of year, but I don’t understand why this is only problematic under logit and not OLS.
  
My reply:
 
I’d recommend including four multilevel variance parameters, one for firm, one for industry, one for year, and one for industry-year.  (In lmer, that’s (1 | firm) + (1 | industry) + (1 | year) + (1 | industry.year)).  No need to include (1 | firm.year) since in your data this is the error term.  Try</p><p>2 0.81090671 <a title="417-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-12-year_%2B_%281%7Cyear%29.html">851 andrew gelman stats-2011-08-12-year + (1|year)</a></p>
<p>Introduction: Ana Sequeira writes:
  
I am using a temporal data series and I am trying specifically to understand if there is a temporal trends in the occurrence of a species, for which I need to use “Year” in my models (and from what I understood from pages 244-246 [in ARM] is that factors should always be used as random effects).
      
I believe that in your book the closest example to my situation is the one shown in Figure 14.3: I also have 4 different regions in my study, states in your example are replaced by years in my study, and the x axis is a specific value for a climatic factor I am using in my analysis (IOD).


The reason why I am writing you, is because I am having troubles understanding if my variable “Year” (factor), should only be added as a random effect (1|Year) or if I should include the “Years” (used not as factor) in my models as well (Species ~ …Years + (1|Year))?


My doubt lies in the fact that I am looking for a trend and if I do not include “Years” as variable I believe</p><p>3 0.8081255 <a title="417-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>Introduction: I received the following email from someone who wishes to remain anonymous:
  
My colleague and I are trying to understand the best way to approach a problem involving measuring a group of individuals’ abilities across time, and are hoping you can offer some guidance.


We are trying to analyze the combined effect of two distinct groups of people (A and B, with no overlap between A and B) who collaborate to produce a binary outcome, using a mixed logistic regression along the lines of the following.


Outcome ~ (1 | A) + (1 | B) + Other variables


What we’re interested in testing was whether the observed A random effects in period  1 are predictive of the A random effects in the following period 2.  Our idea being create two models, each using a different period’s worth of data, to create two sets of A coefficients, then observe the relationship between the two.  If the A’s have a persistent ability across periods, the coefficients should be correlated or show a linear-ish relationshi</p><p>4 0.79073924 <a title="417-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Sof%5Bt%5D.html">77 andrew gelman stats-2010-06-09-Sof[t]</a></p>
<p>Introduction: Joe Fruehwald writes:
  
I’m working with linguistic data, specifically binomial hits and misses of a certain variable for certain words (specifically whether or not the “t” sound was pronounced at the end of words like “soft”). Word frequency follows a power law, with most words appearing just once, and with some words being hyperfrequent. I’m not interested in specific word effects, but I am interested in the effect of word frequency.


A logistic model fit is going to be heavily influenced by the effect of the hyperfrequent words which constitute only one type. To control for the item effect, I would fit a multilevel model with a random intercept by word, but like I said, most of the words appear only once.


Is there a principled approach to this problem?
  
My response:  It’s ok to fit a multilevel model even if most groups only have one observation each.  You’ll want to throw in some word-level predictors too.  Think of the multilevel model not as a substitute for the usual thoug</p><p>5 0.7863093 <a title="417-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>Introduction: Someone writes:
  
I am hoping you can give me some advice about when to use fixed and random effects model. I am currently working on a paper that examines the effect of . . . by comparing states . . .


It got reviewed . . . by three economists and all suggest that we run a fixed effects model.  We ran a hierarchial model in the paper that allow the intercept and slope to vary before and after . . . My question is which is correct? We have ran it both ways and really it makes no difference which model you run, the results are very similar. But for my own learning, I would really like to understand which to use under what circumstances.  Is the fact that we use the whole population reason enough to just run a fixed effect model?


Perhaps you can suggest a good reference to this question of when to run a fixed vs. random effects model.
  
I’m not always sure what is meant by a “fixed effects model”; see my paper on Anova for discussion of the problems with this terminology:
 
http://w</p><p>6 0.78496885 <a title="417-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>7 0.78440005 <a title="417-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>8 0.78416771 <a title="417-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>9 0.78150254 <a title="417-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-21-Finite-population_Anova_calculations_for_models_with_interactions.html">1686 andrew gelman stats-2013-01-21-Finite-population Anova calculations for models with interactions</a></p>
<p>10 0.77910435 <a title="417-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>11 0.77838445 <a title="417-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>12 0.77511048 <a title="417-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>13 0.75413346 <a title="417-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-22-Handling_multiple_versions_of_an_outcome_variable.html">726 andrew gelman stats-2011-05-22-Handling multiple versions of an outcome variable</a></p>
<p>14 0.75405389 <a title="417-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>15 0.74881113 <a title="417-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>16 0.74595261 <a title="417-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-10-R_vs._Stata%2C_or%2C_Different_ways_to_estimate_multilevel_models.html">269 andrew gelman stats-2010-09-10-R vs. Stata, or, Different ways to estimate multilevel models</a></p>
<p>17 0.74279082 <a title="417-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>18 0.74097198 <a title="417-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Multilevel_quantile_regression.html">397 andrew gelman stats-2010-11-06-Multilevel quantile regression</a></p>
<p>19 0.73848385 <a title="417-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Cross-validation_%28What_is_it_good_for%3F%29.html">1395 andrew gelman stats-2012-06-27-Cross-validation (What is it good for?)</a></p>
<p>20 0.73568928 <a title="417-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-24-Multilevel_modeling_and_instrumental_variables.html">1468 andrew gelman stats-2012-08-24-Multilevel modeling and instrumental variables</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.027), (9, 0.028), (16, 0.047), (24, 0.128), (28, 0.023), (36, 0.031), (44, 0.021), (56, 0.012), (59, 0.013), (63, 0.043), (77, 0.018), (80, 0.013), (84, 0.019), (85, 0.199), (90, 0.014), (93, 0.013), (95, 0.021), (99, 0.242)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.92383051 <a title="417-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-06-Calling_Jenny_Davidson_._._..html">1790 andrew gelman stats-2013-04-06-Calling Jenny Davidson . . .</a></p>
<p>Introduction: Now that you have some free time again, you’ll have to check out  these books  and tell us if they’re worth reading.
 
Claire Kirch  reports :
  
Lizzie Skurnick Books launches in September with the release of Debutante Hill by Lois Duncan. The novel, which was originally published by Dodd, Mead, in 1958, has been out of print for about three decades.


The other books on the initial list, all reissues, are A Long Day in November by Ernest J. Gaines (originally published in 1971), Happy Endings Are All Alike by Sandra Scoppettone (1979), I’ll Love You When You’re More Like Me by M.E. Kerr (1977), Secret Lives by Berthe Amoss (1979), To All My Fans, With Love, From Sylvie by Ellen Conford (1982), and Me and Fat Glenda by Lila Perl (1972). . . .


Noting that many of the books of that era beloved by teen boys are still in print – such as Isaac Asimov’s novels and The Chocolate War by Robert Cormier – Skurnick pointed out that, in contrast, many of the books that were embraced by teen gir</p><p>2 0.91340375 <a title="417-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-15-The_strange_reappearance_of_Matthew_Klam.html">1534 andrew gelman stats-2012-10-15-The strange reappearance of Matthew Klam</a></p>
<p>Introduction: A few years ago I  asked  what happened to Matthew Klam, a talented writer who has a bizarrely professional-looking webpage but didn’t seem to be writing anymore.
 
Good news!  He published  a new story  in the New Yorker!  Confusingly, he wrote it under the name “Justin Taylor,” but I’m not fooled (any more than I was fooled when that posthumous Updike story was published under the name “ Antonya Nelson “).  I’m glad to see that Klam is back in action and look forward to seeing some stories under his own name as well.</p><p>same-blog 3 0.91201377 <a title="417-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-17-Clutering_and_variance_components.html">417 andrew gelman stats-2010-11-17-Clutering and variance components</a></p>
<p>Introduction: Raymond Lim writes:
  
Do you have any recommendations on clustering and binary models? My particular problem is I’m running a firm fixed effect logit and want to cluster by industry-year (every combination of industry-year). My control variable of interest in measured by industry-year and when I cluster by industry-year, the standard errors are 300x larger than when I don’t cluster. Strangely, this problem only occurs when doing logit and not OLS (linear probability). Also, clustering just by field doesn’t blow up the errors. My hunch is it has something to do with the non-nested structure of year, but I don’t understand why this is only problematic under logit and not OLS.
  
My reply:
 
I’d recommend including four multilevel variance parameters, one for firm, one for industry, one for year, and one for industry-year.  (In lmer, that’s (1 | firm) + (1 | industry) + (1 | year) + (1 | industry.year)).  No need to include (1 | firm.year) since in your data this is the error term.  Try</p><p>4 0.90555912 <a title="417-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-15-n_%3D_2.html">912 andrew gelman stats-2011-09-15-n = 2</a></p>
<p>Introduction: People in Chicago are nice.  The conductor on the train came by and I asked if I could buy a ticket right there.  He said yes, $2.50.  While I was getting the money he asked if the ticket machine at the station had been broken.  I said, I don’t know, I saw the train and ran up the stairs to catch it.  He said, that’s not what you’re supposed to say.  So I said, that’s right, the machine was broken.
 
It’s just like on that radio show where Peter Sagal hems and haws to clue the contestant in that his guess is wrong so he can try again.</p><p>5 0.89574718 <a title="417-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-09-What_joker_put_seven_dog_lice_in_my_Iraqi_fez_box%3F.html">330 andrew gelman stats-2010-10-09-What joker put seven dog lice in my Iraqi fez box?</a></p>
<p>Introduction: New Sentences For The Testing Of Typewriters (from  John Lennon ):
  

Fetching killjoy Mavis Wax was probed on the quay.






“Yo, never mix Zoloft with Quik,” gabs Doc Jasper.


One zany quaff is vodka mixed with grape juice and blood.


Zitty Vicki smugly quipped in her journal, “Fay waxes her butt.”


Hot Wendy gave me quasi-Kreutzfeld-Jacob pox.


Jack’s pervy moxie quashed Bob’s new Liszt fugue.


I backed Zevy’s qualms over Janet’s wig of phlox.


Tipsy Bangkok panjandrums fix elections with quivering zeal.


Mexican juntas, viewed in fog, piqued Zachary, killed Rob.


Jaywalking Zulu chieftains vex probate judge Marcy Quinn.


Twenty-six Excedrin helped give Jocko quite a firm buzz.


Racy pics of bed hijinx with glam queen sunk Val.


Why Paxil? Jim’s Bodega stocked no quince-flavor Pez.


Wavy-haired quints of El Paz mock Jorge by fax.


Two phony quacks of God bi-exorcize evil mojo.</p><p>6 0.89021766 <a title="417-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-07-Non-rant.html">843 andrew gelman stats-2011-08-07-Non-rant</a></p>
<p>7 0.88401389 <a title="417-lda-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-21-Ticket_to_Baaaath.html">2300 andrew gelman stats-2014-04-21-Ticket to Baaaath</a></p>
<p>8 0.87915885 <a title="417-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-23-The_scalarization_of_America.html">533 andrew gelman stats-2011-01-23-The scalarization of America</a></p>
<p>9 0.8785913 <a title="417-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-29-Stupid_legal_crap.html">58 andrew gelman stats-2010-05-29-Stupid legal crap</a></p>
<p>10 0.8771019 <a title="417-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-28-Matching_for_preprocessing_data_for_causal_inference.html">375 andrew gelman stats-2010-10-28-Matching for preprocessing data for causal inference</a></p>
<p>11 0.87659627 <a title="417-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-13-Stolen_jokes.html">1318 andrew gelman stats-2012-05-13-Stolen jokes</a></p>
<p>12 0.87301797 <a title="417-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-11-Convergence_Monitoring_for_Non-Identifiable_and_Non-Parametric_Models.html">1374 andrew gelman stats-2012-06-11-Convergence Monitoring for Non-Identifiable and Non-Parametric Models</a></p>
<p>13 0.86597317 <a title="417-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-09-The_pretty_picture_is_just_the_beginning_of_the_data_exploration.__But_the_pretty_picture_is_a_great_way_to_get_started.__Another_example_of_how_a_puzzle_can_make_a_graph_appealing.html">1614 andrew gelman stats-2012-12-09-The pretty picture is just the beginning of the data exploration.  But the pretty picture is a great way to get started.  Another example of how a puzzle can make a graph appealing</a></p>
<p>14 0.86517078 <a title="417-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-27-%E2%80%9CApple_confronts_the_law_of_large_numbers%E2%80%9D_._._._huh%3F.html">1187 andrew gelman stats-2012-02-27-“Apple confronts the law of large numbers” . . . huh?</a></p>
<p>15 0.86385608 <a title="417-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-13-Secret_weapon_with_rare_events.html">610 andrew gelman stats-2011-03-13-Secret weapon with rare events</a></p>
<p>16 0.86219692 <a title="417-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-28-Funniest_comment_ever.html">734 andrew gelman stats-2011-05-28-Funniest comment ever</a></p>
<p>17 0.85183579 <a title="417-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-26-Teaching_evaluations%2C_instructor_effectiveness%2C_the_Journal_of_Political_Economy%2C_and_the_Holy_Roman_Empire.html">540 andrew gelman stats-2011-01-26-Teaching evaluations, instructor effectiveness, the Journal of Political Economy, and the Holy Roman Empire</a></p>
<p>18 0.84133875 <a title="417-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-14-Turing_chess_tournament%21.html">1899 andrew gelman stats-2013-06-14-Turing chess tournament!</a></p>
<p>19 0.84011191 <a title="417-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-22-%E2%80%9CAre_Wisconsin_Public_Employees_Underpaid%3F%E2%80%9D.html">584 andrew gelman stats-2011-02-22-“Are Wisconsin Public Employees Underpaid?”</a></p>
<p>20 0.83650029 <a title="417-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Matching_and_regression%3A__two_great_tastes_etc_etc.html">796 andrew gelman stats-2011-07-10-Matching and regression:  two great tastes etc etc</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
