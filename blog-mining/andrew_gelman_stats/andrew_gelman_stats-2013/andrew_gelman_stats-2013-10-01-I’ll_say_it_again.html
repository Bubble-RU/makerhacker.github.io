<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2046 andrew gelman stats-2013-10-01-I’ll say it again</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-2046" href="#">andrew_gelman_stats-2013-2046</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2046 andrew gelman stats-2013-10-01-I’ll say it again</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-2046-html" href="http://andrewgelman.com/2013/10/01/ill-say-it-again/">html</a></p><p>Introduction: Milan Valasek writes:
  
Psychology students (and probably students in other disciplines) are often taught that in order to perform ‘parametric’ tests, e.g. independent t-test, the data for each group need to be normally distributed. However, in literature (and various university lecture notes and slides accessible online), I have come across at least 4 different interpretation of what it is that is supposed to be normally distributed when doing a t-test:


1. population 
2. sampled data for each group 
3. distribution of estimates of means for each group 
4. distribution of estimates of the difference between groups


I can see how 2 would follow from 1 and 4 from 3 but even then, there are two different sets of interpretations of the normality assumption. 
Could you please put this issue to rest for me?
  
My quick response is that normality is  not so important  unless you are focusing on prediction.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Milan Valasek writes:    Psychology students (and probably students in other disciplines) are often taught that in order to perform ‘parametric’ tests, e. [sent-1, score-0.788]
</p><p>2 independent t-test, the data for each group need to be normally distributed. [sent-3, score-0.742]
</p><p>3 However, in literature (and various university lecture notes and slides accessible online), I have come across at least 4 different interpretation of what it is that is supposed to be normally distributed when doing a t-test:   1. [sent-4, score-1.804]
</p><p>4 distribution of estimates of means for each group  4. [sent-7, score-0.662]
</p><p>5 distribution of estimates of the difference between groups   I can see how 2 would follow from 1 and 4 from 3 but even then, there are two different sets of interpretations of the normality assumption. [sent-8, score-1.369]
</p><p>6 My quick response is that normality is  not so important  unless you are focusing on prediction. [sent-10, score-0.831]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('normality', 0.409), ('normally', 0.31), ('group', 0.255), ('milan', 0.235), ('parametric', 0.173), ('disciplines', 0.173), ('distribution', 0.162), ('estimates', 0.161), ('sampled', 0.157), ('students', 0.156), ('lecture', 0.155), ('interpretations', 0.154), ('accessible', 0.151), ('distributed', 0.148), ('slides', 0.14), ('focusing', 0.135), ('taught', 0.127), ('notes', 0.122), ('perform', 0.122), ('sets', 0.115), ('supposed', 0.114), ('independent', 0.113), ('prediction', 0.113), ('unless', 0.112), ('interpretation', 0.112), ('rest', 0.109), ('online', 0.104), ('tests', 0.103), ('groups', 0.102), ('quick', 0.096), ('please', 0.096), ('different', 0.093), ('follow', 0.092), ('order', 0.091), ('psychology', 0.091), ('population', 0.088), ('literature', 0.087), ('means', 0.084), ('university', 0.084), ('across', 0.083), ('difference', 0.081), ('response', 0.079), ('however', 0.079), ('issue', 0.078), ('probably', 0.074), ('various', 0.073), ('come', 0.068), ('least', 0.064), ('data', 0.064), ('often', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="2046-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-01-I%E2%80%99ll_say_it_again.html">2046 andrew gelman stats-2013-10-01-I’ll say it again</a></p>
<p>Introduction: Milan Valasek writes:
  
Psychology students (and probably students in other disciplines) are often taught that in order to perform ‘parametric’ tests, e.g. independent t-test, the data for each group need to be normally distributed. However, in literature (and various university lecture notes and slides accessible online), I have come across at least 4 different interpretation of what it is that is supposed to be normally distributed when doing a t-test:


1. population 
2. sampled data for each group 
3. distribution of estimates of means for each group 
4. distribution of estimates of the difference between groups


I can see how 2 would follow from 1 and 4 from 3 but even then, there are two different sets of interpretations of the normality assumption. 
Could you please put this issue to rest for me?
  
My quick response is that normality is  not so important  unless you are focusing on prediction.</p><p>2 0.28454214 <a title="2046-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>Introduction: Andy Cooper writes:
  
A link to an  article , “Four Assumptions Of Multiple Regression That Researchers Should Always Test”, has been making  the rounds  on Twitter.  Their first rule is “Variables are Normally distributed.”  And they seem to be talking about the independent variables – but then later bring in tests on the residuals (while admitting that the normally-distributed error assumption is a weak assumption).  


I thought we had long-since moved away from transforming our independent variables to make them normally distributed for statistical reasons (as opposed to standardizing them for interpretability, etc.)  Am I missing something?  I agree that leverage in a influence is important, but normality of the variables? The article is from 2002, so it might be dated, but given the popularity of the tweet, I thought I’d ask your opinion.
  
My response:  There’s some useful advice on that page but overall I think the advice was dated even in 2002.  In section 3.6 of my book wit</p><p>3 0.18047208 <a title="2046-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-06-Assumptions_vs._conditions.html">602 andrew gelman stats-2011-03-06-Assumptions vs. conditions</a></p>
<p>Introduction: Jeff Witmer writes:
  
I noticed that you continue the standard practice in statistics of referring to assumptions; e.g. a blog entry on 2/4/11 at 10:54: “Our method, just like any model, relies on assumptions which we have the duty to state and to check.”


I’m in the 6th year of a three-year campaign to get statisticians to drop the word “assumptions” and replace it with “conditions.”  The problem, as I see it, is that people tend to think that an assumption is something that one assumes, as in “assuming that we have a right triangle…” or “assuming that k is even…” when constructing a mathematical proof.  


But in statistics we don’t assume things — unless we have to.  Instead, we know that, for example, the validity of a t-test depends on normality, which is a condition that can and should be checked.  Let’s not call normality an assumption, lest we imply that it is something that can be assumed.  Let’s call it a condition.
  
What do you all think?</p><p>4 0.15452147 <a title="2046-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-Transformations_for_non-normal_data.html">2176 andrew gelman stats-2014-01-19-Transformations for non-normal data</a></p>
<p>Introduction: Steve Peterson writes:
  
I recently submitted a proposal on applying a Bayesian analysis to gender comparisons on motivational constructs. I had an idea on how to improve the model I used and was hoping you could give me some feedback.


The data come from a survey based on 5-point Likert scales. Different constructs are measured for each student as scores derived from averaging a student’s responses on particular subsets of survey questions. (I suppose it is not uncontroversial to treat these scores as interval measures and would be interested to hear if you have any objections.) I am comparing genders on each construct. Researchers typically use t-tests to do so.


To use a Bayesian approach I applied the programs written in R and JAGS by John Kruschke for estimating the difference of means:


http://www.indiana.edu/~kruschke/BEST/


An issue in that analysis is that the distributions of student scores are not normal. There was skewness in some of the distributions and not always in</p><p>5 0.12900609 <a title="2046-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-29-Question_19_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1352 andrew gelman stats-2012-05-29-Question 19 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>Introduction: 19. A survey is taken of students in a metropolitan area. At the first stage a school is sampled at random. The schools are divided into two strata: 20 private schools and 50 public schools are sampled. At the second stage, 5 classes are sampled within each sampled school. At the third stage, 10 students are sampled within each class. What is the probability that any given student is sampled? Express this in terms of the number of students in the class, number of classes in the school, and number of schools in the area. Define appropriate notation as needed.
 
 Solution to question 18 
 
From  yesterday :
  
18. A survey is taken of 100 undergraduates, 100 graduate students, and 100 continuing education students at a university. Assume a simple random sample within each group. Each student is asked to rate his or her satisfaction (on a 1â&euro;&ldquo;10 scale) with his or her experiences. Write the estimate and standard error of the average satisfaction of all the students at the university. Introd</p><p>6 0.11631264 <a title="2046-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-18-The_1.6_rule.html">39 andrew gelman stats-2010-05-18-The 1.6 rule</a></p>
<p>7 0.11101902 <a title="2046-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-30-Question_20_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1353 andrew gelman stats-2012-05-30-Question 20 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>8 0.10801455 <a title="2046-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-12-Steven_Pinker%E2%80%99s_unconvincing_debunking_of_group_selection.html">1414 andrew gelman stats-2012-07-12-Steven Pinker’s unconvincing debunking of group selection</a></p>
<p>9 0.10526753 <a title="2046-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-17-G%2B_hangout_for_test_run_of_BDA_course.html">2066 andrew gelman stats-2013-10-17-G+ hangout for test run of BDA course</a></p>
<p>10 0.10473156 <a title="2046-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-Another_reason_why_you_can_get_good_inferences_from_a_bad_model.html">1527 andrew gelman stats-2012-10-10-Another reason why you can get good inferences from a bad model</a></p>
<p>11 0.095644593 <a title="2046-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-13-%E2%80%9CWhat_are_some_situations_in_which_the_classical_approach_%28or_a_naive_implementation_of_it%2C_based_on_cookbook_recipes%29_gives_worse_results_than_a_Bayesian_approach%2C_results_that_actually_impeded_the_science%3F%E2%80%9D.html">2099 andrew gelman stats-2013-11-13-“What are some situations in which the classical approach (or a naive implementation of it, based on cookbook recipes) gives worse results than a Bayesian approach, results that actually impeded the science?”</a></p>
<p>12 0.095388591 <a title="2046-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-04-Does_it_matter_that_a_sample_is_unrepresentative%3F__It_depends_on_the_size_of_the_treatment_interactions.html">2008 andrew gelman stats-2013-09-04-Does it matter that a sample is unrepresentative?  It depends on the size of the treatment interactions</a></p>
<p>13 0.095245153 <a title="2046-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>14 0.095071077 <a title="2046-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-02-My_course_this_fall_on_l%E2%80%99analyse_bay%C3%A9sienne_de_donn%C3%A9es.html">1965 andrew gelman stats-2013-08-02-My course this fall on l’analyse bayésienne de données</a></p>
<p>15 0.094656371 <a title="2046-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-How_do_you_interpret_standard_errors_from_a_regression_fit_to_the_entire_population%3F.html">972 andrew gelman stats-2011-10-25-How do you interpret standard errors from a regression fit to the entire population?</a></p>
<p>16 0.092717662 <a title="2046-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-27-Setting_up_Jitts_online.html">2041 andrew gelman stats-2013-09-27-Setting up Jitts online</a></p>
<p>17 0.090014927 <a title="2046-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Peer_pressure%2C_selection%2C_and_educational_reform.html">326 andrew gelman stats-2010-10-07-Peer pressure, selection, and educational reform</a></p>
<p>18 0.088620923 <a title="2046-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Online_Education_and_Jazz.html">1752 andrew gelman stats-2013-03-06-Online Education and Jazz</a></p>
<p>19 0.087462194 <a title="2046-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-01-%E2%80%9COn_Inspiring_Students_and_Being_Human%E2%80%9D.html">1517 andrew gelman stats-2012-10-01-“On Inspiring Students and Being Human”</a></p>
<p>20 0.086822711 <a title="2046-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-14-A_new_idea_for_a_science_core_course_based_entirely_on_computer_simulation.html">516 andrew gelman stats-2011-01-14-A new idea for a science core course based entirely on computer simulation</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.143), (1, 0.037), (2, 0.023), (3, -0.044), (4, 0.052), (5, 0.085), (6, 0.015), (7, 0.064), (8, -0.057), (9, 0.008), (10, 0.032), (11, 0.041), (12, 0.004), (13, -0.028), (14, -0.002), (15, -0.008), (16, -0.034), (17, -0.019), (18, -0.013), (19, 0.014), (20, 0.032), (21, 0.014), (22, 0.015), (23, -0.077), (24, 0.009), (25, 0.001), (26, 0.023), (27, 0.004), (28, 0.033), (29, 0.038), (30, 0.009), (31, -0.003), (32, -0.007), (33, 0.021), (34, 0.027), (35, 0.015), (36, -0.023), (37, -0.021), (38, 0.003), (39, 0.012), (40, 0.061), (41, -0.052), (42, 0.048), (43, -0.032), (44, -0.005), (45, 0.026), (46, 0.024), (47, 0.027), (48, -0.007), (49, 0.001)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96319431 <a title="2046-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-01-I%E2%80%99ll_say_it_again.html">2046 andrew gelman stats-2013-10-01-I’ll say it again</a></p>
<p>Introduction: Milan Valasek writes:
  
Psychology students (and probably students in other disciplines) are often taught that in order to perform ‘parametric’ tests, e.g. independent t-test, the data for each group need to be normally distributed. However, in literature (and various university lecture notes and slides accessible online), I have come across at least 4 different interpretation of what it is that is supposed to be normally distributed when doing a t-test:


1. population 
2. sampled data for each group 
3. distribution of estimates of means for each group 
4. distribution of estimates of the difference between groups


I can see how 2 would follow from 1 and 4 from 3 but even then, there are two different sets of interpretations of the normality assumption. 
Could you please put this issue to rest for me?
  
My quick response is that normality is  not so important  unless you are focusing on prediction.</p><p>2 0.76674205 <a title="2046-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-27-Setting_up_Jitts_online.html">2041 andrew gelman stats-2013-09-27-Setting up Jitts online</a></p>
<p>Introduction: I use just-in-time teaching assignments in all my classes now.  Vince helpfully sent along these instructions for setting these up on Google.  See below.
 
I think Jitts are just wonderful, and they’re so easy to set up, you should definitely be doing them in your classes too.  I’ve had more difficulty with Peer Instruction (the companion tool to just-in-time teaching) as it requires questions at just the right level for the class.  I do have students frequently work in pairs, though, so I think I get some of the benefit of that.
 
P.S.  I’d love to share all the Jitts with you for Bayesian Data Analysis, but I’m afraid this would poison the well and future students would not have the opportunity to be surprised by them.  Yes, I know, I should just come up with new ones every year—but I’m not quite ready to do that!  Perhaps soon I will.
 
In the meantime, a commenter asked for some Jitts, so here are the ones for the first and last weeks of class:
  

Jitt questions for Bayesian Data</p><p>3 0.70665854 <a title="2046-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-14-In_an_introductory_course%2C_when_does_learning_occur%3F.html">277 andrew gelman stats-2010-09-14-In an introductory course, when does learning occur?</a></p>
<p>Introduction: Now that September has arrived, it’s time for us to think teaching.   Here’s something  from Andrew Heckler and Eleanor Sayre.  Heckler writes:
  
The article describes a project studying the performance of university level students taking an intro physics course. Every week for ten weeks we took 1/10th of the students (randomly selected only once) and gave them the same set of questions relevant to the course. This allowed us to plot the evolution of average performance in the class during the quarter.  We can then determine when learning occurs: For example, do they learn the material in a relevant lecture or lab or homework? Since we had about 350 students taking the course, we could get some reasonable stats.


In particular, you might be interested in Figure 10 (page 774) which shows student performance day-by-day on a particular question.  The performance does not change directly after lecture, but rather only when the homework was due.  [emphasis added] We could not find any oth</p><p>4 0.70021325 <a title="2046-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-09-Kaggle%3A__forecasting_competitions_in_the_classroom.html">402 andrew gelman stats-2010-11-09-Kaggle:  forecasting competitions in the classroom</a></p>
<p>Introduction: Anthony Goldbloom writes:
  
For those who haven’t come across Kaggle, we are a new platform for data prediction competitions. Companies and researchers put up a dataset and a problem and data scientists compete to produce the best solutions. 


We’ve just launched a new initiative called Kaggle in Class, allowing instructors to host competitions for their students. Competitions are a neat way to engage students, giving them the opportunity to put into practice what they learn. The platform offers live leaderboards, so students get instant feedback on the accuracy of their work. And since competitions are judged on objective criteria (predictions are compared with outcomes), the platform offers unique assessment 
opportunities.


The first Kaggle in Class competition is being hosted by Stanford University’s Stats 202 class and requires students to predict the price of different wines based on vintage, country, ratings and other information.


Those interested in hosting a competition f</p><p>5 0.6722827 <a title="2046-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-31-Value-added_modeling_in_education%3A__Gaming_the_system_by_sending_kids_on_a_field_trip_at_test_time.html">2083 andrew gelman stats-2013-10-31-Value-added modeling in education:  Gaming the system by sending kids on a field trip at test time</a></p>
<p>Introduction: Just in time for Halloween, here’s a horror story for you . . .
 
 
 
Howard Wainer writes:
  
In my book “Uneducated Guesses” in the chapter on value-added models, I discuss how the treatment of missing data can have a profound effect on the estimates of teacher scores. I made up how a principal might send the best students on a field trip at the beginning of the year when the ‘pre-test’ was given (and their scores would be imputed from the students who showed up) and that the bottom half of the class would have a matching field trip on the day of the post test. Everyone laughed.


But apparently someone decided to take it seriously.


http://www.amren.com/news/2012/10/el-paso-schools-confront-scandal-of-students-who-disappeared-at-test-time/


http://www.elpasotimes.com/episd/ci_20848628/former-episd-superintendent-lorenzo-garcia-enter-plea-aggreement


You can’t make this stuff up.
  
This sort of thing is  not surprising  but it’s worth keeping in mind.  That a measurement system c</p><p>6 0.67155719 <a title="2046-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-13-Hey%2C_you%21__Don%E2%80%99t_take_that_class%21.html">956 andrew gelman stats-2011-10-13-Hey, you!  Don’t take that class!</a></p>
<p>7 0.66510946 <a title="2046-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Peer_pressure%2C_selection%2C_and_educational_reform.html">326 andrew gelman stats-2010-10-07-Peer pressure, selection, and educational reform</a></p>
<p>8 0.66412944 <a title="2046-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-01-%E2%80%9COn_Inspiring_Students_and_Being_Human%E2%80%9D.html">1517 andrew gelman stats-2012-10-01-“On Inspiring Students and Being Human”</a></p>
<p>9 0.65007722 <a title="2046-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-06-Lee_Nguyen_Tran_Kim_Song_Shimazaki.html">1657 andrew gelman stats-2013-01-06-Lee Nguyen Tran Kim Song Shimazaki</a></p>
<p>10 0.64628857 <a title="2046-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-14-Questions_about_a_study_of_charter_schools.html">957 andrew gelman stats-2011-10-14-Questions about a study of charter schools</a></p>
<p>11 0.63593286 <a title="2046-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-Comparing_prediction_errors.html">938 andrew gelman stats-2011-10-03-Comparing prediction errors</a></p>
<p>12 0.62592351 <a title="2046-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-Evaluating_Columbia_University%E2%80%99s_Frontiers_of_Science_course.html">1864 andrew gelman stats-2013-05-20-Evaluating Columbia University’s Frontiers of Science course</a></p>
<p>13 0.62363011 <a title="2046-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-18-Data_to_use_for_in-class_sampling_exercises%3F.html">1943 andrew gelman stats-2013-07-18-Data to use for in-class sampling exercises?</a></p>
<p>14 0.62275159 <a title="2046-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-10-It%E2%80%99s_no_fun_being_graded_on_a_curve.html">606 andrew gelman stats-2011-03-10-It’s no fun being graded on a curve</a></p>
<p>15 0.616328 <a title="2046-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-13-Student_project_competition.html">1008 andrew gelman stats-2011-11-13-Student project competition</a></p>
<p>16 0.61174417 <a title="2046-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-23-More_on_those_L.A._Times_estimates_of_teacher_effectiveness.html">226 andrew gelman stats-2010-08-23-More on those L.A. Times estimates of teacher effectiveness</a></p>
<p>17 0.61159158 <a title="2046-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Matching_at_two_levels.html">213 andrew gelman stats-2010-08-17-Matching at two levels</a></p>
<p>18 0.61017722 <a title="2046-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-09-How_to_model_distributions_that_have_outliers_in_one_direction.html">2128 andrew gelman stats-2013-12-09-How to model distributions that have outliers in one direction</a></p>
<p>19 0.60482353 <a title="2046-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-03-He_doesn%E2%80%99t_trust_the_fit_._._._r%3D.999.html">315 andrew gelman stats-2010-10-03-He doesn’t trust the fit . . . r=.999</a></p>
<p>20 0.60424101 <a title="2046-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-14-Statistics_for_firefighters%3A__update.html">1722 andrew gelman stats-2013-02-14-Statistics for firefighters:  update</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.045), (18, 0.17), (24, 0.206), (42, 0.042), (84, 0.062), (99, 0.351)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97791773 <a title="2046-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-01-I%E2%80%99ll_say_it_again.html">2046 andrew gelman stats-2013-10-01-I’ll say it again</a></p>
<p>Introduction: Milan Valasek writes:
  
Psychology students (and probably students in other disciplines) are often taught that in order to perform ‘parametric’ tests, e.g. independent t-test, the data for each group need to be normally distributed. However, in literature (and various university lecture notes and slides accessible online), I have come across at least 4 different interpretation of what it is that is supposed to be normally distributed when doing a t-test:


1. population 
2. sampled data for each group 
3. distribution of estimates of means for each group 
4. distribution of estimates of the difference between groups


I can see how 2 would follow from 1 and 4 from 3 but even then, there are two different sets of interpretations of the normality assumption. 
Could you please put this issue to rest for me?
  
My quick response is that normality is  not so important  unless you are focusing on prediction.</p><p>2 0.97033715 <a title="2046-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-22-Researching_the_cost-effectiveness_of_political_lobbying_organisations.html">969 andrew gelman stats-2011-10-22-Researching the cost-effectiveness of political lobbying organisations</a></p>
<p>Introduction: Sally Murray from  Giving What We Can  writes:
  
We are an organisation that assesses different charitable (/fundable) interventions, to estimate which are the most cost-effective (measured in terms of the improvement of life for people in developing countries gained for every dollar invested). Our research guides and encourages greater donations to the most cost-effective charities we thus identify, and our members have so far pledged a total of $14m to these causes, with many hundreds more relying on our advice in a less formal way.


I am specifically researching the cost-effectiveness of political lobbying organisations. We are initially focusing on organisations that lobby for ‘big win’ outcomes such as increased funding of the most cost-effective NTD treatments/ vaccine research, changes to global trade rules (potentially) and more obscure lobbies such as “Keep Antibiotics Working”.


We’ve a great deal of respect for your work and the superbly rational way you go about it, and</p><p>3 0.95941699 <a title="2046-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>Introduction: Andy Cooper writes:
  
A link to an  article , “Four Assumptions Of Multiple Regression That Researchers Should Always Test”, has been making  the rounds  on Twitter.  Their first rule is “Variables are Normally distributed.”  And they seem to be talking about the independent variables – but then later bring in tests on the residuals (while admitting that the normally-distributed error assumption is a weak assumption).  


I thought we had long-since moved away from transforming our independent variables to make them normally distributed for statistical reasons (as opposed to standardizing them for interpretability, etc.)  Am I missing something?  I agree that leverage in a influence is important, but normality of the variables? The article is from 2002, so it might be dated, but given the popularity of the tweet, I thought I’d ask your opinion.
  
My response:  There’s some useful advice on that page but overall I think the advice was dated even in 2002.  In section 3.6 of my book wit</p><p>4 0.9573518 <a title="2046-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Colorless_green_facts_asserted_resolutely.html">1292 andrew gelman stats-2012-05-01-Colorless green facts asserted resolutely</a></p>
<p>Introduction: Thomas Basbøll [yes, I've learned how to smoothly do this using alt-o] gives  some writing advice :
  
What gives a text presence is our commitment to asserting facts. We have to face the possibility that we may be wrong about them resolutely, and we do this by writing about them as though we are right.
  
This and an earlier  remark  by Basbøll are closely related in my mind to predictive model checking and to  Bayesian statistics :  we make strong assumptions and then engage the data and the assumptions in a dialogue:  assumptions + data -> inference, and we can then compare the inference to the data which can reveal problems with our model (or problems with the data, but that’s really problems with the model too, in this case problems with the model for the data).
 
I like the idea that a condition for a story to be useful is that we put some belief into it.  (One doesn’t put belief into a joke.)  And also the converse, that thnking hard about a story and believing it can be the pre</p><p>5 0.95045638 <a title="2046-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Extreem_p-values%21.html">1691 andrew gelman stats-2013-01-25-Extreem p-values!</a></p>
<p>Introduction: Joshua Vogelstein writes:
  
I know you’ve discussed this on your blog in the past, but I don’t know exactly how you’d answer the following query:


Suppose you run an analysis and obtain a p-value of 10^-300.  What would you actually report?  I’m fairly confident that I’m not that confident :) I’m guessing: “p-value \approx 0.”


One possibility is to determine the accuracy with this one *could* in theory know, by virtue of the sample size, and say that p-value is less than or equal to that?  For example, if I used a Monte Carlo approach to generate the null distribution with 10,000 samples, and I found that the observed value was more extreme than all of the sample values, then I might say that p is less than or equal to 1/10,000.

  
My reply:  Mosteller and Wallace talked a bit about this in their book, the idea that there are various other 1-in-a-million possibilities (for example, the data were faked somewhere before they got to you) so p-values such as 10^-6 don’t really mean an</p><p>6 0.9490571 <a title="2046-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-24-In_case_you_were_wondering%2C_here%E2%80%99s_the_price_of_milk.html">588 andrew gelman stats-2011-02-24-In case you were wondering, here’s the price of milk</a></p>
<p>7 0.94168758 <a title="2046-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-05-Shocking_but_not_surprising.html">698 andrew gelman stats-2011-05-05-Shocking but not surprising</a></p>
<p>8 0.9416247 <a title="2046-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-14-I_hate_to_get_all_Gerd_Gigerenzer_on_you_here%2C_but_._._..html">1319 andrew gelman stats-2012-05-14-I hate to get all Gerd Gigerenzer on you here, but . . .</a></p>
<p>9 0.93907124 <a title="2046-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-28-More_on_Bayesian_deduction-induction.html">114 andrew gelman stats-2010-06-28-More on Bayesian deduction-induction</a></p>
<p>10 0.93242371 <a title="2046-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-20-Reading_a_research_paper_%21%3D_agreeing_with_its_claims.html">1074 andrew gelman stats-2011-12-20-Reading a research paper != agreeing with its claims</a></p>
<p>11 0.92881417 <a title="2046-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-18-Should_kids_be_able_to_bring_their_own_lunches_to_school%3F.html">718 andrew gelman stats-2011-05-18-Should kids be able to bring their own lunches to school?</a></p>
<p>12 0.92466712 <a title="2046-lda-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-19-My_short_career_as_a_Freud_expert.html">2338 andrew gelman stats-2014-05-19-My short career as a Freud expert</a></p>
<p>13 0.92190307 <a title="2046-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-16-Whither_the_%E2%80%9Cbet_on_sparsity_principle%E2%80%9D_in_a_nonsparse_world%3F.html">2136 andrew gelman stats-2013-12-16-Whither the “bet on sparsity principle” in a nonsparse world?</a></p>
<p>14 0.92158568 <a title="2046-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-29-Infovis_vs._statgraphics%3A__A_clear_example_of_their_different_goals.html">829 andrew gelman stats-2011-07-29-Infovis vs. statgraphics:  A clear example of their different goals</a></p>
<p>15 0.91948265 <a title="2046-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-07-The_red-state%2C_blue-state_war_is_happening_in_the_upper_half_of_the_income_distribution.html">456 andrew gelman stats-2010-12-07-The red-state, blue-state war is happening in the upper half of the income distribution</a></p>
<p>16 0.91749233 <a title="2046-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-22-Statistical_inference_based_on_the_minimum_description_length_principle.html">815 andrew gelman stats-2011-07-22-Statistical inference based on the minimum description length principle</a></p>
<p>17 0.9132995 <a title="2046-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-How_does_Bayes_do_it%3F.html">247 andrew gelman stats-2010-09-01-How does Bayes do it?</a></p>
<p>18 0.91309613 <a title="2046-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-20-Maybe_a_great_idea_in_theory%2C_didn%E2%80%99t_work_so_well_in_practice.html">621 andrew gelman stats-2011-03-20-Maybe a great idea in theory, didn’t work so well in practice</a></p>
<p>19 0.91178566 <a title="2046-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-22-Evaluating_the_impacts_of_welfare_reform%3F.html">1732 andrew gelman stats-2013-02-22-Evaluating the impacts of welfare reform?</a></p>
<p>20 0.91091657 <a title="2046-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-25-Spam%21.html">2148 andrew gelman stats-2013-12-25-Spam!</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
