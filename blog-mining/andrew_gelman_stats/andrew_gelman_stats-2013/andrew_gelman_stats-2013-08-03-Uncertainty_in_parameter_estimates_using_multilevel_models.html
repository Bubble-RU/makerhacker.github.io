<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1966" href="#">andrew_gelman_stats-2013-1966</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1966-html" href="http://andrewgelman.com/2013/08/03/uncertainty-in-parameter-estimates-using-multilevel-models/">html</a></p><p>Introduction: David Hsu writes: 
   
 I have a (perhaps) simple question about uncertainty in parameter estimates using multilevel models — what is an appropriate threshold for measure parameter uncertainty in a multilevel model? 
 
The reason why I ask is that I set out to do a crossed two-way model with two varying intercepts, similar to your flight simulator example in your 2007 book.  The difference is that I have a lot of predictors specific to each cell (I think equivalent to airport and pilot in your example), and I find after modeling this in JAGS, I happily find that the predictors are much less important than the variability by cell (airport and pilot effects).  Happily because this is what I am writing a paper about.
 
However, I then went to check subsets of predictors using lm() and lmer().  I understand that they all use different estimation methods, but what I can’t figure out is why the errors on all of the coefficient estimates are *so* different.  
 
For example, using JAGS, and th</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 David Hsu writes:       I have a (perhaps) simple question about uncertainty in parameter estimates using multilevel models — what is an appropriate threshold for measure parameter uncertainty in a multilevel model? [sent-1, score-0.853]
</p><p>2 The reason why I ask is that I set out to do a crossed two-way model with two varying intercepts, similar to your flight simulator example in your 2007 book. [sent-2, score-0.665]
</p><p>3 The difference is that I have a lot of predictors specific to each cell (I think equivalent to airport and pilot in your example), and I find after modeling this in JAGS, I happily find that the predictors are much less important than the variability by cell (airport and pilot effects). [sent-3, score-1.963]
</p><p>4 However, I then went to check subsets of predictors using lm() and lmer(). [sent-5, score-0.617]
</p><p>5 I understand that they all use different estimation methods, but what I can’t figure out is why the errors on all of the coefficient estimates are *so* different. [sent-6, score-0.406]
</p><p>6 For example, using JAGS, and then visualizing the predictors relative to zero (i. [sent-7, score-0.611]
</p><p>7 , the null hypothesis) using a plot similar to your ANOVA graphs (figure 22. [sent-9, score-0.177]
</p><p>8 3), I would find that if I made the error bars either based on 95% confidence intervals or +/- 2 standard deviations, one would conclude that the predictors are not very significant (since 2. [sent-11, score-0.68]
</p><p>9 But if I use the lm() function to check the model without any varying intercepts, I get all of the predictors significant. [sent-14, score-0.623]
</p><p>10 It is based on 12,000 or so observations, so I guess I’d expect the standard errors to be low. [sent-15, score-0.513]
</p><p>11 But by the same token, I’d expect the standard deviation of the chains for each estimate to be equivalently low and asymptotically approaching the standard errors from the normal OLS. [sent-16, score-1.126]
</p><p>12 Even weak prior information (for example, half-Cauchy priors that bound the parameters away from unrealistically high values) can be useful in constraining group-level variance parameters (especially when the number of groups is small). [sent-21, score-0.483]
</p><p>13 Third, if you fit lm(), you’ll tend to get standard errors that are too small because you’re not incorporating the correlations in the unexplained errors. [sent-22, score-0.694]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('predictors', 0.332), ('lm', 0.289), ('errors', 0.235), ('airport', 0.221), ('intercepts', 0.188), ('happily', 0.185), ('standard', 0.184), ('lmer', 0.178), ('jags', 0.17), ('pilot', 0.17), ('cell', 0.152), ('varying', 0.129), ('simulator', 0.117), ('unrealistically', 0.11), ('incorporating', 0.106), ('span', 0.106), ('constraining', 0.106), ('uncertainty', 0.103), ('crossed', 0.102), ('parameter', 0.101), ('unexplained', 0.099), ('approaching', 0.099), ('using', 0.098), ('multilevel', 0.097), ('subsets', 0.094), ('parameters', 0.094), ('expect', 0.094), ('zero', 0.093), ('check', 0.093), ('equivalently', 0.092), ('flight', 0.091), ('asymptotically', 0.091), ('figure', 0.09), ('visualizing', 0.088), ('hsu', 0.086), ('find', 0.085), ('anova', 0.084), ('deviations', 0.081), ('estimates', 0.081), ('bound', 0.079), ('bars', 0.079), ('variability', 0.079), ('similar', 0.079), ('example', 0.078), ('chains', 0.077), ('limits', 0.075), ('threshold', 0.072), ('deviation', 0.07), ('small', 0.07), ('model', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1966-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>Introduction: David Hsu writes: 
   
 I have a (perhaps) simple question about uncertainty in parameter estimates using multilevel models — what is an appropriate threshold for measure parameter uncertainty in a multilevel model? 
 
The reason why I ask is that I set out to do a crossed two-way model with two varying intercepts, similar to your flight simulator example in your 2007 book.  The difference is that I have a lot of predictors specific to each cell (I think equivalent to airport and pilot in your example), and I find after modeling this in JAGS, I happily find that the predictors are much less important than the variability by cell (airport and pilot effects).  Happily because this is what I am writing a paper about.
 
However, I then went to check subsets of predictors using lm() and lmer().  I understand that they all use different estimation methods, but what I can’t figure out is why the errors on all of the coefficient estimates are *so* different.  
 
For example, using JAGS, and th</p><p>2 0.19274844 <a title="1966-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>Introduction: Chris Che-Castaldo writes:
  
I am trying to compute variance components for a hierarchical model where the group level has two binary predictors and their interaction. When I model each of these three predictors as N(0, tau) the model will not converge, perhaps because the number of coefficients in each batch is so small (2 for the main effects and 4 for the interaction). Although I could simply leave all these as predictors as unmodeled fixed effects, the last sentence of section 21.2 on page 462 of Gelman and Hill (2007) suggests this would not be a wise course of action:

 
For example, it is not clear how to define the (finite) standard deviation of variables that are included in interactions.
 

I am curious – is there still no clear cut way to directly compute the finite standard deviation for binary unmodeled variables that are also part of an interaction as well as the interaction itself?
  
My reply:  I’d recommend including these in your model (it’s probably easiest to do so</p><p>3 0.17743894 <a title="1966-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>Introduction: Zoltan Fazekas writes:
  
I am a 2nd year graduate student in political science at the University of Vienna. In my empirical research I often employ multilevel modeling, and recently I came across a situation that kept me wondering for quite a while. As I did not find much on this in the literature and considering the topics that you work on and blog about, I figured I will try to contact you.
      
The situation is as follows: in a linear multilevel model, there are two important individual level predictors (x1 and x2) and a set of controls. Let us assume that there is a theoretically grounded argument suggesting that an interaction between x1 and x2 should be included in the model (x1 * x2). Both x1 and x2 are let to vary randomly across groups. Would this directly imply that the coefficient of the interaction should also be left to vary across country? This is even more burning if there is no specific hypothesis on the variance of the conditional effect across countries. And then i</p><p>4 0.16129002 <a title="1966-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>Introduction: Yi-Chun Ou writes: 
  
  
I am using a multilevel model with three levels. I read that you wrote a book about multilevel models, and wonder if you can solve the following question.  


The data structure is like this: 


Level one: customer (8444 customers) 
Level two: companys (90 companies) 
Level three: industry (17 industries) 


I use 6 level-three variables (i.e. industry characteristics) to explain the variance of the level-one effect across industries. The question here is whether there is an over-fitting problem since there are only 17 industries. I understand that this must be a problem for non-multilevel models, but is it also a problem for multilevel models?
  
My reply:  Yes, this could be a problem.  I’d suggest combining some of your variables into a common score, or using only some of the variables, or using strong priors to control the inferences.  This is an interesting and important area of statistics research, to do this sort of thing systematically.  There’s lots o</p><p>5 0.16038516 <a title="1966-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>Introduction: Nick Firoozye writes:
  
While I am absolutely sympathetic to the Bayesian agenda I am often troubled by the requirement of having priors. We must have priors on the parameter of an infinite number of model we have never seen before and I find this troubling. There is a similarly troubling problem in economics of utility theory. Utility is on consumables. To be complete a consumer must assign utility to all sorts of things they never would have encountered. More recent versions of utility theory instead make consumption goods a portfolio of attributes. Cadillacs are x many units of luxury y of transport etc etc. And we can automatically have personal utilities to all these attributes.  


I don’t ever see parameters. Some model have few and some have hundreds. Instead, I see data. So I don’t know how to have an opinion on parameters themselves. Rather I think it far more natural to have opinions on the behavior of models. The prior predictive density is a good and sensible notion. Also</p><p>6 0.15618484 <a title="1966-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-21-Building_a_regression_model_._._._with_only_27_data_points.html">1506 andrew gelman stats-2012-09-21-Building a regression model . . . with only 27 data points</a></p>
<p>7 0.15579839 <a title="1966-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-25-Avoiding_boundary_estimates_using_a_prior_distribution_as_regularization.html">779 andrew gelman stats-2011-06-25-Avoiding boundary estimates using a prior distribution as regularization</a></p>
<p>8 0.15525022 <a title="1966-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<p>9 0.14835873 <a title="1966-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-25-Is_instrumental_variables_analysis_particularly_susceptible_to_Type_M_errors%3F.html">368 andrew gelman stats-2010-10-25-Is instrumental variables analysis particularly susceptible to Type M errors?</a></p>
<p>10 0.14369939 <a title="1966-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-10-Cross-validation_and_Bayesian_estimation_of_tuning_parameters.html">2129 andrew gelman stats-2013-12-10-Cross-validation and Bayesian estimation of tuning parameters</a></p>
<p>11 0.14040053 <a title="1966-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-10-Combining_data_from_many_sources.html">948 andrew gelman stats-2011-10-10-Combining data from many sources</a></p>
<p>12 0.13653359 <a title="1966-tfidf-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-08-Regression_and_causality_and_variable_ordering.html">2364 andrew gelman stats-2014-06-08-Regression and causality and variable ordering</a></p>
<p>13 0.13227031 <a title="1966-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-29-More_on_scaled-inverse_Wishart_and_prior_independence.html">1474 andrew gelman stats-2012-08-29-More on scaled-inverse Wishart and prior independence</a></p>
<p>14 0.13090475 <a title="1966-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-13-Question_3_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1317 andrew gelman stats-2012-05-13-Question 3 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>15 0.1290292 <a title="1966-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>16 0.12878585 <a title="1966-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>17 0.12479214 <a title="1966-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>18 0.1238957 <a title="1966-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<p>19 0.12304643 <a title="1966-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<p>20 0.12243699 <a title="1966-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-04-Statistics_ethics_question.html">695 andrew gelman stats-2011-05-04-Statistics ethics question</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.202), (1, 0.187), (2, 0.105), (3, -0.041), (4, 0.105), (5, -0.027), (6, 0.057), (7, -0.061), (8, -0.017), (9, 0.039), (10, 0.018), (11, 0.012), (12, 0.03), (13, -0.022), (14, 0.022), (15, -0.022), (16, -0.077), (17, 0.003), (18, 0.015), (19, -0.024), (20, 0.015), (21, 0.007), (22, 0.046), (23, 0.006), (24, -0.006), (25, -0.081), (26, -0.032), (27, -0.004), (28, -0.046), (29, -0.005), (30, 0.014), (31, 0.001), (32, 0.016), (33, -0.029), (34, 0.013), (35, -0.002), (36, -0.003), (37, 0.004), (38, 0.061), (39, -0.057), (40, -0.029), (41, -0.063), (42, 0.004), (43, 0.05), (44, -0.054), (45, -0.029), (46, -0.022), (47, -0.025), (48, 0.01), (49, -0.005)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97566003 <a title="1966-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>Introduction: David Hsu writes: 
   
 I have a (perhaps) simple question about uncertainty in parameter estimates using multilevel models — what is an appropriate threshold for measure parameter uncertainty in a multilevel model? 
 
The reason why I ask is that I set out to do a crossed two-way model with two varying intercepts, similar to your flight simulator example in your 2007 book.  The difference is that I have a lot of predictors specific to each cell (I think equivalent to airport and pilot in your example), and I find after modeling this in JAGS, I happily find that the predictors are much less important than the variability by cell (airport and pilot effects).  Happily because this is what I am writing a paper about.
 
However, I then went to check subsets of predictors using lm() and lmer().  I understand that they all use different estimation methods, but what I can’t figure out is why the errors on all of the coefficient estimates are *so* different.  
 
For example, using JAGS, and th</p><p>2 0.8177501 <a title="1966-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>Introduction: Chris Che-Castaldo writes:
  
I am trying to compute variance components for a hierarchical model where the group level has two binary predictors and their interaction. When I model each of these three predictors as N(0, tau) the model will not converge, perhaps because the number of coefficients in each batch is so small (2 for the main effects and 4 for the interaction). Although I could simply leave all these as predictors as unmodeled fixed effects, the last sentence of section 21.2 on page 462 of Gelman and Hill (2007) suggests this would not be a wise course of action:

 
For example, it is not clear how to define the (finite) standard deviation of variables that are included in interactions.
 

I am curious – is there still no clear cut way to directly compute the finite standard deviation for binary unmodeled variables that are also part of an interaction as well as the interaction itself?
  
My reply:  I’d recommend including these in your model (it’s probably easiest to do so</p><p>3 0.77989465 <a title="1966-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>Introduction: Alex Hoffman points me to  this interview  by Dylan Matthews of education researcher Thomas Kane, who at one point says,
  
Once you corrected for measurement error, a teacher’s score on their chosen videos and on their unchosen videos were correlated at 1. They were perfectly correlated.
  
Hoffman asks, “What do you think? Do you think that just maybe, perhaps, it’s possible we aught to consider, I’m just throwing out the possibility that it might be that the procedure for correcting measurement error might, you now, be a little too strong?”
 
I don’t know exactly what’s happening here, but it might be something that I’ve seen on occasion when fitting multilevel models using a point estimate for the group-level variance.  It goes like this:  measurement-error models are multilevel models, they involve the estimation of a distribution of a latent variable.  When fitting multilevel models, it is possible to estimate the group-level variance to be zero, even though the group-level varia</p><p>4 0.77815998 <a title="1966-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-That_half-Cauchy_prior.html">184 andrew gelman stats-2010-08-04-That half-Cauchy prior</a></p>
<p>Introduction: Xiaoyu Qian writes:
  
 
I have a question when I apply the half-Cauchy prior (Gelman, 2006) for the variance parameter in a hierarchical model. The model I used is a three level IRT model equivalent to a Rasch model. The variance parameter I try to estimate is at the third level. The group size ranges from 15 to 44. The data is TIMSS 2007 data.


I used the syntax provided by the paper and found that the convergence of the standard deviation term is good (sigma.theta), however, the convergence for the parameter “xi” is not very good. Does it mean the whole model has not converged? Do you have any suggestion for this situation.


I also used the uniform prior and correlate the result with the half-Cauchy result for the standard deviation term. The results correlated .99.
 

 
My reply:  It’s not a problem if xi does not converge well.  It’s |xi|*sigma that is relevant.  And, if the number of groups is large, the prior probably won’t matter so much, which would explain your 99% correlat</p><p>5 0.77425039 <a title="1966-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-10-R_vs._Stata%2C_or%2C_Different_ways_to_estimate_multilevel_models.html">269 andrew gelman stats-2010-09-10-R vs. Stata, or, Different ways to estimate multilevel models</a></p>
<p>Introduction: Cyrus writes:
  
I [Cyrus] was teaching a class on multilevel modeling, and we were playing around with different method to fit a random effects logit model with 2 random intercepts—one corresponding to “family” and another corresponding to “community” (labeled “mom” and “cluster” in the data, respectively).  There are also a few regressors at the individual, family, and community level.  We were replicating in part some of the results from the  following paper :  Improved estimation procedures for multilevel models with binary response: a case-study, by G Rodriguez, N Goldman.


(I say “replicating in part” because we didn’t include all the regressors that they use, only a subset.)  We were looking at the performance of estimation via glmer in R’s lme4 package, glmmPQL in R’s MASS package, and Stata’s xtmelogit.  We wanted to study the performance of various estimation methods, including adaptive quadrature methods and penalized quasi-likelihood.


I was shocked to discover that glmer</p><p>6 0.76550514 <a title="1966-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>7 0.76307023 <a title="1966-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Allowing_interaction_terms_to_vary.html">753 andrew gelman stats-2011-06-09-Allowing interaction terms to vary</a></p>
<p>8 0.75472999 <a title="1966-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>9 0.75371361 <a title="1966-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-21-Avoiding_boundary_estimates_in_linear_mixed_models.html">918 andrew gelman stats-2011-09-21-Avoiding boundary estimates in linear mixed models</a></p>
<p>10 0.74535614 <a title="1966-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-21-Finite-population_Anova_calculations_for_models_with_interactions.html">1686 andrew gelman stats-2013-01-21-Finite-population Anova calculations for models with interactions</a></p>
<p>11 0.7436403 <a title="1966-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Adding_more_information_can_make_the_variance_go_up_%28depending_on_your_model%29.html">810 andrew gelman stats-2011-07-20-Adding more information can make the variance go up (depending on your model)</a></p>
<p>12 0.74122339 <a title="1966-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-19-Index_or_indicator_variables.html">2296 andrew gelman stats-2014-04-19-Index or indicator variables</a></p>
<p>13 0.73601329 <a title="1966-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>14 0.72799641 <a title="1966-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>15 0.72651088 <a title="1966-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>16 0.71628702 <a title="1966-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<p>17 0.71529108 <a title="1966-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-25-Avoiding_boundary_estimates_using_a_prior_distribution_as_regularization.html">779 andrew gelman stats-2011-06-25-Avoiding boundary estimates using a prior distribution as regularization</a></p>
<p>18 0.71082711 <a title="1966-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-22-Handling_multiple_versions_of_an_outcome_variable.html">726 andrew gelman stats-2011-05-22-Handling multiple versions of an outcome variable</a></p>
<p>19 0.70748675 <a title="1966-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>20 0.70147157 <a title="1966-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-17-If_you_get_to_the_point_of_asking%2C_just_do_it.__But_some_difficulties_do_arise_._._..html">2294 andrew gelman stats-2014-04-17-If you get to the point of asking, just do it.  But some difficulties do arise . . .</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.012), (9, 0.017), (14, 0.01), (16, 0.045), (21, 0.026), (24, 0.235), (35, 0.011), (36, 0.036), (58, 0.094), (72, 0.039), (85, 0.018), (86, 0.027), (96, 0.016), (98, 0.025), (99, 0.262)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96955228 <a title="1966-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>Introduction: David Hsu writes: 
   
 I have a (perhaps) simple question about uncertainty in parameter estimates using multilevel models — what is an appropriate threshold for measure parameter uncertainty in a multilevel model? 
 
The reason why I ask is that I set out to do a crossed two-way model with two varying intercepts, similar to your flight simulator example in your 2007 book.  The difference is that I have a lot of predictors specific to each cell (I think equivalent to airport and pilot in your example), and I find after modeling this in JAGS, I happily find that the predictors are much less important than the variability by cell (airport and pilot effects).  Happily because this is what I am writing a paper about.
 
However, I then went to check subsets of predictors using lm() and lmer().  I understand that they all use different estimation methods, but what I can’t figure out is why the errors on all of the coefficient estimates are *so* different.  
 
For example, using JAGS, and th</p><p>2 0.9633404 <a title="1966-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-14-%E2%80%9CThe_best_data_visualizations_should_stand_on_their_own%E2%80%9D%3F__I_don%E2%80%99t_think_so..html">574 andrew gelman stats-2011-02-14-“The best data visualizations should stand on their own”?  I don’t think so.</a></p>
<p>Introduction: Jimmy pointed me to  this  blog by Drew Conway on word clouds.  I don’t have much to say about Conway’s specifics–word clouds aren’t really my thing, but I’m glad that people are thinking about how to do them better–but I did notice one phrase of his that I’ll dispute.  Conway writes
  
The best data visualizations should stand on their own . . .
  
I disagree.  I prefer the saying, “A picture plus 1000 words is better than two pictures or 2000 words.”  That is, I see a positive interaction between words and pictures or, to put it another way, diminishing returns for words or pictures on their own.  I don’t have any big theory for this, but I think, when expressed as a joint value function, my idea makes sense.  Also, I live this suggestion in my own work.  I typically accompany my graphs with long captions and I try to accompany my words with pictures (although I’m not doing it here, because with the software I use, it’s much easier to type more words than to find, scale, and insert i</p><p>3 0.9588151 <a title="1966-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-22-Statistical_inference_based_on_the_minimum_description_length_principle.html">815 andrew gelman stats-2011-07-22-Statistical inference based on the minimum description length principle</a></p>
<p>Introduction: Tom Ball writes:
  
Here’s another query to add to the stats backlog…Minimum Description Length (MDL).  I’m  attaching  a 2002 Psych Rev paper on same.  Basically, it’s an approach to model selection that replaces goodness of fit with generalizability or complexity.


Would be great to get your response to this approach.
  
My reply:
 
I’ve heard about the minimum description length principle for a long time but have never really understood it.  So I have nothing to say!  Anyone who has anything useful to say on the topic, feel free to add in the comments.
 
The rest of you might wonder why I posted this.  I just thought it would be good for you to have some sense of the boundaries of my knowledge.</p><p>4 0.94869041 <a title="1966-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-03-Setting_aside_the_politics%2C_the_debate_over_the_new_health-care_study_reveals_that_we%E2%80%99re_moving_to_a_new_high_standard_of_statistical_journalism.html">1838 andrew gelman stats-2013-05-03-Setting aside the politics, the debate over the new health-care study reveals that we’re moving to a new high standard of statistical journalism</a></p>
<p>Introduction: Pointing to this  news article  by Megan McArdle discussing a recent study of Medicaid recipients, Jonathan Falk writes:
  
Forget the interpretation for a moment, and the political spin, but haven’t we reached an interesting point when a journalist says things like:

 
When you do an RCT with more than 12,000 people in it, and your defense of your hypothesis is that maybe the study just didn’t have enough power, what you’re actually saying is “the beneficial effects are probably pretty small”.
 

and

 
A good Bayesian—and aren’t most of us are supposed to be good Bayesians these days?—should be updating in light of this new information. Given this result, what is the likelihood that Obamacare will have a positive impact on the average health of Americans? Every one of us, for or against, should be revising that probability downwards. I’m not saying that you have to revise it to zero; I certainly haven’t. But however high it was yesterday, it should be somewhat lower today.
 
  
This</p><p>5 0.94783658 <a title="1966-lda-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>Introduction: Ken Rice writes:
  
In the recent discussion on  stopping rules  I saw a comment that I wanted to chip in on, but thought it might get a bit lost, in the already long thread. Apologies in advance if I misinterpreted what you wrote, or am trying to tell you things you already know.


 The comment  was: “In Bayesian decision making, there is a utility function and you choose the decision with highest expected utility. Making a decision based on statistical significance does not correspond to any utility function.”


… which immediately suggests  this  little 2010 paper; A Decision-Theoretic Formulation of Fisher’s Approach to Testing, The American Statistician, 64(4) 345-349. It contains utilities that lead to decisions that very closely mimic classical Wald tests, and provides a rationale for why this utility is not totally unconnected from how some scientists think. Some (old) slides discussing it  are here .


A few notes, on things not in the paper:


* I know you don’t like squared-</p><p>6 0.94679379 <a title="1966-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-29-More_on_scaled-inverse_Wishart_and_prior_independence.html">1474 andrew gelman stats-2012-08-29-More on scaled-inverse Wishart and prior independence</a></p>
<p>7 0.94678438 <a title="1966-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-11-Steve_Jobs%E2%80%99s_cancer_and_science-based_medicine.html">953 andrew gelman stats-2011-10-11-Steve Jobs’s cancer and science-based medicine</a></p>
<p>8 0.94672346 <a title="1966-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-23-My_new_writing_strategy.html">727 andrew gelman stats-2011-05-23-My new writing strategy</a></p>
<p>9 0.94591415 <a title="1966-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-07-Robust_logistic_regression.html">1886 andrew gelman stats-2013-06-07-Robust logistic regression</a></p>
<p>10 0.94581926 <a title="1966-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-10-Using_a_%E2%80%9Cpure_infographic%E2%80%9D_to_explore_differences_between_information_visualization_and_statistical_graphics.html">847 andrew gelman stats-2011-08-10-Using a “pure infographic” to explore differences between information visualization and statistical graphics</a></p>
<p>11 0.94522655 <a title="1966-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-11-My_problem_with_the_Lindley_paradox.html">1757 andrew gelman stats-2013-03-11-My problem with the Lindley paradox</a></p>
<p>12 0.94515675 <a title="1966-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-18-Understanding_posterior_p-values.html">2029 andrew gelman stats-2013-09-18-Understanding posterior p-values</a></p>
<p>13 0.94441718 <a title="1966-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-14-Extra_babies_on_Valentine%E2%80%99s_Day%2C_fewer_on_Halloween%3F.html">1167 andrew gelman stats-2012-02-14-Extra babies on Valentine’s Day, fewer on Halloween?</a></p>
<p>14 0.94401991 <a title="1966-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Blogads_update.html">1240 andrew gelman stats-2012-04-02-Blogads update</a></p>
<p>15 0.94375539 <a title="1966-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-%E2%80%9CThe_difference_between_._._.%E2%80%9D%3A__It%E2%80%99s_not_just_p%3D.05_vs._p%3D.06.html">1072 andrew gelman stats-2011-12-19-“The difference between . . .”:  It’s not just p=.05 vs. p=.06</a></p>
<p>16 0.94357443 <a title="1966-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-05-What_is_a_prior_distribution%3F.html">1155 andrew gelman stats-2012-02-05-What is a prior distribution?</a></p>
<p>17 0.94290173 <a title="1966-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-07-X_on_JLP.html">1792 andrew gelman stats-2013-04-07-X on JLP</a></p>
<p>18 0.94285142 <a title="1966-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-27-%E2%80%9CKeeping_things_unridiculous%E2%80%9D%3A__Berger%2C_O%E2%80%99Hagan%2C_and_me_on_weakly_informative_priors.html">1087 andrew gelman stats-2011-12-27-“Keeping things unridiculous”:  Berger, O’Hagan, and me on weakly informative priors</a></p>
<p>19 0.94284463 <a title="1966-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-21-D._Buggin.html">1465 andrew gelman stats-2012-08-21-D. Buggin</a></p>
<p>20 0.94269788 <a title="1966-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-10-The_last_great_essayist%3F.html">197 andrew gelman stats-2010-08-10-The last great essayist?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
