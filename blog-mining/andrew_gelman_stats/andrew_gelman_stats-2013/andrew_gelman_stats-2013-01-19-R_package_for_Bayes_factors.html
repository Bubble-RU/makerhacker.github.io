<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1682 andrew gelman stats-2013-01-19-R package for Bayes factors</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1682" href="#">andrew_gelman_stats-2013-1682</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1682 andrew gelman stats-2013-01-19-R package for Bayes factors</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1682-html" href="http://andrewgelman.com/2013/01/19/r-package-for-bayes-factors/">html</a></p><p>Introduction: Richard Morey writes:
  
You and your blog readers may be interested to know that a we’ve released a major new version of the BayesFactor package to CRAN. The package computes Bayes factors for linear mixed models and regression models. Of course, I’m aware you don’t like point-null model comparisons, but the package does more than that; it also allows sampling from posterior distributions of the compared models, in much the same way that your arm package does with lmer objects. The sampling (both for the Bayes factors and posteriors) is quite fast, since the back end is written in C.


Some basic examples using the package can be found  here , and the CRAN page is  here .
  
Indeed I don’t like point-null model comparisons . . . but maybe this will be useful to some of you!</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Richard Morey writes:    You and your blog readers may be interested to know that a we’ve released a major new version of the BayesFactor package to CRAN. [sent-1, score-1.3]
</p><p>2 The package computes Bayes factors for linear mixed models and regression models. [sent-2, score-1.251]
</p><p>3 Of course, I’m aware you don’t like point-null model comparisons, but the package does more than that; it also allows sampling from posterior distributions of the compared models, in much the same way that your arm package does with lmer objects. [sent-3, score-2.483]
</p><p>4 The sampling (both for the Bayes factors and posteriors) is quite fast, since the back end is written in C. [sent-4, score-0.781]
</p><p>5 Some basic examples using the package can be found  here , and the CRAN page is  here . [sent-5, score-0.985]
</p><p>6 Indeed I don’t like point-null model comparisons . [sent-6, score-0.34]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('package', 0.611), ('factors', 0.212), ('cran', 0.21), ('bayes', 0.205), ('sampling', 0.202), ('comparisons', 0.197), ('morey', 0.197), ('posteriors', 0.192), ('lmer', 0.177), ('released', 0.142), ('arm', 0.136), ('mixed', 0.132), ('allows', 0.126), ('fast', 0.125), ('richard', 0.124), ('models', 0.117), ('aware', 0.113), ('distributions', 0.104), ('linear', 0.104), ('version', 0.102), ('major', 0.099), ('posterior', 0.096), ('basic', 0.094), ('model', 0.092), ('compared', 0.091), ('page', 0.087), ('written', 0.085), ('readers', 0.084), ('examples', 0.08), ('end', 0.079), ('indeed', 0.075), ('quite', 0.075), ('regression', 0.075), ('useful', 0.074), ('interested', 0.069), ('since', 0.066), ('course', 0.066), ('found', 0.064), ('may', 0.062), ('back', 0.062), ('blog', 0.052), ('maybe', 0.051), ('like', 0.051), ('using', 0.049), ('new', 0.042), ('ve', 0.039), ('know', 0.037), ('way', 0.037), ('much', 0.036), ('writes', 0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1682-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-R_package_for_Bayes_factors.html">1682 andrew gelman stats-2013-01-19-R package for Bayes factors</a></p>
<p>Introduction: Richard Morey writes:
  
You and your blog readers may be interested to know that a we’ve released a major new version of the BayesFactor package to CRAN. The package computes Bayes factors for linear mixed models and regression models. Of course, I’m aware you don’t like point-null model comparisons, but the package does more than that; it also allows sampling from posterior distributions of the compared models, in much the same way that your arm package does with lmer objects. The sampling (both for the Bayes factors and posteriors) is quite fast, since the back end is written in C.


Some basic examples using the package can be found  here , and the CRAN page is  here .
  
Indeed I don’t like point-null model comparisons . . . but maybe this will be useful to some of you!</p><p>2 0.39729309 <a title="1682-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Lessons_learned_from_a_recent_R_package_submission.html">1134 andrew gelman stats-2012-01-21-Lessons learned from a recent R package submission</a></p>
<p>Introduction: R has zillions of packages, and people are submitting  new ones each day .  The volunteers who keep R going are doing an incredibly useful service to the profession, and they’re  busy .
 
   
 
A colleague sends in some suugestions based on a recent experience with a package update:
  
 1. Always use the R dev version to write a package.  Not the current stable release.  The R people use the R dev version to check your package anyway.  If you don’t use the R dev version, there is chance that your package won’t pass the check.  In my own experience, every time R has a major change, it tends to have new standards and find new errors in your package with these new standards.  So better use the dev version to find out the potential errors in advance.


 2. After submission, write an email to claim it.   I used to submit the package to the CRAN without writing an email.  This was standard operating procedure, but it has changed. Writing an email to claim about the submission is now a requir</p><p>3 0.32582426 <a title="1682-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-A_new_R_package_for_fititng_multilevel_models.html">501 andrew gelman stats-2011-01-04-A new R package for fititng multilevel models</a></p>
<p>Introduction: Joscha Legewie points to  this article  by Lars Ronnegard, Xia Shen, and Moudud Alam, “hglm: A Package for Fitting Hierarchical Generalized Linear Models,” which just appeared in the R journal.  This new package has the advantage, compared to lmer(), of allowing non-normal distributions for the varying coefficients.  On the downside, they seem to have reverted to the ugly lme-style syntax (for example, “fixed = y ~ week, random = ~ 1|ID” rather than “y ~ week + (1|D)”).  The old-style syntax has difficulties handling non-nested grouping factors.  They also say they can estimated models with correlated random effects, but isn’t that just the same as varying-intercept, varying-slope models, which lmer (or Stata alternatives such as gllam) can already do?  There’s also a bunch of stuff on H-likelihood theory, which seems pretty pointless to me (although probably it won’t do much harm either).
 
In any case, this package might be useful to some of you, hence this note.</p><p>4 0.21776931 <a title="1682-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-10-Two_great_tastes_that_taste_great_together.html">25 andrew gelman stats-2010-05-10-Two great tastes that taste great together</a></p>
<p>Introduction: Vlad Kogan writes:
  
I’ve using your book on regression and multilevel modeling and have a quick R question for you. Do you happen to know if there is any R package that can estimate a two-stage (instrumental variable) multi-level model?
  
My reply:  I don’t know.  I’ll post on blog and maybe there will be a response.  You could also try the R help list.</p><p>5 0.20714197 <a title="1682-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-19-R_package_for_effect_size_calculations_for_psychology_researchers.html">2069 andrew gelman stats-2013-10-19-R package for effect size calculations for psychology researchers</a></p>
<p>Introduction: Dan Gerlanc writes:
  
I read your  post  the other day [now the other month, as our blog is on a bit of a delay] on helping psychologists do research and thought you might be interested in our R package, “bootES”, for robust effect size calculation and confidence interval estimation using resampling techniques. The package provides one function, ‘bootES’, that makes a variety of effect size calculations fairly straightforward for researchers with limited programming experience.  The majority of the implemented are not available in R or SPSS without custom coding. Kris Kirby (Williams College) and I have published a paper in Behavioral Research Methods describing the methods and providing a tutorial on use of the package: http://bit.ly/YIM6VD. We hope that it’s useful to psychologists and other social science researchers!
  
I haven’t tried this out but it might be of interest for some of you.</p><p>6 0.17398512 <a title="1682-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-17-Getting_arm_and_lme4_running_on_the_Mac.html">347 andrew gelman stats-2010-10-17-Getting arm and lme4 running on the Mac</a></p>
<p>7 0.15242738 <a title="1682-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-29-The_gradual_transition_to_replicable_science.html">2117 andrew gelman stats-2013-11-29-The gradual transition to replicable science</a></p>
<p>8 0.13331537 <a title="1682-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-20-The_pervasive_twoishness_of_statistics%3B_in_particular%2C_the_%E2%80%9Csampling_distribution%E2%80%9D_and_the_%E2%80%9Clikelihood%E2%80%9D_are_two_different_models%2C_and_that%E2%80%99s_a_good_thing.html">774 andrew gelman stats-2011-06-20-The pervasive twoishness of statistics; in particular, the “sampling distribution” and the “likelihood” are two different models, and that’s a good thing</a></p>
<p>9 0.12935165 <a title="1682-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-04-Handy_Matrix_Cheat_Sheet%2C_with_Gradients.html">555 andrew gelman stats-2011-02-04-Handy Matrix Cheat Sheet, with Gradients</a></p>
<p>10 0.11800555 <a title="1682-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<p>11 0.11418831 <a title="1682-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>12 0.11379152 <a title="1682-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-17-Modeling_group-level_predictors_in_a_multilevel_regression.html">1216 andrew gelman stats-2012-03-17-Modeling group-level predictors in a multilevel regression</a></p>
<p>13 0.11197244 <a title="1682-tfidf-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-27-%E2%80%9CDisappointed_with_your_results%3F__Boost_your_scientific_paper%E2%80%9D.html">2188 andrew gelman stats-2014-01-27-“Disappointed with your results?  Boost your scientific paper”</a></p>
<p>14 0.11099374 <a title="1682-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>15 0.11099334 <a title="1682-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-17-Joanne_Gowa_scooped_me_by_22_years_in_my_criticism_of_Axelrod%E2%80%99s_Evolution_of_Cooperation.html">348 andrew gelman stats-2010-10-17-Joanne Gowa scooped me by 22 years in my criticism of Axelrod’s Evolution of Cooperation</a></p>
<p>16 0.10844017 <a title="1682-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-17-Statistics_in_a_world_where_nothing_is_random.html">1628 andrew gelman stats-2012-12-17-Statistics in a world where nothing is random</a></p>
<p>17 0.10783486 <a title="1682-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-28-New_book_by_Stef_van_Buuren_on_missing-data_imputation_looks_really_good%21.html">1642 andrew gelman stats-2012-12-28-New book by Stef van Buuren on missing-data imputation looks really good!</a></p>
<p>18 0.1067972 <a title="1682-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<p>19 0.10260285 <a title="1682-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-03-Running_into_a_Stan_Reference_by_Accident.html">2231 andrew gelman stats-2014-03-03-Running into a Stan Reference by Accident</a></p>
<p>20 0.098685957 <a title="1682-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-08-Multilevel_regression_with_shrinkage_for_%E2%80%9Cfixed%E2%80%9D_effects.html">653 andrew gelman stats-2011-04-08-Multilevel regression with shrinkage for “fixed” effects</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.142), (1, 0.112), (2, -0.001), (3, 0.036), (4, 0.07), (5, 0.042), (6, -0.002), (7, -0.079), (8, 0.045), (9, -0.018), (10, 0.019), (11, -0.005), (12, -0.007), (13, -0.003), (14, 0.027), (15, -0.018), (16, -0.028), (17, 0.031), (18, -0.019), (19, -0.016), (20, 0.016), (21, 0.01), (22, -0.018), (23, 0.021), (24, -0.008), (25, -0.007), (26, -0.026), (27, 0.05), (28, 0.084), (29, -0.023), (30, -0.063), (31, 0.042), (32, -0.001), (33, -0.002), (34, -0.014), (35, -0.018), (36, -0.004), (37, -0.02), (38, -0.026), (39, 0.003), (40, -0.043), (41, 0.025), (42, 0.06), (43, 0.004), (44, 0.017), (45, -0.043), (46, -0.12), (47, 0.04), (48, 0.006), (49, -0.142)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96019936 <a title="1682-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-R_package_for_Bayes_factors.html">1682 andrew gelman stats-2013-01-19-R package for Bayes factors</a></p>
<p>Introduction: Richard Morey writes:
  
You and your blog readers may be interested to know that a we’ve released a major new version of the BayesFactor package to CRAN. The package computes Bayes factors for linear mixed models and regression models. Of course, I’m aware you don’t like point-null model comparisons, but the package does more than that; it also allows sampling from posterior distributions of the compared models, in much the same way that your arm package does with lmer objects. The sampling (both for the Bayes factors and posteriors) is quite fast, since the back end is written in C.


Some basic examples using the package can be found  here , and the CRAN page is  here .
  
Indeed I don’t like point-null model comparisons . . . but maybe this will be useful to some of you!</p><p>2 0.85991597 <a title="1682-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-04-Handy_Matrix_Cheat_Sheet%2C_with_Gradients.html">555 andrew gelman stats-2011-02-04-Handy Matrix Cheat Sheet, with Gradients</a></p>
<p>Introduction: This post is an (unpaid) advertisement for the following extremely useful resource:
  
 Petersen, K. B. and M. S. Pedersen. 2008.   The Matrix Cookbook  .  Tehcnical Report, Technical University of Denmark. 
  
It contains 70+ pages of useful relations and derivations involving matrices.  What grabbed my eye was the computation of gradients for matrix operations ranging from eigenvalues and determinants to multivariate normal density functions.   I had no idea the multivariate normal had such a clean gradient (see section 8).
  

 
We’ve been playing around with  Hamiltonian (aka Hybrid) Monte Carlo  for sampling from the posterior of hierarchical generalized linear models with lots of interactions.  HMC speeds up Metropolis sampling by using the gradient of the log probability to drive samples in the direction of higher probability density, which is particularly useful for correlated parameters that mix slowly with standard Gibbs sampling.   Matt “III” Hoffman ‘s already got it workin</p><p>3 0.77465278 <a title="1682-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>Introduction: In response to our  recent posting  of Amazon’s offer of Bayesian Data Analysis 3rd edition at 40% off, some people asked what was in this new edition, with more information beyond the beautiful cover image and the  brief paragraph  I’d posted earlier.
 
 Here’s  the table of contents.  The following sections have all-new material:
 
1.4 New introduction of BDA principles using a simple spell checking example 
2.9 Weakly informative prior distributions 
5.7 Weakly informative priors for hierarchical variance parameters 
7.1-7.4 Predictive accuracy for model evaluation and comparison 
10.6 Computing environments 
11.4 Split R-hat 
11.5 New measure of effective number of simulation draws 
13.7 Variational inference 
13.8 Expectation propagation 
13.9 Other approximations 
14.6 Regularization for regression models 
C.1 Getting started with R and Stan 
C.2 Fitting a hierarchical model in Stan 
C.4 Programming Hamiltonian Monte Carlo in R
 
And the new chapters: 
20 Basis function models 
2</p><p>4 0.77387011 <a title="1682-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-A_new_R_package_for_fititng_multilevel_models.html">501 andrew gelman stats-2011-01-04-A new R package for fititng multilevel models</a></p>
<p>Introduction: Joscha Legewie points to  this article  by Lars Ronnegard, Xia Shen, and Moudud Alam, “hglm: A Package for Fitting Hierarchical Generalized Linear Models,” which just appeared in the R journal.  This new package has the advantage, compared to lmer(), of allowing non-normal distributions for the varying coefficients.  On the downside, they seem to have reverted to the ugly lme-style syntax (for example, “fixed = y ~ week, random = ~ 1|ID” rather than “y ~ week + (1|D)”).  The old-style syntax has difficulties handling non-nested grouping factors.  They also say they can estimated models with correlated random effects, but isn’t that just the same as varying-intercept, varying-slope models, which lmer (or Stata alternatives such as gllam) can already do?  There’s also a bunch of stuff on H-likelihood theory, which seems pretty pointless to me (although probably it won’t do much harm either).
 
In any case, this package might be useful to some of you, hence this note.</p><p>5 0.72943532 <a title="1682-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-29-The_gradual_transition_to_replicable_science.html">2117 andrew gelman stats-2013-11-29-The gradual transition to replicable science</a></p>
<p>Introduction: Somebody emailed me:
  
I am a researcher at ** University and I have recently read your article on average predictive comparisons for statistical models published 2007 in the journal “Sociological Methodology”.


Gelman, Andrew/Iain Pardoe. 2007. “Average Predictive Comparisons for Models with Nonlinearity, Interactions, and Variance Components”. Sociological Methodology 37: 23-51.


Currently I am working with multilevel models and find your approach very interesting and useful.


May I ask you whether replication materials (e.g. R Code) for this article are available?
  
I had to reply:
  
Hi—I’m embarrassed to say that our R files are a mess!  I had ideas of programming the approach more generally as an R package but this has not yet happened yet.</p><p>6 0.71422458 <a title="1682-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-18-Derivative-based_MCMC_as_a_breakthrough_technique_for_implementing_Bayesian_statistics.html">419 andrew gelman stats-2010-11-18-Derivative-based MCMC as a breakthrough technique for implementing Bayesian statistics</a></p>
<p>7 0.71107769 <a title="1682-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-29-Hamiltonian_Monte_Carlo_stories.html">931 andrew gelman stats-2011-09-29-Hamiltonian Monte Carlo stories</a></p>
<p>8 0.68634319 <a title="1682-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>9 0.68586147 <a title="1682-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Visualizing_Distributions_of_Covariance_Matrices.html">1477 andrew gelman stats-2012-08-30-Visualizing Distributions of Covariance Matrices</a></p>
<p>10 0.67904174 <a title="1682-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-What_are_the_trickiest_models_to_fit%3F.html">575 andrew gelman stats-2011-02-15-What are the trickiest models to fit?</a></p>
<p>11 0.66337675 <a title="1682-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>12 0.64419639 <a title="1682-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-19-An_interweaving-transformation_strategy_for_boosting_MCMC_efficiency.html">964 andrew gelman stats-2011-10-19-An interweaving-transformation strategy for boosting MCMC efficiency</a></p>
<p>13 0.6404109 <a title="1682-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Computer_models_of_the_oil_spill.html">243 andrew gelman stats-2010-08-30-Computer models of the oil spill</a></p>
<p>14 0.63280284 <a title="1682-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-06-The_new_Stan_1.1.1%2C_featuring_Gaussian_processes%21.html">1710 andrew gelman stats-2013-02-06-The new Stan 1.1.1, featuring Gaussian processes!</a></p>
<p>15 0.62551415 <a title="1682-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-10-R_vs._Stata%2C_or%2C_Different_ways_to_estimate_multilevel_models.html">269 andrew gelman stats-2010-09-10-R vs. Stata, or, Different ways to estimate multilevel models</a></p>
<p>16 0.61576724 <a title="1682-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-17-Getting_arm_and_lme4_running_on_the_Mac.html">347 andrew gelman stats-2010-10-17-Getting arm and lme4 running on the Mac</a></p>
<p>17 0.61293572 <a title="1682-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-The_most-cited_statistics_papers_ever.html">2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</a></p>
<p>18 0.60857248 <a title="1682-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Lessons_learned_from_a_recent_R_package_submission.html">1134 andrew gelman stats-2012-01-21-Lessons learned from a recent R package submission</a></p>
<p>19 0.60608965 <a title="1682-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-23-Learning_Differential_Geometry_for_Hamiltonian_Monte_Carlo.html">1339 andrew gelman stats-2012-05-23-Learning Differential Geometry for Hamiltonian Monte Carlo</a></p>
<p>20 0.60107958 <a title="1682-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-15-More_on_AIC%2C_WAIC%2C_etc.html">1983 andrew gelman stats-2013-08-15-More on AIC, WAIC, etc</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.034), (16, 0.05), (24, 0.137), (25, 0.06), (82, 0.12), (85, 0.074), (86, 0.036), (99, 0.35)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97394139 <a title="1682-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-R_package_for_Bayes_factors.html">1682 andrew gelman stats-2013-01-19-R package for Bayes factors</a></p>
<p>Introduction: Richard Morey writes:
  
You and your blog readers may be interested to know that a we’ve released a major new version of the BayesFactor package to CRAN. The package computes Bayes factors for linear mixed models and regression models. Of course, I’m aware you don’t like point-null model comparisons, but the package does more than that; it also allows sampling from posterior distributions of the compared models, in much the same way that your arm package does with lmer objects. The sampling (both for the Bayes factors and posteriors) is quite fast, since the back end is written in C.


Some basic examples using the package can be found  here , and the CRAN page is  here .
  
Indeed I don’t like point-null model comparisons . . . but maybe this will be useful to some of you!</p><p>2 0.9639802 <a title="1682-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-31-Using_factor_analysis_or_principal_components_analysis_or_measurement-error_models_for_biological_measurements_in_archaeology%3F.html">1094 andrew gelman stats-2011-12-31-Using factor analysis or principal components analysis or measurement-error models for biological measurements in archaeology?</a></p>
<p>Introduction: Greg Campbell writes:
  
I am a Canadian archaeologist (BSc in Chemistry) researching the past human use of European Atlantic shellfish. After two decades of practice I am finally getting a MA in archaeology at Reading. I am seeing if the habitat or size of harvested mussels (Mytilus edulis) can be reconstructed from measurements of the umbo (the pointy end, and the only bit that survives well in archaeological deposits) using log-transformed measurements (or allometry; relationships between dimensions are more likely exponential than linear). 
Of course multivariate regressions in most statistics packages (Minitab, SPSS, SAS) assume you are trying to predict one variable from all the others (a Model I regression), and use ordinary least squares to fit the regression line. For organismal dimensions this makes little sense, since all the dimensions are (at least in theory) free to change their mutual proportions during growth. So there is no predictor and predicted, mutual variation of</p><p>3 0.96302736 <a title="1682-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Lessons_learned_from_a_recent_R_package_submission.html">1134 andrew gelman stats-2012-01-21-Lessons learned from a recent R package submission</a></p>
<p>Introduction: R has zillions of packages, and people are submitting  new ones each day .  The volunteers who keep R going are doing an incredibly useful service to the profession, and they’re  busy .
 
   
 
A colleague sends in some suugestions based on a recent experience with a package update:
  
 1. Always use the R dev version to write a package.  Not the current stable release.  The R people use the R dev version to check your package anyway.  If you don’t use the R dev version, there is chance that your package won’t pass the check.  In my own experience, every time R has a major change, it tends to have new standards and find new errors in your package with these new standards.  So better use the dev version to find out the potential errors in advance.


 2. After submission, write an email to claim it.   I used to submit the package to the CRAN without writing an email.  This was standard operating procedure, but it has changed. Writing an email to claim about the submission is now a requir</p><p>4 0.95742846 <a title="1682-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-17-%E2%80%9C1.7%25%E2%80%9D_ha_ha_ha.html">1725 andrew gelman stats-2013-02-17-“1.7%” ha ha ha</a></p>
<p>Introduction: Jordan Ellenberg writes:
  
Lots of people sharing  this  today.


Isn’t this exactly the kind of situation where they should have done some kind of shrinkage towards the national mean, as in that thing you wrote about kidney cancer rates by county? i.e. you see, just as you might expect, the extreme values of “proportion of people who said they were gay” are disproportionately taken by small states.
  
My reply:
 
If I don’t have the individual-level survey data that would allow me to do full-scale  Mister P , yes, I’d fit a multilevel model to the state-level averages.  I wouldn’t quite just partially pool toward the national mean; I think it would make sense to include some state-level predictors.
 
In any case, I think it’s tacky to report poll numbers to fractional percentage points.  That kind of precision simply isn’t there.
 
P.S.  More discussion of variances of large and small states in the  comments .</p><p>5 0.95331627 <a title="1682-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Peer_pressure%2C_selection%2C_and_educational_reform.html">326 andrew gelman stats-2010-10-07-Peer pressure, selection, and educational reform</a></p>
<p>Introduction: Partly in response to my blog on the Harlem Children’s Zone study, Mark Palko wrote  this :
  
Talk of education reform always makes me [Palko] deeply nervous. Part of the anxiety comes having spent a number of years behind the podium and having seen the disparity between the claims and the reality of previous reforms. The rest comes from being a statistician and knowing what things like convergence can do to data.


Convergent behavior violates the assumption of independent observations used in most simple analyses, but educational studies commonly, perhaps even routinely ignore the complex ways that social norming can cause the nesting of student performance data.


In other words, educational research is often based of the idea that teenagers do not respond to peer pressure. . . .
  
and  this :
  
 
When you isolate a group of students, they will quickly arrive at a consensus of what constitutes normal behavior. It is a complex and somewhat unpredictable process driven by personali</p><p>6 0.9533152 <a title="1682-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-13-Randomized_experiments%2C_non-randomized_experiments%2C_and_observational_studies.html">340 andrew gelman stats-2010-10-13-Randomized experiments, non-randomized experiments, and observational studies</a></p>
<p>7 0.9524914 <a title="1682-lda-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-31-Jessica_Tracy_and_Alec_Beall_%28authors_of_the_fertile-women-wear-pink_study%29_comment_on_our_Garden_of_Forking_Paths_paper%2C_and_I_comment_on_their_comments.html">2355 andrew gelman stats-2014-05-31-Jessica Tracy and Alec Beall (authors of the fertile-women-wear-pink study) comment on our Garden of Forking Paths paper, and I comment on their comments</a></p>
<p>8 0.95195085 <a title="1682-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-30-Real_rothko%2C_fake_rothko.html">1553 andrew gelman stats-2012-10-30-Real rothko, fake rothko</a></p>
<p>9 0.95112085 <a title="1682-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-31-Response_by_Jessica_Tracy_and_Alec_Beall_to_my_critique_of_the_methods_in_their_paper%2C_%E2%80%9CWomen_Are_More_Likely_to_Wear_Red_or_Pink_at_Peak_Fertility%E2%80%9D.html">1963 andrew gelman stats-2013-07-31-Response by Jessica Tracy and Alec Beall to my critique of the methods in their paper, “Women Are More Likely to Wear Red or Pink at Peak Fertility”</a></p>
<p>10 0.94875234 <a title="1682-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-It_depends_upon_what_the_meaning_of_the_word_%E2%80%9Cfirm%E2%80%9D_is..html">940 andrew gelman stats-2011-10-03-It depends upon what the meaning of the word “firm” is.</a></p>
<p>11 0.94834363 <a title="1682-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-30-Stan_Project%3A__Continuous_Relaxations_for_Discrete_MRFs.html">2003 andrew gelman stats-2013-08-30-Stan Project:  Continuous Relaxations for Discrete MRFs</a></p>
<p>12 0.94608325 <a title="1682-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-03-More_on_that_Dartmouth_health_care_study.html">67 andrew gelman stats-2010-06-03-More on that Dartmouth health care study</a></p>
<p>13 0.94601542 <a title="1682-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-02-I_just_flew_in_from_the_econ_seminar%2C_and_boy_are_my_arms_tired.html">1039 andrew gelman stats-2011-12-02-I just flew in from the econ seminar, and boy are my arms tired</a></p>
<p>14 0.94595647 <a title="1682-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-31-Skepticism_about_skepticism_of_global_warming_skepticism_skepticism.html">983 andrew gelman stats-2011-10-31-Skepticism about skepticism of global warming skepticism skepticism</a></p>
<p>15 0.94421506 <a title="1682-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-02-Culture_clash.html">1836 andrew gelman stats-2013-05-02-Culture clash</a></p>
<p>16 0.94326842 <a title="1682-lda-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-11-How_to_think_about_Lou_Dobbs.html">335 andrew gelman stats-2010-10-11-How to think about Lou Dobbs</a></p>
<p>17 0.9393903 <a title="1682-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-15-Charles_Murray_on_the_new_upper_class.html">1169 andrew gelman stats-2012-02-15-Charles Murray on the new upper class</a></p>
<p>18 0.93836528 <a title="1682-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-A_new_R_package_for_fititng_multilevel_models.html">501 andrew gelman stats-2011-01-04-A new R package for fititng multilevel models</a></p>
<p>19 0.93818003 <a title="1682-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-10-It%E2%80%99s_no_fun_being_graded_on_a_curve.html">606 andrew gelman stats-2011-03-10-It’s no fun being graded on a curve</a></p>
<p>20 0.93690944 <a title="1682-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-26-Teaching_evaluations%2C_instructor_effectiveness%2C_the_Journal_of_Political_Economy%2C_and_the_Holy_Roman_Empire.html">540 andrew gelman stats-2011-01-26-Teaching evaluations, instructor effectiveness, the Journal of Political Economy, and the Holy Roman Empire</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
