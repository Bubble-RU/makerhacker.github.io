<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1926 andrew gelman stats-2013-07-05-More plain old everyday Bayesianism</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1926" href="#">andrew_gelman_stats-2013-1926</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1926 andrew gelman stats-2013-07-05-More plain old everyday Bayesianism</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1926-html" href="http://andrewgelman.com/2013/07/05/more-plain-old-everyday-bayesianism/">html</a></p><p>Introduction: Following up on  this story , Bob Goodman writes:
  
A most recent issue of the New England Journal of Medicine published a study entitled  “Biventricular Pacing for Atrioventricular Block and Systolic Dysfunction,” (N Engl J Med 2013; 368:1585-1593), whereby “A hierarchical Bayesian proportional-hazards model was used for analysis of the primary outcome.” It is the first study I can recall in this journal that has reported on Table 2 (primary outcomes) “The Posterior Probability of Hazard Ratio < 1" (which in this case was .9978).
  
This is ok, but to be really picky I will say that there’s typically not so much reason to care about the posterior probability that the effect is greater than 1; I’d rather have an estimate of the effect.  Also we  should  be using informative priors.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ” It is the first study I can recall in this journal that has reported on Table 2 (primary outcomes) “The Posterior Probability of Hazard Ratio < 1" (which in this case was . [sent-2, score-0.71]
</p><p>2 This is ok, but to be really picky I will say that there’s typically not so much reason to care about the posterior probability that the effect is greater than 1; I’d rather have an estimate of the effect. [sent-4, score-1.493]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('primary', 0.311), ('med', 0.269), ('goodman', 0.248), ('whereby', 0.241), ('picky', 0.234), ('posterior', 0.234), ('hazard', 0.224), ('england', 0.19), ('block', 0.188), ('journal', 0.183), ('probability', 0.18), ('entitled', 0.177), ('ratio', 0.171), ('medicine', 0.16), ('study', 0.159), ('greater', 0.159), ('bob', 0.156), ('table', 0.142), ('outcomes', 0.135), ('priors', 0.133), ('informative', 0.13), ('recall', 0.127), ('reported', 0.125), ('hierarchical', 0.122), ('care', 0.112), ('typically', 0.109), ('ok', 0.097), ('issue', 0.094), ('estimate', 0.089), ('reason', 0.087), ('effect', 0.084), ('published', 0.082), ('story', 0.079), ('following', 0.075), ('bayesian', 0.074), ('recent', 0.073), ('used', 0.069), ('case', 0.061), ('analysis', 0.061), ('using', 0.059), ('rather', 0.059), ('model', 0.056), ('first', 0.055), ('say', 0.054), ('new', 0.051), ('really', 0.048), ('much', 0.044), ('writes', 0.043), ('also', 0.037)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1926-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-05-More_plain_old_everyday_Bayesianism.html">1926 andrew gelman stats-2013-07-05-More plain old everyday Bayesianism</a></p>
<p>Introduction: Following up on  this story , Bob Goodman writes:
  
A most recent issue of the New England Journal of Medicine published a study entitled  “Biventricular Pacing for Atrioventricular Block and Systolic Dysfunction,” (N Engl J Med 2013; 368:1585-1593), whereby “A hierarchical Bayesian proportional-hazards model was used for analysis of the primary outcome.” It is the first study I can recall in this journal that has reported on Table 2 (primary outcomes) “The Posterior Probability of Hazard Ratio < 1" (which in this case was .9978).
  
This is ok, but to be really picky I will say that there’s typically not so much reason to care about the posterior probability that the effect is greater than 1; I’d rather have an estimate of the effect.  Also we  should  be using informative priors.</p><p>2 0.26875666 <a title="1926-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-12-As_a_Bayesian_I_want_scientists_to_report_their_data_non-Bayesianly.html">1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</a></p>
<p>Introduction: Philipp Doebler writes: 
  
  
I was quite happy that recently you shared some thoughts of yours and others on meta-analysis. I especially liked the  slides by Chris Schmid  that you linked from your blog. A large portion of my work deals with meta-analysis and I am also fond of using Bayesian methods (actually two of the projects I am working on are very Bayesian), though I can not say I have opinions with respect to the underlying philosophy. I would say though, that I do share your view that there are good reasons to use informative priors.


The reason I am writing to you is that this leads to the following dilemma, which is puzzling me. Say a number of scientists conduct similar studies over the years and all of them did this in a Bayesian fashion. If each of the groups used informative priors based on the research of existing groups the priors could become more and more informative over the years, since more and more is known over the subject. At least in smallish studies these p</p><p>3 0.13748123 <a title="1926-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-08-P-values_and_statistical_practice.html">1713 andrew gelman stats-2013-02-08-P-values and statistical practice</a></p>
<p>Introduction: From  my new article  in the journal Epidemiology:
  
Sander Greenland and Charles Poole accept that P values are here to stay but recognize that some of their most common interpretations have problems. The casual view of the P value as posterior probability of the truth of the null hypothesis is false and not even close to valid under any reasonable model, yet this misunderstanding persists even in high-stakes settings (as discussed, for example, by Greenland in 2011). The formal view of the P value as a probability conditional on the null is mathematically correct but typically irrelevant to research goals (hence, the popularity of alternative—if wrong—interpretations). A Bayesian interpretation based on a spike-and-slab model makes little sense in applied contexts in epidemiology, political science, and other fields in which true effects are typically nonzero and bounded (thus violating both the “spike” and the “slab” parts of the model).


I find Greenland and Poole’s perspective t</p><p>4 0.12989603 <a title="1926-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>Introduction: Nick Firoozye writes:
  
While I am absolutely sympathetic to the Bayesian agenda I am often troubled by the requirement of having priors. We must have priors on the parameter of an infinite number of model we have never seen before and I find this troubling. There is a similarly troubling problem in economics of utility theory. Utility is on consumables. To be complete a consumer must assign utility to all sorts of things they never would have encountered. More recent versions of utility theory instead make consumption goods a portfolio of attributes. Cadillacs are x many units of luxury y of transport etc etc. And we can automatically have personal utilities to all these attributes.  


I don’t ever see parameters. Some model have few and some have hundreds. Instead, I see data. So I don’t know how to have an opinion on parameters themselves. Rather I think it far more natural to have opinions on the behavior of models. The prior predictive density is a good and sensible notion. Also</p><p>5 0.12462186 <a title="1926-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-21-Fundamental_difficulty_of_inference_for_a_ratio_when_the_denominator_could_be_positive_or_negative.html">775 andrew gelman stats-2011-06-21-Fundamental difficulty of inference for a ratio when the denominator could be positive or negative</a></p>
<p>Introduction: Ratio estimates are common in statistics.  In survey sampling, the ratio estimate is when you use y/x to estimate Y/X (using the notation in which x,y are totals of sample measurements and X,Y are population totals).
 
In textbook sampling examples, the denominator X will be an all-positive variable, something that is easy to measure and is, ideally, close to proportional to Y.  For example, X is last year’s sales and Y is this year’s sales, or X is the number of people in a cluster and Y is some count.
 
Ratio estimation doesn’t work so well if X can be either positive or negative.
 
More generally we can consider any estimate of a ratio, with no need for a survey sampling context.  The problem with estimating Y/X is that the very interpretation of Y/X can change completely if the sign of X changes.
 
Everything is ok for a point estimate:  you get X.hat and Y.hat, you can take the ratio Y.hat/X.hat, no problem.  But the inference falls apart if you have enough uncertainty in X.hat th</p><p>6 0.11628205 <a title="1926-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-05-Prior_distribution_for_a_predicted_probability.html">2200 andrew gelman stats-2014-02-05-Prior distribution for a predicted probability</a></p>
<p>7 0.11388073 <a title="1926-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>8 0.11261594 <a title="1926-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<p>9 0.10651644 <a title="1926-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-14-Subtleties_with_measurement-error_models_for_the_evaluation_of_wacky_claims.html">803 andrew gelman stats-2011-07-14-Subtleties with measurement-error models for the evaluation of wacky claims</a></p>
<p>10 0.10639571 <a title="1926-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<p>11 0.10529747 <a title="1926-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-27-%E2%80%9CKeeping_things_unridiculous%E2%80%9D%3A__Berger%2C_O%E2%80%99Hagan%2C_and_me_on_weakly_informative_priors.html">1087 andrew gelman stats-2011-12-27-“Keeping things unridiculous”:  Berger, O’Hagan, and me on weakly informative priors</a></p>
<p>12 0.10324808 <a title="1926-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<p>13 0.10313188 <a title="1926-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-03-Question_about_predictive_checks.html">1363 andrew gelman stats-2012-06-03-Question about predictive checks</a></p>
<p>14 0.10287468 <a title="1926-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-07-Neutral_noninformative_and_informative_conjugate_beta_and_gamma_prior_distributions.html">1046 andrew gelman stats-2011-12-07-Neutral noninformative and informative conjugate beta and gamma prior distributions</a></p>
<p>15 0.10238912 <a title="1926-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-27-Bayesian_model_averaging_or_fitting_a_larger_model.html">1999 andrew gelman stats-2013-08-27-Bayesian model averaging or fitting a larger model</a></p>
<p>16 0.10028517 <a title="1926-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-Scalable_Stan.html">2035 andrew gelman stats-2013-09-23-Scalable Stan</a></p>
<p>17 0.10003968 <a title="1926-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-30-Infill_asymptotics_and_sprawl_asymptotics.html">1877 andrew gelman stats-2013-05-30-Infill asymptotics and sprawl asymptotics</a></p>
<p>18 0.099290848 <a title="1926-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-11-Bayes_in_the_research_conversation.html">2368 andrew gelman stats-2014-06-11-Bayes in the research conversation</a></p>
<p>19 0.097285964 <a title="1926-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-21-D._Buggin.html">1465 andrew gelman stats-2012-08-21-D. Buggin</a></p>
<p>20 0.096879959 <a title="1926-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-30-David_Hogg_on_statistics.html">1401 andrew gelman stats-2012-06-30-David Hogg on statistics</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.158), (1, 0.11), (2, 0.018), (3, -0.052), (4, -0.065), (5, -0.056), (6, 0.046), (7, -0.023), (8, -0.089), (9, -0.048), (10, 0.026), (11, -0.013), (12, 0.003), (13, 0.041), (14, 0.012), (15, -0.015), (16, 0.044), (17, 0.037), (18, -0.01), (19, 0.017), (20, -0.053), (21, 0.026), (22, 0.018), (23, -0.003), (24, -0.004), (25, 0.037), (26, -0.046), (27, 0.027), (28, -0.019), (29, -0.043), (30, -0.069), (31, -0.039), (32, -0.049), (33, 0.006), (34, -0.018), (35, 0.024), (36, -0.013), (37, -0.026), (38, 0.037), (39, 0.003), (40, -0.032), (41, -0.014), (42, 0.017), (43, -0.017), (44, 0.06), (45, -0.021), (46, -0.044), (47, 0.069), (48, -0.017), (49, 0.003)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98164314 <a title="1926-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-05-More_plain_old_everyday_Bayesianism.html">1926 andrew gelman stats-2013-07-05-More plain old everyday Bayesianism</a></p>
<p>Introduction: Following up on  this story , Bob Goodman writes:
  
A most recent issue of the New England Journal of Medicine published a study entitled  “Biventricular Pacing for Atrioventricular Block and Systolic Dysfunction,” (N Engl J Med 2013; 368:1585-1593), whereby “A hierarchical Bayesian proportional-hazards model was used for analysis of the primary outcome.” It is the first study I can recall in this journal that has reported on Table 2 (primary outcomes) “The Posterior Probability of Hazard Ratio < 1" (which in this case was .9978).
  
This is ok, but to be really picky I will say that there’s typically not so much reason to care about the posterior probability that the effect is greater than 1; I’d rather have an estimate of the effect.  Also we  should  be using informative priors.</p><p>2 0.69488811 <a title="1926-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-12-As_a_Bayesian_I_want_scientists_to_report_their_data_non-Bayesianly.html">1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</a></p>
<p>Introduction: Philipp Doebler writes: 
  
  
I was quite happy that recently you shared some thoughts of yours and others on meta-analysis. I especially liked the  slides by Chris Schmid  that you linked from your blog. A large portion of my work deals with meta-analysis and I am also fond of using Bayesian methods (actually two of the projects I am working on are very Bayesian), though I can not say I have opinions with respect to the underlying philosophy. I would say though, that I do share your view that there are good reasons to use informative priors.


The reason I am writing to you is that this leads to the following dilemma, which is puzzling me. Say a number of scientists conduct similar studies over the years and all of them did this in a Bayesian fashion. If each of the groups used informative priors based on the research of existing groups the priors could become more and more informative over the years, since more and more is known over the subject. At least in smallish studies these p</p><p>3 0.67786717 <a title="1926-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-08-P-values_and_statistical_practice.html">1713 andrew gelman stats-2013-02-08-P-values and statistical practice</a></p>
<p>Introduction: From  my new article  in the journal Epidemiology:
  
Sander Greenland and Charles Poole accept that P values are here to stay but recognize that some of their most common interpretations have problems. The casual view of the P value as posterior probability of the truth of the null hypothesis is false and not even close to valid under any reasonable model, yet this misunderstanding persists even in high-stakes settings (as discussed, for example, by Greenland in 2011). The formal view of the P value as a probability conditional on the null is mathematically correct but typically irrelevant to research goals (hence, the popularity of alternative—if wrong—interpretations). A Bayesian interpretation based on a spike-and-slab model makes little sense in applied contexts in epidemiology, political science, and other fields in which true effects are typically nonzero and bounded (thus violating both the “spike” and the “slab” parts of the model).


I find Greenland and Poole’s perspective t</p><p>4 0.66942132 <a title="1926-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-13-%E2%80%9CWhat_are_some_situations_in_which_the_classical_approach_%28or_a_naive_implementation_of_it%2C_based_on_cookbook_recipes%29_gives_worse_results_than_a_Bayesian_approach%2C_results_that_actually_impeded_the_science%3F%E2%80%9D.html">2099 andrew gelman stats-2013-11-13-“What are some situations in which the classical approach (or a naive implementation of it, based on cookbook recipes) gives worse results than a Bayesian approach, results that actually impeded the science?”</a></p>
<p>Introduction: Phil Nelson writes in the context of a biostatistics textbook he is writing, “Physical models of living systems”:
  
There are a number of classic statistical problems that arise every day in the lab, and which are discussed in any book:


1. In a control group, M untreated rats out of 20 got a form of cancer. In a test group, N treated rats out of 20 got that cancer. Is this a significant difference? 
2. In a control group of 20 untreated rates, their body weights at 2 weeks were w_1,…, w_20. In a test group of 20 treated rats, their body weights at 2 weeks were w’_1,…, w’_20. Are the means significantly different? 
3. In a group of 20 rats, each given dose d_i of a drug, their body weights at 2 weeks were w_i. Is there a significant correlation between d and w?


I would like to ask: What are some situations in which the classical approach (or a naive implementation of it, based on cookbook recipes) gives worse results than a Bayesian approach, results that actually impeded the scien</p><p>5 0.65380603 <a title="1926-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-07-Neutral_noninformative_and_informative_conjugate_beta_and_gamma_prior_distributions.html">1046 andrew gelman stats-2011-12-07-Neutral noninformative and informative conjugate beta and gamma prior distributions</a></p>
<p>Introduction: Jouni Kerman did a cool bit of research justifying the Beta (1/3, 1/3) prior as noninformative for binomial data, and the Gamma (1/3, 0) prior for Poisson data.
 
You probably thought that nothing new could be said about noninformative priors in such basic problems, but you were wrong!
 
Here’s  the story :
  
The conjugate binomial and Poisson models are commonly used for estimating proportions or rates. However, it is not well known that the conventional noninformative conjugate priors tend to shrink the posterior quantiles toward the boundary or toward the middle of the parameter space, making them thus appear excessively informative. The shrinkage is always largest when the number of observed events is small. This behavior persists for all sample sizes and exposures. The effect of the prior is therefore most conspicuous and potentially controversial when analyzing rare events. As alternative default conjugate priors, I [Jouni] introduce Beta(1/3, 1/3) and Gamma(1/3, 0), which I cal</p><p>6 0.64684075 <a title="1926-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-30-Infill_asymptotics_and_sprawl_asymptotics.html">1877 andrew gelman stats-2013-05-30-Infill asymptotics and sprawl asymptotics</a></p>
<p>7 0.62919325 <a title="1926-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-15-Static_sensitivity_analysis.html">804 andrew gelman stats-2011-07-15-Static sensitivity analysis</a></p>
<p>8 0.62834144 <a title="1926-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-28-Plain_old_everyday_Bayesianism%21.html">1829 andrew gelman stats-2013-04-28-Plain old everyday Bayesianism!</a></p>
<p>9 0.62693489 <a title="1926-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-05-Prior_distribution_for_a_predicted_probability.html">2200 andrew gelman stats-2014-02-05-Prior distribution for a predicted probability</a></p>
<p>10 0.61703598 <a title="1926-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-18-Multimodality_in_hierarchical_models.html">916 andrew gelman stats-2011-09-18-Multimodality in hierarchical models</a></p>
<p>11 0.61013216 <a title="1926-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<p>12 0.60762167 <a title="1926-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>13 0.60654658 <a title="1926-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-19-Revised_evidence_for_statistical_standards.html">2140 andrew gelman stats-2013-12-19-Revised evidence for statistical standards</a></p>
<p>14 0.60548127 <a title="1926-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-On_the_half-Cauchy_prior_for_a_global_scale_parameter.html">801 andrew gelman stats-2011-07-13-On the half-Cauchy prior for a global scale parameter</a></p>
<p>15 0.59696704 <a title="1926-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-26-%E2%80%9CPlease_make_fun_of_this_claim%E2%80%9D.html">2114 andrew gelman stats-2013-11-26-“Please make fun of this claim”</a></p>
<p>16 0.59463996 <a title="1926-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-15-Reputations_changeable%2C_situations_tolerable.html">1858 andrew gelman stats-2013-05-15-Reputations changeable, situations tolerable</a></p>
<p>17 0.59268576 <a title="1926-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-17-Christian_Robert_on_the_Jeffreys-Lindley_paradox%3B_more_generally%2C_it%E2%80%99s_good_news_when_philosophical_arguments_can_be_transformed_into_technical_modeling_issues.html">2027 andrew gelman stats-2013-09-17-Christian Robert on the Jeffreys-Lindley paradox; more generally, it’s good news when philosophical arguments can be transformed into technical modeling issues</a></p>
<p>18 0.59040838 <a title="1926-lsi-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-24-%E2%80%9CEdlin%E2%80%99s_rule%E2%80%9D_for_routinely_scaling_down_published_estimates.html">2223 andrew gelman stats-2014-02-24-“Edlin’s rule” for routinely scaling down published estimates</a></p>
<p>19 0.59036011 <a title="1926-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-06-Bootstrap_averaging%3A_Examples_where_it_works_and_where_it_doesn%E2%80%99t_work.html">2201 andrew gelman stats-2014-02-06-Bootstrap averaging: Examples where it works and where it doesn’t work</a></p>
<p>20 0.58526862 <a title="1926-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-18-Prior_information_._._._about_the_likelihood.html">618 andrew gelman stats-2011-03-18-Prior information . . . about the likelihood</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.028), (16, 0.083), (24, 0.172), (30, 0.033), (35, 0.187), (53, 0.048), (55, 0.023), (99, 0.297)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95912695 <a title="1926-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-Why_a_bonobo_won%E2%80%99t_play_poker_with_you.html">473 andrew gelman stats-2010-12-17-Why a bonobo won’t play poker with you</a></p>
<p>Introduction: Sciencedaily has posted an article titled  Apes Unwilling to Gamble When Odds Are Uncertain :
  

The apes readily distinguished between the different probabilities of winning: they gambled a lot when there was a 100 percent chance, less when there was a 50 percent chance, and only rarely when there was no chance In some trials, however, the experimenter didn’t remove a lid from the bowl, so the apes couldn’t assess the likelihood of winning a banana The odds from the covered bowl were identical to those from the risky option: a 50 percent chance of getting the much sought-after banana. But apes of both species were less likely to choose this ambiguous option.

   

Like humans, they showed “ambiguity aversion” — preferring to gamble more when they knew the odds than when they didn’t. Given some of the other differences between chimps and bonobos, Hare and Rosati had expected to find the bonobos to be more averse to ambiguity, but that didn’t turn out to be the case.

  
Thanks to  Sta</p><p>2 0.9521969 <a title="1926-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-04-Is_it_rational_to_vote%3F.html">837 andrew gelman stats-2011-08-04-Is it rational to vote?</a></p>
<p>Introduction: Hear me interviewed on the topic  here .
 
P.S.  The interview was fine but I donâ&euro;&trade;t agree with everything on the linked website.  For example,  this  bit:
  
Global warming is not the first case of a widespread fear based on incomplete knowledge turned out to be false or at least greatly exaggerated.  Global warming has many of the characteristics of a popular delusion, an irrational fear or cause that is embraced by millions of people because, well, it is believed by millions of people!
  
All right, then.</p><p>3 0.94653118 <a title="1926-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-03-On_house_arrest_for_p-hacking.html">2049 andrew gelman stats-2013-10-03-On house arrest for p-hacking</a></p>
<p>Introduction: People keep pointing me to  this  excellent news article by David Brown, about a scientist who was convicted of data manipulation:
  
In all, 330 patients were randomly assigned to get either interferon gamma-1b or placebo injections. Disease progression or death occurred in 46 percent of those on the drug and 52 percent of those on placebo. That was not a significant difference, statistically speaking. When only survival was considered, however, the drug looked better: 10 percent of people getting the drug died, compared with 17 percent of those on placebo. However, that difference wasn’t “statistically significant,” either.


Specifically, the so-called P value — a mathematical measure of the strength of the evidence that there’s a true difference between a treatment and placebo — was 0.08. . . . Technically, the study was a bust, although the results leaned toward a benefit from interferon gamma-1b. Was there a group of patients in which the results tipped? Harkonen asked the statis</p><p>same-blog 4 0.94533551 <a title="1926-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-05-More_plain_old_everyday_Bayesianism.html">1926 andrew gelman stats-2013-07-05-More plain old everyday Bayesianism</a></p>
<p>Introduction: Following up on  this story , Bob Goodman writes:
  
A most recent issue of the New England Journal of Medicine published a study entitled  “Biventricular Pacing for Atrioventricular Block and Systolic Dysfunction,” (N Engl J Med 2013; 368:1585-1593), whereby “A hierarchical Bayesian proportional-hazards model was used for analysis of the primary outcome.” It is the first study I can recall in this journal that has reported on Table 2 (primary outcomes) “The Posterior Probability of Hazard Ratio < 1" (which in this case was .9978).
  
This is ok, but to be really picky I will say that there’s typically not so much reason to care about the posterior probability that the effect is greater than 1; I’d rather have an estimate of the effect.  Also we  should  be using informative priors.</p><p>5 0.94496429 <a title="1926-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<p>Introduction: Burak Bayramli writes:
  
In  this paper  by Sunjin Ahn, Anoop Korattikara, and Max Welling and  this paper  by Welling and Yee Whye The, there are some arguments on big data and the use of MCMC. Both papers have suggested improvements to speed up MCMC computations. I was wondering what your thoughts were, especially on this paragraph:

 
When a dataset has a billion data-cases (as is not uncommon these days) MCMC algorithms will not even have generated a single (burn-in) sample when a clever learning algorithm based on stochastic gradients may already be making fairly good predictions. In fact, the intriguing results of Bottou and Bousquet (2008) seem to indicate that in terms of “number of bits learned per unit of computation”, an algorithm as simple as stochastic gradient descent is almost optimally efficient. We therefore argue that for Bayesian methods to remain useful in an age when the datasets grow at an exponential rate, they need to embrace the ideas of the stochastic optimiz</p><p>6 0.93655694 <a title="1926-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-25-Quantitative_Methods_in_the_Social_Sciences_M.A.%3A_Innovative%2C_interdisciplinary_social_science_research_program_for_a_data-rich_world.html">591 andrew gelman stats-2011-02-25-Quantitative Methods in the Social Sciences M.A.: Innovative, interdisciplinary social science research program for a data-rich world</a></p>
<p>7 0.93118978 <a title="1926-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-04-45%25_hitting%2C_25%25_fielding%2C_25%25_pitching%2C_and_100%25_not_telling_us_how_they_did_it.html">942 andrew gelman stats-2011-10-04-45% hitting, 25% fielding, 25% pitching, and 100% not telling us how they did it</a></p>
<p>8 0.92747688 <a title="1926-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-30-Computational_problems_with_glm_etc..html">1516 andrew gelman stats-2012-09-30-Computational problems with glm etc.</a></p>
<p>9 0.92166877 <a title="1926-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-30-Rickey_Henderson_and_Peter_Angelos%2C_together_again.html">881 andrew gelman stats-2011-08-30-Rickey Henderson and Peter Angelos, together again</a></p>
<p>10 0.9165684 <a title="1926-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-26-A_simple_semigraphic_display.html">296 andrew gelman stats-2010-09-26-A simple semigraphic display</a></p>
<p>11 0.91452324 <a title="1926-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-01-The_placebo_effect_in_pharma.html">388 andrew gelman stats-2010-11-01-The placebo effect in pharma</a></p>
<p>12 0.90607023 <a title="1926-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-08-How_to_solve_the_Post_Office%E2%80%99s_problems%3F.html">895 andrew gelman stats-2011-09-08-How to solve the Post Office’s problems?</a></p>
<p>13 0.90394342 <a title="1926-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-03-Taleb_%2B_3.5_years.html">392 andrew gelman stats-2010-11-03-Taleb + 3.5 years</a></p>
<p>14 0.89660937 <a title="1926-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-14-Learning_from_failure.html">1264 andrew gelman stats-2012-04-14-Learning from failure</a></p>
<p>15 0.89342558 <a title="1926-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-20-Prior_beliefs_about_locations_of_decision_boundaries.html">1130 andrew gelman stats-2012-01-20-Prior beliefs about locations of decision boundaries</a></p>
<p>16 0.88488734 <a title="1926-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-17-Macro_causality.html">807 andrew gelman stats-2011-07-17-Macro causality</a></p>
<p>17 0.8819651 <a title="1926-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-30-Adjudicating_between_alternative_interpretations_of_a_statistical_interaction%3F.html">2274 andrew gelman stats-2014-03-30-Adjudicating between alternative interpretations of a statistical interaction?</a></p>
<p>18 0.87651002 <a title="1926-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-03-Boot.html">1881 andrew gelman stats-2013-06-03-Boot</a></p>
<p>19 0.87605917 <a title="1926-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-12-Stan_1.3.0_and_RStan_1.3.0_Ready_for_Action.html">1799 andrew gelman stats-2013-04-12-Stan 1.3.0 and RStan 1.3.0 Ready for Action</a></p>
<p>20 0.87335026 <a title="1926-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-29-Zero_is_zero.html">687 andrew gelman stats-2011-04-29-Zero is zero</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
