<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1880 andrew gelman stats-2013-06-02-Flame bait</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1880" href="#">andrew_gelman_stats-2013-1880</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1880 andrew gelman stats-2013-06-02-Flame bait</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1880-html" href="http://andrewgelman.com/2013/06/02/flame-bait/">html</a></p><p>Introduction: Mark Palko asks what I think of  this article  by Francisco Louca, who writes about “‘hybridization’, a synthesis between Fisherian and Neyman-Pearsonian precepts, defined as a number of practical proceedings for statistical testing and inference that were developed notwithstanding the original authors, as an eventual convergence between what they considered to be radically irreconcilable.”
 
To me, the statistical ideas in this paper are too old-fashioned.  The issue is not that the Neyman-Pearson and Fisher approaches are “irreconcilable” but rather that neither does the job in the sort of hard problems that face statistical science today.  I’m thinking of technically difficult models such as hierarchical Gaussian processes and also challenges that arise with small sample size and multiple testing. Neyman, Pearson, and Fisher all were brilliant, and they all developed statistical methods that remain useful today, but I think their foundations are out of date.  Yes, we currently use m</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ”   To me, the statistical ideas in this paper are too old-fashioned. [sent-2, score-0.265]
</p><p>2 The issue is not that the Neyman-Pearson and Fisher approaches are “irreconcilable” but rather that neither does the job in the sort of hard problems that face statistical science today. [sent-3, score-0.492]
</p><p>3 I’m thinking of technically difficult models such as hierarchical Gaussian processes and also challenges that arise with small sample size and multiple testing. [sent-4, score-0.917]
</p><p>4 Neyman, Pearson, and Fisher all were brilliant, and they all developed statistical methods that remain useful today, but I think their foundations are out of date. [sent-5, score-0.554]
</p><p>5 Yes, we currently use many of Fisher’s, Neyman’s, and Pearson’s ideas, but I don’t think either of their philosophies, or any convex mixture of the two, will really work anymore, as general frameworks for inference. [sent-6, score-0.501]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fisher', 0.341), ('pearson', 0.269), ('neyman', 0.262), ('developed', 0.196), ('notwithstanding', 0.175), ('radically', 0.167), ('eventual', 0.167), ('convex', 0.162), ('kanazawa', 0.162), ('hierarchical', 0.16), ('synthesis', 0.157), ('frameworks', 0.146), ('technically', 0.146), ('francisco', 0.143), ('proceedings', 0.143), ('philosophies', 0.143), ('statistical', 0.143), ('anymore', 0.141), ('ioannidis', 0.137), ('convergence', 0.124), ('simonsohn', 0.123), ('ideas', 0.122), ('foundations', 0.12), ('brilliant', 0.118), ('bem', 0.118), ('gaussian', 0.113), ('mixture', 0.107), ('palko', 0.106), ('challenges', 0.104), ('processes', 0.104), ('face', 0.096), ('arise', 0.095), ('remain', 0.095), ('neither', 0.094), ('mention', 0.094), ('models', 0.093), ('approaches', 0.091), ('asks', 0.09), ('defined', 0.088), ('currently', 0.086), ('practical', 0.086), ('testing', 0.084), ('mark', 0.079), ('considered', 0.076), ('size', 0.075), ('today', 0.073), ('multiple', 0.071), ('difficult', 0.069), ('authors', 0.068), ('job', 0.068)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1880-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-02-Flame_bait.html">1880 andrew gelman stats-2013-06-02-Flame bait</a></p>
<p>Introduction: Mark Palko asks what I think of  this article  by Francisco Louca, who writes about “‘hybridization’, a synthesis between Fisherian and Neyman-Pearsonian precepts, defined as a number of practical proceedings for statistical testing and inference that were developed notwithstanding the original authors, as an eventual convergence between what they considered to be radically irreconcilable.”
 
To me, the statistical ideas in this paper are too old-fashioned.  The issue is not that the Neyman-Pearson and Fisher approaches are “irreconcilable” but rather that neither does the job in the sort of hard problems that face statistical science today.  I’m thinking of technically difficult models such as hierarchical Gaussian processes and also challenges that arise with small sample size and multiple testing. Neyman, Pearson, and Fisher all were brilliant, and they all developed statistical methods that remain useful today, but I think their foundations are out of date.  Yes, we currently use m</p><p>2 0.31136298 <a title="1880-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>Introduction: As a data analyst and a scientist, Fisher > Neyman, no question.  But as a theorist, Fisher came up with ideas that worked just fine in his applications but can fall apart when people try to apply them too generally.
 
Here’s an example that recently came up.
 
Deborah Mayo pointed me to a  comment  by Stephen Senn on the so-called Fisher and Neyman null hypotheses.  In an experiment with n participants (or, as we used to say, subjects or experimental units), the Fisher null hypothesis is that the treatment effect is exactly 0 for every one of the n units, while the Neyman null hypothesis is that the individual treatment effects can be negative or positive but have an average of zero.
 
Senn explains why Neyman’s hypothesis in general makes no sense—the short story is that Fisher’s hypothesis seems relevant in some problems (sometimes we really are studying effects that are zero or close enough for all practical purposes), whereas Neyman’s hypothesis just seems weird (it’s implausible</p><p>3 0.22016451 <a title="1880-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-19-On_deck_this_week.html">2339 andrew gelman stats-2014-05-19-On deck this week</a></p>
<p>Introduction: Mon:   My short career as a Freud expert
 
 Tues:   “P.S. Is anyone working on hierarchical survival models?”
 
 Wed:   Skepticism about a published claim regarding income inequality and happiness
 
 Thurs:   Big Data needs Big Model
 
 Fri:   Did Neyman really say of Fisher’s work, “It’s easy to get the right answer if you never define what the question is,” and did Fisher really describe Neyman as “a theorem-proving poseur who wouldn’t recognized real data if it bit him in the ass”
 
 Sat:   An interesting mosaic of a data programming course
 
 Sun:   Why I decided not to be a physicist</p><p>4 0.14362256 <a title="1880-tfidf-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-05-On_deck_this_month.html">2320 andrew gelman stats-2014-05-05-On deck this month</a></p>
<p>Introduction: Can we make better graphs of global temperature history? 
 Priors I don’t believe 
 Cause he thinks he’s so-phisticated 
 Discussion with Steven Pinker on research that is attached to data that are so noisy as to be essentially uninformative 
 Combining forecasts: Evidence on the relative accuracy of the simple average and Bayesian model averaging for predicting social science problems 
 What property is important in a risk prediction model? Discrimination or calibration? 
 “What should you talk about?” 
 Science tells us that fast food lovers are more likely to marry other fast food lovers 
 Personally, I’d rather go with Teragram 
 How much can we learn about individual-level causal claims from state-level correlations? 
 Bill Easterly vs. Jeff Sachs: What percentage of the recipients didn’t use the free malaria bed nets in Zambia? 
 Models with constraints 
 Forum in  Ecology  on p-values and model selection 
 Never back down: The culture of poverty and the culture of journalism 
 M</p><p>5 0.13754715 <a title="1880-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Huff_the_Magic_Dragon.html">1293 andrew gelman stats-2012-05-01-Huff the Magic Dragon</a></p>
<p>Introduction: Upon reading  this , Susan remarked, “Don’t you think it’s interesting that a guy who promotes smoking has a last name of ‘Huff’?  Reminds me of the Dennis/Dentist studies.”
 
Good point.
 
P.S.  As discussed in the linked thread, the great statistician R. A. Fisher was notorious for minimizing the risks of smoking.  How does this connect to Fisher’s name, one might ask?</p><p>6 0.13595378 <a title="1880-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>7 0.13582365 <a title="1880-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-The_most-cited_statistics_papers_ever.html">2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</a></p>
<p>8 0.12850021 <a title="1880-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-15-How_I_think_about_mixture_models.html">1459 andrew gelman stats-2012-08-15-How I think about mixture models</a></p>
<p>9 0.11761799 <a title="1880-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-20-Reading_a_research_paper_%21%3D_agreeing_with_its_claims.html">1074 andrew gelman stats-2011-12-20-Reading a research paper != agreeing with its claims</a></p>
<p>10 0.11424589 <a title="1880-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-21-%E2%80%9CHow_segregated_is_your_city%3F%E2%80%9D%3A__A_story_of_why_every_graph%2C_no_matter_how_clear_it_seems_to_be%2C_needs_a_caption_to_anchor_the_reader_in_some_numbers.html">289 andrew gelman stats-2010-09-21-“How segregated is your city?”:  A story of why every graph, no matter how clear it seems to be, needs a caption to anchor the reader in some numbers</a></p>
<p>11 0.10735942 <a title="1880-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-25-Classics_of_statistics.html">109 andrew gelman stats-2010-06-25-Classics of statistics</a></p>
<p>12 0.10192709 <a title="1880-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-04-Model_checking_and_model_understanding_in_machine_learning.html">1482 andrew gelman stats-2012-09-04-Model checking and model understanding in machine learning</a></p>
<p>13 0.095850028 <a title="1880-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>14 0.095061719 <a title="1880-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-15-Mr._P_by_another_name_._._._is_still_great%21.html">769 andrew gelman stats-2011-06-15-Mr. P by another name . . . is still great!</a></p>
<p>15 0.094300255 <a title="1880-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-13-Stolen_jokes.html">1318 andrew gelman stats-2012-05-13-Stolen jokes</a></p>
<p>16 0.092165232 <a title="1880-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-23-Examples_of_the_use_of_hierarchical_modeling_to_generalize_to_new_settings.html">1425 andrew gelman stats-2012-07-23-Examples of the use of hierarchical modeling to generalize to new settings</a></p>
<p>17 0.092119306 <a title="1880-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<p>18 0.090760365 <a title="1880-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-With_a_bit_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_again_on_this_topic%2C_and_with_a_lot_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_today.html">576 andrew gelman stats-2011-02-15-With a bit of precognition, you’d have known I was going to post again on this topic, and with a lot of precognition, you’d have known I was going to post today</a></p>
<p>19 0.088196047 <a title="1880-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<p>20 0.087608948 <a title="1880-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-09-The_difference_between_significant_and_not_significant%E2%80%A6.html">897 andrew gelman stats-2011-09-09-The difference between significant and not significant…</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.141), (1, 0.064), (2, -0.043), (3, -0.057), (4, -0.023), (5, -0.003), (6, -0.067), (7, -0.009), (8, 0.021), (9, -0.011), (10, -0.026), (11, 0.031), (12, -0.018), (13, -0.015), (14, 0.033), (15, -0.045), (16, -0.037), (17, 0.003), (18, -0.001), (19, -0.057), (20, -0.0), (21, -0.039), (22, 0.019), (23, 0.038), (24, -0.002), (25, -0.049), (26, -0.04), (27, 0.044), (28, 0.016), (29, -0.007), (30, 0.024), (31, -0.003), (32, 0.042), (33, 0.003), (34, -0.01), (35, -0.025), (36, -0.035), (37, -0.005), (38, 0.002), (39, 0.067), (40, -0.057), (41, 0.084), (42, 0.04), (43, 0.035), (44, 0.008), (45, 0.054), (46, -0.094), (47, -0.043), (48, 0.006), (49, -0.081)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95200002 <a title="1880-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-02-Flame_bait.html">1880 andrew gelman stats-2013-06-02-Flame bait</a></p>
<p>Introduction: Mark Palko asks what I think of  this article  by Francisco Louca, who writes about “‘hybridization’, a synthesis between Fisherian and Neyman-Pearsonian precepts, defined as a number of practical proceedings for statistical testing and inference that were developed notwithstanding the original authors, as an eventual convergence between what they considered to be radically irreconcilable.”
 
To me, the statistical ideas in this paper are too old-fashioned.  The issue is not that the Neyman-Pearson and Fisher approaches are “irreconcilable” but rather that neither does the job in the sort of hard problems that face statistical science today.  I’m thinking of technically difficult models such as hierarchical Gaussian processes and also challenges that arise with small sample size and multiple testing. Neyman, Pearson, and Fisher all were brilliant, and they all developed statistical methods that remain useful today, but I think their foundations are out of date.  Yes, we currently use m</p><p>2 0.76703453 <a title="1880-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-31-The_most-cited_statistics_papers_ever.html">2277 andrew gelman stats-2014-03-31-The most-cited statistics papers ever</a></p>
<p>Introduction: Robert Grant has a  list .  I’ll just give the ones with more than 10,000 Google Scholar cites:
  

Cox (1972) Regression and life tables: 35,512 citations. 


Dempster, Laird, Rubin (1977) Maximum likelihood from incomplete data via the EM algorithm: 34,988


Bland & Altman (1986) Statistical methods for assessing agreement between two methods of clinical measurement: 27,181


Geman & Geman (1984) Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images: 15,106
  
We can find some more via searching Google scholar for familiar names and topics; thus:
  

Metropolis et al. (1953) Equation of state calculations by fast computing machines: 26,000


Benjamini and Hochberg (1995) Controlling the false discovery rate: a practical and powerful approach to multiple testing: 21,000


White (1980) A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity: 18,000


Heckman (1977) Sample selection bias as a specification error:</p><p>3 0.64876646 <a title="1880-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-09-The_difference_between_significant_and_not_significant%E2%80%A6.html">897 andrew gelman stats-2011-09-09-The difference between significant and not significant…</a></p>
<p>Introduction: E. J. Wagenmakers writes:
  
You may be interested in  a recent article  [by Nieuwenhuis, Forstmann, and Wagenmakers] showing how often researchers draw conclusions by comparing p-values. As you and Hal Stern have pointed out, this is potentially misleading because the difference between significant and not significant is not necessarily significant.


We were really suprised to see how often researchers in the neurosciences make this mistake. In the paper we speculate a little bit on the cause of the error.
  
From their paper:
  
In theory, a comparison of two experimental effects requires a statistical test on their difference. In practice, this comparison is often based on an incorrect procedure involving two separate tests in which researchers conclude that effects differ when one effect is significant (P < 0.05) but the other 
is not (P > 0.05). We reviewed 513 behavioral, systems and cognitive neuroscience articles in five top-ranking journals (Science, Nature, Nature Neuroscien</p><p>4 0.64326423 <a title="1880-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-23-When_are_complicated_models_helpful_in_psychology_research_and_when_are_they_overkill%3F.html">1690 andrew gelman stats-2013-01-23-When are complicated models helpful in psychology research and when are they overkill?</a></p>
<p>Introduction: Nick Brown is bothered by  this article , “An unscented Kalman filter approach to the estimation of nonlinear dynamical systems models,” by Sy-Miin Chow, Emilio Ferrer, and John Nesselroade.  The introduction of the article cites a bunch of articles in serious psych/statistics journals.  The question is, are such advanced statistical techniques really needed, or even legitimate, with the kind of very rough data that is usually available in psych applications? Or is it just fishing in the hope of discovering patterns that are not really there?
 
I wrote:
 
It seems like a pretty innocuous literature review.  I agree that many of the applications are silly (for example, they cite the work of the notorious  John Gottman  in fitting a predator-prey model to spousal relations (!)), but overall they just seem to be presenting very standard ideas for the mathematical-psychology audience.  It’s not clear whether advanced techniques are always appropriate here, but they come in through a natura</p><p>5 0.63109565 <a title="1880-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-03-Statistical_methods_for_healthcare_regulation%3A_rating%2C_screening_and_surveillance.html">744 andrew gelman stats-2011-06-03-Statistical methods for healthcare regulation: rating, screening and surveillance</a></p>
<p>Introduction: Here is my discussion of  a recent article  by David Spiegelhalter, Christopher 
Sherlaw-Johnson, Martin Bardsley, Ian Blunt, Christopher Wood and Olivia Grigg, that is scheduled to appear in the Journal of the Royal Statistical Society:
 
I applaud the authors’ use of a mix of statistical methods to attack an important real-world problem. Policymakers need results right away, and I admire the authors’ ability and willingness to combine several different modeling and significance testing ideas for the purposes of rating and surveillance.
 
That said, I am uncomfortable with the statistical ideas here, for three reasons. First, I feel that the proposed methods, centered as they are around data manipulation and corrections for uncertainty, has serious defects compared to a more model-based approach. My problem with methods based on p-values and z-scores–however they happen to be adjusted–is that they draw discussion toward error rates, sequential analysis, and other technical statistical</p><p>6 0.62293279 <a title="1880-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-01-Martin_and_Liu%3A__Probabilistic_inference_based_on_consistency_of_model_with_data.html">1095 andrew gelman stats-2012-01-01-Martin and Liu:  Probabilistic inference based on consistency of model with data</a></p>
<p>7 0.61658126 <a title="1880-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-A_new_R_package_for_fititng_multilevel_models.html">501 andrew gelman stats-2011-01-04-A new R package for fititng multilevel models</a></p>
<p>8 0.61459595 <a title="1880-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-29-Ethics_and_statistics_in_development_research.html">241 andrew gelman stats-2010-08-29-Ethics and statistics in development research</a></p>
<p>9 0.60307699 <a title="1880-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>10 0.59344149 <a title="1880-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-08-The_never-ending_%28and_often_productive%29_race_between_theory_and_practice.html">2127 andrew gelman stats-2013-12-08-The never-ending (and often productive) race between theory and practice</a></p>
<p>11 0.59177142 <a title="1880-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>12 0.59169966 <a title="1880-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>13 0.58898133 <a title="1880-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-29-The_gradual_transition_to_replicable_science.html">2117 andrew gelman stats-2013-11-29-The gradual transition to replicable science</a></p>
<p>14 0.58896786 <a title="1880-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-19-Data_exploration_and_multiple_comparisons.html">524 andrew gelman stats-2011-01-19-Data exploration and multiple comparisons</a></p>
<p>15 0.58256274 <a title="1880-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-20-%E2%80%9CSix_red_flags_for_suspect_work%E2%80%9D.html">2032 andrew gelman stats-2013-09-20-“Six red flags for suspect work”</a></p>
<p>16 0.57793027 <a title="1880-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-15-Bayesian_statistical_pragmatism.html">662 andrew gelman stats-2011-04-15-Bayesian statistical pragmatism</a></p>
<p>17 0.57256925 <a title="1880-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>18 0.5650059 <a title="1880-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-05-Cleaning_up_science.html">1842 andrew gelman stats-2013-05-05-Cleaning up science</a></p>
<p>19 0.56072026 <a title="1880-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-14-Everyone%E2%80%99s_trading_bias_for_variance_at_some_point%2C_it%E2%80%99s_just_done_at_different_places_in_the_analyses.html">1763 andrew gelman stats-2013-03-14-Everyone’s trading bias for variance at some point, it’s just done at different places in the analyses</a></p>
<p>20 0.55928171 <a title="1880-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-19-Just_chaid.html">421 andrew gelman stats-2010-11-19-Just chaid</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.07), (16, 0.031), (18, 0.02), (22, 0.04), (24, 0.067), (27, 0.082), (31, 0.18), (44, 0.018), (53, 0.017), (66, 0.013), (79, 0.05), (84, 0.016), (86, 0.036), (99, 0.26)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.91438198 <a title="1880-lda-1" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-18-The_Fixie_Bike_Index.html">1127 andrew gelman stats-2012-01-18-The Fixie Bike Index</a></p>
<p>Introduction: Where are the fixed-gear bike riders?
 
   
 
Rohin Dhar  explains : 
  
  
At Priceonomics, in order to build our bicycle price guide, we measure what kind of used bikes people are trying to sell and the quantity sold in any city. By mining our database of 1.3 million bicycle listings, we can tell what are the largest markets for used bicycles, how the prices vary by region, and where people who prize fixed gear bikes live.


Fixies (fixed gear bikes) are considered to be a strong indicator of hipsterness. For those unfamiliar, a fixed gear bike requires riding in a single gear and the only way to stop the bike is to pedal backwards to help skid the bike to a halt. You can’t “coast” on a fixie; when you are biking downhill, your pedals will keep moving so you better keep pedaling too. Because of the minimalism of this fixed gear system, the bikes tend to be aesthetically pleasing but somewhat challenging to ride. . . .


   


In short, fixed gear bikes = hipsters, and New York boroug</p><p>same-blog 2 0.91121733 <a title="1880-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-02-Flame_bait.html">1880 andrew gelman stats-2013-06-02-Flame bait</a></p>
<p>Introduction: Mark Palko asks what I think of  this article  by Francisco Louca, who writes about “‘hybridization’, a synthesis between Fisherian and Neyman-Pearsonian precepts, defined as a number of practical proceedings for statistical testing and inference that were developed notwithstanding the original authors, as an eventual convergence between what they considered to be radically irreconcilable.”
 
To me, the statistical ideas in this paper are too old-fashioned.  The issue is not that the Neyman-Pearson and Fisher approaches are “irreconcilable” but rather that neither does the job in the sort of hard problems that face statistical science today.  I’m thinking of technically difficult models such as hierarchical Gaussian processes and also challenges that arise with small sample size and multiple testing. Neyman, Pearson, and Fisher all were brilliant, and they all developed statistical methods that remain useful today, but I think their foundations are out of date.  Yes, we currently use m</p><p>3 0.90797472 <a title="1880-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-My_talk_at_the_University_of_Michigan_today_4pm.html">1778 andrew gelman stats-2013-03-27-My talk at the University of Michigan today 4pm</a></p>
<p>Introduction: Causality and Statistical Learning 
 
Andrew Gelman, Statistics and Political Science, Columbia University
 
Wed 27 Mar, 4pm, Betty Ford Auditorium, Ford School of Public Policy
 
Causal inference is central to the social and biomedical sciences.  There are unresolved debates about the meaning of causality and the methods that should be used to measure it.  As a statistician, I am trained to say that randomized experiments are a gold standard, yet I have spent almost all my applied career analyzing observational data.  In this talk we shall consider various approaches to causal reasoning from the perspective of an applied statistician who recognizes the importance of causal identification yet must learn from available information.
 
Two relevant papers are  here  and  here .</p><p>4 0.9070583 <a title="1880-lda-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-30-History_is_too_important_to_be_left_to_the_history_professors%2C_Part_2.html">2192 andrew gelman stats-2014-01-30-History is too important to be left to the history professors, Part 2</a></p>
<p>Introduction: Completely non-gay historian Niall Ferguson, a man who  we can be sure  would never be caught at a ballet or a poetry reading,  informs us  that the British decision to enter the first world war on the side of France and Belgium was “the biggest error in modern history.”
 
Ummm, here are a few bigger errors: 
   
The German decision to invade Russia in 1941.
 
The Japanese decision to attack America in 1941.
 
 Oh yeah , the German decision to invade Belgium in 1914.
 
The Russian decision to invade Afghanistan in 1981 doesn’t look like such a great decision either.
 
And it wasn’t so smart for Saddam Hussein to invade Kuwait, but maybe the countries involved were too small for this to count as “the biggest error in modern history.”
 
It’s striking that, in considering the biggest error in modern history, Ferguson omits all these notorious acts of aggression (bombing Pearl Harbor, leading to the destruction of much of your country, that was pretty bad, huh?), and decides that the worst</p><p>5 0.90049899 <a title="1880-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-05-Deadwood_in_the_math_curriculum.html">992 andrew gelman stats-2011-11-05-Deadwood in the math curriculum</a></p>
<p>Introduction: Mark Palko  asks :  What are the worst examples of curriculum dead wood?
 
Here’s the background:
  
One of the first things that hit me [Palko] when I started teaching high school math was how much material there was to cover. . . . The most annoying part, though, was the number of topics that could easily have been cut, thus giving the students the time to master the important skills and concepts.


The example that really stuck with me was synthetic division, a more concise but less intuitive way of performing polynomial long division. Both of these topics are pretty much useless in daily life but polynomial long division does, at least, give the student some insight into the relationship between polynomials and familiar base-ten numbers. Synthetic division has no such value; it’s just a faster but less interesting way of doing something you’ll never have to do.


I started asking hardcore math people — mathematicians, statisticians, physicists, rocket scientists — if they.’d ever u</p><p>6 0.8909874 <a title="1880-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-01-Classic_probability_mistake%2C_this_time_in_the_%28virtual%29_pages_of_the_New_York_Times.html">386 andrew gelman stats-2010-11-01-Classic probability mistake, this time in the (virtual) pages of the New York Times</a></p>
<p>7 0.88738799 <a title="1880-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-10-I_guess_they_noticed_that_if_you_take_the_first_word_on_every_seventeenth_page%2C_it_spells_out_%E2%80%9CDeath_to_the_Shah%E2%80%9D.html">510 andrew gelman stats-2011-01-10-I guess they noticed that if you take the first word on every seventeenth page, it spells out “Death to the Shah”</a></p>
<p>8 0.87804401 <a title="1880-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-29-The_Subtle_Micro-Effects_of_Peacekeeping.html">242 andrew gelman stats-2010-08-29-The Subtle Micro-Effects of Peacekeeping</a></p>
<p>9 0.87171185 <a title="1880-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-23-%E2%80%9CI_mean%2C_what_exact_buttons_do_I_have_to_hit%3F%E2%80%9D.html">1995 andrew gelman stats-2013-08-23-“I mean, what exact buttons do I have to hit?”</a></p>
<p>10 0.86932731 <a title="1880-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-25-A_question_about_the_Tiger_Mom%3A__what_if_she%E2%80%99d_had_boys_instead_of_girls%3F.html">1391 andrew gelman stats-2012-06-25-A question about the Tiger Mom:  what if she’d had boys instead of girls?</a></p>
<p>11 0.86905855 <a title="1880-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-26-Ethnicity_and_Population_Structure_in_Personal_Naming_Networks.html">925 andrew gelman stats-2011-09-26-Ethnicity and Population Structure in Personal Naming Networks</a></p>
<p>12 0.86904591 <a title="1880-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-27-%E2%80%9CThe_ultimate_left-wing_novel%E2%80%9D.html">682 andrew gelman stats-2011-04-27-“The ultimate left-wing novel”</a></p>
<p>13 0.85904825 <a title="1880-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-23-I_hate_this_stuff.html">2144 andrew gelman stats-2013-12-23-I hate this stuff</a></p>
<p>14 0.85373282 <a title="1880-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-04-One_more_thought_on_Hoover_historian_Niall_Ferguson%E2%80%99s_thing_about_Keynes_being_gay_and_marrying_a_ballerina_and_talking_about_poetry.html">1840 andrew gelman stats-2013-05-04-One more thought on Hoover historian Niall Ferguson’s thing about Keynes being gay and marrying a ballerina and talking about poetry</a></p>
<p>15 0.84432304 <a title="1880-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-19-Prose_is_paragraphs%2C_prose_is_sentences.html">1863 andrew gelman stats-2013-05-19-Prose is paragraphs, prose is sentences</a></p>
<p>16 0.84246576 <a title="1880-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-15-My_talk_last_night_at_the_visualization_meetup.html">1673 andrew gelman stats-2013-01-15-My talk last night at the visualization meetup</a></p>
<p>17 0.84110975 <a title="1880-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-07-Like_Casper_the_ghost%2C_Niall_Ferguson_is_not_only_white.__He_is_also_very%2C_very_adorable..html">1846 andrew gelman stats-2013-05-07-Like Casper the ghost, Niall Ferguson is not only white.  He is also very, very adorable.</a></p>
<p>18 0.84062696 <a title="1880-lda-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-11-My_talks_in_Bristol_this_Wed_and_London_this_Thurs.html">2207 andrew gelman stats-2014-02-11-My talks in Bristol this Wed and London this Thurs</a></p>
<p>19 0.83836472 <a title="1880-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-19-Steven_Pinker_is_a_psychologist_who_writes_on_politics.__His_theories_are_interesting_but_are_framed_too_universally_to_be_valid.html">1631 andrew gelman stats-2012-12-19-Steven Pinker is a psychologist who writes on politics.  His theories are interesting but are framed too universally to be valid</a></p>
<p>20 0.83717817 <a title="1880-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-26-Lies%2C_Damn_Lies%E2%80%A6that%E2%80%99s_pretty_much_it..html">539 andrew gelman stats-2011-01-26-Lies, Damn Lies…that’s pretty much it.</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
