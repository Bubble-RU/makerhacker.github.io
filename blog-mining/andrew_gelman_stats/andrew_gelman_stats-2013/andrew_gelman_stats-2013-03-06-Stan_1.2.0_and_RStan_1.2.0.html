<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1753 andrew gelman stats-2013-03-06-Stan 1.2.0 and RStan 1.2.0</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1753" href="#">andrew_gelman_stats-2013-1753</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1753 andrew gelman stats-2013-03-06-Stan 1.2.0 and RStan 1.2.0</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1753-html" href="http://andrewgelman.com/2013/03/06/stan-1-2-0-and-rstan-1-2-0/">html</a></p><p>Introduction: Stan 1.2.0 and RStan 1.2.0 are now available for download. See:
  
  http://mc-stan.org/ 
   
Here are the highlights.
  Full Mass Matrix Estimation during Warmup  
Yuanjun Gao, a first-year grad student here at Columbia (!), built a regularized mass-matrix estimator.   This helps for posteriors with high correlation among parameters and varying scales.  We’re still testing this ourselves, so the estimation procedure may change in the future (don’t worry — it satisfies detailed balance as is, but we might be able to make it more computationally efficient in terms of time per effective sample).
 
It’s not the default option.  The major reason is the matrix operations required are expensive, raising the algorithm cost to    , where   is the average number of leapfrog steps,   is the number of iterations, and   is the number of parameters.
 
Yuanjun did a great job with the Cholesky factorizations and implemented this about as efficiently as is possible. (His homework for Andrew’s class w</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We’re still testing this ourselves, so the estimation procedure may change in the future (don’t worry — it satisfies detailed balance as is, but we might be able to make it more computationally efficient in terms of time per effective sample). [sent-11, score-0.153]
</p><p>2 The major reason is the matrix operations required are expensive, raising the algorithm cost to    , where   is the average number of leapfrog steps,   is the number of iterations, and   is the number of parameters. [sent-13, score-0.494]
</p><p>3 Yuanjun did a great job with the Cholesky factorizations and implemented this about as efficiently as is possible. [sent-14, score-0.076]
</p><p>4 Cumulative Distribution Functions   The practical upshot is that Stan supports more truncated distributions, and hence more truncated and censored data models. [sent-17, score-0.21]
</p><p>5 Michael Betancourt did the heavy lifting here, which involved a crazy amount of “special function” derivative calculations and implementations. [sent-18, score-0.142]
</p><p>6 Everyone knows that the derivative of a distribution function with respect to the variate is the density. [sent-19, score-0.437]
</p><p>7 We’ll be documenting all of the functions and derivatives in the manual. [sent-21, score-0.471]
</p><p>8 Daniel Lee generalized the entire density and distribution function testing framework to generate code for tests. [sent-22, score-0.367]
</p><p>9 We’re doing much more extensive tests of the vectorizations and derivatives. [sent-23, score-0.06]
</p><p>10 Also, Daniel implemented efficient vectorized derivatives for many more of the density functions. [sent-24, score-0.361]
</p><p>11 Model Log Probability and Derivatives in R   Jiqiang Guo, who’s at the helm of RStan, wrote code to allow users to access the log probability function in a Stan model and its gradients directly. [sent-25, score-0.454]
</p><p>12 The functions are parameterized with the unconstrained parameterization of a Stan model with support on all of R^N. [sent-26, score-0.361]
</p><p>13 He also exposed the model functions to convert back and forth between the constrained and unconstrained parameterizations for initialization and interpretation of the samples. [sent-27, score-0.421]
</p><p>14 Print Posterior Summary Statistics from Command Line   Daniel Lee wrote a program to print a summary of one or more chains from the command line, mirroring the print() command of RStan. [sent-30, score-0.509]
</p><p>15 Bug Fixes   We also fixed a bad memory leak in multivariate operations that was introduced in the last release when we optimized the matrix operations for derivative calculations. [sent-31, score-1.336]
</p><p>16 We also fixed the Windows issue with conservative matrix resizing which caused multivariate models to crash under Windows at optimization levels above 0. [sent-32, score-0.742]
</p><p>17 The Future   There hass been a lot of activity in various branches that haven’t been merged into the trunk yet, so stay tuned. [sent-33, score-0.06]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('matrix', 0.321), ('functions', 0.266), ('function', 0.212), ('rstan', 0.183), ('operations', 0.173), ('fixed', 0.17), ('windows', 0.168), ('print', 0.156), ('derivatives', 0.145), ('derivative', 0.142), ('command', 0.137), ('yuanjun', 0.132), ('stan', 0.131), ('bug', 0.126), ('warmup', 0.114), ('multivariate', 0.107), ('log', 0.106), ('leak', 0.105), ('truncated', 0.105), ('daniel', 0.1), ('preventing', 0.095), ('fixes', 0.095), ('unconstrained', 0.095), ('documentation', 0.093), ('gradient', 0.092), ('cumulative', 0.087), ('estimation', 0.085), ('distribution', 0.083), ('chains', 0.079), ('memory', 0.079), ('probability', 0.076), ('optimization', 0.076), ('implemented', 0.076), ('density', 0.072), ('lee', 0.072), ('efficient', 0.068), ('caused', 0.068), ('mass', 0.068), ('release', 0.066), ('full', 0.065), ('trunk', 0.06), ('documenting', 0.06), ('grave', 0.06), ('helm', 0.06), ('vectorizations', 0.06), ('wrapped', 0.06), ('cholesky', 0.06), ('gao', 0.06), ('initialization', 0.06), ('jiqiang', 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="1753-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Stan_1.2.0_and_RStan_1.2.0.html">1753 andrew gelman stats-2013-03-06-Stan 1.2.0 and RStan 1.2.0</a></p>
<p>Introduction: Stan 1.2.0 and RStan 1.2.0 are now available for download. See:
  
  http://mc-stan.org/ 
   
Here are the highlights.
  Full Mass Matrix Estimation during Warmup  
Yuanjun Gao, a first-year grad student here at Columbia (!), built a regularized mass-matrix estimator.   This helps for posteriors with high correlation among parameters and varying scales.  We’re still testing this ourselves, so the estimation procedure may change in the future (don’t worry — it satisfies detailed balance as is, but we might be able to make it more computationally efficient in terms of time per effective sample).
 
It’s not the default option.  The major reason is the matrix operations required are expensive, raising the algorithm cost to    , where   is the average number of leapfrog steps,   is the number of iterations, and   is the number of parameters.
 
Yuanjun did a great job with the Cholesky factorizations and implemented this about as efficiently as is possible. (His homework for Andrew’s class w</p><p>2 0.37897328 <a title="1753-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-12-Stan_1.3.0_and_RStan_1.3.0_Ready_for_Action.html">1799 andrew gelman stats-2013-04-12-Stan 1.3.0 and RStan 1.3.0 Ready for Action</a></p>
<p>Introduction: The Stan Development Team is happy to announce that Stan 1.3.0 and RStan 1.3.0 are available for download. Follow the links on:
  
 Stan home page:   http://mc-stan.org/ 
   
Please let us know if you have problems updating.
 
Hereâ&euro;&trade;s the full set of release notes.
  
v1.3.0 (12 April 2013)
======================================================================
Enhancements
----------------------------------

Modeling Language
* forward sampling (random draws from distributions)
  in generated quantities
* better error messages in parser
* new distributions: 
    + exp_mod_normal
    + gumbel 
    + skew_normal
* new special functions: 
    + owenst
* new broadcast (repetition) functions for vectors, arrays, matrices
    + rep_arrray
    + rep_matrix
    + rep_row_vector
    + rep_vector    

Command-Line
* added option to display autocorrelations in the command-line program
  to print output
* changed default point estimation routine from the command line to</p><p>3 0.33378801 <a title="1753-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-17-Stan_and_RStan_1.1.0.html">1627 andrew gelman stats-2012-12-17-Stan and RStan 1.1.0</a></p>
<p>Introduction: We’re happy to announce the availability of Stan and RStan versions 1.1.0, which are general tools for performing model-based Bayesian inference using the no-U-turn sampler, an adaptive form of Hamiltonian Monte Carlo.   Information on downloading and installing and using them is available as always from
 
 Stan Home Page:   http://mc-stan.org/ 
 
Let us know if you have any problems on the mailing lists or at the e-mails linked on the home page (please don’t use this web page).  The full release notes follow.
  
(R)Stan Version 1.1.0 Release Notes
===================================
-- Backward Compatibility Issue
   * Categorical distribution recoded to match documentation;  it
     now has support {1,...,K} rather than {0,...,K-1}.  
   * (RStan) change default value of permuted flag from FALSE to TRUE for
     Stan fit S4 extract() method
-- New Features
   * Conditional (if-then-else) statements
   * While statements
-- New Functions
   * generalized multiply_lower_tri</p><p>4 0.32984087 <a title="1753-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-06-The_new_Stan_1.1.1%2C_featuring_Gaussian_processes%21.html">1710 andrew gelman stats-2013-02-06-The new Stan 1.1.1, featuring Gaussian processes!</a></p>
<p>Introduction: We just released Stan 1.1.1 and RStan 1.1.1
 
As usual, you can find download and install instructions at:
 
http://mc-stan.org/
 
This is a patch release and is fully backward compatible with Stan and RStan 1.1.0.  The main thing you should notice is that the multivariate models should be much faster and all the bugs reported for 1.1.0 have been fixed.  We’ve also added a bit more functionality.  The substantial changes are listed in the following release notes. 
   
v1.1.1 (5 February 2012) 
======================================================================
 
Bug Fixes 
———————————- 
* fixed bug in comparison operators, which swapped operator< with operator<= and swapped operator> with operator>= semantics 
* auto-initialize all variables to prevent segfaults 
* atan2 gradient propagation fixed 
* fixed off-by-one in NUTS treedepth bound so NUTS goes at most to specified tree depth rather than specified depth + 1 
* various compiler compatibility and minor consistency issues 
* f</p><p>5 0.26829085 <a title="1753-tfidf-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-13-CmdStan%2C_RStan%2C_PyStan_v2.2.0.html">2209 andrew gelman stats-2014-02-13-CmdStan, RStan, PyStan v2.2.0</a></p>
<p>Introduction: The Stan Development Team is happy to announce CmdStan, RStan, and PyStan v2.2.0.  As usual, more info is available on the
 
  Stan Home Page . 
 

This is a minor release with a mix of bug fixes and features. For a full list of changes, please see the  v2.2.0 milestone  on stan-dev/stan’s issue tracker. Some of the bug fixes and issues are listed below.


 Bug Fixes 

 
 increment_log_prob is now vectorized and compiles with vector arguments 
 multinomial random number generator used the wrong size for the return value 
 fixed memory leaks in auto-diff implementation 
 variables can start with the prefix ‘inf’ 
 fixed parameter output order for arrays when using optimization 
 RStan compatibility issue with latest Rcpp 0.11.0
  

 Features 

 
 suppress command line output with refresh <= 0 
 added 1 to treedepth to match usual definition of treedepth 
 added distance, squared_distance, diag_pre_multiply, diag_pre_multiply to Stan modeling lnaguage 
 added a ‘fixed_param’ sampler for</p><p>6 0.23249505 <a title="1753-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-27-%28R-Py-Cmd%29Stan_2.1.0.html">2150 andrew gelman stats-2013-12-27-(R-Py-Cmd)Stan 2.1.0</a></p>
<p>7 0.20728654 <a title="1753-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-07-My_recent_debugging_experience.html">2161 andrew gelman stats-2014-01-07-My recent debugging experience</a></p>
<p>8 0.19387798 <a title="1753-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>9 0.18694586 <a title="1753-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-19-Index_or_indicator_variables.html">2296 andrew gelman stats-2014-04-19-Index or indicator variables</a></p>
<p>10 0.17856513 <a title="1753-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-04-Handy_Matrix_Cheat_Sheet%2C_with_Gradients.html">555 andrew gelman stats-2011-02-04-Handy Matrix Cheat Sheet, with Gradients</a></p>
<p>11 0.15746218 <a title="1753-tfidf-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-21-Random_matrices_in_the_news.html">2258 andrew gelman stats-2014-03-21-Random matrices in the news</a></p>
<p>12 0.14830644 <a title="1753-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-A_Stan_is_Born.html">1475 andrew gelman stats-2012-08-30-A Stan is Born</a></p>
<p>13 0.14665151 <a title="1753-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-17-Data_problems%2C_coding_errors%E2%80%A6what_can_be_done%3F.html">1807 andrew gelman stats-2013-04-17-Data problems, coding errors…what can be done?</a></p>
<p>14 0.13581926 <a title="1753-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-04-Shlemiel_the_Software_Developer_and_Unknown_Unknowns.html">2089 andrew gelman stats-2013-11-04-Shlemiel the Software Developer and Unknown Unknowns</a></p>
<p>15 0.12194574 <a title="1753-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-29-Hamiltonian_Monte_Carlo_stories.html">931 andrew gelman stats-2011-09-29-Hamiltonian Monte Carlo stories</a></p>
<p>16 0.12021074 <a title="1753-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>17 0.11132383 <a title="1753-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-16-Stantastic%21.html">1580 andrew gelman stats-2012-11-16-Stantastic!</a></p>
<p>18 0.11097538 <a title="1753-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-09-The_future_of_R.html">266 andrew gelman stats-2010-09-09-The future of R</a></p>
<p>19 0.10555406 <a title="1753-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-21-Optimizing_software_in_C%2B%2B.html">1423 andrew gelman stats-2012-07-21-Optimizing software in C++</a></p>
<p>20 0.10500392 <a title="1753-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-04-PyStan%21.html">1748 andrew gelman stats-2013-03-04-PyStan!</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, 0.112), (2, -0.002), (3, 0.073), (4, 0.124), (5, 0.062), (6, 0.043), (7, -0.192), (8, -0.099), (9, -0.1), (10, -0.139), (11, -0.019), (12, -0.108), (13, -0.062), (14, 0.051), (15, -0.02), (16, -0.003), (17, 0.076), (18, -0.03), (19, -0.028), (20, 0.019), (21, 0.005), (22, -0.061), (23, -0.004), (24, 0.034), (25, 0.013), (26, 0.006), (27, 0.088), (28, 0.019), (29, -0.029), (30, -0.017), (31, 0.061), (32, 0.004), (33, 0.002), (34, 0.028), (35, -0.098), (36, -0.036), (37, 0.052), (38, 0.012), (39, 0.038), (40, 0.006), (41, -0.067), (42, -0.011), (43, -0.023), (44, 0.003), (45, 0.041), (46, -0.0), (47, -0.002), (48, 0.035), (49, -0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97017163 <a title="1753-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Stan_1.2.0_and_RStan_1.2.0.html">1753 andrew gelman stats-2013-03-06-Stan 1.2.0 and RStan 1.2.0</a></p>
<p>Introduction: Stan 1.2.0 and RStan 1.2.0 are now available for download. See:
  
  http://mc-stan.org/ 
   
Here are the highlights.
  Full Mass Matrix Estimation during Warmup  
Yuanjun Gao, a first-year grad student here at Columbia (!), built a regularized mass-matrix estimator.   This helps for posteriors with high correlation among parameters and varying scales.  We’re still testing this ourselves, so the estimation procedure may change in the future (don’t worry — it satisfies detailed balance as is, but we might be able to make it more computationally efficient in terms of time per effective sample).
 
It’s not the default option.  The major reason is the matrix operations required are expensive, raising the algorithm cost to    , where   is the average number of leapfrog steps,   is the number of iterations, and   is the number of parameters.
 
Yuanjun did a great job with the Cholesky factorizations and implemented this about as efficiently as is possible. (His homework for Andrew’s class w</p><p>2 0.94843519 <a title="1753-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-12-Stan_1.3.0_and_RStan_1.3.0_Ready_for_Action.html">1799 andrew gelman stats-2013-04-12-Stan 1.3.0 and RStan 1.3.0 Ready for Action</a></p>
<p>Introduction: The Stan Development Team is happy to announce that Stan 1.3.0 and RStan 1.3.0 are available for download. Follow the links on:
  
 Stan home page:   http://mc-stan.org/ 
   
Please let us know if you have problems updating.
 
Hereâ&euro;&trade;s the full set of release notes.
  
v1.3.0 (12 April 2013)
======================================================================
Enhancements
----------------------------------

Modeling Language
* forward sampling (random draws from distributions)
  in generated quantities
* better error messages in parser
* new distributions: 
    + exp_mod_normal
    + gumbel 
    + skew_normal
* new special functions: 
    + owenst
* new broadcast (repetition) functions for vectors, arrays, matrices
    + rep_arrray
    + rep_matrix
    + rep_row_vector
    + rep_vector    

Command-Line
* added option to display autocorrelations in the command-line program
  to print output
* changed default point estimation routine from the command line to</p><p>3 0.93866092 <a title="1753-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-06-The_new_Stan_1.1.1%2C_featuring_Gaussian_processes%21.html">1710 andrew gelman stats-2013-02-06-The new Stan 1.1.1, featuring Gaussian processes!</a></p>
<p>Introduction: We just released Stan 1.1.1 and RStan 1.1.1
 
As usual, you can find download and install instructions at:
 
http://mc-stan.org/
 
This is a patch release and is fully backward compatible with Stan and RStan 1.1.0.  The main thing you should notice is that the multivariate models should be much faster and all the bugs reported for 1.1.0 have been fixed.  We’ve also added a bit more functionality.  The substantial changes are listed in the following release notes. 
   
v1.1.1 (5 February 2012) 
======================================================================
 
Bug Fixes 
———————————- 
* fixed bug in comparison operators, which swapped operator< with operator<= and swapped operator> with operator>= semantics 
* auto-initialize all variables to prevent segfaults 
* atan2 gradient propagation fixed 
* fixed off-by-one in NUTS treedepth bound so NUTS goes at most to specified tree depth rather than specified depth + 1 
* various compiler compatibility and minor consistency issues 
* f</p><p>4 0.89511681 <a title="1753-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-17-Stan_and_RStan_1.1.0.html">1627 andrew gelman stats-2012-12-17-Stan and RStan 1.1.0</a></p>
<p>Introduction: We’re happy to announce the availability of Stan and RStan versions 1.1.0, which are general tools for performing model-based Bayesian inference using the no-U-turn sampler, an adaptive form of Hamiltonian Monte Carlo.   Information on downloading and installing and using them is available as always from
 
 Stan Home Page:   http://mc-stan.org/ 
 
Let us know if you have any problems on the mailing lists or at the e-mails linked on the home page (please don’t use this web page).  The full release notes follow.
  
(R)Stan Version 1.1.0 Release Notes
===================================
-- Backward Compatibility Issue
   * Categorical distribution recoded to match documentation;  it
     now has support {1,...,K} rather than {0,...,K-1}.  
   * (RStan) change default value of permuted flag from FALSE to TRUE for
     Stan fit S4 extract() method
-- New Features
   * Conditional (if-then-else) statements
   * While statements
-- New Functions
   * generalized multiply_lower_tri</p><p>5 0.84409916 <a title="1753-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-27-%28R-Py-Cmd%29Stan_2.1.0.html">2150 andrew gelman stats-2013-12-27-(R-Py-Cmd)Stan 2.1.0</a></p>
<p>Introduction: We’re happy to announce the release of Stan C++, CmdStan, 
RStan, and PyStan 2.1.0.  This is a minor feature release, 
but it is also an important bug fix release.  As always, the 
place to start is the (all new) Stan web pages:
 
 http://mc-stan.org 
 
 
 
 Major Bug in 2.0.0, 2.0.1 
 
Stan 2.0.0 and Stan 2.0.1 introduced a bug in the implementation 
of the NUTS criterion that led to poor tail exploration and 
thus biased the posterior uncertainty downward.  There was no 
bug in NUTS in Stan 1.3 or earlier, and 2.1 has been extensively tested 
and tests put in place so this problem will not recur.
 
If you are using Stan 2.0.0 or 2.0.1, you should switch to 2.1.0 as 
soon as possible and rerun any models you care about.
 
 
 
 New Target Acceptance Rate Default for Stan 2.1.0 
  Another big change aimed at reducing posterior estimation bias 
was an increase in the target acceptance rate during adaptation 
from 0.65 to 0.80.  The bad news is that iterations will take 
around 50% longer</p><p>6 0.80604291 <a title="1753-lsi-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-13-CmdStan%2C_RStan%2C_PyStan_v2.2.0.html">2209 andrew gelman stats-2014-02-13-CmdStan, RStan, PyStan v2.2.0</a></p>
<p>7 0.77609897 <a title="1753-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-30-Stan_Project%3A__Continuous_Relaxations_for_Discrete_MRFs.html">2003 andrew gelman stats-2013-08-30-Stan Project:  Continuous Relaxations for Discrete MRFs</a></p>
<p>8 0.77150458 <a title="1753-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-30-Stan_uses_Nuts%21.html">1036 andrew gelman stats-2011-11-30-Stan uses Nuts!</a></p>
<p>9 0.76675129 <a title="1753-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>10 0.76360291 <a title="1753-lsi-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-07-My_recent_debugging_experience.html">2161 andrew gelman stats-2014-01-07-My recent debugging experience</a></p>
<p>11 0.72772062 <a title="1753-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-A_Stan_is_Born.html">1475 andrew gelman stats-2012-08-30-A Stan is Born</a></p>
<p>12 0.71290773 <a title="1753-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-16-Stantastic%21.html">1580 andrew gelman stats-2012-11-16-Stantastic!</a></p>
<p>13 0.68610859 <a title="1753-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-10-Stan_Model_of_the_Week%3A__PK_Calculation_of_IV_and_Oral_Dosing.html">2242 andrew gelman stats-2014-03-10-Stan Model of the Week:  PK Calculation of IV and Oral Dosing</a></p>
<p>14 0.68473351 <a title="1753-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-12-Samplers_for_Big_Science%3A__emcee_and_BAT.html">2020 andrew gelman stats-2013-09-12-Samplers for Big Science:  emcee and BAT</a></p>
<p>15 0.6816293 <a title="1753-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-04-Handy_Matrix_Cheat_Sheet%2C_with_Gradients.html">555 andrew gelman stats-2011-02-04-Handy Matrix Cheat Sheet, with Gradients</a></p>
<p>16 0.66505331 <a title="1753-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-03-Running_into_a_Stan_Reference_by_Accident.html">2231 andrew gelman stats-2014-03-03-Running into a Stan Reference by Accident</a></p>
<p>17 0.65748668 <a title="1753-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-04-PyStan%21.html">1748 andrew gelman stats-2013-03-04-PyStan!</a></p>
<p>18 0.63754231 <a title="1753-lsi-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-14-Transitioning_to_Stan.html">2291 andrew gelman stats-2014-04-14-Transitioning to Stan</a></p>
<p>19 0.63571876 <a title="1753-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-14-The_joys_of_working_in_the_public_domain.html">712 andrew gelman stats-2011-05-14-The joys of working in the public domain</a></p>
<p>20 0.63554394 <a title="1753-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-12-%E2%80%9CThe_results_%28not_shown%29_._._.%E2%80%9D.html">2332 andrew gelman stats-2014-05-12-“The results (not shown) . . .”</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.036), (9, 0.012), (13, 0.015), (15, 0.01), (16, 0.048), (21, 0.024), (24, 0.157), (35, 0.036), (36, 0.029), (44, 0.025), (53, 0.014), (59, 0.026), (65, 0.026), (66, 0.011), (69, 0.023), (73, 0.011), (79, 0.014), (86, 0.046), (91, 0.122), (98, 0.014), (99, 0.161)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93674487 <a title="1753-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Stan_1.2.0_and_RStan_1.2.0.html">1753 andrew gelman stats-2013-03-06-Stan 1.2.0 and RStan 1.2.0</a></p>
<p>Introduction: Stan 1.2.0 and RStan 1.2.0 are now available for download. See:
  
  http://mc-stan.org/ 
   
Here are the highlights.
  Full Mass Matrix Estimation during Warmup  
Yuanjun Gao, a first-year grad student here at Columbia (!), built a regularized mass-matrix estimator.   This helps for posteriors with high correlation among parameters and varying scales.  We’re still testing this ourselves, so the estimation procedure may change in the future (don’t worry — it satisfies detailed balance as is, but we might be able to make it more computationally efficient in terms of time per effective sample).
 
It’s not the default option.  The major reason is the matrix operations required are expensive, raising the algorithm cost to    , where   is the average number of leapfrog steps,   is the number of iterations, and   is the number of parameters.
 
Yuanjun did a great job with the Cholesky factorizations and implemented this about as efficiently as is possible. (His homework for Andrew’s class w</p><p>2 0.8993274 <a title="1753-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-22-Top_10_blog_obsessions.html">920 andrew gelman stats-2011-09-22-Top 10 blog obsessions</a></p>
<p>Introduction: I was just thinking about this because we seem to be circling around the same few topics over and over (while occasionally slipping in some new statistical ideas): 
   
10. Wegman 
9. Hipmunk 
8. Dennis the dentist 
7. Freakonomics 
6. The difference between significant and non-significant is not itself statistically significant 
5. Just use a hierarchical model already! 
4. Innumerate journalists who think that presidential elections are just like high school 
3. A graph can be pretty but convey essentially no information 
2. Stan is coming 
1. Clippy!
 
Did I miss anything important?</p><p>3 0.88880873 <a title="1753-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-27-Confusion_from_illusory_precision.html">1186 andrew gelman stats-2012-02-27-Confusion from illusory precision</a></p>
<p>Introduction: When I posted this  link  to Dean Foster’s rants, some commenters pointed out  this  linked claim by famed statistician/provacateur Bjorn Lomberg:
  
If [writes Lomborg] you reduce your child’s intake of fruits and vegetables by just 0.03 grams a day (that’s the equivalent of half a grain of rice) when you opt for more expensive organic produce, the total risk of cancer goes up, not down. Omit buying just one apple every 20 years because you have gone organic, and your child is worse off.
  
Let’s unpack Lomborg’s claim.  I don’t know anything about the science of pesticides and cancer, but can he really be so sure that the effects are so small as to be comparable to the health effects of eating “just one apple every 20 years”?
 
I can’t believe you could estimate effects to anything like that precision.  I can’t believe anyone has such a precise estimate of the health effects of pesticides, and also I can’t believe anyone has such a precise effect of the health effect of eating an app</p><p>4 0.88637888 <a title="1753-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-29-Unfinished_business.html">637 andrew gelman stats-2011-03-29-Unfinished business</a></p>
<p>Introduction: This  blog  by J. Robert Lennon on abandoned novels made me think of the more general topic of abandoned projects.  I seem to recall George V. Higgins writing that he’d written and discarded 14 novels or so before publishing The Friends of Eddie Coyle.
 
I haven’t abandoned any novels but I’ve abandoned lots of research projects (and also have started various projects that there’s no way I’ll finish).  If you think about the decisions involved, it really has to be that way. You learn while you’re working on a project whether it’s worth continuing.  Sometimes I’ve put in the hard work and pushed a project to completion, published the article, and then I think . . . what was the point?  The modal number of citations of our articles is zero, etc.</p><p>5 0.88308001 <a title="1753-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-29-Response_to_%E2%80%9CWhy_Tables_Are_Really_Much_Better_Than_Graphs%E2%80%9D.html">736 andrew gelman stats-2011-05-29-Response to “Why Tables Are Really Much Better Than Graphs”</a></p>
<p>Introduction: Ellen Barnes writes, in response to  my paper and the associated discussion at JCGS ,
  
I [Barnes] am an industry statistician.  I will agree that a table of numbers is essential in an academic publication.  The readers want to be able to sit down with the numbers, and make sure they can replicate the results.  However, graphics communicate faster – especially when a group of engineers are trying to figure out what is going on.  Or, there are times when I have just a couple minutes to convey a complex relationship to a director or a vice-president.


One example from this week:  We are putting a new subsystem into some of our vehicles – using new technology.  The technical specialist leading the project wanted to double check to make sure the system was working properly and finalize the calibration procedure.  He mentioned a concern that was nagging him.  I plotted his data in a matrix plot (a matrix of two dimensional scatter plots).  We immediately keyed in on one plot that showed s</p><p>6 0.86744142 <a title="1753-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-26-Tumors%2C_on_the_left%2C_or_on_the_right%3F.html">53 andrew gelman stats-2010-05-26-Tumors, on the left, or on the right?</a></p>
<p>7 0.84902239 <a title="1753-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-04-Question_25_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1365 andrew gelman stats-2012-06-04-Question 25 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>8 0.84532344 <a title="1753-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-A_Stan_is_Born.html">1475 andrew gelman stats-2012-08-30-A Stan is Born</a></p>
<p>9 0.843018 <a title="1753-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-My_talk_at_MIT_on_Thurs_11_Oct.html">1528 andrew gelman stats-2012-10-10-My talk at MIT on Thurs 11 Oct</a></p>
<p>10 0.84239745 <a title="1753-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-05-Question_26_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1367 andrew gelman stats-2012-06-05-Question 26 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>11 0.84138089 <a title="1753-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-13-CmdStan%2C_RStan%2C_PyStan_v2.2.0.html">2209 andrew gelman stats-2014-02-13-CmdStan, RStan, PyStan v2.2.0</a></p>
<p>12 0.83814073 <a title="1753-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-12-Stan_1.3.0_and_RStan_1.3.0_Ready_for_Action.html">1799 andrew gelman stats-2013-04-12-Stan 1.3.0 and RStan 1.3.0 Ready for Action</a></p>
<p>13 0.83631152 <a title="1753-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-11-Steve_Jobs%E2%80%99s_cancer_and_science-based_medicine.html">953 andrew gelman stats-2011-10-11-Steve Jobs’s cancer and science-based medicine</a></p>
<p>14 0.83619148 <a title="1753-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-25-Avoiding_boundary_estimates_using_a_prior_distribution_as_regularization.html">779 andrew gelman stats-2011-06-25-Avoiding boundary estimates using a prior distribution as regularization</a></p>
<p>15 0.83573395 <a title="1753-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-29-More_on_scaled-inverse_Wishart_and_prior_independence.html">1474 andrew gelman stats-2012-08-29-More on scaled-inverse Wishart and prior independence</a></p>
<p>16 0.83533198 <a title="1753-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<p>17 0.83453631 <a title="1753-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-20-Prior_beliefs_about_locations_of_decision_boundaries.html">1130 andrew gelman stats-2012-01-20-Prior beliefs about locations of decision boundaries</a></p>
<p>18 0.83366841 <a title="1753-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-02-Blogads_update.html">1240 andrew gelman stats-2012-04-02-Blogads update</a></p>
<p>19 0.83317208 <a title="1753-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-11-Actually%2C_I_have_no_problem_with_this_graph.html">1851 andrew gelman stats-2013-05-11-Actually, I have no problem with this graph</a></p>
<p>20 0.83248776 <a title="1753-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-06-Question_27_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1368 andrew gelman stats-2012-06-06-Question 27 of my final exam for Design and Analysis of Sample Surveys</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
