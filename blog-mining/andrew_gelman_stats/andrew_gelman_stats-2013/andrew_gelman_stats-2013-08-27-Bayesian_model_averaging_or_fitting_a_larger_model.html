<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1999 andrew gelman stats-2013-08-27-Bayesian model averaging or fitting a larger model</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1999" href="#">andrew_gelman_stats-2013-1999</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1999 andrew gelman stats-2013-08-27-Bayesian model averaging or fitting a larger model</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1999-html" href="http://andrewgelman.com/2013/08/27/bayesian-model-averaging-or-fitting-a-larger-model/">html</a></p><p>Introduction: Nick Firoozye writes:
  
I had a question about BMA [Bayesian model averaging] and model combinations in general, and direct it to you since they are a basic form of hierarchical model, albeit in the simplest of forms. I wanted to ask what the underlying assumptions are that could lead to BMA improving on a larger model. 


I know model combination is a topic of interest in the (frequentist) econometrics community (e.g., Bates & Granger, http://www.jstor.org/discover/10.2307/3008764?uid=3738032&uid;=2&uid;=4&sid;=21101948653381) but at the time it was considered a bit of a puzzle. Perhaps small models combined outperform a big model due to standard errors, insufficient data, etc. But I haven’t seen much in way of Bayesian justification.


In simplest terms, you might have a joint density P(Y,theta_1,theta_2) from which you could use the two marginals P(Y,theta_1) and P(Y,theta_2) to derive two separate forecasts. A BMA-er would do a weighted average of the two forecast densities, having p</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Nick Firoozye writes:    I had a question about BMA [Bayesian model averaging] and model combinations in general, and direct it to you since they are a basic form of hierarchical model, albeit in the simplest of forms. [sent-1, score-0.983]
</p><p>2 I know model combination is a topic of interest in the (frequentist) econometrics community (e. [sent-3, score-0.356]
</p><p>3 Perhaps small models combined outperform a big model due to standard errors, insufficient data, etc. [sent-10, score-0.58]
</p><p>4 In simplest terms, you might have a joint density P(Y,theta_1,theta_2) from which you could use the two marginals P(Y,theta_1) and P(Y,theta_2) to derive two separate forecasts. [sent-12, score-0.435]
</p><p>5 A BMA-er would do a weighted average of the two forecast densities, having previously had a model prior. [sent-13, score-0.456]
</p><p>6 Is it an inability to impose proper priors on the larger parameter space? [sent-21, score-0.322]
</p><p>7 Of course I’m thinking in terms of simple easily combined models (e. [sent-24, score-0.313]
</p><p>8 , a regression on two variables), and a BMA-er could easily combine far more challenging models that don’t naturally form a supermodel. [sent-26, score-0.371]
</p><p>9 My reply:  Conditional on being required to use noninformative priors on each submodel, the strategy of model averaging or model selection can be better than using the larger model. [sent-27, score-1.064]
</p><p>10 But I agree that, if you’re thinking of fitting the small model or the large model, it makes more sense to use an informative prior that allows for shrinkage directly. [sent-28, score-0.564]
</p><p>11 I believe some of the early examples of BMA involved running 2^k regressions and averaging rather than running a single k dimensional regression with shrinkage (so much simpler doing a lasso,… er…, shrinkage estimator, to be honest). [sent-32, score-0.661]
</p><p>12 And the BMA was meant to be preferable to frequentist sequential model selection or using a criterion which involves the 2^k regressions anyway. [sent-33, score-0.6]
</p><p>13 And if so aren’t you saying it is better to have a single large non-hierarchical model than it is a hierarchical model? [sent-35, score-0.492]
</p><p>14 If we had informative priors on both parameter (and hyperparameter) we might have a better model yet? [sent-37, score-0.477]
</p><p>15 If so, why should we be doing hierarchical models at all, other than they can be far more intuitive than super-models? [sent-38, score-0.475]
</p><p>16 While Dempster and Shaffer do extend Bayes’ theorem to their special case, it just seems their theory is so more complex than just using a hierarchical model. [sent-40, score-0.368]
</p><p>17 Second order probability is merely a hierarchical model, with weights being put on a family of probability measures, and so much more intuitive than belief functions. [sent-41, score-0.597]
</p><p>18 My response:   Indeed, discrete model averaging can be seen as a sort of implementation of continuous model expansion in which the probability of setting a coefficient to zero is a way to get some shrinkage. [sent-42, score-0.995]
</p><p>19 For similar reasons, I have no particular interest in seeing which sets of predictors the fitted model wants me to include. [sent-44, score-0.356]
</p><p>20 On your larger question:  yes, I think hierarchical priors can be useful in specifying dependent uncertainty. [sent-45, score-0.467]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bma', 0.413), ('model', 0.285), ('phi', 0.24), ('hierarchical', 0.207), ('averaging', 0.171), ('theta', 0.168), ('shrinkage', 0.146), ('simplest', 0.141), ('marginals', 0.138), ('larger', 0.131), ('firoozye', 0.13), ('priors', 0.129), ('easily', 0.124), ('frequentist', 0.116), ('probability', 0.109), ('insufficient', 0.106), ('models', 0.103), ('intuitive', 0.099), ('extend', 0.097), ('weighted', 0.093), ('combined', 0.086), ('two', 0.078), ('regressions', 0.076), ('discrete', 0.076), ('functions', 0.076), ('belief', 0.073), ('interest', 0.071), ('prior', 0.07), ('continuous', 0.069), ('bates', 0.069), ('imprecise', 0.069), ('separable', 0.069), ('tractable', 0.069), ('collinearity', 0.069), ('shaffer', 0.069), ('far', 0.066), ('question', 0.065), ('expands', 0.065), ('granger', 0.065), ('hyperprior', 0.065), ('complex', 0.064), ('informative', 0.063), ('lead', 0.063), ('selection', 0.063), ('er', 0.062), ('inability', 0.062), ('running', 0.061), ('dempster', 0.06), ('preferable', 0.06), ('incompatible', 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1999-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-27-Bayesian_model_averaging_or_fitting_a_larger_model.html">1999 andrew gelman stats-2013-08-27-Bayesian model averaging or fitting a larger model</a></p>
<p>Introduction: Nick Firoozye writes:
  
I had a question about BMA [Bayesian model averaging] and model combinations in general, and direct it to you since they are a basic form of hierarchical model, albeit in the simplest of forms. I wanted to ask what the underlying assumptions are that could lead to BMA improving on a larger model. 


I know model combination is a topic of interest in the (frequentist) econometrics community (e.g., Bates & Granger, http://www.jstor.org/discover/10.2307/3008764?uid=3738032&uid;=2&uid;=4&sid;=21101948653381) but at the time it was considered a bit of a puzzle. Perhaps small models combined outperform a big model due to standard errors, insufficient data, etc. But I haven’t seen much in way of Bayesian justification.


In simplest terms, you might have a joint density P(Y,theta_1,theta_2) from which you could use the two marginals P(Y,theta_1) and P(Y,theta_2) to derive two separate forecasts. A BMA-er would do a weighted average of the two forecast densities, having p</p><p>2 0.24744451 <a title="1999-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>Introduction: Nick Firoozye writes:
  
While I am absolutely sympathetic to the Bayesian agenda I am often troubled by the requirement of having priors. We must have priors on the parameter of an infinite number of model we have never seen before and I find this troubling. There is a similarly troubling problem in economics of utility theory. Utility is on consumables. To be complete a consumer must assign utility to all sorts of things they never would have encountered. More recent versions of utility theory instead make consumption goods a portfolio of attributes. Cadillacs are x many units of luxury y of transport etc etc. And we can automatically have personal utilities to all these attributes.  


I don’t ever see parameters. Some model have few and some have hundreds. Instead, I see data. So I don’t know how to have an opinion on parameters themselves. Rather I think it far more natural to have opinions on the behavior of models. The prior predictive density is a good and sensible notion. Also</p><p>3 0.24595267 <a title="1999-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>Introduction: In response to  this article  by Cosma Shalizi and myself on the philosophy of Bayesian statistics, David Hogg writes:
  
I [Hogg] agree–even in physics and astronomy–that the models are not “True” in the God-like sense of being absolute reality (that is, I am not a realist); and I  have argued  (a philosophically very naive 
paper, but hey, I was new to all this) that for pretty fundamental reasons we could never arrive at the True (with a capital “T”) model of the Universe.  The goal of inference is to find the “best” model, where “best” might have something to do with prediction, or explanation, or message length, or (horror!) our utility.  Needless to say, most of my physics friends *are* realists, even in the face of “effective theories” as Newtonian mechanics is an effective theory of GR and GR is an effective theory of “quantum gravity” (this plays to your point, because if you think any theory is possibly an effective theory, how could you ever find Truth?).  I also liked the i</p><p>4 0.20011364 <a title="1999-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-05-An_example_of_Bayesian_model_averaging.html">840 andrew gelman stats-2011-08-05-An example of Bayesian model averaging</a></p>
<p>Introduction: Jay Ulfelder writes:
  
I see that you  blogged  about limitations of Bayesian model averaging. As it happens, I was  also blogging  about BMA, but with an example where it seems to be working reasonably well, at least for the narrow purpose of forecasting. The topic is the analysis I did for CFR earlier this year on nonviolent uprisings.
  
I donâ&euro;&trade;t have time to look into this one but I wanted to pass it on.</p><p>5 0.19751696 <a title="1999-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>Introduction: Following up on Christian’s  post  [link fixed] on the topic, I’d like to offer a few thoughts of my own.
 
In BDA, we express the idea that a noninformative prior is a placeholder:  you can use the noninformative prior to get the analysis started, then if your posterior distribution is less informative than you would like, or if it does not make sense, you can go back and add prior information.
 
Same thing for the data model (the “likelihood”), for that matter:  it often makes sense to start with something simple and conventional and then go from there.
 
So, in that sense, noninformative priors are no big deal, they’re just a way to get started.  Just don’t take them too seriously.
 
Traditionally in statistics we’ve worked with the paradigm of a single highly informative dataset with only weak external information.  But if the data are sparse and prior information is strong, we have to think differently.  And, when you increase the dimensionality of a problem, both these things hap</p><p>6 0.19624834 <a title="1999-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>7 0.19587457 <a title="1999-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-27-Overfitting.html">1431 andrew gelman stats-2012-07-27-Overfitting</a></p>
<p>8 0.19445369 <a title="1999-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>9 0.18356185 <a title="1999-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>10 0.17940874 <a title="1999-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>11 0.17770873 <a title="1999-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<p>12 0.17494076 <a title="1999-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-23-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1868 andrew gelman stats-2013-05-23-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>13 0.17488614 <a title="1999-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>14 0.17314535 <a title="1999-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-07-Prior_distributions_for_regression_coefficients.html">1486 andrew gelman stats-2012-09-07-Prior distributions for regression coefficients</a></p>
<p>15 0.17148866 <a title="1999-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-23-Examples_of_the_use_of_hierarchical_modeling_to_generalize_to_new_settings.html">1425 andrew gelman stats-2012-07-23-Examples of the use of hierarchical modeling to generalize to new settings</a></p>
<p>16 0.16864759 <a title="1999-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>17 0.16776122 <a title="1999-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-05-Prior_distribution_for_a_predicted_probability.html">2200 andrew gelman stats-2014-02-05-Prior distribution for a predicted probability</a></p>
<p>18 0.16702412 <a title="1999-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>19 0.16303314 <a title="1999-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-13-Flexibility_is_good.html">2133 andrew gelman stats-2013-12-13-Flexibility is good</a></p>
<p>20 0.16185148 <a title="1999-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.26), (1, 0.303), (2, 0.037), (3, 0.079), (4, -0.016), (5, -0.02), (6, 0.076), (7, -0.01), (8, 0.031), (9, 0.062), (10, 0.033), (11, 0.06), (12, -0.042), (13, -0.016), (14, -0.077), (15, -0.015), (16, 0.042), (17, -0.008), (18, 0.008), (19, -0.008), (20, 0.004), (21, -0.008), (22, -0.027), (23, -0.063), (24, -0.04), (25, 0.005), (26, 0.003), (27, -0.03), (28, -0.003), (29, -0.006), (30, -0.041), (31, -0.014), (32, -0.032), (33, 0.012), (34, -0.029), (35, 0.015), (36, 0.002), (37, -0.017), (38, -0.021), (39, 0.023), (40, -0.001), (41, 0.028), (42, 0.018), (43, 0.01), (44, -0.025), (45, -0.029), (46, 0.029), (47, 0.013), (48, -0.021), (49, 0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97566205 <a title="1999-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-27-Bayesian_model_averaging_or_fitting_a_larger_model.html">1999 andrew gelman stats-2013-08-27-Bayesian model averaging or fitting a larger model</a></p>
<p>Introduction: Nick Firoozye writes:
  
I had a question about BMA [Bayesian model averaging] and model combinations in general, and direct it to you since they are a basic form of hierarchical model, albeit in the simplest of forms. I wanted to ask what the underlying assumptions are that could lead to BMA improving on a larger model. 


I know model combination is a topic of interest in the (frequentist) econometrics community (e.g., Bates & Granger, http://www.jstor.org/discover/10.2307/3008764?uid=3738032&uid;=2&uid;=4&sid;=21101948653381) but at the time it was considered a bit of a puzzle. Perhaps small models combined outperform a big model due to standard errors, insufficient data, etc. But I haven’t seen much in way of Bayesian justification.


In simplest terms, you might have a joint density P(Y,theta_1,theta_2) from which you could use the two marginals P(Y,theta_1) and P(Y,theta_2) to derive two separate forecasts. A BMA-er would do a weighted average of the two forecast densities, having p</p><p>2 0.90601987 <a title="1999-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>Introduction: In response to  this article  by Cosma Shalizi and myself on the philosophy of Bayesian statistics, David Hogg writes:
  
I [Hogg] agree–even in physics and astronomy–that the models are not “True” in the God-like sense of being absolute reality (that is, I am not a realist); and I  have argued  (a philosophically very naive 
paper, but hey, I was new to all this) that for pretty fundamental reasons we could never arrive at the True (with a capital “T”) model of the Universe.  The goal of inference is to find the “best” model, where “best” might have something to do with prediction, or explanation, or message length, or (horror!) our utility.  Needless to say, most of my physics friends *are* realists, even in the face of “effective theories” as Newtonian mechanics is an effective theory of GR and GR is an effective theory of “quantum gravity” (this plays to your point, because if you think any theory is possibly an effective theory, how could you ever find Truth?).  I also liked the i</p><p>3 0.89681077 <a title="1999-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-27-Overfitting.html">1431 andrew gelman stats-2012-07-27-Overfitting</a></p>
<p>Introduction: Ilya Esteban writes:
  
In traditional machine learning and statistical learning techniques, you spend a lot of time selecting your input features, fiddling with model parameter values, etc., all of which leads to the problem of overfitting the data and producing overly optimistic estimates for how good the model really is. You can use techniques such as cross-validation and out-of-sample validation data to try to limit the damage, but they are imperfect solutions at best.


While Bayesian models have the great advantage of not forcing you to manually select among the various weights and input features, you still often end up trying different priors and model structures (especially with hierarchical models), before coming up with a “final” model. When applying Bayesian modeling to real world data sets, how does should you evaluate alternate priors and topologies for the model without falling into the same overfitting trap as you do with non-Bayesian models? If you try several different</p><p>4 0.89593726 <a title="1999-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-17-Modeling_group-level_predictors_in_a_multilevel_regression.html">1216 andrew gelman stats-2012-03-17-Modeling group-level predictors in a multilevel regression</a></p>
<p>Introduction: Trey Causey writes:
  
Do you have suggestions as to model selection strategies akin to Bayesian model averaging for multilevel models when level-2 inputs are of substantive interest? I [Causey] have seen plenty of R packages and procedures for non-multilevel models, and tried the glmulti package but found that it did not perform well with more than a few level-2 variables.
  
My quick answer is:  with a name like that, you should really be fitting three-level models!
 
My longer answer is:  regular readers will be unsurprised to hear that I’m no fan of  Bayesian model averaging .  Instead I’d prefer to bite the bullet and assign an informative prior distribution on these coefficients.  I don’t have a great example of such an analysis but I’m more and more thinking that this is the way to go.  I don’t see the point in aiming for the intermediate goal of pruning the predictors; I’d rather have a procedure that includes prior information on the predictors and their interactions.</p><p>5 0.89323896 <a title="1999-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-15-Wacky_priors_can_work_well%3F.html">1723 andrew gelman stats-2013-02-15-Wacky priors can work well?</a></p>
<p>Introduction: Dave Judkins writes:
  
I would love to see a blog entry on  this article , Bayesian Model Selection in High-Dimensional Settings, by Valen Johnson and David Rossell.  The simulation results are very encouraging although the choice of colors for some of the graphics is unfortunate.  Unless I am colorblind in some way that I am unaware of, they have two thin charcoal lines that are indistinguishable.
  
When Dave Judkins puts in a request, I’ll respond.  Also, I’m always happy to see a new Val Johnson paper.  Val and I are contemporaries—he and I got our PhD’s at around the same time, with both of us working on Bayesian image reconstruction, then in the early 1990s Val was part of the legendary group at Duke’s Institute of Statistics and Decision Sciences—a veritable ’27 Yankees featuring Mike West, Merlise Clyde, Michael Lavine, Dave Higdon, Peter Mueller, Val, and a bunch of others.  I always thought it was too bad they all had to go their separate ways.
 
Val also wrote two classic p</p><p>6 0.89242691 <a title="1999-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>7 0.89188725 <a title="1999-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-15-How_I_think_about_mixture_models.html">1459 andrew gelman stats-2012-08-15-How I think about mixture models</a></p>
<p>8 0.87608171 <a title="1999-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>9 0.86814994 <a title="1999-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-25-Incoherence_of_Bayesian_data_analysis.html">1510 andrew gelman stats-2012-09-25-Incoherence of Bayesian data analysis</a></p>
<p>10 0.86701721 <a title="1999-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-21-More_on_Bayesian_model_selection_in_high-dimensional_settings.html">1817 andrew gelman stats-2013-04-21-More on Bayesian model selection in high-dimensional settings</a></p>
<p>11 0.86430138 <a title="1999-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>12 0.86421967 <a title="1999-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>13 0.85860217 <a title="1999-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-12-How_to_think_about_%E2%80%9Cidentifiability%E2%80%9D_in_Bayesian_inference%3F.html">2208 andrew gelman stats-2014-02-12-How to think about “identifiability” in Bayesian inference?</a></p>
<p>14 0.85794479 <a title="1999-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-19-Whassup_with_deviance_having_a_high_posterior_correlation_with_a_parameter_in_the_model%3F.html">1221 andrew gelman stats-2012-03-19-Whassup with deviance having a high posterior correlation with a parameter in the model?</a></p>
<p>15 0.85150015 <a title="1999-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-28-Understanding_simulations_in_terms_of_predictive_inference%3F.html">1287 andrew gelman stats-2012-04-28-Understanding simulations in terms of predictive inference?</a></p>
<p>16 0.8481698 <a title="1999-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-26-Modeling_probability_data.html">1284 andrew gelman stats-2012-04-26-Modeling probability data</a></p>
<p>17 0.84617984 <a title="1999-lsi-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-06-Quote_of_the_day.html">398 andrew gelman stats-2010-11-06-Quote of the day</a></p>
<p>18 0.84537667 <a title="1999-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-07-Bayesian_hierarchical_model_for_the_prediction_of_soccer_results.html">20 andrew gelman stats-2010-05-07-Bayesian hierarchical model for the prediction of soccer results</a></p>
<p>19 0.84168613 <a title="1999-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-21-Models_with_constraints.html">2342 andrew gelman stats-2014-05-21-Models with constraints</a></p>
<p>20 0.83672047 <a title="1999-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Adding_more_information_can_make_the_variance_go_up_%28depending_on_your_model%29.html">810 andrew gelman stats-2011-07-20-Adding more information can make the variance go up (depending on your model)</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.042), (21, 0.013), (22, 0.011), (24, 0.473), (27, 0.014), (86, 0.015), (89, 0.015), (99, 0.246)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99658531 <a title="1999-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-02-So-called_Bayesian_hypothesis_testing_is_just_as_bad_as_regular_hypothesis_testing.html">643 andrew gelman stats-2011-04-02-So-called Bayesian hypothesis testing is just as bad as regular hypothesis testing</a></p>
<p>Introduction: Steve Ziliak points me to  this article  by the always-excellent Carl Bialik, slamming hypothesis tests.  I only wish Carl had talked with me before so hastily posting, though!  I would’ve argued with some of the things in the article.  In particular, he writes:
  
Reese and Brad Carlin . . . suggest that Bayesian statistics are a better alternative, because they tackle the probability that the hypothesis is true head-on, and incorporate prior knowledge about the variables involved.
  
Brad Carlin does great work in theory, methods, and applications, and I like the bit about the prior knowledge (although I might prefer the more general phrase “additional information”), but I hate that quote!  
 
My quick response is that the hypothesis of zero effect is almost never true!  The problem with the significance testing framework–Bayesian or otherwise–is in the obsession with the possibility of an exact zero effect.  The real concern is not with zero, it’s with claiming a positive effect whe</p><p>2 0.99611235 <a title="1999-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-18-Breastfeeding%2C_infant_hyperbilirubinemia%2C_statistical_graphics%2C_and_modern_medicine.html">38 andrew gelman stats-2010-05-18-Breastfeeding, infant hyperbilirubinemia, statistical graphics, and modern medicine</a></p>
<p>Introduction: Dan Lakeland  asks :
  
When are statistical graphics potentially life threatening?  When they’re poorly designed, and used to make decisions on potentially life threatening topics, like medical decision making, engineering design, and the like.  The American Academy of Pediatrics has dropped the ball on communicating to physicians about infant jaundice.  Another message in this post is that bad decisions can compound each other.
  
It’s an interesting story (follow the link above for the details), would be great for a class in decision analysis or statistical communication.  I have no idea how to get from A to B here, in the sense of persuading hospitals to do this sort of thing better.  I’d guess the first step is to carefully lay out costs and benefits.  When doctors and nurses make extra precautions for safety, it could be useful to lay out the ultimate goals and estimate the potential costs and benefits of different approaches.</p><p>3 0.99532336 <a title="1999-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-Comparing_prediction_errors.html">938 andrew gelman stats-2011-10-03-Comparing prediction errors</a></p>
<p>Introduction: Someone named James writes: 
  
  
I’m working on a classification task, sentence segmentation.  The classifier algorithm we use (BoosTexter, a boosted learning algorithm) classifies each word independently conditional on its features, i.e. a bag-of-words model, so any contextual clues need to be encoded into the features.  The feature extraction system I am proposing in my thesis uses a heteroscedastic LDA to transform data to produce the features the classifier runs on. The HLDA system has a couple parameters I’m testing, and I’m running a 3×2 full factorial experiment. That’s the background which may or may not be relevant to the question.


The output of each trial is a class (there are only 2 classes, right now) for every word in the dataset.  Because of the nature of the task, one class strongly predominates, say 90-95% of the data.  My question is this: in terms of overall performance (we use F1 score), many of these trials are pretty close together, which leads me to ask whethe</p><p>4 0.99458539 <a title="1999-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-29-More_by_Berger_and_me_on_weakly_informative_priors.html">1092 andrew gelman stats-2011-12-29-More by Berger and me on weakly informative priors</a></p>
<p>Introduction: A couple days ago we  discussed  some remarks by Tony O’Hagan and Jim Berger on weakly informative priors.  Jim  followed up  on Deborah Mayo’s blog with this:
  
Objective Bayesian priors are often improper (i.e., have infinite total mass), but this is not a problem when they are developed correctly. But not every improper prior is satisfactory. For instance, the constant prior is known to be unsatisfactory in many situations. The ‘solution’ pseudo-Bayesians often use is to choose a constant prior over a large but bounded set (a ‘weakly informative’ prior), saying it is now proper and so all is well. This is not true; if the constant prior on the whole parameter space is bad, so will be the constant prior over the bounded set. The problem is, in part, that some people confuse proper priors with subjective priors and, having learned that true subjective priors are fine, incorrectly presume that weakly informative proper priors are fine.
  
I have a few reactions to this:
 
1.  I agree</p><p>5 0.99302202 <a title="1999-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-29-Ethics_and_statistics_in_development_research.html">241 andrew gelman stats-2010-08-29-Ethics and statistics in development research</a></p>
<p>Introduction: From Bannerjee and Duflo, “The Experimental Approach to Development Economics,” Annual Review of Economics (2009):
  
One issue with the explicit acknowledgment of randomization as a fair way to allocate the program is that implementers may find that the easiest way to present it to the community is to say that an expansion of the program is planned for the control areas in the future (especially when such is indeed the case, as in phased-in design).
  
I can’t quite figure out whether Bannerjee and Duflo are saying that  they  would lie and tell people that an expansion is planned when it isn’t, or whether they’re deploring that other people do it.
 
I’m not bothered by a lot of the deception in experimental research–for example, I think the Milgram obedience experiment was just fine–but somehow the above deception bothers me.  It just seems wrong to tell people that an expansion is planned if it’s not.
 
P.S.  Overall the article is pretty good.  My only real problem with it is that</p><p>6 0.99281555 <a title="1999-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-12-Fixing_the_race%2C_ethnicity%2C_and_national_origin_questions_on_the_U.S._Census.html">1978 andrew gelman stats-2013-08-12-Fixing the race, ethnicity, and national origin questions on the U.S. Census</a></p>
<p>7 0.99232793 <a title="1999-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-01-Mothers_and_Moms.html">1479 andrew gelman stats-2012-09-01-Mothers and Moms</a></p>
<p>8 0.99081933 <a title="1999-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-23-Capitalism_as_a_form_of_voluntarism.html">482 andrew gelman stats-2010-12-23-Capitalism as a form of voluntarism</a></p>
<p>9 0.98895687 <a title="1999-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-30-New_innovations_in_spam.html">545 andrew gelman stats-2011-01-30-New innovations in spam</a></p>
<p>10 0.98880106 <a title="1999-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-29-ARM_solutions.html">240 andrew gelman stats-2010-08-29-ARM solutions</a></p>
<p>11 0.98635912 <a title="1999-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-04-Too_many_MC%E2%80%99s_not_enough_MIC%E2%80%99s%2C_or_What_principles_should_govern_attempts_to_summarize_bivariate_associations_in_large_multivariate_datasets%3F.html">1706 andrew gelman stats-2013-02-04-Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets?</a></p>
<p>12 0.98623478 <a title="1999-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-04-Wanna_be_the_next_Tyler_Cowen%3F__It%E2%80%99s_not_as_easy_as_you_might_think%21.html">1787 andrew gelman stats-2013-04-04-Wanna be the next Tyler Cowen?  It’s not as easy as you might think!</a></p>
<p>13 0.98569643 <a title="1999-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-03-An_argument_that_can%E2%80%99t_possibly_make_sense.html">743 andrew gelman stats-2011-06-03-An argument that can’t possibly make sense</a></p>
<p>14 0.98412001 <a title="1999-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>15 0.98337561 <a title="1999-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-28-God-leaf-tree.html">2229 andrew gelman stats-2014-02-28-God-leaf-tree</a></p>
<p>16 0.97746038 <a title="1999-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-07-Neutral_noninformative_and_informative_conjugate_beta_and_gamma_prior_distributions.html">1046 andrew gelman stats-2011-12-07-Neutral noninformative and informative conjugate beta and gamma prior distributions</a></p>
<p>17 0.97669756 <a title="1999-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-12-Simple_graph_WIN%3A__the_example_of_birthday_frequencies.html">1376 andrew gelman stats-2012-06-12-Simple graph WIN:  the example of birthday frequencies</a></p>
<p>18 0.9712652 <a title="1999-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-15-Advice_that_might_make_sense_for_individuals_but_is_negative-sum_overall.html">278 andrew gelman stats-2010-09-15-Advice that might make sense for individuals but is negative-sum overall</a></p>
<p>19 0.97043496 <a title="1999-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-Paying_survey_respondents.html">1437 andrew gelman stats-2012-07-31-Paying survey respondents</a></p>
<p>20 0.96765006 <a title="1999-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-12-Probabilistic_screening_to_get_an_approximate_self-weighted_sample.html">1455 andrew gelman stats-2012-08-12-Probabilistic screening to get an approximate self-weighted sample</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
