<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1826" href="#">andrew_gelman_stats-2013-1826</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1826-html" href="http://andrewgelman.com/2013/04/26/a-vast-graveyard-of-undead-theories-publication-bias-and-psychological-sciences-aversion-to-the-null-2/">html</a></p><p>Introduction: Erin Jonaitis points us to  this article  by Christopher Ferguson and Moritz Heene, who write:
  
Publication bias remains a controversial issue in psychological science. . . . that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. Given that science is dependent on the process of falsification, we argue that these problems reduce psychological science’s capability to have a proper mechanism for theory falsification, thus resulting in the promulgation of numerous “undead” theories that are ideologically popular but have little basis in fact.
  
They mention the infamous Daryl Bem article.  It is pretty much only because Bem’s claims are (presumably) false that they got published in a major research journal.  Had the claims been true—that is, had Bem run identical experiments, analyzed his data more carefully and objectively, and reported that the r</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Erin Jonaitis points us to  this article  by Christopher Ferguson and Moritz Heene, who write:    Publication bias remains a controversial issue in psychological science. [sent-1, score-0.144]
</p><p>2 that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. [sent-5, score-1.191]
</p><p>3 It is pretty much only because Bem’s claims are (presumably) false that they got published in a major research journal. [sent-8, score-0.177]
</p><p>4 Had the claims been true—that is, had Bem run identical experiments, analyzed his data more carefully and objectively, and reported that the results were consistent with the null hypothesis—then the result would be entirely unpublishable. [sent-9, score-0.424]
</p><p>5 Without making this computational error, the FSN turns out to be a gross overestimate of the number of unpublished studies required to bring the mean Z value of published studies to an insignificant level. [sent-23, score-0.59]
</p><p>6 The FSN thus gives the meta-analytic researcher a false sense of security. [sent-24, score-0.241]
</p><p>7 The false sense of security persists:    Although this fundamental flaw had been spotted early, the number of applications of the FSN has grown exponentially since its publication. [sent-25, score-0.162]
</p><p>8 Problems with meta-analysis    Ferguson and Heene continue:    Meta-analyses should be more objective arbiters of review for a field than are narrative reviews, but we argue that this is not the case in practice. [sent-29, score-0.145]
</p><p>9 The selection and interpretation of effect sizes from individual studies requires decisions that may be susceptible to researcher biases. [sent-33, score-0.383]
</p><p>10 meta-analyses may be used in such debates to essentially confound the process of replication and falsification. [sent-38, score-0.28]
</p><p>11 Thus:    The average effect size may be largely meaningless and spurious due to the avoidance of null findings in the published literature. [sent-39, score-0.609]
</p><p>12 This aversion to the null is arguably one of the most pernicious and unscientific aspects of modern social science. [sent-40, score-0.599]
</p><p>13 I think it’s important to separate the  statistical  from the  scientific  null hypothesis. [sent-42, score-0.454]
</p><p>14 - The  statistical null hypothesis  is typically that a particular comparison is exactly zero in the population. [sent-43, score-0.491]
</p><p>15 - The  scientific null hypothesis  is typically that a certain effect is nonexistent or, more generally, that the effect depends so much on situation as to be unreplicable in general. [sent-44, score-0.773]
</p><p>16 I might well believe in the scientific null but not in the statistical null. [sent-45, score-0.454]
</p><p>17 Virtually unkillable    Ferguson and Heene continue:    The aversion to the null and the persistence of publication bias and denial of the same, renders a situation in which psychological theories are virtually unkillable. [sent-46, score-0.909]
</p><p>18 Instead of rigid adherence to an objective process of replication and falsification, debates within psychology too easily degenerate into ideological snowball fights, the end result of which is to allow poor quality theories to survive indefinitely. [sent-47, score-0.465]
</p><p>19 We see this reversal of the burden of proof all the time. [sent-50, score-0.222]
</p><p>20 do not and cannot provide irrefutable proof of the alleged clerical errors. [sent-56, score-0.14]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fsn', 0.414), ('null', 0.364), ('heene', 0.269), ('ferguson', 0.173), ('proof', 0.14), ('aversion', 0.133), ('unpublished', 0.121), ('publication', 0.119), ('falsification', 0.117), ('bem', 0.103), ('unscientific', 0.102), ('false', 0.099), ('rosenthal', 0.097), ('effect', 0.096), ('studies', 0.092), ('scientific', 0.09), ('theories', 0.087), ('insignificant', 0.085), ('field', 0.084), ('burden', 0.082), ('process', 0.082), ('psychological', 0.079), ('published', 0.078), ('continue', 0.077), ('thus', 0.073), ('virtually', 0.073), ('may', 0.071), ('slate', 0.071), ('researcher', 0.069), ('flawed', 0.068), ('debates', 0.066), ('hypothesis', 0.065), ('controversial', 0.065), ('number', 0.063), ('typically', 0.062), ('objective', 0.061), ('replication', 0.061), ('results', 0.06), ('value', 0.059), ('magazine', 0.058), ('sizes', 0.055), ('theory', 0.055), ('adherence', 0.054), ('erin', 0.054), ('renders', 0.054), ('undead', 0.054), ('claimant', 0.054), ('onus', 0.054), ('antagonists', 0.054), ('degenerate', 0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="1826-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>Introduction: Erin Jonaitis points us to  this article  by Christopher Ferguson and Moritz Heene, who write:
  
Publication bias remains a controversial issue in psychological science. . . . that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. Given that science is dependent on the process of falsification, we argue that these problems reduce psychological science’s capability to have a proper mechanism for theory falsification, thus resulting in the promulgation of numerous “undead” theories that are ideologically popular but have little basis in fact.
  
They mention the infamous Daryl Bem article.  It is pretty much only because Bem’s claims are (presumably) false that they got published in a major research journal.  Had the claims been true—that is, had Bem run identical experiments, analyzed his data more carefully and objectively, and reported that the r</p><p>2 0.21759981 <a title="1826-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>Introduction: Masanao sends  this one  in, under the heading, “another incident of misunderstood p-value”:
  
Warren Davies, a positive psychology MSc student at UEL, provides the latest in our ongoing series of guest features for students. Warren has just released a Psychology Study Guide, which covers information on statistics, research methods and study skills for psychology students.

 
Despite the myriad rules and procedures of science, some research findings are pure flukes. Perhaps you’re testing a new drug, and by chance alone, a large number of people spontaneously get better. The better your study is conducted, the lower the chance that your result was a fluke – but still, there is always a certain probability that it was.


Statistical significance testing gives you an idea of what this probability is.


In science we’re always testing hypotheses. We never conduct a study to ‘see what happens’, because there’s always at least one way to make any useless set of data look important. We take</p><p>3 0.18796988 <a title="1826-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-16-The_lamest%2C_grudgingest%2C_non-retraction_retraction_ever.html">1626 andrew gelman stats-2012-12-16-The lamest, grudgingest, non-retraction retraction ever</a></p>
<p>Introduction: In politics we’re familiar with the non-apology apology (well described in Wikipedia as “a statement that has the form of an apology but does not express the expected contrition”).  Here’s the scientific equivalent:  the non-retraction retraction.
 
Sanjay Srivastava  points  to an amusing yet barfable story of a pair of researchers who (inadvertently, I assume) made a data coding error and were eventually moved to issue a correction notice, but even then refused to fully admit their error.  As Srivastava puts it, the story “ended up with Lew [Goldberg] and colleagues [Kibeom Lee and Michael Ashton] publishing a comment on an erratum – the only time I’ve ever heard of that happening in a scientific journal.”
 
From the  comment  on the erratum:
  
In their “erratum and addendum,” Anderson and Ones (this issue) explained that we had brought their attention to the “potential” of a “possible” misalignment and described the results computed from re-aligned data as being based on a “post-ho</p><p>4 0.18291174 <a title="1826-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-13-How_should_journals_handle_replication_studies%3F.html">762 andrew gelman stats-2011-06-13-How should journals handle replication studies?</a></p>
<p>Introduction: Sanjay Srivastava  reports :
  
Recently  Ben Goldacre wrote  about a group of researchers (Stuart Ritchie, Chris French, and Richard Wiseman) whose null replication of 3 experiments from the infamous Bem ESP paper was rejected by JPSP – the same journal that published Bem’s paper.
  
Srivastava recognizes that JPSP does not usually publish replications but this is a different story because it’s an anti-replication.
 
Here’s the paradox:
 
- From a scientific point of view, the Ritchie et al. results are boring.  To find out that there’s no evidence for ESP . . . that adds essentially zero to our scientific understanding.  What next, a paper demonstrating that pigeons can fly higher than chickens?  Maybe an article in the Journal of the Materials Research Society demonstrating that diamonds can scratch marble but not the reverse??
 
- But from a science-communication perspective, the null replication is a big deal because it adds credence to  my hypothesis  that the earlier ESP claims</p><p>5 0.17467009 <a title="1826-tfidf-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>Introduction: A recent  discussion  between commenters Question and Fernando captured one of the recurrent themes here from the past year.
 
 Question:   The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct.
 
 Fernando:   Whereas it is probably true that researchers misuse NHT, the problem with tabloid science is broader and deeper. It is systemic.
 
 Question:   I do not see how anything can be deeper than replacing careful description, prediction, falsification, and independent replication with dynamite plots, p-values, affirming the consequent, and peer review. From my own experience I am confident in saying that confusion caused by NHST is at the root of this problem.
 
 Fernando:   Incentives? Impact factors? Publish or die? “Interesting” and “new” above quality and reliability, or actually answering a research question, and a silly and unbecoming obsession with being quoted in NYT, etc. . . . Giv</p><p>6 0.17353815 <a title="1826-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-More_proposals_to_reform_the_peer-review_system.html">1272 andrew gelman stats-2012-04-20-More proposals to reform the peer-review system</a></p>
<p>7 0.17044693 <a title="1826-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>8 0.17016229 <a title="1826-tfidf-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>9 0.16991334 <a title="1826-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>10 0.16442236 <a title="1826-tfidf-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>11 0.16031869 <a title="1826-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>12 0.15401563 <a title="1826-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-26-Statistical_evidence_for_revised_standards.html">2149 andrew gelman stats-2013-12-26-Statistical evidence for revised standards</a></p>
<p>13 0.14880246 <a title="1826-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<p>14 0.14261925 <a title="1826-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>15 0.14130598 <a title="1826-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-01-Going_meta_on_Niall_Ferguson.html">1921 andrew gelman stats-2013-07-01-Going meta on Niall Ferguson</a></p>
<p>16 0.14020213 <a title="1826-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-12-Misunderstanding_the_p-value.html">1760 andrew gelman stats-2013-03-12-Misunderstanding the p-value</a></p>
<p>17 0.13885653 <a title="1826-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-30-Systematic_review_of_publication_bias_in_studies_on_publication_bias.html">1291 andrew gelman stats-2012-04-30-Systematic review of publication bias in studies on publication bias</a></p>
<p>18 0.13723898 <a title="1826-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>19 0.13173579 <a title="1826-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-12-Niall_Ferguson%2C_the_John_Yoo_line%2C_and_the_paradox_of_influence.html">1493 andrew gelman stats-2012-09-12-Niall Ferguson, the John Yoo line, and the paradox of influence</a></p>
<p>20 0.1303716 <a title="1826-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.191), (1, -0.013), (2, -0.011), (3, -0.195), (4, -0.102), (5, -0.088), (6, -0.0), (7, -0.02), (8, -0.013), (9, -0.036), (10, -0.067), (11, 0.01), (12, -0.041), (13, -0.053), (14, 0.014), (15, -0.062), (16, -0.074), (17, -0.12), (18, -0.05), (19, -0.076), (20, -0.025), (21, 0.081), (22, -0.025), (23, -0.027), (24, -0.073), (25, -0.009), (26, 0.065), (27, 0.058), (28, 0.009), (29, -0.019), (30, -0.023), (31, -0.013), (32, 0.057), (33, 0.023), (34, -0.057), (35, -0.031), (36, 0.023), (37, -0.059), (38, 0.023), (39, -0.028), (40, -0.07), (41, 0.005), (42, 0.003), (43, 0.008), (44, 0.034), (45, 0.065), (46, -0.011), (47, -0.007), (48, 0.052), (49, 0.014)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97002393 <a title="1826-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>Introduction: Erin Jonaitis points us to  this article  by Christopher Ferguson and Moritz Heene, who write:
  
Publication bias remains a controversial issue in psychological science. . . . that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. Given that science is dependent on the process of falsification, we argue that these problems reduce psychological science’s capability to have a proper mechanism for theory falsification, thus resulting in the promulgation of numerous “undead” theories that are ideologically popular but have little basis in fact.
  
They mention the infamous Daryl Bem article.  It is pretty much only because Bem’s claims are (presumably) false that they got published in a major research journal.  Had the claims been true—that is, had Bem run identical experiments, analyzed his data more carefully and objectively, and reported that the r</p><p>2 0.78015447 <a title="1826-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>Introduction: This article  is a discussion of a  paper  by Greg Francis for a special issue, edited by E. J. Wagenmakers, of the Journal of Mathematical Psychology.  Here’s what I wrote:
  
Much of statistical practice is an effort to reduce or deny variation and uncertainty. The reduction is done through standardization, replication, and other practices of experimental design, with the idea being to isolate and stabilize the quantity being estimated and then average over many cases. Even so, however, uncertainty persists, and statistical hypothesis testing is in many ways an endeavor to deny this, by reporting binary accept/reject decisions.


Classical statistical methods produce binary statements, but there is no reason to assume that the world works that way. Expressions such as Type 1 error, Type 2 error, false positive, and so on, are based on a model in which the world is divided into real and non-real effects. To put it another way, I understand the general scientific distinction of real vs</p><p>3 0.74566978 <a title="1826-lsi-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>Introduction: The anonymous commenter  puts it well :
  
The problem is simple, the researchers are disproving always false null hypotheses and taking this disproof as near proof that their theory is correct.</p><p>4 0.73536146 <a title="1826-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>Introduction: Masanao sends  this one  in, under the heading, “another incident of misunderstood p-value”:
  
Warren Davies, a positive psychology MSc student at UEL, provides the latest in our ongoing series of guest features for students. Warren has just released a Psychology Study Guide, which covers information on statistics, research methods and study skills for psychology students.

 
Despite the myriad rules and procedures of science, some research findings are pure flukes. Perhaps you’re testing a new drug, and by chance alone, a large number of people spontaneously get better. The better your study is conducted, the lower the chance that your result was a fluke – but still, there is always a certain probability that it was.


Statistical significance testing gives you an idea of what this probability is.


In science we’re always testing hypotheses. We never conduct a study to ‘see what happens’, because there’s always at least one way to make any useless set of data look important. We take</p><p>5 0.73027128 <a title="1826-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-13-How_should_journals_handle_replication_studies%3F.html">762 andrew gelman stats-2011-06-13-How should journals handle replication studies?</a></p>
<p>Introduction: Sanjay Srivastava  reports :
  
Recently  Ben Goldacre wrote  about a group of researchers (Stuart Ritchie, Chris French, and Richard Wiseman) whose null replication of 3 experiments from the infamous Bem ESP paper was rejected by JPSP – the same journal that published Bem’s paper.
  
Srivastava recognizes that JPSP does not usually publish replications but this is a different story because it’s an anti-replication.
 
Here’s the paradox:
 
- From a scientific point of view, the Ritchie et al. results are boring.  To find out that there’s no evidence for ESP . . . that adds essentially zero to our scientific understanding.  What next, a paper demonstrating that pigeons can fly higher than chickens?  Maybe an article in the Journal of the Materials Research Society demonstrating that diamonds can scratch marble but not the reverse??
 
- But from a science-communication perspective, the null replication is a big deal because it adds credence to  my hypothesis  that the earlier ESP claims</p><p>6 0.7101683 <a title="1826-lsi-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>7 0.70747113 <a title="1826-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-26-Statistical_evidence_for_revised_standards.html">2149 andrew gelman stats-2013-12-26-Statistical evidence for revised standards</a></p>
<p>8 0.69925201 <a title="1826-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>9 0.69785076 <a title="1826-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>10 0.69469059 <a title="1826-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-12-Misunderstanding_the_p-value.html">1760 andrew gelman stats-2013-03-12-Misunderstanding the p-value</a></p>
<p>11 0.68042088 <a title="1826-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-16-%E2%80%9CFalse-positive_psychology%E2%80%9D.html">1171 andrew gelman stats-2012-02-16-“False-positive psychology”</a></p>
<p>12 0.67169058 <a title="1826-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-08-Discussion_with_Steven_Pinker_on_research_that_is_attached_to_data_that_are_so_noisy_as_to_be_essentially_uninformative.html">2326 andrew gelman stats-2014-05-08-Discussion with Steven Pinker on research that is attached to data that are so noisy as to be essentially uninformative</a></p>
<p>13 0.66772521 <a title="1826-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>14 0.66314667 <a title="1826-lsi-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>15 0.65546626 <a title="1826-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-31-Response_by_Jessica_Tracy_and_Alec_Beall_to_my_critique_of_the_methods_in_their_paper%2C_%E2%80%9CWomen_Are_More_Likely_to_Wear_Red_or_Pink_at_Peak_Fertility%E2%80%9D.html">1963 andrew gelman stats-2013-07-31-Response by Jessica Tracy and Alec Beall to my critique of the methods in their paper, “Women Are More Likely to Wear Red or Pink at Peak Fertility”</a></p>
<p>16 0.65480739 <a title="1826-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>17 0.6526643 <a title="1826-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-11-%E2%80%9CMore_research_from_the_lunatic_fringe%E2%80%9D.html">2289 andrew gelman stats-2014-04-11-“More research from the lunatic fringe”</a></p>
<p>18 0.65236372 <a title="1826-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-28-50_shades_of_gray%3A__A_research_story.html">1959 andrew gelman stats-2013-07-28-50 shades of gray:  A research story</a></p>
<p>19 0.64903677 <a title="1826-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-More_proposals_to_reform_the_peer-review_system.html">1272 andrew gelman stats-2012-04-20-More proposals to reform the peer-review system</a></p>
<p>20 0.64224476 <a title="1826-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-25-Revised_statistical_standards_for_evidence_%28comments_to_Val_Johnson%E2%80%99s_comments_on_our_comments_on_Val%E2%80%99s_comments_on_p-values%29.html">2305 andrew gelman stats-2014-04-25-Revised statistical standards for evidence (comments to Val Johnson’s comments on our comments on Val’s comments on p-values)</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.026), (15, 0.056), (16, 0.079), (21, 0.257), (24, 0.122), (41, 0.025), (42, 0.016), (63, 0.012), (86, 0.021), (99, 0.209)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96242082 <a title="1826-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-The_R_code_for_those_time-use_graphs.html">672 andrew gelman stats-2011-04-20-The R code for those time-use graphs</a></p>
<p>Introduction: By popular demand, hereâ&euro;&trade;s my R script for the  time-use graphs :
  

 
 
# The data
a1 <- c(4.2,3.2,11.1,1.3,2.2,2.0)
a2 <- c(3.9,3.2,10.0,0.8,3.1,3.1)
a3 <- c(6.3,2.5,9.8,0.9,2.2,2.4)
a4 <- c(4.4,3.1,9.8,0.8,3.3,2.7)
a5 <- c(4.8,3.0,9.9,0.7,3.3,2.4)
a6 <- c(4.0,3.4,10.5,0.7,3.3,2.1)
a <- rbind(a1,a2,a3,a4,a5,a6)
avg <- colMeans (a)
avg.array <- t (array (avg, rev(dim(a))))
diff <- a - avg.array
country.name <- c("France", "Germany", "Japan", "Britain", "USA", "Turkey")

# The line plots

par (mfrow=c(2,3), mar=c(4,4,2,.5), mgp=c(2,.7,0), tck=-.02, oma=c(3,0,4,0),
  bg="gray96", fg="gray30")
for (i in 1:6){
  plot (c(1,6), c(-1,1.7), xlab="", ylab="", xaxt="n", yaxt="n",
    bty="l", type="n")
  lines (1:6, diff[i,], col="blue")
  points (1:6, diff[i,], pch=19, col="black")
  if (i>3){
    axis (1, c(1,3,5), c ("Work,\nstudy", "Eat,\nsleep",
      "Leisure"), mgp=c(2,1.5,0), tck=0, cex.axis=1.2)
    axis (1, c(2,4,6), c ("Unpaid\nwork",
      "Personal\nCare", "Other"), mgp=c(2,1.5,0),</p><p>same-blog 2 0.94259238 <a title="1826-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>Introduction: Erin Jonaitis points us to  this article  by Christopher Ferguson and Moritz Heene, who write:
  
Publication bias remains a controversial issue in psychological science. . . . that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. Given that science is dependent on the process of falsification, we argue that these problems reduce psychological science’s capability to have a proper mechanism for theory falsification, thus resulting in the promulgation of numerous “undead” theories that are ideologically popular but have little basis in fact.
  
They mention the infamous Daryl Bem article.  It is pretty much only because Bem’s claims are (presumably) false that they got published in a major research journal.  Had the claims been true—that is, had Bem run identical experiments, analyzed his data more carefully and objectively, and reported that the r</p><p>3 0.93910694 <a title="1826-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-16-Wanted%3A__Probability_distributions_for_rank_orderings.html">151 andrew gelman stats-2010-07-16-Wanted:  Probability distributions for rank orderings</a></p>
<p>Introduction: Dietrich Stoyan writes:
  
 
I asked the IMS people for an expert in statistics of voting/elections and they wrote me your name. I am a statistician, but never worked in the field voting/elections. It was my son-in-law who asked me for statistical theories in that field.


He posed in particular the following problem:


The aim of the voting is to come to a ranking of c candidates. Every vote is a permutation of these c candidates. The problem is to have probability distributions in the set of all permutations of c elements.


Are there theories for such distributions?


I should be very grateful for a fast answer with hints to literature. (I confess that I do not know your books.) 
 

 
My reply:  Rather than trying to model the ranks directly, Iâ&euro;&trade;d recommend modeling a latent continuous outcome which then implies a distribution on ranks, if the ranks are of interest. There are lots of distributions of c-dimensional continuous outcomes.  In political science, the usual way to start is</p><p>4 0.92572409 <a title="1826-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-27-Banned_in_NYC_school_tests.html">1232 andrew gelman stats-2012-03-27-Banned in NYC school tests</a></p>
<p>Introduction: The list  includes “hunting” but not “fishing,” so that’s cool.  I wonder how they’d feel about a question involving different cuts of meat.  In any case, I’m happy to see that  “Bayes”  is not on the banned list.
 
P.S.  Russell  explains .</p><p>5 0.92167276 <a title="1826-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-22-Please_stop_me_before_I_barf_again.html">1275 andrew gelman stats-2012-04-22-Please stop me before I barf again</a></p>
<p>Introduction: Pointing  to some horrible graphs, Kaiser writes, “The Earth Institute needs a graphics adviser.”
 
   
 
I agree.  The graphs are corporate standard, neither pretty or innovative enough to qualify as infographics, not informational enough to be good statistical data displays.
 
Some examples include the above exploding pie chart, which, as Kaiser notes, is not merely ugly and ridiculously difficult to read (given that it is conveying only nine data points) but also invites suspicion of its numbers, and pages and pages of graphs that could be better compressed into a compact displays (see pages 25-65 of the report).  Yes, this is all better than tables of numbers, but I don’t see that much thought went into displaying patterns of information or telling a story.  It’s more graph-as-data-dump.
 
To be fair, the report does have some a clean scatterplot (on page 65).  But, overall, the graphs are not well-integrated with the messages in the text.
 
I feel a little bit bad about this, beca</p><p>6 0.91772735 <a title="1826-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-27-Neumann_update.html">432 andrew gelman stats-2010-11-27-Neumann update</a></p>
<p>7 0.91661751 <a title="1826-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-10-A_defense_of_Tom_Wolfe_based_on_the_impossibility_of_the_law_of_small_numbers_in_network_structure.html">1615 andrew gelman stats-2012-12-10-A defense of Tom Wolfe based on the impossibility of the law of small numbers in network structure</a></p>
<p>8 0.91370553 <a title="1826-lda-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-21-On_deck_this_week.html">2298 andrew gelman stats-2014-04-21-On deck this week</a></p>
<p>9 0.90420121 <a title="1826-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-01-Two_Postdoc_Positions_Available_on_Bayesian_Hierarchical_Modeling.html">62 andrew gelman stats-2010-06-01-Two Postdoc Positions Available on Bayesian Hierarchical Modeling</a></p>
<p>10 0.90325511 <a title="1826-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-07-Hipmunk_FAIL%3A__Graphics_without_content_is_not_enough.html">894 andrew gelman stats-2011-09-07-Hipmunk FAIL:  Graphics without content is not enough</a></p>
<p>11 0.90034962 <a title="1826-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-30-David_Hogg_on_statistics.html">1401 andrew gelman stats-2012-06-30-David Hogg on statistics</a></p>
<p>12 0.89441299 <a title="1826-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-15-Does_quantum_uncertainty_have_a_place_in_everyday_applied_statistics%3F.html">1857 andrew gelman stats-2013-05-15-Does quantum uncertainty have a place in everyday applied statistics?</a></p>
<p>13 0.89372492 <a title="1826-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-15-%E2%80%9C10_Things_You_Need_to_Know_About_Causal_Effects%E2%80%9D.html">1675 andrew gelman stats-2013-01-15-“10 Things You Need to Know About Causal Effects”</a></p>
<p>14 0.89159739 <a title="1826-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-26-Sleazy_sock_puppet_can%E2%80%99t_stop_spamming_our_discussion_of_compressed_sensing_and_promoting_the_work_of_Xiteng_Liu.html">2306 andrew gelman stats-2014-04-26-Sleazy sock puppet can’t stop spamming our discussion of compressed sensing and promoting the work of Xiteng Liu</a></p>
<p>15 0.88699567 <a title="1826-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-15-A_silly_paper_that_tries_to_make_fun_of_multilevel_models.html">854 andrew gelman stats-2011-08-15-A silly paper that tries to make fun of multilevel models</a></p>
<p>16 0.88547844 <a title="1826-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-13-News_coverage_of_statistical_issues%E2%80%A6how_did_I_do%3F.html">514 andrew gelman stats-2011-01-13-News coverage of statistical issues…how did I do?</a></p>
<p>17 0.88032961 <a title="1826-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-19-The_grasshopper_wins%2C_and_Greg_Mankiw%E2%80%99s_grandmother_would_be_%E2%80%9Cshocked_and_appalled%E2%80%9D_all_over_again.html">1728 andrew gelman stats-2013-02-19-The grasshopper wins, and Greg Mankiw’s grandmother would be “shocked and appalled” all over again</a></p>
<p>18 0.86870587 <a title="1826-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-13-Jim_Campbell_argues_that_Larry_Bartels%E2%80%99s_%E2%80%9CUnequal_Democracy%E2%80%9D_findings_are_not_robust.html">659 andrew gelman stats-2011-04-13-Jim Campbell argues that Larry Bartels’s “Unequal Democracy” findings are not robust</a></p>
<p>19 0.8581481 <a title="1826-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>20 0.85214186 <a title="1826-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Adding_more_information_can_make_the_variance_go_up_%28depending_on_your_model%29.html">810 andrew gelman stats-2011-07-20-Adding more information can make the variance go up (depending on your model)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
