<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1726 andrew gelman stats-2013-02-18-What to read to catch up on multivariate statistics?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1726" href="#">andrew_gelman_stats-2013-1726</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1726 andrew gelman stats-2013-02-18-What to read to catch up on multivariate statistics?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1726-html" href="http://andrewgelman.com/2013/02/18/what-to-read-to-catch-up-on-multivariate-statistics/">html</a></p><p>Introduction: Henry Harpending writes:
  
I am writing to ask you for a recommendation of something I can read to catch up on multivariate statistics.  I am happy with random processes and linear algebra since they are important in population genetics.  My last encounter with  real  statistics was several decades ago.


Recently I have had to dip my toes into real multivariate statistics again and I am completely lost.  I can’t, for example, figure out how a random effects model is different from what we used to call “partialing out” nuisance covariates.  I have a hard time concentrating on exactly what a “BLURP” model is because the name is so silly.


Can you recommend something accessible to me that would put me on track?
  
My reply:  if you’re interested particularly in random effects models, I will (parochially) refer you to  my own book  with Jennifer Hill.  You can jump straight to the chapters on multilevel modeling.
 
If the question is about traditional multivariate methods such as factor</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Henry Harpending writes:    I am writing to ask you for a recommendation of something I can read to catch up on multivariate statistics. [sent-1, score-0.82]
</p><p>2 I am happy with random processes and linear algebra since they are important in population genetics. [sent-2, score-0.7]
</p><p>3 My last encounter with  real  statistics was several decades ago. [sent-3, score-0.482]
</p><p>4 Recently I have had to dip my toes into real multivariate statistics again and I am completely lost. [sent-4, score-1.081]
</p><p>5 I can’t, for example, figure out how a random effects model is different from what we used to call “partialing out” nuisance covariates. [sent-5, score-0.725]
</p><p>6 I have a hard time concentrating on exactly what a “BLURP” model is because the name is so silly. [sent-6, score-0.229]
</p><p>7 Can you recommend something accessible to me that would put me on track? [sent-7, score-0.283]
</p><p>8 My reply:  if you’re interested particularly in random effects models, I will (parochially) refer you to  my own book  with Jennifer Hill. [sent-8, score-0.674]
</p><p>9 You can jump straight to the chapters on multilevel modeling. [sent-9, score-0.41]
</p><p>10 If the question is about traditional multivariate methods such as factor analysis, principal components, etc. [sent-10, score-1.116]
</p><p>11 Do readers have any suggestions for a good book, preferably model-based, on multivariate methods such as factor analysis, principal components, etc. [sent-13, score-1.406]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('multivariate', 0.457), ('principal', 0.267), ('components', 0.249), ('random', 0.22), ('toes', 0.193), ('harpending', 0.193), ('factor', 0.182), ('dip', 0.168), ('nuisance', 0.163), ('preferably', 0.159), ('book', 0.151), ('encounter', 0.14), ('henry', 0.14), ('algebra', 0.135), ('accessible', 0.124), ('effects', 0.12), ('jump', 0.113), ('methods', 0.112), ('chapters', 0.111), ('refer', 0.11), ('real', 0.11), ('catch', 0.109), ('processes', 0.108), ('recommendation', 0.106), ('straight', 0.106), ('track', 0.105), ('jennifer', 0.103), ('traditional', 0.098), ('suggestions', 0.096), ('decades', 0.091), ('linear', 0.086), ('recommend', 0.084), ('analysis', 0.083), ('statistics', 0.081), ('multilevel', 0.08), ('happy', 0.078), ('name', 0.078), ('model', 0.076), ('something', 0.075), ('exactly', 0.075), ('figure', 0.074), ('particularly', 0.073), ('ask', 0.073), ('population', 0.073), ('call', 0.072), ('completely', 0.072), ('readers', 0.069), ('good', 0.064), ('recently', 0.061), ('several', 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1726-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-18-What_to_read_to_catch_up_on_multivariate_statistics%3F.html">1726 andrew gelman stats-2013-02-18-What to read to catch up on multivariate statistics?</a></p>
<p>Introduction: Henry Harpending writes:
  
I am writing to ask you for a recommendation of something I can read to catch up on multivariate statistics.  I am happy with random processes and linear algebra since they are important in population genetics.  My last encounter with  real  statistics was several decades ago.


Recently I have had to dip my toes into real multivariate statistics again and I am completely lost.  I can’t, for example, figure out how a random effects model is different from what we used to call “partialing out” nuisance covariates.  I have a hard time concentrating on exactly what a “BLURP” model is because the name is so silly.


Can you recommend something accessible to me that would put me on track?
  
My reply:  if you’re interested particularly in random effects models, I will (parochially) refer you to  my own book  with Jennifer Hill.  You can jump straight to the chapters on multilevel modeling.
 
If the question is about traditional multivariate methods such as factor</p><p>2 0.13682768 <a title="1726-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-01-Heller%2C_Heller%2C_and_Gorfine_on_univariate_and_multivariate_information_measures.html">2314 andrew gelman stats-2014-05-01-Heller, Heller, and Gorfine on univariate and multivariate information measures</a></p>
<p>Introduction: Malka Gorfine writes:
  
We noticed that the important topic of association measures and tests  came up again  in your blog, and we have few comments in this regard.


It is useful to distinguish between the univariate and multivariate methods. A consistent multivariate method can recognise dependence between two vectors of random variables, while a univariate method can only loop over pairs of components and check for dependency between them.


There are very few consistent multivariate methods. To the best of our  knowledge there are three practical methods:


1) HSIC by Gretton et al. (http://www.gatsby.ucl.ac.uk/~gretton/papers/GreBouSmoSch05.pdf)


2) dcov by Szekely et al. (http://projecteuclid.org/euclid.aoas/1267453933)


3) A method we introduced in Heller et al (Biometrika, 2013, 503—510, http://biomet.oxfordjournals.org/content/early/2012/12/04/biomet.ass070.full.pdf+html, and an R package, HHG, is available as well http://cran.r-project.org/web/packages/HHG/index.html).


A</p><p>3 0.12891304 <a title="1726-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-12-year_%2B_%281%7Cyear%29.html">851 andrew gelman stats-2011-08-12-year + (1|year)</a></p>
<p>Introduction: Ana Sequeira writes:
  
I am using a temporal data series and I am trying specifically to understand if there is a temporal trends in the occurrence of a species, for which I need to use “Year” in my models (and from what I understood from pages 244-246 [in ARM] is that factors should always be used as random effects).
      
I believe that in your book the closest example to my situation is the one shown in Figure 14.3: I also have 4 different regions in my study, states in your example are replaced by years in my study, and the x axis is a specific value for a climatic factor I am using in my analysis (IOD).


The reason why I am writing you, is because I am having troubles understanding if my variable “Year” (factor), should only be added as a random effect (1|Year) or if I should include the “Years” (used not as factor) in my models as well (Species ~ …Years + (1|Year))?


My doubt lies in the fact that I am looking for a trend and if I do not include “Years” as variable I believe</p><p>4 0.12653369 <a title="1726-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<p>Introduction: Dean Eckles writes:
  
I make extensive use of random effects models in my academic and industry research, as they are very often appropriate.


However, with very large data sets, I am not sure what to do. Say I have thousands of levels of a grouping factor, and the number of observations totals in the billions. Despite having lots of observations, I am often either dealing with (a) small effects or (b) trying to fit models with many predictors.


So I would really like to use a random effects model to borrow strength across the levels of the grouping factor, but I am not sure how to practically do this. Are you aware of any approaches to fitting random effects models (including approximations) that work for very large data sets? For example, applying a procedure to each group, and then using the results of this to shrink each fit in some appropriate way.


Just to clarify, here I am only worried about the non-crossed and in fact single-level case. I don’t see any easy route for cross</p><p>5 0.12302168 <a title="1726-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-21-Readings_for_a_two-week_segment_on_Bayesian_modeling%3F.html">1586 andrew gelman stats-2012-11-21-Readings for a two-week segment on Bayesian modeling?</a></p>
<p>Introduction: Michael Landy writes:
  
I’m in Psych and Center for Neural Science and I’m teaching a doctoral course this term in methods in psychophysics (never mind the details) at the tail end of which I’m planning on at least 2 lectures on Bayesian parameter estimation and Bayesian model comparison. So far, all the readings I have are a bit too obscure and either glancing (bits of machine-learning books: Bishop, MacKay) or too low-level. The only useful reference I’ve got is an application of these methods (a methods article of mine in a Neuroscience Methods journal). The idea is to give them a decent idea of both estimation (Jeffries priors, marginals of the posterior over the parameters) and model comparison (cross-validation, AIC, BIC, full-blown Bayesian model posterior comparisons, Bayes factor, Occam factor, blah blah blah).


So: have you any suggestions for articles or chapters that might be suitable (yes, I’m aware you have an entire book that’s obviously relevant)?  In the class topic</p><p>6 0.12292041 <a title="1726-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-04-Handy_Matrix_Cheat_Sheet%2C_with_Gradients.html">555 andrew gelman stats-2011-02-04-Handy Matrix Cheat Sheet, with Gradients</a></p>
<p>7 0.11364704 <a title="1726-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>8 0.11311127 <a title="1726-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-30-Fixed_effects%2C_followed_by_Bayes_shrinkage%3F.html">1644 andrew gelman stats-2012-12-30-Fixed effects, followed by Bayes shrinkage?</a></p>
<p>9 0.11037416 <a title="1726-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Visualizing_Distributions_of_Covariance_Matrices.html">1477 andrew gelman stats-2012-08-30-Visualizing Distributions of Covariance Matrices</a></p>
<p>10 0.1100655 <a title="1726-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Bayesian_inference_viewed_as_a_computational_approximation_to_classical_calculations.html">254 andrew gelman stats-2010-09-04-Bayesian inference viewed as a computational approximation to classical calculations</a></p>
<p>11 0.10550511 <a title="1726-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-06-The_new_Stan_1.1.1%2C_featuring_Gaussian_processes%21.html">1710 andrew gelman stats-2013-02-06-The new Stan 1.1.1, featuring Gaussian processes!</a></p>
<p>12 0.10536273 <a title="1726-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>13 0.10444532 <a title="1726-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-17-Statistics_in_a_world_where_nothing_is_random.html">1628 andrew gelman stats-2012-12-17-Statistics in a world where nothing is random</a></p>
<p>14 0.10438995 <a title="1726-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-24-Estimating_and_summarizing_inference_for_hierarchical_variance_parameters_when_the_number_of_groups_is_small.html">2145 andrew gelman stats-2013-12-24-Estimating and summarizing inference for hierarchical variance parameters when the number of groups is small</a></p>
<p>15 0.10297491 <a title="1726-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>16 0.099485114 <a title="1726-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>17 0.099468373 <a title="1726-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-04-All_the_Assumptions_That_Are_My_Life.html">2359 andrew gelman stats-2014-06-04-All the Assumptions That Are My Life</a></p>
<p>18 0.097260267 <a title="1726-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-17-So-called_fixed_and_random_effects.html">472 andrew gelman stats-2010-12-17-So-called fixed and random effects</a></p>
<p>19 0.096171767 <a title="1726-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>20 0.095835209 <a title="1726-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-02-The_problem_of_overestimation_of_group-level_variance_parameters.html">63 andrew gelman stats-2010-06-02-The problem of overestimation of group-level variance parameters</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.166), (1, 0.071), (2, -0.007), (3, 0.011), (4, 0.059), (5, 0.071), (6, 0.001), (7, -0.011), (8, 0.086), (9, 0.057), (10, 0.046), (11, -0.016), (12, 0.048), (13, -0.021), (14, 0.113), (15, 0.012), (16, -0.075), (17, 0.05), (18, 0.024), (19, -0.016), (20, 0.021), (21, -0.004), (22, 0.048), (23, 0.062), (24, 0.009), (25, -0.038), (26, -0.058), (27, 0.08), (28, 0.047), (29, 0.033), (30, -0.06), (31, 0.015), (32, -0.001), (33, 0.024), (34, 0.005), (35, -0.008), (36, -0.007), (37, 0.024), (38, -0.04), (39, 0.001), (40, -0.002), (41, -0.019), (42, 0.03), (43, 0.026), (44, -0.023), (45, -0.027), (46, -0.031), (47, -0.01), (48, 0.025), (49, -0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96309638 <a title="1726-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-18-What_to_read_to_catch_up_on_multivariate_statistics%3F.html">1726 andrew gelman stats-2013-02-18-What to read to catch up on multivariate statistics?</a></p>
<p>Introduction: Henry Harpending writes:
  
I am writing to ask you for a recommendation of something I can read to catch up on multivariate statistics.  I am happy with random processes and linear algebra since they are important in population genetics.  My last encounter with  real  statistics was several decades ago.


Recently I have had to dip my toes into real multivariate statistics again and I am completely lost.  I can’t, for example, figure out how a random effects model is different from what we used to call “partialing out” nuisance covariates.  I have a hard time concentrating on exactly what a “BLURP” model is because the name is so silly.


Can you recommend something accessible to me that would put me on track?
  
My reply:  if you’re interested particularly in random effects models, I will (parochially) refer you to  my own book  with Jennifer Hill.  You can jump straight to the chapters on multilevel modeling.
 
If the question is about traditional multivariate methods such as factor</p><p>2 0.7417618 <a title="1726-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-28-Reference_on_longitudinal_models%3F.html">1188 andrew gelman stats-2012-02-28-Reference on longitudinal models?</a></p>
<p>Introduction: Antonio Ramos writes:
  
The book with Hill has very little on longitudinal models. So do you recommended any reference to complement your book on covariance structures typical from these models, such as AR(1), Antedependence, Factor Analytic, etc? I am very much interest in BUGS code for these basic models as well as how to extend them to more complex situations.
  
My reply:
 
There is a book by Banerjee, Carlin, and Gelfand on Bayesian space-time models.  Beyond that, I think there is good work in psychometrics on covaraince structures but I donâ&euro;&trade;t know the literature.</p><p>3 0.73653078 <a title="1726-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-10-R_vs._Stata%2C_or%2C_Different_ways_to_estimate_multilevel_models.html">269 andrew gelman stats-2010-09-10-R vs. Stata, or, Different ways to estimate multilevel models</a></p>
<p>Introduction: Cyrus writes:
  
I [Cyrus] was teaching a class on multilevel modeling, and we were playing around with different method to fit a random effects logit model with 2 random intercepts—one corresponding to “family” and another corresponding to “community” (labeled “mom” and “cluster” in the data, respectively).  There are also a few regressors at the individual, family, and community level.  We were replicating in part some of the results from the  following paper :  Improved estimation procedures for multilevel models with binary response: a case-study, by G Rodriguez, N Goldman.


(I say “replicating in part” because we didn’t include all the regressors that they use, only a subset.)  We were looking at the performance of estimation via glmer in R’s lme4 package, glmmPQL in R’s MASS package, and Stata’s xtmelogit.  We wanted to study the performance of various estimation methods, including adaptive quadrature methods and penalized quasi-likelihood.


I was shocked to discover that glmer</p><p>4 0.72272485 <a title="1726-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multilevel_modeling_even_when_you%E2%80%99re_not_interested_in_predictions_for_new_groups.html">1194 andrew gelman stats-2012-03-04-Multilevel modeling even when you’re not interested in predictions for new groups</a></p>
<p>Introduction: Fred Wu writes: 
  
  
I work at National Prescribing Services in Australia.  I have a database representing say, antidiabetic drug utilisation for the entire Australia in the past few years. I planned to do a longitudinal analysis across GP Division Network (112 divisions in AUS) using mixed-effects models (or as you called in your book varying intercept and varying slope) on this data. 


The problem here is: as data actually represent the population who use antidiabetic drugs in AUS, should I use 112 fixed dummy variables to capture the random variations or use varying intercept and varying slope for the model ? Because some one may aruge, like divisions in AUS or states in USA can hardly be considered from a “superpopulation”, then fixed dummies should be used.  What I think is the population are those who use the drugs, what will happen when the rest need to use them? In terms of exchangeability, using varying intercept and varying slopes can be justified.


Also you provided in y</p><p>5 0.7060982 <a title="1726-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-How_many_parameters_are_in_a_multilevel_model%3F.html">1144 andrew gelman stats-2012-01-29-How many parameters are in a multilevel model?</a></p>
<p>Introduction: Stephen Collins writes:
  
I’m reading your Multilevel modeling book and am trying to apply it to my work.  I’m concerned with how to estimate a random intercept model if there are hundreds/thousands of levels.  In the Gibbs sampling, am I sampling a parameter for each level?  Or, just the hyper-parameters?  In other words, say I had 500 zipcode intercepts modeled as ~ N(m,s).  Would my posterior be two dimensional, sampling for “m” and “s,” or would it have 502 dimensions?
  
My reply:  Indeed you will have hundreds or thousands of parameters—or, in classical terms, hundreds or thousands of predictive quantities.  But that’s ok.  Even if none of those predictions is precise, you’re learning  about the model.
 
See page 526 of the book for more discussion of the number of parameters in a multilevel model.</p><p>6 0.6982432 <a title="1726-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-17-How_to_make_a_good_fig%3F.html">1382 andrew gelman stats-2012-06-17-How to make a good fig?</a></p>
<p>7 0.69806099 <a title="1726-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-04-A_new_R_package_for_fititng_multilevel_models.html">501 andrew gelman stats-2011-01-04-A new R package for fititng multilevel models</a></p>
<p>8 0.69760358 <a title="1726-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-06-17_groups%2C_6_group-level_predictors%3A__What_to_do%3F.html">1248 andrew gelman stats-2012-04-06-17 groups, 6 group-level predictors:  What to do?</a></p>
<p>9 0.69679457 <a title="1726-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-19-Index_or_indicator_variables.html">2296 andrew gelman stats-2014-04-19-Index or indicator variables</a></p>
<p>10 0.67866254 <a title="1726-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-12-year_%2B_%281%7Cyear%29.html">851 andrew gelman stats-2011-08-12-year + (1|year)</a></p>
<p>11 0.66219991 <a title="1726-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-28-New_book_by_Stef_van_Buuren_on_missing-data_imputation_looks_really_good%21.html">1642 andrew gelman stats-2012-12-28-New book by Stef van Buuren on missing-data imputation looks really good!</a></p>
<p>12 0.65518284 <a title="1726-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-25-Good_introductory_book_for_statistical_computation%3F.html">590 andrew gelman stats-2011-02-25-Good introductory book for statistical computation?</a></p>
<p>13 0.65516907 <a title="1726-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-R_package_for_Bayes_factors.html">1682 andrew gelman stats-2013-01-19-R package for Bayes factors</a></p>
<p>14 0.64921117 <a title="1726-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-29-The_gradual_transition_to_replicable_science.html">2117 andrew gelman stats-2013-11-29-The gradual transition to replicable science</a></p>
<p>15 0.648229 <a title="1726-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>16 0.64189714 <a title="1726-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-12-Finite-population_standard_deviation_in_a_hierarchical_model.html">464 andrew gelman stats-2010-12-12-Finite-population standard deviation in a hierarchical model</a></p>
<p>17 0.64159411 <a title="1726-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>18 0.64106238 <a title="1726-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-09-Both_R_and_Stata.html">76 andrew gelman stats-2010-06-09-Both R and Stata</a></p>
<p>19 0.63952994 <a title="1726-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-06-Bayesian_Anova_found_useful_in_ecology.html">1102 andrew gelman stats-2012-01-06-Bayesian Anova found useful in ecology</a></p>
<p>20 0.63417578 <a title="1726-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-17-Hierarchical-multilevel_modeling_with_%E2%80%9Cbig_data%E2%80%9D.html">1267 andrew gelman stats-2012-04-17-Hierarchical-multilevel modeling with “big data”</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.027), (16, 0.077), (21, 0.015), (24, 0.099), (42, 0.244), (55, 0.025), (72, 0.019), (77, 0.021), (99, 0.358)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97039866 <a title="1726-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-23-In_which_I_disagree_with_John_Maynard_Keynes.html">1775 andrew gelman stats-2013-03-23-In which I disagree with John Maynard Keynes</a></p>
<p>Introduction: In his  review  in 1938 of  Historical Development of the Graphical Representation of Statistical Data , by H. Gray Funkhauser, for  The Economic Journal , the great economist writes:
  
Perhaps the most striking outcome of Mr. Funkhouser’s researches is the fact of the very slow progress which graphical methods made until quite recently. . . . In the first fifty volumes of the Statistical Journal, 1837-87, only fourteen graphs are printed altogether. It is surprising to be told that Laplace never drew a graph of the normal law of error . . . Edgeworth made no use of statistical charts as distinct from mathematical diagrams.


Apart from Quetelet and Jevons, the most important influences were probably those of Galton and of Mulhall’s Dictionary, first published in 1884. Galton was indeed following his father and grandfather in this field, but his pioneer work was mainly restricted to meteorological maps, and he did not contribute to the development of the graphical representation of ec</p><p>2 0.95570564 <a title="1726-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-18-The_estimated_effect_size_is_implausibly_large.__Under_what_models_is_this_a_piece_of_evidence_that_the_true_effect_is_small%3F.html">808 andrew gelman stats-2011-07-18-The estimated effect size is implausibly large.  Under what models is this a piece of evidence that the true effect is small?</a></p>
<p>Introduction: Paul Pudaite writes in response to  my discussion with Bartels  regarding effect sizes and measurement error models:
  
You [Gelman] wrote: “I actually think there will be some (non-Gaussian) models for which, as y gets larger, E(x|y) can actually go back toward zero.”


I [Pudaite] encountered this phenomenon some time in the ’90s. See this graph which shows the conditional expectation of X given Z, when Z = X + Y and the probability density functions of X and Y are, respectively, exp(-x^2) and 1/(y^2+1) (times appropriate constants). As the magnitude of Z increases, E[X|Z] shrinks to zero.


 


I wasn’t sure it was worth the effort to try to publish a two paragraph paper.


I suspect that this is true whenever the tail of one distribution is ‘sufficiently heavy’ with respect to the tail of the other. Hmm, I suppose there might be enough substance in a paper that attempted to characterize this outcome for, say, unimodal symmetric distributions.
  
Maybe someone can do this? I think i</p><p>3 0.95174885 <a title="1726-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-25-Good_introductory_book_for_statistical_computation%3F.html">590 andrew gelman stats-2011-02-25-Good introductory book for statistical computation?</a></p>
<p>Introduction: Geen Tomko asks:
  
Can you recommend a good introductory book for statistical computation? Mostly, something that would help make it easier in collecting and analyzing data from student test scores.
  
I don’t know.  Usually, when people ask for a starter statistics book, my recommendation (beyond my own books) is The Statistical Sleuth.  But that’s not really a computation book.  ARM isn’t really a statistical computation book either.  But the statistical computation books that I’ve seen don’t seems so relevant for the analyses that Tomko is looking for.  For example, the R book of Venables and Ripley focuses on nonparametric statistics, which is fine but seems a bit esoteric for these purposes.
 
Does anyone have any suggestions?</p><p>4 0.95154691 <a title="1726-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-15-1-2_social_scientist_%2B_1-2_politician_%3D_%3F%3F%3F.html">713 andrew gelman stats-2011-05-15-1-2 social scientist + 1-2 politician = ???</a></p>
<p>Introduction: A couple things in  this interview  by Andrew Goldman of Larry Summers currently irritated me.
 
I’ll give the quotes and then explain my annoyance.
  
 
1.  Goldman: What would the economy look like now if $1.2 trillion had been spent?


Summers:  I think it’s an artificial question because there would have been all kinds of problems in actually moving $1.2 trillion dollars through the system — finding enough bridge projects that were ready to go and the like. But the recovery probably would have proceeded more rapidly if the fiscal program had been larger. . . .


2.  Goldman:  You’re aware of — and were making light of — the fact that you occasionally rub people the wrong way.


Summers:   In meetings, I’m more focused on trying to figure out what the right answer is than making everybody feel validated. In Washington and at Harvard, that sometimes rubs people the wrong way.
 

 
OK, now my reactions:
 
1.  Not enough bridge projects, huh?  I don’t believe it.  We’ve been hearing fo</p><p>5 0.9498378 <a title="1726-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-23-Science%2C_ideology%2C_and_human_origins.html">483 andrew gelman stats-2010-12-23-Science, ideology, and human origins</a></p>
<p>Introduction: A  link  from Tyler Cowen led me to this  long blog article  by Razib Khan, discussing some recent genetic findings on human origins in the context of the past twenty-five years of research and popularization of science.
  

 
I don’t know much about human origins (beyond my ooh-that’s-cool reactions to exhibits at the Natural History Museum, my general statistician’s skepticism at various over-the-top claims I’ve heard over the years about “mitochondrial Eve” and the like, and various bits I’ve read over the years regarding when people came over to Australia, America, etc.), but what particularly interested me about Khan’s article was his discussion about the various controversies among scientists, his own reactions when reading and thinking about these issues as they were happening (Khan was a student at the time), and the interaction between science and political ideology.
 
There’s a limit to how far you can go with this sort of cultural criticism of science, and Khan realizes this</p><p>6 0.94936663 <a title="1726-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-30-What_Auteur_Theory_and_Freshwater_Economics_have_in_common.html">60 andrew gelman stats-2010-05-30-What Auteur Theory and Freshwater Economics have in common</a></p>
<p>7 0.94851613 <a title="1726-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-29-%E2%80%9CTexting_bans_don%E2%80%99t_reduce_crashes%3B_effects_are_slight_crash_increases%E2%80%9D.html">307 andrew gelman stats-2010-09-29-“Texting bans don’t reduce crashes; effects are slight crash increases”</a></p>
<p>8 0.94676459 <a title="1726-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-15-Freakonomics%3A__What_went_wrong%3F.html">1060 andrew gelman stats-2011-12-15-Freakonomics:  What went wrong?</a></p>
<p>9 0.9463467 <a title="1726-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-07-Scatterplot_charades%21.html">1791 andrew gelman stats-2013-04-07-Scatterplot charades!</a></p>
<p>10 0.93797684 <a title="1726-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-25-Chris_Schmid_on_Evidence_Based_Medicine.html">1138 andrew gelman stats-2012-01-25-Chris Schmid on Evidence Based Medicine</a></p>
<p>11 0.93146539 <a title="1726-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-30-That_puzzle-solving_feeling.html">492 andrew gelman stats-2010-12-30-That puzzle-solving feeling</a></p>
<p>same-blog 12 0.93034691 <a title="1726-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-18-What_to_read_to_catch_up_on_multivariate_statistics%3F.html">1726 andrew gelman stats-2013-02-18-What to read to catch up on multivariate statistics?</a></p>
<p>13 0.92742008 <a title="1726-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>14 0.91769058 <a title="1726-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>15 0.91626066 <a title="1726-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Tough_love_as_a_style_of_writing.html">111 andrew gelman stats-2010-06-26-Tough love as a style of writing</a></p>
<p>16 0.9153567 <a title="1726-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-04-Flip_it_around.html">943 andrew gelman stats-2011-10-04-Flip it around</a></p>
<p>17 0.91452318 <a title="1726-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-13-Economic_policy_does_not_occur_in_a_political_vacuum.html">1936 andrew gelman stats-2013-07-13-Economic policy does not occur in a political vacuum</a></p>
<p>18 0.91275692 <a title="1726-lda-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-09-Hermann_Goering_and_Jane_Jacobs%2C_together_at_last%21.html">2164 andrew gelman stats-2014-01-09-Hermann Goering and Jane Jacobs, together at last!</a></p>
<p>19 0.91270304 <a title="1726-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Freakonomics_Experiments.html">1692 andrew gelman stats-2013-01-25-Freakonomics Experiments</a></p>
<p>20 0.91107827 <a title="1726-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-06-Against_optimism_about_social_science.html">1844 andrew gelman stats-2013-05-06-Against optimism about social science</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
