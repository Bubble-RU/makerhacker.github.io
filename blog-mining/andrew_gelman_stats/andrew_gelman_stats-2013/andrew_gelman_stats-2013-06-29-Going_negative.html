<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1918 andrew gelman stats-2013-06-29-Going negative</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1918" href="#">andrew_gelman_stats-2013-1918</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1918 andrew gelman stats-2013-06-29-Going negative</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1918-html" href="http://andrewgelman.com/2013/06/29/going-negative/">html</a></p><p>Introduction: Troels Ring writes: 
  
  
I have measured total phosphorus, TP, on a number of dialysis patients, and also measured conventional phosphate, Pi. Now P is exchanged with the environment as Pi, so in principle a correlation between TP and Pi could perhaps be expected. I’m really most interested in the fraction of TP which is not Pi, that is TP-Pi. I would also expect that to be positively correlated with Pi. However, looking at the data using a mixed model an insignificant negative correlation is obtained. Then I thought, that since TP-Pi is bound to be small if Pi is large a negative correlation is almost dictated by the math even if the biology would have it otherwise in so far as the the TP-Pi, likely organic P, must someday have been Pi. Hence I thought about correcting the slight negative correlation between TP-Pi and Pi for the expected large negative correlation due to the math – to eventually recover what I came from: a positive correlation. People seems to agree that this thinki</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Troels Ring writes:        I have measured total phosphorus, TP, on a number of dialysis patients, and also measured conventional phosphate, Pi. [sent-1, score-0.384]
</p><p>2 Now P is exchanged with the environment as Pi, so in principle a correlation between TP and Pi could perhaps be expected. [sent-2, score-0.472]
</p><p>3 I’m really most interested in the fraction of TP which is not Pi, that is TP-Pi. [sent-3, score-0.064]
</p><p>4 I would also expect that to be positively correlated with Pi. [sent-4, score-0.125]
</p><p>5 However, looking at the data using a mixed model an insignificant negative correlation is obtained. [sent-5, score-0.628]
</p><p>6 Then I thought, that since TP-Pi is bound to be small if Pi is large a negative correlation is almost dictated by the math even if the biology would have it otherwise in so far as the the TP-Pi, likely organic P, must someday have been Pi. [sent-6, score-0.995]
</p><p>7 Hence I thought about correcting the slight negative correlation between TP-Pi and Pi for the expected large negative correlation due to the math – to eventually recover what I came from: a positive correlation. [sent-7, score-1.514]
</p><p>8 People seems to agree that this thinking is nonsense. [sent-8, score-0.059]
</p><p>9 They say I can just keep to the analysis and forget about RTM. [sent-9, score-0.055]
</p><p>10 I cannot help thinking that if I could measure TP-Pi by a method not requiring me to subtract Pi, I would get at least a cleaner result. [sent-10, score-0.281]
</p><p>11 My reply:  I’m getting confused on the details here, but, yes, it is typical that if you have two variables A and B measured on a common scale, that A-B has a negative correlation with B. [sent-11, score-0.768]
</p><p>12 This comes up, for example, in adjusting for pretest scores in education. [sent-12, score-0.388]
</p><p>13 People often have the intuition that they should be analyzing posttest – pretest, but it typically makes more sense to look at posttest – 0. [sent-13, score-0.482]
</p><p>14 Ultimately I suppose the solution is to go beyond correlations and to have a generative model for the joint distribution of TP and Pi. [sent-16, score-0.184]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pi', 0.555), ('tp', 0.433), ('correlation', 0.28), ('pretest', 0.267), ('negative', 0.214), ('posttest', 0.186), ('measured', 0.166), ('phosphate', 0.099), ('math', 0.097), ('exchanged', 0.093), ('organic', 0.089), ('dictated', 0.086), ('ring', 0.083), ('subtract', 0.079), ('electric', 0.079), ('insignificant', 0.078), ('slight', 0.076), ('cleaner', 0.076), ('generative', 0.075), ('positively', 0.074), ('recover', 0.074), ('correcting', 0.071), ('adjusting', 0.068), ('bound', 0.067), ('requiring', 0.067), ('patients', 0.065), ('fraction', 0.064), ('thinking', 0.059), ('large', 0.059), ('intuition', 0.057), ('biology', 0.057), ('mixed', 0.056), ('joint', 0.056), ('confused', 0.055), ('forget', 0.055), ('eventually', 0.054), ('analyzing', 0.053), ('scores', 0.053), ('typical', 0.053), ('correlations', 0.053), ('jennifer', 0.052), ('environment', 0.052), ('conventional', 0.052), ('correlated', 0.051), ('company', 0.049), ('thought', 0.049), ('hence', 0.048), ('principle', 0.047), ('otherwise', 0.046), ('due', 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1918-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-29-Going_negative.html">1918 andrew gelman stats-2013-06-29-Going negative</a></p>
<p>Introduction: Troels Ring writes: 
  
  
I have measured total phosphorus, TP, on a number of dialysis patients, and also measured conventional phosphate, Pi. Now P is exchanged with the environment as Pi, so in principle a correlation between TP and Pi could perhaps be expected. I’m really most interested in the fraction of TP which is not Pi, that is TP-Pi. I would also expect that to be positively correlated with Pi. However, looking at the data using a mixed model an insignificant negative correlation is obtained. Then I thought, that since TP-Pi is bound to be small if Pi is large a negative correlation is almost dictated by the math even if the biology would have it otherwise in so far as the the TP-Pi, likely organic P, must someday have been Pi. Hence I thought about correcting the slight negative correlation between TP-Pi and Pi for the expected large negative correlation due to the math – to eventually recover what I came from: a positive correlation. People seems to agree that this thinki</p><p>2 0.12863034 <a title="1918-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-Measurement_error_in_monkey_studies.html">1997 andrew gelman stats-2013-08-24-Measurement error in monkey studies</a></p>
<p>Introduction: Following up on our recent  discussion  of combative linguist Noam Chomsky and disgraced primatologist Marc Hauser, here are  some stories  from Jay Livingston about monkey research.
 
Don’t get me wrong—I eat burgers, so I’m not trying to get on my moral high horse here.  But the stories do get you thinking about measurement error and why I would  not  trust the PI of a monkey study to code his own measurements and keep his data secret.</p><p>3 0.10705476 <a title="1918-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-16-The_%E2%80%9CWashington_read%E2%80%9D_and_the_algebra_of_conditional_distributions.html">961 andrew gelman stats-2011-10-16-The “Washington read” and the algebra of conditional distributions</a></p>
<p>Introduction: I was trying to explain in class how a (Bayesian) statistician reads the formula for a probability distribution.  In old-fashioned statistics textbooks you’re told that if you want to compute a conditional distribution from a joint distribution you need to do some heavy math:  p(a|b) = p(a,b)/\int p(a’,b)da’.
 
When doing Bayesian statistics, though, you usually don’t have to do the integration or the division. If you have parameters theta and data y, you first write p(y,theta).  Then to get p(theta|y), you  don’t  need to integrate or divide.  All you have to do is look at p(y,theta) in a certain way:  Treat y as a constant and theta as a variable.  Similarly, if you’re doing the Gibbs sampler and want a conditional distribution, just consider the parameter you’re updating as the variable and everything else as a constant.  No need to integrate or divide, you just take the joint distribution and look at it from the right perspective.
 
Awhile ago Yair told me there’s something called</p><p>4 0.10622288 <a title="1918-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-29-More_on_scaled-inverse_Wishart_and_prior_independence.html">1474 andrew gelman stats-2012-08-29-More on scaled-inverse Wishart and prior independence</a></p>
<p>Introduction: I’ve had a couple of email conversations in the past couple days on dependence in multivariate prior distributions.
 
 Modeling the degrees of freedom and scale parameters in the t distribution 
 
First, in our Stan group we’ve been discussing the choice of priors for the degrees-of-freedom parameter in the t distribution.  I wrote that also there’s the question of parameterization.  It does not necessarily make sense to have independent priors on the df and scale parameters.  In some sense, the meaning of the scale parameter changes with the df.
 
 Prior dependence between correlation and scale parameters in the scaled inverse-Wishart model 
 
The second case of parameterization in prior distribution arose from an email I received from Chris Chatham pointing me to  this exploration  by Matt Simpson of the scaled inverse-Wishart prior distribution for hierarchical covariance matrices.  Simpson writes:
  
A popular prior for Σ is the inverse-Wishart distribution [ not  the same as the</p><p>5 0.10365023 <a title="1918-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-22-That_claim_that_students_whose_parents_pay_for_more_of_college_get_worse_grades.html">1688 andrew gelman stats-2013-01-22-That claim that students whose parents pay for more of college get worse grades</a></p>
<p>Introduction: Theodore Vasiloudis writes:
  
I came upon  this article  by Laura Hamilton, an assistant professor in the University of California at Merced, that claims that “The more money that parents provide for higher education, the lower the grades their children earn.”


I can’t help but feel that there something wrong with the basis of the study or a confounding factor causing this apparent correlation, and since you often comment on studies on your blog I thought you might find this study interesting.
  
My reply:  I have to admit that the description above made me suspicious of the study before I even looked at it.  On first thought, I’d expect the effect of parent’s financial contributions to be positive (as they free the student from the need to get a job during college), but not negative.  Hamilton argues that “parental investments create a disincentive for student achievement,” which may be—but I’m generally suspicious of arguments in which the rebound is bigger than the main effect.</p><p>6 0.10343511 <a title="1918-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>7 0.087530822 <a title="1918-tfidf-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-03-He_doesn%E2%80%99t_trust_the_fit_._._._r%3D.999.html">315 andrew gelman stats-2010-10-03-He doesn’t trust the fit . . . r=.999</a></p>
<p>8 0.086352691 <a title="1918-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-All_inference_is_about_generalizing_from_sample_to_population.html">1996 andrew gelman stats-2013-08-24-All inference is about generalizing from sample to population</a></p>
<p>9 0.081594467 <a title="1918-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-13-Test_scores_and_grades_predict_job_performance_%28but_maybe_not_at_Google%29.html">1980 andrew gelman stats-2013-08-13-Test scores and grades predict job performance (but maybe not at Google)</a></p>
<p>10 0.081438921 <a title="1918-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-25-Spam%21.html">2148 andrew gelman stats-2013-12-25-Spam!</a></p>
<p>11 0.078714773 <a title="1918-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-16-Mr._Pearson%2C_meet_Mr._Mandelbrot%3A__Detecting_Novel_Associations_in_Large_Data_Sets.html">1062 andrew gelman stats-2011-12-16-Mr. Pearson, meet Mr. Mandelbrot:  Detecting Novel Associations in Large Data Sets</a></p>
<p>12 0.071713917 <a title="1918-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-21-Derman%2C_Rodrik_and_the_nature_of_statistical_models.html">1076 andrew gelman stats-2011-12-21-Derman, Rodrik and the nature of statistical models</a></p>
<p>13 0.069737196 <a title="1918-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-02-Covariate_Adjustment_in_RCT_-_Model_Overfitting_in_Multilevel_Regression.html">936 andrew gelman stats-2011-10-02-Covariate Adjustment in RCT - Model Overfitting in Multilevel Regression</a></p>
<p>14 0.068414874 <a title="1918-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-05-What_do_practitioners_need_to_know_about_regression%3F.html">451 andrew gelman stats-2010-12-05-What do practitioners need to know about regression?</a></p>
<p>15 0.067701295 <a title="1918-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-16-Learning_about_correlations_using_cross-sectional_and_over-time_comparisons_between_and_within_countries.html">1985 andrew gelman stats-2013-08-16-Learning about correlations using cross-sectional and over-time comparisons between and within countries</a></p>
<p>16 0.066136479 <a title="1918-tfidf-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-09-Advice%3A__positive-sum%2C_zero-sum%2C_or_negative-sum.html">2287 andrew gelman stats-2014-04-09-Advice:  positive-sum, zero-sum, or negative-sum</a></p>
<p>17 0.064171292 <a title="1918-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Poverty%2C_educational_performance_%E2%80%93_and_can_be_done_about_it.html">561 andrew gelman stats-2011-02-06-Poverty, educational performance – and can be done about it</a></p>
<p>18 0.063053668 <a title="1918-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-04-Too_many_MC%E2%80%99s_not_enough_MIC%E2%80%99s%2C_or_What_principles_should_govern_attempts_to_summarize_bivariate_associations_in_large_multivariate_datasets%3F.html">1706 andrew gelman stats-2013-02-04-Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets?</a></p>
<p>19 0.060845483 <a title="1918-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-Another_reason_why_you_can_get_good_inferences_from_a_bad_model.html">1527 andrew gelman stats-2012-10-10-Another reason why you can get good inferences from a bad model</a></p>
<p>20 0.058499612 <a title="1918-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Futures_contracts%2C_Granger_causality%2C_and_my_preference_for_estimation_to_testing.html">212 andrew gelman stats-2010-08-17-Futures contracts, Granger causality, and my preference for estimation to testing</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.107), (1, 0.024), (2, 0.037), (3, -0.012), (4, 0.033), (5, 0.009), (6, 0.033), (7, 0.014), (8, 0.011), (9, 0.034), (10, 0.001), (11, 0.011), (12, -0.009), (13, -0.026), (14, 0.005), (15, 0.004), (16, 0.02), (17, 0.013), (18, 0.013), (19, -0.01), (20, 0.019), (21, 0.004), (22, 0.016), (23, -0.009), (24, 0.021), (25, 0.029), (26, 0.003), (27, 0.025), (28, -0.0), (29, 0.012), (30, -0.005), (31, 0.014), (32, 0.035), (33, 0.02), (34, 0.027), (35, 0.026), (36, 0.022), (37, 0.005), (38, -0.007), (39, -0.03), (40, 0.009), (41, -0.011), (42, 0.011), (43, 0.018), (44, -0.011), (45, -0.021), (46, 0.01), (47, 0.001), (48, 0.015), (49, 0.02)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94335693 <a title="1918-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-29-Going_negative.html">1918 andrew gelman stats-2013-06-29-Going negative</a></p>
<p>Introduction: Troels Ring writes: 
  
  
I have measured total phosphorus, TP, on a number of dialysis patients, and also measured conventional phosphate, Pi. Now P is exchanged with the environment as Pi, so in principle a correlation between TP and Pi could perhaps be expected. I’m really most interested in the fraction of TP which is not Pi, that is TP-Pi. I would also expect that to be positively correlated with Pi. However, looking at the data using a mixed model an insignificant negative correlation is obtained. Then I thought, that since TP-Pi is bound to be small if Pi is large a negative correlation is almost dictated by the math even if the biology would have it otherwise in so far as the the TP-Pi, likely organic P, must someday have been Pi. Hence I thought about correcting the slight negative correlation between TP-Pi and Pi for the expected large negative correlation due to the math – to eventually recover what I came from: a positive correlation. People seems to agree that this thinki</p><p>2 0.77770352 <a title="1918-lsi-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-28-%E2%80%9CGenomics%E2%80%9D_vs._genetics.html">303 andrew gelman stats-2010-09-28-“Genomics” vs. genetics</a></p>
<p>Introduction: John Cook  and  Joseph Delaney  point to  an article  by Yurii Aulchenko et al., who write:
  
54 loci showing strong statistical evidence for association to human height were described, providing us with potential genomic means of human height prediction. In a population-based study of 5748 people, we find that a 54-loci genomic profile explained 4-6% of the sex- and age-adjusted height variance, and had limited ability to discriminate tall/short people. . . .


In a family-based study of 550 people, with both parents having height measurements, we find that the Galtonian mid-parental prediction method explained 40% of the sex- and age-adjusted height variance, and showed high discriminative accuracy. . . .
  
The message is that the simple approach of predicting child’s height using a regression model given parents’ average height performs much better than the method they have based on combining 54 genes.
 
They also find that, if you start with the prediction based on parents’ heigh</p><p>3 0.76579994 <a title="1918-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-28-Correlation%2C_prediction%2C_variation%2C_etc..html">301 andrew gelman stats-2010-09-28-Correlation, prediction, variation, etc.</a></p>
<p>Introduction: Hamdan Azhar writes:
  
 
I [Azhar] write with a question about language in the context of statistics. Consider the three statements below.


a) Y is significantly associated (correlated) with X;


b) knowledge of X allows us to account for __% of the variance in Y;


c) Y can be predicted to a significant extent given knowledge of X.


To what extent are these statements equivalent? Much of the (non-statistical) scientific literature doesn’t seem to distinguish between these notions. Is this just about semantics — or are there meaningful differences here, particularly between b and c?


Consider a framework where X constitutes a predictor space of p variables (x1,…,xp). We wish to generate a linear combination of these variables to yield a score that optimally correlates with Y. Can we substitute the word “predicts” for “optimally correlates with” in this context?


One can argue that “correlating” or “accounting for variance” suggests that we are trying to maximize goodness-of-fit (i</p><p>4 0.76206619 <a title="1918-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Poverty%2C_educational_performance_%E2%80%93_and_can_be_done_about_it.html">561 andrew gelman stats-2011-02-06-Poverty, educational performance – and can be done about it</a></p>
<p>Introduction: Andrew has pointed to Jonathan Livengood’s  analysis  of the correlation between poverty and PISA results, whereby schools with poorer students get poorer test results. I’d have written a comment, but then I couldn’t have inserted a chart.
 
Andrew points out that a causal analysis is needed. This reminds me of an intervention that has been done before: take a child out of poverty, and bring him up in a better-off family. What’s going to happen? There have been several studies examining correlations between adoptive and biological parents’ IQ (assuming IQ is a test analogous to the math and verbal tests, and that parent IQ is analogous to the quality of instruction – but the point is in the analysis not in the metric). This is the result (from  Adoption Strategies  by Robin P Corley in Encyclopedia of Life Sciences):
 
 
 
So, while it did make a difference at an early age, with increasing age of the adopted child, the intelligence of adoptive parents might not be making any difference</p><p>5 0.74185801 <a title="1918-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>Introduction: Andrew Eppig writes:
  
I’m a physicist by training who is transitioning to the social sciences. I recently came across a  reference  in the Economist to a paper on IQ and parasites which I read as I have more than a passing interest in IQ research (having read much that you and others (e.g., Shalizi, Wicherts) have written). In this paper I note that the authors find a very high correlation between national IQ and parasite prevalence. The strength of the correlation (-0.76 to -0.82) surprised me, as I’m used to much weaker correlations in the social sciences. To me, it’s a bit too high, suggesting that there are other factors at play or that one of the variables is merely a proxy for a large number of other variables. But I have no basis for this other than a gut feeling and a memory of a plot on  Language Log  about the distribution of correlation coefficients in social psychology.


So my question is this: Is a correlation in the range of (-0.82,-0.76) more likely to be a correlatio</p><p>6 0.72450763 <a title="1918-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-03-He_doesn%E2%80%99t_trust_the_fit_._._._r%3D.999.html">315 andrew gelman stats-2010-10-03-He doesn’t trust the fit . . . r=.999</a></p>
<p>7 0.71892667 <a title="1918-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-27-Average_predictive_comparisons_when_changing_a_pair_of_variables.html">1346 andrew gelman stats-2012-05-27-Average predictive comparisons when changing a pair of variables</a></p>
<p>8 0.71384346 <a title="1918-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-24-What_is_the_normal_range_of_values_in_a_medical_test%3F.html">923 andrew gelman stats-2011-09-24-What is the normal range of values in a medical test?</a></p>
<p>9 0.70032132 <a title="1918-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-22-Struggles_over_the_criticism_of_the_%E2%80%9Ccannabis_users_and_IQ_change%E2%80%9D_paper.html">1910 andrew gelman stats-2013-06-22-Struggles over the criticism of the “cannabis users and IQ change” paper</a></p>
<p>10 0.69798189 <a title="1918-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-23-More_on_those_L.A._Times_estimates_of_teacher_effectiveness.html">226 andrew gelman stats-2010-08-23-More on those L.A. Times estimates of teacher effectiveness</a></p>
<p>11 0.69297737 <a title="1918-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>12 0.69247508 <a title="1918-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-29-Difficulties_with_the_1-4-power_transformation.html">1142 andrew gelman stats-2012-01-29-Difficulties with the 1-4-power transformation</a></p>
<p>13 0.68432885 <a title="1918-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-The_scope_for_snooping.html">1070 andrew gelman stats-2011-12-19-The scope for snooping</a></p>
<p>14 0.68238854 <a title="1918-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-12-Controversy_about_average_personality_differences_between_men_and_women.html">1114 andrew gelman stats-2012-01-12-Controversy about average personality differences between men and women</a></p>
<p>15 0.6822325 <a title="1918-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-Comparing_prediction_errors.html">938 andrew gelman stats-2011-10-03-Comparing prediction errors</a></p>
<p>16 0.67985684 <a title="1918-lsi-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>17 0.67833662 <a title="1918-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-03-Boot.html">1881 andrew gelman stats-2013-06-03-Boot</a></p>
<p>18 0.67623115 <a title="1918-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-22-That_claim_that_students_whose_parents_pay_for_more_of_college_get_worse_grades.html">1688 andrew gelman stats-2013-01-22-That claim that students whose parents pay for more of college get worse grades</a></p>
<p>19 0.6757319 <a title="1918-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-28-Value-added_assessment%3A__What_went_wrong%3F.html">1350 andrew gelman stats-2012-05-28-Value-added assessment:  What went wrong?</a></p>
<p>20 0.67465365 <a title="1918-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-21-Random_matrices_in_the_news.html">2258 andrew gelman stats-2014-03-21-Random matrices in the news</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(4, 0.248), (15, 0.015), (16, 0.062), (21, 0.044), (24, 0.088), (30, 0.011), (45, 0.037), (49, 0.011), (77, 0.012), (85, 0.019), (86, 0.01), (87, 0.011), (91, 0.013), (95, 0.048), (99, 0.247)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.91510093 <a title="1918-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-08-GiveWell_sez%3A__Cost-effectiveness_of_de-worming_was_overstated_by_a_factor_of_100_%28%21%29_due_to_a_series_of_sloppy_calculations.html">947 andrew gelman stats-2011-10-08-GiveWell sez:  Cost-effectiveness of de-worming was overstated by a factor of 100 (!) due to a series of sloppy calculations</a></p>
<p>Introduction: Alexander at GiveWell  writes :
  
The Disease Control Priorities in Developing Countries (DCP2), a major report funded by the Gates Foundation . . . provides an estimate of $3.41 per disability-adjusted life-year (DALY) for the cost-effectiveness of soil-transmitted-helminth (STH) treatment, implying that STH treatment is one of the most cost-effective interventions for global health. In investigating this figure, we have corresponded, over a period of months, with six scholars who had been directly or indirectly involved in the production of the estimate. Eventually, we were able to obtain the spreadsheet that was used to generate the $3.41/DALY estimate. That spreadsheet contains five separate errors that, when corrected, shift the estimated cost effectiveness of deworming from $3.41 to $326.43. [I think they mean to say $300 -- ed.] We came to this conclusion a year after learning that the DCP2’s published cost-effectiveness estimate for schistosomiasis treatment – another kind of</p><p>2 0.9112832 <a title="1918-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-11-The_consulting_biz.html">1618 andrew gelman stats-2012-12-11-The consulting biz</a></p>
<p>Introduction: I received the following (unsolicited) email:
  
Hello, 


*** LLC, a ***-based market research company, has a financial client who is interested in speaking with a statistician who has done research in the field of Alzheimer’s Disease and preferably familiar with the SOLA and BAPI trials.  We offer an honorarium of $200 for a 30 minute telephone interview.


Please advise us if you have an employment or consulting agreement with any organization or operate professionally pursuant to an organization’s code of conduct or employee manual that may control activities by you outside of your regular present and former employment, such as participating in this consulting project for MedPanel.  If there are such contracts or other documents that do apply to you, please forward MedPanel a copy of each such document asap as we are obligated to review such documents to determine if you are permitted to participate as a consultant for MedPanel on a project with this particular client.


If you are</p><p>same-blog 3 0.89008272 <a title="1918-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-29-Going_negative.html">1918 andrew gelman stats-2013-06-29-Going negative</a></p>
<p>Introduction: Troels Ring writes: 
  
  
I have measured total phosphorus, TP, on a number of dialysis patients, and also measured conventional phosphate, Pi. Now P is exchanged with the environment as Pi, so in principle a correlation between TP and Pi could perhaps be expected. I’m really most interested in the fraction of TP which is not Pi, that is TP-Pi. I would also expect that to be positively correlated with Pi. However, looking at the data using a mixed model an insignificant negative correlation is obtained. Then I thought, that since TP-Pi is bound to be small if Pi is large a negative correlation is almost dictated by the math even if the biology would have it otherwise in so far as the the TP-Pi, likely organic P, must someday have been Pi. Hence I thought about correcting the slight negative correlation between TP-Pi and Pi for the expected large negative correlation due to the math – to eventually recover what I came from: a positive correlation. People seems to agree that this thinki</p><p>4 0.88567603 <a title="1918-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-29-R_sucks.html">1919 andrew gelman stats-2013-06-29-R sucks</a></p>
<p>Introduction: I was trying to make some new graphs using 5-year-old R code and I got all these problems because I was reading in files with variable names such as “co.fipsid” and now R is automatically changing them to “co_fipsid”.  Or maybe the names had underbars all along, and the old R had changed them into dots.  Whatever.  I understand that backward compatibility can be hard to maintain, but this is just annoying.</p><p>5 0.86709368 <a title="1918-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-13-Can_you_write_a_program_to_determine_the_causal_order%3F.html">1801 andrew gelman stats-2013-04-13-Can you write a program to determine the causal order?</a></p>
<p>Introduction: Mike Zyphur writes:
  
Kaggle.com has launched a  competition  to determine what’s an effect and what’s a cause. They’ve got correlated variables, they’re deprived of context, and you’re asked to determine the causal order.  $5,000 prizes.
  
I followed the link and the example they gave didn’t make much sense to me (the two variables were temperature and altitude of cities in Germany, and they said that altitude causes temperature).  It has the feeling to me of one of those weird standardized tests we used to see sometimes in school, where there’s no real correct answer so the goal is to figure out what the test-writer wanted you to say.
 
Nonetheless, this might be of interest, so I’m passing it along to you.</p><p>6 0.8576442 <a title="1918-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-Measurement_error_in_monkey_studies.html">1997 andrew gelman stats-2013-08-24-Measurement error in monkey studies</a></p>
<p>7 0.85394263 <a title="1918-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-27-No_radon_lobby.html">238 andrew gelman stats-2010-08-27-No radon lobby</a></p>
<p>8 0.84721923 <a title="1918-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-28-Advocacy_in_the_form_of_a_%E2%80%9Cdeliberative_forum%E2%80%9D.html">113 andrew gelman stats-2010-06-28-Advocacy in the form of a “deliberative forum”</a></p>
<p>9 0.83743393 <a title="1918-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-28-Plain_old_everyday_Bayesianism%21.html">1829 andrew gelman stats-2013-04-28-Plain old everyday Bayesianism!</a></p>
<p>10 0.8353551 <a title="1918-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-14-Reproducibility_in_Practice.html">907 andrew gelman stats-2011-09-14-Reproducibility in Practice</a></p>
<p>11 0.82012212 <a title="1918-lda-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-18-Derivative-based_MCMC_as_a_breakthrough_technique_for_implementing_Bayesian_statistics.html">419 andrew gelman stats-2010-11-18-Derivative-based MCMC as a breakthrough technique for implementing Bayesian statistics</a></p>
<p>12 0.81620455 <a title="1918-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-26-Graphs_showing_regression_uncertainty%3A__the_code%21.html">1470 andrew gelman stats-2012-08-26-Graphs showing regression uncertainty:  the code!</a></p>
<p>13 0.80733323 <a title="1918-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-28-Why_during_the_1950-1960%E2%80%B2s_did_Jerry_Cornfield_become_a_Bayesian%3F.html">2000 andrew gelman stats-2013-08-28-Why during the 1950-1960′s did Jerry Cornfield become a Bayesian?</a></p>
<p>14 0.80402064 <a title="1918-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-14-The_popularity_of_certain_baby_names_is_falling_off_the_clifffffffffffff.html">2211 andrew gelman stats-2014-02-14-The popularity of certain baby names is falling off the clifffffffffffff</a></p>
<p>15 0.80132121 <a title="1918-lda-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-15-Mary%2C_Mary%2C_why_ya_buggin.html">2212 andrew gelman stats-2014-02-15-Mary, Mary, why ya buggin</a></p>
<p>16 0.79315531 <a title="1918-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-26-%E2%80%9CThe_Bayesian_approach_to_forensic_evidence%E2%80%9D.html">2078 andrew gelman stats-2013-10-26-“The Bayesian approach to forensic evidence”</a></p>
<p>17 0.77229935 <a title="1918-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-28-Value-added_assessment%3A__What_went_wrong%3F.html">1350 andrew gelman stats-2012-05-28-Value-added assessment:  What went wrong?</a></p>
<p>18 0.77054226 <a title="1918-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-All_inference_is_about_generalizing_from_sample_to_population.html">1996 andrew gelman stats-2013-08-24-All inference is about generalizing from sample to population</a></p>
<p>19 0.75907016 <a title="1918-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-23-The_bane_of_many_causes.html">48 andrew gelman stats-2010-05-23-The bane of many causes</a></p>
<p>20 0.75418329 <a title="1918-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-14-1.5_million_people_were_told_that_extreme_conservatives_are_happier_than_political_moderates.__Approximately_.0001_million_Americans_learned_that_the_opposite_is_true..html">1458 andrew gelman stats-2012-08-14-1.5 million people were told that extreme conservatives are happier than political moderates.  Approximately .0001 million Americans learned that the opposite is true.</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
