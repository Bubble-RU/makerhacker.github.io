<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1702 andrew gelman stats-2013-02-01-Don’t let your standard errors drive your research agenda</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1702" href="#">andrew_gelman_stats-2013-1702</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1702 andrew gelman stats-2013-02-01-Don’t let your standard errors drive your research agenda</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1702-html" href="http://andrewgelman.com/2013/02/01/dont-let-your-standard-errors-drive-your-research-agenda/">html</a></p><p>Introduction: Alexis Le Nestour writes:
  
How do you test for no effect? I attended a seminar where the person assumed that a non significant difference between groups implied an absence of effect. In that case, the researcher needed to show that two groups were similar before being hit by a shock conditional on some observable variables. The assumption was that the two groups were similar and that the shock was random. What would be the good way to set up a test in that case?


I know you’ve been through that before (http://andrewgelman.com/2009/02/not_statistical/) and there are interesting comments but I wanted to have your opinion on that.
  
My reply:  I think you have to get quantitative here.  How similar is similar?  Don’t let your standard errors drive your research agenda.  Or, to put it another way, what would you do if you had all the data?  If your sample size were 1 zillion, then everything would statistically distinguishable from everything else.  And then you’d have to think about w</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Alexis Le Nestour writes:    How do you test for no effect? [sent-1, score-0.171]
</p><p>2 I attended a seminar where the person assumed that a non significant difference between groups implied an absence of effect. [sent-2, score-1.487]
</p><p>3 In that case, the researcher needed to show that two groups were similar before being hit by a shock conditional on some observable variables. [sent-3, score-1.765]
</p><p>4 The assumption was that the two groups were similar and that the shock was random. [sent-4, score-1.171]
</p><p>5 What would be the good way to set up a test in that case? [sent-5, score-0.387]
</p><p>6 com/2009/02/not_statistical/) and there are interesting comments but I wanted to have your opinion on that. [sent-7, score-0.316]
</p><p>7 My reply:  I think you have to get quantitative here. [sent-8, score-0.162]
</p><p>8 Don’t let your standard errors drive your research agenda. [sent-10, score-0.417]
</p><p>9 Or, to put it another way, what would you do if you had all the data? [sent-11, score-0.19]
</p><p>10 If your sample size were 1 zillion, then everything would statistically distinguishable from everything else. [sent-12, score-0.922]
</p><p>11 And then you’d have to think about what you really care about. [sent-13, score-0.141]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('shock', 0.358), ('similar', 0.31), ('groups', 0.3), ('distinguishable', 0.231), ('alexis', 0.231), ('le', 0.195), ('observable', 0.186), ('everything', 0.173), ('non', 0.173), ('test', 0.171), ('attended', 0.168), ('zillion', 0.166), ('absence', 0.156), ('seminar', 0.155), ('implied', 0.155), ('drive', 0.14), ('assumed', 0.132), ('hit', 0.127), ('assumption', 0.116), ('quantitative', 0.112), ('needed', 0.11), ('conditional', 0.108), ('http', 0.104), ('case', 0.099), ('researcher', 0.099), ('statistically', 0.096), ('size', 0.094), ('opinion', 0.094), ('errors', 0.093), ('care', 0.091), ('wanted', 0.09), ('significant', 0.087), ('two', 0.087), ('person', 0.081), ('show', 0.08), ('difference', 0.08), ('sample', 0.078), ('would', 0.077), ('comments', 0.073), ('standard', 0.073), ('way', 0.073), ('effect', 0.068), ('reply', 0.067), ('set', 0.066), ('let', 0.065), ('interesting', 0.059), ('put', 0.058), ('another', 0.055), ('think', 0.05), ('research', 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1702-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-01-Don%E2%80%99t_let_your_standard_errors_drive_your_research_agenda.html">1702 andrew gelman stats-2013-02-01-Don’t let your standard errors drive your research agenda</a></p>
<p>Introduction: Alexis Le Nestour writes:
  
How do you test for no effect? I attended a seminar where the person assumed that a non significant difference between groups implied an absence of effect. In that case, the researcher needed to show that two groups were similar before being hit by a shock conditional on some observable variables. The assumption was that the two groups were similar and that the shock was random. What would be the good way to set up a test in that case?


I know you’ve been through that before (http://andrewgelman.com/2009/02/not_statistical/) and there are interesting comments but I wanted to have your opinion on that.
  
My reply:  I think you have to get quantitative here.  How similar is similar?  Don’t let your standard errors drive your research agenda.  Or, to put it another way, what would you do if you had all the data?  If your sample size were 1 zillion, then everything would statistically distinguishable from everything else.  And then you’d have to think about w</p><p>2 0.10126675 <a title="1702-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>Introduction: Someone writes:
  
Suppose I have two groups of people, A and B, which differ on some characteristic of interest to me;  and for each person I measure a single real-valued quantity X.  I have a theory that group A has a higher mean value of X than group B.  I test this theory by using a t-test.  Am I entitled to use a *one-tailed* t-test?  Or should I use a *two-tailed* one (thereby giving a p-value that is twice as large)?


I know you will probably answer:  Forget the t-test; you should use Bayesian methods instead.


But what is the standard frequentist answer to this question?
  
My reply:
 
The quick answer here is that different people will do different things here.  I would say the 2-tailed p-value is more standard but some people will insist on the one-tailed version, and itâ&euro;&trade;s hard to make a big stand on this one, given all the other problems with p-values in practice:
 
http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf
 
http://www.stat.columbia.edu/~gelm</p><p>3 0.098751947 <a title="1702-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-%E2%80%9CThe_difference_between_._._.%E2%80%9D%3A__It%E2%80%99s_not_just_p%3D.05_vs._p%3D.06.html">1072 andrew gelman stats-2011-12-19-“The difference between . . .”:  It’s not just p=.05 vs. p=.06</a></p>
<p>Introduction: The title of  this post  by Sanjay Srivastava illustrates an annoying misconception that’s crept into the (otherwise delightful) recent  publicity  related to my  article  with Hal Stern, he difference between “significant” and “not significant” is not itself statistically significant.
 
When people bring this up, they keep referring to the difference between p=0.05 and p=0.06, making the familiar (and correct) point about the arbitrariness of the conventional p-value threshold of 0.05.  And, sure, I agree with this, but everybody knows that already.
 
The point Hal and I were making was that even apparently large differences in p-values are not statistically significant. For example, if you have one study with z=2.5 (almost significant at the 1% level!) and another with z=1 (not statistically significant at all, only 1 se from zero!), then their difference has a z of about 1 (again, not statistically significant at all). So it’s not just a comparison of 0.05 vs. 0.06, even a differenc</p><p>4 0.094817109 <a title="1702-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>Introduction: From a recent email exchange:
 
I agree that you should never compare p-values directly.  The p-value is a strange nonlinear transformation of data that is only interpretable under the null hypothesis. Once you abandon the null (as we do when we observe something with a very low p-value), the p-value itself becomes irrelevant.  To put it another way, the p-value is a measure of evidence, it is not an estimate of effect size (as it is often treated, with the idea that a p=.001 effect is larger than a p=.01 effect, etc).  Even conditional on sample size, the p-value is not a measure of effect size.</p><p>5 0.09252885 <a title="1702-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-03-Uncertainty_in_parameter_estimates_using_multilevel_models.html">1966 andrew gelman stats-2013-08-03-Uncertainty in parameter estimates using multilevel models</a></p>
<p>Introduction: David Hsu writes: 
   
 I have a (perhaps) simple question about uncertainty in parameter estimates using multilevel models — what is an appropriate threshold for measure parameter uncertainty in a multilevel model? 
 
The reason why I ask is that I set out to do a crossed two-way model with two varying intercepts, similar to your flight simulator example in your 2007 book.  The difference is that I have a lot of predictors specific to each cell (I think equivalent to airport and pilot in your example), and I find after modeling this in JAGS, I happily find that the predictors are much less important than the variability by cell (airport and pilot effects).  Happily because this is what I am writing a paper about.
 
However, I then went to check subsets of predictors using lm() and lmer().  I understand that they all use different estimation methods, but what I can’t figure out is why the errors on all of the coefficient estimates are *so* different.  
 
For example, using JAGS, and th</p><p>6 0.08815828 <a title="1702-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-28-Another_argument_in_favor_of_expressing_conditional_probability_statements_using_the_population_distribution.html">56 andrew gelman stats-2010-05-28-Another argument in favor of expressing conditional probability statements using the population distribution</a></p>
<p>7 0.083728693 <a title="1702-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-15-Progress_in_U.S._education%3B_also%2C_a_discussion_of_what_it_takes_to_hit_the_op-ed_pages.html">1265 andrew gelman stats-2012-04-15-Progress in U.S. education; also, a discussion of what it takes to hit the op-ed pages</a></p>
<p>8 0.083410926 <a title="1702-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-Write_This_Book.html">1605 andrew gelman stats-2012-12-04-Write This Book</a></p>
<p>9 0.082280718 <a title="1702-tfidf-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-18-%E2%80%9CI_was_finding_the_test_so_irritating_and_boring_that_I_just_started_to_click_through_as_fast_as_I_could%E2%80%9D.html">351 andrew gelman stats-2010-10-18-“I was finding the test so irritating and boring that I just started to click through as fast as I could”</a></p>
<p>10 0.081255123 <a title="1702-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-08-Silly_old_chi-square%21.html">401 andrew gelman stats-2010-11-08-Silly old chi-square!</a></p>
<p>11 0.081069909 <a title="1702-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>12 0.080046117 <a title="1702-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<p>13 0.077599555 <a title="1702-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-22-Struggles_over_the_criticism_of_the_%E2%80%9Ccannabis_users_and_IQ_change%E2%80%9D_paper.html">1910 andrew gelman stats-2013-06-22-Struggles over the criticism of the “cannabis users and IQ change” paper</a></p>
<p>14 0.077504613 <a title="1702-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-24-What_is_the_normal_range_of_values_in_a_medical_test%3F.html">923 andrew gelman stats-2011-09-24-What is the normal range of values in a medical test?</a></p>
<p>15 0.075972468 <a title="1702-tfidf-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-How_does_multilevel_modeling_affect_the_estimate_of_the_grand_mean%3F.html">255 andrew gelman stats-2010-09-04-How does multilevel modeling affect the estimate of the grand mean?</a></p>
<p>16 0.075662106 <a title="1702-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-How_do_you_interpret_standard_errors_from_a_regression_fit_to_the_entire_population%3F.html">972 andrew gelman stats-2011-10-25-How do you interpret standard errors from a regression fit to the entire population?</a></p>
<p>17 0.075034767 <a title="1702-tfidf-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-14-Questions_about_a_study_of_charter_schools.html">957 andrew gelman stats-2011-10-14-Questions about a study of charter schools</a></p>
<p>18 0.07450562 <a title="1702-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-09-%E2%80%9CHeterogeneity_of_variance_in_experimental_studies%3A__A_challenge_to_conventional_interpretations%E2%80%9D.html">1891 andrew gelman stats-2013-06-09-“Heterogeneity of variance in experimental studies:  A challenge to conventional interpretations”</a></p>
<p>19 0.07336247 <a title="1702-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-12-As_a_Bayesian_I_want_scientists_to_report_their_data_non-Bayesianly.html">1209 andrew gelman stats-2012-03-12-As a Bayesian I want scientists to report their data non-Bayesianly</a></p>
<p>20 0.072891131 <a title="1702-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-02-I_just_flew_in_from_the_econ_seminar%2C_and_boy_are_my_arms_tired.html">1039 andrew gelman stats-2011-12-02-I just flew in from the econ seminar, and boy are my arms tired</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.14), (1, 0.006), (2, 0.037), (3, -0.074), (4, 0.028), (5, -0.008), (6, 0.009), (7, 0.022), (8, 0.012), (9, -0.005), (10, -0.03), (11, -0.008), (12, 0.055), (13, -0.069), (14, 0.013), (15, 0.012), (16, -0.024), (17, -0.005), (18, 0.002), (19, 0.004), (20, 0.01), (21, 0.0), (22, 0.013), (23, -0.024), (24, -0.007), (25, -0.03), (26, 0.016), (27, -0.013), (28, -0.026), (29, 0.011), (30, 0.03), (31, -0.012), (32, 0.026), (33, 0.038), (34, 0.044), (35, 0.034), (36, -0.018), (37, 0.01), (38, 0.028), (39, 0.005), (40, 0.02), (41, -0.019), (42, -0.004), (43, -0.002), (44, -0.009), (45, -0.04), (46, 0.025), (47, -0.054), (48, 0.03), (49, -0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96425474 <a title="1702-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-01-Don%E2%80%99t_let_your_standard_errors_drive_your_research_agenda.html">1702 andrew gelman stats-2013-02-01-Don’t let your standard errors drive your research agenda</a></p>
<p>Introduction: Alexis Le Nestour writes:
  
How do you test for no effect? I attended a seminar where the person assumed that a non significant difference between groups implied an absence of effect. In that case, the researcher needed to show that two groups were similar before being hit by a shock conditional on some observable variables. The assumption was that the two groups were similar and that the shock was random. What would be the good way to set up a test in that case?


I know you’ve been through that before (http://andrewgelman.com/2009/02/not_statistical/) and there are interesting comments but I wanted to have your opinion on that.
  
My reply:  I think you have to get quantitative here.  How similar is similar?  Don’t let your standard errors drive your research agenda.  Or, to put it another way, what would you do if you had all the data?  If your sample size were 1 zillion, then everything would statistically distinguishable from everything else.  And then you’d have to think about w</p><p>2 0.76534861 <a title="1702-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-02-The_inevitable_problems_with_statistical_significance_and_95%25_intervals.html">1150 andrew gelman stats-2012-02-02-The inevitable problems with statistical significance and 95% intervals</a></p>
<p>Introduction: I’m thinking more and more that we have to get rid of statistical significance, 95% intervals, and all the rest, and just come to a more fundamental acceptance of uncertainty.
 
In practice, I think we use confidence intervals and hypothesis tests as a way to avoid acknowledging uncertainty. We set up some rules and then act as if we know what is real and what is not. Even in my own applied work, I’ve often enough presented 95% intervals and gone on from there. But maybe that’s just not right.
 
I was thinking about this after receiving the following email from a psychology student: 
  
  
I [the student] am trying to conceptualize the lessons in  your paper with Stern  with comparing treatment effects across studies. When trying to understand if a certain intervention works, we must look at what the literature says. However this can be complicated if the literature has divergent results. There are four situations I am thinking of. FOr each of these situations, assume the studies are r</p><p>3 0.76433599 <a title="1702-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-23-Scientists_can_read_your_mind_._._._as_long_as_the%E2%80%99re_allowed_to_look_at_more_than_one_place_in_your_brain_and_then_make_a_prediction_after_seeing_what_you_actually_did.html">106 andrew gelman stats-2010-06-23-Scientists can read your mind . . . as long as the’re allowed to look at more than one place in your brain and then make a prediction after seeing what you actually did</a></p>
<p>Introduction: Maggie Fox  writes :
  
Brain scans may be able to predict what you will do better than you can yourself . . .  They found a way to interpret “real time” brain images to show whether people who viewed messages about using sunscreen would actually use sunscreen during the following week.


The scans were more accurate than the volunteers were, Emily Falk and colleagues at the University of California Los Angeles reported in the Journal of Neuroscience. . . .


About half the volunteers had correctly predicted whether they would use sunscreen. The research team analyzed and re-analyzed the MRI scans to see if they could find any brain activity that would do better.


Activity in one area of the brain, a particular part of the medial prefrontal cortex, provided the best information.


“From this region of the brain, we can predict for about three-quarters of the people whether they will increase their use of sunscreen beyond what they say they will do,” Lieberman said.


“It is the one re</p><p>4 0.75708514 <a title="1702-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Futures_contracts%2C_Granger_causality%2C_and_my_preference_for_estimation_to_testing.html">212 andrew gelman stats-2010-08-17-Futures contracts, Granger causality, and my preference for estimation to testing</a></p>
<p>Introduction: José Iparraguirre writes:
  
There’s  a letter  in the latest issue of The Economist (July 31st) signed by Sir Richard Branson (Virgin), Michael Masters (Masters Capital Management) and David Frenk (Better Markets) about an    “>OECD report  on speculation and the prices of commodities, which includes the following: “The report uses a Granger causality test to measure the relationship between the level of commodities futures contracts held by swap dealers, and the prices of those commodities. Granger tests, however, are of dubious applicability to extremely volatile variables like commodities prices.”
  
The report says:
  
Granger causality is a standard statistical technique for determining whether one time series is useful in forecasting another. It is important to bear in mind that the term causality is used in a statistical sense, and not in a philosophical one of structural causation. More precisely a variable A is said to Granger cause B if knowing the time paths of B and A toge</p><p>5 0.75193352 <a title="1702-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-05-How_much_do_we_trust_a_new_claim_that_early_childhood_stimulation_raised_earnings_by_42%25%3F.html">2090 andrew gelman stats-2013-11-05-How much do we trust a new claim that early childhood stimulation raised earnings by 42%?</a></p>
<p>Introduction: Hal Pashler wrote in about a  recent paper , “Labor Market Returns to Early Childhood Stimulation:  a 20-year Followup to an Experimental Intervention in Jamaica,” by Paul Gertler, James Heckman, Rodrigo Pinto, Arianna Zanolini, Christel Vermeerch, Susan Walker, Susan M. Chang, and Sally Grantham-McGregor.  Here’s Pashler:
  
Dan Willingham tweeted: @DTWillingham: RCT from Jamaica: Big effects 20 years later of intervention—teaching parenting/child stimulation to moms in poverty http://t.co/rX6904zxvN


Browsing pp. 4 ff, it seems the authors are basically saying “hey the stats were challenging, the sample size tiny, other problems, but we solved them all—using innovative methods of our own devising!—and lo and behold, big positive results!”.


So this made me think (and tweet) basically that I hope the topic (which is pretty important) will happen to interest Andy Gelman enough to incline him to give us his take.  If you happen to have time and interest…
  
My reply became  this artic</p><p>6 0.74727488 <a title="1702-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-28-Difficulties_of_using_statistical_significance_%28or_lack_thereof%29_to_sift_through_and_compare_research_hypotheses.html">2042 andrew gelman stats-2013-09-28-Difficulties of using statistical significance (or lack thereof) to sift through and compare research hypotheses</a></p>
<p>7 0.73574251 <a title="1702-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-22-Struggles_over_the_criticism_of_the_%E2%80%9Ccannabis_users_and_IQ_change%E2%80%9D_paper.html">1910 andrew gelman stats-2013-06-22-Struggles over the criticism of the “cannabis users and IQ change” paper</a></p>
<p>8 0.73566401 <a title="1702-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-02-Fishing_for_cherries.html">1746 andrew gelman stats-2013-03-02-Fishing for cherries</a></p>
<p>9 0.73551899 <a title="1702-lsi-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-08-Silly_old_chi-square%21.html">401 andrew gelman stats-2010-11-08-Silly old chi-square!</a></p>
<p>10 0.72769558 <a title="1702-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-Write_This_Book.html">1605 andrew gelman stats-2012-12-04-Write This Book</a></p>
<p>11 0.7224704 <a title="1702-lsi-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>12 0.71971321 <a title="1702-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-04-Statistics_ethics_question.html">695 andrew gelman stats-2011-05-04-Statistics ethics question</a></p>
<p>13 0.71695465 <a title="1702-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-08-Censoring_on_one_end%2C_%E2%80%9Coutliers%E2%80%9D_on_the_other%2C_what_can_we_do_with_the_middle%3F.html">791 andrew gelman stats-2011-07-08-Censoring on one end, “outliers” on the other, what can we do with the middle?</a></p>
<p>14 0.71013165 <a title="1702-lsi-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-04-%E2%80%9CDogs_are_sensitive_to_small_variations_of_the_Earth%E2%80%99s_magnetic_field%E2%80%9D.html">2159 andrew gelman stats-2014-01-04-“Dogs are sensitive to small variations of the Earth’s magnetic field”</a></p>
<p>15 0.70949405 <a title="1702-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-29-Brain_Structure_and_the_Big_Five.html">490 andrew gelman stats-2010-12-29-Brain Structure and the Big Five</a></p>
<p>16 0.70742851 <a title="1702-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Poverty%2C_educational_performance_%E2%80%93_and_can_be_done_about_it.html">561 andrew gelman stats-2011-02-06-Poverty, educational performance – and can be done about it</a></p>
<p>17 0.70595378 <a title="1702-lsi-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>18 0.70434892 <a title="1702-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-19-The_scope_for_snooping.html">1070 andrew gelman stats-2011-12-19-The scope for snooping</a></p>
<p>19 0.7041828 <a title="1702-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>20 0.70350003 <a title="1702-lsi-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-24-%E2%80%9CEdlin%E2%80%99s_rule%E2%80%9D_for_routinely_scaling_down_published_estimates.html">2223 andrew gelman stats-2014-02-24-“Edlin’s rule” for routinely scaling down published estimates</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.024), (16, 0.091), (21, 0.067), (24, 0.183), (49, 0.028), (61, 0.037), (82, 0.022), (89, 0.17), (99, 0.256)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96391678 <a title="1702-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-05-Wouldn%E2%80%99t_it_be_cool_if_Glenn_Hubbard_were_consulting_for_Herbalife_and_I_were_on_the_other_side%3F.html">1708 andrew gelman stats-2013-02-05-Wouldn’t it be cool if Glenn Hubbard were consulting for Herbalife and I were on the other side?</a></p>
<p>Introduction: I remember in 4th grade or so, the teacher would give us a list of vocabulary words each week and we’d have to show we learned them by using each in a sentence.  We quickly got bored and decided to do the assignment by writing a single sentence using all ten words.  (Which the teacher hated, of course.)
 
The above headline is in that spirit, combining  blog   posts  rather than vocabulary words.
 
But that only uses two of the entries.  To really do the job, I’d need to throw in bivariate associations, ecological fallacies, high-dimensional feature selection, statistical significance, the suddenly unpopular name Hilary, snotty reviewers, the contagion of obesity, and milk-related spam.
 
Or we could bring in some of the all-time favorites, such as Bayesians, economists, Finland, beautiful parents and their daughters, goofy graphics, red and blue states, essentialism in children’s reasoning, chess running, and zombies.  Putting 8 of these in a single sentence (along with Glenn Hubbard</p><p>2 0.95628625 <a title="1702-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-31-Untunable_Metropolis.html">833 andrew gelman stats-2011-07-31-Untunable Metropolis</a></p>
<p>Introduction: Michael Margolis writes:
  
What are we to make of it when a Metropolis-Hastings step just won’t tune? That is, the acceptance rate is zero at expected-jump-size X, and way above 1/2 at X-exp(-16) (i.e.,  machine precision ).


I’ve solved my practical problem by writing that I would have liked to include results from a diffuse prior, but couldn’t. But I’m bothered by the poverty of my intuition. And since everything I’ve read says this is an issue of efficiency, rather than accuracy, I wonder if I could solve it just by running massive and heavily thinned chains.
  
My reply:
 
I can’t see how this could happen in a well-specified problem!  I suspect it’s a bug.  Otherwise try rescaling your variables so that your parameters will have values on the order of magnitude of 1.
 
To which Margolis responded:
  
I hardly wrote any of the code, so I can’t speak to the bug question — it’s binomial kriging from the R package geoRglm. And there are no covariates to scale — just the zero and one</p><p>3 0.95384181 <a title="1702-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-09-Familial_Linkage_between_Neuropsychiatric_Disorders_and_Intellectual_Interests.html">1160 andrew gelman stats-2012-02-09-Familial Linkage between Neuropsychiatric Disorders and Intellectual Interests</a></p>
<p>Introduction: When I spoke at Princeton last year, I talked with neuroscientist Sam Wang, who told me about a project he did surveying incoming Princeton freshmen about mental illness in their families.  He and his coauthor Benjamin Campbell found some interesting results, which they just  published :
  
A link between intellect and temperament has long been the subject of speculation. . . . Studies of the artistically inclined report linkage with familial depression, while among eminent and creative scientists, a lower incidence of affective disorders is found. In the case of developmental disorders, a heightened prevalence of autism spectrum disorders (ASDs) has been found in the families of mathematicians, physicists, and engineers. . . .


We surveyed the incoming class of 2014 at Princeton University about their intended academic major, familial incidence of neuropsychiatric disorders, and demographic variables. . . . Consistent with prior findings, we noticed a relation between intended academ</p><p>4 0.95247078 <a title="1702-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-10-He_said_he_was_sorry.html">1756 andrew gelman stats-2013-03-10-He said he was sorry</a></p>
<p>Introduction: Yes, it can be  done :
  
Hereby I contact you to clarify the situation that occurred with the publication of the article entitled *** which was published in Volume 11, Issue 3 of *** and I made the mistake of declaring as an author.  This chapter is a plagiarism of . . .


I wish to express and acknowledge that I am solely responsible for this . . . I recognize the gravity of the offense committed, since there is no justification for so doing. Therefore, and as a sign of shame and regret I feel in this situation, I will publish this letter, in order to set an example for other researchers do not engage in a similar error.


No more, and to please accept my apologies,


Sincerely,


***
  
P.S.  Since we’re on Retraction Watch already, I’ll point you to  this unrelated story  featuring a hilarious photo of a fraudster, who in this case was a grad student in psychology who faked his data and “has agreed to submit to a three-year supervisory period for any work involving funding from the</p><p>5 0.94800937 <a title="1702-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-11-Data_Visualization_vs._Statistical_Graphics.html">407 andrew gelman stats-2010-11-11-Data Visualization vs. Statistical Graphics</a></p>
<p>Introduction: I have this great talk on the above topic but nowhere to give it.
 
Here’s the story.  Several months ago, I was invited to speak at IEEE VisWeek.  It sounded like a great opportunity.  The organizer told me that there were typically about 700 people in the audience, and these are people in the visualization community whom I’d like to reach but normally wouldn’t have the opportunity to encounter.  It sounded great, but I didn’t want to fly most of the way across the country by myself, so I offered to give the talk by videolink.
 
I was surprised to get a No response:  I’d think that a visualization conference, of all things, would welcome a video talk.
 
In the meantime, though, I’d thought a lot about what I’d talk about and had started preparing something.  Once I found out I wouldn’t be giving the talk, I channeled the efforts into an article which, with the collaboration of Antony Unwin, was completed about a month ago.
 
It would take very little effort to adapt this graph-laden a</p><p>6 0.94568133 <a title="1702-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-16-The_%E2%80%9Chot_hand%E2%80%9D_and_problems_with_hypothesis_testing.html">1215 andrew gelman stats-2012-03-16-The “hot hand” and problems with hypothesis testing</a></p>
<p>same-blog 7 0.94104588 <a title="1702-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-01-Don%E2%80%99t_let_your_standard_errors_drive_your_research_agenda.html">1702 andrew gelman stats-2013-02-01-Don’t let your standard errors drive your research agenda</a></p>
<p>8 0.94074255 <a title="1702-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-10-I_don%E2%80%99t_like_this_cartoon.html">1572 andrew gelman stats-2012-11-10-I don’t like this cartoon</a></p>
<p>9 0.93970561 <a title="1702-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>10 0.93220037 <a title="1702-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-14-Question_4_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1320 andrew gelman stats-2012-05-14-Question 4 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>11 0.93117523 <a title="1702-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-The_myth_of_the_myth_of_the_myth_of_the_hot_hand.html">2243 andrew gelman stats-2014-03-11-The myth of the myth of the myth of the hot hand</a></p>
<p>12 0.92617178 <a title="1702-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-24-Yet_another_Bayesian_job_opportunity.html">231 andrew gelman stats-2010-08-24-Yet another Bayesian job opportunity</a></p>
<p>13 0.91387284 <a title="1702-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-21-Baseball%E2%80%99s_greatest_fielders.html">623 andrew gelman stats-2011-03-21-Baseball’s greatest fielders</a></p>
<p>14 0.91287386 <a title="1702-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-09-The_boxer%2C_the_wrestler%2C_and_the_coin_flip%2C_again.html">566 andrew gelman stats-2011-02-09-The boxer, the wrestler, and the coin flip, again</a></p>
<p>15 0.91175884 <a title="1702-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-16-Stantastic%21.html">1580 andrew gelman stats-2012-11-16-Stantastic!</a></p>
<p>16 0.90805721 <a title="1702-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-17-Statistics_in_a_world_where_nothing_is_random.html">1628 andrew gelman stats-2012-12-17-Statistics in a world where nothing is random</a></p>
<p>17 0.90588307 <a title="1702-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-23-Traditionalist_claims_that_modern_art_could_just_as_well_be_replaced_by_a_%E2%80%9Cpaint-throwing_chimp%E2%80%9D.html">1390 andrew gelman stats-2012-06-23-Traditionalist claims that modern art could just as well be replaced by a “paint-throwing chimp”</a></p>
<p>18 0.90379548 <a title="1702-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-28-Turing_chess_run_update.html">1473 andrew gelman stats-2012-08-28-Turing chess run update</a></p>
<p>19 0.90128708 <a title="1702-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-09-Solve_mazes_by_starting_at_the_exit.html">459 andrew gelman stats-2010-12-09-Solve mazes by starting at the exit</a></p>
<p>20 0.90006149 <a title="1702-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Visualizing_Distributions_of_Covariance_Matrices.html">1477 andrew gelman stats-2012-08-30-Visualizing Distributions of Covariance Matrices</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
