<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1940 andrew gelman stats-2013-07-16-A poll that throws away data???</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1940" href="#">andrew_gelman_stats-2013-1940</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1940 andrew gelman stats-2013-07-16-A poll that throws away data???</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1940-html" href="http://andrewgelman.com/2013/07/16/a-poll-that-throws-away-data/">html</a></p><p>Introduction: Mark Blumenthal writes: 
  
  
What do you think about the “random rejection” method used by PPP that was attacked at some length today by a Republican pollster.  Our just published post on the debate  includes all the details as I know them. The  Storify of Martino’s tweets  has some additional data tables linked to toward the end.  


Also, more specifically, setting aside Martino’s suggestion of manipulation (which is also quite possible with post-stratification weights), would the PPP method introduce more potential random error than weighting? 
  
From Blumenthal’s blog:
  
B.J. Martino, a senior vice president at the Republican polling firm The Tarrance Group, went on an 30-minute Twitter rant on Tuesday questioning the unorthodox method used by PPP [Public Policy Polling] to select samples and weight data: “Looking at @ppppolls new VA SW. Wondering how many interviews they discarded to get down to 601 completes? Because @ppppolls discards a LOT of interviews. Of 64,811 conducted</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Mark Blumenthal writes:        What do you think about the “random rejection” method used by PPP that was attacked at some length today by a Republican pollster. [sent-1, score-0.142]
</p><p>2 The  Storify of Martino’s tweets  has some additional data tables linked to toward the end. [sent-3, score-0.061]
</p><p>3 Also, more specifically, setting aside Martino’s suggestion of manipulation (which is also quite possible with post-stratification weights), would the PPP method introduce more potential random error than weighting? [sent-4, score-0.268]
</p><p>4 Martino, a senior vice president at the Republican polling firm The Tarrance Group, went on an 30-minute Twitter rant on Tuesday questioning the unorthodox method used by PPP [Public Policy Polling] to select samples and weight data: “Looking at @ppppolls new VA SW. [sent-7, score-0.558]
</p><p>5 Wondering how many interviews they discarded to get down to 601 completes? [sent-8, score-0.281]
</p><p>6 Of 64,811 conducted for @DailyKos /SEIU in 2012, they discarded almost 23K. [sent-10, score-0.109]
</p><p>7 Sure, a handful of the @ppppolls discards were not valid interview responses. [sent-11, score-0.314]
</p><p>8 @ppppolls says discarding interviews is a kind of retroactive quota on race, gender and age. [sent-13, score-0.398]
</p><p>9 PPP’s explanation of how they weight data – PPP’s explanation of their method appears on their “About Us” page: “Our first step in weighting is to survey more than enough people. [sent-18, score-0.619]
</p><p>10 For example, in our polling more women answer relative to men, and not enough African-Americans answer our surveys. [sent-20, score-0.167]
</p><p>11 Our random selection eliminates any potential bias from the rejections, plus it functions like a quota, only after the fact. [sent-21, score-0.238]
</p><p>12 PPP also employs a mathematical weighting scheme that assigns a weight based on each demographic. [sent-22, score-0.447]
</p><p>13 Via email, Martino clarifies: “The random process they use to discard older white female interviews in this case, changes the reported composition of and the opinions of the older white females who remain. [sent-26, score-0.881]
</p><p>14 The discard process can be (can be, not saying is) manipulated to produce desired results. [sent-27, score-0.256]
</p><p>15 Even random discards within a selected sub-group can be the result of choices the pollster made. [sent-28, score-0.369]
</p><p>16 Ultimately, why discard at all when you are already weighting after the fact? [sent-29, score-0.354]
</p><p>17 ”   Response from PPP – In response to an email query, PPP’s Tom Jensen defended his company but not the specific methodology challenged by Martino: “I’m sure there are as many methods for weighting polls as there are polling companies. [sent-30, score-0.521]
</p><p>18 We’ve been doing things the way we do them for over a decade and it’s served us well. [sent-31, score-0.094]
</p><p>19 I admit to being a bit baffled by all of this. [sent-35, score-0.064]
</p><p>20 If this organization is actually going to the trouble of doing full survey interviews on these people, then they definitely shouldn’t be throwing away the responses. [sent-36, score-0.217]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ppp', 0.566), ('martino', 0.354), ('ppppolls', 0.283), ('weighting', 0.199), ('discards', 0.193), ('interviews', 0.172), ('polling', 0.167), ('discard', 0.155), ('weight', 0.141), ('random', 0.122), ('blumenthal', 0.121), ('quota', 0.116), ('discarded', 0.109), ('method', 0.094), ('older', 0.078), ('explanation', 0.07), ('valid', 0.07), ('baffled', 0.064), ('unorthodox', 0.064), ('eliminates', 0.064), ('va', 0.064), ('jensen', 0.064), ('white', 0.063), ('republican', 0.062), ('completes', 0.061), ('rejections', 0.061), ('tweets', 0.061), ('retroactive', 0.058), ('pollster', 0.054), ('clarifies', 0.054), ('employs', 0.054), ('females', 0.053), ('assigns', 0.053), ('email', 0.053), ('manipulated', 0.052), ('discarding', 0.052), ('potential', 0.052), ('challenged', 0.051), ('handful', 0.051), ('defended', 0.051), ('query', 0.05), ('screening', 0.049), ('process', 0.049), ('us', 0.048), ('composition', 0.048), ('attacked', 0.048), ('vice', 0.047), ('served', 0.046), ('survey', 0.045), ('questioning', 0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1940-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-A_poll_that_throws_away_data%3F%3F%3F.html">1940 andrew gelman stats-2013-07-16-A poll that throws away data???</a></p>
<p>Introduction: Mark Blumenthal writes: 
  
  
What do you think about the “random rejection” method used by PPP that was attacked at some length today by a Republican pollster.  Our just published post on the debate  includes all the details as I know them. The  Storify of Martino’s tweets  has some additional data tables linked to toward the end.  


Also, more specifically, setting aside Martino’s suggestion of manipulation (which is also quite possible with post-stratification weights), would the PPP method introduce more potential random error than weighting? 
  
From Blumenthal’s blog:
  
B.J. Martino, a senior vice president at the Republican polling firm The Tarrance Group, went on an 30-minute Twitter rant on Tuesday questioning the unorthodox method used by PPP [Public Policy Polling] to select samples and weight data: “Looking at @ppppolls new VA SW. Wondering how many interviews they discarded to get down to 601 completes? Because @ppppolls discards a LOT of interviews. Of 64,811 conducted</p><p>2 0.13914703 <a title="1940-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-26-Some_thoughts_on_survey_weighting.html">1430 andrew gelman stats-2012-07-26-Some thoughts on survey weighting</a></p>
<p>Introduction: From a comment I made in an email exchange:
 
My  work  on survey adjustments has very much been inspired by the ideas of Rod Little.  Much of my efforts have gone toward the goal of integrating hierarchical modeling (which is so helpful for small-area estimation) with post stratification (which adjusts for known differences between sample and population).  In the surveys I’ve dealt with, nonresponse/nonavailability can be a big issue, and I’ve always tried to emphasize that (a) the probability of a person being included in the sample is just about never known, and (b) even if this probability were known, I’d rather know the empirical n/N than the probability p (which is only valid in expectation).  Regarding nonparametric modeling:  I haven’t done much of that (although I hope to at some point) but Rod and his students have.
 
As I wrote in the first sentence of the above-linked paper, I do think the current theory and practice of survey weighting is a mess, in that much depends on so</p><p>3 0.12111849 <a title="1940-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-19-Analysis_of_survey_data%3A_Design_based_models_vs._hierarchical_modeling%3F.html">352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</a></p>
<p>Introduction: Alban Zeber writes:
  
 
Suppose I have survey data from  say 10 countries where by each country collected the data based on different sampling routines –  the results of this being that  each country has its own weights for the data that can be used in the analyses. If I analyse the data of each country separately then I can incorporate the survey design in the analyses e.g in Stata once can use svyset …..


But what happens when I want to do a pooled analysis of the all the data from the 10 countries:


Presumably either 


1.  I analyse the data from each country separately (using multiple or logistic regression, …) accounting for the survey design and then combine the estimates using a meta analysis (fixed or random)


  OR


2.  Assume that the data from each country is a simple random sample from the population, combine the data from the 10 countries and then use multilevel or hierarchical models


My question is which of the methods is likely to give better estimates?  Or is the</p><p>4 0.10577042 <a title="1940-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-15-Of_forecasts_and_graph_theory_and_characterizing_a_statistical_method_by_the_information_it_uses.html">1214 andrew gelman stats-2012-03-15-Of forecasts and graph theory and characterizing a statistical method by the information it uses</a></p>
<p>Introduction: Wayne Folta points me to  “EigenBracket 2012: Using Graph Theory to Predict NCAA March Madness Basketball”  and writes, “I [Folta] have got to believe that he’s simply re-invented a statistical method in a graph-ish context, but don’t know enough to judge.”
 
I have not looked in detail at the method being presented here—I’m not much of college basketball fan—but I’d like to use this as an excuse to make one of my favorite general point, which is that a good way to characterize any statistical method is by what information it uses. 
   
The basketball ranking method here uses score differentials between teams in the past season.  On the plus side, that is better than simply using one-loss records (which (a) discards score differentials and (b) discards information on who played whom).  On the minus side, the method appears to be discretizing the scores (thus throwing away information on the exact score differential) and doesn’t use any external information such as external ratings.
 
A</p><p>5 0.080806389 <a title="1940-tfidf-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-Blending_results_from_two_relatively_independent_multi-level_models.html">250 andrew gelman stats-2010-09-02-Blending results from two relatively independent multi-level models</a></p>
<p>Introduction: David Shor writes:
  
 
I [Shor] am working on a Bayesian Forecasting model for the Mid-term elections that has two components:


1) A poll aggregation system with pooled and hierarchical house and design effects across every race with polls (Average Standard error for house seat level vote-share ~.055)


2) A Bafumi-style regression that applies national-swing to individual seats. (Average Standard error for house seat level vote-share ~.06)


Since these two estimates are essentially independent, estimates can probably be made more accurate by pooling them together. But If a house effect changes in one draw, that changes estimates in every race. Changes in regression coefficients and National swing have a similar effect.  In the face of high and possibly differing seat-to-seat correlations from each method, I’m not sure what the correct way to “blend” these models would be, either for individual or top-line seat estimates.


In the mean-time, I’m just creating variance-weighted avera</p><p>6 0.079068467 <a title="1940-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-12-Probabilistic_screening_to_get_an_approximate_self-weighted_sample.html">1455 andrew gelman stats-2012-08-12-Probabilistic screening to get an approximate self-weighted sample</a></p>
<p>7 0.077717528 <a title="1940-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-01-Weighting_and_prediction_in_sample_surveys.html">784 andrew gelman stats-2011-07-01-Weighting and prediction in sample surveys</a></p>
<p>8 0.077200927 <a title="1940-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-24-Question_14_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1341 andrew gelman stats-2012-05-24-Question 14 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>9 0.075495437 <a title="1940-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-18-There_are_no_fat_sprinters.html">1905 andrew gelman stats-2013-06-18-There are no fat sprinters</a></p>
<p>10 0.074735887 <a title="1940-tfidf-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-23-Postdoc_with_Huffpost_Pollster_to_do_Bayesian_poll_tracking.html">2221 andrew gelman stats-2014-02-23-Postdoc with Huffpost Pollster to do Bayesian poll tracking</a></p>
<p>11 0.074488424 <a title="1940-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-07-Question_28_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1371 andrew gelman stats-2012-06-07-Question 28 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>12 0.072306849 <a title="1940-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-23-Question_13_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1340 andrew gelman stats-2012-05-23-Question 13 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>13 0.069186836 <a title="1940-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-14-Prior_distribution_for_design_effects.html">85 andrew gelman stats-2010-06-14-Prior distribution for design effects</a></p>
<p>14 0.067139842 <a title="1940-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-Participate_in_a_short_survey_about_the_weight_of_evidence_provided_by_statistics.html">1681 andrew gelman stats-2013-01-19-Participate in a short survey about the weight of evidence provided by statistics</a></p>
<p>15 0.066371709 <a title="1940-tfidf-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-22-Big_Data_needs_Big_Model.html">2343 andrew gelman stats-2014-05-22-Big Data needs Big Model</a></p>
<p>16 0.065529816 <a title="1940-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-17-Statistics_in_a_world_where_nothing_is_random.html">1628 andrew gelman stats-2012-12-17-Statistics in a world where nothing is random</a></p>
<p>17 0.06525708 <a title="1940-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-27-Three_unblinded_mice.html">2115 andrew gelman stats-2013-11-27-Three unblinded mice</a></p>
<p>18 0.062770315 <a title="1940-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-22-Politics_is_not_a_random_walk%3A__Momentum_and_mean_reversion_in_polling.html">364 andrew gelman stats-2010-10-22-Politics is not a random walk:  Momentum and mean reversion in polling</a></p>
<p>19 0.06218699 <a title="1940-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-13-Judea_Pearl_overview_on_causal_inference%2C_and_more_general_thoughts_on_the_reexpression_of_existing_methods_by_considering_their_implicit_assumptions.html">2170 andrew gelman stats-2014-01-13-Judea Pearl overview on causal inference, and more general thoughts on the reexpression of existing methods by considering their implicit assumptions</a></p>
<p>20 0.060863495 <a title="1940-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-08-Is_linear_regression_unethical_in_that_it_gives_more_weight_to_cases_that_are_far_from_the_average%3F.html">1409 andrew gelman stats-2012-07-08-Is linear regression unethical in that it gives more weight to cases that are far from the average?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.112), (1, -0.006), (2, 0.056), (3, -0.027), (4, 0.033), (5, 0.032), (6, -0.013), (7, -0.009), (8, 0.016), (9, -0.028), (10, 0.033), (11, -0.054), (12, 0.005), (13, 0.027), (14, -0.032), (15, 0.011), (16, 0.028), (17, -0.001), (18, 0.024), (19, 0.006), (20, -0.012), (21, -0.007), (22, -0.004), (23, 0.022), (24, -0.021), (25, 0.026), (26, 0.018), (27, 0.018), (28, 0.03), (29, 0.044), (30, -0.004), (31, 0.022), (32, -0.01), (33, 0.039), (34, -0.021), (35, -0.005), (36, 0.003), (37, 0.029), (38, -0.015), (39, 0.016), (40, 0.011), (41, -0.013), (42, 0.037), (43, -0.019), (44, -0.007), (45, 0.027), (46, 0.004), (47, -0.013), (48, 0.02), (49, 0.014)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95421761 <a title="1940-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-A_poll_that_throws_away_data%3F%3F%3F.html">1940 andrew gelman stats-2013-07-16-A poll that throws away data???</a></p>
<p>Introduction: Mark Blumenthal writes: 
  
  
What do you think about the “random rejection” method used by PPP that was attacked at some length today by a Republican pollster.  Our just published post on the debate  includes all the details as I know them. The  Storify of Martino’s tweets  has some additional data tables linked to toward the end.  


Also, more specifically, setting aside Martino’s suggestion of manipulation (which is also quite possible with post-stratification weights), would the PPP method introduce more potential random error than weighting? 
  
From Blumenthal’s blog:
  
B.J. Martino, a senior vice president at the Republican polling firm The Tarrance Group, went on an 30-minute Twitter rant on Tuesday questioning the unorthodox method used by PPP [Public Policy Polling] to select samples and weight data: “Looking at @ppppolls new VA SW. Wondering how many interviews they discarded to get down to 601 completes? Because @ppppolls discards a LOT of interviews. Of 64,811 conducted</p><p>2 0.84952766 <a title="1940-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-01-Weighting_and_prediction_in_sample_surveys.html">784 andrew gelman stats-2011-07-01-Weighting and prediction in sample surveys</a></p>
<p>Introduction: A couple years ago Rod Little was invited to write an article for the diamond jubilee of the Calcutta Statistical Association Bulletin.  His article was published with discussions from Danny Pfefferman, J. N. K. Rao, Don Rubin, and myself. 
 Here it all is .
 
I’ll paste my discussion below, but it’s worth reading the others’ perspectives too.  Especially the part in Rod’s rejoinder where he points out a mistake I made.
  

 
Survey weights, like sausage and legislation, are designed and best appreciated by those who are placed a respectable distance from their manufacture. For those of us working inside the factory, vigorous discussion of methods is appreciated. I enjoyed Rod Little’s review of the connections between modeling and survey weighting and have just a few comments.
 
I like Little’s discussion of model-based shrinkage of post-stratum averages, which, as he notes, can be seen to correspond to shrinkage of weights. I would only add one thing to his formula at the end of his</p><p>3 0.84366918 <a title="1940-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-12-Probabilistic_screening_to_get_an_approximate_self-weighted_sample.html">1455 andrew gelman stats-2012-08-12-Probabilistic screening to get an approximate self-weighted sample</a></p>
<p>Introduction: Sharad had a survey sampling question:
  
We’re trying to use mechanical turk to conduct some surveys, and have quickly discovered that turkers tend to be quite young. We’d really like a representative sample of the U.S., or at the least be able to recruit a diverse enough sample from turk that we can post-stratify to adjust the estimates. The approach we ended up taking is to pay turkers a small amount to answer a couple of screening questions (age & sex), and then probabilistically recruit individuals to complete the full survey (for more money) based on the estimated turk population parameters and our desired target distribution. We use rejection sampling, so the end result is that individuals who are invited to take the full survey look as if they came from a representative sample, at least in terms of age and sex. I’m wondering whether this sort of technique—a two step design in which participants are first screened and then probabilistically selected to mimic a target distributio</p><p>4 0.81469911 <a title="1940-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-18-Is_it_really_true_that_only_8%25_of_people_who_buy_Herbalife_products_are_Herbalife_distributors%3F.html">1679 andrew gelman stats-2013-01-18-Is it really true that only 8% of people who buy Herbalife products are Herbalife distributors?</a></p>
<p>Introduction: A reporter emailed me the other day with a question about a case I’d never heard of before, a company called Herbalife that is being accused of being a pyramid scheme.  The reporter pointed me to  this document  which describes a survey conducted by “a third party firm called Lieberman Research”:
  
Two independent studies took place using real time (aka “river”) sampling, in which respondents 
were intercepted across a wide array of websites


Sample size of 2,000 adults 18+ matched to U.S. census on age, gender, income, region and ethnicity
  
“River sampling” in this case appears to mean, according to the reporter, that “people were invited into it through online ads.”  The survey found that 5% of U.S. households had purchased Herbalife products during the past three months (with a “0.8% margin of error,” ha ha ha).
 
They they did a multiplication and a division to estimate that only 8% of households who bought these products were Herbalife distributors:  480,000 active distributor</p><p>5 0.80525929 <a title="1940-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-26-Some_thoughts_on_survey_weighting.html">1430 andrew gelman stats-2012-07-26-Some thoughts on survey weighting</a></p>
<p>Introduction: From a comment I made in an email exchange:
 
My  work  on survey adjustments has very much been inspired by the ideas of Rod Little.  Much of my efforts have gone toward the goal of integrating hierarchical modeling (which is so helpful for small-area estimation) with post stratification (which adjusts for known differences between sample and population).  In the surveys I’ve dealt with, nonresponse/nonavailability can be a big issue, and I’ve always tried to emphasize that (a) the probability of a person being included in the sample is just about never known, and (b) even if this probability were known, I’d rather know the empirical n/N than the probability p (which is only valid in expectation).  Regarding nonparametric modeling:  I haven’t done much of that (although I hope to at some point) but Rod and his students have.
 
As I wrote in the first sentence of the above-linked paper, I do think the current theory and practice of survey weighting is a mess, in that much depends on so</p><p>6 0.80294532 <a title="1940-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Wacky_surveys_where_they_don%E2%80%99t_tell_you_the_questions_they_asked.html">385 andrew gelman stats-2010-10-31-Wacky surveys where they don’t tell you the questions they asked</a></p>
<p>7 0.79376966 <a title="1940-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-27-Ethical_and_data-integrity_problems_in_a_study_of_mortality_in_Iraq.html">5 andrew gelman stats-2010-04-27-Ethical and data-integrity problems in a study of mortality in Iraq</a></p>
<p>8 0.7874108 <a title="1940-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-10-Estimation_from_an_out-of-date_census.html">405 andrew gelman stats-2010-11-10-Estimation from an out-of-date census</a></p>
<p>9 0.75768244 <a title="1940-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-31-Paying_survey_respondents.html">1437 andrew gelman stats-2012-07-31-Paying survey respondents</a></p>
<p>10 0.75297976 <a title="1940-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-07-Question_28_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1371 andrew gelman stats-2012-06-07-Question 28 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>11 0.73374015 <a title="1940-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-13-A_survey%E2%80%99s_not_a_survey_if_they_don%E2%80%99t_tell_you_how_they_did_it.html">761 andrew gelman stats-2011-06-13-A survey’s not a survey if they don’t tell you how they did it</a></p>
<p>12 0.72685909 <a title="1940-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-24-PPS_in_Georgia.html">107 andrew gelman stats-2010-06-24-PPS in Georgia</a></p>
<p>13 0.72541362 <a title="1940-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-12-Fixing_the_race%2C_ethnicity%2C_and_national_origin_questions_on_the_U.S._Census.html">1978 andrew gelman stats-2013-08-12-Fixing the race, ethnicity, and national origin questions on the U.S. Census</a></p>
<p>14 0.72408873 <a title="1940-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-12-God%2C_Guns%2C_and_Gaydar%3A__The_Laws_of_Probability_Push_You_to_Overestimate_Small_Groups.html">142 andrew gelman stats-2010-07-12-God, Guns, and Gaydar:  The Laws of Probability Push You to Overestimate Small Groups</a></p>
<p>15 0.71432108 <a title="1940-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-28-Using_randomized_incentives_as_an_instrument_for_survey_nonresponse%3F.html">2152 andrew gelman stats-2013-12-28-Using randomized incentives as an instrument for survey nonresponse?</a></p>
<p>16 0.70990884 <a title="1940-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-19-Analysis_of_survey_data%3A_Design_based_models_vs._hierarchical_modeling%3F.html">352 andrew gelman stats-2010-10-19-Analysis of survey data: Design based models vs. hierarchical modeling?</a></p>
<p>17 0.70622897 <a title="1940-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-23-Combining_survey_data_obtained_using_different_modes_of_sampling.html">777 andrew gelman stats-2011-06-23-Combining survey data obtained using different modes of sampling</a></p>
<p>18 0.69343811 <a title="1940-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-10-Hey%2C_where%E2%80%99s_my_kickback%3F.html">78 andrew gelman stats-2010-06-10-Hey, where’s my kickback?</a></p>
<p>19 0.68955576 <a title="1940-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-25-Rechecking_the_census.html">730 andrew gelman stats-2011-05-25-Rechecking the census</a></p>
<p>20 0.68570143 <a title="1940-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-26-What_do_statistical_p-values_mean_when_the_sample_%3D_the_population%3F.html">1511 andrew gelman stats-2012-09-26-What do statistical p-values mean when the sample = the population?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.036), (15, 0.029), (16, 0.068), (21, 0.015), (24, 0.132), (29, 0.192), (34, 0.014), (41, 0.03), (43, 0.016), (53, 0.023), (68, 0.01), (69, 0.025), (86, 0.034), (91, 0.012), (93, 0.011), (95, 0.014), (99, 0.188)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.90158522 <a title="1940-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-27-Huh%3F.html">1915 andrew gelman stats-2013-06-27-Huh?</a></p>
<p>Introduction: I received the following bizarre email:
  
Apr 26, 2013


Dear  Andrew Gelman


You are receiving this notice because you have published a paper with the American Journal of Public Health within the last few years. Currently, content on the Journal is closed access for the first 2 years after publication, and then freely accessible thereafter.  On June 1, 2013, the Journal will be extending its closed-access window from 2 years to 10 years. Extending this window will close public access to your article via the Journal web portal, but public access will still be available via the National Institutes of Health PubMedCentral web portal. 


If you would like to make your article available to the public for free on the Journal web portal, we are extending this limited time offer of open access at a steeply discounted rate of  $1,000 per article. If interested in purchasing this access, please contact Brian Selzer, Publications Editor, at brian.selzer@apha.org


Additionally, you may purchas</p><p>2 0.89372849 <a title="1940-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-06-My_talk_at_Northwestern_University_tomorrow_%28Thursday%29.html">651 andrew gelman stats-2011-04-06-My talk at Northwestern University tomorrow (Thursday)</a></p>
<p>Introduction: Of Beauty, Sex, and Power: Statistical Challenges in Estimating Small Effects.  At the Institute of Policy Research,  Thurs 7 Apr 2011, 3.30pm .
 
Regular blog readers know all about this topic.  ( Here  are the slides.)  But, rest assured, I donâ&euro;&trade;t just mock. I also offer constructive suggestions.
 
My last talk at Northwestern was fifteen years ago.  Actually, I gave two lectures then, in the process of  being turned down for a job enjoying their chilly Midwestern hospitality.
 
P.S.  I searched on the web and also found  this announcement  which gives the wrong title.</p><p>same-blog 3 0.89201033 <a title="1940-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-A_poll_that_throws_away_data%3F%3F%3F.html">1940 andrew gelman stats-2013-07-16-A poll that throws away data???</a></p>
<p>Introduction: Mark Blumenthal writes: 
  
  
What do you think about the “random rejection” method used by PPP that was attacked at some length today by a Republican pollster.  Our just published post on the debate  includes all the details as I know them. The  Storify of Martino’s tweets  has some additional data tables linked to toward the end.  


Also, more specifically, setting aside Martino’s suggestion of manipulation (which is also quite possible with post-stratification weights), would the PPP method introduce more potential random error than weighting? 
  
From Blumenthal’s blog:
  
B.J. Martino, a senior vice president at the Republican polling firm The Tarrance Group, went on an 30-minute Twitter rant on Tuesday questioning the unorthodox method used by PPP [Public Policy Polling] to select samples and weight data: “Looking at @ppppolls new VA SW. Wondering how many interviews they discarded to get down to 601 completes? Because @ppppolls discards a LOT of interviews. Of 64,811 conducted</p><p>4 0.87477887 <a title="1940-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-21-Workshop_on_science_communication_for_graduate_students.html">1687 andrew gelman stats-2013-01-21-Workshop on science communication for graduate students</a></p>
<p>Introduction: Nathan Sanders writes: 
  
  
Applications are now open for the Communicating Science 2013 workshop (http://workshop.astrobites.com/), to be held in Cambridge, MA on June 13-15th, 2013.  Graduate students at US institutions in all fields of science and engineering are encouraged to apply â&euro;&ldquo; funding is available for travel expenses and accommodations.


The application can be found here: http://workshop.astrobites.org/application


Participants will build the communication skills that technical professionals need to express complex ideas to their peers, experts in other fields, and the general public.  There will be panel discussions on the following topics:


* Engaging Non-Scientific Audiences 
* Science Writing for a Cause 
* Communicating Science Through Fiction 
* Sharing Science with Scientists 
* The World of Non-Academic Publishing 
* Communicating using Multimedia and the Web


In addition to these discussions, ample time is allotted for interacting with the experts and with att</p><p>5 0.87141067 <a title="1940-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-14-Examining_US_Legislative_process_with_%E2%80%9CMany_Bills%E2%80%9D.html">764 andrew gelman stats-2011-06-14-Examining US Legislative process with “Many Bills”</a></p>
<p>Introduction: This is  Many Bills , a visualization of US bills by IBM:
 
   
 
 
   
 
I learned about it a few days ago from  Irene Ros  at  Foo Camp . It definitely looks better than my own  analysis  of US Senate  bills .</p><p>6 0.86260855 <a title="1940-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-29-World_Class_Speakers_and_Entertainers.html">1034 andrew gelman stats-2011-11-29-World Class Speakers and Entertainers</a></p>
<p>7 0.83669436 <a title="1940-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-04-Scientific_communication_that_accords_you_%E2%80%9Cthe_basic_human_dignity_of_allowing_you_to_draw_your_own_conclusions%E2%80%9D.html">2051 andrew gelman stats-2013-10-04-Scientific communication that accords you “the basic human dignity of allowing you to draw your own conclusions”</a></p>
<p>8 0.83573431 <a title="1940-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-18-IRB_nightmares.html">1539 andrew gelman stats-2012-10-18-IRB nightmares</a></p>
<p>9 0.83405191 <a title="1940-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-25-Question_15_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1344 andrew gelman stats-2012-05-25-Question 15 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>10 0.83192533 <a title="1940-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>11 0.82861507 <a title="1940-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-13-Flexibility_is_good.html">2133 andrew gelman stats-2013-12-13-Flexibility is good</a></p>
<p>12 0.82146603 <a title="1940-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-10-Update_on_Levitt_paper_on_child_car_seats.html">1491 andrew gelman stats-2012-09-10-Update on Levitt paper on child car seats</a></p>
<p>13 0.82087409 <a title="1940-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-18-You%E2%80%99ll_get_a_high_Type_S_error_rate_if_you_use_classical_statistical_methods_to_analyze_data_from_underpowered_studies.html">1944 andrew gelman stats-2013-07-18-You’ll get a high Type S error rate if you use classical statistical methods to analyze data from underpowered studies</a></p>
<p>14 0.81986678 <a title="1940-lda-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>15 0.81777084 <a title="1940-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-14-If_x_is_correlated_with_y%2C_then_y_is_correlated_with_x.html">1533 andrew gelman stats-2012-10-14-If x is correlated with y, then y is correlated with x</a></p>
<p>16 0.81563962 <a title="1940-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-31-Bayes%3A_radical%2C_liberal%2C_or_conservative%3F.html">639 andrew gelman stats-2011-03-31-Bayes: radical, liberal, or conservative?</a></p>
<p>17 0.80715466 <a title="1940-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-10-Chris_Chabris_is_irritated_by_Malcolm_Gladwell.html">2057 andrew gelman stats-2013-10-10-Chris Chabris is irritated by Malcolm Gladwell</a></p>
<p>18 0.80311537 <a title="1940-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-26-Question_16_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1345 andrew gelman stats-2012-05-26-Question 16 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>19 0.79996991 <a title="1940-lda-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-13-%E2%80%9CThe_truth_wears_off%3A__Is_there_something_wrong_with_the_scientific_method%3F%E2%80%9D.html">466 andrew gelman stats-2010-12-13-“The truth wears off:  Is there something wrong with the scientific method?”</a></p>
<p>20 0.79428577 <a title="1940-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-30-%3F%3F%3F.html">2118 andrew gelman stats-2013-11-30-???</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
