<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1825 andrew gelman stats-2013-04-25-It’s binless!  A program for computing normalizing functions</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1825" href="#">andrew_gelman_stats-2013-1825</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1825 andrew gelman stats-2013-04-25-It’s binless!  A program for computing normalizing functions</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1825-html" href="http://andrewgelman.com/2013/04/25/its-binless-a-program-for-computing-normalizing-functions/">html</a></p><p>Introduction: Zhiqiang Tan writes:
  
I have created  an R package  to implement the full likelihood method in Kong et al. (2003). The method can be seen as a binless extension of so-called Weighted Histogram Analysis Method (UWHAM) widely used in physics and chemistry. The method has also been introduced to the physics literature and called the Multivariate Bennet Acceptance Ratio (MBAR) method. But a key point of my implementation is to compute the free energy estimates by minimizing a convex function, instead of solving nonlinear equations by the self-consistency or the Newton-Raphson algorithm.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Zhiqiang Tan writes:    I have created  an R package  to implement the full likelihood method in Kong et al. [sent-1, score-1.133]
</p><p>2 The method can be seen as a binless extension of so-called Weighted Histogram Analysis Method (UWHAM) widely used in physics and chemistry. [sent-3, score-1.113]
</p><p>3 The method has also been introduced to the physics literature and called the Multivariate Bennet Acceptance Ratio (MBAR) method. [sent-4, score-1.015]
</p><p>4 But a key point of my implementation is to compute the free energy estimates by minimizing a convex function, instead of solving nonlinear equations by the self-consistency or the Newton-Raphson algorithm. [sent-5, score-1.81]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('method', 0.378), ('physics', 0.257), ('kong', 0.245), ('tan', 0.234), ('convex', 0.226), ('minimizing', 0.209), ('histogram', 0.2), ('extension', 0.186), ('equations', 0.177), ('weighted', 0.175), ('solving', 0.173), ('nonlinear', 0.168), ('acceptance', 0.168), ('implement', 0.161), ('introduced', 0.157), ('ratio', 0.156), ('implementation', 0.155), ('multivariate', 0.154), ('energy', 0.145), ('compute', 0.145), ('created', 0.14), ('widely', 0.139), ('algorithm', 0.137), ('package', 0.136), ('likelihood', 0.114), ('function', 0.114), ('et', 0.11), ('key', 0.097), ('literature', 0.096), ('free', 0.095), ('full', 0.094), ('called', 0.093), ('seen', 0.091), ('estimates', 0.089), ('instead', 0.084), ('used', 0.062), ('analysis', 0.056), ('point', 0.047), ('writes', 0.039), ('also', 0.034)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1825-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-25-It%E2%80%99s_binless%21__A_program_for_computing_normalizing_functions.html">1825 andrew gelman stats-2013-04-25-It’s binless!  A program for computing normalizing functions</a></p>
<p>Introduction: Zhiqiang Tan writes:
  
I have created  an R package  to implement the full likelihood method in Kong et al. (2003). The method can be seen as a binless extension of so-called Weighted Histogram Analysis Method (UWHAM) widely used in physics and chemistry. The method has also been introduced to the physics literature and called the Multivariate Bennet Acceptance Ratio (MBAR) method. But a key point of my implementation is to compute the free energy estimates by minimizing a convex function, instead of solving nonlinear equations by the self-consistency or the Newton-Raphson algorithm.</p><p>2 0.12834077 <a title="1825-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-19-Will_Stan_work_well_with_40%C3%9740_matrices%3F.html">861 andrew gelman stats-2011-08-19-Will Stan work well with 40×40 matrices?</a></p>
<p>Introduction: Tomas Iesmantas writes:
  
I’m dealing with high dimensional (40-50 parameters) hierarchical bayesian model applied to nonlinear Poisson regression problem.


Now I’m using an adaptive version for the Metropolis adjusted Langevin algorithm with a truncated drift (Yves F. Atchade, 2003) to obtain samples from posterior.


But this algorithm is not very efficient in my case, it needs several millions iterations as burn-in period. And simulation takes quite a long time, since algorithm has to work with 40×40 matrices.


Maybe you know another MCMC algorithm which could take not so many burn-in samples and would be able to deal with nonlinear regression? In non-hierarchical nonlinear regression model adaptive metropolis algorithm is enough, but in hierarchical case I could use something more effective.
  
My reply:
 
Try fitting the model in Stan.  If that doesn’t work, let me know.</p><p>3 0.1283406 <a title="1825-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-20-Likelihood_thresholds_and_decisions.html">1422 andrew gelman stats-2012-07-20-Likelihood thresholds and decisions</a></p>
<p>Introduction: David Hogg points me to  this  discussion:
  
Martin Strasbourg and I [Hogg] discussed his project to detect new satellites of M31 in the PAndAS survey. He can construct a likelihood ratio (possibly even a marginalized likelihood ratio) at every position in the M31 imaging, between the best-fit satellite-plus-background model and the best nothing-plus-background model. He can make a two-dimensional map of these likelihood ratios and show a the histogram of them. Looking at this histogram, which has a tail to very large ratios, he asked me, where should I put my cut? That is, at what likelihood ratio does a candidate deserve follow-up? Here’s my unsatisfying answer:


To a statistician, the distribution of likelihood ratios is interesting and valuable to study. To an astronomer, it is uninteresting. You don’t want to know the distribution of likelihoods, you want to find satellites . . .
  
I wrote that I think this makes sense and that it would actualy be an interesting and useful rese</p><p>4 0.12736434 <a title="1825-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-15-Of_forecasts_and_graph_theory_and_characterizing_a_statistical_method_by_the_information_it_uses.html">1214 andrew gelman stats-2012-03-15-Of forecasts and graph theory and characterizing a statistical method by the information it uses</a></p>
<p>Introduction: Wayne Folta points me to  “EigenBracket 2012: Using Graph Theory to Predict NCAA March Madness Basketball”  and writes, “I [Folta] have got to believe that he’s simply re-invented a statistical method in a graph-ish context, but don’t know enough to judge.”
 
I have not looked in detail at the method being presented here—I’m not much of college basketball fan—but I’d like to use this as an excuse to make one of my favorite general point, which is that a good way to characterize any statistical method is by what information it uses. 
   
The basketball ranking method here uses score differentials between teams in the past season.  On the plus side, that is better than simply using one-loss records (which (a) discards score differentials and (b) discards information on who played whom).  On the minus side, the method appears to be discretizing the scores (thus throwing away information on the exact score differential) and doesn’t use any external information such as external ratings.
 
A</p><p>5 0.12718695 <a title="1825-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-14-%E2%80%9CFree_energy%E2%80%9D_and_economic_resources.html">1010 andrew gelman stats-2011-11-14-“Free energy” and economic resources</a></p>
<p>Introduction: By “free energy” I don’t mean perpetual motion machines, cars that run on water and get 200 mpg, or the latest cold-fusion hype.
 
No, I’m referring to the term from physics.  The free energy of a system is, roughly, the amount of energy that can be directly extracted from it.  For example, a rock at room temperature is just  full  of energy—not just the energy locked in its nuclei, but basic thermal energy—but at room temperature you can’t extract any of it.
 
To the physicists in the audience:  Yes, I realize that free energy has a technical meaning in statistical mechanics and that my above definition is sloppy.  Please bear with me.  And, to the non-physicists:  feel free to head to Wikipedia or a physics textbook for a more careful treatment.
 
I was thinking about free energy the other day when hearing someone on the radio say something about China bailing out the E.U.  I did a double-take.  Huh?  The E.U. is rich, China’s not so rich.  How can a middle-income country bail out a</p><p>6 0.11247364 <a title="1825-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-15-Weakly_informative_priors_and_imprecise_probabilities.html">468 andrew gelman stats-2010-12-15-Weakly informative priors and imprecise probabilities</a></p>
<p>7 0.10770394 <a title="1825-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-01-Heller%2C_Heller%2C_and_Gorfine_on_univariate_and_multivariate_information_measures.html">2314 andrew gelman stats-2014-05-01-Heller, Heller, and Gorfine on univariate and multivariate information measures</a></p>
<p>8 0.10399823 <a title="1825-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-19-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1019 andrew gelman stats-2011-11-19-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>9 0.10122589 <a title="1825-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-12-Samplers_for_Big_Science%3A__emcee_and_BAT.html">2020 andrew gelman stats-2013-09-12-Samplers for Big Science:  emcee and BAT</a></p>
<p>10 0.099438168 <a title="1825-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-23-Physics_is_hard.html">626 andrew gelman stats-2011-03-23-Physics is hard</a></p>
<p>11 0.098845065 <a title="1825-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-05-Monitor_the_efficiency_of_your_Markov_chain_sampler_using_expected_squared_jumped_distance%21.html">650 andrew gelman stats-2011-04-05-Monitor the efficiency of your Markov chain sampler using expected squared jumped distance!</a></p>
<p>12 0.096967645 <a title="1825-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-21-Fundamental_difficulty_of_inference_for_a_ratio_when_the_denominator_could_be_positive_or_negative.html">775 andrew gelman stats-2011-06-21-Fundamental difficulty of inference for a ratio when the denominator could be positive or negative</a></p>
<p>13 0.094513975 <a title="1825-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-16-Update_on_the_generalized_method_of_moments.html">519 andrew gelman stats-2011-01-16-Update on the generalized method of moments</a></p>
<p>14 0.092067115 <a title="1825-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-21-Literary_blurb_translation_guide.html">723 andrew gelman stats-2011-05-21-Literary blurb translation guide</a></p>
<p>15 0.092062704 <a title="1825-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-01-Tukey%E2%80%99s_philosophy.html">496 andrew gelman stats-2011-01-01-Tukey’s philosophy</a></p>
<p>16 0.08831843 <a title="1825-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-16-Mr._Pearson%2C_meet_Mr._Mandelbrot%3A__Detecting_Novel_Associations_in_Large_Data_Sets.html">1062 andrew gelman stats-2011-12-16-Mr. Pearson, meet Mr. Mandelbrot:  Detecting Novel Associations in Large Data Sets</a></p>
<p>17 0.085600972 <a title="1825-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-R_package_for_Bayes_factors.html">1682 andrew gelman stats-2013-01-19-R package for Bayes factors</a></p>
<p>18 0.084612116 <a title="1825-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-20-Thermodynamic_Monte_Carlo%3A__Michael_Betancourt%E2%80%99s_new_method_for_simulating_from_difficult_distributions_and_evaluating_normalizing_constants.html">2340 andrew gelman stats-2014-05-20-Thermodynamic Monte Carlo:  Michael Betancourt’s new method for simulating from difficult distributions and evaluating normalizing constants</a></p>
<p>19 0.080897629 <a title="1825-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-How_does_Bayes_do_it%3F.html">247 andrew gelman stats-2010-09-01-How does Bayes do it?</a></p>
<p>20 0.079310365 <a title="1825-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-03-Statistical_methods_that_work_in_some_settings_but_not_others.html">1560 andrew gelman stats-2012-11-03-Statistical methods that work in some settings but not others</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.082), (1, 0.064), (2, 0.001), (3, 0.001), (4, 0.03), (5, 0.008), (6, 0.01), (7, -0.037), (8, -0.013), (9, -0.024), (10, 0.002), (11, -0.027), (12, -0.024), (13, -0.019), (14, -0.01), (15, -0.021), (16, 0.008), (17, 0.023), (18, 0.006), (19, -0.039), (20, 0.027), (21, 0.002), (22, 0.022), (23, 0.05), (24, 0.048), (25, 0.016), (26, 0.005), (27, 0.054), (28, 0.101), (29, 0.018), (30, 0.042), (31, 0.081), (32, 0.066), (33, -0.011), (34, 0.011), (35, -0.025), (36, -0.024), (37, 0.026), (38, -0.025), (39, -0.01), (40, 0.003), (41, 0.028), (42, -0.001), (43, 0.055), (44, 0.023), (45, -0.056), (46, -0.028), (47, 0.004), (48, -0.015), (49, 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98869818 <a title="1825-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-25-It%E2%80%99s_binless%21__A_program_for_computing_normalizing_functions.html">1825 andrew gelman stats-2013-04-25-It’s binless!  A program for computing normalizing functions</a></p>
<p>Introduction: Zhiqiang Tan writes:
  
I have created  an R package  to implement the full likelihood method in Kong et al. (2003). The method can be seen as a binless extension of so-called Weighted Histogram Analysis Method (UWHAM) widely used in physics and chemistry. The method has also been introduced to the physics literature and called the Multivariate Bennet Acceptance Ratio (MBAR) method. But a key point of my implementation is to compute the free energy estimates by minimizing a convex function, instead of solving nonlinear equations by the self-consistency or the Newton-Raphson algorithm.</p><p>2 0.70265466 <a title="1825-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-01-Heller%2C_Heller%2C_and_Gorfine_on_univariate_and_multivariate_information_measures.html">2314 andrew gelman stats-2014-05-01-Heller, Heller, and Gorfine on univariate and multivariate information measures</a></p>
<p>Introduction: Malka Gorfine writes:
  
We noticed that the important topic of association measures and tests  came up again  in your blog, and we have few comments in this regard.


It is useful to distinguish between the univariate and multivariate methods. A consistent multivariate method can recognise dependence between two vectors of random variables, while a univariate method can only loop over pairs of components and check for dependency between them.


There are very few consistent multivariate methods. To the best of our  knowledge there are three practical methods:


1) HSIC by Gretton et al. (http://www.gatsby.ucl.ac.uk/~gretton/papers/GreBouSmoSch05.pdf)


2) dcov by Szekely et al. (http://projecteuclid.org/euclid.aoas/1267453933)


3) A method we introduced in Heller et al (Biometrika, 2013, 503—510, http://biomet.oxfordjournals.org/content/early/2012/12/04/biomet.ass070.full.pdf+html, and an R package, HHG, is available as well http://cran.r-project.org/web/packages/HHG/index.html).


A</p><p>3 0.68418598 <a title="1825-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-26-Further_thoughts_on_nonparametric_correlation_measures.html">1230 andrew gelman stats-2012-03-26-Further thoughts on nonparametric correlation measures</a></p>
<p>Introduction: Malka Gorfine, Ruth Heller, and Yair Heller write a comment on the paper of Reshef et al. that we  discussed  a few months ago.
 
Just to remind you what’s going on here, here’s my quick summary from December:
  
Reshef et al. propose a new nonlinear R-squared-like measure.


Unlike R-squared, this new method depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way. The dependence on scale is inevitable for such a general method. Just consider: if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data. So the scale of the fit matters.


The clever idea of the paper is that, instead of going for an absolute measure (which, as we’ve seen, will be scale-dependent), they focus on the problem of summarizing the grid of pairwise dependences in a large set of variables. As they put it: “Imagine a data set with hundreds</p><p>4 0.63953209 <a title="1825-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-16-Mr._Pearson%2C_meet_Mr._Mandelbrot%3A__Detecting_Novel_Associations_in_Large_Data_Sets.html">1062 andrew gelman stats-2011-12-16-Mr. Pearson, meet Mr. Mandelbrot:  Detecting Novel Associations in Large Data Sets</a></p>
<p>Introduction: Jeremy Fox asks what I think about  this paper  by David N. Reshef, Yakir Reshef, Hilary Finucane, Sharon  Grossman, Gilean McVean, Peter Turnbaugh, Eric Lander, Michael Mitzenmacher, and Pardis Sabeti which proposes a new nonlinear R-squared-like measure.
 
My quick answer is that it looks really cool!
 
From my quick reading of the paper, it appears that the method reduces on average to the usual R-squared when fit to data of the form y = a + bx + error, and that it also has a similar interpretation when “a + bx” is replaced by other continuous functions.
 
Unlike R-squared, the method of Reshef et al. depends on a tuning parameter that controls the level of discretization, in a “How long is the coast of Britain” sort of way.  The dependence on scale is inevitable for such a general method.  Just consider:  if you sample 1000 points from the unit bivariate normal distribution, (x,y) ~ N(0,I), you’ll be able to fit them perfectly by a 999-degree polynomial fit to the data.  So the sca</p><p>5 0.61746031 <a title="1825-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Bayesian_Uncertainty_Quantification_for_Differential_Equations%21.html">2311 andrew gelman stats-2014-04-29-Bayesian Uncertainty Quantification for Differential Equations!</a></p>
<p>Introduction: Mark Girolami points us to  this paper and software  (with Oksana Chkrebtii, David Campbell, and Ben Calderhead).  They write:
  
We develop a general methodology for the probabilistic integration of differential equations via model based updating of a joint prior measure on the space of functions and their temporal and spatial derivatives. This results in a posterior measure over functions reflecting how well they satisfy the system of differential equations and corresponding initial and boundary values. We show how this posterior measure can be naturally incorporated within the Kennedy and O’Hagan framework for uncertainty quantification and provides a fully Bayesian approach to model calibration. . . . A broad variety of examples are provided to illustrate the potential of this framework for characterising discretization uncertainty, including initial value, delay, and boundary value differential equations, as well as partial differential equations. We also demonstrate our methodolo</p><p>6 0.61351335 <a title="1825-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-04-Too_many_MC%E2%80%99s_not_enough_MIC%E2%80%99s%2C_or_What_principles_should_govern_attempts_to_summarize_bivariate_associations_in_large_multivariate_datasets%3F.html">1706 andrew gelman stats-2013-02-04-Too many MC’s not enough MIC’s, or What principles should govern attempts to summarize bivariate associations in large multivariate datasets?</a></p>
<p>7 0.61145198 <a title="1825-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>8 0.61135978 <a title="1825-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-14-The_maximal_information_coefficient.html">2247 andrew gelman stats-2014-03-14-The maximal information coefficient</a></p>
<p>9 0.58863235 <a title="1825-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-16-Update_on_the_generalized_method_of_moments.html">519 andrew gelman stats-2011-01-16-Update on the generalized method of moments</a></p>
<p>10 0.57370305 <a title="1825-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<p>11 0.57109743 <a title="1825-lsi-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-20-Thermodynamic_Monte_Carlo%3A__Michael_Betancourt%E2%80%99s_new_method_for_simulating_from_difficult_distributions_and_evaluating_normalizing_constants.html">2340 andrew gelman stats-2014-05-20-Thermodynamic Monte Carlo:  Michael Betancourt’s new method for simulating from difficult distributions and evaluating normalizing constants</a></p>
<p>12 0.56517559 <a title="1825-lsi-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-29-Hamiltonian_Monte_Carlo_stories.html">931 andrew gelman stats-2011-09-29-Hamiltonian Monte Carlo stories</a></p>
<p>13 0.56114775 <a title="1825-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-The_first_version_of_my_%E2%80%9Cinference_from_iterative_simulation_using_parallel_sequences%E2%80%9D_paper%21.html">1309 andrew gelman stats-2012-05-09-The first version of my “inference from iterative simulation using parallel sequences” paper!</a></p>
<p>14 0.55212843 <a title="1825-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-30-Works_well_versus_well_understood.html">738 andrew gelman stats-2011-05-30-Works well versus well understood</a></p>
<p>15 0.54013413 <a title="1825-lsi-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-07-Once_more_on_nonparametric_measures_of_mutual_information.html">2324 andrew gelman stats-2014-05-07-Once more on nonparametric measures of mutual information</a></p>
<p>16 0.53005236 <a title="1825-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-03-Running_into_a_Stan_Reference_by_Accident.html">2231 andrew gelman stats-2014-03-03-Running into a Stan Reference by Accident</a></p>
<p>17 0.52755934 <a title="1825-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<p>18 0.52665913 <a title="1825-lsi-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-05-Monitor_the_efficiency_of_your_Markov_chain_sampler_using_expected_squared_jumped_distance%21.html">650 andrew gelman stats-2011-04-05-Monitor the efficiency of your Markov chain sampler using expected squared jumped distance!</a></p>
<p>19 0.52362943 <a title="1825-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-23-Parallel_JAGS_RNGs.html">818 andrew gelman stats-2011-07-23-Parallel JAGS RNGs</a></p>
<p>20 0.51639056 <a title="1825-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.057), (15, 0.026), (16, 0.145), (24, 0.102), (43, 0.029), (79, 0.185), (82, 0.022), (86, 0.023), (95, 0.025), (99, 0.252)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94804418 <a title="1825-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-25-It%E2%80%99s_binless%21__A_program_for_computing_normalizing_functions.html">1825 andrew gelman stats-2013-04-25-It’s binless!  A program for computing normalizing functions</a></p>
<p>Introduction: Zhiqiang Tan writes:
  
I have created  an R package  to implement the full likelihood method in Kong et al. (2003). The method can be seen as a binless extension of so-called Weighted Histogram Analysis Method (UWHAM) widely used in physics and chemistry. The method has also been introduced to the physics literature and called the Multivariate Bennet Acceptance Ratio (MBAR) method. But a key point of my implementation is to compute the free energy estimates by minimizing a convex function, instead of solving nonlinear equations by the self-consistency or the Newton-Raphson algorithm.</p><p>2 0.94027257 <a title="1825-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-14-Cool-ass_signal_processing_using_Gaussian_processes_%28birthdays_again%29.html">1379 andrew gelman stats-2012-06-14-Cool-ass signal processing using Gaussian processes (birthdays again)</a></p>
<p>Introduction: Aki writes:
  
Here’s my version of the  birthday frequency graph . I used Gaussian process with two slowly varying components and periodic component with decay, so that periodic form can change in time. I used Student’s t-distribution as observation model to allow exceptional dates to be outliers. I guess that periodic component due to week effect is still in the data because there is data only from twenty years. Naturally it would be better to model the whole timeseries, but it was easier to just use the cvs by Mulligan.
  
   
 
ALl I can say is . . . wow.  Bayes wins again.  Maybe Aki can supply the R or Matlab code?
 
P.S.  And let’s not forget how great the simple and clear time series plots are, compared to various fancy visualizations that people might try.
 
P.P.S.  More  here .</p><p>3 0.93741846 <a title="1825-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-08-How_adoption_speed_affects_the_abandonment_of_cultural_tastes.html">845 andrew gelman stats-2011-08-08-How adoption speed affects the abandonment of cultural tastes</a></p>
<p>Introduction: Interesting  article  by Jonah Berger and Gael Le Mens:
  
Products, styles, and social movements often catch on and become popular, but little is known about why such identity-relevant cultural tastes and practices die out. We demonstrate that the velocity of adoption may affect abandonment: Analysis of over 100 years of data on first-name adoption in both France and the United States illustrates that cultural tastes that have been adopted quickly die faster (i.e., are less likely to persist). Mirroring this aggregate pattern, at the individual level, expecting parents are more hesitant to adopt names that recently experienced sharper increases in adoption. Further analysis indicate that these effects are driven by concerns about symbolic value: Fads are perceived negatively, so people avoid identity-relevant items with sharply increasing popularity because they believe that they will be short lived. Ancillary analyses also indicate that, in contrast to conventional wisdom, identity-r</p><p>4 0.92724442 <a title="1825-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-18-Bob_on_Stan.html">1126 andrew gelman stats-2012-01-18-Bob on Stan</a></p>
<p>Introduction: Thurs 19 Jan 7pm  at the NYC Machine Learning meetup.
 
 Stan ‘s entirely publicly funded and open-source and it has  no secrets .  Ask us about it and we’ll tell you everything you might want to know.
 
P.S.  And  here ‘s the talk.</p><p>5 0.91395915 <a title="1825-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-29-Jost_Haidt.html">1515 andrew gelman stats-2012-09-29-Jost Haidt</a></p>
<p>Introduction: Research psychologist John Jost  reviews  the recent book, “The Righteous Mind,” by research psychologist Jonathan Haidt.  Some of my thoughts on Haidt’s book are  here .  And here’s some of Jost’s review:
  
Haidt’s book is creative, interesting, and provocative. . . . The book shines a new light on moral psychology and presents a bold, confrontational message. From a scientific perspective, however, I worry that his theory raises more questions than it answers. Why do some individuals feel that it is morally good (or necessary) to obey authority, favor the ingroup, and maintain purity, whereas others are skeptical? (Perhaps parenting style is relevant after all.) Why do some people think that it is morally acceptable to judge or even mistreat others such as gay or lesbian couples or, only a generation ago, interracial couples because they dislike or feel disgusted by them, whereas others do not? Why does the present generation “care about violence toward many more classes of victims</p><p>6 0.8919071 <a title="1825-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-16-2500_people_living_in_a_park_in_Chicago%3F.html">469 andrew gelman stats-2010-12-16-2500 people living in a park in Chicago?</a></p>
<p>7 0.88730943 <a title="1825-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-21-Bad_graph.html">863 andrew gelman stats-2011-08-21-Bad graph</a></p>
<p>8 0.88404155 <a title="1825-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-19-Happy_birthday.html">2139 andrew gelman stats-2013-12-19-Happy birthday</a></p>
<p>9 0.88216817 <a title="1825-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-17-Rust.html">1538 andrew gelman stats-2012-10-17-Rust</a></p>
<p>10 0.87966269 <a title="1825-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-17-Rare_name_analysis_and_wealth_convergence.html">1172 andrew gelman stats-2012-02-17-Rare name analysis and wealth convergence</a></p>
<p>11 0.87963879 <a title="1825-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-DBQQ_rounding_for_labeling_charts_and_communicating_tolerances.html">939 andrew gelman stats-2011-10-03-DBQQ rounding for labeling charts and communicating tolerances</a></p>
<p>12 0.87587547 <a title="1825-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-05-A_story_of_fake-data_checking_being_used_to_shoot_down_a_flawed_analysis_at_the_Farm_Credit_Agency.html">1884 andrew gelman stats-2013-06-05-A story of fake-data checking being used to shoot down a flawed analysis at the Farm Credit Agency</a></p>
<p>13 0.85633409 <a title="1825-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-03-Hierarchical_array_priors_for_ANOVA_decompositions.html">1786 andrew gelman stats-2013-04-03-Hierarchical array priors for ANOVA decompositions</a></p>
<p>14 0.85382581 <a title="1825-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-06-The_K_Foundation_burns_Cosma%E2%80%99s_turkey.html">1044 andrew gelman stats-2011-12-06-The K Foundation burns Cosma’s turkey</a></p>
<p>15 0.8467083 <a title="1825-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-23-Popular_governor%2C_small_state.html">159 andrew gelman stats-2010-07-23-Popular governor, small state</a></p>
<p>16 0.84156603 <a title="1825-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-03-Kuhn%2C_1-f_noise%2C_and_the_fractal_nature_of_scientific_revolutions.html">1924 andrew gelman stats-2013-07-03-Kuhn, 1-f noise, and the fractal nature of scientific revolutions</a></p>
<p>17 0.84066939 <a title="1825-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-29-The_Conservative_States_of_America.html">636 andrew gelman stats-2011-03-29-The Conservative States of America</a></p>
<p>18 0.83898187 <a title="1825-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>19 0.83653826 <a title="1825-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>20 0.83480245 <a title="1825-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-13-Ethical_concerns_in_medical_trials.html">411 andrew gelman stats-2010-11-13-Ethical concerns in medical trials</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
