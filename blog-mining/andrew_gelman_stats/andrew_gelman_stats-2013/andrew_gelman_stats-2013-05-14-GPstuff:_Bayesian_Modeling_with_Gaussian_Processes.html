<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1856" href="#">andrew_gelman_stats-2013-1856</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1856-html" href="http://andrewgelman.com/2013/05/14/gpstuff-bayesian-modeling-with-gaussian-processes/">html</a></p><p>Introduction: I think it’s part of my duty as a blogger to intersperse, along with the steady flow of jokes, rants, and literary criticism, some material that will actually be useful to you.
 
So here goes.
 
Jarno Vanhatalo, Jaakko Riihimäki, Jouni Hartikainen, Pasi Jylänki, Ville Tolvanen, and Aki Vehtari  write :
  
The  GPstuff  toolbox is a versatile collection of Gaussian process models and computational tools required for Bayesian inference. The tools include, among others, various inference methods, sparse approximations and model assessment methods.
  
We can actually now fit Gaussian processes in  Stan .  But for big problems (or even moderately-sized problems), full Bayes can be slow.  GPstuff uses EP, which is faster.  At some point we’d like to implement EP in Stan.  (Right now we’re working with Dave Blei to implement VB.)
 
GPstuff really works.  I saw Aki use it to fit a nonparametric version of the Bangladesh well-switching example in ARM.  He was sitting in his office and just whip</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I think it’s part of my duty as a blogger to intersperse, along with the steady flow of jokes, rants, and literary criticism, some material that will actually be useful to you. [sent-1, score-0.816]
</p><p>2 Jarno Vanhatalo, Jaakko Riihimäki, Jouni Hartikainen, Pasi Jylänki, Ville Tolvanen, and Aki Vehtari  write :    The  GPstuff  toolbox is a versatile collection of Gaussian process models and computational tools required for Bayesian inference. [sent-3, score-0.638]
</p><p>3 The tools include, among others, various inference methods, sparse approximations and model assessment methods. [sent-4, score-0.672]
</p><p>4 We can actually now fit Gaussian processes in  Stan . [sent-5, score-0.326]
</p><p>5 But for big problems (or even moderately-sized problems), full Bayes can be slow. [sent-6, score-0.151]
</p><p>6 At some point we’d like to implement EP in Stan. [sent-8, score-0.206]
</p><p>7 (Right now we’re working with Dave Blei to implement VB. [sent-9, score-0.206]
</p><p>8 I saw Aki use it to fit a nonparametric version of the Bangladesh well-switching example in ARM. [sent-11, score-0.415]
</p><p>9 He was sitting in his office and just whipped up the model and fit it. [sent-12, score-0.575]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gpstuff', 0.469), ('ep', 0.289), ('aki', 0.231), ('implement', 0.206), ('gaussian', 0.202), ('whipped', 0.166), ('bangladesh', 0.166), ('intersperse', 0.166), ('jaakko', 0.166), ('tools', 0.164), ('fit', 0.161), ('jouni', 0.156), ('toolbox', 0.156), ('vehtari', 0.144), ('blei', 0.144), ('rants', 0.131), ('steady', 0.122), ('jokes', 0.122), ('approximations', 0.117), ('flow', 0.116), ('duty', 0.116), ('sparse', 0.114), ('nonparametric', 0.106), ('literary', 0.106), ('dave', 0.106), ('blogger', 0.102), ('assessment', 0.102), ('sitting', 0.096), ('processes', 0.093), ('collection', 0.091), ('problems', 0.091), ('office', 0.087), ('computational', 0.084), ('required', 0.08), ('uses', 0.079), ('material', 0.075), ('saw', 0.075), ('criticism', 0.074), ('bayes', 0.073), ('version', 0.073), ('actually', 0.072), ('stan', 0.072), ('model', 0.065), ('process', 0.063), ('full', 0.06), ('include', 0.059), ('among', 0.057), ('along', 0.054), ('useful', 0.053), ('inference', 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1856-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-14-GPstuff%3A_Bayesian_Modeling_with_Gaussian_Processes.html">1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</a></p>
<p>Introduction: I think it’s part of my duty as a blogger to intersperse, along with the steady flow of jokes, rants, and literary criticism, some material that will actually be useful to you.
 
So here goes.
 
Jarno Vanhatalo, Jaakko Riihimäki, Jouni Hartikainen, Pasi Jylänki, Ville Tolvanen, and Aki Vehtari  write :
  
The  GPstuff  toolbox is a versatile collection of Gaussian process models and computational tools required for Bayesian inference. The tools include, among others, various inference methods, sparse approximations and model assessment methods.
  
We can actually now fit Gaussian processes in  Stan .  But for big problems (or even moderately-sized problems), full Bayes can be slow.  GPstuff uses EP, which is faster.  At some point we’d like to implement EP in Stan.  (Right now we’re working with Dave Blei to implement VB.)
 
GPstuff really works.  I saw Aki use it to fit a nonparametric version of the Bangladesh well-switching example in ARM.  He was sitting in his office and just whip</p><p>2 0.27090484 <a title="1856-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-18-EP_and_ABC.html">2067 andrew gelman stats-2013-10-18-EP and ABC</a></p>
<p>Introduction: Expectation propagation and approximate Bayesian computation.
 
Here are X’s  comments  on a paper, “Expectation-Propagation for Likelihood-Free Inference,” by Simon Barthelme and Nicolas Chopin.  The paper is not new but the topic is still hot.
 
Also there’s  this paper  by Maurizio Filippone and Mark Girolami on computation for Gaussian process models.  I wonder how this connects to  GPstuff , which I think is what Aki did to fit the birthdays model:
 
 
 
This stuff is where it’s at.</p><p>3 0.18247622 <a title="1856-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-19-Slick_time_series_decomposition_of_the_birthdays_data.html">1384 andrew gelman stats-2012-06-19-Slick time series decomposition of the birthdays data</a></p>
<p>Introduction: Aki  updates :
  
Here is my plot using the full time series data to make the model. 
Data analysis could be made in many different ways, but my hammer is Gaussian process, and so I modeled the data with a Gaussian process with six components 
1) slowly changing trend 
2) 7 day periodical component capturing day of week effect 
3) 365.25 day periodical component capturing day of year effect 
4) component to take into account the special days and interaction with weekends 
5) small time scale correlating noise 
6) independent Gaussian noise


- Day of the week effect has been increasing in 80′s 
- Day of year effect has changed only a little during years 
- 22nd to 31st December is strange time


I [Aki] will make the code available this week, but we have to first make new release of our GPstuff toolbox, as I used our development code to do this.
  
   
 
I have no idea what’s going on with 29 Feb; I wouldn’t see why births would be less likely on that day.  Also, the above graphs are g</p><p>4 0.13984649 <a title="1856-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-19-Happy_birthday.html">2139 andrew gelman stats-2013-12-19-Happy birthday</a></p>
<p>Introduction: (Click for bigger image.)
 
The above is Akiâ&euro;&trade;s decomposition of the birthdays data (the number of babies born each day in the United States, from 1968 through 1988) using a Gaussian process model, as described in more detail in  our book .</p><p>5 0.12046277 <a title="1856-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-14-Cool-ass_signal_processing_using_Gaussian_processes_%28birthdays_again%29.html">1379 andrew gelman stats-2012-06-14-Cool-ass signal processing using Gaussian processes (birthdays again)</a></p>
<p>Introduction: Aki writes:
  
Here’s my version of the  birthday frequency graph . I used Gaussian process with two slowly varying components and periodic component with decay, so that periodic form can change in time. I used Student’s t-distribution as observation model to allow exceptional dates to be outliers. I guess that periodic component due to week effect is still in the data because there is data only from twenty years. Naturally it would be better to model the whole timeseries, but it was easier to just use the cvs by Mulligan.
  
   
 
ALl I can say is . . . wow.  Bayes wins again.  Maybe Aki can supply the R or Matlab code?
 
P.S.  And let’s not forget how great the simple and clear time series plots are, compared to various fancy visualizations that people might try.
 
P.P.S.  More  here .</p><p>6 0.11762951 <a title="1856-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-02-A_important_new_survey_of_Bayesian_predictive_methods_for_model_assessment%2C_selection_and_comparison.html">1648 andrew gelman stats-2013-01-02-A important new survey of Bayesian predictive methods for model assessment, selection and comparison</a></p>
<p>7 0.092357688 <a title="1856-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-14-Transitioning_to_Stan.html">2291 andrew gelman stats-2014-04-14-Transitioning to Stan</a></p>
<p>8 0.088833787 <a title="1856-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-11-Weakly_informative_priors_for_Bayesian_nonparametric_models%3F.html">1454 andrew gelman stats-2012-08-11-Weakly informative priors for Bayesian nonparametric models?</a></p>
<p>9 0.08774174 <a title="1856-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-15-Reputations_changeable%2C_situations_tolerable.html">1858 andrew gelman stats-2013-05-15-Reputations changeable, situations tolerable</a></p>
<p>10 0.086140133 <a title="1856-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-22-My_talks_that_were_scheduled_for_Tues_at_the_Data_Skeptics_meetup_and_Wed_at_the_Open_Statistical_Programming_meetup.html">1950 andrew gelman stats-2013-07-22-My talks that were scheduled for Tues at the Data Skeptics meetup and Wed at the Open Statistical Programming meetup</a></p>
<p>11 0.085428007 <a title="1856-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-21-Discussion_of_the_paper_by_Girolami_and_Calderhead_on_Bayesian_computation.html">288 andrew gelman stats-2010-09-21-Discussion of the paper by Girolami and Calderhead on Bayesian computation</a></p>
<p>12 0.084844172 <a title="1856-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>13 0.082046136 <a title="1856-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>14 0.081853598 <a title="1856-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-07-Here%E2%80%99s_what_happened_when_I_finished_my_PhD_thesis.html">2011 andrew gelman stats-2013-09-07-Here’s what happened when I finished my PhD thesis</a></p>
<p>15 0.081661731 <a title="1856-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-29-Postdocs_in_probabilistic_modeling%21__With_David_Blei%21__And_Stan%21.html">1961 andrew gelman stats-2013-07-29-Postdocs in probabilistic modeling!  With David Blei!  And Stan!</a></p>
<p>16 0.080917194 <a title="1856-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-11-Zipfian_Academy%2C_A_School_for_Data_Science.html">2016 andrew gelman stats-2013-09-11-Zipfian Academy, A School for Data Science</a></p>
<p>17 0.07980141 <a title="1856-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-28-Bayesian_nonparametric_weighted_sampling_inference.html">2351 andrew gelman stats-2014-05-28-Bayesian nonparametric weighted sampling inference</a></p>
<p>18 0.079012118 <a title="1856-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>19 0.075996846 <a title="1856-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-07-My_recent_debugging_experience.html">2161 andrew gelman stats-2014-01-07-My recent debugging experience</a></p>
<p>20 0.074406855 <a title="1856-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.104), (1, 0.084), (2, -0.043), (3, 0.055), (4, 0.005), (5, 0.037), (6, -0.021), (7, -0.067), (8, 0.026), (9, -0.023), (10, -0.005), (11, 0.017), (12, -0.067), (13, -0.012), (14, 0.003), (15, -0.014), (16, 0.03), (17, 0.006), (18, -0.018), (19, 0.0), (20, -0.005), (21, -0.025), (22, -0.036), (23, -0.02), (24, 0.001), (25, -0.001), (26, -0.019), (27, -0.005), (28, 0.004), (29, 0.01), (30, 0.004), (31, -0.004), (32, -0.015), (33, -0.023), (34, 0.009), (35, -0.002), (36, -0.033), (37, -0.005), (38, 0.017), (39, 0.005), (40, -0.017), (41, 0.034), (42, -0.002), (43, 0.005), (44, 0.04), (45, 0.018), (46, -0.012), (47, -0.004), (48, -0.013), (49, -0.014)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96138197 <a title="1856-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-14-GPstuff%3A_Bayesian_Modeling_with_Gaussian_Processes.html">1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</a></p>
<p>Introduction: I think it’s part of my duty as a blogger to intersperse, along with the steady flow of jokes, rants, and literary criticism, some material that will actually be useful to you.
 
So here goes.
 
Jarno Vanhatalo, Jaakko Riihimäki, Jouni Hartikainen, Pasi Jylänki, Ville Tolvanen, and Aki Vehtari  write :
  
The  GPstuff  toolbox is a versatile collection of Gaussian process models and computational tools required for Bayesian inference. The tools include, among others, various inference methods, sparse approximations and model assessment methods.
  
We can actually now fit Gaussian processes in  Stan .  But for big problems (or even moderately-sized problems), full Bayes can be slow.  GPstuff uses EP, which is faster.  At some point we’d like to implement EP in Stan.  (Right now we’re working with Dave Blei to implement VB.)
 
GPstuff really works.  I saw Aki use it to fit a nonparametric version of the Bangladesh well-switching example in ARM.  He was sitting in his office and just whip</p><p>2 0.8138237 <a title="1856-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-19-An_interweaving-transformation_strategy_for_boosting_MCMC_efficiency.html">964 andrew gelman stats-2011-10-19-An interweaving-transformation strategy for boosting MCMC efficiency</a></p>
<p>Introduction: Yaming Yu and Xiao-Li Meng  write in  with a cool new idea for improving the efficiency of Gibbs and Metropolis in multilevel models:
  
For a broad class of multilevel models, there exist two well-known competing parameterizations, the centered parameterization (CP) and the non-centered parameterization (NCP), for effective MCMC implementation. Much literature has been devoted to the questions of when to use which and how to compromise between them via partial CP/NCP. This article introduces an alternative strategy for boosting MCMC efficiency via simply interweaving—but not alternating—the two parameterizations. This strategy has the surprising property that failure of both the CP and NCP chains to converge geometrically does not prevent the interweaving algorithm from doing so. It achieves this seemingly magical property by taking advantage of the discordance of the two parameterizations, namely, the sufficiency of CP and the ancillarity of NCP, to substantially reduce the Markovian</p><p>3 0.79056317 <a title="1856-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-30-Stan_Project%3A__Continuous_Relaxations_for_Discrete_MRFs.html">2003 andrew gelman stats-2013-08-30-Stan Project:  Continuous Relaxations for Discrete MRFs</a></p>
<p>Introduction: Hamiltonian Monte Carlo (HMC), as used by  Stan , is only defined for continuous parameters.  We’d love to be able to do discrete sampling.  So I was excited when I saw this:
  

Yichuan Zhang, Charles Sutton, Amos J Storkey, and Zoubin Ghahramani.  2012.  Continuous Relaxations for Discrete Hamiltonian Monte Carlo .   NIPS  25.


 Abstract:  Continuous relaxations play an important role in discrete optimization, but have not seen much use in approximate probabilistic inference. Here we show that a general form of the Gaussian Integral Trick makes it possible to transform a wide class of discrete variable undirected models into fully continuous systems. The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference, results in new ways of estimating normalization constants (partition functions), and in general opens up a number of new avenues for inference in difficult discrete systems. We demonstrate some of these continuous relaxation inference a</p><p>4 0.78394997 <a title="1856-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-12-Samplers_for_Big_Science%3A__emcee_and_BAT.html">2020 andrew gelman stats-2013-09-12-Samplers for Big Science:  emcee and BAT</a></p>
<p>Introduction: Over the past few months, we’ve talked about modeling with particle physicists ( Allen Caldwell ), astrophysicists ( David Hogg , who regularly comments here), and climate and energy usage modelers ( Phil Price , who regularly posts here).  
 
 Big Science Black Boxes 
 
We’ve gotten pretty much the same story from all of them:  their models involve “big science” components that are hugely complex and provided by outside implementations from labs like CERN or LBL. Some concrete examples for energy modeling are the  TOUGH2  thermal simulator, the EnergyPlus building energy usage simulator, and global climate model (GCM) implementations.
 
These models have the character of not only being black boxes, but taking several seconds or more to generate the equivalent of a likelihood function evaluation.  So we can’t use something like Stan, because nobody has the person years required to implement something like TOUGH2 in Stan (and Stan doesn’t have the debugging or modularity tools to suppor</p><p>5 0.77472091 <a title="1856-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>Introduction: David Duvenaud writes:
  
I’ve been following  your recent discussions  about how an AI could do statistics [see also  here ].  I was especially excited about your suggestion for new statistical methods using “a language-like approach to recursively creating new models from a specified list of distributions and transformations, and an automatic approach to checking model fit.”


Your discussion of these ideas was exciting to me and my colleagues because we recently  did some work  taking a step in this direction, automatically searching through a grammar over Gaussian process regression models.


Roger Grosse previously  did the same thing , but over matrix decomposition models using held-out predictive likelihood to check model fit.


These are both examples of automatic Bayesian model-building by a search over more and more complex models, as you suggested.  One nice thing is that both grammars include lots of standard models for free, and they seem to work pretty well, although the</p><p>6 0.75500762 <a title="1856-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>7 0.750736 <a title="1856-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-21-Stan_Model_of_the_Week%3A_Hierarchical_Modeling_of_Supernovas.html">2299 andrew gelman stats-2014-04-21-Stan Model of the Week: Hierarchical Modeling of Supernovas</a></p>
<p>8 0.74851978 <a title="1856-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-10-Stan_Model_of_the_Week%3A__PK_Calculation_of_IV_and_Oral_Dosing.html">2242 andrew gelman stats-2014-03-10-Stan Model of the Week:  PK Calculation of IV and Oral Dosing</a></p>
<p>9 0.74791431 <a title="1856-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>10 0.74319595 <a title="1856-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-15-How_I_think_about_mixture_models.html">1459 andrew gelman stats-2012-08-15-How I think about mixture models</a></p>
<p>11 0.74016207 <a title="1856-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-18-Should_we_always_be_using_the_t_and_robit_instead_of_the_normal_and_logit%3F.html">773 andrew gelman stats-2011-06-18-Should we always be using the t and robit instead of the normal and logit?</a></p>
<p>12 0.73763019 <a title="1856-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-10-My_talk_at_MIT_on_Thurs_11_Oct.html">1528 andrew gelman stats-2012-10-10-My talk at MIT on Thurs 11 Oct</a></p>
<p>13 0.72978854 <a title="1856-lsi-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>14 0.72833025 <a title="1856-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-07-Robust_logistic_regression.html">1886 andrew gelman stats-2013-06-07-Robust logistic regression</a></p>
<p>15 0.72549087 <a title="1856-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Valencia%3A___Summer_of_1991.html">72 andrew gelman stats-2010-06-07-Valencia:   Summer of 1991</a></p>
<p>16 0.7211042 <a title="1856-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-22-My_talks_that_were_scheduled_for_Tues_at_the_Data_Skeptics_meetup_and_Wed_at_the_Open_Statistical_Programming_meetup.html">1950 andrew gelman stats-2013-07-22-My talks that were scheduled for Tues at the Data Skeptics meetup and Wed at the Open Statistical Programming meetup</a></p>
<p>17 0.72099596 <a title="1856-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-Scalable_Stan.html">2035 andrew gelman stats-2013-09-23-Scalable Stan</a></p>
<p>18 0.71779239 <a title="1856-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>19 0.71673328 <a title="1856-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-14-Transitioning_to_Stan.html">2291 andrew gelman stats-2014-04-14-Transitioning to Stan</a></p>
<p>20 0.70252526 <a title="1856-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-30-Stan_uses_Nuts%21.html">1036 andrew gelman stats-2011-11-30-Stan uses Nuts!</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(13, 0.02), (15, 0.013), (16, 0.037), (24, 0.126), (30, 0.017), (53, 0.363), (55, 0.015), (62, 0.015), (63, 0.014), (86, 0.053), (99, 0.21)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96452141 <a title="1856-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-14-Statistics_of_food_consumption.html">413 andrew gelman stats-2010-11-14-Statistics of food consumption</a></p>
<p>Introduction: Visual Economics  shows statistics on average food consumption in America:
 
   
 
My brief feedback is that water is confounded with these results. They should have subtracted water content from the weight of all dietary items, as it inflates the proportion of milk, vegetable and fruit items that contain more water. They did that for soda (which is represented as sugar/corn syrup), amplifying the inconsistency.
 
Time Magazine had a  beautiful gallery  that visualizes diets around the world in a more appealing way.</p><p>2 0.92289221 <a title="1856-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-25-Life_as_a_blogger%3A__the_emails_just_get_weirder_and_weirder.html">1589 andrew gelman stats-2012-11-25-Life as a blogger:  the emails just get weirder and weirder</a></p>
<p>Introduction: In the email the other day, subject line “Casting blogger, writer, journalist to host cable series”:
  
Hi there Andrew, 


I’m casting a male journalist, writer, blogger, documentary filmmaker or comedian with a certain type personality for a television pilot along with production company, Pipeline39.  See below:


A certain type of character – no cockiness, no ego, a person who is smart, savvy, dry humor, but someone who isn’t imposing, who can infiltrate these organizations.   This person will be hosting his own show and covering alternative lifestyles and secret societies around the world.


If you’re interested in hearing more or would like to be considered for this project, please email me a photo and a bio of yourself, along with contact information. I’ll respond to you ASAP.


I’m looking forward to hearing from you.


***


Casting Producer


(646) ***.****


***@gmail.com
  
I was with them until I got to the “no ego” part. . . . Also, I don’t think I could infiltrate any org</p><p>3 0.89879119 <a title="1856-lda-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-27-Who_is_that_masked_person%3A_The_use_of_face_masks_on_Mexico_City_public_transportation_during_the_Influenza_A_%28H1N1%29_outbreak.html">298 andrew gelman stats-2010-09-27-Who is that masked person: The use of face masks on Mexico City public transportation during the Influenza A (H1N1) outbreak</a></p>
<p>Introduction: Tapen Sinha writes:
  
Living in Mexico, I have been witness to many strange (and beautiful) things. Perhaps the strangest happened during the first outbreak of A(H1N1) in Mexico City. We had our university closed, football (soccer) was played in empty stadiums (or should it be stadia) because the government feared a spread of the virus. The Metro was operating and so were the private/public buses and taxis. Since the university was closed, we took the opportunity to collect data on facemask use in the public transport systems. It was a simple (but potentially deadly!) exercise in first hand statistical data collection that we teach our students (Although I must admit that I did not dare sending my research assistant to collect data â&euro;&ldquo; what if she contracted the virus?). I believe it was a unique experiment never to be repeated.
  
 The paper  appeared in the journal Health Policy.  From the abstract:
  
At the height of the influenza epidemic in Mexico City in the spring of 2009, the f</p><p>same-blog 4 0.89142966 <a title="1856-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-14-GPstuff%3A_Bayesian_Modeling_with_Gaussian_Processes.html">1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</a></p>
<p>Introduction: I think it’s part of my duty as a blogger to intersperse, along with the steady flow of jokes, rants, and literary criticism, some material that will actually be useful to you.
 
So here goes.
 
Jarno Vanhatalo, Jaakko Riihimäki, Jouni Hartikainen, Pasi Jylänki, Ville Tolvanen, and Aki Vehtari  write :
  
The  GPstuff  toolbox is a versatile collection of Gaussian process models and computational tools required for Bayesian inference. The tools include, among others, various inference methods, sparse approximations and model assessment methods.
  
We can actually now fit Gaussian processes in  Stan .  But for big problems (or even moderately-sized problems), full Bayes can be slow.  GPstuff uses EP, which is faster.  At some point we’d like to implement EP in Stan.  (Right now we’re working with Dave Blei to implement VB.)
 
GPstuff really works.  I saw Aki use it to fit a nonparametric version of the Bangladesh well-switching example in ARM.  He was sitting in his office and just whip</p><p>5 0.85755157 <a title="1856-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-16-Greenland_is_one_tough_town.html">1677 andrew gelman stats-2013-01-16-Greenland is one tough town</a></p>
<p>Introduction: Americans (including me) don’t know much about other countries.
 
Jeff Lax sent me to  this blog post  by Myrddin pointing out that Belgium has a higher murder rate than the rest of Western Europe.  I have no particular take on this, but it’s a good reminder that other countries differ from each other.  Here in the U.S., we tend to think all western European countries are the same, all eastern European countries are the same, etc.  In reality,  Sweden is not Finland .
 
P.S.  According to the  Wiki , Greenland is one tough town.  I guess there’s nothing much to do out there but watch satellite TV, chew the blubber, and kill people.</p><p>6 0.82934314 <a title="1856-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-24-Multilevel_modeling_and_instrumental_variables.html">1468 andrew gelman stats-2012-08-24-Multilevel modeling and instrumental variables</a></p>
<p>7 0.8292858 <a title="1856-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-14-Detecting_predictability_in_complex_ecosystems.html">1802 andrew gelman stats-2013-04-14-Detecting predictability in complex ecosystems</a></p>
<p>8 0.82597286 <a title="1856-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-21-Careers%2C_one-hit_wonders%2C_and_an_offer_of_a_free_book.html">46 andrew gelman stats-2010-05-21-Careers, one-hit wonders, and an offer of a free book</a></p>
<p>9 0.82159114 <a title="1856-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-04-Insecure_researchers_aren%E2%80%99t_sharing_their_data.html">991 andrew gelman stats-2011-11-04-Insecure researchers aren’t sharing their data</a></p>
<p>10 0.8096019 <a title="1856-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-18-There_are_no_fat_sprinters.html">1905 andrew gelman stats-2013-06-18-There are no fat sprinters</a></p>
<p>11 0.80521512 <a title="1856-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-17-Job_opening_at_new_%E2%80%9Cbig_data%E2%80%9D_consulting_firm%21.html">1902 andrew gelman stats-2013-06-17-Job opening at new “big data” consulting firm!</a></p>
<p>12 0.78192103 <a title="1856-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-27-Another_silly_graph.html">733 andrew gelman stats-2011-05-27-Another silly graph</a></p>
<p>13 0.77873099 <a title="1856-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-Social_scientists_who_use_medical_analogies_to_explain_causal_inference_are%2C_I_think%2C_implicitly_trying_to_borrow_some_of_the_scientific_and_cultural_authority_of_that_field_for_our_own_purposes.html">1555 andrew gelman stats-2012-10-31-Social scientists who use medical analogies to explain causal inference are, I think, implicitly trying to borrow some of the scientific and cultural authority of that field for our own purposes</a></p>
<p>14 0.77859324 <a title="1856-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-08-I_Am_Too_Absolutely_Heteroskedastic_for_This_Probit_Model.html">1047 andrew gelman stats-2011-12-08-I Am Too Absolutely Heteroskedastic for This Probit Model</a></p>
<p>15 0.77480769 <a title="1856-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-13-You_heard_it_here_first%3A_Intense_exercise_can_suppress_appetite.html">2022 andrew gelman stats-2013-09-13-You heard it here first: Intense exercise can suppress appetite</a></p>
<p>16 0.75845551 <a title="1856-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Aleks_says_this_is_the_future_of_visualization.html">795 andrew gelman stats-2011-07-10-Aleks says this is the future of visualization</a></p>
<p>17 0.75577301 <a title="1856-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-18-EP_and_ABC.html">2067 andrew gelman stats-2013-10-18-EP and ABC</a></p>
<p>18 0.75378418 <a title="1856-lda-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-%E2%80%9CThreshold_earners%E2%80%9D_and_economic_inequality.html">495 andrew gelman stats-2010-12-31-“Threshold earners” and economic inequality</a></p>
<p>19 0.7465862 <a title="1856-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-30-Annals_of_spam.html">880 andrew gelman stats-2011-08-30-Annals of spam</a></p>
<p>20 0.7458328 <a title="1856-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-31-Using_sample_size_in_the_prior_distribution.html">547 andrew gelman stats-2011-01-31-Using sample size in the prior distribution</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
