<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-2102" href="#">andrew_gelman_stats-2013-2102</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-2102-html" href="http://andrewgelman.com/2013/11/15/are-all-significant-p-values-created-equal/">html</a></p><p>Introduction: The answer is no, as explained in  this classic article  by Warren Browner and Thomas Newman from 1987.  If I were to rewrite this article today, I would frame things slightly differently—referring to Type S and Type M errors rather than speaking of “the probability that the research hypothesis is true”—but overall they make good points, and I like their analogy to medical diagnostic testing.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The answer is no, as explained in  this classic article  by Warren Browner and Thomas Newman from 1987. [sent-1, score-0.594]
</p><p>2 If I were to rewrite this article today, I would frame things slightly differently—referring to Type S and Type M errors rather than speaking of “the probability that the research hypothesis is true”—but overall they make good points, and I like their analogy to medical diagnostic testing. [sent-2, score-2.577]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('newman', 0.349), ('type', 0.298), ('rewrite', 0.287), ('diagnostic', 0.275), ('warren', 0.275), ('differently', 0.229), ('frame', 0.227), ('referring', 0.205), ('analogy', 0.181), ('thomas', 0.181), ('classic', 0.175), ('explained', 0.173), ('speaking', 0.172), ('slightly', 0.168), ('overall', 0.167), ('medical', 0.161), ('testing', 0.159), ('hypothesis', 0.141), ('errors', 0.14), ('today', 0.137), ('article', 0.136), ('probability', 0.111), ('answer', 0.11), ('true', 0.108), ('points', 0.091), ('things', 0.078), ('rather', 0.072), ('research', 0.069), ('good', 0.058), ('make', 0.057), ('would', 0.039), ('like', 0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="2102-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-15-%E2%80%9CAre_all_significant_p-values_created_equal%3F%E2%80%9D.html">2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</a></p>
<p>Introduction: The answer is no, as explained in  this classic article  by Warren Browner and Thomas Newman from 1987.  If I were to rewrite this article today, I would frame things slightly differently—referring to Type S and Type M errors rather than speaking of “the probability that the research hypothesis is true”—but overall they make good points, and I like their analogy to medical diagnostic testing.</p><p>2 0.16342011 <a title="2102-tfidf-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>Introduction: Masanao sends  this one  in, under the heading, “another incident of misunderstood p-value”:
  
Warren Davies, a positive psychology MSc student at UEL, provides the latest in our ongoing series of guest features for students. Warren has just released a Psychology Study Guide, which covers information on statistics, research methods and study skills for psychology students.

 
Despite the myriad rules and procedures of science, some research findings are pure flukes. Perhaps you’re testing a new drug, and by chance alone, a large number of people spontaneously get better. The better your study is conducted, the lower the chance that your result was a fluke – but still, there is always a certain probability that it was.


Statistical significance testing gives you an idea of what this probability is.


In science we’re always testing hypotheses. We never conduct a study to ‘see what happens’, because there’s always at least one way to make any useless set of data look important. We take</p><p>3 0.14837998 <a title="2102-tfidf-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-Type_S_error_rates_for_classical_and_Bayesian_single_and_multiple_comparison_procedures.html">494 andrew gelman stats-2010-12-31-Type S error rates for classical and Bayesian single and multiple comparison procedures</a></p>
<p>Introduction: Type S error:  When your estimate is the wrong sign, compared to the true value of the parameter
 
Type M error:  When the magnitude of your estimate is far off, compared to the true value of the parameter 
  
More here.</p><p>4 0.12495616 <a title="2102-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>Introduction: After seeing a document sent to me and others regarding the  crisis  of spurious, statistically-significant research findings in psychology research, I had the following reaction:
  
I am unhappy with the use in the document of the phrase “false positives.”  I feel that this expression is unhelpful as it frames science in terms of “true” and “false” claims, which I don’t think is particularly accurate.  In particular, in most of the recent disputed Psych Science type studies (the ESP study excepted, perhaps), there is little doubt that there is _some_ underlying effect.  The issue, as I see it, as that the underlying effects are much smaller, and much more variable, than mainstream researchers imagine.  So what happens is that Psych Science or Nature or whatever will publish a result that is purported to be some sort of universal truth, but it is actually a pattern specific to one data set, one population, and one experimental condition.  In a sense, yes, these journals are publishing</p><p>5 0.10781135 <a title="2102-tfidf-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-20-How_to_schedule_projects_in_an_introductory_statistics_course%3F.html">423 andrew gelman stats-2010-11-20-How to schedule projects in an introductory statistics course?</a></p>
<p>Introduction: John Haubrick writes:
  
Next semester I want to center my statistics class around independent projects that they will present at the end of the semester.   My question is, by centering around a project and teaching for the different parts that they need at the time, should topics such as hypothesis testing be moved toward the beginning of the course?  Or should I only discuss setting up a research hypothesis and discuss the actual testing later after they have the data?
  
My reply:
 
Iâ&euro;&trade;m not sure.  There always is a difficulty of what can be covered in a project.  My quick thought is that a project will perhaps work better if it is focused on data collection or exploratory data analysis rather than on estimation and hypothesis testing, which are topics that get covered pretty well in the course as a whole.</p><p>6 0.10622833 <a title="2102-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-20-Picking_on_Gregg_Easterbrook.html">967 andrew gelman stats-2011-10-20-Picking on Gregg Easterbrook</a></p>
<p>7 0.10136917 <a title="2102-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>8 0.10058557 <a title="2102-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-23-Combining_survey_data_obtained_using_different_modes_of_sampling.html">777 andrew gelman stats-2011-06-23-Combining survey data obtained using different modes of sampling</a></p>
<p>9 0.096509308 <a title="2102-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-Write_This_Book.html">1605 andrew gelman stats-2012-12-04-Write This Book</a></p>
<p>10 0.092577122 <a title="2102-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-25-Classics_of_statistics.html">109 andrew gelman stats-2010-06-25-Classics of statistics</a></p>
<p>11 0.092020839 <a title="2102-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>12 0.084677741 <a title="2102-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-26-Difficulties_in_making_inferences_about_scientific_truth_from_distributions_of_published_p-values.html">2040 andrew gelman stats-2013-09-26-Difficulties in making inferences about scientific truth from distributions of published p-values</a></p>
<p>13 0.083754301 <a title="2102-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-17-Rust.html">1538 andrew gelman stats-2012-10-17-Rust</a></p>
<p>14 0.081682213 <a title="2102-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-11-Compare_p-values_from_privately_funded_medical_trials_to_those_in_publicly_funded_research%3F.html">463 andrew gelman stats-2010-12-11-Compare p-values from privately funded medical trials to those in publicly funded research?</a></p>
<p>15 0.080976367 <a title="2102-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>16 0.080668226 <a title="2102-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-13-My_wikipedia_edit.html">904 andrew gelman stats-2011-09-13-My wikipedia edit</a></p>
<p>17 0.079444543 <a title="2102-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>18 0.078064919 <a title="2102-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>19 0.075396672 <a title="2102-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>20 0.074973285 <a title="2102-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-27-Why_don%E2%80%99t_more_medical_discoveries_become_cures%3F.html">167 andrew gelman stats-2010-07-27-Why don’t more medical discoveries become cures?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.098), (1, 0.003), (2, -0.007), (3, -0.048), (4, -0.028), (5, -0.04), (6, 0.003), (7, 0.029), (8, 0.002), (9, -0.069), (10, -0.047), (11, 0.007), (12, 0.0), (13, -0.051), (14, -0.04), (15, -0.011), (16, -0.018), (17, -0.009), (18, -0.009), (19, -0.026), (20, 0.007), (21, 0.013), (22, 0.018), (23, 0.002), (24, -0.044), (25, -0.04), (26, 0.0), (27, 0.006), (28, -0.008), (29, -0.016), (30, 0.037), (31, -0.01), (32, 0.011), (33, 0.039), (34, -0.056), (35, -0.064), (36, 0.065), (37, -0.043), (38, 0.019), (39, -0.007), (40, -0.017), (41, -0.038), (42, -0.002), (43, -0.008), (44, -0.018), (45, 0.047), (46, 0.002), (47, -0.017), (48, -0.02), (49, -0.026)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96560204 <a title="2102-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-15-%E2%80%9CAre_all_significant_p-values_created_equal%3F%E2%80%9D.html">2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</a></p>
<p>Introduction: The answer is no, as explained in  this classic article  by Warren Browner and Thomas Newman from 1987.  If I were to rewrite this article today, I would frame things slightly differently—referring to Type S and Type M errors rather than speaking of “the probability that the research hypothesis is true”—but overall they make good points, and I like their analogy to medical diagnostic testing.</p><p>2 0.80209106 <a title="2102-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>Introduction: Sam Seaver writes:
  
I [Seaver] happened to be reading an ironic  article  by Karl Friston when I learned something new about frequentist vs bayesian, namely Lindley’s paradox, on page 12.  The text is as follows:

 
So why are we worried about trivial effects? They are important because the probability that the true effect size is exactly zero is itself zero and could cause us to reject the null hypothesis inappropriately. This is a fallacy of classical inference and is not unrelated to Lindley’s paradox (Lindley 1957). Lindley’s paradox describes a counterintuitive situation in which Bayesian and frequentist approaches to hypothesis testing give opposite results. It occurs when; (i) a result is significant by a frequentist test, indicating sufficient evidence to reject the null hypothesis d=0 and (ii) priors render the posterior probability of d=0 high, indicating strong evidence that the null hypothesis is true. In his original 
treatment, Lindley (1957) showed that – under a parti</p><p>3 0.78573233 <a title="2102-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>Introduction: Xian, Judith, and I read this line in a book by statistician Murray Aitkin in which he considered the following hypothetical example:
  
A survey of 100 individuals expressing support (Yes/No) for the president, before and after a presidential address . . . The question of interest is whether there has been a change in support between the surveys . . . We want to assess the evidence for the hypothesis of equality H1 against the alternative hypothesis H2 of a change.
  
Here is  our response :
  
Based on our experience in public opinion research, this is not a real question. Support for any political position is always changing. The real question is how much the support has changed, or perhaps how this change is distributed across the population.


A defender of Aitkin (and of classical hypothesis testing) might respond at this point that, yes, everybody knows that changes are never exactly zero and that we should take a more “grown-up” view of the null hypothesis, not that the change</p><p>4 0.772686 <a title="2102-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>Introduction: Masanao sends  this one  in, under the heading, “another incident of misunderstood p-value”:
  
Warren Davies, a positive psychology MSc student at UEL, provides the latest in our ongoing series of guest features for students. Warren has just released a Psychology Study Guide, which covers information on statistics, research methods and study skills for psychology students.

 
Despite the myriad rules and procedures of science, some research findings are pure flukes. Perhaps you’re testing a new drug, and by chance alone, a large number of people spontaneously get better. The better your study is conducted, the lower the chance that your result was a fluke – but still, there is always a certain probability that it was.


Statistical significance testing gives you an idea of what this probability is.


In science we’re always testing hypotheses. We never conduct a study to ‘see what happens’, because there’s always at least one way to make any useless set of data look important. We take</p><p>5 0.74065238 <a title="2102-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-26-Statistical_evidence_for_revised_standards.html">2149 andrew gelman stats-2013-12-26-Statistical evidence for revised standards</a></p>
<p>Introduction: In response to the  discussion  of X and me of his recent  paper , Val Johnson writes:
  
I would like to thank Andrew for forwarding his comments on uniformly most powerful Bayesian tests (UMPBTs) to me and his invitation to respond to them.  I think he  (and also Christian Robert) raise a number of interesting points concerning this new class of Bayesian tests, but I think that they may have confounded several issues that might more usefully be examined separately.


The first issue involves the choice of the Bayesian evidence threshold, gamma, used in rejecting a null hypothesis in favor of an alternative hypothesis.  Andrew objects to the higher values of gamma proposed in my recent PNAS article on grounds that too many important scientific effects would be missed if thresholds of 25-50 were routinely used.  These evidence thresholds correspond roughly to p-values of 0.005; Andrew suggests that evidence thresholds around 5 should continue to be used (gamma=5 corresponds approximate</p><p>6 0.73309302 <a title="2102-lsi-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>7 0.72664005 <a title="2102-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>8 0.71799612 <a title="2102-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-12-Misunderstanding_the_p-value.html">1760 andrew gelman stats-2013-03-12-Misunderstanding the p-value</a></p>
<p>9 0.69104117 <a title="2102-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>10 0.68882859 <a title="2102-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-10-Bayes_jumps_the_shark.html">331 andrew gelman stats-2010-10-10-Bayes jumps the shark</a></p>
<p>11 0.68587089 <a title="2102-lsi-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>12 0.67655516 <a title="2102-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>13 0.65452582 <a title="2102-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>14 0.65406746 <a title="2102-lsi-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>15 0.64218551 <a title="2102-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>16 0.62697119 <a title="2102-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-25-Revised_statistical_standards_for_evidence_%28comments_to_Val_Johnson%E2%80%99s_comments_on_our_comments_on_Val%E2%80%99s_comments_on_p-values%29.html">2305 andrew gelman stats-2014-04-25-Revised statistical standards for evidence (comments to Val Johnson’s comments on our comments on Val’s comments on p-values)</a></p>
<p>17 0.61908388 <a title="2102-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-08-The_Case_for_More_False_Positives_in_Anti-doping_Testing.html">1612 andrew gelman stats-2012-12-08-The Case for More False Positives in Anti-doping Testing</a></p>
<p>18 0.61265969 <a title="2102-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-01-Martin_and_Liu%3A__Probabilistic_inference_based_on_consistency_of_model_with_data.html">1095 andrew gelman stats-2012-01-01-Martin and Liu:  Probabilistic inference based on consistency of model with data</a></p>
<p>19 0.61222893 <a title="2102-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>20 0.61031097 <a title="2102-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-26-%E2%80%9CThe_Bayesian_approach_to_forensic_evidence%E2%80%9D.html">2078 andrew gelman stats-2013-10-26-“The Bayesian approach to forensic evidence”</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(24, 0.203), (28, 0.067), (55, 0.031), (63, 0.059), (75, 0.047), (77, 0.03), (86, 0.173), (87, 0.039), (99, 0.2)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9512307 <a title="2102-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-15-%E2%80%9CAre_all_significant_p-values_created_equal%3F%E2%80%9D.html">2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</a></p>
<p>Introduction: The answer is no, as explained in  this classic article  by Warren Browner and Thomas Newman from 1987.  If I were to rewrite this article today, I would frame things slightly differently—referring to Type S and Type M errors rather than speaking of “the probability that the research hypothesis is true”—but overall they make good points, and I like their analogy to medical diagnostic testing.</p><p>2 0.9416278 <a title="2102-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-29-Quality_control_problems_at_the_New_York_Times.html">436 andrew gelman stats-2010-11-29-Quality control problems at the New York Times</a></p>
<p>Introduction: I guess thereâ&euro;&trade;s a reason they put  this stuff  in the Opinion section and not in the Science section, huh?
 
P.S.  More  here .</p><p>3 0.90463221 <a title="2102-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-29-%E2%80%9CCommunication_is_a_central_task_of_statistics%2C_and_ideally_a_state-of-the-art_data_analysis_can_have_state-of-the-art_displays_to_match%E2%80%9D.html">1552 andrew gelman stats-2012-10-29-“Communication is a central task of statistics, and ideally a state-of-the-art data analysis can have state-of-the-art displays to match”</a></p>
<p>Introduction: The Journal of the Royal Statistical Society publishes papers followed by discussions.  Lots of discussions, each can be no more than 400 words.  Here’s my most recent discussion:
  
The authors are working on an important applied problem and I have no reason to doubt that their approach is a step forward beyond diagnostic criteria based on point estimation.  An attempt at an accurate assessment of variation is important not just for statistical reasons but also because scientists have the duty to convey their uncertainty to the larger world.  I am thinking, for example, of discredited claims such as that of the mathematician who claimed to predict divorces with 93% accuracy (Abraham, 2010).


Regarding the paper at hand, I thought I would try an experiment in comment-writing.  My usual practice is to read the graphs and then go back and clarify any questions through the text.  So, very quickly:  I would prefer Figure 1 to be displayed in terms of standard deviations, not variances.  I</p><p>4 0.89616096 <a title="2102-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-29-Decision_science_vs._social_psychology.html">305 andrew gelman stats-2010-09-29-Decision science vs. social psychology</a></p>
<p>Introduction: Dan Goldstein sends along  this bit of research , distinguishing terms used in two different subfields of psychology.  Dan writes:
  
Intuitive calls included not listing words that don’t occur 3 or more times in both programs. I [Dan] did this because when I looked at the results, those cases tended to be proper names or arbitrary things like header or footer text.  It also narrowed down the space of words to inspect, which means I could actually get the thing done in my copious free time.
  
I think the bar graphs are kinda ugly, maybe there’s a better way to do it based on classifying the words according to content?  Also the whole exercise would gain a new dimension by comparing several areas instead of just two.  Maybe that’s coming next.</p><p>5 0.89442855 <a title="2102-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-18-Comments_on_%E2%80%9CA_Bayesian_approach_to_complex_clinical_diagnoses%3A_a_case-study_in_child_abuse%E2%80%9D.html">1327 andrew gelman stats-2012-05-18-Comments on “A Bayesian approach to complex clinical diagnoses: a case-study in child abuse”</a></p>
<p>Introduction: I was given the opportunity to briefly comment on the  paper , A Bayesian approach to complex clinical diagnoses: a case-study in child abuse, by Nicky Best, Deborah Ashby, Frank Dunstan, David Foreman, and Neil McIntosh, for the Journal of the Royal Statistical Society.  Here is what I wrote:
  
Best et al. are working on an important applied problem and I have no reason to doubt that their approach is a step forward beyond diagnostic criteria based on point estimation.  An attempt at an accurate assessment of variation is important not just for statistical reasons but also because scientists have the duty to convey their uncertainty to the larger world.  I am thinking, for example, of discredited claims such as that of the mathematician who claimed to predict divorces with 93% accuracy (Abraham, 2010).


Regarding the paper at hand, I thought I would try an experiment in comment-writing.  My usual practice is to read the graphs and then go back and clarify any questions through the t</p><p>6 0.87967861 <a title="2102-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-03-Gladwell_vs_Pinker.html">253 andrew gelman stats-2010-09-03-Gladwell vs Pinker</a></p>
<p>7 0.87421918 <a title="2102-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>8 0.87356079 <a title="2102-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-25-Avoiding_boundary_estimates_using_a_prior_distribution_as_regularization.html">779 andrew gelman stats-2011-06-25-Avoiding boundary estimates using a prior distribution as regularization</a></p>
<p>9 0.87337208 <a title="2102-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Toward_a_framework_for_automatic_model_building.html">1718 andrew gelman stats-2013-02-11-Toward a framework for automatic model building</a></p>
<p>10 0.87070751 <a title="2102-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-Type_S_error_rates_for_classical_and_Bayesian_single_and_multiple_comparison_procedures.html">494 andrew gelman stats-2010-12-31-Type S error rates for classical and Bayesian single and multiple comparison procedures</a></p>
<p>11 0.86263835 <a title="2102-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-I_doubt_they_cheated.html">1971 andrew gelman stats-2013-08-07-I doubt they cheated</a></p>
<p>12 0.86239487 <a title="2102-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-15-More_on_AIC%2C_WAIC%2C_etc.html">1983 andrew gelman stats-2013-08-15-More on AIC, WAIC, etc</a></p>
<p>13 0.8609671 <a title="2102-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-30-Berri_Gladwell_Loken_football_update.html">2082 andrew gelman stats-2013-10-30-Berri Gladwell Loken football update</a></p>
<p>14 0.85988379 <a title="2102-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>15 0.85930371 <a title="2102-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-11-Migrating_your_blog_from_Movable_Type_to_WordPress.html">1530 andrew gelman stats-2012-10-11-Migrating your blog from Movable Type to WordPress</a></p>
<p>16 0.85923421 <a title="2102-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-25-College_football%2C_voting%2C_and_the_law_of_large_numbers.html">1547 andrew gelman stats-2012-10-25-College football, voting, and the law of large numbers</a></p>
<p>17 0.85639298 <a title="2102-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-25-Basketball_Stats%3A__Don%E2%80%99t_model_the_probability_of_win%2C_model_the_expected_score_differential..html">2224 andrew gelman stats-2014-02-25-Basketball Stats:  Don’t model the probability of win, model the expected score differential.</a></p>
<p>18 0.85370225 <a title="2102-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-09-Default_priors_update%3F.html">846 andrew gelman stats-2011-08-09-Default priors update?</a></p>
<p>19 0.85186678 <a title="2102-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-11-%E2%80%9CInformative_g-Priors_for_Logistic_Regression%E2%80%9D.html">2017 andrew gelman stats-2013-09-11-“Informative g-Priors for Logistic Regression”</a></p>
<p>20 0.8508957 <a title="2102-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-05-Question_26_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1367 andrew gelman stats-2012-06-05-Question 26 of my final exam for Design and Analysis of Sample Surveys</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
