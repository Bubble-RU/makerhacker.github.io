<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2155 andrew gelman stats-2013-12-31-No on Yes-No decisions</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-2155" href="#">andrew_gelman_stats-2013-2155</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2155 andrew gelman stats-2013-12-31-No on Yes-No decisions</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-2155-html" href="http://andrewgelman.com/2013/12/31/yesno-decisions/">html</a></p><p>Introduction: Just to elaborate on our  post  from last month (“I’m negative on the expression ‘false positives’”), here’s a recent exchange exchange we had regarding the relevance of yes/no decisions in summarizing statistical inferences about scientific questions.
 
Shravan  wrote :
  
Isn’t it true that I am already done if P(theta>0) is much larger than P(theta<0)? I don't need to compute any loss function if the former is 0.99 and the latter 0.01. In most studies of the type that people like me do [Shravan is a linguist], we set up experiments where we have a decisive test like this for theory A and against theory B.
  
To which I  replied :
  
In some way the problem is with the focus on “theta.” Effects (and, more generally, comparisons) vary, they can be positive for some people in some settings and negative for other people in other settings. If you’re talking about a single “theta,” you have to define what population and what scenario you are thinking about. And it’s probably not the popul</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Just to elaborate on our  post  from last month (“I’m negative on the expression ‘false positives’”), here’s a recent exchange exchange we had regarding the relevance of yes/no decisions in summarizing statistical inferences about scientific questions. [sent-1, score-1.387]
</p><p>2 Shravan  wrote :    Isn’t it true that I am already done if P(theta>0) is much larger than P(theta<0)? [sent-2, score-0.123]
</p><p>3 I don't need to compute any loss function if the former is 0. [sent-3, score-0.365]
</p><p>4 In most studies of the type that people like me do [Shravan is a linguist], we set up experiments where we have a decisive test like this for theory A and against theory B. [sent-6, score-0.737]
</p><p>5 To which I  replied :    In some way the problem is with the focus on “theta. [sent-7, score-0.152]
</p><p>6 ” Effects (and, more generally, comparisons) vary, they can be positive for some people in some settings and negative for other people in other settings. [sent-8, score-0.593]
</p><p>7 If you’re talking about a single “theta,” you have to define what population and what scenario you are thinking about. [sent-9, score-0.934]
</p><p>8 And it’s probably not the population of Mechanical Turk participants and the scenario of an online survey. [sent-10, score-0.934]
</p><p>9 If an effect is very small and positive in one population in one scenario, there’s no real reason to be confident that it will be positive in a different population in a different scenario. [sent-11, score-1.207]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('scenario', 0.449), ('shravan', 0.332), ('theta', 0.321), ('population', 0.265), ('positive', 0.208), ('exchange', 0.206), ('negative', 0.153), ('decisive', 0.149), ('linguist', 0.145), ('positives', 0.142), ('turk', 0.13), ('confident', 0.121), ('theory', 0.119), ('mechanical', 0.118), ('elaborate', 0.116), ('summarizing', 0.115), ('expression', 0.11), ('relevance', 0.099), ('latter', 0.099), ('loss', 0.098), ('compute', 0.098), ('vary', 0.095), ('former', 0.092), ('define', 0.09), ('settings', 0.088), ('participants', 0.086), ('inferences', 0.086), ('month', 0.085), ('decisions', 0.084), ('replied', 0.082), ('false', 0.081), ('online', 0.078), ('experiments', 0.078), ('function', 0.077), ('type', 0.075), ('comparisons', 0.074), ('people', 0.072), ('focus', 0.07), ('different', 0.07), ('regarding', 0.068), ('larger', 0.067), ('test', 0.065), ('talking', 0.065), ('single', 0.065), ('generally', 0.061), ('studies', 0.06), ('isn', 0.059), ('scientific', 0.059), ('probably', 0.056), ('already', 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="2155-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-31-No_on_Yes-No_decisions.html">2155 andrew gelman stats-2013-12-31-No on Yes-No decisions</a></p>
<p>Introduction: Just to elaborate on our  post  from last month (“I’m negative on the expression ‘false positives’”), here’s a recent exchange exchange we had regarding the relevance of yes/no decisions in summarizing statistical inferences about scientific questions.
 
Shravan  wrote :
  
Isn’t it true that I am already done if P(theta>0) is much larger than P(theta<0)? I don't need to compute any loss function if the former is 0.99 and the latter 0.01. In most studies of the type that people like me do [Shravan is a linguist], we set up experiments where we have a decisive test like this for theory A and against theory B.
  
To which I  replied :
  
In some way the problem is with the focus on “theta.” Effects (and, more generally, comparisons) vary, they can be positive for some people in some settings and negative for other people in other settings. If you’re talking about a single “theta,” you have to define what population and what scenario you are thinking about. And it’s probably not the popul</p><p>2 0.20087282 <a title="2155-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-28-Path_sampling_for_models_of_varying_dimension.html">1089 andrew gelman stats-2011-12-28-Path sampling for models of varying dimension</a></p>
<p>Introduction: Somebody asks: 
  
  
Iâ&euro;&trade;m reading your paper on path sampling. It essentially solves the 
problem of computing the ratio \int q0(omega)d omega/\int q1(omega) d omega. I.e the arguments in q0() and q1() are the same. But this assumption is not always true in Bayesian model selection using Bayes factor.


In general (for BF), we have this problem, t1 and t2 may have no relation at all.


\int f1(y|t1)p1(t1) d t1 / \int f2(y|t2)p2(t2) d t2


As an example, suppose that we want to compare two sets of normally distributed data with known variance whether they have the same mean (H0) or they are not necessarily have the same mean (H1). Then the dummy variable should be mu in H0 (which is the common mean of both set of samples), and should be (mu1, mu2) (which are the means for each set of samples).


One straight method to address my problem is to preform path integration for the numerate and the denominator, as both the numerate and the denominator are integrals. Each integral can be rewrit</p><p>3 0.17680418 <a title="2155-tfidf-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<p>Introduction: I’ve talked about this a bit but it’s never had its own blog entry (until now).
 
Statistically significant findings tend to overestimate the magnitude of effects.  This holds in general (because E(|x|) > |E(x)|) but even more so if you restrict to statistically significant results.
 
Here’s an example.  Suppose a true effect of theta is unbiasedly estimated by y ~ N (theta, 1).  Further suppose that we will only consider statistically significant results, that is, cases in which |y| > 2.
 
The estimate “|y| conditional on |y|>2″ is clearly an overestimate of |theta|.  First off, if |theta|<2, the estimate |y| conditional on statistical significance is not only too high in expectation, it's  always  too high.  This is a problem, given that |theta| is in reality probably is less than 2.  (The low-hangning fruit have already been picked, remember?)
 
But even if |theta|>2, the estimate |y| conditional on statistical significance will still be too high in expectation.
 
For a discussion o</p><p>4 0.16736346 <a title="2155-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>Introduction: Nick Firoozye writes:
  
While I am absolutely sympathetic to the Bayesian agenda I am often troubled by the requirement of having priors. We must have priors on the parameter of an infinite number of model we have never seen before and I find this troubling. There is a similarly troubling problem in economics of utility theory. Utility is on consumables. To be complete a consumer must assign utility to all sorts of things they never would have encountered. More recent versions of utility theory instead make consumption goods a portfolio of attributes. Cadillacs are x many units of luxury y of transport etc etc. And we can automatically have personal utilities to all these attributes.  


I don’t ever see parameters. Some model have few and some have hundreds. Instead, I see data. So I don’t know how to have an opinion on parameters themselves. Rather I think it far more natural to have opinions on the behavior of models. The prior predictive density is a good and sensible notion. Also</p><p>5 0.159237 <a title="2155-tfidf-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-27-Should_Mister_P_be_allowed-encouraged_to_reside_in_counter-factual_populations%3F.html">7 andrew gelman stats-2010-04-27-Should Mister P be allowed-encouraged to reside in counter-factual populations?</a></p>
<p>Introduction: Lets say you are repeatedly going to recieve unselected sets of well done RCTs on various say medical treatments.
 
One reasonable assumption with all of these treatments is that they are monotonic – either helpful or harmful for all. The treatment effect will (as always) vary for subgroups in the population – these will not be explicitly identified in the studies – but each study very likely will enroll different percentages of the variuos patient subgroups. Being all randomized studies these subgroups will be balanced in the treatment versus control arms – but each study will (as always) be estimating a different – but exchangeable – treatment effect (Exhangeable due to the ignorance about the subgroup memberships of the enrolled patients.) 
 
That reasonable assumption – monotonicity – will be to some extent (as always) wrong, but given that it is a risk believed well worth taking – if the average effect in any population is positive (versus negative) the average effect in any other</p><p>6 0.15683073 <a title="2155-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-How_do_you_interpret_standard_errors_from_a_regression_fit_to_the_entire_population%3F.html">972 andrew gelman stats-2011-10-25-How do you interpret standard errors from a regression fit to the entire population?</a></p>
<p>7 0.15105684 <a title="2155-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>8 0.14912091 <a title="2155-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-01-Why_big_effects_are_more_important_than_small_effects.html">1744 andrew gelman stats-2013-03-01-Why big effects are more important than small effects</a></p>
<p>9 0.13591075 <a title="2155-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-31-Using_sample_size_in_the_prior_distribution.html">547 andrew gelman stats-2011-01-31-Using sample size in the prior distribution</a></p>
<p>10 0.13364491 <a title="2155-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-26-Difficulties_in_making_inferences_about_scientific_truth_from_distributions_of_published_p-values.html">2040 andrew gelman stats-2013-09-26-Difficulties in making inferences about scientific truth from distributions of published p-values</a></p>
<p>11 0.1330144 <a title="2155-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-16-The_%E2%80%9CWashington_read%E2%80%9D_and_the_algebra_of_conditional_distributions.html">961 andrew gelman stats-2011-10-16-The “Washington read” and the algebra of conditional distributions</a></p>
<p>12 0.11589215 <a title="2155-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-04-Does_it_matter_that_a_sample_is_unrepresentative%3F__It_depends_on_the_size_of_the_treatment_interactions.html">2008 andrew gelman stats-2013-09-04-Does it matter that a sample is unrepresentative?  It depends on the size of the treatment interactions</a></p>
<p>13 0.11493687 <a title="2155-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-23-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1868 andrew gelman stats-2013-05-23-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<p>14 0.11314794 <a title="2155-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-09-Advice%3A__positive-sum%2C_zero-sum%2C_or_negative-sum.html">2287 andrew gelman stats-2014-04-09-Advice:  positive-sum, zero-sum, or negative-sum</a></p>
<p>15 0.11029533 <a title="2155-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-30-Stan_is_fast.html">1476 andrew gelman stats-2012-08-30-Stan is fast</a></p>
<p>16 0.10826785 <a title="2155-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-12-Thinking_like_a_statistician_%28continuously%29_rather_than_like_a_civilian_%28discretely%29.html">1575 andrew gelman stats-2012-11-12-Thinking like a statistician (continuously) rather than like a civilian (discretely)</a></p>
<p>17 0.10455801 <a title="2155-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-14-Confusion_about_continuous_probability_densities.html">341 andrew gelman stats-2010-10-14-Confusion about continuous probability densities</a></p>
<p>18 0.10416868 <a title="2155-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-18-What_visualization_is_best%3F.html">40 andrew gelman stats-2010-05-18-What visualization is best?</a></p>
<p>19 0.10341572 <a title="2155-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-20-Prior_beliefs_about_locations_of_decision_boundaries.html">1130 andrew gelman stats-2012-01-20-Prior beliefs about locations of decision boundaries</a></p>
<p>20 0.10293671 <a title="2155-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-17-Jumping_off_the_edge_of_the_world.html">858 andrew gelman stats-2011-08-17-Jumping off the edge of the world</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.139), (1, 0.037), (2, 0.039), (3, -0.084), (4, -0.018), (5, -0.046), (6, 0.014), (7, 0.028), (8, -0.004), (9, -0.064), (10, -0.088), (11, 0.003), (12, 0.038), (13, -0.075), (14, -0.008), (15, 0.008), (16, -0.06), (17, -0.019), (18, -0.001), (19, 0.009), (20, 0.028), (21, -0.003), (22, 0.007), (23, -0.001), (24, -0.036), (25, -0.002), (26, 0.003), (27, 0.041), (28, 0.064), (29, 0.057), (30, -0.022), (31, -0.023), (32, -0.019), (33, 0.009), (34, 0.012), (35, 0.001), (36, -0.002), (37, 0.003), (38, -0.06), (39, -0.005), (40, 0.045), (41, 0.001), (42, -0.051), (43, -0.045), (44, -0.028), (45, -0.038), (46, 0.048), (47, 0.052), (48, -0.027), (49, 0.043)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95773071 <a title="2155-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-31-No_on_Yes-No_decisions.html">2155 andrew gelman stats-2013-12-31-No on Yes-No decisions</a></p>
<p>Introduction: Just to elaborate on our  post  from last month (“I’m negative on the expression ‘false positives’”), here’s a recent exchange exchange we had regarding the relevance of yes/no decisions in summarizing statistical inferences about scientific questions.
 
Shravan  wrote :
  
Isn’t it true that I am already done if P(theta>0) is much larger than P(theta<0)? I don't need to compute any loss function if the former is 0.99 and the latter 0.01. In most studies of the type that people like me do [Shravan is a linguist], we set up experiments where we have a decisive test like this for theory A and against theory B.
  
To which I  replied :
  
In some way the problem is with the focus on “theta.” Effects (and, more generally, comparisons) vary, they can be positive for some people in some settings and negative for other people in other settings. If you’re talking about a single “theta,” you have to define what population and what scenario you are thinking about. And it’s probably not the popul</p><p>2 0.71857548 <a title="2155-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-01-Why_big_effects_are_more_important_than_small_effects.html">1744 andrew gelman stats-2013-03-01-Why big effects are more important than small effects</a></p>
<p>Introduction: The title of this post is silly but I have an important point to make, regarding an implicit model which I think many people assume even though it does not really make sense.
 
Following a link from Sanjay Srivastava, I came across  a post  from David Funder saying that it’s useful to talk about the sizes of effects (I actually prefer the term “comparisons” so as to avoid the causal baggage) rather than just their signs.  I  agree , and I wanted to elaborate a bit on a point that comes up in Funder’s discussion.  He quotes an (unnamed) prominent social psychologist as writing:
  
The key to our research . . . [is not] to accurately estimate effect size. If I were testing an advertisement for a marketing research firm and wanted to be sure that the cost of the ad would produce enough sales to make it worthwhile, effect size would be crucial. But when I am testing a theory about whether, say, positive mood reduces information processing in comparison with negative mood, I am worried abou</p><p>3 0.68196684 <a title="2155-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>Introduction: After seeing a document sent to me and others regarding the  crisis  of spurious, statistically-significant research findings in psychology research, I had the following reaction:
  
I am unhappy with the use in the document of the phrase “false positives.”  I feel that this expression is unhelpful as it frames science in terms of “true” and “false” claims, which I don’t think is particularly accurate.  In particular, in most of the recent disputed Psych Science type studies (the ESP study excepted, perhaps), there is little doubt that there is _some_ underlying effect.  The issue, as I see it, as that the underlying effects are much smaller, and much more variable, than mainstream researchers imagine.  So what happens is that Psych Science or Nature or whatever will publish a result that is purported to be some sort of universal truth, but it is actually a pattern specific to one data set, one population, and one experimental condition.  In a sense, yes, these journals are publishing</p><p>4 0.6749478 <a title="2155-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<p>Introduction: I’ve talked about this a bit but it’s never had its own blog entry (until now).
 
Statistically significant findings tend to overestimate the magnitude of effects.  This holds in general (because E(|x|) > |E(x)|) but even more so if you restrict to statistically significant results.
 
Here’s an example.  Suppose a true effect of theta is unbiasedly estimated by y ~ N (theta, 1).  Further suppose that we will only consider statistically significant results, that is, cases in which |y| > 2.
 
The estimate “|y| conditional on |y|>2″ is clearly an overestimate of |theta|.  First off, if |theta|<2, the estimate |y| conditional on statistical significance is not only too high in expectation, it's  always  too high.  This is a problem, given that |theta| is in reality probably is less than 2.  (The low-hangning fruit have already been picked, remember?)
 
But even if |theta|>2, the estimate |y| conditional on statistical significance will still be too high in expectation.
 
For a discussion o</p><p>5 0.66965175 <a title="2155-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-08-Censoring_on_one_end%2C_%E2%80%9Coutliers%E2%80%9D_on_the_other%2C_what_can_we_do_with_the_middle%3F.html">791 andrew gelman stats-2011-07-08-Censoring on one end, “outliers” on the other, what can we do with the middle?</a></p>
<p>Introduction: This post was written by Phil.
 
A medical company is testing a cancer drug. They get a 16 genetically identical (or nearly identical) rats that all have the same kind of tumor, give 8 of them the drug and leave 8 untreated…or maybe they give them a placebo, I don’t know; is there a placebo effect in rats?.  Anyway, after a while the rats are killed and examined. If the tumors in the treated rats are smaller than the tumors in the untreated rats, then all of the rats have their blood tested for dozens of different proteins that are known to be associated with tumor growth or suppression.  If there is a “significant” difference in one of the protein levels, then the working assumption is that the drug increases or decreases levels of that protein and that may be the mechanism by which the drug affects cancer. All of the above is done on many different cancer types and possibly several different types of rats.  It’s just the initial screening: if things look promising, many more tests an</p><p>6 0.66048098 <a title="2155-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-28-Another_argument_in_favor_of_expressing_conditional_probability_statements_using_the_population_distribution.html">56 andrew gelman stats-2010-05-28-Another argument in favor of expressing conditional probability statements using the population distribution</a></p>
<p>7 0.65741533 <a title="2155-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-10-Preregistration%3A_what%E2%80%99s_in_it_for_you%3F.html">2241 andrew gelman stats-2014-03-10-Preregistration: what’s in it for you?</a></p>
<p>8 0.65620512 <a title="2155-lsi-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-04-27-Should_Mister_P_be_allowed-encouraged_to_reside_in_counter-factual_populations%3F.html">7 andrew gelman stats-2010-04-27-Should Mister P be allowed-encouraged to reside in counter-factual populations?</a></p>
<p>9 0.64897221 <a title="2155-lsi-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-29-Decline_Effect_in_Linguistics%3F.html">1400 andrew gelman stats-2012-06-29-Decline Effect in Linguistics?</a></p>
<p>10 0.64891124 <a title="2155-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-Fourteen_magic_words%3A_an_update.html">898 andrew gelman stats-2011-09-10-Fourteen magic words: an update</a></p>
<p>11 0.64437634 <a title="2155-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-28-Path_sampling_for_models_of_varying_dimension.html">1089 andrew gelman stats-2011-12-28-Path sampling for models of varying dimension</a></p>
<p>12 0.63459039 <a title="2155-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>13 0.63410652 <a title="2155-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-26-Is_it_plausible_that_1%25_of_people_pick_a_career_based_on_their_first_name%3F.html">629 andrew gelman stats-2011-03-26-Is it plausible that 1% of people pick a career based on their first name?</a></p>
<p>14 0.63288754 <a title="2155-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-26-Difficulties_in_making_inferences_about_scientific_truth_from_distributions_of_published_p-values.html">2040 andrew gelman stats-2013-09-26-Difficulties in making inferences about scientific truth from distributions of published p-values</a></p>
<p>15 0.62421107 <a title="2155-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>16 0.62203324 <a title="2155-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>17 0.62180692 <a title="2155-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<p>18 0.62155569 <a title="2155-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-16-The_%E2%80%9Chot_hand%E2%80%9D_and_problems_with_hypothesis_testing.html">1215 andrew gelman stats-2012-03-16-The “hot hand” and problems with hypothesis testing</a></p>
<p>19 0.6214208 <a title="2155-lsi-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-14-Subtleties_with_measurement-error_models_for_the_evaluation_of_wacky_claims.html">803 andrew gelman stats-2011-07-14-Subtleties with measurement-error models for the evaluation of wacky claims</a></p>
<p>20 0.61262023 <a title="2155-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-24-What_is_the_normal_range_of_values_in_a_medical_test%3F.html">923 andrew gelman stats-2011-09-24-What is the normal range of values in a medical test?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.017), (2, 0.058), (4, 0.047), (15, 0.012), (18, 0.017), (24, 0.212), (29, 0.016), (53, 0.156), (65, 0.014), (99, 0.325)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96889591 <a title="2155-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-31-No_on_Yes-No_decisions.html">2155 andrew gelman stats-2013-12-31-No on Yes-No decisions</a></p>
<p>Introduction: Just to elaborate on our  post  from last month (“I’m negative on the expression ‘false positives’”), here’s a recent exchange exchange we had regarding the relevance of yes/no decisions in summarizing statistical inferences about scientific questions.
 
Shravan  wrote :
  
Isn’t it true that I am already done if P(theta>0) is much larger than P(theta<0)? I don't need to compute any loss function if the former is 0.99 and the latter 0.01. In most studies of the type that people like me do [Shravan is a linguist], we set up experiments where we have a decisive test like this for theory A and against theory B.
  
To which I  replied :
  
In some way the problem is with the focus on “theta.” Effects (and, more generally, comparisons) vary, they can be positive for some people in some settings and negative for other people in other settings. If you’re talking about a single “theta,” you have to define what population and what scenario you are thinking about. And it’s probably not the popul</p><p>2 0.96098876 <a title="2155-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-Social_scientists_who_use_medical_analogies_to_explain_causal_inference_are%2C_I_think%2C_implicitly_trying_to_borrow_some_of_the_scientific_and_cultural_authority_of_that_field_for_our_own_purposes.html">1555 andrew gelman stats-2012-10-31-Social scientists who use medical analogies to explain causal inference are, I think, implicitly trying to borrow some of the scientific and cultural authority of that field for our own purposes</a></p>
<p>Introduction: I’m sorry I don’t have any new zombie papers in time for Halloween.  Instead I’d like to be a little monster by reproducing a mini-rant from  this article  on experimental reasoning in social science:
  
I will restrict my discussion to social science examples. Social scientists are often tempted to illustrate their ideas with examples from medical research. When it comes to medicine, though, we are, with rare exceptions, at best ignorant laypersons (in my case, not even reaching that level), and it is my impression that by reaching for medical analogies we are implicitly trying to borrow some of the scientific and cultural authority of that field for our own purposes. Evidence-based medicine is the subject of a large literature of its own (see, for example, Lau, Ioannidis, and Schmid, 1998).</p><p>3 0.95729071 <a title="2155-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-04-Insecure_researchers_aren%E2%80%99t_sharing_their_data.html">991 andrew gelman stats-2011-11-04-Insecure researchers aren’t sharing their data</a></p>
<p>Introduction: Jelte Wicherts writes:
  
I thought you might be interested in reading  this paper  that is to appear this week in PLoS ONE.


In it we [Wicherts, Marjan Bakker, and Dylan Molenaar] show that the willingness to share data from published psychological research is associated both with “the strength of the evidence” (against H0) and the prevalence of errors in the reporting of p-values. 


The issue of data archiving will likely be put on the agenda of granting bodies and the APA/APS because of what Diederik Stapel  did .
  
I hate hate hate hate hate when people don’t share their data.  In fact, that’s the subject of my very first column on ethics for Chance magazine.  I have a story from 22 years ago, when I contacted some scientists and showed them how I could reanalyze their data more efficiently (based on a preliminary analysis of their published summary statistics).  They seemed to feel threatened by the suggestion and refused to send me their raw data.  (It was an animal experiment</p><p>4 0.95475787 <a title="2155-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-08-I_Am_Too_Absolutely_Heteroskedastic_for_This_Probit_Model.html">1047 andrew gelman stats-2011-12-08-I Am Too Absolutely Heteroskedastic for This Probit Model</a></p>
<p>Introduction: Soren Lorensen wrote:
  
I’m working on a project that uses a binary choice model on panel data. Since I have panel data and am using MLE, I’m concerned about heteroskedasticity making my estimates inconsistent and biased. 


Are you familiar with any statistical packages with pre-built tests for heteroskedasticity in binary choice ML models? If not, is there value in cutting my data into groups over which I guess the error variance might vary and eyeballing residual plots? Have you other suggestions about how I might resolve this concern?
  
I replied that I wouldn’t worry so much about heteroskedasticity.  Breaking up the data into pieces might make sense, but for the purpose of estimating how the coefficients might vary—that is, nonlinearity and interactions.
 
Soren shot back:
  
I’m somewhat puzzled however: homoskedasticity is an identifying assumption in estimating a probit model: if we don’t have it all sorts of bad things can happen to our parameter estimates. Do you suggest n</p><p>5 0.95304495 <a title="2155-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-03-Is_0.05_too_strict_as_a_p-value_threshold%3F.html">446 andrew gelman stats-2010-12-03-Is 0.05 too strict as a p-value threshold?</a></p>
<p>Introduction: Seth sent along an article (not by him) from the psychology literature and wrote:
  
This is a good example of your complaint about statistical significance. The authors want to say that predictability of information determines how distracting something is and have two conditions that vary in predictability. One is significantly distracting, the other isn’t. But the two conditions are not significantly different from each other. So the two conditions are different more weakly than p = 0.05.


I don’t think the reviewers failed to notice this. They just thought it should be published anyway, is my guess.


To me, the interesting question is: where should the bar be? at p = 0.05? at p = 0.10? something else? How can we figure out where to put the bar?
  
I replied:
 
My quick answer is that we have to get away from .05 and .10 and move to something that takes into account prior information.  This could be Bayesian (of course) or could be done classically using power calculations, as disc</p><p>6 0.9520371 <a title="2155-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-31-Using_sample_size_in_the_prior_distribution.html">547 andrew gelman stats-2011-01-31-Using sample size in the prior distribution</a></p>
<p>7 0.94940293 <a title="2155-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-14-GPstuff%3A_Bayesian_Modeling_with_Gaussian_Processes.html">1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</a></p>
<p>8 0.94879091 <a title="2155-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-25-Life_as_a_blogger%3A__the_emails_just_get_weirder_and_weirder.html">1589 andrew gelman stats-2012-11-25-Life as a blogger:  the emails just get weirder and weirder</a></p>
<p>9 0.94425505 <a title="2155-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-18-There_are_no_fat_sprinters.html">1905 andrew gelman stats-2013-06-18-There are no fat sprinters</a></p>
<p>10 0.94154102 <a title="2155-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-%E2%80%9CThreshold_earners%E2%80%9D_and_economic_inequality.html">495 andrew gelman stats-2010-12-31-“Threshold earners” and economic inequality</a></p>
<p>11 0.94130564 <a title="2155-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-29-Zero_is_zero.html">687 andrew gelman stats-2011-04-29-Zero is zero</a></p>
<p>12 0.9368183 <a title="2155-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-30-Annals_of_spam.html">880 andrew gelman stats-2011-08-30-Annals of spam</a></p>
<p>13 0.93467826 <a title="2155-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-01-Ratios_where_the_numerator_and_denominator_both_change_signs.html">248 andrew gelman stats-2010-09-01-Ratios where the numerator and denominator both change signs</a></p>
<p>14 0.93254322 <a title="2155-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-27-Who_is_that_masked_person%3A_The_use_of_face_masks_on_Mexico_City_public_transportation_during_the_Influenza_A_%28H1N1%29_outbreak.html">298 andrew gelman stats-2010-09-27-Who is that masked person: The use of face masks on Mexico City public transportation during the Influenza A (H1N1) outbreak</a></p>
<p>15 0.93162453 <a title="2155-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-27-Another_silly_graph.html">733 andrew gelman stats-2011-05-27-Another silly graph</a></p>
<p>16 0.92957491 <a title="2155-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-24-Multilevel_modeling_and_instrumental_variables.html">1468 andrew gelman stats-2012-08-24-Multilevel modeling and instrumental variables</a></p>
<p>17 0.92639488 <a title="2155-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-What_should_be_in_a_machine_learning_course%3F.html">1956 andrew gelman stats-2013-07-25-What should be in a machine learning course?</a></p>
<p>18 0.92636126 <a title="2155-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-17-Job_opening_at_new_%E2%80%9Cbig_data%E2%80%9D_consulting_firm%21.html">1902 andrew gelman stats-2013-06-17-Job opening at new “big data” consulting firm!</a></p>
<p>19 0.92507422 <a title="2155-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-19-My_short_career_as_a_Freud_expert.html">2338 andrew gelman stats-2014-05-19-My short career as a Freud expert</a></p>
<p>20 0.92396891 <a title="2155-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-14-Detecting_predictability_in_complex_ecosystems.html">1802 andrew gelman stats-2013-04-14-Detecting predictability in complex ecosystems</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
