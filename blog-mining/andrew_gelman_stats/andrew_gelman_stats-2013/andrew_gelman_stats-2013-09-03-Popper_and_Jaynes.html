<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2007 andrew gelman stats-2013-09-03-Popper and Jaynes</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-2007" href="#">andrew_gelman_stats-2013-2007</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2007 andrew gelman stats-2013-09-03-Popper and Jaynes</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-2007-html" href="http://andrewgelman.com/2013/09/03/popper-and-jaynes/">html</a></p><p>Introduction: Deborah Mayo quotes me as saying, “Popper has argued (convincingly, in my opinion) that scientific inference is not inductive but deductive.”  She then  follows up  with:
  
Gelman employs significance test-type reasoning to reject a model when the data sufficiently disagree.


Now, strictly speaking, a model falsification, even to inferring something as weak as “the model breaks down,” is not purely deductive, but Gelman is right to see it as about as close as one can get, in statistics, to a deductive falsification of a model. But where does that leave him as a Jaynesian?
  
My reply:
 
I was influenced by reading a toy example from Jaynes’s book where he sets up a model (for the probability of a die landing on each of its six sides) based on first principles, then presents some data that contradict the model, then expands the model.
 
I’d seen very little of this sort of this reasoning before in statistics!  In physics it’s the standard way to go:  you set up a model based on physic</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Deborah Mayo quotes me as saying, “Popper has argued (convincingly, in my opinion) that scientific inference is not inductive but deductive. [sent-1, score-0.179]
</p><p>2 ”  She then  follows up  with:    Gelman employs significance test-type reasoning to reject a model when the data sufficiently disagree. [sent-2, score-0.662]
</p><p>3 Now, strictly speaking, a model falsification, even to inferring something as weak as “the model breaks down,” is not purely deductive, but Gelman is right to see it as about as close as one can get, in statistics, to a deductive falsification of a model. [sent-3, score-1.197]
</p><p>4 My reply:   I was influenced by reading a toy example from Jaynes’s book where he sets up a model (for the probability of a die landing on each of its six sides) based on first principles, then presents some data that contradict the model, then expands the model. [sent-5, score-0.833]
</p><p>5 I’d seen very little of this sort of this reasoning before in statistics! [sent-6, score-0.118]
</p><p>6 But in statistics we weren’t usually seeing this. [sent-8, score-0.077]
</p><p>7 Instead, model checking typically was placed in the category of “hypothesis testing,” where the rejection was the goal. [sent-9, score-0.546]
</p><p>8 Models to be tested were straw men, build up only to be rejected. [sent-10, score-0.184]
</p><p>9 You can see this, for example, in social science papers that list research hypotheses that are  not  the same as the statistical “hypotheses” being tested. [sent-11, score-0.141]
</p><p>10 A typical research hypothesis is “Y causes Z,” with the corresponding statistical hypothesis being “Y has no association with Z after controlling for X. [sent-12, score-0.372]
</p><p>11 ”  Jaynes’s approach—or, at least, what I took away from Jaynes’s presentation—was more simpatico to my way of doing science. [sent-13, score-0.077]
</p><p>12 And I put a lot of effort into formalizing this idea, so that the kind of modeling I talk and write about can be the kind of modeling I actually do. [sent-14, score-0.467]
</p><p>13 I don’t want to overstate this—as I wrote earlier,  Jaynes is no guru —but I do think this combination of model building and checking is important. [sent-15, score-0.586]
</p><p>14 Indeed, just as a chicken is said to be an egg’s way of making another egg, we can view inference as a way of sharpening the implications of an assumed model so that it can better be checked. [sent-16, score-0.591]
</p><p>15 In response to Larry’s post  here , let me give a quick +1 to  this comment  and also refer to  this post , which remains relevant 3 years later. [sent-19, score-0.08]
</p><p>16 See  here  for years and years of Popper-blogging. [sent-23, score-0.16]
</p><p>17 And  here’s  my article with Shalizi and our  rejoinder  to the discussion. [sent-24, score-0.083]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('jaynes', 0.368), ('model', 0.267), ('egg', 0.222), ('deductive', 0.208), ('falsification', 0.179), ('hypothesis', 0.15), ('hypotheses', 0.141), ('principles', 0.125), ('reasoning', 0.118), ('expands', 0.116), ('checking', 0.114), ('guru', 0.111), ('simplifications', 0.111), ('landing', 0.111), ('formalizing', 0.111), ('gelman', 0.109), ('inferring', 0.107), ('straw', 0.107), ('employs', 0.104), ('inductive', 0.101), ('sufficiently', 0.097), ('convincingly', 0.095), ('element', 0.095), ('overstate', 0.094), ('toy', 0.094), ('kind', 0.092), ('chicken', 0.092), ('assume', 0.088), ('stability', 0.087), ('breaks', 0.086), ('influenced', 0.086), ('modeling', 0.086), ('rejection', 0.084), ('rejoinder', 0.083), ('strictly', 0.083), ('popper', 0.082), ('contradict', 0.082), ('deborah', 0.082), ('mayo', 0.082), ('placed', 0.081), ('years', 0.08), ('inference', 0.078), ('way', 0.077), ('statistics', 0.077), ('die', 0.077), ('tested', 0.077), ('reject', 0.076), ('shalizi', 0.076), ('sides', 0.072), ('controlling', 0.072)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="2007-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Popper_and_Jaynes.html">2007 andrew gelman stats-2013-09-03-Popper and Jaynes</a></p>
<p>Introduction: Deborah Mayo quotes me as saying, “Popper has argued (convincingly, in my opinion) that scientific inference is not inductive but deductive.”  She then  follows up  with:
  
Gelman employs significance test-type reasoning to reject a model when the data sufficiently disagree.


Now, strictly speaking, a model falsification, even to inferring something as weak as “the model breaks down,” is not purely deductive, but Gelman is right to see it as about as close as one can get, in statistics, to a deductive falsification of a model. But where does that leave him as a Jaynesian?
  
My reply:
 
I was influenced by reading a toy example from Jaynes’s book where he sets up a model (for the probability of a die landing on each of its six sides) based on first principles, then presents some data that contradict the model, then expands the model.
 
I’d seen very little of this sort of this reasoning before in statistics!  In physics it’s the standard way to go:  you set up a model based on physic</p><p>2 0.21645908 <a title="2007-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>Introduction: Konrad Scheffler writes:
  
I was interested by your  paper  “Induction and deduction in Bayesian data analysis” and was wondering if you would entertain a few questions:
  
  
  
 – Under the banner of objective Bayesianism, I would posit something like this as a description of Bayesian inference:


“Objective Bayesian probability is not a degree of belief (which would necessarily be subjective) but a measure of the plausibility of a hypothesis, conditional on a formally specified information state. One way of specifying a formal information state is to specify a model, which involves specifying both a prior distribution (typically for a set of unobserved variables) and a likelihood function (typically for a set of observed variables, conditioned on the values of the unobserved variables). Bayesian inference involves calculating the objective degree of plausibility of a hypothesis (typically the truth value of the hypothesis is a function of the variables mentioned above) given such a</p><p>3 0.21098587 <a title="2007-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>Introduction: Robert Bloomfield writes:
  
Most of the people in my field (accounting, which is basically applied economics and finance, leavened with psychology and organizational behavior) use ‘positive research methods’, which are typically described as coming to the data with a predefined theory, and using hypothesis testing to accept or reject the theory’s predictions.  But a substantial minority use ‘interpretive research methods’ (sometimes called qualitative methods, for those that call positive research ‘quantitative’).  No one seems entirely happy with the definition of this method, but I’ve found it useful to think of it as an attempt to see the world through the eyes of your subjects, much as Jane Goodall lived with gorillas and tried to see the world through their eyes.)


Interpretive researchers often criticize positive researchers by noting that the latter don’t make the best use of their data, because they come to the data with a predetermined theory, and only test a narrow set of h</p><p>4 0.20905207 <a title="2007-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>Introduction: In response to  my remarks  on his online book, Think Bayes, Allen Downey wrote: 
   
I [Downey] have a question about one of your comments: 
   My [Gelman's] main criticism with both books is that they talk a lot about inference but not so much about model building or model checking (recall the three steps of Bayesian data analysis). I think it’s ok for an introductory book to focus on inference, which of course is central to the data-analytic process—but I’d like them to at least mention that Bayesian ideas arise in model building and model checking as well. 

This sounds like something I agree with, and one of the things I tried to do in the book is to put modeling decisions front and center.  But the word “modeling” is used in lots of ways, so I want to see if we are talking about the same thing.


For example, in many chapters, I start with a simple model of the scenario, do some analysis, then check whether the model is good enough, and iterate.  Here’s the discussion of modeling</p><p>5 0.19710188 <a title="2007-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>Introduction: Jonathan Livengood writes:
  
I have a couple of questions on your paper with Cosma Shalizi on “Philosophy and the practice of Bayesian statistics.”


First, you distinguish between inductive approaches and hypothetico-deductive approaches to inference and locate statistical practice (at least, the practice of model building and checking) on the hypothetico-deductive side.  Do you think that there are any interesting elements of statistical practice that are properly inductive?  For example, suppose someone is playing around with a system that more or less resembles a toy model, like drawing balls from an urn or some such, and where the person has some well-defined priors.  The person makes a number of draws from the urn and applies Bayes theorem to get a posterior.  On your view, is that person making an induction?  If so, how much space is there in statistical practice for genuine inductions like this?


Second, I agree with you that one ought to distinguish induction from other kind</p><p>6 0.1932071 <a title="2007-tfidf-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>7 0.16358022 <a title="2007-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>8 0.16036259 <a title="2007-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>9 0.15410462 <a title="2007-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>10 0.14822216 <a title="2007-tfidf-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-08-Bayes-Godel.html">998 andrew gelman stats-2011-11-08-Bayes-Godel</a></p>
<p>11 0.14786386 <a title="2007-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>12 0.14538622 <a title="2007-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>13 0.14370032 <a title="2007-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-20-The_pervasive_twoishness_of_statistics%3B_in_particular%2C_the_%E2%80%9Csampling_distribution%E2%80%9D_and_the_%E2%80%9Clikelihood%E2%80%9D_are_two_different_models%2C_and_that%E2%80%99s_a_good_thing.html">774 andrew gelman stats-2011-06-20-The pervasive twoishness of statistics; in particular, the “sampling distribution” and the “likelihood” are two different models, and that’s a good thing</a></p>
<p>14 0.13782594 <a title="2007-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-23-Examples_of_the_use_of_hierarchical_modeling_to_generalize_to_new_settings.html">1425 andrew gelman stats-2012-07-23-Examples of the use of hierarchical modeling to generalize to new settings</a></p>
<p>15 0.13776545 <a title="2007-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-05-An_unexpected_benefit_of_Arrow%E2%80%99s_other_theorem.html">746 andrew gelman stats-2011-06-05-An unexpected benefit of Arrow’s other theorem</a></p>
<p>16 0.13594164 <a title="2007-tfidf-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-13-Flexibility_is_good.html">2133 andrew gelman stats-2013-12-13-Flexibility is good</a></p>
<p>17 0.13525848 <a title="2007-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>18 0.13094088 <a title="2007-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>19 0.13051002 <a title="2007-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>20 0.12787212 <a title="2007-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.235), (1, 0.127), (2, -0.053), (3, 0.027), (4, -0.073), (5, 0.007), (6, -0.072), (7, 0.019), (8, 0.148), (9, -0.025), (10, 0.003), (11, 0.046), (12, -0.041), (13, -0.018), (14, -0.056), (15, -0.007), (16, 0.014), (17, -0.037), (18, -0.0), (19, -0.029), (20, 0.031), (21, -0.063), (22, -0.043), (23, -0.068), (24, -0.056), (25, -0.001), (26, -0.04), (27, -0.034), (28, -0.0), (29, -0.044), (30, -0.02), (31, -0.043), (32, -0.026), (33, 0.013), (34, -0.067), (35, 0.017), (36, 0.057), (37, -0.022), (38, 0.056), (39, -0.043), (40, -0.008), (41, -0.043), (42, 0.037), (43, -0.002), (44, -0.049), (45, 0.023), (46, -0.023), (47, -0.098), (48, -0.044), (49, -0.003)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96651167 <a title="2007-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Popper_and_Jaynes.html">2007 andrew gelman stats-2013-09-03-Popper and Jaynes</a></p>
<p>Introduction: Deborah Mayo quotes me as saying, “Popper has argued (convincingly, in my opinion) that scientific inference is not inductive but deductive.”  She then  follows up  with:
  
Gelman employs significance test-type reasoning to reject a model when the data sufficiently disagree.


Now, strictly speaking, a model falsification, even to inferring something as weak as “the model breaks down,” is not purely deductive, but Gelman is right to see it as about as close as one can get, in statistics, to a deductive falsification of a model. But where does that leave him as a Jaynesian?
  
My reply:
 
I was influenced by reading a toy example from Jaynes’s book where he sets up a model (for the probability of a die landing on each of its six sides) based on first principles, then presents some data that contradict the model, then expands the model.
 
I’d seen very little of this sort of this reasoning before in statistics!  In physics it’s the standard way to go:  you set up a model based on physic</p><p>2 0.83332521 <a title="2007-lsi-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>Introduction: Jonathan Livengood writes:
  
I have a couple of questions on your paper with Cosma Shalizi on “Philosophy and the practice of Bayesian statistics.”


First, you distinguish between inductive approaches and hypothetico-deductive approaches to inference and locate statistical practice (at least, the practice of model building and checking) on the hypothetico-deductive side.  Do you think that there are any interesting elements of statistical practice that are properly inductive?  For example, suppose someone is playing around with a system that more or less resembles a toy model, like drawing balls from an urn or some such, and where the person has some well-defined priors.  The person makes a number of draws from the urn and applies Bayes theorem to get a posterior.  On your view, is that person making an induction?  If so, how much space is there in statistical practice for genuine inductions like this?


Second, I agree with you that one ought to distinguish induction from other kind</p><p>3 0.83210868 <a title="2007-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>Introduction: David Rohde writes:
  
 
I have been thinking a lot lately about your Bayesian model checking approach.  This is in part because I have been working on exploratory data analysis and wishing to avoid controversy and mathematical statistics we omitted model checking from our discussion.  This is something that the refereeing process picked us up on and we ultimately added a critical discussion of null-hypothesis testing to  our paper .  The exploratory technique we discussed was essentially a 2D histogram approach, but we used Polya models as a formal model for the histogram.  We are currently working on a new paper, and we are thinking through how or if we should do “confirmatory analysis” or model checking in the paper.


What I find most admirable about your statistical work is that you clearly use the Bayesian approach to do useful applied statistical analysis.  My own attempts at applied Bayesian analysis makes me greatly admire your applied successes.  On the other hand it may be t</p><p>4 0.80913681 <a title="2007-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>Introduction: In response to  my remarks  on his online book, Think Bayes, Allen Downey wrote: 
   
I [Downey] have a question about one of your comments: 
   My [Gelman's] main criticism with both books is that they talk a lot about inference but not so much about model building or model checking (recall the three steps of Bayesian data analysis). I think it’s ok for an introductory book to focus on inference, which of course is central to the data-analytic process—but I’d like them to at least mention that Bayesian ideas arise in model building and model checking as well. 

This sounds like something I agree with, and one of the things I tried to do in the book is to put modeling decisions front and center.  But the word “modeling” is used in lots of ways, so I want to see if we are talking about the same thing.


For example, in many chapters, I start with a simple model of the scenario, do some analysis, then check whether the model is good enough, and iterate.  Here’s the discussion of modeling</p><p>5 0.80701113 <a title="2007-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-19-The_%E2%80%9Ceither-or%E2%80%9D_fallacy_of_believing_in_discrete_models%3A__an_example_of_folk_statistics.html">217 andrew gelman stats-2010-08-19-The “either-or” fallacy of believing in discrete models:  an example of folk statistics</a></p>
<p>Introduction: Psychologists talk about “folk psychology”:  ideas that make sense to us about how people think and behave, even if these ideas are not accurate descriptions of reality.  And physicists talk about “folk physics” (for example, the idea that a thrown ball falls in a straight line and then suddenly drops, rather than following an approximate parabola).
 
There’s also “folk statistics.”  Some of the ideas of folk statistics are so strong that even educated people–even well-known researchers–can make these mistakes.
 
One of the ideas of folk statistics that bothers me a lot is what might be called the “either/or fallacy”:  the idea that if there are two possible stories, the truth has to be one or the other.
 
I have often encountered the either/or fallacy in Bayesian statistics, for example the vast literature on “model selection” or “variable selection” or “model averaging” in which it is assumed that one of some pre-specified discrete set of models is the truth, and that this true model</p><p>6 0.79654574 <a title="2007-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-12-UnConMax_%E2%80%93_uncertainty_consideration_maxims_7_%2B--_2.html">82 andrew gelman stats-2010-06-12-UnConMax – uncertainty consideration maxims 7 +-- 2</a></p>
<p>7 0.78782922 <a title="2007-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>8 0.78436154 <a title="2007-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Multiple_comparisons_dispute_in_the_tabloids.html">1195 andrew gelman stats-2012-03-04-Multiple comparisons dispute in the tabloids</a></p>
<p>9 0.78071994 <a title="2007-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-21-More_on_Bayesian_model_selection_in_high-dimensional_settings.html">1817 andrew gelman stats-2013-04-21-More on Bayesian model selection in high-dimensional settings</a></p>
<p>10 0.77501869 <a title="2007-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-01-Tukey%E2%80%99s_philosophy.html">496 andrew gelman stats-2011-01-01-Tukey’s philosophy</a></p>
<p>11 0.7748031 <a title="2007-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>12 0.77311021 <a title="2007-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-13-Flexibility_is_good.html">2133 andrew gelman stats-2013-12-13-Flexibility is good</a></p>
<p>13 0.77122378 <a title="2007-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>14 0.77073175 <a title="2007-lsi-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>15 0.76670933 <a title="2007-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>16 0.76611215 <a title="2007-lsi-16" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-03-This_is_a_footnote_in_one_of_my_papers.html">448 andrew gelman stats-2010-12-03-This is a footnote in one of my papers</a></p>
<p>17 0.76557523 <a title="2007-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-04-Columbo_does_posterior_predictive_checks.html">1521 andrew gelman stats-2012-10-04-Columbo does posterior predictive checks</a></p>
<p>18 0.76302892 <a title="2007-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-09-Special_journal_issue_on_statistical_methods_for_the_social_sciences.html">24 andrew gelman stats-2010-05-09-Special journal issue on statistical methods for the social sciences</a></p>
<p>19 0.76134068 <a title="2007-lsi-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-07-Valencia%3A___Summer_of_1991.html">72 andrew gelman stats-2010-06-07-Valencia:   Summer of 1991</a></p>
<p>20 0.76074821 <a title="2007-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.011), (15, 0.055), (16, 0.108), (21, 0.061), (24, 0.127), (50, 0.01), (63, 0.032), (64, 0.011), (68, 0.037), (77, 0.062), (81, 0.031), (88, 0.027), (94, 0.011), (95, 0.014), (96, 0.023), (99, 0.277)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96761316 <a title="2007-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Popper_and_Jaynes.html">2007 andrew gelman stats-2013-09-03-Popper and Jaynes</a></p>
<p>Introduction: Deborah Mayo quotes me as saying, “Popper has argued (convincingly, in my opinion) that scientific inference is not inductive but deductive.”  She then  follows up  with:
  
Gelman employs significance test-type reasoning to reject a model when the data sufficiently disagree.


Now, strictly speaking, a model falsification, even to inferring something as weak as “the model breaks down,” is not purely deductive, but Gelman is right to see it as about as close as one can get, in statistics, to a deductive falsification of a model. But where does that leave him as a Jaynesian?
  
My reply:
 
I was influenced by reading a toy example from Jaynes’s book where he sets up a model (for the probability of a die landing on each of its six sides) based on first principles, then presents some data that contradict the model, then expands the model.
 
I’d seen very little of this sort of this reasoning before in statistics!  In physics it’s the standard way to go:  you set up a model based on physic</p><p>2 0.95482796 <a title="2007-lda-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-27-%E2%80%9CWhat_Can_we_Learn_from_the_Many_Labs_Replication_Project%3F%E2%80%9D.html">2227 andrew gelman stats-2014-02-27-“What Can we Learn from the Many Labs Replication Project?”</a></p>
<p>Introduction: Aki points us to  this discussion  from Rolf Zwaan:
  
The first massive replication project in psychology has just reached completion (several others are to follow). . . . What can we learn from the ManyLabs project? The results here show the effect sizes for the replication efforts (in green and grey) as well as the original studies (in blue). The 99% confidence intervals are for the meta-analysis of the effect size (the green dots); the studies are ordered by effect size.


 


Let’s first consider what we canNOT learn from these data. Of the 13 replication attempts (when the first four are taken together), 11 succeeded and 2 did not (in fact, at some point ManyLabs suggests that a third one, Imagined Contact also doesn’t really replicate). We cannot learn from this that the vast majority of psychological findings will replicate . . .


But even if we had an accurate estimate of the percentage of findings that replicate, how useful would that be? Rather than trying to arrive at a mo</p><p>3 0.95223212 <a title="2007-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>Introduction: This seems to be the topic of the week.  Yesterday I posted on the sister blog  some further thoughts  on those “Psychological Science” papers on menstrual cycles, biceps size, and political attitudes, tied to a horrible press release from the journal Psychological Science hyping the biceps and politics study.
 
Then I was pointed to these  suggestions  from Richard Lucas and M. Brent Donnellan have on improving the replicability and reproducibility of research published in the Journal of Research in Personality:
  
It goes without saying that editors of scientific journals strive to publish research that is not only theoretically interesting but also methodologically rigorous. The goal is to select papers that advance the field. Accordingly, editors want to publish findings that can be reproduced and replicated by other scientists. Unfortunately, there has been a recent “crisis in confidence” among psychologists about the quality of psychological research (Pashler & Wagenmakers, 2012)</p><p>4 0.95131695 <a title="2007-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-23-A_statistical_version_of_Arrow%E2%80%99s_paradox.html">586 andrew gelman stats-2011-02-23-A statistical version of Arrow’s paradox</a></p>
<p>Introduction: Unfortunately, when we deal with scientists, statisticians are often put in a setting reminiscent of Arrow’s paradox, where we are asked to provide estimates that are informative and unbiased and confidence statements that are correct conditional on the data and also on the underlying true parameter. [It's not generally possible for an estimate to do all these things at the same time -- ed.]  Larry Wasserman feels that scientists are truly frequentist, and Don Rubin has told me how he feels that scientists interpret all statistical estimates Bayesianly. I have no doubt that both Larry and Don are correct. Voters want lower taxes and more services, and scientists want both Bayesian and frequency coverage; as the saying goes, everybody wants to go to heaven but nobody wants to die.</p><p>5 0.94916713 <a title="2007-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-25-Fascinating_graphs_from_facebook_data.html">1824 andrew gelman stats-2013-04-25-Fascinating graphs from facebook data</a></p>
<p>Introduction: Yair points us to  this  page full of wonderful graphs from the Stephen Wolfram blog.  Here are a few:
 
 
 
 
 
 
 
And some words:
  
People talk less about video games as they get older, and more about politics and the weather. Men typically talk more about sports and technology than women—and, somewhat surprisingly to me, they also talk more about movies, television and music. Women talk more about pets+animals, family+friends, relationships—and, at least after they reach child-bearing years, health. . . . Some of this is rather depressingly stereotypical. And most of it isn’t terribly surprising to anyone who’s known a reasonable diversity of people of different ages. But what to me is remarkable is how we can see everything laid out in such quantitative detail in the pictures above—kind of a signature of people’s thinking as they go through life. 


Of course, the pictures above are all based on aggregate data, carefully anonymized. But if we start looking at individuals, we’ll s</p><p>6 0.94870126 <a title="2007-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>7 0.94824606 <a title="2007-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-14-Pourquoi_Google_search_est_devenu_plus_raisonnable%3F.html">207 andrew gelman stats-2010-08-14-Pourquoi Google search est devenu plus raisonnable?</a></p>
<p>8 0.94769382 <a title="2007-lda-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-08-Discussion_with_Steven_Pinker_on_research_that_is_attached_to_data_that_are_so_noisy_as_to_be_essentially_uninformative.html">2326 andrew gelman stats-2014-05-08-Discussion with Steven Pinker on research that is attached to data that are so noisy as to be essentially uninformative</a></p>
<p>9 0.94706005 <a title="2007-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-07-That_last_satisfaction_at_the_end_of_the_career.html">1568 andrew gelman stats-2012-11-07-That last satisfaction at the end of the career</a></p>
<p>10 0.9466992 <a title="2007-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-02-R_needs_a_good_function_to_make_line_plots.html">252 andrew gelman stats-2010-09-02-R needs a good function to make line plots</a></p>
<p>11 0.94548655 <a title="2007-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>12 0.94385362 <a title="2007-lda-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-20-Do_differences_between_biology_and_statistics_explain_some_of_our_diverging_attitudes_regarding_criticism_and_replication_of_scientific_claims%3F.html">2218 andrew gelman stats-2014-02-20-Do differences between biology and statistics explain some of our diverging attitudes regarding criticism and replication of scientific claims?</a></p>
<p>13 0.94344145 <a title="2007-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-05-Wacky_interview_questions%3A__An_exploration_into_the_nature_of_evidence_on_the_internet.html">505 andrew gelman stats-2011-01-05-Wacky interview questions:  An exploration into the nature of evidence on the internet</a></p>
<p>14 0.94337428 <a title="2007-lda-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-%E2%80%9CThe_British_amateur_who_debunked_the_mathematics_of_happiness%E2%80%9D.html">2177 andrew gelman stats-2014-01-19-“The British amateur who debunked the mathematics of happiness”</a></p>
<p>15 0.94270688 <a title="2007-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-04-When_is_there_%E2%80%9Chidden_structure_in_data%E2%80%9D_to_be_discovered%3F.html">1788 andrew gelman stats-2013-04-04-When is there “hidden structure in data” to be discovered?</a></p>
<p>16 0.94233263 <a title="2007-lda-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-27-A_whole_fleet_of_gremlins%3A__Looking_more_carefully_at_Richard_Tol%E2%80%99s_twice-corrected_paper%2C_%E2%80%9CThe_Economic_Effects_of_Climate_Change%E2%80%9D.html">2350 andrew gelman stats-2014-05-27-A whole fleet of gremlins:  Looking more carefully at Richard Tol’s twice-corrected paper, “The Economic Effects of Climate Change”</a></p>
<p>17 0.94190902 <a title="2007-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-22-The_Jumpstart_financial_literacy_survey_and_the_different_purposes_of_tests.html">481 andrew gelman stats-2010-12-22-The Jumpstart financial literacy survey and the different purposes of tests</a></p>
<p>18 0.94149321 <a title="2007-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-06-Statistician_cracks_Toronto_lottery.html">562 andrew gelman stats-2011-02-06-Statistician cracks Toronto lottery</a></p>
<p>19 0.94121075 <a title="2007-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-20-The_AAA_Tranche_of_Subprime_Science.html">2179 andrew gelman stats-2014-01-20-The AAA Tranche of Subprime Science</a></p>
<p>20 0.94107383 <a title="2007-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-13-Test_scores_and_grades_predict_job_performance_%28but_maybe_not_at_Google%29.html">1980 andrew gelman stats-2013-08-13-Test scores and grades predict job performance (but maybe not at Google)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
