<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2041 andrew gelman stats-2013-09-27-Setting up Jitts online</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-2041" href="#">andrew_gelman_stats-2013-2041</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2041 andrew gelman stats-2013-09-27-Setting up Jitts online</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-2041-html" href="http://andrewgelman.com/2013/09/27/setting-up-jitts-online/">html</a></p><p>Introduction: I use just-in-time teaching assignments in all my classes now.  Vince helpfully sent along these instructions for setting these up on Google.  See below.
 
I think Jitts are just wonderful, and they’re so easy to set up, you should definitely be doing them in your classes too.  I’ve had more difficulty with Peer Instruction (the companion tool to just-in-time teaching) as it requires questions at just the right level for the class.  I do have students frequently work in pairs, though, so I think I get some of the benefit of that.
 
P.S.  I’d love to share all the Jitts with you for Bayesian Data Analysis, but I’m afraid this would poison the well and future students would not have the opportunity to be surprised by them.  Yes, I know, I should just come up with new ones every year—but I’m not quite ready to do that!  Perhaps soon I will.
 
In the meantime, a commenter asked for some Jitts, so here are the ones for the first and last weeks of class:
  

Jitt questions for Bayesian Data</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Vince helpfully sent along these instructions for setting these up on Google. [sent-2, score-0.196]
</p><p>2 In a national survey of n people, you estimate the gender gap—the difference in support for Obama among men and women. [sent-13, score-0.175]
</p><p>3 How large does n have to be so that you can estimate this gender gap to within a standard error of +/- 3 percentage points? [sent-14, score-0.28]
</p><p>4 I have three cards:  one is black on both sides, one is red on both sides, and one is black on one side and red on the other. [sent-16, score-0.448]
</p><p>5 I pick a card at random out of a hat and look at one side only. [sent-17, score-0.253]
</p><p>6 What is the probability that the other side is black? [sent-19, score-0.18]
</p><p>7 If x ~ N(0,1) and y ~ N(0,1) are indepdent random variables, calculate the probability that |x| > 2|y|. [sent-23, score-0.184]
</p><p>8 It would be best to use the full posterior distribution but you need a point estimate. [sent-37, score-0.204]
</p><p>9 Which of the following would you prefer:  the posterior mean, the posterior median, or the posterior mode? [sent-38, score-0.612]
</p><p>10 Assume each of these is done pointwise (that is, you are getting the marginal mean, median, or mode of the latent component for each data point, not the joint mean, median, or mode for all the data points at once). [sent-39, score-0.472]
</p><p>11 Assume x and y are normally distributed with mean 0, variance 1, and correlation r>0. [sent-43, score-0.211]
</p><p>12 We draw a large sample from this bivariate distribution and then throw away all (x,y) pairs where either x or y is less than zero. [sent-44, score-0.192]
</p><p>13 We calculate the sample correlation using the remaining samples. [sent-45, score-0.306]
</p><p>14 On average, will this sample correlation be higher, lower, or equal to r? [sent-46, score-0.2]
</p><p>15 Consider a Dirichlet process with the precision parameter alpha converging to 0. [sent-48, score-0.198]
</p><p>16 The limiting posterior of is sometimes known as ________. [sent-49, score-0.322]
</p><p>17 What is the limiting posterior as alpha increases to infinity? [sent-50, score-0.437]
</p><p>18 com/  2) Sign in, if necessary  3) Click create -> Form  4) Bypass the annoying pop-up, if necessary  5) Name the form, probably pick the default theme  6) Repeat until done:   6. [sent-56, score-0.547]
</p><p>19 0) For the first time through, create a text response with the student’s name   6. [sent-57, score-0.386]
</p><p>20 5) Click “Add item” if necessary  7) Under Confirmation Page at the bottom, probably disable “Show link to submit…” and enable “Allow responders to edit”  8) Under “Choose response destination” button on the toolbar, can have it all go into a common spreadsheet. [sent-62, score-0.401]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('jitts', 0.248), ('class', 0.214), ('posterior', 0.204), ('median', 0.165), ('create', 0.159), ('mode', 0.157), ('vince', 0.144), ('chapter', 0.14), ('classes', 0.134), ('black', 0.133), ('text', 0.128), ('button', 0.128), ('limiting', 0.118), ('instructions', 0.118), ('correlation', 0.117), ('question', 0.117), ('necessary', 0.116), ('alpha', 0.115), ('pairs', 0.109), ('calculate', 0.106), ('gap', 0.105), ('side', 0.102), ('name', 0.099), ('gender', 0.098), ('sides', 0.097), ('mean', 0.094), ('form', 0.092), ('interaction', 0.092), ('bottom', 0.09), ('click', 0.088), ('sample', 0.083), ('questions', 0.083), ('converging', 0.083), ('jitt', 0.083), ('pointwise', 0.083), ('students', 0.082), ('ones', 0.08), ('three', 0.08), ('probably', 0.079), ('probability', 0.078), ('bypass', 0.078), ('helpfully', 0.078), ('responders', 0.078), ('pick', 0.077), ('estimate', 0.077), ('send', 0.075), ('done', 0.075), ('share', 0.075), ('companion', 0.074), ('hat', 0.074)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="2041-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-27-Setting_up_Jitts_online.html">2041 andrew gelman stats-2013-09-27-Setting up Jitts online</a></p>
<p>Introduction: I use just-in-time teaching assignments in all my classes now.  Vince helpfully sent along these instructions for setting these up on Google.  See below.
 
I think Jitts are just wonderful, and they’re so easy to set up, you should definitely be doing them in your classes too.  I’ve had more difficulty with Peer Instruction (the companion tool to just-in-time teaching) as it requires questions at just the right level for the class.  I do have students frequently work in pairs, though, so I think I get some of the benefit of that.
 
P.S.  I’d love to share all the Jitts with you for Bayesian Data Analysis, but I’m afraid this would poison the well and future students would not have the opportunity to be surprised by them.  Yes, I know, I should just come up with new ones every year—but I’m not quite ready to do that!  Perhaps soon I will.
 
In the meantime, a commenter asked for some Jitts, so here are the ones for the first and last weeks of class:
  

Jitt questions for Bayesian Data</p><p>2 0.18698621 <a title="2041-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-25-Avoiding_boundary_estimates_using_a_prior_distribution_as_regularization.html">779 andrew gelman stats-2011-06-25-Avoiding boundary estimates using a prior distribution as regularization</a></p>
<p>Introduction: For awhile I’ve been fitting most of my multilevel models using lmer/glmer, which gives point estimates of the group-level variance parameters (maximum marginal likelihood estimate for lmer and an approximation for glmer).  I’m usually satisfied with this–sure, point estimation understates the uncertainty in model fitting, but that’s typically the least of our worries. 
 
Sometimes, though, lmer/glmer estimates group-level variances at 0 or estimates group-level correlation parameters at +/- 1.  Typically, when this happens, it’s not that we’re so sure the variance is close to zero or that the correlation is close to 1 or -1; rather, the marginal likelihood does not provide a lot of information about these parameters of the group-level error distribution.
 
I don’t want point estimates on the boundary.  I don’t want to say that the unexplained variance in some dimension is exactly zero.
 
One way to handle this problem is full Bayes:  slap a prior on sigma, do your Gibbs and Metropolis</p><p>3 0.16386642 <a title="2041-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-07-Feedback_on_my_Bayesian_Data_Analysis_class_at_Columbia.html">1611 andrew gelman stats-2012-12-07-Feedback on my Bayesian Data Analysis class at Columbia</a></p>
<p>Introduction: In one of the final Jitts, we asked the students how the course could be improved.  Some of their suggestions would work, some would not.  I’m putting all the suggestions below, interpolating my responses.  (Overall, I think the course went well.  Please remember that the remarks below are not course evaluations; they are answers to my specific question of how the course could be better.  If we’d had a Jitt asking all the ways the course was good, you’d be seeing lots of positive remarks.  But that wouldn’t be particularly useful or interesting.)  The best thing about the course is that the kids worked hard each week on their homeworks.
 
OK, here are the comments and my replies: 
  
  
Could have been better if we did less amount but more in detail.
  
I don’t know if this would’ve been possible.  I wanted to get to the harder stuff (HMC, VB, nonparametric models) which required a certain amount of preparation.  And, even so, there was not time for everything.
  
And also, needs solut</p><p>4 0.15032201 <a title="2041-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-01-%E2%80%9COn_Inspiring_Students_and_Being_Human%E2%80%9D.html">1517 andrew gelman stats-2012-10-01-“On Inspiring Students and Being Human”</a></p>
<p>Introduction: Rachel Schutt (the author of the Taxonomy of Confusion)  has a blog!  for the course she’s teaching at Columbia, “Introduction to Data Science.”  It sounds like a great course—I wish I could take it!
 
Her latest post is “On Inspiring Students and Being Human”:
 
   
  
Of course one hopes as a teacher that one will inspire students . . . But what I actually mean by “inspiring students” is that you are inspiring me; you are students who inspire: “inspiring students”. This is one of the happy unintended consequences of this course so far for me.
  
She then gives examples of some of the students in her class and some of their interesting ideas:
  
Phillip is a PhD student in the sociology department . . . He’s in the process of developing his thesis topic around some of the themes we’ve been discussing in this class, such as the emerging data science community.


Arvi works at the College Board and is a part time student . . . He analyzes user-level data of students who have signed up f</p><p>5 0.14815724 <a title="2041-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-02-My_course_this_fall_on_l%E2%80%99analyse_bay%C3%A9sienne_de_donn%C3%A9es.html">1965 andrew gelman stats-2013-08-02-My course this fall on l’analyse bayésienne de données</a></p>
<p>Introduction: X marks the  spot .  I’ll post the slides soon (not just for the students in my class; these should be helpful for anyone teaching Bayesian data analysis from  our book ).  But I don’t think you’ll get much from reading the slides alone; you’ll get more out of the book (or, of course, from taking the class).</p><p>6 0.14755808 <a title="2041-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-23-Combining_survey_data_obtained_using_different_modes_of_sampling.html">777 andrew gelman stats-2011-06-23-Combining survey data obtained using different modes of sampling</a></p>
<p>7 0.13818361 <a title="2041-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-06-Bootstrap_averaging%3A_Examples_where_it_works_and_where_it_doesn%E2%80%99t_work.html">2201 andrew gelman stats-2014-02-06-Bootstrap averaging: Examples where it works and where it doesn’t work</a></p>
<p>8 0.13522181 <a title="2041-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Online_Education_and_Jazz.html">1752 andrew gelman stats-2013-03-06-Online Education and Jazz</a></p>
<p>9 0.1342566 <a title="2041-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>10 0.129554 <a title="2041-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-16-Priors.html">1941 andrew gelman stats-2013-07-16-Priors</a></p>
<p>11 0.12851097 <a title="2041-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-03-Question_about_predictive_checks.html">1363 andrew gelman stats-2012-06-03-Question about predictive checks</a></p>
<p>12 0.1253417 <a title="2041-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-29-Question_19_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1352 andrew gelman stats-2012-05-29-Question 19 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>13 0.12013342 <a title="2041-tfidf-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-28-New_app_for_learning_intro_statistics.html">735 andrew gelman stats-2011-05-28-New app for learning intro statistics</a></p>
<p>14 0.11978083 <a title="2041-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>15 0.11971679 <a title="2041-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>16 0.11936399 <a title="2041-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-28-Question_18_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1349 andrew gelman stats-2012-05-28-Question 18 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>17 0.11733691 <a title="2041-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<p>18 0.11511638 <a title="2041-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-18-What_is_this%2C_a_statistics_class_or_a_dentist%E2%80%99s_office%3F%3F.html">579 andrew gelman stats-2011-02-18-What is this, a statistics class or a dentist’s office??</a></p>
<p>19 0.11199526 <a title="2041-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-18-How_to_teach_methods_we_don%E2%80%99t_like%3F.html">1582 andrew gelman stats-2012-11-18-How to teach methods we don’t like?</a></p>
<p>20 0.11022583 <a title="2041-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.269), (1, 0.068), (2, 0.063), (3, 0.009), (4, 0.098), (5, 0.101), (6, 0.074), (7, 0.091), (8, -0.067), (9, -0.069), (10, 0.072), (11, -0.001), (12, 0.015), (13, 0.008), (14, 0.007), (15, -0.04), (16, 0.02), (17, -0.018), (18, -0.06), (19, 0.004), (20, 0.044), (21, 0.008), (22, 0.063), (23, -0.046), (24, -0.023), (25, 0.04), (26, 0.03), (27, 0.016), (28, 0.052), (29, -0.043), (30, 0.019), (31, 0.026), (32, -0.029), (33, 0.0), (34, 0.013), (35, 0.001), (36, -0.019), (37, -0.074), (38, -0.008), (39, 0.002), (40, 0.013), (41, -0.043), (42, 0.023), (43, -0.006), (44, -0.004), (45, 0.053), (46, 0.022), (47, 0.017), (48, 0.017), (49, -0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97313881 <a title="2041-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-27-Setting_up_Jitts_online.html">2041 andrew gelman stats-2013-09-27-Setting up Jitts online</a></p>
<p>Introduction: I use just-in-time teaching assignments in all my classes now.  Vince helpfully sent along these instructions for setting these up on Google.  See below.
 
I think Jitts are just wonderful, and they’re so easy to set up, you should definitely be doing them in your classes too.  I’ve had more difficulty with Peer Instruction (the companion tool to just-in-time teaching) as it requires questions at just the right level for the class.  I do have students frequently work in pairs, though, so I think I get some of the benefit of that.
 
P.S.  I’d love to share all the Jitts with you for Bayesian Data Analysis, but I’m afraid this would poison the well and future students would not have the opportunity to be surprised by them.  Yes, I know, I should just come up with new ones every year—but I’m not quite ready to do that!  Perhaps soon I will.
 
In the meantime, a commenter asked for some Jitts, so here are the ones for the first and last weeks of class:
  

Jitt questions for Bayesian Data</p><p>2 0.76769918 <a title="2041-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-20-The_candy_weighing_demonstration%2C_or%2C_the_unwisdom_of_crowds.html">2257 andrew gelman stats-2014-03-20-The candy weighing demonstration, or, the unwisdom of crowds</a></p>
<p>Introduction: From 2008:
  
 The candy weighing demonstration, or, the unwisdom of crowds 


My favorite statistics demonstration is the one with the bag of candies. I’ve elaborated upon it since including it in  the Teaching Statistics book  and I thought these tips might be useful to some of you.


 Preparation 


Buy 100 candies of different sizes and shapes and put them in a bag (the plastic bag from the store is fine). Get something like 20 large full-sized candy bars, 20 or 30 little things like mini Snickers bars and mini Peppermint Patties. And then 50 or 60 really little things like tiny Tootsie Rolls, lollipops, and individually-wrapped Life Savers. Count and make sure it’s exactly 100.


You also need a digital kitchen scale that reads out in grams.


Also bring a sealed envelope inside of which is a note (details below). When you get into the room, unobtrusively put the note somewhere, for example between two books on a shelf or behind a window shade.


 Setup 


Hold up the back of cand</p><p>3 0.76251185 <a title="2041-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-01-I%E2%80%99ll_say_it_again.html">2046 andrew gelman stats-2013-10-01-I’ll say it again</a></p>
<p>Introduction: Milan Valasek writes:
  
Psychology students (and probably students in other disciplines) are often taught that in order to perform ‘parametric’ tests, e.g. independent t-test, the data for each group need to be normally distributed. However, in literature (and various university lecture notes and slides accessible online), I have come across at least 4 different interpretation of what it is that is supposed to be normally distributed when doing a t-test:


1. population 
2. sampled data for each group 
3. distribution of estimates of means for each group 
4. distribution of estimates of the difference between groups


I can see how 2 would follow from 1 and 4 from 3 but even then, there are two different sets of interpretations of the normality assumption. 
Could you please put this issue to rest for me?
  
My quick response is that normality is  not so important  unless you are focusing on prediction.</p><p>4 0.73040742 <a title="2041-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-14-In_an_introductory_course%2C_when_does_learning_occur%3F.html">277 andrew gelman stats-2010-09-14-In an introductory course, when does learning occur?</a></p>
<p>Introduction: Now that September has arrived, it’s time for us to think teaching.   Here’s something  from Andrew Heckler and Eleanor Sayre.  Heckler writes:
  
The article describes a project studying the performance of university level students taking an intro physics course. Every week for ten weeks we took 1/10th of the students (randomly selected only once) and gave them the same set of questions relevant to the course. This allowed us to plot the evolution of average performance in the class during the quarter.  We can then determine when learning occurs: For example, do they learn the material in a relevant lecture or lab or homework? Since we had about 350 students taking the course, we could get some reasonable stats.


In particular, you might be interested in Figure 10 (page 774) which shows student performance day-by-day on a particular question.  The performance does not change directly after lecture, but rather only when the homework was due.  [emphasis added] We could not find any oth</p><p>5 0.7214936 <a title="2041-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-07-Feedback_on_my_Bayesian_Data_Analysis_class_at_Columbia.html">1611 andrew gelman stats-2012-12-07-Feedback on my Bayesian Data Analysis class at Columbia</a></p>
<p>Introduction: In one of the final Jitts, we asked the students how the course could be improved.  Some of their suggestions would work, some would not.  I’m putting all the suggestions below, interpolating my responses.  (Overall, I think the course went well.  Please remember that the remarks below are not course evaluations; they are answers to my specific question of how the course could be better.  If we’d had a Jitt asking all the ways the course was good, you’d be seeing lots of positive remarks.  But that wouldn’t be particularly useful or interesting.)  The best thing about the course is that the kids worked hard each week on their homeworks.
 
OK, here are the comments and my replies: 
  
  
Could have been better if we did less amount but more in detail.
  
I don’t know if this would’ve been possible.  I wanted to get to the harder stuff (HMC, VB, nonparametric models) which required a certain amount of preparation.  And, even so, there was not time for everything.
  
And also, needs solut</p><p>6 0.7104339 <a title="2041-lsi-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-10-Hey%2C_where%E2%80%99s_my_kickback%3F.html">78 andrew gelman stats-2010-06-10-Hey, where’s my kickback?</a></p>
<p>7 0.7018224 <a title="2041-lsi-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-09-Kaggle%3A__forecasting_competitions_in_the_classroom.html">402 andrew gelman stats-2010-11-09-Kaggle:  forecasting competitions in the classroom</a></p>
<p>8 0.69696015 <a title="2041-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-03-Comparing_prediction_errors.html">938 andrew gelman stats-2011-10-03-Comparing prediction errors</a></p>
<p>9 0.68969995 <a title="2041-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-31-Value-added_modeling_in_education%3A__Gaming_the_system_by_sending_kids_on_a_field_trip_at_test_time.html">2083 andrew gelman stats-2013-10-31-Value-added modeling in education:  Gaming the system by sending kids on a field trip at test time</a></p>
<p>10 0.68739665 <a title="2041-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-10-Who%E2%80%99s_holding_the_pen%3F%2C_The_split_screen%2C_and_other_ideas_for_one-on-one_instruction.html">462 andrew gelman stats-2010-12-10-Who’s holding the pen?, The split screen, and other ideas for one-on-one instruction</a></p>
<p>11 0.68490195 <a title="2041-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-01-%E2%80%9COn_Inspiring_Students_and_Being_Human%E2%80%9D.html">1517 andrew gelman stats-2012-10-01-“On Inspiring Students and Being Human”</a></p>
<p>12 0.68175519 <a title="2041-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-18-Course_proposal%3A_Bayesian_and_advanced_likelihood_statistical_methods_for_zombies..html">96 andrew gelman stats-2010-06-18-Course proposal: Bayesian and advanced likelihood statistical methods for zombies.</a></p>
<p>13 0.67919284 <a title="2041-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-06-Online_Education_and_Jazz.html">1752 andrew gelman stats-2013-03-06-Online Education and Jazz</a></p>
<p>14 0.67160898 <a title="2041-lsi-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-21-Everything_I_need_to_know_about_Bayesian_statistics%2C_I_learned_in_eight_schools..html">2180 andrew gelman stats-2014-01-21-Everything I need to know about Bayesian statistics, I learned in eight schools.</a></p>
<p>15 0.66804981 <a title="2041-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-Evaluating_Columbia_University%E2%80%99s_Frontiers_of_Science_course.html">1864 andrew gelman stats-2013-05-20-Evaluating Columbia University’s Frontiers of Science course</a></p>
<p>16 0.66696775 <a title="2041-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-13-Hey%2C_you%21__Don%E2%80%99t_take_that_class%21.html">956 andrew gelman stats-2011-10-13-Hey, you!  Don’t take that class!</a></p>
<p>17 0.66694826 <a title="2041-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-18-Data_to_use_for_in-class_sampling_exercises%3F.html">1943 andrew gelman stats-2013-07-18-Data to use for in-class sampling exercises?</a></p>
<p>18 0.66206241 <a title="2041-lsi-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-31-Somewhat_Bayesian_multilevel_modeling.html">246 andrew gelman stats-2010-08-31-Somewhat Bayesian multilevel modeling</a></p>
<p>19 0.66075921 <a title="2041-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-18-How_to_teach_methods_we_don%E2%80%99t_like%3F.html">1582 andrew gelman stats-2012-11-18-How to teach methods we don’t like?</a></p>
<p>20 0.65942562 <a title="2041-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-18-What_is_this%2C_a_statistics_class_or_a_dentist%E2%80%99s_office%3F%3F.html">579 andrew gelman stats-2011-02-18-What is this, a statistics class or a dentist’s office??</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.011), (6, 0.011), (9, 0.036), (16, 0.062), (21, 0.036), (24, 0.164), (45, 0.038), (52, 0.046), (59, 0.011), (66, 0.021), (72, 0.032), (86, 0.061), (99, 0.351)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9877004 <a title="2041-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-27-Setting_up_Jitts_online.html">2041 andrew gelman stats-2013-09-27-Setting up Jitts online</a></p>
<p>Introduction: I use just-in-time teaching assignments in all my classes now.  Vince helpfully sent along these instructions for setting these up on Google.  See below.
 
I think Jitts are just wonderful, and they’re so easy to set up, you should definitely be doing them in your classes too.  I’ve had more difficulty with Peer Instruction (the companion tool to just-in-time teaching) as it requires questions at just the right level for the class.  I do have students frequently work in pairs, though, so I think I get some of the benefit of that.
 
P.S.  I’d love to share all the Jitts with you for Bayesian Data Analysis, but I’m afraid this would poison the well and future students would not have the opportunity to be surprised by them.  Yes, I know, I should just come up with new ones every year—but I’m not quite ready to do that!  Perhaps soon I will.
 
In the meantime, a commenter asked for some Jitts, so here are the ones for the first and last weeks of class:
  

Jitt questions for Bayesian Data</p><p>2 0.97904557 <a title="2041-lda-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-04-Questions_about_quantum_computing.html">786 andrew gelman stats-2011-07-04-Questions about quantum computing</a></p>
<p>Introduction: I read  this article  by Rivka Galchen on quantum computing.  Much of the article was about an eccentric scientist in his fifties named David Deutch.  I’m sure the guy is brilliant but I wasn’t particularly interested in his not particularly interesting life story (apparently he’s thin and lives in Oxford).  There was a brief description of quantum computing itself, which reminds me of the discussion we had a couple years ago under the heading,  The laws of conditional probability are false  (and the update  here ).
 
I don’t have anything new to say here; I’d just never heard of quantum computing before and it seemed relevant to our discussion.  The uncertainty inherent in quantum computing seems closely related to Jouni’s idea of  fully Bayesian computing , that uncertainty should be inherent in the computational structure rather than tacked on at the end.
 
P.S.  No, I’m not working on July 4th!  This post is two months old, we just have a long waiting list of blog entries.</p><p>3 0.9788664 <a title="2041-lda-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-06-Your_conclusion_is_only_as_good_as_your_data.html">1369 andrew gelman stats-2012-06-06-Your conclusion is only as good as your data</a></p>
<p>Introduction: Jay Livingston  points  to an excellent rant from Peter Moskos, trashing a study about “food deserts” (which I kept reading as “food desserts”) in inner-city neighborhoods.
 
Here’s Moskos:
  
From the Times:

 
There is no relationship between the type of food being sold in a neighborhood and obesity among its children and adolescents. 


Within a couple of miles of almost any urban neighborhood, “you can get basically any type of food,” said Roland Sturm of the RAND Corporation, lead author of one of the studies. “Maybe we should call it a food swamp rather than a desert,” he said.
 

Sure thing, Sturm. But I suspect you wouldn’t think certain neighborhoods are swamped with good food if you actually got out of your office and went to one of the neighborhoods. After all, what are going to believe: A nice data set or your lying eyes?


“Food outlet data … are classifıed using the North American Industry Classifıcation System (NAICS)” (p. 130). Assuming validity and reliability of NAICS</p><p>4 0.97801375 <a title="2041-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-22-My_talks_that_were_scheduled_for_Tues_at_the_Data_Skeptics_meetup_and_Wed_at_the_Open_Statistical_Programming_meetup.html">1950 andrew gelman stats-2013-07-22-My talks that were scheduled for Tues at the Data Skeptics meetup and Wed at the Open Statistical Programming meetup</a></p>
<p>Introduction: Statistical Methods and Data Skepticism 
  
Data analysis today is dominated by three paradigms:  null hypothesis significance testing, Bayesian inference, and exploratory data analysis.  There is concern that all these methods lead to overconfidence on the part of researchers and the general public, and this concern has led to the new “data skepticism” movement.


But the history of statistics is already in some sense a history of data skepticism.  Concepts of bias, variance, sampling and measurement error, least-squares regression, and statistical significance can all be viewed as formalizations of data skepticism.  All these methods address the concern that patterns in observed data might not generalize to the population of interest.


We discuss the challenge of attaining data skepticism while avoiding data nihilism, and consider some proposed future directions.
  
 Stan 
  
Stan (mc-stan.org) is an open-source package for obtaining Bayesian inference using the No-U-Turn sampler, a</p><p>5 0.97720158 <a title="2041-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>Introduction: Astrophysicist Andrew Jaffe pointed me to  this and discussion  of my  philosophy  of statistics (which is, in turn, my rational reconstruction of the statistical practice of Bayesians such as Rubin and Jaynes).  Jaffe’s summary is fair enough and I only disagree in a few points: 
   
1.  Jaffe writes:
  
Subjective probability, at least the way it is actually used by practicing scientists, is a sort of “as-if” subjectivity — how would an agent reason if her beliefs were reflected in a certain set of probability distributions? This is why when I discuss probability I try to make the pedantic point that all probabilities are conditional, at least on some background prior information or context.
  
I agree, and my problem with the usual procedures used for Bayesian model comparison and Bayesian model averaging is not that these approaches are subjective but that the particular models being considered don’t make sense.  I’m thinking of the sorts of models that say the truth is either A or</p><p>6 0.97716898 <a title="2041-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>7 0.97711146 <a title="2041-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-21-Discussion_of_the_paper_by_Girolami_and_Calderhead_on_Bayesian_computation.html">288 andrew gelman stats-2010-09-21-Discussion of the paper by Girolami and Calderhead on Bayesian computation</a></p>
<p>8 0.97562546 <a title="2041-lda-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-22-Struggles_over_the_criticism_of_the_%E2%80%9Ccannabis_users_and_IQ_change%E2%80%9D_paper.html">1910 andrew gelman stats-2013-06-22-Struggles over the criticism of the “cannabis users and IQ change” paper</a></p>
<p>9 0.97538114 <a title="2041-lda-9" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-03-He_doesn%E2%80%99t_trust_the_fit_._._._r%3D.999.html">315 andrew gelman stats-2010-10-03-He doesn’t trust the fit . . . r=.999</a></p>
<p>10 0.97503167 <a title="2041-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-02-Fishing_for_cherries.html">1746 andrew gelman stats-2013-03-02-Fishing for cherries</a></p>
<p>11 0.97438991 <a title="2041-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-24-Parables_vs._stories.html">2184 andrew gelman stats-2014-01-24-Parables vs. stories</a></p>
<p>12 0.97432363 <a title="2041-lda-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>13 0.97429991 <a title="2041-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-11-Gladwell_and_Chabris%2C_David_and_Goliath%2C_and_science_writing_as_stone_soup.html">2058 andrew gelman stats-2013-10-11-Gladwell and Chabris, David and Goliath, and science writing as stone soup</a></p>
<p>14 0.97424281 <a title="2041-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-06-%2463%2C000_worth_of_abusive_research_._._._or_just_a_really_stupid_waste_of_time%3F.html">18 andrew gelman stats-2010-05-06-$63,000 worth of abusive research . . . or just a really stupid waste of time?</a></p>
<p>15 0.97410065 <a title="2041-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-Contest_for_developing_an_R_package_recommendation_system.html">324 andrew gelman stats-2010-10-07-Contest for developing an R package recommendation system</a></p>
<p>16 0.9740817 <a title="2041-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-10-Chris_Chabris_is_irritated_by_Malcolm_Gladwell.html">2057 andrew gelman stats-2013-10-10-Chris Chabris is irritated by Malcolm Gladwell</a></p>
<p>17 0.97405809 <a title="2041-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>18 0.97399217 <a title="2041-lda-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-18-Postdoc_positions_at_Microsoft_Research_%E2%80%93_NYC.html">1630 andrew gelman stats-2012-12-18-Postdoc positions at Microsoft Research – NYC</a></p>
<p>19 0.97346711 <a title="2041-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>20 0.97315991 <a title="2041-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-23-No_one_knows_what_it%E2%80%99s_like_to_be_the_bad_man.html">1588 andrew gelman stats-2012-11-23-No one knows what it’s like to be the bad man</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
