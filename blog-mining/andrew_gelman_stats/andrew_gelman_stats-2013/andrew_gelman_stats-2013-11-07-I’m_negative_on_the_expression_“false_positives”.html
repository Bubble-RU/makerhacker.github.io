<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-2093" href="#">andrew_gelman_stats-2013-2093</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-2093-html" href="http://andrewgelman.com/2013/11/07/nix-expression-false-positives/">html</a></p><p>Introduction: After seeing a document sent to me and others regarding the  crisis  of spurious, statistically-significant research findings in psychology research, I had the following reaction:
  
I am unhappy with the use in the document of the phrase “false positives.”  I feel that this expression is unhelpful as it frames science in terms of “true” and “false” claims, which I don’t think is particularly accurate.  In particular, in most of the recent disputed Psych Science type studies (the ESP study excepted, perhaps), there is little doubt that there is _some_ underlying effect.  The issue, as I see it, as that the underlying effects are much smaller, and much more variable, than mainstream researchers imagine.  So what happens is that Psych Science or Nature or whatever will publish a result that is purported to be some sort of universal truth, but it is actually a pattern specific to one data set, one population, and one experimental condition.  In a sense, yes, these journals are publishing</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 After seeing a document sent to me and others regarding the  crisis  of spurious, statistically-significant research findings in psychology research, I had the following reaction:    I am unhappy with the use in the document of the phrase “false positives. [sent-1, score-0.758]
</p><p>2 ”  I feel that this expression is unhelpful as it frames science in terms of “true” and “false” claims, which I don’t think is particularly accurate. [sent-2, score-0.751]
</p><p>3 In particular, in most of the recent disputed Psych Science type studies (the ESP study excepted, perhaps), there is little doubt that there is _some_ underlying effect. [sent-3, score-0.773]
</p><p>4 The issue, as I see it, as that the underlying effects are much smaller, and much more variable, than mainstream researchers imagine. [sent-4, score-0.491]
</p><p>5 So what happens is that Psych Science or Nature or whatever will publish a result that is purported to be some sort of universal truth, but it is actually a pattern specific to one data set, one population, and one experimental condition. [sent-5, score-0.57]
</p><p>6 In a sense, yes, these journals are publishing false claims. [sent-6, score-0.588]
</p><p>7 But it’s not clear to me that the framing in terms of “false positive” etc. [sent-7, score-0.405]
</p><p>8 It’s not like I think the true effects are zero, I just think there’s not much of a relationship between what is found in a particular study, and more general phenomena of interest. [sent-9, score-0.685]
</p><p>9 I can understand if my preferred framing in terms of Type M and Type S errors is too new and unfamiliar to use here, but I do think that a key part of this effort should be to move away from the whole Type 1, Type 2, false positive, false negative, etc. [sent-10, score-1.7]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('false', 0.438), ('type', 0.338), ('psych', 0.25), ('framing', 0.218), ('document', 0.199), ('terms', 0.187), ('excepted', 0.149), ('unhelpful', 0.143), ('underlying', 0.142), ('frames', 0.138), ('disputed', 0.134), ('positive', 0.125), ('spurious', 0.122), ('unfamiliar', 0.12), ('purported', 0.117), ('science', 0.115), ('phenomena', 0.109), ('unhappy', 0.107), ('esp', 0.106), ('mainstream', 0.105), ('universal', 0.104), ('preferred', 0.1), ('expression', 0.099), ('effects', 0.098), ('true', 0.098), ('crisis', 0.098), ('study', 0.088), ('phrase', 0.086), ('relationship', 0.086), ('particular', 0.083), ('smaller', 0.081), ('framework', 0.081), ('truth', 0.08), ('reaction', 0.078), ('publishing', 0.078), ('experimental', 0.074), ('much', 0.073), ('journals', 0.072), ('pattern', 0.072), ('doubt', 0.071), ('seeing', 0.069), ('think', 0.069), ('negative', 0.069), ('nature', 0.069), ('publish', 0.068), ('happens', 0.068), ('specific', 0.067), ('move', 0.066), ('variable', 0.064), ('effort', 0.064)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="2093-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>Introduction: After seeing a document sent to me and others regarding the  crisis  of spurious, statistically-significant research findings in psychology research, I had the following reaction:
  
I am unhappy with the use in the document of the phrase “false positives.”  I feel that this expression is unhelpful as it frames science in terms of “true” and “false” claims, which I don’t think is particularly accurate.  In particular, in most of the recent disputed Psych Science type studies (the ESP study excepted, perhaps), there is little doubt that there is _some_ underlying effect.  The issue, as I see it, as that the underlying effects are much smaller, and much more variable, than mainstream researchers imagine.  So what happens is that Psych Science or Nature or whatever will publish a result that is purported to be some sort of universal truth, but it is actually a pattern specific to one data set, one population, and one experimental condition.  In a sense, yes, these journals are publishing</p><p>2 0.18992105 <a title="2093-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-26-Difficulties_in_making_inferences_about_scientific_truth_from_distributions_of_published_p-values.html">2040 andrew gelman stats-2013-09-26-Difficulties in making inferences about scientific truth from distributions of published p-values</a></p>
<p>Introduction: Jeff Leek  just posted  the discussions of his paper (with Leah Jager), “An estimate of the science-wise false discovery rate and application to the top medical literature,” along with some further comments of his own.
 
 Here  are my original thoughts on an earlier version of their article.  Keith O’Rourke and I expanded these thoughts into  a formal comment  for the journal.  We’re pretty much in agreement with John Ioannidis (you can find his discussion in the top link above).
 
In quick summary, I agree with Jager and Leek that this is an important topic.  I think there are two key places where Keith and I disagree with them:
 
1.  They take published p-values at face value whereas we consider them as the result of a complicated process of selection.  This is something I didn’t used to think much about, but now I’ve become increasingly convinced that the problems with published p-values is not a simple file-drawer effect or the case of a few p=0.051 values nudged toward p=0.049, bu</p><p>3 0.16711566 <a title="2093-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>Introduction: This article  is a discussion of a  paper  by Greg Francis for a special issue, edited by E. J. Wagenmakers, of the Journal of Mathematical Psychology.  Here’s what I wrote:
  
Much of statistical practice is an effort to reduce or deny variation and uncertainty. The reduction is done through standardization, replication, and other practices of experimental design, with the idea being to isolate and stabilize the quantity being estimated and then average over many cases. Even so, however, uncertainty persists, and statistical hypothesis testing is in many ways an endeavor to deny this, by reporting binary accept/reject decisions.


Classical statistical methods produce binary statements, but there is no reason to assume that the world works that way. Expressions such as Type 1 error, Type 2 error, false positive, and so on, are based on a model in which the world is divided into real and non-real effects. To put it another way, I understand the general scientific distinction of real vs</p><p>4 0.1612331 <a title="2093-tfidf-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-Type_S_error_rates_for_classical_and_Bayesian_single_and_multiple_comparison_procedures.html">494 andrew gelman stats-2010-12-31-Type S error rates for classical and Bayesian single and multiple comparison procedures</a></p>
<p>Introduction: Type S error:  When your estimate is the wrong sign, compared to the true value of the parameter
 
Type M error:  When the magnitude of your estimate is far off, compared to the true value of the parameter 
  
More here.</p><p>5 0.15174648 <a title="2093-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>Introduction: This seems to be the topic of the week.  Yesterday I posted on the sister blog  some further thoughts  on those “Psychological Science” papers on menstrual cycles, biceps size, and political attitudes, tied to a horrible press release from the journal Psychological Science hyping the biceps and politics study.
 
Then I was pointed to these  suggestions  from Richard Lucas and M. Brent Donnellan have on improving the replicability and reproducibility of research published in the Journal of Research in Personality:
  
It goes without saying that editors of scientific journals strive to publish research that is not only theoretically interesting but also methodologically rigorous. The goal is to select papers that advance the field. Accordingly, editors want to publish findings that can be reproduced and replicated by other scientists. Unfortunately, there has been a recent “crisis in confidence” among psychologists about the quality of psychological research (Pashler & Wagenmakers, 2012)</p><p>6 0.15105684 <a title="2093-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-31-No_on_Yes-No_decisions.html">2155 andrew gelman stats-2013-12-31-No on Yes-No decisions</a></p>
<p>7 0.15079761 <a title="2093-tfidf-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-12-Thinking_like_a_statistician_%28continuously%29_rather_than_like_a_civilian_%28discretely%29.html">1575 andrew gelman stats-2012-11-12-Thinking like a statistician (continuously) rather than like a civilian (discretely)</a></p>
<p>8 0.14690083 <a title="2093-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>9 0.1337807 <a title="2093-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-06-That_silly_ESP_paper_and_some_silliness_in_a_rebuttal_as_well.html">506 andrew gelman stats-2011-01-06-That silly ESP paper and some silliness in a rebuttal as well</a></p>
<p>10 0.13030142 <a title="2093-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-16-%E2%80%9CFalse-positive_psychology%E2%80%9D.html">1171 andrew gelman stats-2012-02-16-“False-positive psychology”</a></p>
<p>11 0.12495616 <a title="2093-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-15-%E2%80%9CAre_all_significant_p-values_created_equal%3F%E2%80%9D.html">2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</a></p>
<p>12 0.12037399 <a title="2093-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-23-Combining_survey_data_obtained_using_different_modes_of_sampling.html">777 andrew gelman stats-2011-06-23-Combining survey data obtained using different modes of sampling</a></p>
<p>13 0.11720879 <a title="2093-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-27-No_radon_lobby.html">238 andrew gelman stats-2010-08-27-No radon lobby</a></p>
<p>14 0.10991053 <a title="2093-tfidf-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-With_a_bit_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_again_on_this_topic%2C_and_with_a_lot_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_today.html">576 andrew gelman stats-2011-02-15-With a bit of precognition, you’d have known I was going to post again on this topic, and with a lot of precognition, you’d have known I was going to post today</a></p>
<p>15 0.10840676 <a title="2093-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>16 0.1072224 <a title="2093-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>17 0.10575053 <a title="2093-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-12-My_talk_at_Leuven%2C_Sat_14_Dec.html">2131 andrew gelman stats-2013-12-12-My talk at Leuven, Sat 14 Dec</a></p>
<p>18 0.096815832 <a title="2093-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>19 0.095869854 <a title="2093-tfidf-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>20 0.09399797 <a title="2093-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-23-More_on_those_divorce_prediction_statistics%2C_including_a_discussion_of_the_innumeracy_of_%28some%29_mathematicians.html">105 andrew gelman stats-2010-06-23-More on those divorce prediction statistics, including a discussion of the innumeracy of (some) mathematicians</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.166), (1, -0.011), (2, 0.0), (3, -0.154), (4, -0.049), (5, -0.062), (6, -0.006), (7, -0.022), (8, -0.015), (9, -0.014), (10, -0.056), (11, 0.016), (12, -0.003), (13, -0.07), (14, 0.001), (15, 0.019), (16, -0.04), (17, -0.017), (18, -0.039), (19, -0.007), (20, -0.004), (21, -0.006), (22, -0.035), (23, -0.019), (24, -0.079), (25, -0.016), (26, 0.028), (27, 0.032), (28, -0.019), (29, -0.015), (30, -0.006), (31, -0.027), (32, -0.022), (33, 0.001), (34, -0.006), (35, -0.019), (36, -0.004), (37, -0.027), (38, -0.016), (39, -0.043), (40, 0.015), (41, -0.003), (42, 0.025), (43, 0.009), (44, -0.03), (45, 0.004), (46, 0.012), (47, 0.083), (48, 0.001), (49, 0.041)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97851932 <a title="2093-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>Introduction: After seeing a document sent to me and others regarding the  crisis  of spurious, statistically-significant research findings in psychology research, I had the following reaction:
  
I am unhappy with the use in the document of the phrase “false positives.”  I feel that this expression is unhelpful as it frames science in terms of “true” and “false” claims, which I don’t think is particularly accurate.  In particular, in most of the recent disputed Psych Science type studies (the ESP study excepted, perhaps), there is little doubt that there is _some_ underlying effect.  The issue, as I see it, as that the underlying effects are much smaller, and much more variable, than mainstream researchers imagine.  So what happens is that Psych Science or Nature or whatever will publish a result that is purported to be some sort of universal truth, but it is actually a pattern specific to one data set, one population, and one experimental condition.  In a sense, yes, these journals are publishing</p><p>2 0.82504129 <a title="2093-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-26-Difficulties_in_making_inferences_about_scientific_truth_from_distributions_of_published_p-values.html">2040 andrew gelman stats-2013-09-26-Difficulties in making inferences about scientific truth from distributions of published p-values</a></p>
<p>Introduction: Jeff Leek  just posted  the discussions of his paper (with Leah Jager), “An estimate of the science-wise false discovery rate and application to the top medical literature,” along with some further comments of his own.
 
 Here  are my original thoughts on an earlier version of their article.  Keith O’Rourke and I expanded these thoughts into  a formal comment  for the journal.  We’re pretty much in agreement with John Ioannidis (you can find his discussion in the top link above).
 
In quick summary, I agree with Jager and Leek that this is an important topic.  I think there are two key places where Keith and I disagree with them:
 
1.  They take published p-values at face value whereas we consider them as the result of a complicated process of selection.  This is something I didn’t used to think much about, but now I’ve become increasingly convinced that the problems with published p-values is not a simple file-drawer effect or the case of a few p=0.051 values nudged toward p=0.049, bu</p><p>3 0.81988156 <a title="2093-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>Introduction: Erin Jonaitis points us to  this article  by Christopher Ferguson and Moritz Heene, who write:
  
Publication bias remains a controversial issue in psychological science. . . . that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. Given that science is dependent on the process of falsification, we argue that these problems reduce psychological science’s capability to have a proper mechanism for theory falsification, thus resulting in the promulgation of numerous “undead” theories that are ideologically popular but have little basis in fact.
  
They mention the infamous Daryl Bem article.  It is pretty much only because Bem’s claims are (presumably) false that they got published in a major research journal.  Had the claims been true—that is, had Bem run identical experiments, analyzed his data more carefully and objectively, and reported that the r</p><p>4 0.80079275 <a title="2093-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>Introduction: This article  is a discussion of a  paper  by Greg Francis for a special issue, edited by E. J. Wagenmakers, of the Journal of Mathematical Psychology.  Here’s what I wrote:
  
Much of statistical practice is an effort to reduce or deny variation and uncertainty. The reduction is done through standardization, replication, and other practices of experimental design, with the idea being to isolate and stabilize the quantity being estimated and then average over many cases. Even so, however, uncertainty persists, and statistical hypothesis testing is in many ways an endeavor to deny this, by reporting binary accept/reject decisions.


Classical statistical methods produce binary statements, but there is no reason to assume that the world works that way. Expressions such as Type 1 error, Type 2 error, false positive, and so on, are based on a model in which the world is divided into real and non-real effects. To put it another way, I understand the general scientific distinction of real vs</p><p>5 0.78403634 <a title="2093-lsi-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>Introduction: This seems to be the topic of the week.  Yesterday I posted on the sister blog  some further thoughts  on those “Psychological Science” papers on menstrual cycles, biceps size, and political attitudes, tied to a horrible press release from the journal Psychological Science hyping the biceps and politics study.
 
Then I was pointed to these  suggestions  from Richard Lucas and M. Brent Donnellan have on improving the replicability and reproducibility of research published in the Journal of Research in Personality:
  
It goes without saying that editors of scientific journals strive to publish research that is not only theoretically interesting but also methodologically rigorous. The goal is to select papers that advance the field. Accordingly, editors want to publish findings that can be reproduced and replicated by other scientists. Unfortunately, there has been a recent “crisis in confidence” among psychologists about the quality of psychological research (Pashler & Wagenmakers, 2012)</p><p>6 0.77287239 <a title="2093-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-12-Misunderstanding_the_p-value.html">1760 andrew gelman stats-2013-03-12-Misunderstanding the p-value</a></p>
<p>7 0.77275842 <a title="2093-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-10-Preregistration%3A_what%E2%80%99s_in_it_for_you%3F.html">2241 andrew gelman stats-2014-03-10-Preregistration: what’s in it for you?</a></p>
<p>8 0.76679164 <a title="2093-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-08-Discussion_with_Steven_Pinker_on_research_that_is_attached_to_data_that_are_so_noisy_as_to_be_essentially_uninformative.html">2326 andrew gelman stats-2014-05-08-Discussion with Steven Pinker on research that is attached to data that are so noisy as to be essentially uninformative</a></p>
<p>9 0.75404543 <a title="2093-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-28-50_shades_of_gray%3A__A_research_story.html">1959 andrew gelman stats-2013-07-28-50 shades of gray:  A research story</a></p>
<p>10 0.75307298 <a title="2093-lsi-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-16-%E2%80%9CFalse-positive_psychology%E2%80%9D.html">1171 andrew gelman stats-2012-02-16-“False-positive psychology”</a></p>
<p>11 0.75271076 <a title="2093-lsi-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>12 0.75065869 <a title="2093-lsi-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-31-Response_by_Jessica_Tracy_and_Alec_Beall_to_my_critique_of_the_methods_in_their_paper%2C_%E2%80%9CWomen_Are_More_Likely_to_Wear_Red_or_Pink_at_Peak_Fertility%E2%80%9D.html">1963 andrew gelman stats-2013-07-31-Response by Jessica Tracy and Alec Beall to my critique of the methods in their paper, “Women Are More Likely to Wear Red or Pink at Peak Fertility”</a></p>
<p>13 0.74805385 <a title="2093-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-Fourteen_magic_words%3A_an_update.html">898 andrew gelman stats-2011-09-10-Fourteen magic words: an update</a></p>
<p>14 0.74141467 <a title="2093-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-With_a_bit_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_again_on_this_topic%2C_and_with_a_lot_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_today.html">576 andrew gelman stats-2011-02-15-With a bit of precognition, you’d have known I was going to post again on this topic, and with a lot of precognition, you’d have known I was going to post today</a></p>
<p>15 0.73359013 <a title="2093-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-31-No_on_Yes-No_decisions.html">2155 andrew gelman stats-2013-12-31-No on Yes-No decisions</a></p>
<p>16 0.72997314 <a title="2093-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>17 0.72798479 <a title="2093-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-29-Decline_Effect_in_Linguistics%3F.html">1400 andrew gelman stats-2012-06-29-Decline Effect in Linguistics?</a></p>
<p>18 0.72379744 <a title="2093-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-01-Why_big_effects_are_more_important_than_small_effects.html">1744 andrew gelman stats-2013-03-01-Why big effects are more important than small effects</a></p>
<p>19 0.71761549 <a title="2093-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-20-The_AAA_Tranche_of_Subprime_Science.html">2179 andrew gelman stats-2014-01-20-The AAA Tranche of Subprime Science</a></p>
<p>20 0.71008354 <a title="2093-lsi-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-28-Difficulties_of_using_statistical_significance_%28or_lack_thereof%29_to_sift_through_and_compare_research_hypotheses.html">2042 andrew gelman stats-2013-09-28-Difficulties of using statistical significance (or lack thereof) to sift through and compare research hypotheses</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(13, 0.018), (15, 0.079), (21, 0.022), (24, 0.214), (34, 0.017), (40, 0.053), (59, 0.024), (65, 0.01), (86, 0.127), (87, 0.015), (88, 0.013), (95, 0.04), (99, 0.269)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96836782 <a title="2093-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-07-I%E2%80%99m_negative_on_the_expression_%E2%80%9Cfalse_positives%E2%80%9D.html">2093 andrew gelman stats-2013-11-07-I’m negative on the expression “false positives”</a></p>
<p>Introduction: After seeing a document sent to me and others regarding the  crisis  of spurious, statistically-significant research findings in psychology research, I had the following reaction:
  
I am unhappy with the use in the document of the phrase “false positives.”  I feel that this expression is unhelpful as it frames science in terms of “true” and “false” claims, which I don’t think is particularly accurate.  In particular, in most of the recent disputed Psych Science type studies (the ESP study excepted, perhaps), there is little doubt that there is _some_ underlying effect.  The issue, as I see it, as that the underlying effects are much smaller, and much more variable, than mainstream researchers imagine.  So what happens is that Psych Science or Nature or whatever will publish a result that is purported to be some sort of universal truth, but it is actually a pattern specific to one data set, one population, and one experimental condition.  In a sense, yes, these journals are publishing</p><p>2 0.9544481 <a title="2093-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-31-Type_S_error_rates_for_classical_and_Bayesian_single_and_multiple_comparison_procedures.html">494 andrew gelman stats-2010-12-31-Type S error rates for classical and Bayesian single and multiple comparison procedures</a></p>
<p>Introduction: Type S error:  When your estimate is the wrong sign, compared to the true value of the parameter
 
Type M error:  When the magnitude of your estimate is far off, compared to the true value of the parameter 
  
More here.</p><p>3 0.94052827 <a title="2093-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-15-%E2%80%9CAre_all_significant_p-values_created_equal%3F%E2%80%9D.html">2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</a></p>
<p>Introduction: The answer is no, as explained in  this classic article  by Warren Browner and Thomas Newman from 1987.  If I were to rewrite this article today, I would frame things slightly differently—referring to Type S and Type M errors rather than speaking of “the probability that the research hypothesis is true”—but overall they make good points, and I like their analogy to medical diagnostic testing.</p><p>4 0.93785769 <a title="2093-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-29-%E2%80%9CCommunication_is_a_central_task_of_statistics%2C_and_ideally_a_state-of-the-art_data_analysis_can_have_state-of-the-art_displays_to_match%E2%80%9D.html">1552 andrew gelman stats-2012-10-29-“Communication is a central task of statistics, and ideally a state-of-the-art data analysis can have state-of-the-art displays to match”</a></p>
<p>Introduction: The Journal of the Royal Statistical Society publishes papers followed by discussions.  Lots of discussions, each can be no more than 400 words.  Here’s my most recent discussion:
  
The authors are working on an important applied problem and I have no reason to doubt that their approach is a step forward beyond diagnostic criteria based on point estimation.  An attempt at an accurate assessment of variation is important not just for statistical reasons but also because scientists have the duty to convey their uncertainty to the larger world.  I am thinking, for example, of discredited claims such as that of the mathematician who claimed to predict divorces with 93% accuracy (Abraham, 2010).


Regarding the paper at hand, I thought I would try an experiment in comment-writing.  My usual practice is to read the graphs and then go back and clarify any questions through the text.  So, very quickly:  I would prefer Figure 1 to be displayed in terms of standard deviations, not variances.  I</p><p>5 0.93662125 <a title="2093-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-25-Avoiding_boundary_estimates_using_a_prior_distribution_as_regularization.html">779 andrew gelman stats-2011-06-25-Avoiding boundary estimates using a prior distribution as regularization</a></p>
<p>Introduction: For awhile I’ve been fitting most of my multilevel models using lmer/glmer, which gives point estimates of the group-level variance parameters (maximum marginal likelihood estimate for lmer and an approximation for glmer).  I’m usually satisfied with this–sure, point estimation understates the uncertainty in model fitting, but that’s typically the least of our worries. 
 
Sometimes, though, lmer/glmer estimates group-level variances at 0 or estimates group-level correlation parameters at +/- 1.  Typically, when this happens, it’s not that we’re so sure the variance is close to zero or that the correlation is close to 1 or -1; rather, the marginal likelihood does not provide a lot of information about these parameters of the group-level error distribution.
 
I don’t want point estimates on the boundary.  I don’t want to say that the unexplained variance in some dimension is exactly zero.
 
One way to handle this problem is full Bayes:  slap a prior on sigma, do your Gibbs and Metropolis</p><p>6 0.93589985 <a title="2093-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-29-Decision_science_vs._social_psychology.html">305 andrew gelman stats-2010-09-29-Decision science vs. social psychology</a></p>
<p>7 0.93578738 <a title="2093-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-15-More_on_AIC%2C_WAIC%2C_etc.html">1983 andrew gelman stats-2013-08-15-More on AIC, WAIC, etc</a></p>
<p>8 0.93570566 <a title="2093-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-18-Comments_on_%E2%80%9CA_Bayesian_approach_to_complex_clinical_diagnoses%3A_a_case-study_in_child_abuse%E2%80%9D.html">1327 andrew gelman stats-2012-05-18-Comments on “A Bayesian approach to complex clinical diagnoses: a case-study in child abuse”</a></p>
<p>9 0.93269193 <a title="2093-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-25-Basketball_Stats%3A__Don%E2%80%99t_model_the_probability_of_win%2C_model_the_expected_score_differential..html">2224 andrew gelman stats-2014-02-25-Basketball Stats:  Don’t model the probability of win, model the expected score differential.</a></p>
<p>10 0.93063724 <a title="2093-lda-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-05-Question_26_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1367 andrew gelman stats-2012-06-05-Question 26 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>11 0.92977214 <a title="2093-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-29-More_on_scaled-inverse_Wishart_and_prior_independence.html">1474 andrew gelman stats-2012-08-29-More on scaled-inverse Wishart and prior independence</a></p>
<p>12 0.92940503 <a title="2093-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-I_doubt_they_cheated.html">1971 andrew gelman stats-2013-08-07-I doubt they cheated</a></p>
<p>13 0.92933279 <a title="2093-lda-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>14 0.92883193 <a title="2093-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-23-Scalable_Stan.html">2035 andrew gelman stats-2013-09-23-Scalable Stan</a></p>
<p>15 0.92798948 <a title="2093-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-04-Bayesian_models_for_simultaneous_equation_systems%3F.html">183 andrew gelman stats-2010-08-04-Bayesian models for simultaneous equation systems?</a></p>
<p>16 0.92756069 <a title="2093-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-06-Josh_Tenenbaum_presents_._._._a_model_of_folk_physics%21.html">994 andrew gelman stats-2011-11-06-Josh Tenenbaum presents . . . a model of folk physics!</a></p>
<p>17 0.92707014 <a title="2093-lda-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-10-The_statistical_significance_filter.html">899 andrew gelman stats-2011-09-10-The statistical significance filter</a></p>
<p>18 0.9266305 <a title="2093-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-11-%E2%80%9C2_level_logit_with_2_REs_%26_large_sample._computational_nightmare_%E2%80%93_please_help%E2%80%9D.html">759 andrew gelman stats-2011-06-11-“2 level logit with 2 REs & large sample. computational nightmare – please help”</a></p>
<p>19 0.92425162 <a title="2093-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-19-The_mysterious_Gamma_%281.4%2C_0.4%29.html">669 andrew gelman stats-2011-04-19-The mysterious Gamma (1.4, 0.4)</a></p>
<p>20 0.92388952 <a title="2093-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-28-Correlation%2C_prediction%2C_variation%2C_etc..html">301 andrew gelman stats-2010-09-28-Correlation, prediction, variation, etc.</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
