<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1691 andrew gelman stats-2013-01-25-Extreem p-values!</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1691" href="#">andrew_gelman_stats-2013-1691</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1691 andrew gelman stats-2013-01-25-Extreem p-values!</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1691-html" href="http://andrewgelman.com/2013/01/25/extreem-p-values/">html</a></p><p>Introduction: Joshua Vogelstein writes:
  
I know you’ve discussed this on your blog in the past, but I don’t know exactly how you’d answer the following query:


Suppose you run an analysis and obtain a p-value of 10^-300.  What would you actually report?  I’m fairly confident that I’m not that confident :) I’m guessing: “p-value \approx 0.”


One possibility is to determine the accuracy with this one *could* in theory know, by virtue of the sample size, and say that p-value is less than or equal to that?  For example, if I used a Monte Carlo approach to generate the null distribution with 10,000 samples, and I found that the observed value was more extreme than all of the sample values, then I might say that p is less than or equal to 1/10,000.

  
My reply:  Mosteller and Wallace talked a bit about this in their book, the idea that there are various other 1-in-a-million possibilities (for example, the data were faked somewhere before they got to you) so p-values such as 10^-6 don’t really mean an</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Joshua Vogelstein writes:    I know you’ve discussed this on your blog in the past, but I don’t know exactly how you’d answer the following query:   Suppose you run an analysis and obtain a p-value of 10^-300. [sent-1, score-0.485]
</p><p>2 I’m fairly confident that I’m not that confident :) I’m guessing: “p-value \approx 0. [sent-3, score-0.692]
</p><p>3 ”   One possibility is to determine the accuracy with this one *could* in theory know, by virtue of the sample size, and say that p-value is less than or equal to that? [sent-4, score-1.027]
</p><p>4 For example, if I used a Monte Carlo approach to generate the null distribution with 10,000 samples, and I found that the observed value was more extreme than all of the sample values, then I might say that p is less than or equal to 1/10,000. [sent-5, score-0.985]
</p><p>5 My reply:  Mosteller and Wallace talked a bit about this in their book, the idea that there are various other 1-in-a-million possibilities (for example, the data were faked somewhere before they got to you) so p-values such as 10^-6 don’t really mean anything. [sent-6, score-0.518]
</p><p>6 On the other hand, in some fields such as genetics with extreem multiple comparisons issues, they demand p-values on the order of 10^-6 before doing anything at all. [sent-7, score-0.783]
</p><p>7 Here I think the solution is  multilevel modeling  (which may well be done implicitly as part of a classical multiple comparisons adjustment procedure). [sent-8, score-0.854]
</p><p>8 In general, I think the way to go is to move away from p-values and instead focus directly on effect sizes. [sent-9, score-0.248]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('confident', 0.286), ('equal', 0.225), ('approx', 0.187), ('mosteller', 0.181), ('comparisons', 0.175), ('vogelstein', 0.175), ('wallace', 0.16), ('query', 0.16), ('faked', 0.16), ('multiple', 0.158), ('joshua', 0.155), ('sample', 0.14), ('genetics', 0.139), ('virtue', 0.137), ('possibilities', 0.135), ('carlo', 0.129), ('demand', 0.128), ('adjustment', 0.127), ('obtain', 0.126), ('monte', 0.123), ('fairly', 0.12), ('implicitly', 0.118), ('generate', 0.118), ('talked', 0.118), ('possibility', 0.117), ('null', 0.117), ('guessing', 0.111), ('accuracy', 0.111), ('determine', 0.11), ('less', 0.108), ('procedure', 0.107), ('samples', 0.107), ('sizes', 0.106), ('somewhere', 0.105), ('fields', 0.103), ('extreme', 0.101), ('know', 0.1), ('observed', 0.097), ('classical', 0.096), ('solution', 0.094), ('move', 0.087), ('multilevel', 0.086), ('values', 0.086), ('size', 0.084), ('focus', 0.082), ('exactly', 0.08), ('order', 0.08), ('say', 0.079), ('run', 0.079), ('directly', 0.079)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="1691-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Extreem_p-values%21.html">1691 andrew gelman stats-2013-01-25-Extreem p-values!</a></p>
<p>Introduction: Joshua Vogelstein writes:
  
I know you’ve discussed this on your blog in the past, but I don’t know exactly how you’d answer the following query:


Suppose you run an analysis and obtain a p-value of 10^-300.  What would you actually report?  I’m fairly confident that I’m not that confident :) I’m guessing: “p-value \approx 0.”


One possibility is to determine the accuracy with this one *could* in theory know, by virtue of the sample size, and say that p-value is less than or equal to that?  For example, if I used a Monte Carlo approach to generate the null distribution with 10,000 samples, and I found that the observed value was more extreme than all of the sample values, then I might say that p is less than or equal to 1/10,000.

  
My reply:  Mosteller and Wallace talked a bit about this in their book, the idea that there are various other 1-in-a-million possibilities (for example, the data were faked somewhere before they got to you) so p-values such as 10^-6 don’t really mean an</p><p>2 0.16543353 <a title="1691-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Correcting_for_multiple_comparisons_in_a_Bayesian_regression_model.html">1989 andrew gelman stats-2013-08-20-Correcting for multiple comparisons in a Bayesian regression model</a></p>
<p>Introduction: Joe Northrup writes:
  
I have a question about correcting for multiple comparisons in a Bayesian regression model. I believe I understand the argument in  your 2012 paper  in Journal of Research on Educational Effectiveness that when you have a hierarchical model there is shrinkage of estimates towards the group-level mean and thus there is no need to add any additional penalty to correct for multiple comparisons. In my case I do not have hierarchically structured dataâ&euro;&rdquo;i.e. I have only 1 observation per group but have a categorical variable with a large number of categories. Thus, I am fitting a simple multiple regression in a Bayesian framework. Would putting a strong, mean 0, multivariate normal prior on the betas in this model accomplish the same sort of shrinkage (it seems to me that it would) and do you believe this is a valid way to address criticism of multiple comparisons in this setting?
  
My reply:  Yes, I think this makes sense.  One way to address concerns of multiple com</p><p>3 0.14677928 <a title="1691-tfidf-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-17-How_to_make_a_good_fig%3F.html">1382 andrew gelman stats-2012-06-17-How to make a good fig?</a></p>
<p>Introduction: Joshua Vogelstein writes:
  
Are you aware of a paper the explains current best practice of figure generation, in general? i’m thinking things like: have legends and labels that are legible, etc. seems like you or hadley shoulda written some such thing by now….
  
My reply:
 
A couple of sources I can think of are:  one of the appendixes in my book with Jennifer, and  the book  by Rafe Donahue.</p><p>4 0.12851974 <a title="1691-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>Introduction: After I gave  my talk  at an econ seminar on Why We (Usually) Don’t Care About Multiple Comparisons, I got the following comment:
  
One question that came up later was whether your argument is really with testing in general, rather than only with testing in multiple comparison settings.
  
My reply:
 
Yes, my argument is with testing in general.  But it arises with particular force in multiple comparisons.  With a single test, we can just say we dislike testing so we use confidence intervals or Bayesian inference instead, and it’s no problem—really more of a change in emphasis than a change in methods.  But with multiple tests, the classical advice is not simply to look at type 1 error rates but more specifically to make a multiplicity adjustment, for example to make confidence intervals wider to account for multiplicity.  I don’t want to do this!  So here there is a real battle to fight.
 
P.S.   Here’s  the article (with Jennifer and Masanao), to appear in the Journal of Research on</p><p>5 0.12412185 <a title="1691-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-11-Yes%2C_worry_about_generalizing_from_data_to_population.__But_multilevel_modeling_is_the_solution%2C_not_the_problem.html">1934 andrew gelman stats-2013-07-11-Yes, worry about generalizing from data to population.  But multilevel modeling is the solution, not the problem</a></p>
<p>Introduction: A sociologist writes in:
  
Samuel Lucas has just published  a paper  in Quality and Quantity arguing that anything less than a full probability sample of higher levels in HLMs yields biased and unusable results. If I follow him correctly, he is arguing that not only are the SEs too small, but the parameter estimates themselves are biased and we cannot say in advance whether the bias is positive or negative.


Lucas has thrown down a big gauntlet, advising us throw away our data unless the sample of macro units is right and ignore the published results that fail this standard. Extreme. 
Is there another conclusion to be drawn? 
Other advice to be given? 
A Bayesian path out of the valley?
  
Heres’s the abstract to Lucas’s paper:
  
The multilevel model has become a staple of social research. I textually and formally explicate sample design features that, I contend, are required for unbiased estimation of macro-level multilevel model parameters and the use of tools for statistical infe</p><p>6 0.12098058 <a title="1691-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-25-Bayes-respecting_experimental_design_and_other_things.html">1955 andrew gelman stats-2013-07-25-Bayes-respecting experimental design and other things</a></p>
<p>7 0.1169934 <a title="1691-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-25-Correlation_of_1_._._._too_good_to_be_true%3F.html">1737 andrew gelman stats-2013-02-25-Correlation of 1 . . . too good to be true?</a></p>
<p>8 0.1147639 <a title="1691-tfidf-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-15-The_bias-variance_tradeoff.html">960 andrew gelman stats-2011-10-15-The bias-variance tradeoff</a></p>
<p>9 0.11212885 <a title="1691-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>10 0.11156446 <a title="1691-tfidf-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>11 0.10873526 <a title="1691-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-18-Question_on_Type_M_errors.html">963 andrew gelman stats-2011-10-18-Question on Type M errors</a></p>
<p>12 0.10462032 <a title="1691-tfidf-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-25-Clusters_with_very_small_numbers_of_observations.html">295 andrew gelman stats-2010-09-25-Clusters with very small numbers of observations</a></p>
<p>13 0.1041715 <a title="1691-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-28-Difficulties_of_using_statistical_significance_%28or_lack_thereof%29_to_sift_through_and_compare_research_hypotheses.html">2042 andrew gelman stats-2013-09-28-Difficulties of using statistical significance (or lack thereof) to sift through and compare research hypotheses</a></p>
<p>14 0.10326618 <a title="1691-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-12-Question_2_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1315 andrew gelman stats-2012-05-12-Question 2 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>15 0.10162812 <a title="1691-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-02-Fishing_for_cherries.html">1746 andrew gelman stats-2013-03-02-Fishing for cherries</a></p>
<p>16 0.098311692 <a title="1691-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-25-Design_of_nonrandomized_cluster_sample_study.html">820 andrew gelman stats-2011-07-25-Design of nonrandomized cluster sample study</a></p>
<p>17 0.097521499 <a title="1691-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>18 0.095393315 <a title="1691-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-31-Analyzing_the_entire_population_rather_than_a_sample.html">383 andrew gelman stats-2010-10-31-Analyzing the entire population rather than a sample</a></p>
<p>19 0.095277637 <a title="1691-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-09-The_first_version_of_my_%E2%80%9Cinference_from_iterative_simulation_using_parallel_sequences%E2%80%9D_paper%21.html">1309 andrew gelman stats-2012-05-09-The first version of my “inference from iterative simulation using parallel sequences” paper!</a></p>
<p>20 0.094780862 <a title="1691-tfidf-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-11-Free_online_course_in_multilevel_modeling.html">80 andrew gelman stats-2010-06-11-Free online course in multilevel modeling</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.195), (1, 0.052), (2, 0.055), (3, -0.076), (4, 0.054), (5, -0.006), (6, 0.02), (7, 0.01), (8, 0.035), (9, -0.046), (10, -0.016), (11, -0.034), (12, 0.02), (13, -0.026), (14, 0.025), (15, -0.015), (16, -0.062), (17, -0.023), (18, 0.038), (19, -0.029), (20, 0.015), (21, 0.02), (22, 0.014), (23, 0.051), (24, -0.047), (25, -0.03), (26, 0.013), (27, 0.015), (28, 0.019), (29, -0.024), (30, 0.019), (31, -0.017), (32, 0.03), (33, 0.062), (34, -0.051), (35, -0.02), (36, 0.026), (37, -0.002), (38, -0.003), (39, 0.027), (40, -0.035), (41, 0.064), (42, -0.005), (43, -0.06), (44, 0.01), (45, -0.031), (46, 0.014), (47, 0.0), (48, -0.004), (49, -0.05)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96096748 <a title="1691-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Extreem_p-values%21.html">1691 andrew gelman stats-2013-01-25-Extreem p-values!</a></p>
<p>Introduction: Joshua Vogelstein writes:
  
I know you’ve discussed this on your blog in the past, but I don’t know exactly how you’d answer the following query:


Suppose you run an analysis and obtain a p-value of 10^-300.  What would you actually report?  I’m fairly confident that I’m not that confident :) I’m guessing: “p-value \approx 0.”


One possibility is to determine the accuracy with this one *could* in theory know, by virtue of the sample size, and say that p-value is less than or equal to that?  For example, if I used a Monte Carlo approach to generate the null distribution with 10,000 samples, and I found that the observed value was more extreme than all of the sample values, then I might say that p is less than or equal to 1/10,000.

  
My reply:  Mosteller and Wallace talked a bit about this in their book, the idea that there are various other 1-in-a-million possibilities (for example, the data were faked somewhere before they got to you) so p-values such as 10^-6 don’t really mean an</p><p>2 0.75245953 <a title="1691-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-02-Fishing_for_cherries.html">1746 andrew gelman stats-2013-03-02-Fishing for cherries</a></p>
<p>Introduction: Someone writes: 
  
  
I’m currently trying to make sense of the Army’s preliminary figures on their Comprehensive Soldier Fitness programme, which I found  here . That report (see for example table 4 on p.15) has only a few very small “effect sizes” with p<.01 on some of the subscales and nothing significant on the rest.  It looks to me like it's not much different from random noise, which I suspect might be caused by the large N (and there's more to come, because N for the whole programme will be in excess of 1 million).  While googling on the subject of large N, I came across  this entry  in your blog.  My question is, does that imply that when one has a large N – and, thus, presumably, large statistical power – one should systematically reduce alpha as well?  Is there any literature on this?  Does one always/sometimes/never need to take Lindley’s “paradox” into account?


And a supplementary question: can it ever be legitimate to quote a result as significant for one DV (“Social fi</p><p>3 0.71224803 <a title="1691-lsi-3" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-24-PPS_in_Georgia.html">107 andrew gelman stats-2010-06-24-PPS in Georgia</a></p>
<p>Introduction: Lucy Flynn writes:
  
I’m working at a non-profit organization called CRRC in the Republic of Georgia.
      
I’m having a methodological problem and I saw the syllabus for your sampling class online and thought I might be able to ask you about it?


We do a lot of complex surveys nationwide; our typical sample design is as follows:


- stratify by rural/urban/capital 
- sub-stratify the rural and urban strata into NE/NW/SE/SW geographic quadrants 
- select voting precincts as PSUs 
- select households as SSUs 
- select individual respondents as TSUs


I’m relatively new here, and past practice has been to sample voting precincts with probability proportional to size.  It’s desirable because it’s not logistically feasible for us to vary the number of interviews per precinct with precinct size, so it makes the selection probabilities for households more even across precinct sizes. However, I have a complex sampling textbook (Lohr 1999), and it explains how complex it is to calculate sel</p><p>4 0.70381135 <a title="1691-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-How_do_you_interpret_standard_errors_from_a_regression_fit_to_the_entire_population%3F.html">972 andrew gelman stats-2011-10-25-How do you interpret standard errors from a regression fit to the entire population?</a></p>
<p>Introduction: David Radwin asks a question which comes up fairly often in one form or another:
  
How should one respond to requests for statistical hypothesis tests for population (or universe) data?


I [Radwin] first encountered this issue as an undergraduate when a professor suggested a statistical significance test for my paper comparing roll call votes between freshman and veteran members of Congress. Later I learned that such tests apply only to samples because their purpose is to tell you whether the difference in the observed sample is likely to exist in the population. If you have data for the whole population, like all members of the 103rd House of Representatives, you do not need a test to discern the true difference in the population. 


Sometimes researchers assume some sort of superpopulation like “all possible Congresses” or “Congresses across all time” and that the members of any given Congress constitute a sample. In my current work in education research, it is sometimes asserted t</p><p>5 0.70077586 <a title="1691-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-19-Cross-validation_to_check_missing-data_imputation.html">1330 andrew gelman stats-2012-05-19-Cross-validation to check missing-data imputation</a></p>
<p>Introduction: Aureliano Crameri writes: 
  
  
I have questions regarding one technique you and your colleagues described in your papers: the cross validation (Multiple Imputation with Diagnostics (mi) in R: Opening Windows into the Black Box, with reference to Gelman, King, and Liu, 1998). I think this is the technique I need for my purpose, but I am not sure I understand it right. I want to use the multiple imputation to estimate the outcome of psychotherapies based on longitudinal data. First I have to demonstrate that I am able to get unbiased estimates with the multiple imputation. The expected bias is the overestimation of the outcome of dropouts.


I will test my imputation strategies by means of a series of simulations (delete values, impute, compare with the original). Due to the complexity of the statistical analyses I think I need at least 200 cases. Now I don’t have so many cases without any missings. My data have missing values in different variables. The proportion of missing values is</p><p>6 0.69961828 <a title="1691-lsi-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-04-%E2%80%9CDogs_are_sensitive_to_small_variations_of_the_Earth%E2%80%99s_magnetic_field%E2%80%9D.html">2159 andrew gelman stats-2014-01-04-“Dogs are sensitive to small variations of the Earth’s magnetic field”</a></p>
<p>7 0.69838065 <a title="1691-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-Write_This_Book.html">1605 andrew gelman stats-2012-12-04-Write This Book</a></p>
<p>8 0.69755876 <a title="1691-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>9 0.69719511 <a title="1691-lsi-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-12-Single_or_multiple_imputation%3F.html">608 andrew gelman stats-2011-03-12-Single or multiple imputation?</a></p>
<p>10 0.69400972 <a title="1691-lsi-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-19-Tempering_and_modes.html">1018 andrew gelman stats-2011-11-19-Tempering and modes</a></p>
<p>11 0.69377047 <a title="1691-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-28-Using_randomized_incentives_as_an_instrument_for_survey_nonresponse%3F.html">2152 andrew gelman stats-2013-12-28-Using randomized incentives as an instrument for survey nonresponse?</a></p>
<p>12 0.68777567 <a title="1691-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>13 0.68722129 <a title="1691-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-31-Untunable_Metropolis.html">833 andrew gelman stats-2011-07-31-Untunable Metropolis</a></p>
<p>14 0.68627512 <a title="1691-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-10-Multiple_imputation_and_multilevel_analysis.html">704 andrew gelman stats-2011-05-10-Multiple imputation and multilevel analysis</a></p>
<p>15 0.68612516 <a title="1691-lsi-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>16 0.66809404 <a title="1691-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-22-Handling_multiple_versions_of_an_outcome_variable.html">726 andrew gelman stats-2011-05-22-Handling multiple versions of an outcome variable</a></p>
<p>17 0.66624177 <a title="1691-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>18 0.66336769 <a title="1691-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-01-Don%E2%80%99t_let_your_standard_errors_drive_your_research_agenda.html">1702 andrew gelman stats-2013-02-01-Don’t let your standard errors drive your research agenda</a></p>
<p>19 0.66169387 <a title="1691-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>20 0.66117257 <a title="1691-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-17-Futures_contracts%2C_Granger_causality%2C_and_my_preference_for_estimation_to_testing.html">212 andrew gelman stats-2010-08-17-Futures contracts, Granger causality, and my preference for estimation to testing</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.012), (16, 0.105), (18, 0.18), (21, 0.013), (24, 0.162), (35, 0.032), (55, 0.015), (73, 0.039), (89, 0.013), (99, 0.336)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9590798 <a title="1691-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-22-Researching_the_cost-effectiveness_of_political_lobbying_organisations.html">969 andrew gelman stats-2011-10-22-Researching the cost-effectiveness of political lobbying organisations</a></p>
<p>Introduction: Sally Murray from  Giving What We Can  writes:
  
We are an organisation that assesses different charitable (/fundable) interventions, to estimate which are the most cost-effective (measured in terms of the improvement of life for people in developing countries gained for every dollar invested). Our research guides and encourages greater donations to the most cost-effective charities we thus identify, and our members have so far pledged a total of $14m to these causes, with many hundreds more relying on our advice in a less formal way.


I am specifically researching the cost-effectiveness of political lobbying organisations. We are initially focusing on organisations that lobby for ‘big win’ outcomes such as increased funding of the most cost-effective NTD treatments/ vaccine research, changes to global trade rules (potentially) and more obscure lobbies such as “Keep Antibiotics Working”.


We’ve a great deal of respect for your work and the superbly rational way you go about it, and</p><p>2 0.95820123 <a title="1691-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-07-The_red-state%2C_blue-state_war_is_happening_in_the_upper_half_of_the_income_distribution.html">456 andrew gelman stats-2010-12-07-The red-state, blue-state war is happening in the upper half of the income distribution</a></p>
<p>Introduction: As we said in Red State, Blue State, it’s not the Prius vs. the pickup truck, it’s the Prius vs. the Hummer.  Here’s the graph:
 
 
 
Or, as Ross Douthat put it in  an op-ed  yesterday:
  
This means that a culture war that’s often seen as a clash between liberal elites and a conservative middle America looks more and more like a conflict within the educated class — pitting Wheaton and Baylor against Brown and Bard, Redeemer Presbyterian Church against the 92nd Street Y, C. S. Lewis devotees against the Philip Pullman fan club.
  
Our main motivation for doing this work was to change how the news media think about America’s political divisions, and so it’s good to see our ideas getting mainstreamed and moving toward conventional wisdom.
  

 
P.S.  Here’s the time series of graphs showing how the pattern that we and Douthat noticed, of a battle between coastal states and middle America that is occurring among upper-income Americans, is relatively recent, having arisen in the Clinton ye</p><p>same-blog 3 0.95689052 <a title="1691-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-25-Extreem_p-values%21.html">1691 andrew gelman stats-2013-01-25-Extreem p-values!</a></p>
<p>Introduction: Joshua Vogelstein writes:
  
I know you’ve discussed this on your blog in the past, but I don’t know exactly how you’d answer the following query:


Suppose you run an analysis and obtain a p-value of 10^-300.  What would you actually report?  I’m fairly confident that I’m not that confident :) I’m guessing: “p-value \approx 0.”


One possibility is to determine the accuracy with this one *could* in theory know, by virtue of the sample size, and say that p-value is less than or equal to that?  For example, if I used a Monte Carlo approach to generate the null distribution with 10,000 samples, and I found that the observed value was more extreme than all of the sample values, then I might say that p is less than or equal to 1/10,000.

  
My reply:  Mosteller and Wallace talked a bit about this in their book, the idea that there are various other 1-in-a-million possibilities (for example, the data were faked somewhere before they got to you) so p-values such as 10^-6 don’t really mean an</p><p>4 0.95392996 <a title="1691-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-05-Shocking_but_not_surprising.html">698 andrew gelman stats-2011-05-05-Shocking but not surprising</a></p>
<p>Introduction: Much-honored playwright Tony Kushner was set to receive one more honor–a degree from John Jay College–but it was suddenly  taken away  from him on an 11-1 vote of the trustees  of the City University of New York.  This was the first rejection of an honorary degree nomination since 1961.
 
The news article focuses on one trustee, Jeffrey Wiesenfeld, an investment adviser and onetime political aide, who opposed Kushner’s honorary degree, but to me the relevant point is that the committee as a whole voted 11-1 to ding him.
 
Kusnher said, “I’m sickened,” he added, “that this is happening in New York City. Shocked, really.”  I can see why he’s shocked, but perhaps it’s not so surprising that it’s happening in NYC.  Recall the famous incident from 1940 in which Bertrand Russell was invited and then uninvited to teach at City College.  The problem that time was Russell’s views on free love (as they called it back then).  There seems to be a long tradition of city college officials being will</p><p>5 0.95306516 <a title="1691-lda-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>Introduction: Andy Cooper writes:
  
A link to an  article , “Four Assumptions Of Multiple Regression That Researchers Should Always Test”, has been making  the rounds  on Twitter.  Their first rule is “Variables are Normally distributed.”  And they seem to be talking about the independent variables – but then later bring in tests on the residuals (while admitting that the normally-distributed error assumption is a weak assumption).  


I thought we had long-since moved away from transforming our independent variables to make them normally distributed for statistical reasons (as opposed to standardizing them for interpretability, etc.)  Am I missing something?  I agree that leverage in a influence is important, but normality of the variables? The article is from 2002, so it might be dated, but given the popularity of the tweet, I thought I’d ask your opinion.
  
My response:  There’s some useful advice on that page but overall I think the advice was dated even in 2002.  In section 3.6 of my book wit</p><p>6 0.95183343 <a title="1691-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-18-Should_kids_be_able_to_bring_their_own_lunches_to_school%3F.html">718 andrew gelman stats-2011-05-18-Should kids be able to bring their own lunches to school?</a></p>
<p>7 0.95067084 <a title="1691-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Colorless_green_facts_asserted_resolutely.html">1292 andrew gelman stats-2012-05-01-Colorless green facts asserted resolutely</a></p>
<p>8 0.94404674 <a title="1691-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-14-I_hate_to_get_all_Gerd_Gigerenzer_on_you_here%2C_but_._._..html">1319 andrew gelman stats-2012-05-14-I hate to get all Gerd Gigerenzer on you here, but . . .</a></p>
<p>9 0.9435482 <a title="1691-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-01-I%E2%80%99ll_say_it_again.html">2046 andrew gelman stats-2013-10-01-I’ll say it again</a></p>
<p>10 0.94173145 <a title="1691-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-24-In_case_you_were_wondering%2C_here%E2%80%99s_the_price_of_milk.html">588 andrew gelman stats-2011-02-24-In case you were wondering, here’s the price of milk</a></p>
<p>11 0.93958771 <a title="1691-lda-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-20-Maybe_a_great_idea_in_theory%2C_didn%E2%80%99t_work_so_well_in_practice.html">621 andrew gelman stats-2011-03-20-Maybe a great idea in theory, didn’t work so well in practice</a></p>
<p>12 0.92384219 <a title="1691-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-08-The_politics_of_economic_and_statistical_models.html">1204 andrew gelman stats-2012-03-08-The politics of economic and statistical models</a></p>
<p>13 0.92298931 <a title="1691-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-28-More_on_Bayesian_deduction-induction.html">114 andrew gelman stats-2010-06-28-More on Bayesian deduction-induction</a></p>
<p>14 0.92246926 <a title="1691-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-20-Reading_a_research_paper_%21%3D_agreeing_with_its_claims.html">1074 andrew gelman stats-2011-12-20-Reading a research paper != agreeing with its claims</a></p>
<p>15 0.91615999 <a title="1691-lda-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-29-Infovis_vs._statgraphics%3A__A_clear_example_of_their_different_goals.html">829 andrew gelman stats-2011-07-29-Infovis vs. statgraphics:  A clear example of their different goals</a></p>
<p>16 0.91349345 <a title="1691-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-17-How_to_make_a_good_fig%3F.html">1382 andrew gelman stats-2012-06-17-How to make a good fig?</a></p>
<p>17 0.91117811 <a title="1691-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-02-They_want_me_to_send_them_free_material_and_pay_for_the_privilege.html">1922 andrew gelman stats-2013-07-02-They want me to send them free material and pay for the privilege</a></p>
<p>18 0.90716708 <a title="1691-lda-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-21-The_Commissar_for_Traffic_presents_the_latest_Five-Year_Plan.html">2181 andrew gelman stats-2014-01-21-The Commissar for Traffic presents the latest Five-Year Plan</a></p>
<p>19 0.90541101 <a title="1691-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-09-Reviewing_the_peer_review_process%3F.html">2239 andrew gelman stats-2014-03-09-Reviewing the peer review process?</a></p>
<p>20 0.90127861 <a title="1691-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-25-Spam%21.html">2148 andrew gelman stats-2013-12-25-Spam!</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
