<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1869" href="#">andrew_gelman_stats-2013-1869</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1869-html" href="http://andrewgelman.com/2013/05/24/in-which-i-side-with-neyman-over-fisher/">html</a></p><p>Introduction: As a data analyst and a scientist, Fisher > Neyman, no question.  But as a theorist, Fisher came up with ideas that worked just fine in his applications but can fall apart when people try to apply them too generally.
 
Here’s an example that recently came up.
 
Deborah Mayo pointed me to a  comment  by Stephen Senn on the so-called Fisher and Neyman null hypotheses.  In an experiment with n participants (or, as we used to say, subjects or experimental units), the Fisher null hypothesis is that the treatment effect is exactly 0 for every one of the n units, while the Neyman null hypothesis is that the individual treatment effects can be negative or positive but have an average of zero.
 
Senn explains why Neyman’s hypothesis in general makes no sense—the short story is that Fisher’s hypothesis seems relevant in some problems (sometimes we really are studying effects that are zero or close enough for all practical purposes), whereas Neyman’s hypothesis just seems weird (it’s implausible</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 As a data analyst and a scientist, Fisher > Neyman, no question. [sent-1, score-0.065]
</p><p>2 But as a theorist, Fisher came up with ideas that worked just fine in his applications but can fall apart when people try to apply them too generally. [sent-2, score-0.291]
</p><p>3 Deborah Mayo pointed me to a  comment  by Stephen Senn on the so-called Fisher and Neyman null hypotheses. [sent-4, score-0.31]
</p><p>4 And I remember a similar discussion as a student, many years ago, when Rubin talked about that silly Neyman null hypothesis. [sent-7, score-0.362]
</p><p>5 Thinking about it more, though, I side with Neyman over Fisher, because the interesting problem for me is not testing the null hypothesis, which in nontrivial problems can never be true anyway, but in estimation. [sent-8, score-0.48]
</p><p>6 And in estimation I am intersted in an average effect, not an effect that is identical across all people. [sent-9, score-0.351]
</p><p>7 I could imagine a model in which the variance of the treatment effect is proportional to its mean—this would bridge between the Neyman and Fisher ideas—but this is not a model that anyone ever fits. [sent-10, score-0.425]
</p><p>8 So, just to say it again:  if it’s a pure null hypothesis, sure, go with Fisher. [sent-11, score-0.424]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('neyman', 0.583), ('fisher', 0.393), ('null', 0.31), ('hypothesis', 0.297), ('treatment', 0.155), ('senn', 0.151), ('effect', 0.136), ('units', 0.121), ('implausible', 0.121), ('identical', 0.11), ('exactly', 0.106), ('ideas', 0.09), ('effects', 0.085), ('omits', 0.083), ('theorist', 0.083), ('cancel', 0.077), ('inverting', 0.077), ('bridge', 0.075), ('nonzero', 0.07), ('nontrivial', 0.07), ('analyst', 0.065), ('requirement', 0.063), ('average', 0.062), ('go', 0.062), ('deborah', 0.061), ('mayo', 0.061), ('proportional', 0.059), ('purposes', 0.058), ('came', 0.057), ('weird', 0.054), ('apart', 0.054), ('stephen', 0.053), ('interval', 0.052), ('talked', 0.052), ('pure', 0.052), ('problems', 0.05), ('never', 0.05), ('explains', 0.05), ('items', 0.05), ('subjects', 0.049), ('rubin', 0.048), ('fall', 0.047), ('family', 0.045), ('participants', 0.045), ('studying', 0.045), ('application', 0.044), ('confidence', 0.044), ('applications', 0.043), ('estimation', 0.043), ('experimental', 0.043)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1869-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>Introduction: As a data analyst and a scientist, Fisher > Neyman, no question.  But as a theorist, Fisher came up with ideas that worked just fine in his applications but can fall apart when people try to apply them too generally.
 
Here’s an example that recently came up.
 
Deborah Mayo pointed me to a  comment  by Stephen Senn on the so-called Fisher and Neyman null hypotheses.  In an experiment with n participants (or, as we used to say, subjects or experimental units), the Fisher null hypothesis is that the treatment effect is exactly 0 for every one of the n units, while the Neyman null hypothesis is that the individual treatment effects can be negative or positive but have an average of zero.
 
Senn explains why Neyman’s hypothesis in general makes no sense—the short story is that Fisher’s hypothesis seems relevant in some problems (sometimes we really are studying effects that are zero or close enough for all practical purposes), whereas Neyman’s hypothesis just seems weird (it’s implausible</p><p>2 0.33849299 <a title="1869-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-19-On_deck_this_week.html">2339 andrew gelman stats-2014-05-19-On deck this week</a></p>
<p>Introduction: Mon:   My short career as a Freud expert
 
 Tues:   “P.S. Is anyone working on hierarchical survival models?”
 
 Wed:   Skepticism about a published claim regarding income inequality and happiness
 
 Thurs:   Big Data needs Big Model
 
 Fri:   Did Neyman really say of Fisher’s work, “It’s easy to get the right answer if you never define what the question is,” and did Fisher really describe Neyman as “a theorem-proving poseur who wouldn’t recognized real data if it bit him in the ass”
 
 Sat:   An interesting mosaic of a data programming course
 
 Sun:   Why I decided not to be a physicist</p><p>3 0.31136298 <a title="1869-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-02-Flame_bait.html">1880 andrew gelman stats-2013-06-02-Flame bait</a></p>
<p>Introduction: Mark Palko asks what I think of  this article  by Francisco Louca, who writes about “‘hybridization’, a synthesis between Fisherian and Neyman-Pearsonian precepts, defined as a number of practical proceedings for statistical testing and inference that were developed notwithstanding the original authors, as an eventual convergence between what they considered to be radically irreconcilable.”
 
To me, the statistical ideas in this paper are too old-fashioned.  The issue is not that the Neyman-Pearson and Fisher approaches are “irreconcilable” but rather that neither does the job in the sort of hard problems that face statistical science today.  I’m thinking of technically difficult models such as hierarchical Gaussian processes and also challenges that arise with small sample size and multiple testing. Neyman, Pearson, and Fisher all were brilliant, and they all developed statistical methods that remain useful today, but I think their foundations are out of date.  Yes, we currently use m</p><p>4 0.25589848 <a title="1869-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-25-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">870 andrew gelman stats-2011-08-25-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>Introduction: Peter Bergman points me to  this discussion  from Cyrus of  a presentation  by Guido Imbens on design of randomized experiments.
 
Cyrus writes:
  
The standard analysis that Imbens proposes includes (1) a Fisher-type permutation test of the sharp null hypothesis–what Imbens referred to as “testing”–along with a (2) Neyman-type point estimate of the sample average treatment effect and confidence interval–what Imbens referred to as “estimation.” . . .


Imbens claimed that testing and estimation are separate enterprises with separate goals and that the two should not be confused. I [Cyrus] took it as a warning against proposals that use “inverted” tests in order to produce point estimates and confidence intervals. There is no reason that such confidence intervals will have accurate coverage except under rather dire assumptions, meaning that they are not “confidence intervals” in the way that we usually think of them.
  
I agree completely.  This is something I’ve been saying for a long</p><p>5 0.25004473 <a title="1869-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-24-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">1913 andrew gelman stats-2013-06-24-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<p>Introduction: I’m reposing  this  classic from 2011 . . . Peter Bergman pointed me to  this discussion  from Cyrus of  a presentation  by Guido Imbens on design of randomized experiments.
 
Cyrus writes:
  
The standard analysis that Imbens proposes includes (1) a Fisher-type permutation test of the sharp null hypothesis–what Imbens referred to as “testing”–along with a (2) Neyman-type point estimate of the sample average treatment effect and confidence interval–what Imbens referred to as “estimation.” . . .


Imbens claimed that testing and estimation are separate enterprises with separate goals and that the two should not be confused. I [Cyrus] took it as a warning against proposals that use “inverted” tests in order to produce point estimates and confidence intervals. There is no reason that such confidence intervals will have accurate coverage except under rather dire assumptions, meaning that they are not “confidence intervals” in the way that we usually think of them.
  
I agree completely.  T</p><p>6 0.21908225 <a title="1869-tfidf-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>7 0.21654645 <a title="1869-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>8 0.21654193 <a title="1869-tfidf-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-05-On_deck_this_month.html">2320 andrew gelman stats-2014-05-05-On deck this month</a></p>
<p>9 0.20719305 <a title="1869-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>10 0.20305212 <a title="1869-tfidf-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>11 0.19836456 <a title="1869-tfidf-11" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>12 0.16991334 <a title="1869-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>13 0.16173168 <a title="1869-tfidf-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>14 0.15925573 <a title="1869-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-25-Classical_probability_does_not_apply_to_quantum_systems_%28causal_inference_edition%29.html">2037 andrew gelman stats-2013-09-25-Classical probability does not apply to quantum systems (causal inference edition)</a></p>
<p>15 0.15853693 <a title="1869-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>16 0.15834315 <a title="1869-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Huff_the_Magic_Dragon.html">1293 andrew gelman stats-2012-05-01-Huff the Magic Dragon</a></p>
<p>17 0.15322305 <a title="1869-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-04-Write_This_Book.html">1605 andrew gelman stats-2012-12-04-Write This Book</a></p>
<p>18 0.14748621 <a title="1869-tfidf-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-11-One_more_time_on_that_ESP_study%3A__The_problem_of_overestimates_and_the_shrinkage_solution.html">511 andrew gelman stats-2011-01-11-One more time on that ESP study:  The problem of overestimates and the shrinkage solution</a></p>
<p>19 0.14541262 <a title="1869-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-09-The_difference_between_significant_and_not_significant%E2%80%A6.html">897 andrew gelman stats-2011-09-09-The difference between significant and not significant…</a></p>
<p>20 0.14500092 <a title="1869-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-More_proposals_to_reform_the_peer-review_system.html">1272 andrew gelman stats-2012-04-20-More proposals to reform the peer-review system</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.145), (1, 0.054), (2, 0.012), (3, -0.12), (4, -0.048), (5, -0.052), (6, -0.013), (7, 0.064), (8, 0.069), (9, -0.111), (10, -0.136), (11, 0.075), (12, 0.075), (13, -0.119), (14, 0.045), (15, -0.046), (16, -0.067), (17, -0.062), (18, -0.013), (19, -0.095), (20, 0.044), (21, -0.02), (22, 0.047), (23, 0.016), (24, -0.054), (25, -0.107), (26, -0.047), (27, 0.025), (28, -0.028), (29, 0.022), (30, -0.0), (31, -0.061), (32, 0.014), (33, 0.03), (34, -0.094), (35, -0.069), (36, 0.015), (37, -0.062), (38, 0.065), (39, 0.034), (40, -0.091), (41, 0.069), (42, 0.068), (43, 0.007), (44, -0.008), (45, 0.105), (46, -0.034), (47, -0.143), (48, 0.052), (49, 0.04)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97858661 <a title="1869-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>Introduction: As a data analyst and a scientist, Fisher > Neyman, no question.  But as a theorist, Fisher came up with ideas that worked just fine in his applications but can fall apart when people try to apply them too generally.
 
Here’s an example that recently came up.
 
Deborah Mayo pointed me to a  comment  by Stephen Senn on the so-called Fisher and Neyman null hypotheses.  In an experiment with n participants (or, as we used to say, subjects or experimental units), the Fisher null hypothesis is that the treatment effect is exactly 0 for every one of the n units, while the Neyman null hypothesis is that the individual treatment effects can be negative or positive but have an average of zero.
 
Senn explains why Neyman’s hypothesis in general makes no sense—the short story is that Fisher’s hypothesis seems relevant in some problems (sometimes we really are studying effects that are zero or close enough for all practical purposes), whereas Neyman’s hypothesis just seems weird (it’s implausible</p><p>2 0.78598118 <a title="1869-lsi-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-31-Lindley%E2%80%99s_paradox.html">1355 andrew gelman stats-2012-05-31-Lindley’s paradox</a></p>
<p>Introduction: Sam Seaver writes:
  
I [Seaver] happened to be reading an ironic  article  by Karl Friston when I learned something new about frequentist vs bayesian, namely Lindley’s paradox, on page 12.  The text is as follows:

 
So why are we worried about trivial effects? They are important because the probability that the true effect size is exactly zero is itself zero and could cause us to reject the null hypothesis inappropriately. This is a fallacy of classical inference and is not unrelated to Lindley’s paradox (Lindley 1957). Lindley’s paradox describes a counterintuitive situation in which Bayesian and frequentist approaches to hypothesis testing give opposite results. It occurs when; (i) a result is significant by a frequentist test, indicating sufficient evidence to reject the null hypothesis d=0 and (ii) priors render the posterior probability of d=0 high, indicating strong evidence that the null hypothesis is true. In his original 
treatment, Lindley (1957) showed that – under a parti</p><p>3 0.78202844 <a title="1869-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-23-Of_hypothesis_tests_and_Unitarians.html">1024 andrew gelman stats-2011-11-23-Of hypothesis tests and Unitarians</a></p>
<p>Introduction: Xian, Judith, and I read this line in a book by statistician Murray Aitkin in which he considered the following hypothetical example:
  
A survey of 100 individuals expressing support (Yes/No) for the president, before and after a presidential address . . . The question of interest is whether there has been a change in support between the surveys . . . We want to assess the evidence for the hypothesis of equality H1 against the alternative hypothesis H2 of a change.
  
Here is  our response :
  
Based on our experience in public opinion research, this is not a real question. Support for any political position is always changing. The real question is how much the support has changed, or perhaps how this change is distributed across the population.


A defender of Aitkin (and of classical hypothesis testing) might respond at this point that, yes, everybody knows that changes are never exactly zero and that we should take a more “grown-up” view of the null hypothesis, not that the change</p><p>4 0.7081365 <a title="1869-lsi-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-18-One-tailed_or_two-tailed%3F.html">2295 andrew gelman stats-2014-04-18-One-tailed or two-tailed?</a></p>
<p>Introduction: Someone writes:
  
Suppose I have two groups of people, A and B, which differ on some characteristic of interest to me;  and for each person I measure a single real-valued quantity X.  I have a theory that group A has a higher mean value of X than group B.  I test this theory by using a t-test.  Am I entitled to use a *one-tailed* t-test?  Or should I use a *two-tailed* one (thereby giving a p-value that is twice as large)?


I know you will probably answer:  Forget the t-test; you should use Bayesian methods instead.


But what is the standard frequentist answer to this question?
  
My reply:
 
The quick answer here is that different people will do different things here.  I would say the 2-tailed p-value is more standard but some people will insist on the one-tailed version, and itâ&euro;&trade;s hard to make a big stand on this one, given all the other problems with p-values in practice:
 
http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf
 
http://www.stat.columbia.edu/~gelm</p><p>5 0.67450643 <a title="1869-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21%21.html">256 andrew gelman stats-2010-09-04-Noooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</a></p>
<p>Introduction: Masanao sends  this one  in, under the heading, “another incident of misunderstood p-value”:
  
Warren Davies, a positive psychology MSc student at UEL, provides the latest in our ongoing series of guest features for students. Warren has just released a Psychology Study Guide, which covers information on statistics, research methods and study skills for psychology students.

 
Despite the myriad rules and procedures of science, some research findings are pure flukes. Perhaps you’re testing a new drug, and by chance alone, a large number of people spontaneously get better. The better your study is conducted, the lower the chance that your result was a fluke – but still, there is always a certain probability that it was.


Statistical significance testing gives you an idea of what this probability is.


In science we’re always testing hypotheses. We never conduct a study to ‘see what happens’, because there’s always at least one way to make any useless set of data look important. We take</p><p>6 0.66892213 <a title="1869-lsi-6" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-04-The_Notorious_N.H.S.T._presents%3A__Mo_P-values_Mo_Problems.html">2281 andrew gelman stats-2014-04-04-The Notorious N.H.S.T. presents:  Mo P-values Mo Problems</a></p>
<p>7 0.66670263 <a title="1869-lsi-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>8 0.63928962 <a title="1869-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-I_agree_with_this_comment.html">2272 andrew gelman stats-2014-03-29-I agree with this comment</a></p>
<p>9 0.63088393 <a title="1869-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-24-Empirical_implications_of_Empirical_Implications_of_Theoretical_Models.html">2263 andrew gelman stats-2014-03-24-Empirical implications of Empirical Implications of Theoretical Models</a></p>
<p>10 0.62759376 <a title="1869-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-26-Statistical_evidence_for_revised_standards.html">2149 andrew gelman stats-2013-12-26-Statistical evidence for revised standards</a></p>
<p>11 0.62036967 <a title="1869-lsi-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>12 0.61776167 <a title="1869-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>13 0.60361439 <a title="1869-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-26-%E2%80%9CA_Vast_Graveyard_of_Undead_Theories%3A__Publication_Bias_and_Psychological_Science%E2%80%99s_Aversion_to_the_Null%E2%80%9D.html">1826 andrew gelman stats-2013-04-26-“A Vast Graveyard of Undead Theories:  Publication Bias and Psychological Science’s Aversion to the Null”</a></p>
<p>14 0.60315424 <a title="1869-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-15-%E2%80%9CAre_all_significant_p-values_created_equal%3F%E2%80%9D.html">2102 andrew gelman stats-2013-11-15-“Are all significant p-values created equal?”</a></p>
<p>15 0.59991038 <a title="1869-lsi-15" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-23-Discussion_on_preregistration_of_research_studies.html">2183 andrew gelman stats-2014-01-23-Discussion on preregistration of research studies</a></p>
<p>16 0.58671099 <a title="1869-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-02-So-called_Bayesian_hypothesis_testing_is_just_as_bad_as_regular_hypothesis_testing.html">643 andrew gelman stats-2011-04-02-So-called Bayesian hypothesis testing is just as bad as regular hypothesis testing</a></p>
<p>17 0.56949246 <a title="1869-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-17-I_got_99_comparisons_but_multiplicity_ain%E2%80%99t_one.html">1016 andrew gelman stats-2011-11-17-I got 99 comparisons but multiplicity ain’t one</a></p>
<p>18 0.5689376 <a title="1869-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-12-Misunderstanding_the_p-value.html">1760 andrew gelman stats-2013-03-12-Misunderstanding the p-value</a></p>
<p>19 0.56886268 <a title="1869-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-The_myth_of_the_myth_of_the_myth_of_the_hot_hand.html">2243 andrew gelman stats-2014-03-11-The myth of the myth of the myth of the hot hand</a></p>
<p>20 0.55791795 <a title="1869-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-25-Why_it_doesn%E2%80%99t_make_sense_in_general_to_form_confidence_intervals_by_inverting_hypothesis_tests.html">870 andrew gelman stats-2011-08-25-Why it doesn’t make sense in general to form confidence intervals by inverting hypothesis tests</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.021), (16, 0.025), (21, 0.084), (24, 0.236), (25, 0.028), (27, 0.164), (55, 0.027), (69, 0.01), (84, 0.03), (89, 0.028), (92, 0.012), (99, 0.207)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96371639 <a title="1869-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-24-In_which_I_side_with_Neyman_over_Fisher.html">1869 andrew gelman stats-2013-05-24-In which I side with Neyman over Fisher</a></p>
<p>Introduction: As a data analyst and a scientist, Fisher > Neyman, no question.  But as a theorist, Fisher came up with ideas that worked just fine in his applications but can fall apart when people try to apply them too generally.
 
Here’s an example that recently came up.
 
Deborah Mayo pointed me to a  comment  by Stephen Senn on the so-called Fisher and Neyman null hypotheses.  In an experiment with n participants (or, as we used to say, subjects or experimental units), the Fisher null hypothesis is that the treatment effect is exactly 0 for every one of the n units, while the Neyman null hypothesis is that the individual treatment effects can be negative or positive but have an average of zero.
 
Senn explains why Neyman’s hypothesis in general makes no sense—the short story is that Fisher’s hypothesis seems relevant in some problems (sometimes we really are studying effects that are zero or close enough for all practical purposes), whereas Neyman’s hypothesis just seems weird (it’s implausible</p><p>2 0.89482057 <a title="1869-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-28-Migrating_from_dot_to_underscore.html">1472 andrew gelman stats-2012-08-28-Migrating from dot to underscore</a></p>
<p>Introduction: My C-oriented Stan collaborators have convinced me to use underscore (_) rather than dot (.) as much as possible in expressions in R.  For example, I can name a variable n_years rather than n.years.  This is fine.  But I’m getting annoyed because I need to press the shift key every time I type the underscore.
 
What do people do about this?  I know that it’s easy enough to reassign keys (I could, for example, assign underscore to backslash, which I never use).  I’m just wondering what C programmers actually do.  Do they reassign the key or do they just get used to pressing Shift?
 
P.S.  In comments, Ben Hyde  points  to Google’s R style guide, which recommends that variable names use dots,  not  underscore or camel case, for variable names (for example, “avg.clicks” rather than “avg_Clicks” or “avgClicks”).  I think they’re recommending this to be consistent with  R coding conventions .
 
I am switching to underscores in R variable names to be consistent with C.  Otherwise we were run</p><p>3 0.8916111 <a title="1869-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-Super_Sam_Fuld_Needs_Your_Help_%28with_Foul_Ball_stats%29.html">802 andrew gelman stats-2011-07-13-Super Sam Fuld Needs Your Help (with Foul Ball stats)</a></p>
<p>Introduction: I was pleasantly surprised to have my recreational reading about baseball in the  New Yorker  interrupted by a digression on statistics.   Sam Fuld  of the Tampa Bay Rays, was the subjet of a Ben McGrath profile in the 4 July 2011 issue of the  New Yorker , in an article titled  Super Sam .  After quoting a minor-league trainer who described Fuld as “a bit of a geek” (who isn’t these days?), McGrath gets into that lovely  New Yorker  detail:
  

One could have pointed out the more persuasive and telling examples, such as the fact that in 2005, after his first pro season, with the Class-A Peoria Chiefs, Fuld applied for a fall internship with Stats, Inc., the research firm that supplies broadcasters with much of the data anad analysis that you hear in sports telecasts.

  
After a description of what they had him doing, reviewing footage of games and cataloguing, he said
  

“I thought, They have a stat for everything, but they don’t have any stats regarding foul balls.”

     
 Fuld’s</p><p>4 0.88462967 <a title="1869-lda-4" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-05-Can_we_make_better_graphs_of_global_temperature_history%3F.html">2319 andrew gelman stats-2014-05-05-Can we make better graphs of global temperature history?</a></p>
<p>Introduction: Chris Gittins sends along  this post  by Gavin Schmidt, who writes:
  
Some editors at Wikipedia have made an attempt to produce a complete record for the Phanerozoic:


     But these collations are imperfect in many ways. On the last figure the time axis is a rather confusing mix of linear segments and logarithmic scaling, there is no calibration during overlap periods, and the scaling and baselining of the individual, differently sourced data is a little ad hoc. Wikipedia has figures for other time periods that have not been updated in years and treatment of uncertainties is haphazard (many originally from  GlobalWarmingArt ).


I think this could all be done better. However, creating good graphics takes time and some skill, especially when the sources of data are so disparate. So this might be usefully done using some crowd-sourcing . . .
  
In general, I’d give the advice that multiple graphs are a good idea, and that many graphics difficulties come from people trying to come up w</p><p>5 0.88351583 <a title="1869-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-15-%3F.html">343 andrew gelman stats-2010-10-15-?</a></p>
<p>Introduction: How am I supposed to handle this sort of thing?  (See below.)  I just stuck it one of my email folders without responding, but then I wondered . . . what’s it all about?  Is there some sort of Glengarry Glen Ross-like parallel world where down-on-their-luck Jack Lemmons of public relations world send out electronic cold calls?  More than anything else, this sort of thing makes me glad I have a steady job.
 
Here’s the (unsolicited) email, which came with the subject line “Please help a reporter do his job”:
  
Dear Andrew,


As an Editor for the Bulldog Reporter (www.bulldogreporter.com/dailydog), a media relations trade publication, my job is to help ensure that my readers have accurate info about you and send you the best quality pitches. By taking five minutes or less to answer my questions (pasted below), you’ll receive targeted PR pitches from our client base that will match your beat and interests. Any help or direction is appreciated. Here are my questions.


We have you listed</p><p>6 0.88273537 <a title="1869-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-08-%E2%80%9CWhat_do_you_think_about_curved_lines_connecting_discrete_data-points%3F%E2%80%9D.html">134 andrew gelman stats-2010-07-08-“What do you think about curved lines connecting discrete data-points?”</a></p>
<p>7 0.88178003 <a title="1869-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-11-Toshiro_Kageyama_on_professionalism.html">1113 andrew gelman stats-2012-01-11-Toshiro Kageyama on professionalism</a></p>
<p>8 0.88007224 <a title="1869-lda-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-27-One_way_that_psychology_research_is_different_than_medical_research.html">433 andrew gelman stats-2010-11-27-One way that psychology research is different than medical research</a></p>
<p>9 0.87475443 <a title="1869-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-31-Dispute_about_ethics_of_data_sharing.html">1238 andrew gelman stats-2012-03-31-Dispute about ethics of data sharing</a></p>
<p>10 0.87228429 <a title="1869-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-09-My_homework_success.html">896 andrew gelman stats-2011-09-09-My homework success</a></p>
<p>11 0.87215054 <a title="1869-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Ken_Rice_presents_a_unifying_approach_to_statistical_inference_and_hypothesis_testing.html">2312 andrew gelman stats-2014-04-29-Ken Rice presents a unifying approach to statistical inference and hypothesis testing</a></p>
<p>12 0.86970276 <a title="1869-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-01-Huff_the_Magic_Dragon.html">1293 andrew gelman stats-2012-05-01-Huff the Magic Dragon</a></p>
<p>13 0.86953086 <a title="1869-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-13-%243M_health_care_prediction_challenge.html">465 andrew gelman stats-2010-12-13-$3M health care prediction challenge</a></p>
<p>14 0.86823344 <a title="1869-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-17-Getting_arm_and_lme4_running_on_the_Mac.html">347 andrew gelman stats-2010-10-17-Getting arm and lme4 running on the Mac</a></p>
<p>15 0.86675858 <a title="1869-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-11-My_problem_with_the_Lindley_paradox.html">1757 andrew gelman stats-2013-03-11-My problem with the Lindley paradox</a></p>
<p>16 0.86434639 <a title="1869-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-22-The_kluges_of_today_are_the_textbook_solutions_of_tomorrow..html">2143 andrew gelman stats-2013-12-22-The kluges of today are the textbook solutions of tomorrow.</a></p>
<p>17 0.86373448 <a title="1869-lda-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-05-The_p-value_is_not_._._..html">1607 andrew gelman stats-2012-12-05-The p-value is not . . .</a></p>
<p>18 0.86242354 <a title="1869-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-18-Understanding_posterior_p-values.html">2029 andrew gelman stats-2013-09-18-Understanding posterior p-values</a></p>
<p>19 0.86181438 <a title="1869-lda-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-30-David_Hogg_on_statistics.html">1401 andrew gelman stats-2012-06-30-David Hogg on statistics</a></p>
<p>20 0.86009228 <a title="1869-lda-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-15-Static_sensitivity_analysis.html">804 andrew gelman stats-2011-07-15-Static sensitivity analysis</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
