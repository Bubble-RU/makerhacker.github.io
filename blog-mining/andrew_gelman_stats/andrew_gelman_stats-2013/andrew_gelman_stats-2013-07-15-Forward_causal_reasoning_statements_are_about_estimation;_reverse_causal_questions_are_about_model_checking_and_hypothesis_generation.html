<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1939" href="#">andrew_gelman_stats-2013-1939</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1939-html" href="http://andrewgelman.com/2013/07/15/forward-causal-inference-is-about-estimation-reverse-causal-inference-is-about-model-checking-and-hypothesis-generation/">html</a></p><p>Introduction: Consider two broad classes of inferential  questions :
  
1.  Forward causal inference . What might happen if we do X? What are the effects of smoking on health, the effects of schooling on knowledge, the effect of campaigns on election outcomes, and so forth?


2.  Reverse causal inference . What causes Y? Why do more attractive people earn more money? Why do many poor people vote for Republicans and rich people vote for Democrats? Why did the economy collapse?
  
When statisticians and econometricians write about causal inference, they focus on forward causal questions.  Rubin always told us:  Never ask Why?  Only ask What if?  And, from the econ perspective, causation is typically framed in terms of manipulations:  if x had changed by 1, how much would y be expected to change, holding all else constant?
 
But reverse causal questions are important too.  They’re a natural way to think (consider the importance of the word “Why”) and are arguably more important than forward questions.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 When statisticians and econometricians write about causal inference, they focus on forward causal questions. [sent-11, score-1.169]
</p><p>2 But reverse causal questions are important too. [sent-15, score-1.141]
</p><p>3 In many ways, it is the reverse causal questions that lead to the experiments and observational studies that we use to answer the forward questions. [sent-17, score-1.402]
</p><p>4 My question here is:  How can we incorporate reverse causal questions into a statistical framework that is centered around forward causal inference. [sent-18, score-1.993]
</p><p>5 )   My resolution is as follows:  Forward causal inference is about estimation; reverse causal inference is about model checking and hypothesis generation. [sent-20, score-1.869]
</p><p>6 Now a reverse question:  Why do incumbents running for reelection to Congress get so much more funding than challengers? [sent-25, score-0.837]
</p><p>7 I believe that forward causal inferences can be handled in a potential-outcome or graphical-modeling framework involving a treatment variable T, an outcome y, and pre-treatment variables, x, so that the causal effect is defined (in the simple case of binary treatment) as y(T=1,x) – y(T=0,x). [sent-29, score-1.317]
</p><p>8 I would like to frame reverse causal questions as model checking. [sent-33, score-1.256]
</p><p>9 A key theme in this discussion is the distinction between causal  statements  and causal  questions . [sent-44, score-1.164]
</p><p>10 When Rubin dismissed reverse causal reasoning as “cocktail party chatter,” I think it was because you can’t clearly formulate a reverse causal statement. [sent-45, score-2.173]
</p><p>11 That is, a reverse causal question does not in general have a well-defined answer, even in a setting where all possible data are made available. [sent-46, score-1.122]
</p><p>12 The key is that reverse questions are valuable in that they focus on an anomaly—an aspect of the data unlikely to be reproducible by the current (possibly implicit) model—and point toward possible directions of model improvement. [sent-48, score-0.813]
</p><p>13 It has been (correctly) said that one of the main virtues of forward causal thinking is that it motivates us to be explicit about interventions and outcomes. [sent-49, score-0.853]
</p><p>14 Similarly, one of the main virtues of reverse causal thinking is that it motivates us to be explicit about our model. [sent-50, score-1.166]
</p><p>15 Rubin dismissed reverse causal reasoning because it can’t be fit into the “inference” step; others have struggled with little success (in my opinion) to construct direct answers to reverse causal questions. [sent-55, score-2.232]
</p><p>16 By formalizing reverse casual reasoning within the process of data analysis, I hope to make a step toward connecting our statistical reasoning to the ways that we naturally think and talk about causality. [sent-58, score-0.906]
</p><p>17 As LBJ might say:  Better to have reverse causal inference inside the statistical tent pissing out than outside pissing in. [sent-59, score-1.334]
</p><p>18 Let me say it again:   I think reverse casual  questions  are important. [sent-63, score-0.771]
</p><p>19 But I don’t think there are reverse causal  answers . [sent-64, score-1.101]
</p><p>20 The question reveals a gap between reality and our (implicit) models, but I think the answer to the question must come in the form of a forward causal statement. [sent-67, score-0.998]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reverse', 0.512), ('causal', 0.485), ('challengers', 0.257), ('incumbents', 0.238), ('forward', 0.199), ('questions', 0.144), ('inference', 0.136), ('implicit', 0.126), ('model', 0.115), ('question', 0.083), ('rubin', 0.082), ('pissing', 0.078), ('reasoning', 0.075), ('ask', 0.074), ('casual', 0.073), ('answers', 0.062), ('answer', 0.062), ('dismissed', 0.062), ('motivates', 0.059), ('effect', 0.058), ('virtues', 0.057), ('explicit', 0.053), ('vote', 0.052), ('expected', 0.05), ('theme', 0.05), ('treatment', 0.05), ('funding', 0.048), ('money', 0.047), ('explanations', 0.047), ('higher', 0.046), ('statistical', 0.045), ('form', 0.044), ('phrase', 0.043), ('think', 0.042), ('data', 0.042), ('explanation', 0.042), ('analysis', 0.042), ('ways', 0.042), ('graphical', 0.041), ('change', 0.041), ('framework', 0.04), ('existing', 0.039), ('models', 0.039), ('challenger', 0.039), ('struggled', 0.039), ('folded', 0.039), ('chatter', 0.039), ('phases', 0.039), ('get', 0.039), ('needs', 0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1939-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-15-Forward_causal_reasoning_statements_are_about_estimation%3B_reverse_causal_questions_are_about_model_checking_and_hypothesis_generation.html">1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</a></p>
<p>Introduction: Consider two broad classes of inferential  questions :
  
1.  Forward causal inference . What might happen if we do X? What are the effects of smoking on health, the effects of schooling on knowledge, the effect of campaigns on election outcomes, and so forth?


2.  Reverse causal inference . What causes Y? Why do more attractive people earn more money? Why do many poor people vote for Republicans and rich people vote for Democrats? Why did the economy collapse?
  
When statisticians and econometricians write about causal inference, they focus on forward causal questions.  Rubin always told us:  Never ask Why?  Only ask What if?  And, from the econ perspective, causation is typically framed in terms of manipulations:  if x had changed by 1, how much would y be expected to change, holding all else constant?
 
But reverse causal questions are important too.  They’re a natural way to think (consider the importance of the word “Why”) and are arguably more important than forward questions.</p><p>2 0.27602902 <a title="1939-tfidf-2" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-New_journal_on_causal_inference.html">879 andrew gelman stats-2011-08-29-New journal on causal inference</a></p>
<p>Introduction: Judea Pearl is starting an (online) Journal of Causal Inference.  The first issue is planned for Fall 2011 and the  website  is now open for submissions.  Here’s the background (from Pearl):
  
Existing discipline-specific journals tend to bury causal analysis in the language and methods of traditional statistical methodologies, creating the inaccurate impression that causal questions can be handled by routine methods of regression, simultaneous equations or logical implications, and glossing over the special ingredients  needed for causal analysis.  In contrast, Journal of Causal Inference highlights both the uniqueness and interdisciplinary nature of causal research.


In addition to significant original research articles, Journal of Causal Inference also welcomes: 
1) Submissions that synthesize and assess cross-disciplinary methodological research 
2) Submissions that discuss the history of the causal inference field and its philosophical underpinnings 
3) Unsolicited short communi</p><p>3 0.27256462 <a title="1939-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-15-%E2%80%9C10_Things_You_Need_to_Know_About_Causal_Effects%E2%80%9D.html">1675 andrew gelman stats-2013-01-15-“10 Things You Need to Know About Causal Effects”</a></p>
<p>Introduction: Macartan Humphreys pointed me to  this excellent guide .
 
Here are the 10 items:
  
1. A causal claim is a statement about what didn’t happen. 
2. There is a fundamental problem of causal inference. 
3. You can estimate average causal effects even if you cannot observe any individual causal effects. 
4. If you know that, on average, A causes B and that B causes C, this does not mean that you know that A causes C. 
5. The counterfactual model is all about contribution, not attribution. 
6. X can cause Y even if there is no “causal path” connecting X and Y. 
7. Correlation is not causation. 
8. X can cause Y even if X is not a necessary condition or a sufficient condition for Y. 
9. Estimating average causal effects does not require that treatment and control groups are identical. 
10. There is no causation without manipulation.
  
The  article  follows with crisp discussions of each point.  My favorite is item #6, not because it’s the most important but because it brings in some real s</p><p>4 0.2643643 <a title="1939-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>Introduction: Elias Bareinboim asked what I thought about  his comment  on selection bias in which he referred to a  paper  by himself and Judea Pearl, “Controlling Selection Bias in Causal Inference.”
 
I replied that I have no problem with what he wrote, but that from my perspective I find it easier to conceptualize such problems in terms of multilevel models. I elaborated on that point in a  recent post , “Hierarchical modeling as a framework for extrapolation,” which I think was read by only a few people (I say this because it received only two comments).
 
I don’t think Bareinboim objected to anything I wrote, but like me he is comfortable working within his own framework.  He wrote the following to me: 
  
  
In some sense, “not ad hoc” could mean logically consistent. In other words, if one agrees with the assumptions encoded in the model, one must also agree with the conclusions entailed by these assumptions. I am not aware of any other way of doing mathematics. As it turns out, to get causa</p><p>5 0.20446932 <a title="1939-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-08-New_Judea_Pearl_journal_of_causal_inference.html">1888 andrew gelman stats-2013-06-08-New Judea Pearl journal of causal inference</a></p>
<p>Introduction: Pearl reports that his Journal of Causal Inference has just posted its  first issue , which contains a mix of theoretical and applied papers.  Pearl writes that they welcome submissions on all aspects of causal inference.</p><p>6 0.20345277 <a title="1939-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-17-Macro_causality.html">807 andrew gelman stats-2011-07-17-Macro causality</a></p>
<p>7 0.20273584 <a title="1939-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-08-Understanding_Simpson%E2%80%99s_paradox_using_a_graph.html">2286 andrew gelman stats-2014-04-08-Understanding Simpson’s paradox using a graph</a></p>
<p>8 0.17707647 <a title="1939-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-My_talk_at_the_University_of_Michigan_today_4pm.html">1778 andrew gelman stats-2013-03-27-My talk at the University of Michigan today 4pm</a></p>
<p>9 0.17552154 <a title="1939-tfidf-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-30-Adjudicating_between_alternative_interpretations_of_a_statistical_interaction%3F.html">2274 andrew gelman stats-2014-03-30-Adjudicating between alternative interpretations of a statistical interaction?</a></p>
<p>10 0.17358525 <a title="1939-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-All_inference_is_about_generalizing_from_sample_to_population.html">1996 andrew gelman stats-2013-08-24-All inference is about generalizing from sample to population</a></p>
<p>11 0.17239027 <a title="1939-tfidf-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-13-Randomized_experiments%2C_non-randomized_experiments%2C_and_observational_studies.html">340 andrew gelman stats-2010-10-13-Randomized experiments, non-randomized experiments, and observational studies</a></p>
<p>12 0.15073244 <a title="1939-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-22-Battle_of_the_Repo_Man_quotes%3A__Reid_Hastie%E2%80%99s_turn.html">1336 andrew gelman stats-2012-05-22-Battle of the Repo Man quotes:  Reid Hastie’s turn</a></p>
<p>13 0.15016535 <a title="1939-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-11-Why_ask_why%3F_Forward_causal_inference_and_reverse_causal_questions.html">2097 andrew gelman stats-2013-11-11-Why ask why? Forward causal inference and reverse causal questions</a></p>
<p>14 0.14818022 <a title="1939-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-22-Evaluating_the_impacts_of_welfare_reform%3F.html">1732 andrew gelman stats-2013-02-22-Evaluating the impacts of welfare reform?</a></p>
<p>15 0.14664625 <a title="1939-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>16 0.14264229 <a title="1939-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-24-Bleg%3A_Automatic_Differentiation_for_Log_Prob_Gradients%3F.html">535 andrew gelman stats-2011-01-24-Bleg: Automatic Differentiation for Log Prob Gradients?</a></p>
<p>17 0.14212926 <a title="1939-tfidf-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-13-Judea_Pearl_overview_on_causal_inference%2C_and_more_general_thoughts_on_the_reexpression_of_existing_methods_by_considering_their_implicit_assumptions.html">2170 andrew gelman stats-2014-01-13-Judea Pearl overview on causal inference, and more general thoughts on the reexpression of existing methods by considering their implicit assumptions</a></p>
<p>18 0.14036001 <a title="1939-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>19 0.13782488 <a title="1939-tfidf-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-11-My_talks_in_Bristol_this_Wed_and_London_this_Thurs.html">2207 andrew gelman stats-2014-02-11-My talks in Bristol this Wed and London this Thurs</a></p>
<p>20 0.13640732 <a title="1939-tfidf-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-14-Subtleties_with_measurement-error_models_for_the_evaluation_of_wacky_claims.html">803 andrew gelman stats-2011-07-14-Subtleties with measurement-error models for the evaluation of wacky claims</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.23), (1, 0.065), (2, 0.046), (3, -0.028), (4, -0.038), (5, 0.023), (6, -0.109), (7, -0.007), (8, 0.129), (9, 0.037), (10, -0.063), (11, 0.074), (12, -0.001), (13, -0.03), (14, 0.007), (15, -0.02), (16, 0.002), (17, -0.007), (18, -0.063), (19, 0.122), (20, -0.056), (21, -0.141), (22, 0.133), (23, 0.015), (24, 0.114), (25, 0.222), (26, 0.044), (27, -0.075), (28, -0.044), (29, 0.066), (30, 0.027), (31, -0.07), (32, -0.046), (33, 0.032), (34, -0.083), (35, 0.029), (36, 0.045), (37, -0.031), (38, -0.018), (39, 0.046), (40, -0.059), (41, 0.004), (42, -0.048), (43, 0.035), (44, -0.019), (45, 0.026), (46, -0.04), (47, 0.021), (48, 0.027), (49, -0.029)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97021639 <a title="1939-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-15-Forward_causal_reasoning_statements_are_about_estimation%3B_reverse_causal_questions_are_about_model_checking_and_hypothesis_generation.html">1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</a></p>
<p>Introduction: Consider two broad classes of inferential  questions :
  
1.  Forward causal inference . What might happen if we do X? What are the effects of smoking on health, the effects of schooling on knowledge, the effect of campaigns on election outcomes, and so forth?


2.  Reverse causal inference . What causes Y? Why do more attractive people earn more money? Why do many poor people vote for Republicans and rich people vote for Democrats? Why did the economy collapse?
  
When statisticians and econometricians write about causal inference, they focus on forward causal questions.  Rubin always told us:  Never ask Why?  Only ask What if?  And, from the econ perspective, causation is typically framed in terms of manipulations:  if x had changed by 1, how much would y be expected to change, holding all else constant?
 
But reverse causal questions are important too.  They’re a natural way to think (consider the importance of the word “Why”) and are arguably more important than forward questions.</p><p>2 0.90433466 <a title="1939-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-15-%E2%80%9C10_Things_You_Need_to_Know_About_Causal_Effects%E2%80%9D.html">1675 andrew gelman stats-2013-01-15-“10 Things You Need to Know About Causal Effects”</a></p>
<p>Introduction: Macartan Humphreys pointed me to  this excellent guide .
 
Here are the 10 items:
  
1. A causal claim is a statement about what didn’t happen. 
2. There is a fundamental problem of causal inference. 
3. You can estimate average causal effects even if you cannot observe any individual causal effects. 
4. If you know that, on average, A causes B and that B causes C, this does not mean that you know that A causes C. 
5. The counterfactual model is all about contribution, not attribution. 
6. X can cause Y even if there is no “causal path” connecting X and Y. 
7. Correlation is not causation. 
8. X can cause Y even if X is not a necessary condition or a sufficient condition for Y. 
9. Estimating average causal effects does not require that treatment and control groups are identical. 
10. There is no causation without manipulation.
  
The  article  follows with crisp discussions of each point.  My favorite is item #6, not because it’s the most important but because it brings in some real s</p><p>3 0.84420812 <a title="1939-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-08-New_Judea_Pearl_journal_of_causal_inference.html">1888 andrew gelman stats-2013-06-08-New Judea Pearl journal of causal inference</a></p>
<p>Introduction: Pearl reports that his Journal of Causal Inference has just posted its  first issue , which contains a mix of theoretical and applied papers.  Pearl writes that they welcome submissions on all aspects of causal inference.</p><p>4 0.84357375 <a title="1939-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-23-Fight%21__%28also_a_bit_of_reminiscence_at_the_end%29.html">1136 andrew gelman stats-2012-01-23-Fight!  (also a bit of reminiscence at the end)</a></p>
<p>Introduction: Martin Lindquist and Michael Sobel published a  fun little article  in Neuroimage on models and assumptions for causal inference with intermediate outcomes. As their subtitle indicates (“A response to the comments on our comment”), this is a topic of some controversy. Lindquist and Sobel write:
  
Our original comment (Lindquist and Sobel, 2011) made explicit the types of assumptions neuroimaging researchers are making when directed graphical models (DGMs), which include certain types of structural equation models (SEMs), are used to estimate causal effects. When these assumptions, which many researchers are not aware of, are not met, parameters of these models should not be interpreted as effects. . . . [Judea] Pearl does not disagree with anything we stated. However, he takes exception to our use of potential outcomes notation, which is the standard notation used in the statistical literature on causal inference, and his comment is devoted to promoting his alternative conventions. [C</p><p>5 0.83068913 <a title="1939-lsi-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-13-Randomized_experiments%2C_non-randomized_experiments%2C_and_observational_studies.html">340 andrew gelman stats-2010-10-13-Randomized experiments, non-randomized experiments, and observational studies</a></p>
<p>Introduction: In the spirit of Dehejia and Wahba:
 
 Three Conditions under Which Experiments and Observational Studies Produce Comparable Causal Estimates: New Findings from Within-Study Comparisons , by Cook, Shadish, and Wong.
 
 Can Nonrandomized Experiments Yield Accurate Answers?  A Randomized Experiment Comparing Random and Nonrandom Assignments, by Shadish, Clark, and Steiner.
 
I just talk about causal inference.  These people do it.  The second link above is particularly interesting because it includes discussions by some causal inference heavyweights.  WWJD and all that.</p><p>6 0.80937034 <a title="1939-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-New_journal_on_causal_inference.html">879 andrew gelman stats-2011-08-29-New journal on causal inference</a></p>
<p>7 0.80917174 <a title="1939-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-17-Macro_causality.html">807 andrew gelman stats-2011-07-17-Macro causality</a></p>
<p>8 0.80676275 <a title="1939-lsi-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-11-Why_ask_why%3F_Forward_causal_inference_and_reverse_causal_questions.html">2097 andrew gelman stats-2013-11-11-Why ask why? Forward causal inference and reverse causal questions</a></p>
<p>9 0.80650395 <a title="1939-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-08-Understanding_Simpson%E2%80%99s_paradox_using_a_graph.html">2286 andrew gelman stats-2014-04-08-Understanding Simpson’s paradox using a graph</a></p>
<p>10 0.79787248 <a title="1939-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-24-All_inference_is_about_generalizing_from_sample_to_population.html">1996 andrew gelman stats-2013-08-24-All inference is about generalizing from sample to population</a></p>
<p>11 0.78946114 <a title="1939-lsi-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>12 0.78554827 <a title="1939-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-04-Estimating_the_effect_of_A_on_B%2C_and_also_the_effect_of_B_on_A.html">393 andrew gelman stats-2010-11-04-Estimating the effect of A on B, and also the effect of B on A</a></p>
<p>13 0.76400697 <a title="1939-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-11-Using_the_%E2%80%9Cinstrumental_variables%E2%80%9D_or_%E2%80%9Cpotential_outcomes%E2%80%9D_approach_to_clarify_causal_thinking.html">1492 andrew gelman stats-2012-09-11-Using the “instrumental variables” or “potential outcomes” approach to clarify causal thinking</a></p>
<p>14 0.75472414 <a title="1939-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-02-An_IV_won%E2%80%99t_save_your_life_if_the_line_is_tangled.html">550 andrew gelman stats-2011-02-02-An IV won’t save your life if the line is tangled</a></p>
<p>15 0.73545092 <a title="1939-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-15-New_prize_on_causality_in_statstistics_education.html">1624 andrew gelman stats-2012-12-15-New prize on causality in statstistics education</a></p>
<p>16 0.72789454 <a title="1939-lsi-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-My_talk_at_the_University_of_Michigan_today_4pm.html">1778 andrew gelman stats-2013-03-27-My talk at the University of Michigan today 4pm</a></p>
<p>17 0.71566814 <a title="1939-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-22-Evaluating_the_impacts_of_welfare_reform%3F.html">1732 andrew gelman stats-2013-02-22-Evaluating the impacts of welfare reform?</a></p>
<p>18 0.70942914 <a title="1939-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-14-Detecting_predictability_in_complex_ecosystems.html">1802 andrew gelman stats-2013-04-14-Detecting predictability in complex ecosystems</a></p>
<p>19 0.70519328 <a title="1939-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-13-Judea_Pearl_overview_on_causal_inference%2C_and_more_general_thoughts_on_the_reexpression_of_existing_methods_by_considering_their_implicit_assumptions.html">2170 andrew gelman stats-2014-01-13-Judea Pearl overview on causal inference, and more general thoughts on the reexpression of existing methods by considering their implicit assumptions</a></p>
<p>20 0.70052385 <a title="1939-lsi-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-21-Judea_Pearl_on_why_he_is_%E2%80%9Conly_a_half-Bayesian%E2%80%9D.html">1133 andrew gelman stats-2012-01-21-Judea Pearl on why he is “only a half-Bayesian”</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.01), (9, 0.022), (15, 0.023), (16, 0.075), (21, 0.044), (24, 0.172), (36, 0.013), (45, 0.011), (46, 0.065), (53, 0.012), (63, 0.014), (76, 0.012), (86, 0.025), (89, 0.073), (99, 0.3)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97573292 <a title="1939-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-15-Forward_causal_reasoning_statements_are_about_estimation%3B_reverse_causal_questions_are_about_model_checking_and_hypothesis_generation.html">1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</a></p>
<p>Introduction: Consider two broad classes of inferential  questions :
  
1.  Forward causal inference . What might happen if we do X? What are the effects of smoking on health, the effects of schooling on knowledge, the effect of campaigns on election outcomes, and so forth?


2.  Reverse causal inference . What causes Y? Why do more attractive people earn more money? Why do many poor people vote for Republicans and rich people vote for Democrats? Why did the economy collapse?
  
When statisticians and econometricians write about causal inference, they focus on forward causal questions.  Rubin always told us:  Never ask Why?  Only ask What if?  And, from the econ perspective, causation is typically framed in terms of manipulations:  if x had changed by 1, how much would y be expected to change, holding all else constant?
 
But reverse causal questions are important too.  They’re a natural way to think (consider the importance of the word “Why”) and are arguably more important than forward questions.</p><p>2 0.97505116 <a title="1939-lda-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-23-Traditionalist_claims_that_modern_art_could_just_as_well_be_replaced_by_a_%E2%80%9Cpaint-throwing_chimp%E2%80%9D.html">1390 andrew gelman stats-2012-06-23-Traditionalist claims that modern art could just as well be replaced by a “paint-throwing chimp”</a></p>
<p>Introduction: Jed Dougherty points me to  this opinion piece  by Jacqueline Stevens, a professor of art at Northwestern University, who writes:
  
Artists are defensive these days because in May the House passed an amendment to a bill eliminating the National Endowment for the Arts.  Colleagues, especially those who have received N.E.A. grants, will loathe me for saying this, but just this once I’m sympathetic with the anti-intellectual Republicans behind this amendment. Why? The bill incited a national conversation about a subject that has troubled me for decades: the government — disproportionately — supports art that I do not like.


Actually, just about nobody likes modern art.  All those soup cans—what’s that all about?  The stuff they have in museums nowadays, my 4-year-old could do better than that.  Two-thirds of so-called modern artists are drunk and two-thirds are frauds.  And, no, I didn’t get my math wrong—there’s just a lot of overlap among these categories!


It’s an open secret in my</p><p>3 0.97382551 <a title="1939-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-01-Don%E2%80%99t_let_your_standard_errors_drive_your_research_agenda.html">1702 andrew gelman stats-2013-02-01-Don’t let your standard errors drive your research agenda</a></p>
<p>Introduction: Alexis Le Nestour writes:
  
How do you test for no effect? I attended a seminar where the person assumed that a non significant difference between groups implied an absence of effect. In that case, the researcher needed to show that two groups were similar before being hit by a shock conditional on some observable variables. The assumption was that the two groups were similar and that the shock was random. What would be the good way to set up a test in that case?


I know you’ve been through that before (http://andrewgelman.com/2009/02/not_statistical/) and there are interesting comments but I wanted to have your opinion on that.
  
My reply:  I think you have to get quantitative here.  How similar is similar?  Don’t let your standard errors drive your research agenda.  Or, to put it another way, what would you do if you had all the data?  If your sample size were 1 zillion, then everything would statistically distinguishable from everything else.  And then you’d have to think about w</p><p>4 0.97103316 <a title="1939-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-24-Yet_another_Bayesian_job_opportunity.html">231 andrew gelman stats-2010-08-24-Yet another Bayesian job opportunity</a></p>
<p>Introduction: Steve Cohen writes:
  
My [Cohen's] firm is looking for strong candidates to help us in developing software and analyzing data using Bayesian methods.


We have been developing a suite of programs in C++ which allow us to do Bayesian hierarchical regression and logit/probit models on marketing data. These efforts have included the use of high performance computing tools like nVidia’s CUDA and the new OpenCL standard, which allow parallel processing of Bayesian models. Our software is very, very fast – even on databases that are ½ terabyte in size. The software still needs many additions and improvements and a person with the right skill set will have the chance to make a significant contribution.
  
Here’s the job description he sent:
  
 
Bayesian statistician and C++ programmer


The company


In4mation Insights is a marketing research, analytics, and consulting firm which operates on the leading-edge of our industry.  Our clients are Fortune 500 companies and major management consul</p><p>5 0.96968251 <a title="1939-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-10-I_don%E2%80%99t_like_this_cartoon.html">1572 andrew gelman stats-2012-11-10-I don’t like this cartoon</a></p>
<p>Introduction: Some people pointed me to  this :
 
 
 
I am happy to see statistical theory and methods be a topic in popular culture, and of course I’m glad that, contra  Feller , the Bayesian is presented as the hero this time, but . . . . I think the lower-left panel of the cartoon unfairly misrepresents frequentist statisticians.
 
Frequentist statisticians recognize many statistical goals.  Point estimates trade off bias and variance.  Interval estimates have the goal of achieving nominal coverage and the goal of being informative.  Tests have the goals of calibration and power.  Frequentists know that no single principle applies in all settings, and this is a setting where this particular method is clearly inappropriate.  All statisticians use prior information in their statistical analysis.  Non-Bayesians express their prior information not through a probability distribution on parameters but rather through their choice of methods.  I think this non-Bayesian attitude is too restrictive, but in</p><p>6 0.96860999 <a title="1939-lda-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-16-Stantastic%21.html">1580 andrew gelman stats-2012-11-16-Stantastic!</a></p>
<p>7 0.96668237 <a title="1939-lda-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-04-Shlemiel_the_Software_Developer_and_Unknown_Unknowns.html">2089 andrew gelman stats-2013-11-04-Shlemiel the Software Developer and Unknown Unknowns</a></p>
<p>8 0.96356499 <a title="1939-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-19-Scalability_in_education.html">1502 andrew gelman stats-2012-09-19-Scalability in education</a></p>
<p>9 0.96335304 <a title="1939-lda-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-28-Turing_chess_run_update.html">1473 andrew gelman stats-2012-08-28-Turing chess run update</a></p>
<p>10 0.96173489 <a title="1939-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-21-BDA3_table_of_contents_%28also_a_new_paper_on_visualization%29.html">1991 andrew gelman stats-2013-08-21-BDA3 table of contents (also a new paper on visualization)</a></p>
<p>11 0.96109998 <a title="1939-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-03-How_best_to_compare_effects_measured_in_two_different_time_periods%3F.html">2086 andrew gelman stats-2013-11-03-How best to compare effects measured in two different time periods?</a></p>
<p>12 0.96051073 <a title="1939-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-17-Macro_causality.html">807 andrew gelman stats-2011-07-17-Macro causality</a></p>
<p>13 0.96036518 <a title="1939-lda-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-20-Fooled_by_randomness.html">2297 andrew gelman stats-2014-04-20-Fooled by randomness</a></p>
<p>14 0.96005857 <a title="1939-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-23-Combining_survey_data_obtained_using_different_modes_of_sampling.html">777 andrew gelman stats-2011-06-23-Combining survey data obtained using different modes of sampling</a></p>
<p>15 0.95856404 <a title="1939-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-29-More_consulting_experiences%2C_this_time_in_computational_linguistics.html">1596 andrew gelman stats-2012-11-29-More consulting experiences, this time in computational linguistics</a></p>
<p>16 0.95762849 <a title="1939-lda-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-11-Adding_an_error_model_to_a_deterministic_model.html">1162 andrew gelman stats-2012-02-11-Adding an error model to a deterministic model</a></p>
<p>17 0.95760381 <a title="1939-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<p>18 0.95729172 <a title="1939-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-12-Misunderstanding_the_p-value.html">1760 andrew gelman stats-2013-03-12-Misunderstanding the p-value</a></p>
<p>19 0.9560703 <a title="1939-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-21-Chasing_the_noise.html">2142 andrew gelman stats-2013-12-21-Chasing the noise</a></p>
<p>20 0.95583296 <a title="1939-lda-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-02-Moving_beyond_hopeless_graphics.html">1403 andrew gelman stats-2012-07-02-Moving beyond hopeless graphics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
