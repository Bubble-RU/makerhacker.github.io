<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1656" href="#">andrew_gelman_stats-2013-1656</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1656-html" href="http://andrewgelman.com/2013/01/05/understanding-regression-models-and-regression-coefficients/">html</a></p><p>Introduction: David Hoaglin writes:
  
After seeing it cited, I just read  your paper  in Technometrics.  The home radon levels provide an interesting and instructive example.


I [Hoaglin] have a different take on the difficulty of interpreting the estimated coefficient of the county-level basement proportion (gamma-sub-2) on page 434.  An important part of the difficulty involves “other things being equal.”  That sounds like the widespread interpretation of a regression coefficient as telling how the dependent variable responds to change in that predictor when the other predictors are held constant.  Unfortunately, as a general interpretation, that language is oversimplified; it doesn’t reflect how regression actually works.  The appropriate general interpretation is that the coefficient tells how the dependent variable responds to change in that predictor after allowing for simultaneous change in the other predictors in the data at hand.  Thus, in the county-level regression gamma-sub-2 summarize</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I [Hoaglin] have a different take on the difficulty of interpreting the estimated coefficient of the county-level basement proportion (gamma-sub-2) on page 434. [sent-3, score-0.361]
</p><p>2 ”  That sounds like the widespread interpretation of a regression coefficient as telling how the dependent variable responds to change in that predictor when the other predictors are held constant. [sent-5, score-1.439]
</p><p>3 The appropriate general interpretation is that the coefficient tells how the dependent variable responds to change in that predictor after allowing for simultaneous change in the other predictors in the data at hand. [sent-7, score-1.717]
</p><p>4 Thus, in the county-level regression gamma-sub-2 summarizes the relation of  alpha to x-bar after allowing for the contribution of u (the log of the uranium level in the county). [sent-8, score-0.675]
</p><p>5 What was the relation between the basement proportion and the uranium level? [sent-9, score-0.406]
</p><p>6 I continue to be surprised at the number of textbooks that shortchange students by teaching the “held constant” interpretation of coefficients in multiple regression. [sent-18, score-0.363]
</p><p>7 ”    My reply:  As Jennifer and I discuss in our book, regression coefficients can be interpreted in more than one way. [sent-23, score-0.364]
</p><p>8 Hoaglin writes, “The appropriate general interpretation is that the coefficient tells how the dependent variable responds to change in that predictor after allowing for simultaneous change in the other predictors in the data at hand,” and Speed says something similar. [sent-24, score-1.717]
</p><p>9 But I don’t actually find that description very helpful because I don’t really know how to interpret the phrase, “allowing for simultaneous change in the other predictors. [sent-25, score-0.472]
</p><p>10 ”  If I’m in purely descriptive mode, I prefer to say that, if you’re regressing y on u and v, the coefficient of u is the average difference in y per difference in u, comparing pairs of items that differ in u but are identical in v. [sent-26, score-0.77]
</p><p>11 (See my paper with Pardoe on average predictive comparisons for more on this idea, including how to define this averaging so that, in a simple linear model, you end up with the usual regression coefficient. [sent-27, score-0.478]
</p><p>12 Because, in its most basic form, regression tells you nothing at all about change. [sent-31, score-0.409]
</p><p>13 For sparse or continuous data, you can’t really find these comparisons where v is identical, so it’s clear that regression coefficients are model-based. [sent-37, score-0.513]
</p><p>14 In that sense, I don’t mind vague statements such as “allowing for simultaneous change in the other predictors. [sent-38, score-0.36]
</p><p>15 ”  I’d prefer the term “comparison” rather than “change,” but the real point is that regression coefficients represent averages in a sort of smoothed comparison, a particular smoothing based on a linear model. [sent-39, score-0.439]
</p><p>16 More in a bit, but first another quote from Terry:    Think of the world of difference between using a regression model for prediction and using one for estimating a parameter with a causal interpretation, for example, the effect of class size on school children’s test scores. [sent-53, score-0.603]
</p><p>17 With prediction, we don’t need our relationship to be causal, but we do need to be concerned with the relation between our training and our test set. [sent-54, score-0.415]
</p><p>18 When estimating the causal parameter, we do need to ask whether the children were randomly assigned to classes of different sizes, and if not, we need to find a way to deal with possible selection bias. [sent-56, score-0.408]
</p><p>19 Terry seems unaware of the potential-outcome framing of causal inference, in which causal estimands are defined in terms of various hypothetical scenarios. [sent-58, score-0.314]
</p><p>20 Terry continues:    I would like to see multiple regression taught as a series of case studies, each study addressing a sharp question, and focussing on those aspects of the topic that are relevant to that question. [sent-61, score-0.376]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('terry', 0.448), ('regression', 0.251), ('interpretation', 0.186), ('hoaglin', 0.185), ('simultaneous', 0.184), ('change', 0.176), ('allowing', 0.176), ('causal', 0.157), ('responds', 0.151), ('coefficient', 0.15), ('predictor', 0.128), ('relation', 0.125), ('uranium', 0.123), ('coefficients', 0.113), ('dependent', 0.106), ('predictors', 0.106), ('speed', 0.103), ('identical', 0.101), ('basement', 0.098), ('differ', 0.097), ('partial', 0.097), ('comparisons', 0.095), ('held', 0.094), ('training', 0.093), ('variable', 0.091), ('tells', 0.087), ('children', 0.083), ('test', 0.083), ('linear', 0.075), ('nothing', 0.071), ('hill', 0.069), ('descriptive', 0.068), ('constant', 0.068), ('multiple', 0.064), ('purely', 0.064), ('items', 0.061), ('taught', 0.061), ('computing', 0.06), ('proportion', 0.06), ('jennifer', 0.06), ('interpret', 0.058), ('difference', 0.058), ('average', 0.057), ('need', 0.057), ('regressing', 0.056), ('woes', 0.056), ('easier', 0.055), ('find', 0.054), ('prediction', 0.054), ('difficulty', 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1656-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>Introduction: David Hoaglin writes:
  
After seeing it cited, I just read  your paper  in Technometrics.  The home radon levels provide an interesting and instructive example.


I [Hoaglin] have a different take on the difficulty of interpreting the estimated coefficient of the county-level basement proportion (gamma-sub-2) on page 434.  An important part of the difficulty involves “other things being equal.”  That sounds like the widespread interpretation of a regression coefficient as telling how the dependent variable responds to change in that predictor when the other predictors are held constant.  Unfortunately, as a general interpretation, that language is oversimplified; it doesn’t reflect how regression actually works.  The appropriate general interpretation is that the coefficient tells how the dependent variable responds to change in that predictor after allowing for simultaneous change in the other predictors in the data at hand.  Thus, in the county-level regression gamma-sub-2 summarize</p><p>2 0.17846112 <a title="1656-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>Introduction: Dan Kahan writes: 
  
  
Okay, have done due diligence here & can’t find the reference. It was in recent blog — and was more or less an aside — but you ripped into researchers (pretty sure econometricians, but this could be my memory adding to your account recollections it conjured from my own experience) who purport to make estimates or predictions based on multivariate regression in which the value of particular predictor is set at some level while others “held constant” etc., on ground that variance in that particular predictor independent of covariance in other model predictors is unrealistic.  You made it sound, too, as if this were one of the pet peeves in your menagerie — leading me to think you had blasted into it before.


Know what I’m talking about?


Also — isn’t this really just a way of saying that the model is misspecified — at least if the goal is to try to make a valid & unbiased estimate of the impact of that particular predictor? The problem can’t be that one is usin</p><p>3 0.14513856 <a title="1656-tfidf-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-14-The_robust_beauty_of_improper_linear_models_in_decision_making.html">1981 andrew gelman stats-2013-08-14-The robust beauty of improper linear models in decision making</a></p>
<p>Introduction: Andreas Graefe writes (see  here   here   here ):
  
The usual procedure for developing linear models to predict any kind of target variable is to identify a subset of most important predictors and to estimate weights that provide the best possible solution for a given sample. The resulting “optimally” weighted linear composite is then used when predicting new data. This approach is useful in situations with large and reliable datasets and few predictor variables. However, a large body of analytical and empirical evidence since the 1970s shows that the weighting of variables is of little, if any, value in situations with small and noisy datasets and a large number of predictor variables. In such situations, including all relevant variables is more important than their weighting. These findings have yet to impact many fields. This study uses data from nine established U.S. election-forecasting models whose forecasts are regularly published in academic journals to demonstrate the value o</p><p>4 0.14424148 <a title="1656-tfidf-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>Introduction: Elias Bareinboim asked what I thought about  his comment  on selection bias in which he referred to a  paper  by himself and Judea Pearl, “Controlling Selection Bias in Causal Inference.”
 
I replied that I have no problem with what he wrote, but that from my perspective I find it easier to conceptualize such problems in terms of multilevel models. I elaborated on that point in a  recent post , “Hierarchical modeling as a framework for extrapolation,” which I think was read by only a few people (I say this because it received only two comments).
 
I don’t think Bareinboim objected to anything I wrote, but like me he is comfortable working within his own framework.  He wrote the following to me: 
  
  
In some sense, “not ad hoc” could mean logically consistent. In other words, if one agrees with the assumptions encoded in the model, one must also agree with the conclusions entailed by these assumptions. I am not aware of any other way of doing mathematics. As it turns out, to get causa</p><p>5 0.13695721 <a title="1656-tfidf-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Matching_and_regression%3A__two_great_tastes_etc_etc.html">796 andrew gelman stats-2011-07-10-Matching and regression:  two great tastes etc etc</a></p>
<p>Introduction: Matthew Bogard writes:
  
Regarding the book Mostly Harmless Econometrics, you  state :

 
A casual reader of the book might be left with the unfortunate impression that matching is a competitor to regression rather than a tool for making regression more effective.
 

But in fact isn’t that what they are arguing, that, in a  ‘mostly harmless way’ regression is in fact a matching estimator itself?


“Our view is that regression can be motivated as a particular sort of weighted matching estimator, and therefore the differences between regression and matching estimates are unlikely to be of major empirical importance” (Chapter 3 p. 70)


They seem to be distinguishing regression (without prior matching) from all other types of matching techniques, and therefore implying that regression can be a ‘mostly harmless’ substitute or competitor to matching. My previous understanding, before starting this book was as you say, that matching is a tool that makes regression more effective.


I have n</p><p>6 0.13664398 <a title="1656-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>7 0.13584292 <a title="1656-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-15-Forward_causal_reasoning_statements_are_about_estimation%3B_reverse_causal_questions_are_about_model_checking_and_hypothesis_generation.html">1939 andrew gelman stats-2013-07-15-Forward causal reasoning statements are about estimation; reverse causal questions are about model checking and hypothesis generation</a></p>
<p>8 0.13474531 <a title="1656-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-15-Exploratory_multilevel_analysis_when_group-level_variables_are_of_importance.html">1900 andrew gelman stats-2013-06-15-Exploratory multilevel analysis when group-level variables are of importance</a></p>
<p>9 0.13313554 <a title="1656-tfidf-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-17-Graphical_tools_for_understanding_multilevel_models.html">772 andrew gelman stats-2011-06-17-Graphical tools for understanding multilevel models</a></p>
<p>10 0.13165523 <a title="1656-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-26-How_to_understand_coefficients_that_reverse_sign_when_you_start_controlling_for_things%3F.html">1870 andrew gelman stats-2013-05-26-How to understand coefficients that reverse sign when you start controlling for things?</a></p>
<p>11 0.12711297 <a title="1656-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-20-Correcting_for_multiple_comparisons_in_a_Bayesian_regression_model.html">1989 andrew gelman stats-2013-08-20-Correcting for multiple comparisons in a Bayesian regression model</a></p>
<p>12 0.1257917 <a title="1656-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-03-A_psychology_researcher_asks%3A__Is_Anova_dead%3F.html">888 andrew gelman stats-2011-09-03-A psychology researcher asks:  Is Anova dead?</a></p>
<p>13 0.12251225 <a title="1656-tfidf-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>14 0.12143586 <a title="1656-tfidf-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-05-What_do_practitioners_need_to_know_about_regression%3F.html">451 andrew gelman stats-2010-12-05-What do practitioners need to know about regression?</a></p>
<p>15 0.11952542 <a title="1656-tfidf-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-05-Question_26_of_my_final_exam_for_Design_and_Analysis_of_Sample_Surveys.html">1367 andrew gelman stats-2012-06-05-Question 26 of my final exam for Design and Analysis of Sample Surveys</a></p>
<p>16 0.11834502 <a title="1656-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-08-29-New_journal_on_causal_inference.html">879 andrew gelman stats-2011-08-29-New journal on causal inference</a></p>
<p>17 0.11743353 <a title="1656-tfidf-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-21-Building_a_regression_model_._._._with_only_27_data_points.html">1506 andrew gelman stats-2012-09-21-Building a regression model . . . with only 27 data points</a></p>
<p>18 0.11612043 <a title="1656-tfidf-18" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-29-References_%28with_code%29_for_Bayesian_hierarchical_%28multilevel%29_modeling_and_structural_equation_modeling.html">2273 andrew gelman stats-2014-03-29-References (with code) for Bayesian hierarchical (multilevel) modeling and structural equation modeling</a></p>
<p>19 0.11572986 <a title="1656-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>20 0.11404345 <a title="1656-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-Why_we_hate_stepwise_regression.html">2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.238), (1, 0.085), (2, 0.061), (3, -0.045), (4, 0.1), (5, 0.028), (6, 0.002), (7, -0.005), (8, 0.075), (9, 0.085), (10, 0.015), (11, 0.059), (12, 0.006), (13, -0.02), (14, 0.066), (15, 0.014), (16, -0.033), (17, -0.003), (18, -0.026), (19, -0.0), (20, -0.001), (21, 0.058), (22, 0.096), (23, -0.006), (24, 0.079), (25, 0.063), (26, 0.08), (27, -0.101), (28, -0.028), (29, 0.01), (30, 0.062), (31, 0.019), (32, 0.01), (33, 0.01), (34, -0.022), (35, -0.023), (36, 0.064), (37, 0.029), (38, 0.007), (39, -0.011), (40, -0.04), (41, 0.01), (42, -0.018), (43, -0.055), (44, 0.02), (45, 0.012), (46, -0.039), (47, 0.056), (48, 0.044), (49, -0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97493029 <a title="1656-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>Introduction: David Hoaglin writes:
  
After seeing it cited, I just read  your paper  in Technometrics.  The home radon levels provide an interesting and instructive example.


I [Hoaglin] have a different take on the difficulty of interpreting the estimated coefficient of the county-level basement proportion (gamma-sub-2) on page 434.  An important part of the difficulty involves “other things being equal.”  That sounds like the widespread interpretation of a regression coefficient as telling how the dependent variable responds to change in that predictor when the other predictors are held constant.  Unfortunately, as a general interpretation, that language is oversimplified; it doesn’t reflect how regression actually works.  The appropriate general interpretation is that the coefficient tells how the dependent variable responds to change in that predictor after allowing for simultaneous change in the other predictors in the data at hand.  Thus, in the county-level regression gamma-sub-2 summarize</p><p>2 0.82698512 <a title="1656-lsi-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-06-02-Why_we_hate_stepwise_regression.html">2357 andrew gelman stats-2014-06-02-Why we hate stepwise regression</a></p>
<p>Introduction: Haynes Goddard writes:
  
I have been slowly working my way through the grad program in stats here, and the latest course was a biostats course on categorical and survival analysis.  I noticed in the semi-parametric  and parametric material (Wang and Lee is the text) that they use stepwise regression a lot.


I learned in econometrics that stepwise is poor practice, as it defaults to the “theory of the regression line”, that is no theory at all, just the variation in the data.


I don’t find the topic on your blog, and wonder if you have addressed the issue.
  
My reply:
 
Stepwise regression is one of these things, like outlier detection and pie charts, which appear to be popular among non-statisticans but are considered by statisticians to be a bit of a joke.  For example, Jennifer and I don’t mention stepwise regression in our book, not even once.
 
To address the issue more directly:  the motivation behind stepwise regression is that you have a lot of potential predictors but not e</p><p>3 0.8263483 <a title="1656-lsi-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>Introduction: Andy Cooper writes:
  
A link to an  article , “Four Assumptions Of Multiple Regression That Researchers Should Always Test”, has been making  the rounds  on Twitter.  Their first rule is “Variables are Normally distributed.”  And they seem to be talking about the independent variables – but then later bring in tests on the residuals (while admitting that the normally-distributed error assumption is a weak assumption).  


I thought we had long-since moved away from transforming our independent variables to make them normally distributed for statistical reasons (as opposed to standardizing them for interpretability, etc.)  Am I missing something?  I agree that leverage in a influence is important, but normality of the variables? The article is from 2002, so it might be dated, but given the popularity of the tweet, I thought I’d ask your opinion.
  
My response:  There’s some useful advice on that page but overall I think the advice was dated even in 2002.  In section 3.6 of my book wit</p><p>4 0.82523173 <a title="1656-lsi-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-10-Matching_and_regression%3A__two_great_tastes_etc_etc.html">796 andrew gelman stats-2011-07-10-Matching and regression:  two great tastes etc etc</a></p>
<p>Introduction: Matthew Bogard writes:
  
Regarding the book Mostly Harmless Econometrics, you  state :

 
A casual reader of the book might be left with the unfortunate impression that matching is a competitor to regression rather than a tool for making regression more effective.
 

But in fact isn’t that what they are arguing, that, in a  ‘mostly harmless way’ regression is in fact a matching estimator itself?


“Our view is that regression can be motivated as a particular sort of weighted matching estimator, and therefore the differences between regression and matching estimates are unlikely to be of major empirical importance” (Chapter 3 p. 70)


They seem to be distinguishing regression (without prior matching) from all other types of matching techniques, and therefore implying that regression can be a ‘mostly harmless’ substitute or competitor to matching. My previous understanding, before starting this book was as you say, that matching is a tool that makes regression more effective.


I have n</p><p>5 0.8138386 <a title="1656-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-31-Using_factor_analysis_or_principal_components_analysis_or_measurement-error_models_for_biological_measurements_in_archaeology%3F.html">1094 andrew gelman stats-2011-12-31-Using factor analysis or principal components analysis or measurement-error models for biological measurements in archaeology?</a></p>
<p>Introduction: Greg Campbell writes:
  
I am a Canadian archaeologist (BSc in Chemistry) researching the past human use of European Atlantic shellfish. After two decades of practice I am finally getting a MA in archaeology at Reading. I am seeing if the habitat or size of harvested mussels (Mytilus edulis) can be reconstructed from measurements of the umbo (the pointy end, and the only bit that survives well in archaeological deposits) using log-transformed measurements (or allometry; relationships between dimensions are more likely exponential than linear). 
Of course multivariate regressions in most statistics packages (Minitab, SPSS, SAS) assume you are trying to predict one variable from all the others (a Model I regression), and use ordinary least squares to fit the regression line. For organismal dimensions this makes little sense, since all the dimensions are (at least in theory) free to change their mutual proportions during growth. So there is no predictor and predicted, mutual variation of</p><p>6 0.79067308 <a title="1656-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-26-How_to_understand_coefficients_that_reverse_sign_when_you_start_controlling_for_things%3F.html">1870 andrew gelman stats-2013-05-26-How to understand coefficients that reverse sign when you start controlling for things?</a></p>
<p>7 0.78606719 <a title="1656-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-04-Piss-poor_monocausal_social_science.html">1196 andrew gelman stats-2012-03-04-Piss-poor monocausal social science</a></p>
<p>8 0.77417475 <a title="1656-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-15-Still_more_Mr._P_in_public_health.html">770 andrew gelman stats-2011-06-15-Still more Mr. P in public health</a></p>
<p>9 0.76955098 <a title="1656-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-09-The_effects_of_fiscal_consolidation.html">1663 andrew gelman stats-2013-01-09-The effects of fiscal consolidation</a></p>
<p>10 0.76373267 <a title="1656-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-05-What_do_practitioners_need_to_know_about_regression%3F.html">451 andrew gelman stats-2010-12-05-What do practitioners need to know about regression?</a></p>
<p>11 0.75277847 <a title="1656-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-04-Question_about_standard_range_for_social_science_correlations.html">257 andrew gelman stats-2010-09-04-Question about standard range for social science correlations</a></p>
<p>12 0.73144758 <a title="1656-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-09-Keli_Liu_and_Xiao-Li_Meng_on_Simpson%E2%80%99s_paradox.html">2204 andrew gelman stats-2014-02-09-Keli Liu and Xiao-Li Meng on Simpson’s paradox</a></p>
<p>13 0.73065531 <a title="1656-lsi-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-20-Displaying_inferences_from_complex_models.html">1815 andrew gelman stats-2013-04-20-Displaying inferences from complex models</a></p>
<p>14 0.72466761 <a title="1656-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-19-Cross-validation_to_check_missing-data_imputation.html">1330 andrew gelman stats-2012-05-19-Cross-validation to check missing-data imputation</a></p>
<p>15 0.72103637 <a title="1656-lsi-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-16-Bayesian_analogue_to_stepwise_regression%3F.html">1535 andrew gelman stats-2012-10-16-Bayesian analogue to stepwise regression?</a></p>
<p>16 0.71753836 <a title="1656-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-03-is_it_possible_to_%E2%80%9Coverstratify%E2%80%9D_when_assigning_a_treatment_in_a_randomized_control_trial%3F.html">553 andrew gelman stats-2011-02-03-is it possible to “overstratify” when assigning a treatment in a randomized control trial?</a></p>
<p>17 0.71203494 <a title="1656-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-18-Standardizing_regression_inputs.html">1462 andrew gelman stats-2012-08-18-Standardizing regression inputs</a></p>
<p>18 0.7116673 <a title="1656-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-15-R-squared_for_multilevel_models.html">1121 andrew gelman stats-2012-01-15-R-squared for multilevel models</a></p>
<p>19 0.70668888 <a title="1656-lsi-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-02-Interaction-based_feature_selection_and_classification_for_high-dimensional_biological_data.html">1703 andrew gelman stats-2013-02-02-Interaction-based feature selection and classification for high-dimensional biological data</a></p>
<p>20 0.70543593 <a title="1656-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-05-01-Imputing_count_data.html">14 andrew gelman stats-2010-05-01-Imputing count data</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.02), (15, 0.02), (16, 0.117), (18, 0.014), (21, 0.031), (24, 0.13), (53, 0.015), (54, 0.096), (84, 0.016), (86, 0.036), (87, 0.014), (99, 0.371)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98527098 <a title="1656-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-08-Using_trends_in_R-squared_to_measure_progress_in_criminology%3F%3F.html">1889 andrew gelman stats-2013-06-08-Using trends in R-squared to measure progress in criminology??</a></p>
<p>Introduction: Torbjørn Skardhamar writes: 
  
  
I am a sociologist/criminologist working at Statistics Norway. As I am not a trained statistician, I find myself sometimes in need to check basic statistical concepts. Recently, I came across an article which I found a bit strange, but I needed to check up on my statistical understanding of a very basic concept: the r-squared. When doing so, I realized that this was also an interesting case of research ethics. Given your interest in research ethics, I though this might be interesting to you.


 Here’s  the mentioned article, by Weisburd and Piquero, is attached. What they do is to analyzed reported results from all articles published in the highest ranking criminological journal since 1968 through 2005 to determine whether there are any progress in the field of criminology. Their approach is basically to calculate the average r-square from linear models in published articles. For example, they state that “variance explained provides one way to assess</p><p>2 0.98109418 <a title="1656-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-20-When_Kerry_Met_Sally%3A_Politics_and_Perceptions_in_the_Demand_for_Movies.html">358 andrew gelman stats-2010-10-20-When Kerry Met Sally: Politics and Perceptions in the Demand for Movies</a></p>
<p>Introduction: Jason Roos sends along  this article :
  
On election days many of us see a colorful map of the U.S. where each tiny county has a color on the continuum between red and blue. So far we have not used such data to improve the effectiveness of marketing models. In this study, we show that we should.


We demonstrate the usefulness of political data via an interesting application–the demand for movies. Using boxoffice data from 25 counties in the U.S. Midwest (21 quarters between 2000 and 2005) we show that by including political data one can improve out-of-sample predictions significantly. Specifically, we estimate the improvement in forecasts due to the addition of political data to be around $43 million per year for the entire U.S. theatrical market.


Furthermore, when it comes to movies we depart from previous work in another way. While previous studies have relied on pre-determined movie genres, we estimate perceived movie attributes in a latent space and formulate viewers’ tastes as</p><p>same-blog 3 0.98000097 <a title="1656-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-05-Understanding_regression_models_and_regression_coefficients.html">1656 andrew gelman stats-2013-01-05-Understanding regression models and regression coefficients</a></p>
<p>Introduction: David Hoaglin writes:
  
After seeing it cited, I just read  your paper  in Technometrics.  The home radon levels provide an interesting and instructive example.


I [Hoaglin] have a different take on the difficulty of interpreting the estimated coefficient of the county-level basement proportion (gamma-sub-2) on page 434.  An important part of the difficulty involves “other things being equal.”  That sounds like the widespread interpretation of a regression coefficient as telling how the dependent variable responds to change in that predictor when the other predictors are held constant.  Unfortunately, as a general interpretation, that language is oversimplified; it doesn’t reflect how regression actually works.  The appropriate general interpretation is that the coefficient tells how the dependent variable responds to change in that predictor after allowing for simultaneous change in the other predictors in the data at hand.  Thus, in the county-level regression gamma-sub-2 summarize</p><p>4 0.97846472 <a title="1656-lda-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-16-Detecting_cheating_in_chess.html">1676 andrew gelman stats-2013-01-16-Detecting cheating in chess</a></p>
<p>Introduction: Three different people have pointed me to  this post  by Ken Regan on statistical evaluation of claims of cheating in chess.  So I figured I have to satisfy demand and post something on this.  But I have nothing to say.  All these topics interest me, but I somehow had difficulty reading through the entire post.  I scanned through but what I really wanted to see was some data.  Show me a scatterplot, then I’ll get interested.
 
P.S.  This is meant as no disparagement of Regan or his blog.  I just couldn’t quite get into this particular example.</p><p>5 0.97685379 <a title="1656-lda-5" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-17-SAT_stories.html">94 andrew gelman stats-2010-06-17-SAT stories</a></p>
<p>Introduction: I received a bunch of interesting comments on my  blog  on adjusting SAT scores.  Below I have a long comment from a colleague with experience in the field.
 
But first, this hilarious (from a statistical perspective) story from Howard Wainer:
  
Some years ago when we were visiting Harvard [as a parent of a potential student, not in Howard's role as educational researcher], an admissions director said two things of relevance (i) the SAT hasn’t got enough ‘top’ for Harvard — it doesn’t discriminate well enough at the high end. To prove this she said (ii) that Harvard had more than 1500 ‘perfect 1600s’ apply. Some were rejected. I mentioned that there were only about 750 1600s from HS seniors in the US — about 400 had 1600 in their junior year (and obviously didn’t retake) and about 350 from their senior year. So, I concluded, she must be mistaken.


Then I found out that they allowed applicants to pick and choose their highest SAT-V score and their highest SAT-M score from separate adm</p><p>6 0.97263962 <a title="1656-lda-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-26-The_quals_and_the_quants.html">1083 andrew gelman stats-2011-12-26-The quals and the quants</a></p>
<p>7 0.97103679 <a title="1656-lda-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-16-Chess_vs._checkers.html">615 andrew gelman stats-2011-03-16-Chess vs. checkers</a></p>
<p>8 0.9708581 <a title="1656-lda-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-08-Econ_debate_about_prices_at_a_fancy_restaurant.html">1105 andrew gelman stats-2012-01-08-Econ debate about prices at a fancy restaurant</a></p>
<p>9 0.96692777 <a title="1656-lda-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-13-A_must-read_paper_on_statistical_analysis_of_experimental_data.html">1721 andrew gelman stats-2013-02-13-A must-read paper on statistical analysis of experimental data</a></p>
<p>10 0.96673614 <a title="1656-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>11 0.96578729 <a title="1656-lda-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-27-A_whole_fleet_of_gremlins%3A__Looking_more_carefully_at_Richard_Tol%E2%80%99s_twice-corrected_paper%2C_%E2%80%9CThe_Economic_Effects_of_Climate_Change%E2%80%9D.html">2350 andrew gelman stats-2014-05-27-A whole fleet of gremlins:  Looking more carefully at Richard Tol’s twice-corrected paper, “The Economic Effects of Climate Change”</a></p>
<p>12 0.96552479 <a title="1656-lda-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-26-Philosophy_and_the_practice_of_Bayesian_statistics.html">110 andrew gelman stats-2010-06-26-Philosophy and the practice of Bayesian statistics</a></p>
<p>13 0.96524507 <a title="1656-lda-13" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-06-More_on_the_differences_between_drugs_and_medical_devices.html">322 andrew gelman stats-2010-10-06-More on the differences between drugs and medical devices</a></p>
<p>14 0.96518886 <a title="1656-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>15 0.96508121 <a title="1656-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-12-Meta-analysis%2C_game_theory%2C_and_incentives_to_do_replicable_research.html">1163 andrew gelman stats-2012-02-12-Meta-analysis, game theory, and incentives to do replicable research</a></p>
<p>16 0.96462119 <a title="1656-lda-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-14-Steven_Rhoads%E2%80%99s_book%2C_%E2%80%9CThe_Economist%E2%80%99s_View_of_the_World%E2%80%9D.html">711 andrew gelman stats-2011-05-14-Steven Rhoads’s book, “The Economist’s View of the World”</a></p>
<p>17 0.96380687 <a title="1656-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-18-Predictive_checks_for_hierarchical_models.html">154 andrew gelman stats-2010-07-18-Predictive checks for hierarchical models</a></p>
<p>18 0.96354502 <a title="1656-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-05-09-%E2%80%9CDiscovered%3A_the_genetic_secret_of_a_happy_life%E2%80%9D.html">702 andrew gelman stats-2011-05-09-“Discovered: the genetic secret of a happy life”</a></p>
<p>19 0.96342957 <a title="1656-lda-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-03-As_the_boldest_experiment_in_journalism_history%2C_you_admit_you_made_a_mistake.html">2280 andrew gelman stats-2014-04-03-As the boldest experiment in journalism history, you admit you made a mistake</a></p>
<p>20 0.96325642 <a title="1656-lda-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-20-Do_differences_between_biology_and_statistics_explain_some_of_our_diverging_attitudes_regarding_criticism_and_replication_of_scientific_claims%3F.html">2218 andrew gelman stats-2014-02-20-Do differences between biology and statistics explain some of our diverging attitudes regarding criticism and replication of scientific claims?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
