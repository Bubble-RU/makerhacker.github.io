<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>2136 andrew gelman stats-2013-12-16-Whither the “bet on sparsity principle” in a nonsparse world?</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-2136" href="#">andrew_gelman_stats-2013-2136</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>2136 andrew gelman stats-2013-12-16-Whither the “bet on sparsity principle” in a nonsparse world?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-2136-html" href="http://andrewgelman.com/2013/12/16/whither-the-bet-on-sparsity-principle-in-a-nonsparse-world/">html</a></p><p>Introduction: Rob Tibshirani  writes :
  
Hastie et al. (2001) coined the informal “Bet on Sparsity” principle. The l1 methods assume that the truth is sparse, in some basis. If the assumption holds true, then the parameters can be efficiently estimated using l1 penalties. If the assumption does not hold—so that the truth is dense—then no method will be able to recover the underlying model without a large amount of data per parameter.
  
I’ve earlier  expressed  my full and sincere appreciation for Hastie and Tibshirani’s work in this area.
 
Now I’d like to briefly comment on the above snippet.  The question is, how do we think about the “bet on sparsity” principle in a world where the truth  is  dense?  I’m thinking here of social science, where no effects are clean and no coefficient is zero (see page 960 of  this article  or various blog discussions in the past few years), where every contrast is meaningful—but some of these contrasts might be lost in the noise with any realistic size of data.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The l1 methods assume that the truth is sparse, in some basis. [sent-3, score-0.245]
</p><p>2 If the assumption holds true, then the parameters can be efficiently estimated using l1 penalties. [sent-4, score-0.269]
</p><p>3 If the assumption does not hold—so that the truth is dense—then no method will be able to recover the underlying model without a large amount of data per parameter. [sent-5, score-0.827]
</p><p>4 I’ve earlier  expressed  my full and sincere appreciation for Hastie and Tibshirani’s work in this area. [sent-6, score-0.244]
</p><p>5 Now I’d like to briefly comment on the above snippet. [sent-7, score-0.068]
</p><p>6 The question is, how do we think about the “bet on sparsity” principle in a world where the truth  is  dense? [sent-8, score-0.24]
</p><p>7 I’m thinking here of social science, where no effects are clean and no coefficient is zero (see page 960 of  this article  or various blog discussions in the past few years), where every contrast is meaningful—but some of these contrasts might be lost in the noise with any realistic size of data. [sent-9, score-0.422]
</p><p>8 I think there is a way out here, which is that in a dense setting we are not actually interested in “recovering the underlying model. [sent-10, score-0.524]
</p><p>9 ”  The underlying model, such as it is, is a continuous mix of effects. [sent-11, score-0.277]
</p><p>10 If there’s no discrete thing to recover, there’s no reason to worry that we can’t recover it! [sent-12, score-0.325]
</p><p>11 I’m sure things are different in a field such as chemistry, where you can try to identify the key compounds that make up some substance. [sent-13, score-0.174]
</p><p>12 The above quote and link come from Rob’s chapter, “In praise of sparsity and convexity,” in the Committee of Presidents of Statistical Societies volume. [sent-16, score-0.473]
</p><p>13 My chapter, “How do we choose our default methods? [sent-17, score-0.06]
</p><p>14 I do think it can often make sense to consider the decision-analytic reasons why it can make sense to go for sparsity:  sparse models can be faster to compute, easier to understand, and yield more stable inferences. [sent-22, score-0.742]
</p><p>15 (Sometimes people say that a sparse model is less likely to overfit but I don’t think that’s quite right, as you can also get rid of overfitting by using a strong regularizer. [sent-23, score-0.669]
</p><p>16 But I think it is fair to say that a sparse model can yield more stable inferences, in that the inferences for the more complex model can be sensitive to the details of the regularizer or the prior distribution. [sent-24, score-1.085]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sparsity', 0.383), ('sparse', 0.321), ('dense', 0.304), ('recover', 0.261), ('hastie', 0.187), ('truth', 0.177), ('tibshirani', 0.174), ('rob', 0.171), ('underlying', 0.157), ('stable', 0.147), ('bet', 0.141), ('yield', 0.139), ('assumption', 0.117), ('compounds', 0.116), ('model', 0.115), ('inferences', 0.113), ('recovering', 0.105), ('coined', 0.105), ('chapter', 0.098), ('contrasts', 0.096), ('appreciation', 0.094), ('praise', 0.09), ('overfitting', 0.09), ('sincere', 0.086), ('presidents', 0.086), ('societies', 0.084), ('chemistry', 0.084), ('efficiently', 0.081), ('committee', 0.08), ('rid', 0.08), ('informal', 0.076), ('realistic', 0.075), ('sensitive', 0.072), ('faster', 0.072), ('meaningful', 0.071), ('holds', 0.071), ('briefly', 0.068), ('methods', 0.068), ('compute', 0.065), ('discrete', 0.064), ('noise', 0.064), ('expressed', 0.064), ('think', 0.063), ('clean', 0.063), ('coefficient', 0.062), ('lost', 0.062), ('mix', 0.061), ('default', 0.06), ('continuous', 0.059), ('identify', 0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="2136-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-16-Whither_the_%E2%80%9Cbet_on_sparsity_principle%E2%80%9D_in_a_nonsparse_world%3F.html">2136 andrew gelman stats-2013-12-16-Whither the “bet on sparsity principle” in a nonsparse world?</a></p>
<p>Introduction: Rob Tibshirani  writes :
  
Hastie et al. (2001) coined the informal “Bet on Sparsity” principle. The l1 methods assume that the truth is sparse, in some basis. If the assumption holds true, then the parameters can be efficiently estimated using l1 penalties. If the assumption does not hold—so that the truth is dense—then no method will be able to recover the underlying model without a large amount of data per parameter.
  
I’ve earlier  expressed  my full and sincere appreciation for Hastie and Tibshirani’s work in this area.
 
Now I’d like to briefly comment on the above snippet.  The question is, how do we think about the “bet on sparsity” principle in a world where the truth  is  dense?  I’m thinking here of social science, where no effects are clean and no coefficient is zero (see page 960 of  this article  or various blog discussions in the past few years), where every contrast is meaningful—but some of these contrasts might be lost in the noise with any realistic size of data.</p><p>2 0.43940607 <a title="2136-tfidf-2" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-25-Xihong_Lin_on_sparsity_and_density.html">2185 andrew gelman stats-2014-01-25-Xihong Lin on sparsity and density</a></p>
<p>Introduction: I pointed Xihong Lin to  this post  from last month regarding Hastie and Tibshirani’s “bet on sparsity principle.”  I argued that, in the worlds in which I work, in social and environmental science, every contrast is meaningful, even if not all of them can be distinguished from noise given a particular dataset.  That is, I claim that effects are dense but data can be sparse—and any apparent sparsity of effects is typically just an artifact of sparsity of data.
 
But things might be different in other fields.  Xihong had an interesting perspective in the application areas where she works:
  
Sparsity and density both appear in genetic studies too. For example, ethnicity has effects across millions of genetic variants across the genome (dense). Disease associated genetic variants are sparse.</p><p>3 0.17912871 <a title="2136-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-04-Honored_oldsters_write_about_statistics.html">2317 andrew gelman stats-2014-05-04-Honored oldsters write about statistics</a></p>
<p>Introduction: The new book titled: Past, Present, and Future of Statistical Science is now  available for download .
 
The official description makes the book sound pretty stuffy:
  
Past, Present, and Future of Statistical Science, commissioned by the Committee of Presidents of Statistical Societies (COPSS) to celebrate its 50th anniversary and the International Year of Statistics, will be published in April by Taylor & Francis/CRC Press. Through the contributions of a distinguished group of 50 statisticians, the book showcases the breadth and vibrancy of statistics, describes current challenges and new opportunities, highlights the exciting future of statistical science, and provides guidance for future statisticians. Contributors are past COPSS award honorees.
  
But it actually has lots of good stuff, including the chapter by Tibshirani which I  discussed  last year (in the context of the “bet on sparsity principle”), and chapters by XL and other fun people.  Also my own chapter,  How do we choo</p><p>4 0.14966367 <a title="2136-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-21-Hidden_dangers_of_noninformative_priors.html">2109 andrew gelman stats-2013-11-21-Hidden dangers of noninformative priors</a></p>
<p>Introduction: Following up on Christian’s  post  [link fixed] on the topic, I’d like to offer a few thoughts of my own.
 
In BDA, we express the idea that a noninformative prior is a placeholder:  you can use the noninformative prior to get the analysis started, then if your posterior distribution is less informative than you would like, or if it does not make sense, you can go back and add prior information.
 
Same thing for the data model (the “likelihood”), for that matter:  it often makes sense to start with something simple and conventional and then go from there.
 
So, in that sense, noninformative priors are no big deal, they’re just a way to get started.  Just don’t take them too seriously.
 
Traditionally in statistics we’ve worked with the paradigm of a single highly informative dataset with only weak external information.  But if the data are sparse and prior information is strong, we have to think differently.  And, when you increase the dimensionality of a problem, both these things hap</p><p>5 0.14289251 <a title="2136-tfidf-5" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-18-Tibshirani_announces_new_research_result%3A__A_significance_test_for_the_lasso.html">1769 andrew gelman stats-2013-03-18-Tibshirani announces new research result:  A significance test for the lasso</a></p>
<p>Introduction: Lasso and me 
 
For a long time I was wrong about lasso.
 
Lasso (“least absolute shrinkage and selection operator”) is a regularization procedure that shrinks regression coefficients toward zero, and in its basic form is equivalent to maximum penalized likelihood estimation with a penalty function that is proportional to the sum of the absolute values of the regression coefficients.
 
I first heard about lasso from a talk that  Trevor Hastie  Rob Tibshirani gave at Berkeley in 1994 or 1995.  He demonstrated that it shrunk regression coefficients to zero.  I wasn’t impressed, first because it seemed like no big deal (if that’s the prior you use, that’s the shrinkage you get) and second because, from a Bayesian perspective, I don’t  want  to shrink things all the way to zero.  In the sorts of social and environmental science problems I’ve worked on, just about nothing is zero.  I’d like to control my noisy estimates but there’s nothing special about zero.  At the end of the talk I stood</p><p>6 0.14021757 <a title="2136-tfidf-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-14-I_hate_to_get_all_Gerd_Gigerenzer_on_you_here%2C_but_._._..html">1319 andrew gelman stats-2012-05-14-I hate to get all Gerd Gigerenzer on you here, but . . .</a></p>
<p>7 0.11714284 <a title="2136-tfidf-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>8 0.10964648 <a title="2136-tfidf-8" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-07-There_are_never_70_distinct_parameters.html">327 andrew gelman stats-2010-10-07-There are never 70 distinct parameters</a></p>
<p>9 0.10543533 <a title="2136-tfidf-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-07-When_you%E2%80%99re_planning_on_fitting_a_model%2C_build_up_to_it_by_fitting_simpler_models_first.__Then%2C_once_you_have_a_model_you_like%2C_check_the_hell_out_of_it.html">1972 andrew gelman stats-2013-08-07-When you’re planning on fitting a model, build up to it by fitting simpler models first.  Then, once you have a model you like, check the hell out of it</a></p>
<p>10 0.10143348 <a title="2136-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>11 0.1002717 <a title="2136-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-30-Infill_asymptotics_and_sprawl_asymptotics.html">1877 andrew gelman stats-2013-05-30-Infill asymptotics and sprawl asymptotics</a></p>
<p>12 0.095931247 <a title="2136-tfidf-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>13 0.095615335 <a title="2136-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-19-Prior_distributions_on_derived_quantities_rather_than_on_parameters_themselves.html">1946 andrew gelman stats-2013-07-19-Prior distributions on derived quantities rather than on parameters themselves</a></p>
<p>14 0.09428861 <a title="2136-tfidf-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-27-Uncompressing_the_concept_of_compressed_sensing.html">2079 andrew gelman stats-2013-10-27-Uncompressing the concept of compressed sensing</a></p>
<p>15 0.09405455 <a title="2136-tfidf-15" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-28-The_holes_in_my_philosophy_of_Bayesian_data_analysis.html">781 andrew gelman stats-2011-06-28-The holes in my philosophy of Bayesian data analysis</a></p>
<p>16 0.091720946 <a title="2136-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>17 0.090955287 <a title="2136-tfidf-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-10-Creating_a_good_wager_based_on_probability_estimates.html">138 andrew gelman stats-2010-07-10-Creating a good wager based on probability estimates</a></p>
<p>18 0.088569812 <a title="2136-tfidf-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-27-Overfitting.html">1431 andrew gelman stats-2012-07-27-Overfitting</a></p>
<p>19 0.088067219 <a title="2136-tfidf-19" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-19-The_%E2%80%9Ceither-or%E2%80%9D_fallacy_of_believing_in_discrete_models%3A__an_example_of_folk_statistics.html">217 andrew gelman stats-2010-08-19-The “either-or” fallacy of believing in discrete models:  an example of folk statistics</a></p>
<p>20 0.085469194 <a title="2136-tfidf-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-13-Flexibility_is_good.html">2133 andrew gelman stats-2013-12-13-Flexibility is good</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.165), (1, 0.087), (2, 0.002), (3, 0.019), (4, -0.016), (5, -0.017), (6, 0.008), (7, -0.01), (8, 0.037), (9, 0.035), (10, -0.016), (11, 0.015), (12, -0.006), (13, -0.02), (14, -0.042), (15, 0.011), (16, -0.006), (17, -0.005), (18, -0.031), (19, 0.014), (20, -0.005), (21, -0.069), (22, -0.026), (23, 0.01), (24, 0.018), (25, 0.021), (26, 0.015), (27, 0.024), (28, 0.022), (29, -0.014), (30, -0.028), (31, 0.015), (32, -0.01), (33, -0.025), (34, 0.056), (35, 0.003), (36, 0.023), (37, -0.032), (38, 0.017), (39, -0.008), (40, 0.012), (41, 0.018), (42, 0.023), (43, -0.002), (44, 0.009), (45, -0.036), (46, -0.047), (47, 0.025), (48, -0.032), (49, 0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95529389 <a title="2136-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-16-Whither_the_%E2%80%9Cbet_on_sparsity_principle%E2%80%9D_in_a_nonsparse_world%3F.html">2136 andrew gelman stats-2013-12-16-Whither the “bet on sparsity principle” in a nonsparse world?</a></p>
<p>Introduction: Rob Tibshirani  writes :
  
Hastie et al. (2001) coined the informal “Bet on Sparsity” principle. The l1 methods assume that the truth is sparse, in some basis. If the assumption holds true, then the parameters can be efficiently estimated using l1 penalties. If the assumption does not hold—so that the truth is dense—then no method will be able to recover the underlying model without a large amount of data per parameter.
  
I’ve earlier  expressed  my full and sincere appreciation for Hastie and Tibshirani’s work in this area.
 
Now I’d like to briefly comment on the above snippet.  The question is, how do we think about the “bet on sparsity” principle in a world where the truth  is  dense?  I’m thinking here of social science, where no effects are clean and no coefficient is zero (see page 960 of  this article  or various blog discussions in the past few years), where every contrast is meaningful—but some of these contrasts might be lost in the noise with any realistic size of data.</p><p>2 0.78813106 <a title="2136-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-15-More_on_AIC%2C_WAIC%2C_etc.html">1983 andrew gelman stats-2013-08-15-More on AIC, WAIC, etc</a></p>
<p>Introduction: Following up on our  discussion  from the other day, Angelika van der Linde sends along  this paper  from 2012 (link to journal  here ).
 
And Aki pulls out this great quote from Geisser and Eddy (1979):
  
This discussion makes clear that in the nested case this method, as Akaike’s, is not consistent; i.e., even if $M_k$ is true, it will be rejected with probability $\alpha$ as $N\to\infty$. This point is also made by Schwarz (1978).  However, from the point of view of prediction, this is of no great consequence. For large numbers of observations, a prediction based on the falsely assumed $M_k$, will not differ appreciably from one based on the true $M_k$.  For example, if we assert that two normal populations have different means when in fact they have the same mean, then the use of the group mean as opposed to the grand mean for predicting a future observation results in predictors which are asymptotically equivalent and whose predictive variances are $\sigma^2[1 + (1/2n)]$ and $\si</p><p>3 0.7589308 <a title="2136-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-26-Occam.html">1392 andrew gelman stats-2012-06-26-Occam</a></p>
<p>Introduction: Cosma Shalizi  and  Larry Wasserman  discuss some papers from a conference on Ockham’s Razor.  I don’t have anything new to add on this so let me link to  past blog entries  on the topic and repost the following  from 2004 :
  
A lot has been written in statistics about “parsimony”—that is, the desire to explain phenomena using fewer parameters–but I’ve never seen any good general justification for parsimony.  (I don’t count “Occam’s Razor,” or “Ockham’s Razor,” or whatever, as a justification.  You gotta do better than digging up a 700-year-old quote.)


Maybe it’s because I work in social science, but my feeling is:  if you can approximate reality with just a few parameters, fine.  If you can use more parameters to fold in more information, that’s even better.


In practice, I often use simple models—because they are less effort to fit and, especially, to understand.  But I don’t kid myself that they’re better than more complicated efforts!


My favorite quote on this comes from  Rad</p><p>4 0.74833721 <a title="2136-lsi-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-27-Cross-validation_%28What_is_it_good_for%3F%29.html">1395 andrew gelman stats-2012-06-27-Cross-validation (What is it good for?)</a></p>
<p>Introduction: I think cross-validation is a good way to estimate a model’s forecasting error but I don’t think it’s always such a great tool for comparing models.  I mean, sure, if the differences are dramatic, ok.  But you can easily have a few candidate models, and one model makes a lot more sense than the others (even from a purely predictive sense, I’m not talking about causality here).  The difference between the model doesn’t show up in a xval measure of total error but in the patterns of the predictions.
 
For a simple example, imagine using a linear model with positive slope to model a function that is constrained to be increasing.  If the constraint isn’t in the model, the predicted/imputed series will sometimes be nonmonotonic.  The effect on the prediction error can be so tiny as to be undetectable (or it might even increase avg prediction error to include the constraint); nonetheless, the predictions will be clearly nonsensical.
 
That’s an extreme example but I think the general point h</p><p>5 0.74582398 <a title="2136-lsi-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-09-Difficulties_with_Bayesian_model_averaging.html">754 andrew gelman stats-2011-06-09-Difficulties with Bayesian model averaging</a></p>
<p>Introduction: In response to  this article  by Cosma Shalizi and myself on the philosophy of Bayesian statistics, David Hogg writes:
  
I [Hogg] agree–even in physics and astronomy–that the models are not “True” in the God-like sense of being absolute reality (that is, I am not a realist); and I  have argued  (a philosophically very naive 
paper, but hey, I was new to all this) that for pretty fundamental reasons we could never arrive at the True (with a capital “T”) model of the Universe.  The goal of inference is to find the “best” model, where “best” might have something to do with prediction, or explanation, or message length, or (horror!) our utility.  Needless to say, most of my physics friends *are* realists, even in the face of “effective theories” as Newtonian mechanics is an effective theory of GR and GR is an effective theory of “quantum gravity” (this plays to your point, because if you think any theory is possibly an effective theory, how could you ever find Truth?).  I also liked the i</p><p>6 0.74510968 <a title="2136-lsi-6" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-10-More_questions_on_the_contagion_of_obesity%2C_height%2C_etc..html">1412 andrew gelman stats-2012-07-10-More questions on the contagion of obesity, height, etc.</a></p>
<p>7 0.73987985 <a title="2136-lsi-7" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>8 0.73422164 <a title="2136-lsi-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-03-Model_Makers%E2%80%99_Hippocratic_Oath.html">552 andrew gelman stats-2011-02-03-Model Makers’ Hippocratic Oath</a></p>
<p>9 0.73348832 <a title="2136-lsi-9" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>10 0.7304436 <a title="2136-lsi-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-19-The_%E2%80%9Ceither-or%E2%80%9D_fallacy_of_believing_in_discrete_models%3A__an_example_of_folk_statistics.html">217 andrew gelman stats-2010-08-19-The “either-or” fallacy of believing in discrete models:  an example of folk statistics</a></p>
<p>11 0.72913378 <a title="2136-lsi-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-27-What_is_%E2%80%9Cexplanation%E2%80%9D%3F.html">1742 andrew gelman stats-2013-02-27-What is “explanation”?</a></p>
<p>12 0.72421068 <a title="2136-lsi-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-02-Fighting_a_losing_battle.html">1518 andrew gelman stats-2012-10-02-Fighting a losing battle</a></p>
<p>13 0.7168119 <a title="2136-lsi-13" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-22-Deviance%2C_DIC%2C_AIC%2C_cross-validation%2C_etc.html">776 andrew gelman stats-2011-06-22-Deviance, DIC, AIC, cross-validation, etc</a></p>
<p>14 0.71484005 <a title="2136-lsi-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>15 0.71472317 <a title="2136-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-19-Just_chaid.html">421 andrew gelman stats-2010-11-19-Just chaid</a></p>
<p>16 0.71283448 <a title="2136-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-01-Tukey%E2%80%99s_philosophy.html">496 andrew gelman stats-2011-01-01-Tukey’s philosophy</a></p>
<p>17 0.71275383 <a title="2136-lsi-17" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-15-Induction_within_a_model%2C_deductive_inference_for_model_evaluation.html">614 andrew gelman stats-2011-03-15-Induction within a model, deductive inference for model evaluation</a></p>
<p>18 0.70559591 <a title="2136-lsi-18" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-15-How_I_think_about_mixture_models.html">1459 andrew gelman stats-2012-08-15-How I think about mixture models</a></p>
<p>19 0.70473754 <a title="2136-lsi-19" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-12-How_to_think_about_%E2%80%9Cidentifiability%E2%80%9D_in_Bayesian_inference%3F.html">2208 andrew gelman stats-2014-02-12-How to think about “identifiability” in Bayesian inference?</a></p>
<p>20 0.69983292 <a title="2136-lsi-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.046), (16, 0.04), (17, 0.059), (18, 0.048), (21, 0.078), (24, 0.152), (31, 0.012), (53, 0.019), (68, 0.033), (70, 0.012), (84, 0.052), (87, 0.037), (95, 0.044), (99, 0.265)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96921968 <a title="2136-lda-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-16-Whither_the_%E2%80%9Cbet_on_sparsity_principle%E2%80%9D_in_a_nonsparse_world%3F.html">2136 andrew gelman stats-2013-12-16-Whither the “bet on sparsity principle” in a nonsparse world?</a></p>
<p>Introduction: Rob Tibshirani  writes :
  
Hastie et al. (2001) coined the informal “Bet on Sparsity” principle. The l1 methods assume that the truth is sparse, in some basis. If the assumption holds true, then the parameters can be efficiently estimated using l1 penalties. If the assumption does not hold—so that the truth is dense—then no method will be able to recover the underlying model without a large amount of data per parameter.
  
I’ve earlier  expressed  my full and sincere appreciation for Hastie and Tibshirani’s work in this area.
 
Now I’d like to briefly comment on the above snippet.  The question is, how do we think about the “bet on sparsity” principle in a world where the truth  is  dense?  I’m thinking here of social science, where no effects are clean and no coefficient is zero (see page 960 of  this article  or various blog discussions in the past few years), where every contrast is meaningful—but some of these contrasts might be lost in the noise with any realistic size of data.</p><p>2 0.93609542 <a title="2136-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-25-An_interesting_but_flawed_attempt_to_apply_general_forecasting_principles_to_contextualize_attitudes_toward_risks_of_global_warming.html">2112 andrew gelman stats-2013-11-25-An interesting but flawed attempt to apply general forecasting principles to contextualize attitudes toward risks of global warming</a></p>
<p>Introduction: I came across  a document  [updated link  here ], “Applying structured analogies to the global warming alarm movement,” by Kesten Green and Scott Armstrong.  The general approach is appealing to me, but the execution seemed disturbingly flawed.
 
Here’s how they introduce the project:
  
The structured analogies procedure we [Green and Armstrong] used for this study was as follows:


1. Identify possible analogies by searching the literature and by asking experts with different viewpoints to nominate analogies to the target situation: alarm over dangerous manmade global warming. 
2. Screen the possible analogies to ensure they meet the stated criteria and that the outcomes are known. 
3. Code the relevant characteristics of the analogous situations. 
4. Forecast target situation outcomes by using a predetermined mechanical rule to select the outcomes of the analogies. 
Here is how we posed the question to the experts:

 
The Intergovernmental Panel on Climate Change and other organizat</p><p>3 0.93205923 <a title="2136-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-25-Classical_probability_does_not_apply_to_quantum_systems_%28causal_inference_edition%29.html">2037 andrew gelman stats-2013-09-25-Classical probability does not apply to quantum systems (causal inference edition)</a></p>
<p>Introduction: James Robins, Tyler VanderWeele, and Richard Gill  write :
  
Neyman introduced a formal mathematical theory of counterfactual causation that now has become standard language in many quantitative disciplines, but not in physics. We use results on causal interaction and interference between treatments (derived under the Neyman theory) to give a simple new proof of a well-known result in quantum physics, namely, Bellís inequality.


Now the predictions of quantum mechanics and the results of experiment both violate Bell’s inequality. In the remainder of the talk, we review the implications for a counterfactual theory of causation. Assuming with Einstein that faster than light (supraluminal) communication is not possible, one can view the Neyman theory of counterfactuals as falsified by experiment. . . .


Is it safe for a quantitative discipline to rely on a counterfactual approach to causation, when our best confirmed physical theory falsifies their existence?
  
I haven’t seen the talk</p><p>4 0.93112195 <a title="2136-lda-4" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-15-How_I_think_about_mixture_models.html">1459 andrew gelman stats-2012-08-15-How I think about mixture models</a></p>
<p>Introduction: Larry Wasserman  refers  to finite mixture models as “beasts” and  writes  jokes that they “should be avoided at all costs.”
 
I’ve thought a lot about mixture models, ever since using them in an  analysis  of voting patterns that was published in 1990.  First off, I’d like to say that our model was useful so I’d prefer not to pay the cost of avoiding it.  For a quick description of our mixture model and its context, see pp. 379-380 of my  article  in the Jim Berger volume).  Actually, our case was particularly difficult because we were not even fitting a mixture model to data, we were fitting it to latent data and using the model to perform partial pooling.  My difficulties in trying to fit this model inspired our discussion of mixture models in Bayesian Data Analysis (page 109 in the second edition, in the section on “Counterexamples to the theorems”).
 
I agree with Larry that if you’re fitting a mixture model, it’s good to be aware of the problems that arise if you try to estimate</p><p>5 0.92816097 <a title="2136-lda-5" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Adding_more_information_can_make_the_variance_go_up_%28depending_on_your_model%29.html">810 andrew gelman stats-2011-07-20-Adding more information can make the variance go up (depending on your model)</a></p>
<p>Introduction: Andy McKenzie writes:
  
In their March 9 “ counterpoint ” in nature biotech to the prospect that we should try to integrate more sources of data in clinical practice (see “ point ” arguing for this), Isaac Kohane and David Margulies claim that,


“Finally, how much better is our new knowledge than older knowledge? When is the incremental benefit of a genomic variant(s) or gene expression profile relative to a family history or classic histopathology insufficient and when does it add rather than subtract variance?”  


Perhaps I am mistaken (thus this email), but it seems that this claim runs contra to the definition of conditional probability. That is, if you have a hierarchical model, and the family history / classical histopathology already suggests a parameter estimate with some variance, how could the new genomic info possibly increase the variance of that parameter estimate? Surely the question is how much variance the new genomic info reduces and whether it therefore justifies t</p><p>6 0.92610395 <a title="2136-lda-6" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-12-26-Age_and_happiness%3A__The_pattern_isn%E2%80%99t_as_clear_as_you_might_think.html">486 andrew gelman stats-2010-12-26-Age and happiness:  The pattern isn’t as clear as you might think</a></p>
<p>7 0.9259581 <a title="2136-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-23-Fight%21__%28also_a_bit_of_reminiscence_at_the_end%29.html">1136 andrew gelman stats-2012-01-23-Fight!  (also a bit of reminiscence at the end)</a></p>
<p>8 0.92569989 <a title="2136-lda-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-04-%E2%80%9CDogs_are_sensitive_to_small_variations_of_the_Earth%E2%80%99s_magnetic_field%E2%80%9D.html">2159 andrew gelman stats-2014-01-04-“Dogs are sensitive to small variations of the Earth’s magnetic field”</a></p>
<p>9 0.92550719 <a title="2136-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-13-News_coverage_of_statistical_issues%E2%80%A6how_did_I_do%3F.html">514 andrew gelman stats-2011-01-13-News coverage of statistical issues…how did I do?</a></p>
<p>10 0.92550701 <a title="2136-lda-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-11-11-Why_ask_why%3F_Forward_causal_inference_and_reverse_causal_questions.html">2097 andrew gelman stats-2013-11-11-Why ask why? Forward causal inference and reverse causal questions</a></p>
<p>11 0.92495292 <a title="2136-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-26-Further_thoughts_on_nonparametric_correlation_measures.html">1230 andrew gelman stats-2012-03-26-Further thoughts on nonparametric correlation measures</a></p>
<p>12 0.92480552 <a title="2136-lda-12" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-07-Descriptive_statistics%2C_causal_inference%2C_and_story_time.html">789 andrew gelman stats-2011-07-07-Descriptive statistics, causal inference, and story time</a></p>
<p>13 0.92463648 <a title="2136-lda-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-20-Likelihood_thresholds_and_decisions.html">1422 andrew gelman stats-2012-07-20-Likelihood thresholds and decisions</a></p>
<p>14 0.92308629 <a title="2136-lda-14" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-15-Quote_of_the_day%3A__statisticians_and_defaults.html">147 andrew gelman stats-2010-07-15-Quote of the day:  statisticians and defaults</a></p>
<p>15 0.92222714 <a title="2136-lda-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-06-19-Further_thoughts_on_happiness_and_life_satisfaction_research.html">98 andrew gelman stats-2010-06-19-Further thoughts on happiness and life satisfaction research</a></p>
<p>16 0.92202735 <a title="2136-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-30-Infill_asymptotics_and_sprawl_asymptotics.html">1877 andrew gelman stats-2013-05-30-Infill asymptotics and sprawl asymptotics</a></p>
<p>17 0.92158198 <a title="2136-lda-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-04-Interrogating_p-values.html">1883 andrew gelman stats-2013-06-04-Interrogating p-values</a></p>
<p>18 0.92091501 <a title="2136-lda-18" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-04-20-Attractive_but_hard-to-read_graph_could_be_made_much_much_better.html">670 andrew gelman stats-2011-04-20-Attractive but hard-to-read graph could be made much much better</a></p>
<p>19 0.92063975 <a title="2136-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-04-What_are_the_key_assumptions_of_linear_regression%3F.html">1967 andrew gelman stats-2013-08-04-What are the key assumptions of linear regression?</a></p>
<p>20 0.92010069 <a title="2136-lda-20" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-21-Chasing_the_noise.html">2142 andrew gelman stats-2013-12-21-Chasing the noise</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
