<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1683 andrew gelman stats-2013-01-19-“Confirmation, on the other hand, is not sexy”</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1683" href="#">andrew_gelman_stats-2013-1683</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1683 andrew gelman stats-2013-01-19-“Confirmation, on the other hand, is not sexy”</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1683-html" href="http://andrewgelman.com/2013/01/19/confirmation-on-the-other-hand-is-not-sexy/">html</a></p><p>Introduction: Mark Palko  writes :
  
I can understand the appeal of the cutting edge. The new stuff is sexier. It gets people’s attention. The trouble is, those cutting edge studies often collapse under scrutiny. Some can’t be replicated. Others prove to be not that important.


Confirmation, on the other hand, is not sexy. It doesn’t drive traffic. It’s harder to fit into a paragraph. In a way, though, it’s more interesting because it has a high likelihood of being true and fills in the gaps in big, important questions. The interaction between the ideas is usually the interesting part.
  
In this particular example, Palko is telling the story of a journalist who reports a finding as new when it is essentially a replication of decades-old work.  Palko’s point is not that there’s anything wrong with replication but rather that the journalist seems to feel that it is necessary to report the idea as new and cutting-edge, even if it falls within a long tradition.  (Also, Palko is not claiming that this</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Mark Palko  writes :    I can understand the appeal of the cutting edge. [sent-1, score-0.138]
</p><p>2 The trouble is, those cutting edge studies often collapse under scrutiny. [sent-4, score-0.414]
</p><p>3 In a way, though, it’s more interesting because it has a high likelihood of being true and fills in the gaps in big, important questions. [sent-10, score-0.165]
</p><p>4 In this particular example, Palko is telling the story of a journalist who reports a finding as new when it is essentially a replication of decades-old work. [sent-12, score-0.355]
</p><p>5 Palko’s point is not that there’s anything wrong with replication but rather that the journalist seems to feel that it is necessary to report the idea as new and cutting-edge, even if it falls within a long tradition. [sent-13, score-0.424]
</p><p>6 )   Palko’s observations fit into a topic that’s been coming up a lot in this blog (as well as in statistical discussions more generally) in recent years:   To review:   - Lots of iffy studies are published every year in psychology, medicine, biology etc. [sent-15, score-0.221]
</p><p>7 For reasons explained by Uri Simohnson and others, it’s possible to get tons of publishable (i. [sent-16, score-0.153]
</p><p>8 - It would be great if studies were routinely replicated. [sent-20, score-0.26]
</p><p>9 In medicine there are ethical concerns, but in biolab or psychology experiments, why not? [sent-21, score-0.187]
</p><p>10 What if first- and second-year grad students in these fields were routinely required to conduct replications of well-known findings? [sent-22, score-0.244]
</p><p>11 There are lots of grad students out there, and we’d soon get a big N on all these questionable claims—at least those that can be evaluated by collecting new data in the lab. [sent-23, score-0.369]
</p><p>12 (We also need to ditch the system where people are expected to anonymously review papers for free, but that’s not such a big deal. [sent-27, score-0.5]
</p><p>13 We could pay reviewers (using the money that otherwise would go to the executives at Springer etc) and also move to an open post-publication review system (that is, the journal looks something like a blog, in that there’s a space to comment on any article). [sent-28, score-0.496]
</p><p>14 Paying reviewers might sound expensive, but peer review is part of the scientific process. [sent-29, score-0.345]
</p><p>15 Journalists like to report “man bites dog” not “dog bites man,” but when you look into some of those “man bites dog” stories they’re not actually true. [sent-32, score-0.909]
</p><p>16 - Everybody’s talking about the problem of false claims in the scientific literature. [sent-34, score-0.183]
</p><p>17 Back then, we thought of publication bias as a minor nuisance, but now we see it as part of a big picture of the breakdown of the culture of science. [sent-36, score-0.367]
</p><p>18 - I think statistics needs to move beyond the paradigm of analyzing studies or datasets one at a time. [sent-37, score-0.217]
</p><p>19 Fisher, I’m guessing that back in the day at Rothamsted Experimental Station or the experimental farm in Ames, Iowa, that each experiment was part of a long thread of trial and error (perhaps Steve Stigler can supply more details on this). [sent-40, score-0.355]
</p><p>20 But somewhere along the way came the idea that each little experiment was supposed to come in a box, nicely tied up and statistically significant. [sent-41, score-0.248]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('palko', 0.282), ('bites', 0.28), ('dog', 0.239), ('replication', 0.169), ('man', 0.153), ('review', 0.147), ('cutting', 0.138), ('confirmation', 0.138), ('studies', 0.135), ('routinely', 0.125), ('grad', 0.119), ('reviewers', 0.118), ('paying', 0.118), ('journalist', 0.115), ('medicine', 0.111), ('claims', 0.11), ('big', 0.105), ('springer', 0.099), ('picture', 0.098), ('farm', 0.093), ('stigler', 0.093), ('experimental', 0.092), ('experiment', 0.09), ('anonymously', 0.089), ('fills', 0.089), ('iffy', 0.086), ('iowa', 0.086), ('ditch', 0.084), ('newly', 0.084), ('sexy', 0.084), ('nuisance', 0.084), ('breakdown', 0.084), ('publishable', 0.084), ('move', 0.082), ('statistically', 0.082), ('part', 0.08), ('station', 0.078), ('gaps', 0.076), ('nicely', 0.076), ('psychology', 0.076), ('system', 0.075), ('executives', 0.074), ('questionable', 0.074), ('talking', 0.073), ('new', 0.071), ('edge', 0.071), ('collapse', 0.07), ('report', 0.069), ('tons', 0.069), ('resolution', 0.068)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="1683-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-%E2%80%9CConfirmation%2C_on_the_other_hand%2C_is_not_sexy%E2%80%9D.html">1683 andrew gelman stats-2013-01-19-“Confirmation, on the other hand, is not sexy”</a></p>
<p>Introduction: Mark Palko  writes :
  
I can understand the appeal of the cutting edge. The new stuff is sexier. It gets people’s attention. The trouble is, those cutting edge studies often collapse under scrutiny. Some can’t be replicated. Others prove to be not that important.


Confirmation, on the other hand, is not sexy. It doesn’t drive traffic. It’s harder to fit into a paragraph. In a way, though, it’s more interesting because it has a high likelihood of being true and fills in the gaps in big, important questions. The interaction between the ideas is usually the interesting part.
  
In this particular example, Palko is telling the story of a journalist who reports a finding as new when it is essentially a replication of decades-old work.  Palko’s point is not that there’s anything wrong with replication but rather that the journalist seems to feel that it is necessary to report the idea as new and cutting-edge, even if it falls within a long tradition.  (Also, Palko is not claiming that this</p><p>2 0.1987102 <a title="1683-tfidf-2" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-05-13-Stolen_jokes.html">1318 andrew gelman stats-2012-05-13-Stolen jokes</a></p>
<p>Introduction: Fun stories  here  (from Kliph Nesteroff,  link  from Mark Palko).</p><p>3 0.15148318 <a title="1683-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-12-More_on_publishing_in_journals.html">2245 andrew gelman stats-2014-03-12-More on publishing in journals</a></p>
<p>Introduction: I’m postponing today’s scheduled post (“Empirical implications of Empirical Implications of Theoretical Models”) to continue the lively discussion from yesterday,  What if I were to stop publishing in journals? . 
   
 An example:  my papers with Basbøll 
 
Thomas Basbøll and I got into a long discussion on our blogs about business school professor Karl Weick and other cases of  plagiarism  copying text without attribution.  We felt it useful to take our ideas to the next level and write them up as a manuscript, which ended up being logical to split into two papers.  At that point I put some effort into getting these papers published, which I eventually did:   To throw away data: Plagiarism as a statistical crime  went into American Scientist and  When do stories work? Evidence and illustration in the social sciences  will appear in Sociological Methods and Research.  The second paper, in particular, took some effort to place; I got some advice from colleagues in sociology as to where</p><p>4 0.14832056 <a title="1683-tfidf-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>Introduction: Raghuveer Parthasarathy pointed me to an article in Nature by Mina Bissell, who  writes , “The push to replicate findings could shelve promising research and unfairly damage the reputations of careful, meticulous scientists.”
 
I can see where she’s coming from:  if you work hard day after day in the lab, it’s gotta be a bit frustrating to find all your work questioned, for the frauds of the  Dr. Anil Pottis  and Diederik Stapels to be treated as a reason for everyone else’s work to be considered guilty until proven innocent.
 
That said, I pretty much disagree with Bissell’s article, and really the best thing I can say about it is that I think it’s a good sign that the push for replication is so strong that now there’s a backlash against it.  Traditionally, leading scientists have been able to simply ignore the push for replication.  If they are feeling that the replication movement is strong enough that they need to fight it, that to me is good news.
 
I’ll explain a bit in the conte</p><p>5 0.14732574 <a title="1683-tfidf-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>Introduction: Jeff Leek  points to  a post by Alex Holcombe, who disputes the idea that science is self-correcting.  Holcombe  writes  [scroll down to get to his part]:
  
The pace of scientific production has quickened, and self-correction has suffered. Findings that might correct old results are considered less interesting than results from more original research questions. Potential corrections are also more contested. As the competition for space in prestigious journals has become increasingly frenzied, doing and publishing studies that would confirm the rapidly accumulating new discoveries, or would correct them, became a losing proposition.
  
Holcombe picks up on some points that we’ve discussed a lot here in the past year.  Here’s Holcombe:
  
In certain subfields, almost all new work appears in only a very few journals, all associated with a single professional society. There is then no way around the senior gatekeepers, who may then suppress corrections with impunity. . . .


The bias agai</p><p>6 0.14464599 <a title="1683-tfidf-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Evaluating_evidence_from_published_research.html">2006 andrew gelman stats-2013-09-03-Evaluating evidence from published research</a></p>
<p>7 0.13773656 <a title="1683-tfidf-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>8 0.1263126 <a title="1683-tfidf-8" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-13-Preregistration_of_Studies_and_Mock_Reports.html">1671 andrew gelman stats-2013-01-13-Preregistration of Studies and Mock Reports</a></p>
<p>9 0.12606613 <a title="1683-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>10 0.12462108 <a title="1683-tfidf-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-01-Back_when_fifty_years_was_a_long_time_ago.html">1646 andrew gelman stats-2013-01-01-Back when fifty years was a long time ago</a></p>
<p>11 0.12448297 <a title="1683-tfidf-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-19-It_is_difficult_to_convey_intonation_in_typed_speech.html">1463 andrew gelman stats-2012-08-19-It is difficult to convey intonation in typed speech</a></p>
<p>12 0.12285486 <a title="1683-tfidf-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>13 0.12245433 <a title="1683-tfidf-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>14 0.12012452 <a title="1683-tfidf-14" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-29-%E2%80%9CQuestioning_The_Lancet%2C_PLOS%2C_And_Other_Surveys_On_Iraqi_Deaths%2C_An_Interview_With_Univ._of_London_Professor_Michael_Spagat%E2%80%9D.html">2191 andrew gelman stats-2014-01-29-“Questioning The Lancet, PLOS, And Other Surveys On Iraqi Deaths, An Interview With Univ. of London Professor Michael Spagat”</a></p>
<p>15 0.1201127 <a title="1683-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-17-The_disappearing_or_non-disappearing_middle_class.html">1767 andrew gelman stats-2013-03-17-The disappearing or non-disappearing middle class</a></p>
<p>16 0.11342151 <a title="1683-tfidf-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-01-23-The_scalarization_of_America.html">533 andrew gelman stats-2011-01-23-The scalarization of America</a></p>
<p>17 0.10954687 <a title="1683-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-06-Against_optimism_about_social_science.html">1844 andrew gelman stats-2013-05-06-Against optimism about social science</a></p>
<p>18 0.10818762 <a title="1683-tfidf-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>19 0.10707967 <a title="1683-tfidf-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-04-Flip_it_around.html">943 andrew gelman stats-2011-10-04-Flip it around</a></p>
<p>20 0.1058647 <a title="1683-tfidf-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.241), (1, -0.084), (2, -0.065), (3, -0.097), (4, -0.047), (5, -0.035), (6, 0.043), (7, -0.018), (8, -0.009), (9, 0.003), (10, 0.022), (11, 0.025), (12, -0.03), (13, -0.012), (14, -0.001), (15, -0.014), (16, 0.031), (17, 0.028), (18, -0.001), (19, -0.019), (20, -0.005), (21, 0.005), (22, -0.012), (23, -0.015), (24, -0.022), (25, -0.016), (26, 0.026), (27, 0.031), (28, -0.015), (29, -0.009), (30, -0.041), (31, -0.011), (32, 0.044), (33, -0.033), (34, 0.026), (35, 0.028), (36, -0.057), (37, 0.009), (38, 0.033), (39, 0.024), (40, -0.025), (41, 0.038), (42, 0.019), (43, 0.075), (44, 0.075), (45, 0.035), (46, -0.056), (47, 0.056), (48, -0.024), (49, -0.008)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96940696 <a title="1683-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-%E2%80%9CConfirmation%2C_on_the_other_hand%2C_is_not_sexy%E2%80%9D.html">1683 andrew gelman stats-2013-01-19-“Confirmation, on the other hand, is not sexy”</a></p>
<p>Introduction: Mark Palko  writes :
  
I can understand the appeal of the cutting edge. The new stuff is sexier. It gets people’s attention. The trouble is, those cutting edge studies often collapse under scrutiny. Some can’t be replicated. Others prove to be not that important.


Confirmation, on the other hand, is not sexy. It doesn’t drive traffic. It’s harder to fit into a paragraph. In a way, though, it’s more interesting because it has a high likelihood of being true and fills in the gaps in big, important questions. The interaction between the ideas is usually the interesting part.
  
In this particular example, Palko is telling the story of a journalist who reports a finding as new when it is essentially a replication of decades-old work.  Palko’s point is not that there’s anything wrong with replication but rather that the journalist seems to feel that it is necessary to report the idea as new and cutting-edge, even if it falls within a long tradition.  (Also, Palko is not claiming that this</p><p>2 0.82207596 <a title="1683-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-13-Preregistration_of_Studies_and_Mock_Reports.html">1671 andrew gelman stats-2013-01-13-Preregistration of Studies and Mock Reports</a></p>
<p>Introduction: The traditional system of scientific and scholarly publishing is breaking down in two different directions.
 
On one hand, we are moving away from relying on a small set of journals as gatekeepers: the number of papers and research projects is increasing, the number of publication outlets is increasing, and important manuscripts are being posted on SSRN, Arxiv, and other nonrefereed sites.
 
At the same time, many researchers are worried about the profusion of published claims that turn out to not replicate or in plain language, to be false. This concern is not new–some prominent discussions include Rosenthal (1979), Ioannidis (2005), and Vul et al. (2009)–but there is a growing sense that the scientific signal is being swamped by noise.
 
I recently had the opportunity to comment in the journal Political Analysis on two papers, one by Humphreys, Sierra, and Windt, and one by Monogan, on the preregistration of studies and mock reports.   Here’s  the issue of the journal.
 
Given the hi</p><p>3 0.7962479 <a title="1683-lsi-3" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-26-Suggested_resolution_of_the_Bem_paradox.html">1139 andrew gelman stats-2012-01-26-Suggested resolution of the Bem paradox</a></p>
<p>Introduction: There has been an increasing discussion about the proliferation of flawed research in psychology and medicine, with some landmark events being John Ioannides’s  article , “Why most published research findings are false” (according to Google Scholar, cited 973 times since its appearance in 2005), the scandals of Marc Hauser and Diederik Stapel, two leading psychology professors who resigned after disclosures of scientific misconduct, and Daryl Bem’s  dubious  recent paper on ESP, published to much  fanfare  in Journal of Personality and Social Psychology, one of the top journals in the field.
 
Alongside all this are the plagiarism scandals, which are uninteresting from a scientific context but are relevant in that, in many cases, neither the institutions housing the plagiarists nor the editors and publishers of the plagiarized material seem to care.  Perhaps these universities and publishers are more worried about bad publicity (and maybe lawsuits, given that many of the plagiarism cas</p><p>4 0.79206187 <a title="1683-lsi-4" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-12-17-Replication_backlash.html">2137 andrew gelman stats-2013-12-17-Replication backlash</a></p>
<p>Introduction: Raghuveer Parthasarathy pointed me to an article in Nature by Mina Bissell, who  writes , “The push to replicate findings could shelve promising research and unfairly damage the reputations of careful, meticulous scientists.”
 
I can see where she’s coming from:  if you work hard day after day in the lab, it’s gotta be a bit frustrating to find all your work questioned, for the frauds of the  Dr. Anil Pottis  and Diederik Stapels to be treated as a reason for everyone else’s work to be considered guilty until proven innocent.
 
That said, I pretty much disagree with Bissell’s article, and really the best thing I can say about it is that I think it’s a good sign that the push for replication is so strong that now there’s a backlash against it.  Traditionally, leading scientists have been able to simply ignore the push for replication.  If they are feeling that the replication movement is strong enough that they need to fight it, that to me is good news.
 
I’ll explain a bit in the conte</p><p>5 0.78902066 <a title="1683-lsi-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-19-The_replication_and_criticism_movement_is_not_about_suppressing_speculative_research%3B_rather%2C_it%E2%80%99s_all_about_enabling_science%E2%80%99s_fabled_self-correcting_nature.html">2217 andrew gelman stats-2014-02-19-The replication and criticism movement is not about suppressing speculative research; rather, it’s all about enabling science’s fabled self-correcting nature</a></p>
<p>Introduction: Jeff Leek  points to  a post by Alex Holcombe, who disputes the idea that science is self-correcting.  Holcombe  writes  [scroll down to get to his part]:
  
The pace of scientific production has quickened, and self-correction has suffered. Findings that might correct old results are considered less interesting than results from more original research questions. Potential corrections are also more contested. As the competition for space in prestigious journals has become increasingly frenzied, doing and publishing studies that would confirm the rapidly accumulating new discoveries, or would correct them, became a losing proposition.
  
Holcombe picks up on some points that we’ve discussed a lot here in the past year.  Here’s Holcombe:
  
In certain subfields, almost all new work appears in only a very few journals, all associated with a single professional society. There is then no way around the senior gatekeepers, who may then suppress corrections with impunity. . . .


The bias agai</p><p>6 0.78821242 <a title="1683-lsi-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-06-Against_optimism_about_social_science.html">1844 andrew gelman stats-2013-05-06-Against optimism about social science</a></p>
<p>7 0.7864868 <a title="1683-lsi-7" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-22-Ticket_to_Baaaaarf.html">2301 andrew gelman stats-2014-04-22-Ticket to Baaaaarf</a></p>
<p>8 0.77984339 <a title="1683-lsi-8" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-20-The_AAA_Tranche_of_Subprime_Science.html">2179 andrew gelman stats-2014-01-20-The AAA Tranche of Subprime Science</a></p>
<p>9 0.77758718 <a title="1683-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-19-%E2%80%9CThe_British_amateur_who_debunked_the_mathematics_of_happiness%E2%80%9D.html">2177 andrew gelman stats-2014-01-19-“The British amateur who debunked the mathematics of happiness”</a></p>
<p>10 0.76502115 <a title="1683-lsi-10" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-25-A_new_Bem_theory.html">1998 andrew gelman stats-2013-08-25-A new Bem theory</a></p>
<p>11 0.75751692 <a title="1683-lsi-11" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-08-More_on_those_dudes_who_will_pay_your_professor_%248000_to_assign_a_book_to_your_class%2C_and_related_stories_about_small-time_sleazoids.html">329 andrew gelman stats-2010-10-08-More on those dudes who will pay your professor $8000 to assign a book to your class, and related stories about small-time sleazoids</a></p>
<p>12 0.75738794 <a title="1683-lsi-12" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-22-Quickies.html">2220 andrew gelman stats-2014-02-22-Quickies</a></p>
<p>13 0.75105536 <a title="1683-lsi-13" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-17-The_Washington_Post_reprints_university_press_releases_without_editing_them.html">2215 andrew gelman stats-2014-02-17-The Washington Post reprints university press releases without editing them</a></p>
<p>14 0.75086683 <a title="1683-lsi-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>15 0.7488814 <a title="1683-lsi-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-03-Evaluating_evidence_from_published_research.html">2006 andrew gelman stats-2013-09-03-Evaluating evidence from published research</a></p>
<p>16 0.74706715 <a title="1683-lsi-16" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-02-20-Do_differences_between_biology_and_statistics_explain_some_of_our_diverging_attitudes_regarding_criticism_and_replication_of_scientific_claims%3F.html">2218 andrew gelman stats-2014-02-20-Do differences between biology and statistics explain some of our diverging attitudes regarding criticism and replication of scientific claims?</a></p>
<p>17 0.74559438 <a title="1683-lsi-17" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-20-Proposals_for_alternative_review_systems_for_scientific_work.html">1273 andrew gelman stats-2012-04-20-Proposals for alternative review systems for scientific work</a></p>
<p>18 0.7439366 <a title="1683-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-31-How_to_fix_the_tabloids%3F__Toward_replicable_social_science_research.html">1878 andrew gelman stats-2013-05-31-How to fix the tabloids?  Toward replicable social science research</a></p>
<p>19 0.74223238 <a title="1683-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-12-14-Can_gambling_addicts_be_identified_in_gambling_venues%3F.html">1622 andrew gelman stats-2012-12-14-Can gambling addicts be identified in gambling venues?</a></p>
<p>20 0.74000514 <a title="1683-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-14-Type_M_errors_in_the_lab.html">908 andrew gelman stats-2011-09-14-Type M errors in the lab</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.026), (9, 0.02), (15, 0.119), (16, 0.055), (21, 0.024), (24, 0.167), (30, 0.015), (42, 0.022), (65, 0.011), (85, 0.02), (94, 0.067), (99, 0.296)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97057784 <a title="1683-lda-1" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-02-15-With_a_bit_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_again_on_this_topic%2C_and_with_a_lot_of_precognition%2C_you%E2%80%99d_have_known_I_was_going_to_post_today.html">576 andrew gelman stats-2011-02-15-With a bit of precognition, you’d have known I was going to post again on this topic, and with a lot of precognition, you’d have known I was going to post today</a></p>
<p>Introduction: Chris Masse points me to  this response  by Daryl Bem and two statisticians (Jessica Utts and Wesley Johnson) to criticisms by Wagenmakers et.al. of Bem’s recent ESP study.  I have nothing to add but would like to repeat a couple bits of my discussions of last month, of  here :
  
Classical statistical methods that work reasonably well when studying moderate or large effects (see the work of Fisher, Snedecor, Cochran, etc.) fall apart in the presence of small effects.


I think it’s naive when people implicitly assume that the study’s claims are correct, or the study’s statistical methods are weak. Generally, the smaller the effects you’re studying, the better the statistics you need. ESP is a field of small effects and so ESP researchers use high-quality statistics.


To put it another way: whatever methodological errors happen to be in the paper in question, probably occur in lots of researcher papers in “legitimate” psychology research. The difference is that when you’re studying a</p><p>same-blog 2 0.96941662 <a title="1683-lda-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-19-%E2%80%9CConfirmation%2C_on_the_other_hand%2C_is_not_sexy%E2%80%9D.html">1683 andrew gelman stats-2013-01-19-“Confirmation, on the other hand, is not sexy”</a></p>
<p>Introduction: Mark Palko  writes :
  
I can understand the appeal of the cutting edge. The new stuff is sexier. It gets people’s attention. The trouble is, those cutting edge studies often collapse under scrutiny. Some can’t be replicated. Others prove to be not that important.


Confirmation, on the other hand, is not sexy. It doesn’t drive traffic. It’s harder to fit into a paragraph. In a way, though, it’s more interesting because it has a high likelihood of being true and fills in the gaps in big, important questions. The interaction between the ideas is usually the interesting part.
  
In this particular example, Palko is telling the story of a journalist who reports a finding as new when it is essentially a replication of decades-old work.  Palko’s point is not that there’s anything wrong with replication but rather that the journalist seems to feel that it is necessary to report the idea as new and cutting-edge, even if it falls within a long tradition.  (Also, Palko is not claiming that this</p><p>3 0.96706104 <a title="1683-lda-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-14-Subtleties_with_measurement-error_models_for_the_evaluation_of_wacky_claims.html">803 andrew gelman stats-2011-07-14-Subtleties with measurement-error models for the evaluation of wacky claims</a></p>
<p>Introduction: A few days ago I  discussed  the evaluation of somewhat-plausible claims that are somewhat supported by theory and somewhat supported by statistical evidence.  One point I raised was that an implausibly large estimate of effect size can be cause for concern:
  
Uri Simonsohn (the author of the recent rebuttal of the name-choice article by Pelham et al.) argued that the implied effects were too large to be believed (just as I was arguing above regarding the July 4th study), which makes more plausible his claims that the results arise from methodological artifacts.


That calculation is straight Bayes: the distribution of systematic errors has much longer tails than the distribution of random errors, so the larger the estimated effect, the more likely it is to be a mistake. This little theoretical result is a bit annoying, because it is the larger effects that are the most interesting!”
  
Larry Bartels notes that my reasoning above is a bit incoherent:
  
I [Bartels] strongly agree with</p><p>4 0.96601838 <a title="1683-lda-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-06-W%E2%80%99man_%3C_W%E2%80%99pedia%2C_again.html">945 andrew gelman stats-2011-10-06-W’man < W’pedia, again</a></p>
<p>Introduction: Blogger Deep Climate  looks at  another paper by the 2002 recipient of the American Statistical Association’s Founders award. This time it’s not funny, it’s just sad. 
   
Here’s Wikipedia on simulated annealing:
  
By analogy with this physical process, each step of the SA algorithm replaces the current solution by a random “nearby” solution, chosen with a probability that depends on the difference between the corresponding function values and on a global parameter T (called the temperature), that is gradually decreased during the process. The dependency is such that the current solution changes almost randomly when T is large, but increasingly “downhill” as T goes to zero. The allowance for “uphill” moves saves the method from becoming stuck at local minima—which are the bane of greedier methods.
  
And here’s Wegman:
  
During each step of the algorithm, the variable that will eventually represent the minimum is replaced by a random solution that is chosen according to a temperature</p><p>5 0.96497613 <a title="1683-lda-5" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-30-I_posted_this_as_a_comment_on_a_sociology_blog.html">2353 andrew gelman stats-2014-05-30-I posted this as a comment on a sociology blog</a></p>
<p>Introduction: I discussed two problems:
 
1.  An artificial scarcity applied to journal publication, a scarcity which I believe is being enforced based on a monetary principle of not wanting to reduce the value of publication.  The problem is that journals don’t just spread information and improve communication, they also represent chits for hiring and promotion.  I’d prefer to separate these two aspects of publication. To keep these functions tied together seems to me like a terrible mistake.  It would be as if, instead of using dollar bills as currency, we were to just use  paper , and then if the government kept paper artificially scarce to retain the value of money, so that we were reduced to scratching notes to each other on walls and tables.
 
2.  The discontinuous way in which unpublished papers and submissions to journals are taken as highly suspect and requiring a strong justification of all methods and assumptions, but once a paper becomes published its conclusions are taken as true unless</p><p>6 0.9646849 <a title="1683-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-27-%E2%80%9CTwo_Dogmas_of_Strong_Objective_Bayesianism%E2%80%9D.html">1779 andrew gelman stats-2013-03-27-“Two Dogmas of Strong Objective Bayesianism”</a></p>
<p>7 0.96425247 <a title="1683-lda-7" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-08-Gratuitous_use_of_%E2%80%9CBayesian_Statistics%2C%E2%80%9D_a_branding_issue%3F.html">133 andrew gelman stats-2010-07-08-Gratuitous use of “Bayesian Statistics,” a branding issue?</a></p>
<p>8 0.96387285 <a title="1683-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-09-12-The_importance_of_style_in_academic_writing.html">902 andrew gelman stats-2011-09-12-The importance of style in academic writing</a></p>
<p>9 0.95776737 <a title="1683-lda-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-11-What_if_I_were_to_stop_publishing_in_journals%3F.html">2244 andrew gelman stats-2014-03-11-What if I were to stop publishing in journals?</a></p>
<p>10 0.95718032 <a title="1683-lda-10" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-14-Battle_of_the_Americans%3A__Writer_at_the_American_Enterprise_Institute_disparages_the_American_Political_Science_Association.html">274 andrew gelman stats-2010-09-14-Battle of the Americans:  Writer at the American Enterprise Institute disparages the American Political Science Association</a></p>
<p>11 0.95461625 <a title="1683-lda-11" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-19-Statistical_discrimination_again.html">1541 andrew gelman stats-2012-10-19-Statistical discrimination again</a></p>
<p>12 0.95377284 <a title="1683-lda-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-09-My_talks_in_DC_and_Baltimore_this_week.html">1794 andrew gelman stats-2013-04-09-My talks in DC and Baltimore this week</a></p>
<p>13 0.95310354 <a title="1683-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-09-A_tale_of_two_discussion_papers.html">1848 andrew gelman stats-2013-05-09-A tale of two discussion papers</a></p>
<p>14 0.95299751 <a title="1683-lda-14" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-21-Interpreting_interactions_in_discrete-data_regression.html">1908 andrew gelman stats-2013-06-21-Interpreting interactions in discrete-data regression</a></p>
<p>15 0.95285773 <a title="1683-lda-15" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-30-Retracted_articles_and_unethical_behavior_in_economics_journals%3F.html">1435 andrew gelman stats-2012-07-30-Retracted articles and unethical behavior in economics journals?</a></p>
<p>16 0.9524017 <a title="1683-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-20-What_happened_that_the_journal_Psychological_Science_published_a_paper_with_no_identifiable_strengths%3F.html">1865 andrew gelman stats-2013-05-20-What happened that the journal Psychological Science published a paper with no identifiable strengths?</a></p>
<p>17 0.95006102 <a title="1683-lda-17" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-01-29-%E2%80%9CQuestioning_The_Lancet%2C_PLOS%2C_And_Other_Surveys_On_Iraqi_Deaths%2C_An_Interview_With_Univ._of_London_Professor_Michael_Spagat%E2%80%9D.html">2191 andrew gelman stats-2014-01-29-“Questioning The Lancet, PLOS, And Other Surveys On Iraqi Deaths, An Interview With Univ. of London Professor Michael Spagat”</a></p>
<p>18 0.9480933 <a title="1683-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-03-22-Likelihood_Ratio_%E2%89%A0_1_Journal.html">1774 andrew gelman stats-2013-03-22-Likelihood Ratio ≠ 1 Journal</a></p>
<p>19 0.94771737 <a title="1683-lda-19" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-30-rms2.html">981 andrew gelman stats-2011-10-30-rms2</a></p>
<p>20 0.9477154 <a title="1683-lda-20" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-27-Why_don%E2%80%99t_more_medical_discoveries_become_cures%3F.html">167 andrew gelman stats-2010-07-27-Why don’t more medical discoveries become cures?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
