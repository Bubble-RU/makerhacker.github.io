<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1648 andrew gelman stats-2013-01-02-A important new survey of Bayesian predictive methods for model assessment, selection and comparison</title>
</head>

<body>
<p><a title="andrew_gelman_stats" href="../andrew_gelman_stats_home.html">andrew_gelman_stats</a> <a title="andrew_gelman_stats-2013" href="../home/andrew_gelman_stats-2013_home.html">andrew_gelman_stats-2013</a> <a title="andrew_gelman_stats-2013-1648" href="#">andrew_gelman_stats-2013-1648</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1648 andrew gelman stats-2013-01-02-A important new survey of Bayesian predictive methods for model assessment, selection and comparison</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="andrew_gelman_stats-2013-1648-html" href="http://andrewgelman.com/2013/01/02/a-important-new-survey-of-bayesian-predictive-methods-for-model-assessment-selection-and-comparison/">html</a></p><p>Introduction: Aki Vehtari and Janne Ojanen just published a  long paper  that begins:
  
To date, several methods exist in the statistical literature for model assessment, which purport themselves specifically as Bayesian predictive methods. The decision theoretic assumptions on which these methods are based are not always clearly stated in the original articles, however. The aim of this survey is to provide a unified review of Bayesian predictive model assessment and selection methods, and of methods closely related to them. We review the various assumptions that are made in this context and discuss the connections between different approaches, with an emphasis on how each method approximates the expected utility of using a Bayesian model for the purpose of predicting future data.
  
AIC (which Akaike called “An Information Criterion”) is the starting point for all these methods.  More recently, Watanabe came up with WAIC (which he called the “Widely Available Information Criterion”).  In between t</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Aki Vehtari and Janne Ojanen just published a  long paper  that begins:    To date, several methods exist in the statistical literature for model assessment, which purport themselves specifically as Bayesian predictive methods. [sent-1, score-0.633]
</p><p>2 The decision theoretic assumptions on which these methods are based are not always clearly stated in the original articles, however. [sent-2, score-0.543]
</p><p>3 The aim of this survey is to provide a unified review of Bayesian predictive model assessment and selection methods, and of methods closely related to them. [sent-3, score-0.936]
</p><p>4 We review the various assumptions that are made in this context and discuss the connections between different approaches, with an emphasis on how each method approximates the expected utility of using a Bayesian model for the purpose of predicting future data. [sent-4, score-0.7]
</p><p>5 AIC (which Akaike called “An Information Criterion”) is the starting point for all these methods. [sent-5, score-0.088]
</p><p>6 More recently, Watanabe came up with WAIC (which he called the “Widely Available Information Criterion”). [sent-6, score-0.088]
</p><p>7 I still dream of coming up with something with Vehtari and calling it the Very Good Information Criterion. [sent-8, score-0.167]
</p><p>8 The tradition in this area has been to come up with clever, computable formula and then hope it does everything we want. [sent-10, score-0.344]
</p><p>9 Vehtari and Ojanen do it slightly differently by asking more clearly what the goals are. [sent-11, score-0.302]
</p><p>10 If the goal is some sort of predictive error than it turns out that there is no magic formula. [sent-12, score-0.492]
</p><p>11 It’s easy to come up with examples where the relevant out-of-sample predictive error can be defined in different, incompatible ways. [sent-14, score-0.489]
</p><p>12 One valuable aspect of the Vehtari and Ojanen paper is that they explicitly discuss these different goals rather than assuming or implying that a single measure will tell the whole story. [sent-15, score-0.444]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('vehtari', 0.429), ('ojanen', 0.406), ('predictive', 0.224), ('criterion', 0.17), ('assessment', 0.151), ('methods', 0.143), ('bayesian', 0.128), ('janne', 0.123), ('purport', 0.123), ('goals', 0.122), ('watanabe', 0.116), ('approximates', 0.116), ('theoretic', 0.116), ('computable', 0.111), ('assumptions', 0.108), ('incompatible', 0.107), ('unified', 0.104), ('waic', 0.104), ('dic', 0.101), ('clearly', 0.099), ('information', 0.097), ('akaike', 0.097), ('aic', 0.097), ('goal', 0.097), ('discuss', 0.094), ('review', 0.091), ('called', 0.088), ('error', 0.087), ('dream', 0.086), ('aki', 0.086), ('implying', 0.085), ('magic', 0.084), ('calling', 0.081), ('aim', 0.081), ('differently', 0.081), ('tradition', 0.081), ('formula', 0.081), ('stated', 0.077), ('clever', 0.076), ('date', 0.075), ('utility', 0.074), ('gon', 0.074), ('different', 0.073), ('model', 0.073), ('come', 0.071), ('connections', 0.071), ('valuable', 0.07), ('exist', 0.07), ('closely', 0.069), ('na', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1648-tfidf-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-02-A_important_new_survey_of_Bayesian_predictive_methods_for_model_assessment%2C_selection_and_comparison.html">1648 andrew gelman stats-2013-01-02-A important new survey of Bayesian predictive methods for model assessment, selection and comparison</a></p>
<p>Introduction: Aki Vehtari and Janne Ojanen just published a  long paper  that begins:
  
To date, several methods exist in the statistical literature for model assessment, which purport themselves specifically as Bayesian predictive methods. The decision theoretic assumptions on which these methods are based are not always clearly stated in the original articles, however. The aim of this survey is to provide a unified review of Bayesian predictive model assessment and selection methods, and of methods closely related to them. We review the various assumptions that are made in this context and discuss the connections between different approaches, with an emphasis on how each method approximates the expected utility of using a Bayesian model for the purpose of predicting future data.
  
AIC (which Akaike called “An Information Criterion”) is the starting point for all these methods.  More recently, Watanabe came up with WAIC (which he called the “Widely Available Information Criterion”).  In between t</p><p>2 0.29320982 <a title="1648-tfidf-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-09-Understanding_predictive_information_criteria_for_Bayesian_models.html">1975 andrew gelman stats-2013-08-09-Understanding predictive information criteria for Bayesian models</a></p>
<p>Introduction: Jessy, Aki, and I  write :
  
We review the Akaike, deviance, and Watanabe-Akaike information criteria from a Bayesian perspective, where the goal is to estimate expected out-of-sample-prediction error using a bias-corrected adjustment of within-sample error. We focus on the choices involved in setting up these measures, and we compare them in three simple examples, one theoretical and two applied. The contribution of this review is to put all these information criteria into a Bayesian predictive context and to better understand, through small examples, how these methods can apply in practice.
  
I like this paper.  It came about as a result of preparing Chapter 7 for the  new BDA .  I had difficulty understanding AIC, DIC, WAIC, etc., but I recognized that these methods served a need.  My first plan was to just apply DIC and WAIC on a couple of simple examples (a linear regression and the 8 schools) and leave it at that.  But when I did the calculations, I couldnâ&euro;&trade;t understand the resu</p><p>3 0.19520542 <a title="1648-tfidf-3" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-26-WAIC_and_cross-validation_in_Stan%21.html">2349 andrew gelman stats-2014-05-26-WAIC and cross-validation in Stan!</a></p>
<p>Introduction: Aki and I  write :
  
The Watanabe-Akaike information criterion (WAIC) and cross-validation are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model. WAIC is based on the series expansion of leave-one-out cross-validation (LOO), and asymptotically they are equal. With finite data, WAIC and cross-validation address different predictive questions and thus it is useful to be able to compute both. WAIC and an importance-sampling approximated LOO can be estimated directly using the log-likelihood evaluated at the posterior simulations of the parameter values. We show how to compute WAIC, IS-LOO, K-fold cross-validation, and related diagnostic quantities in the Bayesian inference package Stan as called from R.
  
This is important, I think.  One reason the deviance information criterion (DIC) has been so popular is its implementation in Bugs.  We think WAIC and cross-validation make more sense than DIC, especially from a Bayesian perspective in whic</p><p>4 0.19462478 <a title="1648-tfidf-4" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<p>Introduction: Martyn Plummer  replied  to my recent  blog  on DIC with information that was important enough that I thought it deserved its own blog entry.  Martyn wrote:
  
DIC has been around for 10 years now and despite being immensely popular with applied statisticians it has generated very little theoretical interest. In fact, the silence has been deafening. I [Martyn] hope my paper added some clarity.


As you say, DIC is (an approximation to) a theoretical out-of-sample predictive error. When I finished the paper I was a little embarrassed to see that I had almost perfectly reconstructed the justification of AIC as approximate cross-validation measure by Stone (1977), with a Bayesian spin of course.


But even this insight leaves a lot of choices open. You need to choose the right loss function and also which level of the model you want to replicate from. David Spiegelhalter and colleagues called this the “focus”. In practice the focus is limited to the lowest level of the model. You generall</p><p>5 0.14885201 <a title="1648-tfidf-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-03-Question_about_predictive_checks.html">1363 andrew gelman stats-2012-06-03-Question about predictive checks</a></p>
<p>Introduction: Klaas Metselaar writes: 
  
  
I [Metselaar] am currently involved in a discussion about the use of the notion “predictive” as used in “posterior predictive check”. I would argue that the notion “predictive” should be reserved for posterior checks using information not used in the determination of the posterior. 
I quote from the discussion: 
“However, the predictive uncertainty in a Bayesian calculation requires sampling from all the random variables, and this includes both the model parameters and the residual error”.


My [Metselaar's] comment:


This may be exactly the point I am worried about: shouldn’t the predictive uncertainty be defined as sampling from the posterior parameter distribution +  residual error + sampling from the prediction error distribution? 
Residual error reduces to measurement error in the case of a  model which is perfect for the sample of experiments. Measurement error could be reduced to almost zero by ideal and perfect measurement instruments. 
I would h</p><p>6 0.14710924 <a title="1648-tfidf-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-22-Deviance%2C_DIC%2C_AIC%2C_cross-validation%2C_etc.html">776 andrew gelman stats-2011-06-22-Deviance, DIC, AIC, cross-validation, etc</a></p>
<p>7 0.13245437 <a title="1648-tfidf-7" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-15-More_on_AIC%2C_WAIC%2C_etc.html">1983 andrew gelman stats-2013-08-15-More on AIC, WAIC, etc</a></p>
<p>8 0.12696624 <a title="1648-tfidf-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-16-Long_discussion_about_causal_inference_and_the_use_of_hierarchical_models_to_bridge_between_different_inferential_settings.html">1418 andrew gelman stats-2012-07-16-Long discussion about causal inference and the use of hierarchical models to bridge between different inferential settings</a></p>
<p>9 0.12563875 <a title="1648-tfidf-9" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-11-Weakly_informative_priors_for_Bayesian_nonparametric_models%3F.html">1454 andrew gelman stats-2012-08-11-Weakly informative priors for Bayesian nonparametric models?</a></p>
<p>10 0.12314991 <a title="1648-tfidf-10" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>11 0.11982876 <a title="1648-tfidf-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-09-18-Understanding_posterior_p-values.html">2029 andrew gelman stats-2013-09-18-Understanding posterior p-values</a></p>
<p>12 0.11762951 <a title="1648-tfidf-12" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-14-GPstuff%3A_Bayesian_Modeling_with_Gaussian_Processes.html">1856 andrew gelman stats-2013-05-14-GPstuff: Bayesian Modeling with Gaussian Processes</a></p>
<p>13 0.11277422 <a title="1648-tfidf-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-04-05-More_philosophy_of_Bayes.html">1247 andrew gelman stats-2012-04-05-More philosophy of Bayes</a></p>
<p>14 0.10980962 <a title="1648-tfidf-14" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-06-13-A_question_about_AIC.html">1377 andrew gelman stats-2012-06-13-A question about AIC</a></p>
<p>15 0.10243788 <a title="1648-tfidf-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-28-Economists_argue_about_Bayes.html">1695 andrew gelman stats-2013-01-28-Economists argue about Bayes</a></p>
<p>16 0.10001294 <a title="1648-tfidf-16" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-10-31-It_not_necessary_that_Bayesian_methods_conform_to_the_likelihood_principle.html">1554 andrew gelman stats-2012-10-31-It not necessary that Bayesian methods conform to the likelihood principle</a></p>
<p>17 0.097977199 <a title="1648-tfidf-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-07-Philosophy_and_the_practice_of_Bayesian_statistics_%28with_all_the_discussions%21%29.html">1712 andrew gelman stats-2013-02-07-Philosophy and the practice of Bayesian statistics (with all the discussions!)</a></p>
<p>18 0.097505726 <a title="1648-tfidf-18" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>19 0.095511369 <a title="1648-tfidf-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-02-01-Philosophy_of_Bayesian_statistics%3A__my_reactions_to_Cox_and_Mayo.html">1149 andrew gelman stats-2012-02-01-Philosophy of Bayesian statistics:  my reactions to Cox and Mayo</a></p>
<p>20 0.095286421 <a title="1648-tfidf-20" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-11-Gelman_on_Hennig_on_Gelman_on_Bayes.html">1208 andrew gelman stats-2012-03-11-Gelman on Hennig on Gelman on Bayes</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/andrew_gelman_stats_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.16), (1, 0.114), (2, -0.04), (3, 0.013), (4, -0.049), (5, -0.005), (6, -0.061), (7, 0.012), (8, 0.025), (9, -0.024), (10, 0.035), (11, -0.02), (12, -0.059), (13, 0.028), (14, -0.03), (15, -0.003), (16, 0.036), (17, -0.005), (18, -0.004), (19, 0.025), (20, 0.016), (21, 0.013), (22, 0.034), (23, -0.013), (24, 0.041), (25, 0.023), (26, 0.016), (27, 0.031), (28, 0.022), (29, 0.002), (30, -0.01), (31, 0.049), (32, 0.063), (33, 0.008), (34, 0.025), (35, -0.011), (36, -0.002), (37, -0.031), (38, 0.01), (39, -0.03), (40, -0.016), (41, -0.001), (42, -0.0), (43, -0.004), (44, 0.012), (45, 0.005), (46, 0.019), (47, -0.038), (48, -0.019), (49, 0.011)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97843719 <a title="1648-lsi-1" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-02-A_important_new_survey_of_Bayesian_predictive_methods_for_model_assessment%2C_selection_and_comparison.html">1648 andrew gelman stats-2013-01-02-A important new survey of Bayesian predictive methods for model assessment, selection and comparison</a></p>
<p>Introduction: Aki Vehtari and Janne Ojanen just published a  long paper  that begins:
  
To date, several methods exist in the statistical literature for model assessment, which purport themselves specifically as Bayesian predictive methods. The decision theoretic assumptions on which these methods are based are not always clearly stated in the original articles, however. The aim of this survey is to provide a unified review of Bayesian predictive model assessment and selection methods, and of methods closely related to them. We review the various assumptions that are made in this context and discuss the connections between different approaches, with an emphasis on how each method approximates the expected utility of using a Bayesian model for the purpose of predicting future data.
  
AIC (which Akaike called “An Information Criterion”) is the starting point for all these methods.  More recently, Watanabe came up with WAIC (which he called the “Widely Available Information Criterion”).  In between t</p><p>2 0.88112861 <a title="1648-lsi-2" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-08-09-Understanding_predictive_information_criteria_for_Bayesian_models.html">1975 andrew gelman stats-2013-08-09-Understanding predictive information criteria for Bayesian models</a></p>
<p>Introduction: Jessy, Aki, and I  write :
  
We review the Akaike, deviance, and Watanabe-Akaike information criteria from a Bayesian perspective, where the goal is to estimate expected out-of-sample-prediction error using a bias-corrected adjustment of within-sample error. We focus on the choices involved in setting up these measures, and we compare them in three simple examples, one theoretical and two applied. The contribution of this review is to put all these information criteria into a Bayesian predictive context and to better understand, through small examples, how these methods can apply in practice.
  
I like this paper.  It came about as a result of preparing Chapter 7 for the  new BDA .  I had difficulty understanding AIC, DIC, WAIC, etc., but I recognized that these methods served a need.  My first plan was to just apply DIC and WAIC on a couple of simple examples (a linear regression and the 8 schools) and leave it at that.  But when I did the calculations, I couldnâ&euro;&trade;t understand the resu</p><p>3 0.82850546 <a title="1648-lsi-3" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-24-New_ideas_on_DIC_from_Martyn_Plummer_and_Sumio_Watanabe.html">778 andrew gelman stats-2011-06-24-New ideas on DIC from Martyn Plummer and Sumio Watanabe</a></p>
<p>Introduction: Martyn Plummer  replied  to my recent  blog  on DIC with information that was important enough that I thought it deserved its own blog entry.  Martyn wrote:
  
DIC has been around for 10 years now and despite being immensely popular with applied statisticians it has generated very little theoretical interest. In fact, the silence has been deafening. I [Martyn] hope my paper added some clarity.


As you say, DIC is (an approximation to) a theoretical out-of-sample predictive error. When I finished the paper I was a little embarrassed to see that I had almost perfectly reconstructed the justification of AIC as approximate cross-validation measure by Stone (1977), with a Bayesian spin of course.


But even this insight leaves a lot of choices open. You need to choose the right loss function and also which level of the model you want to replicate from. David Spiegelhalter and colleagues called this the “focus”. In practice the focus is limited to the lowest level of the model. You generall</p><p>4 0.81903285 <a title="1648-lsi-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-09-22-Philosophy_of_Bayes_and_non-Bayes%3A__A_dialogue_with_Deborah_Mayo.html">291 andrew gelman stats-2010-09-22-Philosophy of Bayes and non-Bayes:  A dialogue with Deborah Mayo</a></p>
<p>Introduction: I sent Deborah Mayo a link to  my paper  with Cosma Shalizi on the philosophy of statistics, and she sent me the link to this conference which unfortunately already occurred.  (It’s too bad, because I’d have liked to have been there.)  I summarized my philosophy as follows:
  
I am highly sympathetic to the approach of Lakatos (or of Popper, if you consider Lakatos’s “Popper_2″ to be a reasonable simulation of the true Popperism), in that (a) I view statistical models as being built within theoretical structures, and (b) I see the checking and refutation of models to be a key part of scientific progress.  A big problem I have with mainstream Bayesianism is its “inductivist” view that science can operate completely smoothly with posterior updates:  the idea that new data causes us to increase the posterior probability of good models and decrease the posterior probability of bad models.  I don’t buy that:  I see models as ever-changing entities that are flexible and can be patched and ex</p><p>5 0.79213649 <a title="1648-lsi-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-09-The_anti-Bayesian_moment_and_its_passing.html">1571 andrew gelman stats-2012-11-09-The anti-Bayesian moment and its passing</a></p>
<p>Introduction: Xian and I respond to the four discussants of our paper, “Not only defended but also applied”: The perceived absurdity of Bayesian inference.”  Here’s the abstract of  our rejoinder :
  
Over the years we have often felt frustration, both at smug Bayesians—in particular, those who object to checking of the fit of model to data, either because all Bayesian models are held to be subjective and thus unquestioned (an odd combination indeed, but that is the subject of another article)—and angry anti-Bayesians who, as we wrote in our article, strain on the gnat of the prior distribution while swallowing the camel that is the likelihood. The present article arose from our memory of a particularly intemperate anti-Bayesian statement that appeared in Feller’s beautiful and classic book on probability theory. We felt that it was worth exploring the very extremeness of Feller’s words, along with similar anti-Bayesian remarks by others, in order to better understand the background underlying contr</p><p>6 0.78798532 <a title="1648-lsi-6" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-06-22-Deviance%2C_DIC%2C_AIC%2C_cross-validation%2C_etc.html">776 andrew gelman stats-2011-06-22-Deviance, DIC, AIC, cross-validation, etc</a></p>
<p>7 0.7818597 <a title="1648-lsi-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-03-09-Coming_to_agreement_on_philosophy_of_statistics.html">1205 andrew gelman stats-2012-03-09-Coming to agreement on philosophy of statistics</a></p>
<p>8 0.77130079 <a title="1648-lsi-8" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-25-Ways_of_knowing.html">1469 andrew gelman stats-2012-08-25-Ways of knowing</a></p>
<p>9 0.75130886 <a title="1648-lsi-9" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-29-Bayesian_Uncertainty_Quantification_for_Differential_Equations%21.html">2311 andrew gelman stats-2014-04-29-Bayesian Uncertainty Quantification for Differential Equations!</a></p>
<p>10 0.75117189 <a title="1648-lsi-10" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-05-26-WAIC_and_cross-validation_in_Stan%21.html">2349 andrew gelman stats-2014-05-26-WAIC and cross-validation in Stan!</a></p>
<p>11 0.74068844 <a title="1648-lsi-11" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-03-18-Those_wacky_anti-Bayesians_used_to_be_intimidating%2C_but_now_they%E2%80%99re_just_pathetic.html">2254 andrew gelman stats-2014-03-18-Those wacky anti-Bayesians used to be intimidating, but now they’re just pathetic</a></p>
<p>12 0.73296565 <a title="1648-lsi-12" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-30-Useful_models%2C_model_checking%2C_and_external_validation%3A__a_mini-discussion.html">244 andrew gelman stats-2010-08-30-Useful models, model checking, and external validation:  a mini-discussion</a></p>
<p>13 0.72852707 <a title="1648-lsi-13" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-07-05-Xiao-Li_Meng_and_Xianchao_Xie_rethink_asymptotics.html">1406 andrew gelman stats-2012-07-05-Xiao-Li Meng and Xianchao Xie rethink asymptotics</a></p>
<p>14 0.7265411 <a title="1648-lsi-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-20-Kind_of_Bayesian.html">811 andrew gelman stats-2011-07-20-Kind of Bayesian</a></p>
<p>15 0.72250134 <a title="1648-lsi-15" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-10-05-Does_posterior_predictive_model_checking_fit_with_the_operational_subjective_approach%3F.html">320 andrew gelman stats-2010-10-05-Does posterior predictive model checking fit with the operational subjective approach?</a></p>
<p>16 0.72150648 <a title="1648-lsi-16" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-12-04-David_MacKay_and_Occam%E2%80%99s_Razor.html">1041 andrew gelman stats-2011-12-04-David MacKay and Occam’s Razor</a></p>
<p>17 0.71932286 <a title="1648-lsi-17" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-11-Why_waste_time_philosophizing%3F.html">1719 andrew gelman stats-2013-02-11-Why waste time philosophizing?</a></p>
<p>18 0.71786803 <a title="1648-lsi-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-02-26-An_AI_can_build_and_try_out_statistical_models_using_an_open-ended_generative_grammar.html">1739 andrew gelman stats-2013-02-26-An AI can build and try out statistical models using an open-ended generative grammar</a></p>
<p>19 0.71626395 <a title="1648-lsi-19" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-08-04-Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics.html">1443 andrew gelman stats-2012-08-04-Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></p>
<p>20 0.71567374 <a title="1648-lsi-20" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-11-19-Validation_of_Software_for_Bayesian_Models_Using_Posterior_Quantiles.html">1019 andrew gelman stats-2011-11-19-Validation of Software for Bayesian Models Using Posterior Quantiles</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/andrew_gelman_stats_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(13, 0.196), (15, 0.017), (16, 0.053), (21, 0.019), (22, 0.016), (24, 0.144), (28, 0.022), (30, 0.019), (61, 0.051), (86, 0.027), (99, 0.304)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96858716 <a title="1648-lda-1" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-08-25-Modeling_constrained_parameters.html">234 andrew gelman stats-2010-08-25-Modeling constrained parameters</a></p>
<p>Introduction: Mike McLaughlin writes:
  
In general, is there any way to do MCMC with a fixed constraint?


E.g., suppose I measure the three internal angles of a triangle with errors ~dnorm(0, tau) where tau might be different for the three measurements.  This would be an easy BUGS/WinBUGS/JAGS exercise but suppose, in addition, I wanted to include prior information to the effect that the three angles had to total 180 degrees exactly.


Is this feasible? Could you point me to any BUGS model in which a constraint of this type is implemented?


Note: Even in my own (non-hierarchical) code which tends to be component-wise, random-walk Metropolis with tuned Laplacian proposals, I cannot see how I could incorporate such a constraint.
  
My reply:  See page 508 of Bayesian Data Analysis (2nd edition).  We have an example of such a model there (from  this paper  with Bois and Jiang).</p><p>2 0.96091902 <a title="1648-lda-2" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-07-30-Why_don%E2%80%99t_we_have_peer_reviewing_for_oral_presentations%3F.html">172 andrew gelman stats-2010-07-30-Why don’t we have peer reviewing for oral presentations?</a></p>
<p>Introduction: Panos Ipeirotis  writes in his blog  post :
  

Everyone who has attended a conference knows that the quality of the talks is very uneven. There are talks that are highly engaging, entertaining, and describe nicely the research challenges and solutions. And there are talks that are a waste of time. Either the presenter cannot present clearly, or the presented content is impossible to digest within the time frame of the presentation.


We already have reviewing for the written part. The program committee examines the quality of the written  paper and vouch for its technical content. However, by looking at a paper it is impossible to know how nicely it can be presented. Perhaps the seemingly solid but boring paper can be a very entertaining presentation. Or an excellent paper may be written by a horrible presenter.


Why not having a second round of reviewing, where the authors of accepted papers submit their presentations (slides and a YouTube video) for presentation to the conference.</p><p>3 0.95042694 <a title="1648-lda-3" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-04-05-Elites_have_alcohol_problems_too%21.html">1789 andrew gelman stats-2013-04-05-Elites have alcohol problems too!</a></p>
<p>Introduction: Speaking of  Tyler Cowen, I’m puzzled by  this paragraph  of his:
  
Guns, like alcohol, have many legitimate uses, and they are enjoyed by many people in a responsible manner.  In both cases, there is an elite which has absolutely no problems handling the institution in question, but still there is the question of whether the nation really can have such bifurcated social norms, namely one set of standards for the elite and another set for everybody else.
  
I don’t know anything about guns so I’ll set that part aside.  My bafflement is with the claim that “there is an elite which has absolutely no problem handling [alcohol].”  Is he kidding?  Unless Cowen is circularly defining “an elite” as the subset of elites who don’t have an alcohol problem, I don’t buy this claim.  And I actually think it’s a serious problem, that various “elites” are so sure that they have “absolutely no problem” that they do dangerous, dangerous things.
 
Consider the notorious incident when Dick Cheney shot a</p><p>4 0.94980985 <a title="1648-lda-4" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-29-The_mystery_of_the_U-shaped_relationship_between_happiness_and_age.html">437 andrew gelman stats-2010-11-29-The mystery of the U-shaped relationship between happiness and age</a></p>
<p>Introduction: For  awhile  I’ve been curious (see also  here ) about the U-shaped relation between happiness and age (with people least happy, on average, in their forties, and happier before and after).
 
But when I tried to demonstrate it to me intro statistics course, using the General Social Survey, I couldn’t find the famed U, or anything like it.  Using pooled GSS data mixes age, period, and cohort, so I tried throwing in some cohort effects (indicators for decades) and a couple other variables, but still couldn’t find that U.
 
So I was intrigued when I came across  this paper by Paul Frijters and Tony Beatton , who write:
  
Whilst the majority of psychologists have concluded there is not much of a relationship at all, the economic literature has unearthed a possible U-shape relationship. In this paper we [Frijters and Beatton] replicate the U-shape for the German SocioEconomic Panel (GSOEP), and we investigate several possible explanations for it.
  
They write:
  
What is the relationship</p><p>5 0.94857872 <a title="1648-lda-5" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-11-02-The_blog_is_back.html">1559 andrew gelman stats-2012-11-02-The blog is back</a></p>
<p>Introduction: We had some security problem:  not an actual virus or anything, but a potential leak which caused Google to blacklist us.   Cord  fixed us and now weâ&euro;&trade;re fine.  Good job, Google!  Better to find the potential problem  before  there is any harm!</p><p>same-blog 6 0.94566011 <a title="1648-lda-6" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-02-A_important_new_survey_of_Bayesian_predictive_methods_for_model_assessment%2C_selection_and_comparison.html">1648 andrew gelman stats-2013-01-02-A important new survey of Bayesian predictive methods for model assessment, selection and comparison</a></p>
<p>7 0.94263685 <a title="1648-lda-7" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-09-24-Analyzing_photon_counts.html">1509 andrew gelman stats-2012-09-24-Analyzing photon counts</a></p>
<p>8 0.93786591 <a title="1648-lda-8" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-29-When_people_meet_this_guy%2C_can_they_resist_the_temptation_to_ask_him_what_he%E2%80%99s_doing_for_breakfast%3F%3F.html">980 andrew gelman stats-2011-10-29-When people meet this guy, can they resist the temptation to ask him what he’s doing for breakfast??</a></p>
<p>9 0.93648541 <a title="1648-lda-9" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-10-25-Apply_now_for_Earth_Institute_postdoctoral_fellowships_at_Columbia_University.html">971 andrew gelman stats-2011-10-25-Apply now for Earth Institute postdoctoral fellowships at Columbia University</a></p>
<p>10 0.93489957 <a title="1648-lda-10" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-03-02-RStudio_%E2%80%93_new_cross-platform_IDE_for_R.html">597 andrew gelman stats-2011-03-02-RStudio – new cross-platform IDE for R</a></p>
<p>11 0.93420953 <a title="1648-lda-11" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-07-17-%E2%80%9CStop_and_frisk%E2%80%9D_statistics.html">1942 andrew gelman stats-2013-07-17-“Stop and frisk” statistics</a></p>
<p>12 0.92796606 <a title="1648-lda-12" href="../andrew_gelman_stats-2012/andrew_gelman_stats-2012-01-24-Difficulties_in_publishing_non-replications_of_implausible_findings.html">1137 andrew gelman stats-2012-01-24-Difficulties in publishing non-replications of implausible findings</a></p>
<p>13 0.92306674 <a title="1648-lda-13" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-05-12-Crime_novels_for_economists.html">1852 andrew gelman stats-2013-05-12-Crime novels for economists</a></p>
<p>14 0.92093331 <a title="1648-lda-14" href="../andrew_gelman_stats-2011/andrew_gelman_stats-2011-07-13-I_like_lineplots.html">800 andrew gelman stats-2011-07-13-I like lineplots</a></p>
<p>15 0.91985172 <a title="1648-lda-15" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-27-The_weirdest_thing_about_the_AJPH_story.html">1916 andrew gelman stats-2013-06-27-The weirdest thing about the AJPH story</a></p>
<p>16 0.90650654 <a title="1648-lda-16" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-10-19-R_package_for_effect_size_calculations_for_psychology_researchers.html">2069 andrew gelman stats-2013-10-19-R package for effect size calculations for psychology researchers</a></p>
<p>17 0.90397125 <a title="1648-lda-17" href="../andrew_gelman_stats-2010/andrew_gelman_stats-2010-11-21-Data_cleaning_tool%21.html">424 andrew gelman stats-2010-11-21-Data cleaning tool!</a></p>
<p>18 0.89879435 <a title="1648-lda-18" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-01-14-How_do_you_think_about_the_values_in_a_confidence_interval%3F.html">1672 andrew gelman stats-2013-01-14-How do you think about the values in a confidence interval?</a></p>
<p>19 0.89823353 <a title="1648-lda-19" href="../andrew_gelman_stats-2013/andrew_gelman_stats-2013-06-20-Amazing_retro_gnu_graphics%21.html">1907 andrew gelman stats-2013-06-20-Amazing retro gnu graphics!</a></p>
<p>20 0.8938356 <a title="1648-lda-20" href="../andrew_gelman_stats-2014/andrew_gelman_stats-2014-04-28-Crowdstorming_a_dataset.html">2309 andrew gelman stats-2014-04-28-Crowdstorming a dataset</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
