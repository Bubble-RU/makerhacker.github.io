<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>143 hunch net-2005-12-27-Automated Labeling</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-143" href="#">hunch_net-2005-143</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>143 hunch net-2005-12-27-Automated Labeling</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-143-html" href="http://hunch.net/?p=153">html</a></p><p>Introduction: One of the common trends in machine learning has been an emphasis on the use
of unlabeled data. The argument goes something like "there aren't many labeled
web pages out there, but there are ahugenumber of web pages, so we must find a
way to take advantage of them." There are several standard approaches for
doing this:Unsupervised Learning. You use only unlabeled data. In a typical
application, you cluster the data and hope that the clusters somehow
correspond to what you care about.Semisupervised Learning. You use both
unlabeled and labeled data to build a predictor. The unlabeled data influences
the learned predictor in some way.Active Learning. You have unlabeled data and
access to a labeling oracle. You interactively choose which examples to label
so as to optimize prediction accuracy.It seems there is a fourth approach
worth serious investigation--automated labeling. The approach goes as
follows:Identify some subset of observed values to predict from the
others.Build a predictor.U</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('unlabeled', 0.387), ('labeling', 0.224), ('distance', 0.219), ('data', 0.198), ('nearby', 0.176), ('medium', 0.169), ('predictor', 0.156), ('pages', 0.153), ('unsupervised', 0.149), ('web', 0.137), ('goes', 0.131), ('automated', 0.127), ('labeled', 0.127), ('extreme', 0.121), ('output', 0.114), ('technique', 0.113), ('label', 0.109), ('supervised', 0.107), ('considers', 0.106), ('thedarpa', 0.106)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="143-tfidf-1" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>Introduction: One of the common trends in machine learning has been an emphasis on the use
of unlabeled data. The argument goes something like "there aren't many labeled
web pages out there, but there are ahugenumber of web pages, so we must find a
way to take advantage of them." There are several standard approaches for
doing this:Unsupervised Learning. You use only unlabeled data. In a typical
application, you cluster the data and hope that the clusters somehow
correspond to what you care about.Semisupervised Learning. You use both
unlabeled and labeled data to build a predictor. The unlabeled data influences
the learned predictor in some way.Active Learning. You have unlabeled data and
access to a labeling oracle. You interactively choose which examples to label
so as to optimize prediction accuracy.It seems there is a fourth approach
worth serious investigation--automated labeling. The approach goes as
follows:Identify some subset of observed values to predict from the
others.Build a predictor.U</p><p>2 0.18225597 <a title="143-tfidf-2" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>Introduction: Fernando Pereirapointed outAndo andZhang'spaperon "structural" learning.
Structural learning is multitask learning on subproblems created from
unlabeled data.The basic idea is to take a look at the unlabeled data and
create many supervised problems. On text data, which they test on, these
subproblems might be of the form "Given surrounding words predict the middle
word". The hope here is that successfully predicting on these subproblems is
relevant to the prediction of your core problem.In the long run, the precise
mechanism used (essentially, linear predictors with parameters tied by a
common matrix) and the precise problems formed may not be critical. What seems
critical is that the hope is realized: the technique provides a significant
edge in practice.Some basic questions about this approach are:Are there
effective automated mechanisms for creating the subproblems?Is it necessary to
use a shared representation?</p><p>3 0.15055333 <a title="143-tfidf-3" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.In selective sampling style
active learning, a learning algorithm chooses which examples to label. We now
have an active learning algorithm that is:Efficientin label complexity,
unlabeled complexity, and computational complexity.Competitivewith supervised
learning anywhere that supervised learning works.Compatiblewith online
learning, with any optimization-based learning algorithm, with any loss
function, with offline testing, and even with changing learning
algorithms.Empiricallyeffective.The basic idea is to combinedisagreement
region-based samplingwithimportance weighting: an example is selected to be
labeled with probability proportional to how useful it is for distinguishing
among near-optimal classifiers, and labeled examples are importance-weighted
by the inverse of these probabilities. The combination of these simple ideas
removes thesampling biasproblem that has plagued many previous heuristics for
active learning, and yet leads to</p><p>4 0.13769373 <a title="143-tfidf-4" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>Introduction: What?Bounds are mathematical formulas relating observations to future error
rates assuming that data is drawn independently. In classical statistics, they
are calld confidence intervals.Why?Good Judgement. In many applications of
learning, it is desirable to know how well the learned predictor works in the
future. This helps you decide if the problem is solved or not.Learning
Essence. The form of some of these bounds helps you understand what the
essence of learning is.Algorithm Design. Some of these bounds suggest,
motivate, or even directly imply learning algorithms.What We Know NowThere are
several families of bounds, based on how information is used.Testing Bounds.
These are methods which use labeled data not used in training to estimate the
future error rate. Examples include thetest set bound,progressive
validationalsohereandhere,train and test bounds, and cross-validation (but see
thebig open problem). These techniques are the best available for goal (1)
above, but provide littl</p><p>5 0.13509785 <a title="143-tfidf-5" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>Introduction: Often, unlabeled data is easy to come by but labels are expensive. For
instance, if you're building a speech recognizer, it's easy enough to get raw
speech samples -- just walk around with a microphone -- but labeling even one
of these samples is a tedious process in which a human must examine the speech
signal and carefully segment it into phonemes. In the field of active
learning, the goal is as usual to construct an accurate classifier, but the
labels of the data points are initially hidden and there is a charge for each
label you want revealed. The hope is that by intelligent adaptive querying,
you can get away with significantly fewer labels than you would need in a
regular supervised learning framework.Here's an example. Suppose the data lie
on the real line, and the classifiers are simple thresholding functions, H =
{hw}:hw(x) = 1 if x > w, and 0 otherwise.VC theory tells us that if the
underlying distribution P can be classified perfectly by some hypothesis in H
(called thereal</p><p>6 0.13364339 <a title="143-tfidf-6" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>7 0.13098703 <a title="143-tfidf-7" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>8 0.12980792 <a title="143-tfidf-8" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>9 0.12398667 <a title="143-tfidf-9" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>10 0.12016903 <a title="143-tfidf-10" href="../hunch_net-2006/hunch_net-2006-12-12-Interesting_Papers_at_NIPS_2006.html">224 hunch net-2006-12-12-Interesting Papers at NIPS 2006</a></p>
<p>11 0.11382838 <a title="143-tfidf-11" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>12 0.11376613 <a title="143-tfidf-12" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>13 0.10907395 <a title="143-tfidf-13" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>14 0.10536919 <a title="143-tfidf-14" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>15 0.10330876 <a title="143-tfidf-15" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>16 0.10313086 <a title="143-tfidf-16" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>17 0.10207035 <a title="143-tfidf-17" href="../hunch_net-2007/hunch_net-2007-10-14-NIPS_workshp%3A_Learning_Problem_Design.html">265 hunch net-2007-10-14-NIPS workshp: Learning Problem Design</a></p>
<p>18 0.10058565 <a title="143-tfidf-18" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>19 0.097560719 <a title="143-tfidf-19" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>20 0.096676044 <a title="143-tfidf-20" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.217), (1, -0.143), (2, 0.015), (3, 0.017), (4, -0.111), (5, 0.008), (6, -0.037), (7, 0.008), (8, -0.002), (9, 0.01), (10, -0.084), (11, 0.089), (12, 0.048), (13, 0.059), (14, 0.042), (15, -0.143), (16, 0.021), (17, 0.064), (18, 0.061), (19, -0.08), (20, 0.032), (21, 0.058), (22, 0.15), (23, -0.087), (24, 0.015), (25, -0.037), (26, -0.021), (27, -0.035), (28, -0.057), (29, 0.007), (30, -0.041), (31, 0.03), (32, 0.054), (33, -0.036), (34, -0.059), (35, -0.067), (36, 0.124), (37, -0.082), (38, 0.03), (39, 0.111), (40, 0.048), (41, -0.037), (42, 0.021), (43, -0.018), (44, 0.122), (45, 0.063), (46, -0.037), (47, -0.039), (48, -0.118), (49, -0.013)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96020025 <a title="143-lsi-1" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>Introduction: One of the common trends in machine learning has been an emphasis on the use
of unlabeled data. The argument goes something like "there aren't many labeled
web pages out there, but there are ahugenumber of web pages, so we must find a
way to take advantage of them." There are several standard approaches for
doing this:Unsupervised Learning. You use only unlabeled data. In a typical
application, you cluster the data and hope that the clusters somehow
correspond to what you care about.Semisupervised Learning. You use both
unlabeled and labeled data to build a predictor. The unlabeled data influences
the learned predictor in some way.Active Learning. You have unlabeled data and
access to a labeling oracle. You interactively choose which examples to label
so as to optimize prediction accuracy.It seems there is a fourth approach
worth serious investigation--automated labeling. The approach goes as
follows:Identify some subset of observed values to predict from the
others.Build a predictor.U</p><p>2 0.79814553 <a title="143-lsi-2" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>Introduction: Fernando Pereirapointed outAndo andZhang'spaperon "structural" learning.
Structural learning is multitask learning on subproblems created from
unlabeled data.The basic idea is to take a look at the unlabeled data and
create many supervised problems. On text data, which they test on, these
subproblems might be of the form "Given surrounding words predict the middle
word". The hope here is that successfully predicting on these subproblems is
relevant to the prediction of your core problem.In the long run, the precise
mechanism used (essentially, linear predictors with parameters tied by a
common matrix) and the precise problems formed may not be critical. What seems
critical is that the hope is realized: the technique provides a significant
edge in practice.Some basic questions about this approach are:Are there
effective automated mechanisms for creating the subproblems?Is it necessary to
use a shared representation?</p><p>3 0.6716277 <a title="143-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>Introduction: Often, unlabeled data is easy to come by but labels are expensive. For
instance, if you're building a speech recognizer, it's easy enough to get raw
speech samples -- just walk around with a microphone -- but labeling even one
of these samples is a tedious process in which a human must examine the speech
signal and carefully segment it into phonemes. In the field of active
learning, the goal is as usual to construct an accurate classifier, but the
labels of the data points are initially hidden and there is a charge for each
label you want revealed. The hope is that by intelligent adaptive querying,
you can get away with significantly fewer labels than you would need in a
regular supervised learning framework.Here's an example. Suppose the data lie
on the real line, and the classifiers are simple thresholding functions, H =
{hw}:hw(x) = 1 if x > w, and 0 otherwise.VC theory tells us that if the
underlying distribution P can be classified perfectly by some hypothesis in H
(called thereal</p><p>4 0.63720077 <a title="143-lsi-4" href="../hunch_net-2005/hunch_net-2005-04-25-Embeddings%3A_what_are_they_good_for%3F.html">61 hunch net-2005-04-25-Embeddings: what are they good for?</a></p>
<p>Introduction: I've been looking at some recent embeddings work, and am struck by how
beautiful the theory and algorithms are. It also makes me wonder, what are
embeddings good for?A few things immediately come to mind:(1) For
visualization of high-dimensional data sets.In this case, one would like good
algorithms for embedding specifically into 2- and 3-dimensional Euclidean
spaces.(2) For nonparametric modeling.The usual nonparametric models
(histograms, nearest neighbor) often require resources which are exponential
in the dimension. So if the data actually lie close to some low-
dimensionalsurface, it might be a good idea to first identify this surface and
embed the data before applying the model.Incidentally, for applications like
these, it's important to have a functional mapping from high to low dimension,
which some techniques do not yield up.(3) As a prelude to classifier
learning.The hope here is presumably that learning will be easier in the low-
dimensional space, because of (i) better ge</p><p>5 0.62650371 <a title="143-lsi-5" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>Introduction: I recently discovered that supervised learning is a controversial term. The
two definitions are:Known LossSupervised learning corresponds to the situation
where you have unlabeled examples plus knowledge of the loss of each possible
predicted choice. This is the definition I'm familiar and comfortable with.
One reason to prefer this definition is that the analysis of sample complexity
for this class of learning problems are all pretty similar.Any kind of
signalSupervised learning corresponds to the situation where you have
unlabeled examples plus any source of side information about what the right
choice is. This notion of supervised learning seems to subsume reinforcement
learning, which makes me uncomfortable, because it means there are two words
for the same class. This also means there isn't a convenient word to describe
the first definition.Reviews suggest there are people who are dedicated to the
second definition out there, so it can be important to discriminate which you
mean.</p><p>6 0.62536401 <a title="143-lsi-6" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>7 0.58994061 <a title="143-lsi-7" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>8 0.58984065 <a title="143-lsi-8" href="../hunch_net-2006/hunch_net-2006-12-12-Interesting_Papers_at_NIPS_2006.html">224 hunch net-2006-12-12-Interesting Papers at NIPS 2006</a></p>
<p>9 0.58513635 <a title="143-lsi-9" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>10 0.56714326 <a title="143-lsi-10" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>11 0.56196642 <a title="143-lsi-11" href="../hunch_net-2010/hunch_net-2010-08-24-Alex_Smola_starts_a_blog.html">408 hunch net-2010-08-24-Alex Smola starts a blog</a></p>
<p>12 0.56032819 <a title="143-lsi-12" href="../hunch_net-2006/hunch_net-2006-02-07-Pittsburgh_Mind_Reading_Competition.html">155 hunch net-2006-02-07-Pittsburgh Mind Reading Competition</a></p>
<p>13 0.54778832 <a title="143-lsi-13" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>14 0.53535968 <a title="143-lsi-14" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>15 0.52451992 <a title="143-lsi-15" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>16 0.52232367 <a title="143-lsi-16" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>17 0.50912803 <a title="143-lsi-17" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>18 0.50832045 <a title="143-lsi-18" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>19 0.49498078 <a title="143-lsi-19" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>20 0.49452558 <a title="143-lsi-20" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.031), (42, 0.295), (48, 0.029), (68, 0.038), (74, 0.516)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99705684 <a title="143-lda-1" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>Introduction: The internet has recently made the research process much smoother: papers are
easy to obtain, citations are easy to follow, and unpublished "tutorials" are
often available. Yet, new research fields can look very complicated to
outsiders or newcomers. Every paper is like a small piece of an unfinished
jigsaw puzzle: to understand just one publication, a researcher without
experience in the field will typically have to follow several layers of
citations, and many of the papers he encounters have a great deal of repeated
information. Furthermore, from one publication to the next, notation and
terminology may not be consistent which can further confuse the reader.But the
internet is now proving to be an extremely useful medium for collaboration and
knowledge aggregation. Online forums allow users to ask and answer questions
and to share ideas. The recent phenomenon of Wikipedia provides a proof-of-
concept for the "anyone can edit" system. Can such models be used to
facilitate research and</p><p>2 0.99532783 <a title="143-lda-2" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>Introduction: The health ofCOLT(Conference on Learning Theory or Computational Learning
Theory depending on who you ask) has been questioned over the last few years.
Low points for the conference occurred whenEuroCOLTmerged with COLT in 2001,
and the attendance at the 2002 Sydney COLT fell to a new low. This occurred in
the general context of machine learning conferences rising in both number and
size over the last decade.Any discussion ofwhyCOLT has had difficulties is
inherently controversial as is any story about well-intentioned people making
the wrong decisions. Nevertheless, this may be worth discussing in the hope of
avoiding problems in the future and general understanding. In any such
discussion there is a strong tendency to identify with a conference/community
in a patriotic manner that is detrimental to thinking. Keep in mind that
conferences exist to further research.My understanding (I wasn't around) is
that COLT started as a subcommunity of the computer science theory community.
This i</p><p>3 0.99423426 <a title="143-lda-3" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>4 0.99165142 <a title="143-lda-4" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>Introduction: We just finished theChicago 2005 Machine Learning Summer School. The school
was 2 weeks long with about 130 (or 140 counting the speakers) participants.
For perspective, this is perhaps the largest graduate level machine learning
class I am aware of anywhere and anytime (previousMLSSs have been close).
Overall, it seemed to go well, although the students are the real authority on
this. For those who missed it, DVDs will be available from our Slovenian
friends. EmailMrs Spela Sitarof the Jozsef Stefan Institute for details.The
following are some notes for future planning and those interested.Good
DecisionsAcquiring the larger-than-necessary "Assembly Hall" atInternational
House. Our attendance came in well above our expectations, so this was a
critical early decision that made a huge difference.The invited speakers were
key. They made a huge difference in the quality of the content.Delegating
early and often was important. One key difficulty here is gauging how much a
volunteer can (or</p><p>5 0.99002409 <a title="143-lda-5" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>6 0.98681259 <a title="143-lda-6" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>same-blog 7 0.96731424 <a title="143-lda-7" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>8 0.94481957 <a title="143-lda-8" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>9 0.928038 <a title="143-lda-9" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>10 0.92410022 <a title="143-lda-10" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>11 0.92398572 <a title="143-lda-11" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>12 0.92291397 <a title="143-lda-12" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>13 0.91923887 <a title="143-lda-13" href="../hunch_net-2007/hunch_net-2007-12-17-New_Machine_Learning_mailing_list.html">278 hunch net-2007-12-17-New Machine Learning mailing list</a></p>
<p>14 0.91643763 <a title="143-lda-14" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>15 0.9032976 <a title="143-lda-15" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>16 0.90315187 <a title="143-lda-16" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>17 0.90270376 <a title="143-lda-17" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>18 0.89684391 <a title="143-lda-18" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>19 0.89242536 <a title="143-lda-19" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>20 0.88774365 <a title="143-lda-20" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
