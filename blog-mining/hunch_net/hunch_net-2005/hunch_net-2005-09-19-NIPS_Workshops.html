<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>113 hunch net-2005-09-19-NIPS Workshops</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-113" href="#">hunch_net-2005-113</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>113 hunch net-2005-09-19-NIPS Workshops</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-113-html" href="http://hunch.net/?p=121">html</a></p><p>Introduction: Attendance at the  NIPS workshops  is highly recommended for both research and learning.   Unfortunately, there does not yet appear to be a public list of workshops. However, I found the following workshop webpages of interest:
  
  Machine Learning in Finance  
  Learning to Rank  
  Foundations of Active Learning  
  Machine Learning Based Robotics in Unstructured Environments  
  
There are  many  more workshops.  In fact, there are so many that it is not plausible anyone can attend every workshop they are interested in.  Maybe in future years the organizers can spread them out over more days to reduce overlap. 
 
Many of these workshops are accepting presentation proposals (due mid-October).</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Attendance at the  NIPS workshops  is highly recommended for both research and learning. [sent-1, score-0.662]
</p><p>2 Unfortunately, there does not yet appear to be a public list of workshops. [sent-2, score-0.426]
</p><p>3 However, I found the following workshop webpages of interest:      Machine Learning in Finance     Learning to Rank     Foundations of Active Learning     Machine Learning Based Robotics in Unstructured Environments      There are  many  more workshops. [sent-3, score-0.704]
</p><p>4 In fact, there are so many that it is not plausible anyone can attend every workshop they are interested in. [sent-4, score-0.854]
</p><p>5 Maybe in future years the organizers can spread them out over more days to reduce overlap. [sent-5, score-0.858]
</p><p>6 Many of these workshops are accepting presentation proposals (due mid-October). [sent-6, score-0.757]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('finance', 0.247), ('unstructured', 0.247), ('workshops', 0.245), ('webpages', 0.229), ('recommended', 0.229), ('environments', 0.216), ('rank', 0.206), ('spread', 0.206), ('accepting', 0.198), ('workshop', 0.192), ('foundations', 0.191), ('robotics', 0.185), ('proposals', 0.179), ('attend', 0.167), ('days', 0.16), ('attendance', 0.16), ('organizers', 0.154), ('maybe', 0.137), ('presentation', 0.135), ('highly', 0.134), ('reduce', 0.132), ('unfortunately', 0.129), ('plausible', 0.127), ('public', 0.125), ('fact', 0.119), ('appear', 0.115), ('years', 0.113), ('list', 0.107), ('active', 0.103), ('anyone', 0.102), ('following', 0.102), ('nips', 0.1), ('future', 0.093), ('interest', 0.092), ('found', 0.091), ('every', 0.09), ('many', 0.09), ('however', 0.089), ('interested', 0.086), ('due', 0.082), ('based', 0.081), ('yet', 0.079), ('machine', 0.072), ('learning', 0.059), ('research', 0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="113-tfidf-1" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>Introduction: Attendance at the  NIPS workshops  is highly recommended for both research and learning.   Unfortunately, there does not yet appear to be a public list of workshops. However, I found the following workshop webpages of interest:
  
  Machine Learning in Finance  
  Learning to Rank  
  Foundations of Active Learning  
  Machine Learning Based Robotics in Unstructured Environments  
  
There are  many  more workshops.  In fact, there are so many that it is not plausible anyone can attend every workshop they are interested in.  Maybe in future years the organizers can spread them out over more days to reduce overlap. 
 
Many of these workshops are accepting presentation proposals (due mid-October).</p><p>2 0.30453128 <a title="113-tfidf-2" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect the  NIPS 2006 workshops  to be quite interesting, and recommend going for anyone interested in machine learning research.  (Most or all of the workshops webpages can be found two links deep.)</p><p>3 0.23011647 <a title="113-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>Introduction: A good workshop is often far more interesting than the papers at a conference.  This happens because a workshop has a much tighter focus than a conference.  Since you choose the workshops fitting your interest, the increased relevance can greatly enhance the level of your interest and attention.  Roughly speaking, a workshop program consists of elements related to a subject of your interest.  The main conference program consists of elements related to someoneâ&euro;&trade;s interest (which is rarely your own).  Workshops are more about doing research while conferences are more about presenting research.  
 
Several conferences have associated workshop programs, some with deadlines due shortly.
  
 
  ICML workshops  
 Due April 1 
 
 
  IJCAI workshops  
 Deadlines Vary 
 
 
 KDD workshops 
 Not yet finalized 
 
  
Anyone going to these conferences should examine the workshops and see if any are of interest.  (If none are, then maybe you should organize one next year.)</p><p>4 0.19986349 <a title="113-tfidf-4" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">285 hunch net-2008-01-23-Why Workshop?</a></p>
<p>Introduction: I second the  call for workshops at ICML/COLT/UAI .
 
 Several   times   before , details of why and how to run a  workshop have been mentioned.  
 
There is a simple reason to prefer workshops here: attendance.  The Helsinki colocation has placed workshops  directly between ICML and COLT/UAI , which is optimal for getting attendees from any conference.  In addition,  last year ICML had relatively few workshops  and NIPS workshops were overloaded.  In addition to  those that happened  a similar number were rejected.  The overload has strange consequences—for example,  the best attended workshop  wasn’t an official NIPS workshop.  Aside from intrinsic interest, the Deep Learning workshop benefited greatly from being off schedule.</p><p>5 0.17230199 <a title="113-tfidf-5" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>Introduction: Founding a successful new conference is extraordinarily difficult.  As a conference founder, you must manage to attract a significant number of good papers—enough to entice the participants into participating next year and to (generally) to grow the conference.  For someone choosing to participate in a new conference, there is a very significant decision to make: do you send a paper to some new conference with no guarantee that the conference will work out?  Or do you send it to another (possibly less related) conference that you are sure will work?
 
The conference founding problem is a joint agreement problem with a very significant barrier.  Workshops are a way around this problem, and workshops attached to conferences are a particularly effective means for this.  A workshop at a conference is sure to have people available to speak and attend and is sure to have a large audience available.  Presenting work at a workshop is not generally exclusive: it can also be presented at a confe</p><p>6 0.17048672 <a title="113-tfidf-6" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>7 0.16028479 <a title="113-tfidf-7" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>8 0.14262959 <a title="113-tfidf-8" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>9 0.13064414 <a title="113-tfidf-9" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>10 0.12142018 <a title="113-tfidf-10" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>11 0.11749841 <a title="113-tfidf-11" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>12 0.11702563 <a title="113-tfidf-12" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>13 0.11000026 <a title="113-tfidf-13" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>14 0.10500291 <a title="113-tfidf-14" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>15 0.10376562 <a title="113-tfidf-15" href="../hunch_net-2005/hunch_net-2005-06-10-Workshops_are_not_Conferences.html">80 hunch net-2005-06-10-Workshops are not Conferences</a></p>
<p>16 0.099569149 <a title="113-tfidf-16" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>17 0.097563975 <a title="113-tfidf-17" href="../hunch_net-2010/hunch_net-2010-08-20-The_Workshop_on_Cores%2C_Clusters%2C_and_Clouds.html">404 hunch net-2010-08-20-The Workshop on Cores, Clusters, and Clouds</a></p>
<p>18 0.09481205 <a title="113-tfidf-18" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>19 0.090000831 <a title="113-tfidf-19" href="../hunch_net-2005/hunch_net-2005-03-29-Academic_Mechanism_Design.html">48 hunch net-2005-03-29-Academic Mechanism Design</a></p>
<p>20 0.08835195 <a title="113-tfidf-20" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.149), (1, -0.132), (2, -0.168), (3, -0.164), (4, 0.032), (5, 0.249), (6, 0.168), (7, 0.062), (8, 0.083), (9, 0.074), (10, 0.009), (11, 0.075), (12, 0.013), (13, 0.005), (14, -0.011), (15, -0.007), (16, -0.036), (17, 0.043), (18, 0.006), (19, -0.016), (20, -0.019), (21, 0.018), (22, 0.007), (23, 0.001), (24, 0.026), (25, -0.051), (26, 0.027), (27, 0.017), (28, 0.028), (29, 0.078), (30, -0.001), (31, 0.056), (32, -0.019), (33, 0.002), (34, -0.003), (35, 0.04), (36, -0.069), (37, 0.046), (38, 0.009), (39, -0.037), (40, -0.114), (41, -0.058), (42, -0.045), (43, -0.008), (44, -0.014), (45, -0.007), (46, 0.007), (47, -0.036), (48, 0.0), (49, 0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94550455 <a title="113-lsi-1" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>Introduction: Attendance at the  NIPS workshops  is highly recommended for both research and learning.   Unfortunately, there does not yet appear to be a public list of workshops. However, I found the following workshop webpages of interest:
  
  Machine Learning in Finance  
  Learning to Rank  
  Foundations of Active Learning  
  Machine Learning Based Robotics in Unstructured Environments  
  
There are  many  more workshops.  In fact, there are so many that it is not plausible anyone can attend every workshop they are interested in.  Maybe in future years the organizers can spread them out over more days to reduce overlap. 
 
Many of these workshops are accepting presentation proposals (due mid-October).</p><p>2 0.87837374 <a title="113-lsi-2" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>Introduction: A good workshop is often far more interesting than the papers at a conference.  This happens because a workshop has a much tighter focus than a conference.  Since you choose the workshops fitting your interest, the increased relevance can greatly enhance the level of your interest and attention.  Roughly speaking, a workshop program consists of elements related to a subject of your interest.  The main conference program consists of elements related to someoneâ&euro;&trade;s interest (which is rarely your own).  Workshops are more about doing research while conferences are more about presenting research.  
 
Several conferences have associated workshop programs, some with deadlines due shortly.
  
 
  ICML workshops  
 Due April 1 
 
 
  IJCAI workshops  
 Deadlines Vary 
 
 
 KDD workshops 
 Not yet finalized 
 
  
Anyone going to these conferences should examine the workshops and see if any are of interest.  (If none are, then maybe you should organize one next year.)</p><p>3 0.85023612 <a title="113-lsi-3" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">285 hunch net-2008-01-23-Why Workshop?</a></p>
<p>Introduction: I second the  call for workshops at ICML/COLT/UAI .
 
 Several   times   before , details of why and how to run a  workshop have been mentioned.  
 
There is a simple reason to prefer workshops here: attendance.  The Helsinki colocation has placed workshops  directly between ICML and COLT/UAI , which is optimal for getting attendees from any conference.  In addition,  last year ICML had relatively few workshops  and NIPS workshops were overloaded.  In addition to  those that happened  a similar number were rejected.  The overload has strange consequences—for example,  the best attended workshop  wasn’t an official NIPS workshop.  Aside from intrinsic interest, the Deep Learning workshop benefited greatly from being off schedule.</p><p>4 0.80370224 <a title="113-lsi-4" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect the  NIPS 2006 workshops  to be quite interesting, and recommend going for anyone interested in machine learning research.  (Most or all of the workshops webpages can be found two links deep.)</p><p>5 0.72878122 <a title="113-lsi-5" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>Introduction: (Unofficially, at least.)  The  Deep Learning Workshop  is being held the afternoon before the rest of the workshops in Vancouver, BC.  Separate registration is needed, and open.
 
Whatâ&euro;&trade;s happening fundamentally here is that there are too many interesting workshops to fit into 2 days.  Perhaps we can get it officially expanded to 3 days next year.</p><p>6 0.71678305 <a title="113-lsi-6" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>7 0.70132649 <a title="113-lsi-7" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>8 0.66891754 <a title="113-lsi-8" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>9 0.66567558 <a title="113-lsi-9" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>10 0.66248953 <a title="113-lsi-10" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>11 0.57404959 <a title="113-lsi-11" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>12 0.499116 <a title="113-lsi-12" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>13 0.48690835 <a title="113-lsi-13" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>14 0.47373518 <a title="113-lsi-14" href="../hunch_net-2010/hunch_net-2010-08-20-The_Workshop_on_Cores%2C_Clusters%2C_and_Clouds.html">404 hunch net-2010-08-20-The Workshop on Cores, Clusters, and Clouds</a></p>
<p>15 0.44692752 <a title="113-lsi-15" href="../hunch_net-2006/hunch_net-2006-07-25-Upcoming_conference.html">198 hunch net-2006-07-25-Upcoming conference</a></p>
<p>16 0.43027171 <a title="113-lsi-16" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>17 0.41454259 <a title="113-lsi-17" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>18 0.40971145 <a title="113-lsi-18" href="../hunch_net-2008/hunch_net-2008-10-01-NIPS_2008_workshop_on_%26%238216%3BLearning_over_Empirical_Hypothesis_Spaces%26%238217%3B.html">319 hunch net-2008-10-01-NIPS 2008 workshop on &#8216;Learning over Empirical Hypothesis Spaces&#8217;</a></p>
<p>19 0.40566367 <a title="113-lsi-19" href="../hunch_net-2005/hunch_net-2005-06-10-Workshops_are_not_Conferences.html">80 hunch net-2005-06-10-Workshops are not Conferences</a></p>
<p>20 0.40394735 <a title="113-lsi-20" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(22, 0.371), (27, 0.179), (55, 0.174), (95, 0.144)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.84838724 <a title="113-lda-1" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>Introduction: Attendance at the  NIPS workshops  is highly recommended for both research and learning.   Unfortunately, there does not yet appear to be a public list of workshops. However, I found the following workshop webpages of interest:
  
  Machine Learning in Finance  
  Learning to Rank  
  Foundations of Active Learning  
  Machine Learning Based Robotics in Unstructured Environments  
  
There are  many  more workshops.  In fact, there are so many that it is not plausible anyone can attend every workshop they are interested in.  Maybe in future years the organizers can spread them out over more days to reduce overlap. 
 
Many of these workshops are accepting presentation proposals (due mid-October).</p><p>2 0.84510088 <a title="113-lda-2" href="../hunch_net-2005/hunch_net-2005-09-20-Workshop_Proposal%3A_Atomic_Learning.html">114 hunch net-2005-09-20-Workshop Proposal: Atomic Learning</a></p>
<p>Introduction: This is a proposal for a workshop.  It may or may not happen depending on the level of interest.  If you are interested, feel free to indicate so (by email or comments).
 
Description: 
Assume(*) that any system for solving large difficult learning problems must decompose into repeated use of basic elements (i.e. atoms).  There are many basic questions which remain:
  
  What are the viable basic elements? 
  What makes a basic element viable? 
  What are the viable principles for the composition of these basic elements? 
  What are the viable principles for learning in such systems? 
  What problems can this approach handle? 
  
Hal Daume adds:
  
 Can composition of atoms be (semi-) automatically constructed[?] 
 When atoms are constructed through reductions, is there some notion of the “naturalness” of the created leaning problems? 
 Other than Markov fields/graphical models/Bayes nets, is there a good language for representing atoms and their compositions? 
  
The answer to these a</p><p>3 0.81277066 <a title="113-lda-3" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>Introduction: On Sept 21, there is another  machine learning meetup  where I’ll be speaking.  Although the topic is contextual bandits, I think of it as “the future of machine learning”.  In particular, it’s all about how to learn in an interactive environment, such as for ad display, trading, news recommendation, etc…
 
On Sept 24, abstracts for the  New York Machine Learning Symposium  are due.  This is the largest Machine Learning event in the area, so it’s a great way to have a conversation with other people.
 
On Oct 22, the NY ML Symposium actually happens.  This year, we are expanding the spotlights, and trying to have more time for posters.  In addition, we have a strong set of invited speakers:  David Blei ,  Sanjoy Dasgupta ,  Tommi Jaakkola , and  Yann LeCun .  After the meeting, a late  hackNY  related event is planned where students and startups can meet.
 
I’d also like to point out the related  CS/Econ symposium  as I have interests there as well.</p><p>4 0.62738252 <a title="113-lda-4" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>Introduction: There are many ways that interesting research gets done.  For example it’s common at a conference for someone to discuss a problem with a partial solution, and for someone else to know how to solve a piece of it, resulting in a paper.  In some sense,  these are the easiest results we can achieve, so we should ask: Can all research be this easy?  
 
The answer is certainly no for fields where research inherently requires  experimentation to discover how the real world works.  However, mathematics, including parts of physics, computer science, statistics, etc… which are effectively mathematics don’t require experimentation. In effect, a paper can be simply a pure expression of thinking.  Can all mathematical-style research be this easy?
 
What’s going on here is research-by-communication.  Someone knows something, someone knows something else, and as soon as someone knows both things, a problem is solved.  The interesting thing about research-by-communication is that it is becoming radic</p><p>5 0.56988704 <a title="113-lda-5" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pool  and I recently discussed the similarities and differences between academia and open source programming.   
 
Similarities:
  
  Cost profile   Research and programming share approximately the same cost profile: A large upfront effort is required to produce something useful, and then “anyone” can use it.  (The “anyone” is not quite right for either group because only sufficiently technical people could use it.) 
  Wealth profile  A “wealthy” academic or open source programmer is someone who has contributed a lot to other people in research or programs.  Much of academia is a “gift culture”: whoever gives the most is most respected. 
  Problems   Both academia and open source programming suffer from similar problems.
 
 Whether or not (and which) open source program is used are perhaps too-often personality driven rather than driven by capability or usefulness.  Similar phenomena can happen in academia with respect to directions of research. 
 Funding is often a problem for</p><p>6 0.56622136 <a title="113-lda-6" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>7 0.54779738 <a title="113-lda-7" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>8 0.54668331 <a title="113-lda-8" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>9 0.54551458 <a title="113-lda-9" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>10 0.54520446 <a title="113-lda-10" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>11 0.53690344 <a title="113-lda-11" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<p>12 0.5358336 <a title="113-lda-12" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>13 0.53357381 <a title="113-lda-13" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>14 0.53142595 <a title="113-lda-14" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>15 0.53093469 <a title="113-lda-15" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>16 0.530698 <a title="113-lda-16" href="../hunch_net-2012/hunch_net-2012-02-24-ICML%2B50%25.html">456 hunch net-2012-02-24-ICML+50%</a></p>
<p>17 0.53010416 <a title="113-lda-17" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>18 0.52893734 <a title="113-lda-18" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>19 0.52736664 <a title="113-lda-19" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>20 0.52539718 <a title="113-lda-20" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
