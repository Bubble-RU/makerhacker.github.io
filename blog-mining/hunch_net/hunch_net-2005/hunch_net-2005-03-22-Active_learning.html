<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>45 hunch net-2005-03-22-Active learning</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-45" href="#">hunch_net-2005-45</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>45 hunch net-2005-03-22-Active learning</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-45-html" href="http://hunch.net/?p=49">html</a></p><p>Introduction: Often, unlabeled data is easy to come by but labels are expensive. For instance, if you’re building a speech recognizer, it’s easy enough to get raw speech samples — just walk around with a microphone — but labeling even one of these samples is a tedious process in which a human must examine the speech signal and carefully segment it into phonemes. In the field of active learning, the goal is as usual to construct an accurate classifier, but the labels of the data points are initially hidden and there is a charge for each label you want revealed. The hope is that by intelligent adaptive querying, you can get away with significantly fewer labels than you would need in a regular supervised learning framework.
 
Here’s an example. Suppose the data lie on the real line, and the classifiers are simple thresholding functions, H = {h w }: 
  h w (x) = 1 if x > w, and 0 otherwise.  
 
VC theory tells us that if the underlying distribution P can be classified perfectly by some hypothesis in H (</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Often, unlabeled data is easy to come by but labels are expensive. [sent-1, score-0.626]
</p><p>2 For instance, if you’re building a speech recognizer, it’s easy enough to get raw speech samples — just walk around with a microphone — but labeling even one of these samples is a tedious process in which a human must examine the speech signal and carefully segment it into phonemes. [sent-2, score-0.847]
</p><p>3 In the field of active learning, the goal is as usual to construct an accurate classifier, but the labels of the data points are initially hidden and there is a charge for each label you want revealed. [sent-3, score-1.199]
</p><p>4 The hope is that by intelligent adaptive querying, you can get away with significantly fewer labels than you would need in a regular supervised learning framework. [sent-4, score-0.418]
</p><p>5 Suppose the data lie on the real line, and the classifiers are simple thresholding functions, H = {h w }:    h w (x) = 1 if x > w, and 0 otherwise. [sent-6, score-0.251]
</p><p>6 But suppose we instead draw  m   unlabeled  samples from P. [sent-8, score-0.543]
</p><p>7 If we lay these points down on the line, their hidden labels are a sequence of 0′s followed by a sequence of 1′s, and the goal is to discover the point  w  at which the transition occurs. [sent-9, score-0.773]
</p><p>8 This can be accomplished with a simple binary search which asks for just  log m  labels. [sent-10, score-0.187]
</p><p>9 Thus active learning gives us an exponential improvement in the number of labels needed: by adaptively querying  log m  labels, we can automatically infer the rest of them. [sent-11, score-1.073]
</p><p>10 To date, the single main theoretical result in the field is  [FSST97] ‘s analysis of the query-by-committee (QBC) learning algorithm. [sent-13, score-0.167]
</p><p>11 In their model, the learner observes a stream of unlabeled data and makes spot decisions about whether or not to ask for a point’s label. [sent-14, score-0.479]
</p><p>12 They show that if the data is drawn uniformly from the surface of the d-dimensional unit sphere, and the hidden labels correspond perfectly to a homogeneous (i. [sent-15, score-0.844]
</p><p>13 This remarkable result is tempered somewhat by the complexity of the QBC algorithm, which involves computing volumes of intermediate version spaces. [sent-18, score-0.195]
</p><p>14 Some recent progress on active learning: [DKM05] show how a simple variant of the perceptron update can be used to achieve these same sample complexity bounds, in the same model. [sent-19, score-0.683]
</p><p>15 [D04]  shows a variety of upper and lower bounds for active learning — for instance, if you allow linear separators which are non-homogeneous then in the above model the sample complexity necessarily shoots up to  1/e . [sent-20, score-0.775]
</p><p>16 The theoretical terrain of active learning remains something of an unexplored wilderness. [sent-21, score-0.296]
</p><p>17 There has, however, been a lot of beautiful theory work (see [A02] for a roundup) on a related model in which the learner is allowed to synthesize query points, rather than simply choosing them from the pool of unlabeled data. [sent-22, score-0.574]
</p><p>18 This ran into some practical problems: [BL92] found that the resulting synthetic instances were often very difficult for a human to classify! [sent-23, score-0.11]
</p><p>19 Query learning can work poorly when a human oracle is used. [sent-30, score-0.181]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('labels', 0.341), ('active', 0.225), ('unlabeled', 0.187), ('qbc', 0.172), ('draw', 0.153), ('querying', 0.153), ('speech', 0.146), ('separators', 0.142), ('hidden', 0.134), ('usual', 0.128), ('points', 0.124), ('learner', 0.123), ('perfectly', 0.118), ('line', 0.118), ('complexity', 0.118), ('samples', 0.114), ('human', 0.11), ('classifier', 0.106), ('query', 0.106), ('log', 0.105), ('sample', 0.105), ('instance', 0.101), ('linear', 0.098), ('data', 0.098), ('exponential', 0.094), ('analysis', 0.089), ('suppose', 0.089), ('model', 0.087), ('sequence', 0.087), ('improvement', 0.084), ('simple', 0.082), ('show', 0.082), ('field', 0.078), ('supervised', 0.077), ('classified', 0.077), ('intermediate', 0.077), ('origin', 0.077), ('separator', 0.077), ('achieve', 0.071), ('classify', 0.071), ('surface', 0.071), ('adaptively', 0.071), ('charge', 0.071), ('lie', 0.071), ('poorly', 0.071), ('sphere', 0.071), ('spot', 0.071), ('synthesize', 0.071), ('tedious', 0.071), ('unexplored', 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="45-tfidf-1" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>Introduction: Often, unlabeled data is easy to come by but labels are expensive. For instance, if you’re building a speech recognizer, it’s easy enough to get raw speech samples — just walk around with a microphone — but labeling even one of these samples is a tedious process in which a human must examine the speech signal and carefully segment it into phonemes. In the field of active learning, the goal is as usual to construct an accurate classifier, but the labels of the data points are initially hidden and there is a charge for each label you want revealed. The hope is that by intelligent adaptive querying, you can get away with significantly fewer labels than you would need in a regular supervised learning framework.
 
Here’s an example. Suppose the data lie on the real line, and the classifiers are simple thresholding functions, H = {h w }: 
  h w (x) = 1 if x > w, and 0 otherwise.  
 
VC theory tells us that if the underlying distribution P can be classified perfectly by some hypothesis in H (</p><p>2 0.2220706 <a title="45-tfidf-2" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.
 
In selective sampling style active learning, a learning algorithm chooses which examples to label.  We now have an active learning algorithm that is:
  
  Efficient  in label complexity, unlabeled complexity, and computational complexity. 
  Competitive  with supervised learning anywhere that supervised learning works. 
  Compatible  with online learning, with any optimization-based learning algorithm, with any loss function, with offline testing, and even with changing learning algorithms. 
  Empirically  effective. 
  
The basic idea is to combine  disagreement region-based sampling  with  importance weighting : an example is selected to be labeled with probability proportional to how useful it is for distinguishing among near-optimal classifiers, and labeled examples are importance-weighted by the inverse of these probabilities.  The combination of these simple ideas removes the  sampling bias  problem that has plagued many previous he</p><p>3 0.20020176 <a title="45-tfidf-3" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>Introduction: Exploration is one of the big unsolved problems in machine learning. This isn’t for lack of trying—there are many models of exploration which have been analyzed in many different ways by many different groups of people. At some point, it is worthwhile to sit back and see what has been done across these many models.
  
   Reinforcement Learning  (1) . Reinforcement learning has traditionally focused on Markov Decision Processes where the next state  s’    is given by a conditional distribution  P(s’|s,a)  given the current state  s  and action  a .  The typical result here is that certain specific algorithms controlling an agent can behave within  e  of optimal for horizon  T  except for  poly(1/e,T,S,A)  “wasted” experiences (with high probability).  This started with  E 3   by  Satinder Singh  and  Michael Kearns .  Sham Kakade’s thesis  has significant discussion. Extensions have typically been of the form “under extra assumptions, we can prove more”, for example  Factored-E 3   and</p><p>4 0.19851036 <a title="45-tfidf-4" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>Introduction: Several bits of progress have been made since  Sanjoy  pointed out the significant  lack of theoretical understanding of active learning .  This is an update on the progress I know of.  As a refresher, active learning as meant here is:
  
 There is a source of unlabeled data. 
 There is an oracle from which labels can be requested for unlabeled data produced by the source. 
 The goal is to perform well with minimal use of the oracle. 
  
Here is what I’ve learned:
  
 Sanjoy has developed sufficient and semi-necessary conditions for active learning given the assumptions of IID data and “realizability” (that one of the classifiers is a correct classifier). 
  Nina ,  Alina , and I developed an algorithm for active learning relying on only the assumption of IID data.  A draft is  here . 
  Nicolo ,  Claudio , and  Luca  showed that it is possible to do active learning in an entirely adversarial setting for linear threshold classifiers  here .  This was published a year or two ago and I r</p><p>5 0.17460634 <a title="45-tfidf-5" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>Introduction: This is a summary of the  workshop on Learning Problem Design  which  Alina  and I ran at  NIPS  this year.
 
The first question many people have is “What is learning problem design?”  This workshop is about admitting that solving learning problems does not start with labeled data, but rather somewhere before.  When humans are hired to produce labels, this is usually not a serious problem because you can tell them precisely what semantics you want the labels to have, and we can fix some set of features in advance.  However, when other methods are used this becomes more problematic.  This focus is important for Machine Learning because there are very large quantities of data which are not labeled by a hired human.
 
The title of the workshop was a bit ambitious, because a workshop is not long enough to synthesize a diversity of approaches into a coherent set of principles.  For me, the posters at the end of the workshop were quite helpful in getting approaches to gel.
 
Here are some an</p><p>6 0.15045857 <a title="45-tfidf-6" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>7 0.14019001 <a title="45-tfidf-7" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>8 0.13619636 <a title="45-tfidf-8" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>9 0.13270521 <a title="45-tfidf-9" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>10 0.12595662 <a title="45-tfidf-10" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>11 0.12281545 <a title="45-tfidf-11" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>12 0.11786484 <a title="45-tfidf-12" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>13 0.11483246 <a title="45-tfidf-13" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>14 0.11479078 <a title="45-tfidf-14" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>15 0.10825843 <a title="45-tfidf-15" href="../hunch_net-2005/hunch_net-2005-04-25-Embeddings%3A_what_are_they_good_for%3F.html">61 hunch net-2005-04-25-Embeddings: what are they good for?</a></p>
<p>16 0.10617594 <a title="45-tfidf-16" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>17 0.10267827 <a title="45-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>18 0.10149065 <a title="45-tfidf-18" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>19 0.10114197 <a title="45-tfidf-19" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>20 0.099980749 <a title="45-tfidf-20" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.231), (1, 0.147), (2, 0.002), (3, -0.077), (4, 0.15), (5, -0.038), (6, 0.028), (7, -0.007), (8, 0.049), (9, -0.045), (10, 0.099), (11, 0.027), (12, -0.101), (13, 0.056), (14, -0.15), (15, -0.064), (16, -0.072), (17, 0.105), (18, -0.06), (19, -0.025), (20, 0.025), (21, 0.036), (22, 0.058), (23, 0.005), (24, 0.083), (25, -0.078), (26, 0.025), (27, 0.022), (28, 0.004), (29, -0.14), (30, 0.078), (31, 0.027), (32, 0.044), (33, -0.004), (34, -0.001), (35, -0.029), (36, 0.042), (37, -0.016), (38, -0.053), (39, -0.101), (40, -0.101), (41, -0.039), (42, 0.061), (43, -0.123), (44, 0.083), (45, 0.092), (46, 0.055), (47, 0.049), (48, -0.02), (49, 0.063)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97679138 <a title="45-lsi-1" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>Introduction: Often, unlabeled data is easy to come by but labels are expensive. For instance, if you’re building a speech recognizer, it’s easy enough to get raw speech samples — just walk around with a microphone — but labeling even one of these samples is a tedious process in which a human must examine the speech signal and carefully segment it into phonemes. In the field of active learning, the goal is as usual to construct an accurate classifier, but the labels of the data points are initially hidden and there is a charge for each label you want revealed. The hope is that by intelligent adaptive querying, you can get away with significantly fewer labels than you would need in a regular supervised learning framework.
 
Here’s an example. Suppose the data lie on the real line, and the classifiers are simple thresholding functions, H = {h w }: 
  h w (x) = 1 if x > w, and 0 otherwise.  
 
VC theory tells us that if the underlying distribution P can be classified perfectly by some hypothesis in H (</p><p>2 0.71529496 <a title="45-lsi-2" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.
 
In selective sampling style active learning, a learning algorithm chooses which examples to label.  We now have an active learning algorithm that is:
  
  Efficient  in label complexity, unlabeled complexity, and computational complexity. 
  Competitive  with supervised learning anywhere that supervised learning works. 
  Compatible  with online learning, with any optimization-based learning algorithm, with any loss function, with offline testing, and even with changing learning algorithms. 
  Empirically  effective. 
  
The basic idea is to combine  disagreement region-based sampling  with  importance weighting : an example is selected to be labeled with probability proportional to how useful it is for distinguishing among near-optimal classifiers, and labeled examples are importance-weighted by the inverse of these probabilities.  The combination of these simple ideas removes the  sampling bias  problem that has plagued many previous he</p><p>3 0.68892831 <a title="45-lsi-3" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>Introduction: Several bits of progress have been made since  Sanjoy  pointed out the significant  lack of theoretical understanding of active learning .  This is an update on the progress I know of.  As a refresher, active learning as meant here is:
  
 There is a source of unlabeled data. 
 There is an oracle from which labels can be requested for unlabeled data produced by the source. 
 The goal is to perform well with minimal use of the oracle. 
  
Here is what I’ve learned:
  
 Sanjoy has developed sufficient and semi-necessary conditions for active learning given the assumptions of IID data and “realizability” (that one of the classifiers is a correct classifier). 
  Nina ,  Alina , and I developed an algorithm for active learning relying on only the assumption of IID data.  A draft is  here . 
  Nicolo ,  Claudio , and  Luca  showed that it is possible to do active learning in an entirely adversarial setting for linear threshold classifiers  here .  This was published a year or two ago and I r</p><p>4 0.68202049 <a title="45-lsi-4" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>Introduction: One of the common trends in machine learning has been an emphasis on the use of unlabeled data.  The argument goes something like “there aren’t many labeled web pages out there, but there are a  huge  number of web pages, so we must find a way to take advantage of them.”  There are several standard approaches for doing this:
  
  Unsupervised Learning .  You use only unlabeled data.  In a typical application, you cluster the data and hope that the clusters somehow correspond to what you care about. 
 Semisupervised Learning.  You use both unlabeled and labeled data to build a predictor.  The unlabeled data influences the learned predictor in some way. 
  Active Learning . You have unlabeled data and access to a labeling oracle.  You interactively choose which examples to label so as to optimize prediction accuracy. 
  
It seems there is a fourth approach worth serious investigation—automated labeling.  The approach goes as follows:
  
 Identify some subset of observed values to predict</p><p>5 0.62377584 <a title="45-lsi-5" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>Introduction: Exploration is one of the big unsolved problems in machine learning. This isn’t for lack of trying—there are many models of exploration which have been analyzed in many different ways by many different groups of people. At some point, it is worthwhile to sit back and see what has been done across these many models.
  
   Reinforcement Learning  (1) . Reinforcement learning has traditionally focused on Markov Decision Processes where the next state  s’    is given by a conditional distribution  P(s’|s,a)  given the current state  s  and action  a .  The typical result here is that certain specific algorithms controlling an agent can behave within  e  of optimal for horizon  T  except for  poly(1/e,T,S,A)  “wasted” experiences (with high probability).  This started with  E 3   by  Satinder Singh  and  Michael Kearns .  Sham Kakade’s thesis  has significant discussion. Extensions have typically been of the form “under extra assumptions, we can prove more”, for example  Factored-E 3   and</p><p>6 0.61724055 <a title="45-lsi-6" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>7 0.59688479 <a title="45-lsi-7" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>8 0.55629343 <a title="45-lsi-8" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>9 0.5367282 <a title="45-lsi-9" href="../hunch_net-2006/hunch_net-2006-12-12-Interesting_Papers_at_NIPS_2006.html">224 hunch net-2006-12-12-Interesting Papers at NIPS 2006</a></p>
<p>10 0.52969354 <a title="45-lsi-10" href="../hunch_net-2005/hunch_net-2005-12-11-More_NIPS_Papers.html">139 hunch net-2005-12-11-More NIPS Papers</a></p>
<p>11 0.51916796 <a title="45-lsi-11" href="../hunch_net-2005/hunch_net-2005-04-25-Embeddings%3A_what_are_they_good_for%3F.html">61 hunch net-2005-04-25-Embeddings: what are they good for?</a></p>
<p>12 0.51607388 <a title="45-lsi-12" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>13 0.51460314 <a title="45-lsi-13" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>14 0.51080078 <a title="45-lsi-14" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>15 0.4957203 <a title="45-lsi-15" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>16 0.49234426 <a title="45-lsi-16" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>17 0.49195847 <a title="45-lsi-17" href="../hunch_net-2006/hunch_net-2006-02-07-Pittsburgh_Mind_Reading_Competition.html">155 hunch net-2006-02-07-Pittsburgh Mind Reading Competition</a></p>
<p>18 0.48752564 <a title="45-lsi-18" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>19 0.48148739 <a title="45-lsi-19" href="../hunch_net-2009/hunch_net-2009-01-23-An_Active_Learning_Survey.html">338 hunch net-2009-01-23-An Active Learning Survey</a></p>
<p>20 0.46673933 <a title="45-lsi-20" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.031), (10, 0.039), (27, 0.665), (33, 0.022), (38, 0.012), (53, 0.025), (55, 0.034), (94, 0.066), (95, 0.024)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99916285 <a title="45-lda-1" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>Introduction: Often, unlabeled data is easy to come by but labels are expensive. For instance, if you’re building a speech recognizer, it’s easy enough to get raw speech samples — just walk around with a microphone — but labeling even one of these samples is a tedious process in which a human must examine the speech signal and carefully segment it into phonemes. In the field of active learning, the goal is as usual to construct an accurate classifier, but the labels of the data points are initially hidden and there is a charge for each label you want revealed. The hope is that by intelligent adaptive querying, you can get away with significantly fewer labels than you would need in a regular supervised learning framework.
 
Here’s an example. Suppose the data lie on the real line, and the classifiers are simple thresholding functions, H = {h w }: 
  h w (x) = 1 if x > w, and 0 otherwise.  
 
VC theory tells us that if the underlying distribution P can be classified perfectly by some hypothesis in H (</p><p>2 0.99566483 <a title="45-lda-2" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>Introduction: Consider the contextual bandit setting where, repeatedly:
  
 A context  x  is observed. 
 An action  a  is taken given the context  x .  
 A reward  r  is observed, dependent on  x  and  a . 
  
Where the goal of a learning agent is to find a policy for step 2 achieving a large expected reward.  
 
This setting is of obvious importance, because in the real world we typically make decisions based on some set of information and then get feedback only about the single action taken.  It also fundamentally differs from supervised learning settings because knowing the value of one action is not equivalent to knowing the value of all actions.
 
A decade ago the best machine learning techniques for this setting where implausibly inefficient.   Dean Foster  once told me he thought the area was a research sinkhole with little progress to be expected.  Now we are on the verge of being able to routinely attack these problems, in almost exactly the same sense that we routinely attack bread and but</p><p>3 0.99298388 <a title="45-lda-3" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner independent of the loss function itself.  
  
 Optimizing squared loss  l sq (y,y’)=(y-y’) 2   means predicting the (conditional) mean of  y . 
 Optimizing absolute value loss  l av (y,y’)=|y-y’|  means predicting the (conditional) median of  y .  Variants can  handle other quantiles .  0/1 loss for classification is a special case. 
 Optimizing log loss  l log (y,y’)=log (1/Pr z~y’ (z=y))  means minimizing the description length of  y . 
  
The semantics (= meaning) of the loss are made explicit by a theorem in each case.  For squared loss, we can prove a theorem of the form: 
For all distributions  D  over  Y , if    y’ = arg min y’  E y ~ D  l sq  (y,y’)   then   y’ = E y~D  y  
 
Similar theorems hold for the other examples above, and they can all be extended to predictors of  y’  for distributions  D  over a context  X  and a value  Y .
 
There are 3 points to this post.
  
 Everyone doing general machine lear</p><p>4 0.99251062 <a title="45-lda-4" href="../hunch_net-2006/hunch_net-2006-04-14-JMLR_is_a_success.html">172 hunch net-2006-04-14-JMLR is a success</a></p>
<p>Introduction: In 2001, the “ Journal of Machine Learning Research ” was created in reaction to unadaptive  publisher policies at  MLJ .  Essentially, with the creation of the internet, the bottleneck in publishing research shifted from publishing to research.  The  declaration of independence  accompanying this move expresses the reasons why in greater detail.
 
MLJ has strongly changed its policy in reaction to this.  In particular, there is no longer an assignment of copyright to the publisher (*), and MLJ regularly sponsors many student “best paper awards” across several conferences with cash prizes.  This is an advantage of MLJ over JMLR: MLJ can afford to sponsor cash prizes for the machine learning community.  The remaining disadvantage is that reading papers in MLJ sometimes requires searching for the author’s website where the free version is available.  In contrast, JMLR articles are freely available to everyone off the JMLR website.  Whether or not this disadvantage cancels the advantage i</p><p>5 0.99127984 <a title="45-lda-5" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<p>Introduction: Here are two papers that seem particularly interesting at this year’s COLT.
  
  Gilles Blanchard  and  FranÃƒÂ§ois Fleuret ,  Occam’s Hammer .  When we are interested in very tight bounds on the true error rate of a classifier, it is tempting to use a PAC-Bayes bound which can (empirically) be  quite tight .  A disadvantage of the PAC-Bayes bound is that it applies to a classifier which is randomized over a set of base classifiers rather than a single classifier.  This paper shows that a similar bound can be proved which holds for a single classifier drawn from the set.   The ability to safely use a single classifier is very nice.  This technique applies generically to any base bound, so it has other applications covered in the paper. 
  Adam Tauman Kalai .  Learning Nested Halfspaces and Uphill Decision Trees .  Classification PAC-learning, where you prove that any problem amongst some set is polytime learnable with respect to any distribution over the input  X  is extraordinarily ch</p><p>6 0.99053317 <a title="45-lda-6" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>7 0.99044371 <a title="45-lda-7" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>8 0.98906446 <a title="45-lda-8" href="../hunch_net-2006/hunch_net-2006-03-24-NLPers.html">166 hunch net-2006-03-24-NLPers</a></p>
<p>9 0.98906446 <a title="45-lda-9" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>10 0.98906446 <a title="45-lda-10" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>11 0.98897564 <a title="45-lda-11" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>12 0.98834008 <a title="45-lda-12" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>13 0.98554146 <a title="45-lda-13" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>14 0.98300034 <a title="45-lda-14" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>15 0.98010039 <a title="45-lda-15" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>16 0.97503316 <a title="45-lda-16" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>17 0.96885556 <a title="45-lda-17" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>18 0.96042174 <a title="45-lda-18" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>19 0.95779109 <a title="45-lda-19" href="../hunch_net-2013/hunch_net-2013-06-10-The_Large_Scale_Learning_class_notes.html">483 hunch net-2013-06-10-The Large Scale Learning class notes</a></p>
<p>20 0.95600313 <a title="45-lda-20" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
