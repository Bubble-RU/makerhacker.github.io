<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>122 hunch net-2005-10-13-Site tweak</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-122" href="#">hunch_net-2005-122</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>122 hunch net-2005-10-13-Site tweak</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-122-html" href="http://hunch.net/?p=133">html</a></p><p>Introduction: Several people have had difficulty with comments which seem to have an allowed language significantly poorer than posts.  The set of allowed html tags has been increased and the  markdown filter  has been put in place to try to make commenting easier.  Iâ&euro;&trade;ll put some examples into the comments of this post.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Several people have had difficulty with comments which seem to have an allowed language significantly poorer than posts. [sent-1, score-1.433]
</p><p>2 The set of allowed html tags has been increased and the  markdown filter  has been put in place to try to make commenting easier. [sent-2, score-2.433]
</p><p>3 Iâ&euro;&trade;ll put some examples into the comments of this post. [sent-3, score-0.848]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('allowed', 0.421), ('put', 0.389), ('comments', 0.359), ('commenting', 0.344), ('html', 0.319), ('filter', 0.244), ('increased', 0.238), ('place', 0.169), ('language', 0.167), ('significantly', 0.164), ('difficulty', 0.157), ('try', 0.142), ('ll', 0.136), ('post', 0.128), ('seem', 0.112), ('examples', 0.1), ('set', 0.091), ('make', 0.076), ('several', 0.066), ('people', 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="122-tfidf-1" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>Introduction: Several people have had difficulty with comments which seem to have an allowed language significantly poorer than posts.  The set of allowed html tags has been increased and the  markdown filter  has been put in place to try to make commenting easier.  Iâ&euro;&trade;ll put some examples into the comments of this post.</p><p>2 0.13421284 <a title="122-tfidf-2" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>Introduction: At the  last ICML ,  Tom Dietterich  asked me to look into systems for commenting on papers.  I’ve been slow getting to this, but it’s relevant now.
 
The essential observation is that we now have many tools for online collaboration, but they are not yet much used in academic research.  If we can find the right way to use them, then perhaps great things might happen, with extra kudos to the first conference that manages to really create an online community.  Various conferences have been poking at this.  For example,  UAI has setup a wiki , COLT has  started using   Joomla , with some dynamic content, and AAAI has been setting up a “ student blog “.  Similarly,  Dinoj Surendran  setup a twiki for the  Chicago Machine Learning Summer School , which was quite useful for coordinating events and other things.
 
I believe the most important thing is a willingness to experiment.  A good place to start seems to be enhancing existing conference websites.  For example, the  ICML 2007 papers pag</p><p>3 0.11789598 <a title="122-tfidf-3" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>Introduction: A substantial difficulty with the 2009 and 2008  ICML discussion system  was a communication vacuum, where authors were not informed of comments, and commenters were not informed of responses to their comments without explicit monitoring.   Mark Reid  has setup a  new discussion system for 2010  with the goal of addressing this.
 
Mark didn’t want to make it to intrusive, so you must opt-in.  As an author,  find your paper  and “Subscribe by email” to the comments.  As a commenter, you have the option of providing an email for follow-up notification.</p><p>4 0.1062701 <a title="122-tfidf-4" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>Introduction: Andrej Bauer has setup a  Mathematics and Computation  Blog.  As a first step he has tried to address the persistent and annoying problem of math on the web.  As a basic tool for precisely stating and transfering understanding of technical subjects, mathematics is very necessary.  Despite this necessity, every mechanism for expressing mathematics on the web seems unnaturally clumsy.  Here are some of the methods and their drawbacks:
  
  MathML   This was supposed to be the answer, but it has two severe drawbacks: “Internet Explorer” doesn’t read it and the language is an example of push-XML-to-the-limit which no one would ever consider writing in.  (In contrast, html is easy to write in.)  It’s also very annoying that math fonts must be installed independent of the browser, even for mozilla based browsers. 
 Create inline images.  This has several big drawbacks: font size is fixed for all viewers, you can’t cut & paste inside the images, and you can’t hyperlink from (say) symbol to de</p><p>5 0.090856783 <a title="122-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>Introduction: This is near the one month point, so it seems appropriate to consider meta-issues for the moment.
 
The number of posts is a bit over 20. 
The number of people speaking up in discussions is about 10. 
The number of people viewing the site is somewhat more than 100.
 
I am (naturally) dissatisfied with many things.
  
 Many of the  potential uses  haven’t been realized.  This is partly a matter of opportunity (no conferences in the last month), partly a matter of will (no open problems because it’s hard to give them up), and partly a matter of tradition.  In academia, there is a strong tradition of trying to get everything perfectly right before presentation.  This is somewhat contradictory to the nature of making many posts, and it’s definitely contradictory to the idea of doing “public research”.  If that sort of idea is to pay off, it must be significantly more succesful than previous methods. In an effort to continue experimenting, I’m going to use the next week as “open problems we</p><p>6 0.087474056 <a title="122-tfidf-6" href="../hunch_net-2008/hunch_net-2008-11-26-Efficient_Reinforcement_Learning_in_MDPs.html">328 hunch net-2008-11-26-Efficient Reinforcement Learning in MDPs</a></p>
<p>7 0.081540063 <a title="122-tfidf-7" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>8 0.081149131 <a title="122-tfidf-8" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>9 0.08083079 <a title="122-tfidf-9" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>10 0.078225806 <a title="122-tfidf-10" href="../hunch_net-2011/hunch_net-2011-08-20-The_Large_Scale_Learning_Survey_Tutorial.html">442 hunch net-2011-08-20-The Large Scale Learning Survey Tutorial</a></p>
<p>11 0.077581808 <a title="122-tfidf-11" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>12 0.076452926 <a title="122-tfidf-12" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>13 0.062969588 <a title="122-tfidf-13" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>14 0.062048212 <a title="122-tfidf-14" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>15 0.056506034 <a title="122-tfidf-15" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>16 0.055997718 <a title="122-tfidf-16" href="../hunch_net-2005/hunch_net-2005-06-22-Languages__of_Learning.html">84 hunch net-2005-06-22-Languages  of Learning</a></p>
<p>17 0.055437401 <a title="122-tfidf-17" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>18 0.054992273 <a title="122-tfidf-18" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>19 0.054708336 <a title="122-tfidf-19" href="../hunch_net-2006/hunch_net-2006-03-24-NLPers.html">166 hunch net-2006-03-24-NLPers</a></p>
<p>20 0.053520482 <a title="122-tfidf-20" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.086), (1, -0.011), (2, -0.016), (3, 0.048), (4, -0.026), (5, -0.012), (6, 0.008), (7, -0.062), (8, 0.022), (9, 0.006), (10, -0.073), (11, -0.019), (12, -0.043), (13, 0.068), (14, 0.067), (15, -0.032), (16, -0.094), (17, -0.029), (18, -0.025), (19, 0.059), (20, -0.016), (21, -0.017), (22, -0.036), (23, -0.085), (24, -0.038), (25, 0.004), (26, 0.005), (27, 0.002), (28, 0.007), (29, 0.062), (30, -0.008), (31, 0.052), (32, 0.067), (33, 0.035), (34, 0.083), (35, 0.095), (36, 0.054), (37, 0.025), (38, -0.013), (39, 0.041), (40, 0.008), (41, -0.068), (42, 0.064), (43, -0.069), (44, -0.087), (45, -0.029), (46, 0.14), (47, 0.085), (48, 0.041), (49, 0.018)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98674399 <a title="122-lsi-1" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>Introduction: Several people have had difficulty with comments which seem to have an allowed language significantly poorer than posts.  The set of allowed html tags has been increased and the  markdown filter  has been put in place to try to make commenting easier.  Iâ&euro;&trade;ll put some examples into the comments of this post.</p><p>2 0.61211312 <a title="122-lsi-2" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>Introduction: The hunch.net server has been updated.  I’ve taken the opportunity to upgrade the version of wordpress which caused cascading changes.
  
 Old threaded comments are now flattened.  The system we used to use ( Brian’s threaded comments ) appears incompatible with the new threading system built into wordpress.  I haven’t yet figured out a workaround. 
 I setup a  feedburner account . 
 I added an RSS aggregator for both Machine Learning and other research blogs that I like to follow.  This is something that I’ve wanted to do for awhile. 
 Many other minor changes in font and format, with some help from  Alina . 
  
If you have any suggestions for site tweaks, please speak up.</p><p>3 0.58095819 <a title="122-lsi-3" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>Introduction: I tweaked the site in a number of ways today, including:
  
 Updating to  WordPress  1.5. 
 Installing and heavily tweaking the  Geekniche  theme.  Update: I switched back to a tweaked version of the old theme. 
 Adding the  Customizable Post Listings  plugin. 
 Installing the  StatTraq  plugin. 
 Updating some of the links.  I particularly recommend looking at the  computer research policy  blog. 
 Adding  threaded comments .  This doesn’t thread old comments obviously, but the extra structure may be helpful for new ones. 
  
Overall, I think this is an improvement, and it addresses a few of my  earlier problems .  If you have any difficulties or anything seems “not quite right”, please speak up.  A few other tweaks to the site may happen in the near future.</p><p>4 0.56072652 <a title="122-lsi-4" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>Introduction: At the  last ICML ,  Tom Dietterich  asked me to look into systems for commenting on papers.  I’ve been slow getting to this, but it’s relevant now.
 
The essential observation is that we now have many tools for online collaboration, but they are not yet much used in academic research.  If we can find the right way to use them, then perhaps great things might happen, with extra kudos to the first conference that manages to really create an online community.  Various conferences have been poking at this.  For example,  UAI has setup a wiki , COLT has  started using   Joomla , with some dynamic content, and AAAI has been setting up a “ student blog “.  Similarly,  Dinoj Surendran  setup a twiki for the  Chicago Machine Learning Summer School , which was quite useful for coordinating events and other things.
 
I believe the most important thing is a willingness to experiment.  A good place to start seems to be enhancing existing conference websites.  For example, the  ICML 2007 papers pag</p><p>5 0.5252949 <a title="122-lsi-5" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>Introduction: Iain  noticed that hunch.net had zero width divs hiding spammy URLs.  Some investigation reveals that the wordpress version being used (2.0.3) had security flaws.  I’ve upgraded to the latest, rotated passwords, and removed the spammy URLs.  I don’t believe any content was lost.  You can check your own and other sites for a similar problem by greping for “width:0″ or “width: 0″ in the delivered html source.</p><p>6 0.49862677 <a title="122-lsi-6" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>7 0.43677735 <a title="122-lsi-7" href="../hunch_net-2005/hunch_net-2005-06-13-Wikis_for_Summer_Schools_and_Workshops.html">81 hunch net-2005-06-13-Wikis for Summer Schools and Workshops</a></p>
<p>8 0.43117741 <a title="122-lsi-8" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>9 0.42717075 <a title="122-lsi-9" href="../hunch_net-2008/hunch_net-2008-11-26-Efficient_Reinforcement_Learning_in_MDPs.html">328 hunch net-2008-11-26-Efficient Reinforcement Learning in MDPs</a></p>
<p>10 0.41437986 <a title="122-lsi-10" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>11 0.40630713 <a title="122-lsi-11" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>12 0.37138575 <a title="122-lsi-12" href="../hunch_net-2005/hunch_net-2005-06-22-Languages__of_Learning.html">84 hunch net-2005-06-22-Languages  of Learning</a></p>
<p>13 0.36751601 <a title="122-lsi-13" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>14 0.36663443 <a title="122-lsi-14" href="../hunch_net-2005/hunch_net-2005-11-05-The_design_of_a_computing_cluster.html">128 hunch net-2005-11-05-The design of a computing cluster</a></p>
<p>15 0.35235557 <a title="122-lsi-15" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>16 0.34868678 <a title="122-lsi-16" href="../hunch_net-2006/hunch_net-2006-01-25-1_year.html">151 hunch net-2006-01-25-1 year</a></p>
<p>17 0.32014588 <a title="122-lsi-17" href="../hunch_net-2006/hunch_net-2006-12-06-The_Spam_Problem.html">223 hunch net-2006-12-06-The Spam Problem</a></p>
<p>18 0.31766275 <a title="122-lsi-18" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>19 0.3152698 <a title="122-lsi-19" href="../hunch_net-2006/hunch_net-2006-04-17-Rexa_is_live.html">173 hunch net-2006-04-17-Rexa is live</a></p>
<p>20 0.3133809 <a title="122-lsi-20" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.202), (49, 0.517), (55, 0.082)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98396283 <a title="122-lda-1" href="../hunch_net-2009/hunch_net-2009-01-23-An_Active_Learning_Survey.html">338 hunch net-2009-01-23-An Active Learning Survey</a></p>
<p>Introduction: Burr Settles  wrote a fairly comprehensive  survey of active learning .  He intends to maintain and update the survey, so send him any suggestions you have.</p><p>2 0.95435226 <a title="122-lda-2" href="../hunch_net-2006/hunch_net-2006-12-12-Interesting_Papers_at_NIPS_2006.html">224 hunch net-2006-12-12-Interesting Papers at NIPS 2006</a></p>
<p>Introduction: Here are some papers that I found surprisingly interesting.
  
  Yoshua Bengio , Pascal Lamblin, Dan Popovici, Hugo Larochelle,  Greedy Layer-wise Training of Deep Networks . Empirically investigates some of the design choices behind deep belief networks.
 
  Long Zhu , Yuanhao Chen,  Alan Yuille  Unsupervised Learning of a Probabilistic Grammar for Object Detection and Parsing.  An unsupervised method for detecting objects using simple feature filters that works remarkably well on the (supervised)  caltech-101 dataset . 
  Shai Ben-David ,  John Blitzer ,  Koby Crammer , and  Fernando Pereira ,  Analysis of Representations for Domain Adaptation .  This is the first analysis I’ve seen of learning with respect to samples drawn differently from the evaluation distribution which depends on reasonable measurable quantities. 
  
All of these papers turn out to have a common theme—the power of unlabeled data to do generically useful things.</p><p>same-blog 3 0.95326978 <a title="122-lda-3" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>Introduction: Several people have had difficulty with comments which seem to have an allowed language significantly poorer than posts.  The set of allowed html tags has been increased and the  markdown filter  has been put in place to try to make commenting easier.  Iâ&euro;&trade;ll put some examples into the comments of this post.</p><p>4 0.69326866 <a title="122-lda-4" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>Introduction: Today brings a new release of the  Vowpal Wabbit  fast online learning software.  This time, unlike the previous release, the project itself is going open source, developing via  github .  For example, the lastest and greatest can be downloaded via:
  
git clone git://github.com/JohnLangford/vowpal_wabbit.git
  
If you aren’t familiar with  git , it’s a distributed version control system which supports quick and easy branching, as well as reconciliation.
 
This version of the code is confirmed to compile without complaint on at least some flavors of OSX as well as Linux boxes.
 
As much of the point of this project is pushing the limits of fast and effective machine learning, let me mention a few datapoints from my experience.
  
 The program can effectively scale up to batch-style training on sparse terafeature (i.e. 10 12  sparse feature) size datasets.  The limiting factor is typically i/o. 
 I started using the the real datasets from the  large-scale learning  workshop as a conve</p><p>5 0.68683761 <a title="122-lda-5" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>Introduction: While everyone is silently working on ICML submissions, I found this discussion about a  fast physics simulator  chip interesting from a learning viewpoint.  In many cases, learning attempts to predict the outcome of physical processes.  Access to a fast simulator for these processes might be quite helpful in predicting the outcome.  Bayesian learning in particular may directly benefit while many other algorithms (like support vector machines) might have their speed greatly increased.
 
The biggest drawback is that writing software for these odd architectures is always difficult and time consuming, but a several-orders-of-magnitude speedup might make that worthwhile.</p><p>6 0.67220098 <a title="122-lda-6" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>7 0.64144015 <a title="122-lda-7" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>8 0.47635457 <a title="122-lda-8" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>9 0.40727809 <a title="122-lda-9" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>10 0.40612704 <a title="122-lda-10" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>11 0.40607274 <a title="122-lda-11" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>12 0.39342979 <a title="122-lda-12" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>13 0.38307336 <a title="122-lda-13" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>14 0.37986314 <a title="122-lda-14" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>15 0.37569201 <a title="122-lda-15" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>16 0.37560999 <a title="122-lda-16" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>17 0.37386626 <a title="122-lda-17" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>18 0.37372148 <a title="122-lda-18" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>19 0.37228745 <a title="122-lda-19" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>20 0.37144893 <a title="122-lda-20" href="../hunch_net-2006/hunch_net-2006-04-14-JMLR_is_a_success.html">172 hunch net-2006-04-14-JMLR is a success</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
