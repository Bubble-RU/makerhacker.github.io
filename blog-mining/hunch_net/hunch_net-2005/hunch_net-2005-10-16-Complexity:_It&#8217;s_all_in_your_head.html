<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-123" href="#">hunch_net-2005-123</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-123-html" href="http://hunch.net/?p=134">html</a></p><p>Introduction: One of the central concerns of learning is to understand and toprevent
overfitting. Various notion of "function complexity" oftenarise: VC dimension,
Rademacher complexity, comparison classes ofexperts, and program length are
just a few.The term "complexity" to me seems somehow misleading; the terms
nevercapture something that meets my intuitive notion of complexity.
TheBayesian notion clearly captures what's going on. Functions
aren't"complex"- they're just "surprising": we assign to them lowprobability.
Most (all?) complexity notions I know boil downto some (generally loose) bound
on the prior probability of the function.In a sense, "complexity"
fundementally arises because probabilitydistributions must sum to one. You
can't believe in all possibilitiesat the same time, or at least not equally.
Rather you have tocarefully spread the probability mass over the options you'd
like toconsider. Large complexity classes means that beliefs are spreadthinly.
In it's simplest form, this phenom</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 One of the central concerns of learning is to understand and toprevent overfitting. [sent-1, score-0.185]
</p><p>2 Various notion of "function complexity" oftenarise: VC dimension, Rademacher complexity, comparison classes ofexperts, and program length are just a few. [sent-2, score-0.655]
</p><p>3 The term "complexity" to me seems somehow misleading; the terms nevercapture something that meets my intuitive notion of complexity. [sent-3, score-0.603]
</p><p>4 Functions aren't"complex"- they're just "surprising": we assign to them lowprobability. [sent-5, score-0.102]
</p><p>5 ) complexity notions I know boil downto some (generally loose) bound on the prior probability of the function. [sent-7, score-1.195]
</p><p>6 In a sense, "complexity" fundementally arises because probabilitydistributions must sum to one. [sent-8, score-0.476]
</p><p>7 Rather you have tocarefully spread the probability mass over the options you'd like toconsider. [sent-10, score-0.479]
</p><p>8 In it's simplest form, this phenomenom give the log (1\n) forn hypotheses in classic PAC bounds. [sent-12, score-0.389]
</p><p>9 In fact, one way to think about good learning algorithms is that theyare those which take full advantage of their probability mass. [sent-13, score-0.319]
</p><p>10 In the language of Minimum Description Length, they correspond to"non-defective distributions". [sent-14, score-0.102]
</p><p>11 So this raises a question: are there notions of complexity (preferably finite,computable ones) that differ fundementally from the notions of "prior"or "surprisingness"? [sent-15, score-1.57]
</p><p>12 Game-theoretic setups would seem to be promising,although much of the work I'm familiar with ties it closely to the notionof prior as well. [sent-16, score-0.489]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('complexity', 0.36), ('notions', 0.347), ('fundementally', 0.298), ('notion', 0.204), ('length', 0.198), ('prior', 0.183), ('probability', 0.173), ('classes', 0.171), ('ties', 0.132), ('boil', 0.132), ('captures', 0.132), ('classic', 0.132), ('rademacher', 0.132), ('raises', 0.132), ('meets', 0.123), ('vc', 0.123), ('hypotheses', 0.11), ('spread', 0.11), ('loose', 0.11), ('intuitive', 0.106), ('somehow', 0.106), ('misleading', 0.106), ('pac', 0.106), ('closely', 0.102), ('correspond', 0.102), ('beliefs', 0.102), ('dimension', 0.102), ('options', 0.102), ('assign', 0.102), ('central', 0.099), ('mass', 0.094), ('distributions', 0.091), ('surprising', 0.091), ('arises', 0.089), ('sum', 0.089), ('differ', 0.086), ('concerns', 0.086), ('description', 0.084), ('comparison', 0.082), ('simplest', 0.081), ('minimum', 0.079), ('full', 0.079), ('ones', 0.075), ('clearly', 0.073), ('familiar', 0.072), ('advantage', 0.067), ('log', 0.066), ('functions', 0.066), ('complex', 0.064), ('term', 0.064)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="123-tfidf-1" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and toprevent
overfitting. Various notion of "function complexity" oftenarise: VC dimension,
Rademacher complexity, comparison classes ofexperts, and program length are
just a few.The term "complexity" to me seems somehow misleading; the terms
nevercapture something that meets my intuitive notion of complexity.
TheBayesian notion clearly captures what's going on. Functions
aren't"complex"- they're just "surprising": we assign to them lowprobability.
Most (all?) complexity notions I know boil downto some (generally loose) bound
on the prior probability of the function.In a sense, "complexity"
fundementally arises because probabilitydistributions must sum to one. You
can't believe in all possibilitiesat the same time, or at least not equally.
Rather you have tocarefully spread the probability mass over the options you'd
like toconsider. Large complexity classes means that beliefs are spreadthinly.
In it's simplest form, this phenom</p><p>2 0.15874112 <a title="123-tfidf-2" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>3 0.13330476 <a title="123-tfidf-3" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.
There are at least 3 distinct ways the word is used.BayesianThe Bayesian
notion of probability is a 'degree of belief'. The degree of belief that some
event (i.e. "stock goes up" or "stock goes down") occurs can be measured by
asking a sequence of questions of the form "Would you bet the stock goes up or
down atYto 1 odds?" A consistent better will switch from 'for' to 'against' at
some single value ofY. The probability is thenY/(Y+1). Bayesian probabilities
express lack of knowledge rather than randomization. They are useful in
learning because we often lack knowledge and expressing that lack flexibly
makes the learning algorithms work better. Bayesian Learning uses
'probability' in this way exclusively.FrequentistThe Frequentist notion of
probability is a rate of occurence. A rate of occurrence can be measured by
doing an experiment many times. If an event occursktimes innexperiments then
it has probability ab</p><p>4 0.10749935 <a title="123-tfidf-4" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>Introduction: One of the enduring stereotypes of academia is that people spend a great deal
of intelligence, time, and effort finding complexity rather than simplicity.
This is at least anecdotally true in my experience.Math++Several people have
found that adding useless math makes their paper more publishable as evidenced
by a reject-add-accept sequence.8 page minimumWho submitted a paper
toICMLviolating the 8 page minimum? Every author fears that the reviewers
won't take their work seriously unless the allowed length is fully used. The
best minimum violation I know isAdam's paper at SODA ongenerating random
factored numbers, but this is deeply exceptional. It's a fair bet that 90% of
papers submitted are exactly at the page limit. We could imagine that this is
because papers naturally take more space, but few people seem to be clamoring
for more space.JournalongHas anyone been asked to review a 100 page journal
paper? I have. Journal papers can be nice, because they give an author the
opportunity</p><p>5 0.10394417 <a title="123-tfidf-5" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these
suggest that some method of saying "I prefer this predictor to that predictor"
is useful and necessary. Examples include Bayesian reasoning, prediction
bounds, and online learning. One difficulty which arises is that the manner
and meaning of saying "I prefer this predictor to that predictor"
differs.Prior(Bayesian) A prior is a probability distribution over a set of
distributions which expresses a belief in the probability that some
distribution is the distribution generating the data."Prior"(Prediction bounds
& online learning) The "prior" is a measure over a set of classifiers which
expresses the degree to which you hope the classifier will predict
well.Bias(Regularization, Early termination of neural network training, etcâ&euro;Ś)
The bias is some (often implicitly specified by an algorithm) way of
preferring one predictor to another.This only scratches the surface--there are
yet more subtleties. For example the (as</p><p>6 0.097964361 <a title="123-tfidf-6" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>7 0.094028778 <a title="123-tfidf-7" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>8 0.09142144 <a title="123-tfidf-8" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>9 0.085953936 <a title="123-tfidf-9" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>10 0.08211831 <a title="123-tfidf-10" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>11 0.081678599 <a title="123-tfidf-11" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>12 0.081087835 <a title="123-tfidf-12" href="../hunch_net-2009/hunch_net-2009-08-26-Another_10-year_paper_in_Machine_Learning.html">368 hunch net-2009-08-26-Another 10-year paper in Machine Learning</a></p>
<p>13 0.080987178 <a title="123-tfidf-13" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>14 0.079760663 <a title="123-tfidf-14" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>15 0.079498895 <a title="123-tfidf-15" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>16 0.076177068 <a title="123-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>17 0.070890754 <a title="123-tfidf-17" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>18 0.07077948 <a title="123-tfidf-18" href="../hunch_net-2009/hunch_net-2009-12-24-Top_graduates_this_season.html">384 hunch net-2009-12-24-Top graduates this season</a></p>
<p>19 0.070243552 <a title="123-tfidf-19" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>20 0.06812387 <a title="123-tfidf-20" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.149), (1, -0.074), (2, -0.033), (3, -0.012), (4, 0.011), (5, -0.05), (6, -0.065), (7, -0.003), (8, -0.037), (9, -0.047), (10, -0.058), (11, 0.027), (12, -0.022), (13, -0.106), (14, -0.049), (15, -0.023), (16, 0.103), (17, 0.045), (18, 0.021), (19, -0.035), (20, -0.041), (21, 0.008), (22, -0.075), (23, 0.001), (24, 0.039), (25, -0.019), (26, -0.094), (27, -0.03), (28, -0.062), (29, 0.011), (30, -0.046), (31, -0.032), (32, 0.005), (33, -0.099), (34, 0.068), (35, 0.024), (36, -0.006), (37, -0.043), (38, 0.046), (39, -0.115), (40, 0.066), (41, -0.048), (42, 0.003), (43, 0.099), (44, 0.02), (45, 0.001), (46, -0.02), (47, -0.206), (48, 0.107), (49, -0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9806816 <a title="123-lsi-1" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and toprevent
overfitting. Various notion of "function complexity" oftenarise: VC dimension,
Rademacher complexity, comparison classes ofexperts, and program length are
just a few.The term "complexity" to me seems somehow misleading; the terms
nevercapture something that meets my intuitive notion of complexity.
TheBayesian notion clearly captures what's going on. Functions
aren't"complex"- they're just "surprising": we assign to them lowprobability.
Most (all?) complexity notions I know boil downto some (generally loose) bound
on the prior probability of the function.In a sense, "complexity"
fundementally arises because probabilitydistributions must sum to one. You
can't believe in all possibilitiesat the same time, or at least not equally.
Rather you have tocarefully spread the probability mass over the options you'd
like toconsider. Large complexity classes means that beliefs are spreadthinly.
In it's simplest form, this phenom</p><p>2 0.64995748 <a title="123-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>3 0.61060417 <a title="123-lsi-3" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>Introduction: This post is about a trick that I learned fromDale Schuurmanswhich has been
repeatedly useful for me over time.The basic trick has to do with importance
weighting for monte carlo integration. Consider the problem of finding:N = Ex
~ Df(x)given samples fromDand knowledge off.Often, we don't have samples
fromDavailable. Instead, we must make do with samples from some other
distributionQ. In that case, we can still often solve the problem, as long as
Q(x) isn't 0 when D(x) is nonzero, using the importance weighting formula:Ex ~
Qf(x) D(x)/Q(x)A basic question is: How many samples fromQare required in
order to estimateNto some precision? In general the convergence rate is not
bounded, becausef(x) D(x)/Q(x)is not bounded given the
assumptions.Nevertheless, there is one special valueQ(x) = f(x) D(x) / Nwhere
the sample complexity turns out to be1, which is typically substantially
better than the sample complexity of the original problem.This observation
underlies the motivation for voluntary</p><p>4 0.54030931 <a title="123-lsi-4" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.
There are at least 3 distinct ways the word is used.BayesianThe Bayesian
notion of probability is a 'degree of belief'. The degree of belief that some
event (i.e. "stock goes up" or "stock goes down") occurs can be measured by
asking a sequence of questions of the form "Would you bet the stock goes up or
down atYto 1 odds?" A consistent better will switch from 'for' to 'against' at
some single value ofY. The probability is thenY/(Y+1). Bayesian probabilities
express lack of knowledge rather than randomization. They are useful in
learning because we often lack knowledge and expressing that lack flexibly
makes the learning algorithms work better. Bayesian Learning uses
'probability' in this way exclusively.FrequentistThe Frequentist notion of
probability is a rate of occurence. A rate of occurrence can be measured by
doing an experiment many times. If an event occursktimes innexperiments then
it has probability ab</p><p>5 0.50068462 <a title="123-lsi-5" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these
suggest that some method of saying "I prefer this predictor to that predictor"
is useful and necessary. Examples include Bayesian reasoning, prediction
bounds, and online learning. One difficulty which arises is that the manner
and meaning of saying "I prefer this predictor to that predictor"
differs.Prior(Bayesian) A prior is a probability distribution over a set of
distributions which expresses a belief in the probability that some
distribution is the distribution generating the data."Prior"(Prediction bounds
& online learning) The "prior" is a measure over a set of classifiers which
expresses the degree to which you hope the classifier will predict
well.Bias(Regularization, Early termination of neural network training, etcâ&euro;Ś)
The bias is some (often implicitly specified by an algorithm) way of
preferring one predictor to another.This only scratches the surface--there are
yet more subtleties. For example the (as</p><p>6 0.49821004 <a title="123-lsi-6" href="../hunch_net-2005/hunch_net-2005-12-11-More_NIPS_Papers.html">139 hunch net-2005-12-11-More NIPS Papers</a></p>
<p>7 0.49741399 <a title="123-lsi-7" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>8 0.49102733 <a title="123-lsi-8" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>9 0.46142125 <a title="123-lsi-9" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>10 0.44489822 <a title="123-lsi-10" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>11 0.42550138 <a title="123-lsi-11" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>12 0.42306179 <a title="123-lsi-12" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>13 0.42291528 <a title="123-lsi-13" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>14 0.4196803 <a title="123-lsi-14" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>15 0.41524214 <a title="123-lsi-15" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>16 0.39821377 <a title="123-lsi-16" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>17 0.39606598 <a title="123-lsi-17" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>18 0.39360958 <a title="123-lsi-18" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>19 0.39027411 <a title="123-lsi-19" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>20 0.38769221 <a title="123-lsi-20" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.25), (69, 0.051), (74, 0.105), (95, 0.04), (99, 0.444)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.82641733 <a title="123-lda-1" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and toprevent
overfitting. Various notion of "function complexity" oftenarise: VC dimension,
Rademacher complexity, comparison classes ofexperts, and program length are
just a few.The term "complexity" to me seems somehow misleading; the terms
nevercapture something that meets my intuitive notion of complexity.
TheBayesian notion clearly captures what's going on. Functions
aren't"complex"- they're just "surprising": we assign to them lowprobability.
Most (all?) complexity notions I know boil downto some (generally loose) bound
on the prior probability of the function.In a sense, "complexity"
fundementally arises because probabilitydistributions must sum to one. You
can't believe in all possibilitiesat the same time, or at least not equally.
Rather you have tocarefully spread the probability mass over the options you'd
like toconsider. Large complexity classes means that beliefs are spreadthinly.
In it's simplest form, this phenom</p><p>2 0.74342227 <a title="123-lda-2" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>Introduction: I have had interesting discussions about distinction between static vs.
dynamic classes withKishoreandHal.The distinction arises in multiclass
prediction settings. A static set of classes is given by a set of
labels{1,â&euro;Ś,k}and the goal is generally to choose the most likely label given
features. The static approach is the one that we typically analyze and think
about in machine learning.The dynamic setting is one that is often used in
practice. The basic idea is that the number of classes is not fixed, varying
on a per example basis. These different classes are generally defined by a
choice of features.The distinction between these two settings as far as theory
goes, appears to be very substantial. For example, in the static setting,
inlearning reductions land, we have techniques now for robustO(log(k))time
prediction in many multiclass setting variants. In the dynamic setting, the
best techniques known areO(k), and furthermore this exponential gap may be
essential, at least without fur</p><p>3 0.72602803 <a title="123-lda-3" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>Introduction: One striking feature of many machine learning algorithms is the gymnastics
that designers go through to avoid symmetry breaking. In the most basic form
of machine learning, there are labeled examples composed of features. Each of
these can be treated symmetrically or asymmetrically by algorithms.feature
symmetryEvery feature is treated the same. In gradient update rules, the same
update is applied whether the feature is first or last. In metric-based
predictions, every feature is just as important in computing the
distance.example symmetryEvery example is treated the same. Batch learning
algorithms are great exemplars of this approach.label symmetryEvery label is
treated the same. This is particularly noticeable in multiclass classification
systems which predict according toarg maxlwlxbut it occurs in many other
places as well.Empirically, breaking symmetry well seems to yield great
algorithms.feature asymmetryFor those who like the "boosting is stepwise
additive regression on exponent</p><p>4 0.5151512 <a title="123-lda-4" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>Introduction: I wanted to expand on thispostand some of the previousproblems/research
directionsabout where learning theory might make large strides.Why theory?The
essential reason for theory is "intuition extension". A very good applied
learning person can master some particular application domain yielding the
best computer algorithms for solving that problem. A very good theory can take
the intuitions discovered by this and other applied learning people and extend
them to new domains in a relatively automatic fashion. To do this, we take
these basic intuitions and try to find a mathematical model that:Explains the
basic intuitions.Makes new testable predictions about how to learn.Succeeds in
so learning.This is "intuition extension": taking what we have learned
somewhere else and applying it in new domains. It is fundamentally useful to
everyone because it increases the level of automation in solving
problems.Where next for learning theory?I like the analogy with physics. Back
before we-the-humans</p><p>5 0.51472765 <a title="123-lda-5" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>Introduction: I want to try to describe what doing research means, especially from the point
of view of an undergraduate. The shift from a class-taking mentality to a
research mentality is very significant and not easy.Problem PosingPosing the
right problem is often as important as solving them. Many people can get by in
research by solving problems others have posed, but that's not sufficient for
really inspiring research. For learning in particular, there is a strong
feeling that we just haven't figured out which questions are the right ones to
ask. You can see this, because the answers we have do not seem
convincing.Gambling your lifeWhen you do research, you think very hard about
new ways of solving problems, new problems, and new solutions. Many
conversations are of the form "I wonder what would happen if…" These processes
can be short (days or weeks) or years-long endeavours. The worst part is that
you'll only know if you were succesful at the end of the process (and
sometimes not even then be</p><p>6 0.51393831 <a title="123-lda-6" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>7 0.51288855 <a title="123-lda-7" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>8 0.51269567 <a title="123-lda-8" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>9 0.51185876 <a title="123-lda-9" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>10 0.51117808 <a title="123-lda-10" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>11 0.51046216 <a title="123-lda-11" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>12 0.51018459 <a title="123-lda-12" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>13 0.50985348 <a title="123-lda-13" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>14 0.50977623 <a title="123-lda-14" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>15 0.50897229 <a title="123-lda-15" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>16 0.5084219 <a title="123-lda-16" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>17 0.50831819 <a title="123-lda-17" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>18 0.50808579 <a title="123-lda-18" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>19 0.50791204 <a title="123-lda-19" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>20 0.5064826 <a title="123-lda-20" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
