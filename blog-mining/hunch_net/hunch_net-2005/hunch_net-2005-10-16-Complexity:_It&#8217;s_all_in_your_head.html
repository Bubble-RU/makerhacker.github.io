<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-123" href="#">hunch_net-2005-123</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-123-html" href="http://hunch.net/?p=134">html</a></p><p>Introduction: One of the central concerns of learning is to understand and to 
prevent overfitting. Various notion of “function complexity” often 
arise: VC dimension, Rademacher complexity, comparison classes of 
experts, and program length are just a few.
 
The term “complexity” to me seems somehow misleading; the terms never 
capture something that meets my intuitive notion of complexity. The 
Bayesian notion clearly captures what’s going on. Functions aren’t 
“complex”– they’re just “surprising”: we assign to them low 
probability. Most (all?) complexity notions I know boil down 
to some (generally loose) bound on the prior probability of the function.
 
In a sense, “complexity” fundementally arises because probability 
distributions must sum to one. You can’t believe in all possibilities 
at the same time, or at least not equally. Rather you have to 
carefully spread the probability mass over the options you’d like to 
consider. Large complexity classes means that beliefs are spread 
thinly. In</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 One of the central concerns of learning is to understand and to  prevent overfitting. [sent-1, score-0.266]
</p><p>2 Various notion of “function complexity” often  arise: VC dimension, Rademacher complexity, comparison classes of  experts, and program length are just a few. [sent-2, score-0.658]
</p><p>3 The term “complexity” to me seems somehow misleading; the terms never  capture something that meets my intuitive notion of complexity. [sent-3, score-0.63]
</p><p>4 The  Bayesian notion clearly captures what’s going on. [sent-4, score-0.37]
</p><p>5 Functions aren’t  “complex”– they’re just “surprising”: we assign to them low  probability. [sent-5, score-0.094]
</p><p>6 ) complexity notions I know boil down  to some (generally loose) bound on the prior probability of the function. [sent-7, score-1.139]
</p><p>7 In a sense, “complexity” fundementally arises because probability  distributions must sum to one. [sent-8, score-0.788]
</p><p>8 You can’t believe in all possibilities  at the same time, or at least not equally. [sent-9, score-0.084]
</p><p>9 Rather you have to  carefully spread the probability mass over the options you’d like to  consider. [sent-10, score-0.591]
</p><p>10 Large complexity classes means that beliefs are spread  thinly. [sent-11, score-0.774]
</p><p>11 In it’s simplest form, this phenomenom give the log (1\n) for  n hypotheses in classic PAC bounds. [sent-12, score-0.292]
</p><p>12 In fact, one way to think about good learning algorithms is that they  are those which take full advantage of their probability mass. [sent-13, score-0.281]
</p><p>13 In the language of Minimum Description Length, they correspond to  “non-defective distributions”. [sent-14, score-0.094]
</p><p>14 So this raises a question: are there notions  of complexity (preferably finite,  computable ones) that differ fundementally from the notions of “prior”  or “surprisingness”? [sent-15, score-1.541]
</p><p>15 Game-theoretic setups would seem to be promising,  although much of the work I’m familiar with ties it closely to the notion  of prior as well. [sent-16, score-0.625]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('complexity', 0.327), ('notions', 0.318), ('fundementally', 0.273), ('notion', 0.249), ('probability', 0.209), ('spread', 0.202), ('length', 0.181), ('prior', 0.164), ('classes', 0.154), ('distributions', 0.151), ('ties', 0.121), ('boil', 0.121), ('captures', 0.121), ('classic', 0.121), ('raises', 0.121), ('rademacher', 0.112), ('meets', 0.112), ('promising', 0.112), ('computable', 0.106), ('vc', 0.101), ('loose', 0.101), ('intuitive', 0.097), ('hypotheses', 0.097), ('misleading', 0.097), ('prevent', 0.097), ('correspond', 0.094), ('somehow', 0.094), ('dimension', 0.094), ('options', 0.094), ('assign', 0.094), ('closely', 0.091), ('beliefs', 0.091), ('central', 0.091), ('pac', 0.088), ('arise', 0.088), ('mass', 0.086), ('possibilities', 0.084), ('surprising', 0.084), ('arises', 0.082), ('re', 0.08), ('differ', 0.078), ('concerns', 0.078), ('capture', 0.078), ('comparison', 0.074), ('description', 0.074), ('simplest', 0.074), ('sum', 0.073), ('minimum', 0.073), ('full', 0.072), ('finite', 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="123-tfidf-1" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and to 
prevent overfitting. Various notion of “function complexity” often 
arise: VC dimension, Rademacher complexity, comparison classes of 
experts, and program length are just a few.
 
The term “complexity” to me seems somehow misleading; the terms never 
capture something that meets my intuitive notion of complexity. The 
Bayesian notion clearly captures what’s going on. Functions aren’t 
“complex”– they’re just “surprising”: we assign to them low 
probability. Most (all?) complexity notions I know boil down 
to some (generally loose) bound on the prior probability of the function.
 
In a sense, “complexity” fundementally arises because probability 
distributions must sum to one. You can’t believe in all possibilities 
at the same time, or at least not equally. Rather you have to 
carefully spread the probability mass over the options you’d like to 
consider. Large complexity classes means that beliefs are spread 
thinly. In</p><p>2 0.17226627 <a title="123-tfidf-2" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatov  says that we should think about regularization a bit.  It’s a complex topic which I only partially understand, so I’ll try to explain from a couple viewpoints.
  
  Functionally . Regularization is optimizing some representation to fit the data  and  minimize some notion of predictor complexity.  This notion of complexity is often the l 1  or l 2  norm on a set of parameters, but the term can be used much more generally.  Empirically, this often works much better than simply fitting the data. 
  Statistical Learning Viewpoint  Regularization is about the failiure of statistical learning to adequately predict generalization error.  Let  e(c,D)  be the expected error rate with respect to  D  of classifier  c  and  e(c,S)  the observed error rate on a sample  S .  There are numerous bounds of the form: assuming i.i.d. samples, with high probability over the drawn samples  S ,   e(c,D) less than e(c,S) + f(complexity)  where  complexity  is some measure of the size of a s</p><p>3 0.1630365 <a title="123-tfidf-3" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.  There are at least 3 distinct ways the word is used. 
  
  Bayesian  The Bayesian notion of probability is a ‘degree of belief’.   The degree of belief that some event (i.e. “stock goes up” or “stock goes down”) occurs can be measured by asking a sequence of questions of the form “Would you bet the stock goes up or down at  Y  to 1 odds?” A consistent better will switch from ‘for’ to ‘against’ at some single value of  Y .  The probability is then  Y/(Y+1) .  Bayesian probabilities express lack of knowledge rather than randomization.  They are useful in learning because we often lack knowledge and expressing that lack flexibly makes the learning algorithms work better.  Bayesian Learning uses ‘probability’ in this way exclusively. 
  Frequentist  The Frequentist notion of probability is a rate of occurence.  A rate of occurrence can be measured by doing an experiment many times.  If an event occurs  k  times in</p><p>4 0.12566254 <a title="123-tfidf-4" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these suggest that some method of saying “I prefer this predictor to that predictor” is useful and necessary.  Examples include Bayesian reasoning, prediction bounds, and online learning.   One difficulty which arises is that the manner and meaning of saying “I prefer this predictor to that predictor” differs.
  
  Prior  (Bayesian) A prior is a probability distribution over a set of distributions which expresses a belief in the probability that some distribution is the distribution generating the data. 
  “Prior”  (Prediction bounds & online learning) The “prior” is a measure over a set of classifiers which expresses the degree to which you hope the classifier will predict well. 
  Bias  (Regularization, Early termination of neural network training, etc…)  The bias is some (often implicitly specified by an algorithm) way of preferring one predictor to another. 
  
This only scratches the surface—there are yet more subt</p><p>5 0.11344875 <a title="123-tfidf-5" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>Introduction: One of the enduring stereotypes of academia is that people spend a great deal of intelligence, time, and effort finding complexity rather than simplicity.  This is at least anecdotally true in my experience.
  
  Math++  Several people have found that adding useless math makes their paper more publishable as evidenced by a reject-add-accept sequence. 
  8 page minimum  Who submitted a paper to  ICML  violating the 8 page minimum?  Every author fears that the reviewers won’t take their work seriously unless the allowed length is fully used.  The best minimum violation I know is  Adam ‘s paper at SODA on  generating random factored numbers , but this is deeply exceptional.  It’s a fair bet that 90% of papers submitted are exactly at the page limit.  We could imagine that this is because papers naturally take more space, but few people seem to be clamoring for more space. 
  Journalong   Has anyone been asked to review a 100 page journal paper?  I have.  Journal papers can be nice, becaus</p><p>6 0.1076713 <a title="123-tfidf-6" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>7 0.094669417 <a title="123-tfidf-7" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>8 0.08609999 <a title="123-tfidf-8" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>9 0.084840328 <a title="123-tfidf-9" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>10 0.082751662 <a title="123-tfidf-10" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>11 0.081803173 <a title="123-tfidf-11" href="../hunch_net-2009/hunch_net-2009-08-26-Another_10-year_paper_in_Machine_Learning.html">368 hunch net-2009-08-26-Another 10-year paper in Machine Learning</a></p>
<p>12 0.079988249 <a title="123-tfidf-12" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>13 0.077608705 <a title="123-tfidf-13" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>14 0.077574931 <a title="123-tfidf-14" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>15 0.077412575 <a title="123-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>16 0.07722237 <a title="123-tfidf-16" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>17 0.076653667 <a title="123-tfidf-17" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>18 0.07563711 <a title="123-tfidf-18" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>19 0.075045682 <a title="123-tfidf-19" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>20 0.074964769 <a title="123-tfidf-20" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.156), (1, 0.085), (2, 0.039), (3, -0.006), (4, -0.017), (5, -0.02), (6, 0.017), (7, 0.056), (8, 0.096), (9, -0.036), (10, 0.038), (11, -0.04), (12, 0.052), (13, -0.041), (14, 0.07), (15, -0.115), (16, -0.033), (17, 0.001), (18, 0.093), (19, -0.018), (20, 0.01), (21, 0.098), (22, 0.047), (23, 0.053), (24, -0.016), (25, -0.0), (26, 0.012), (27, -0.029), (28, -0.034), (29, 0.098), (30, 0.069), (31, -0.011), (32, 0.059), (33, 0.041), (34, -0.1), (35, -0.068), (36, 0.042), (37, 0.038), (38, 0.041), (39, 0.055), (40, -0.066), (41, -0.02), (42, 0.057), (43, 0.006), (44, -0.003), (45, 0.048), (46, -0.028), (47, 0.01), (48, -0.077), (49, 0.135)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98533022 <a title="123-lsi-1" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and to 
prevent overfitting. Various notion of “function complexity” often 
arise: VC dimension, Rademacher complexity, comparison classes of 
experts, and program length are just a few.
 
The term “complexity” to me seems somehow misleading; the terms never 
capture something that meets my intuitive notion of complexity. The 
Bayesian notion clearly captures what’s going on. Functions aren’t 
“complex”– they’re just “surprising”: we assign to them low 
probability. Most (all?) complexity notions I know boil down 
to some (generally loose) bound on the prior probability of the function.
 
In a sense, “complexity” fundementally arises because probability 
distributions must sum to one. You can’t believe in all possibilities 
at the same time, or at least not equally. Rather you have to 
carefully spread the probability mass over the options you’d like to 
consider. Large complexity classes means that beliefs are spread 
thinly. In</p><p>2 0.7870363 <a title="123-lsi-2" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.  There are at least 3 distinct ways the word is used. 
  
  Bayesian  The Bayesian notion of probability is a ‘degree of belief’.   The degree of belief that some event (i.e. “stock goes up” or “stock goes down”) occurs can be measured by asking a sequence of questions of the form “Would you bet the stock goes up or down at  Y  to 1 odds?” A consistent better will switch from ‘for’ to ‘against’ at some single value of  Y .  The probability is then  Y/(Y+1) .  Bayesian probabilities express lack of knowledge rather than randomization.  They are useful in learning because we often lack knowledge and expressing that lack flexibly makes the learning algorithms work better.  Bayesian Learning uses ‘probability’ in this way exclusively. 
  Frequentist  The Frequentist notion of probability is a rate of occurence.  A rate of occurrence can be measured by doing an experiment many times.  If an event occurs  k  times in</p><p>3 0.7331689 <a title="123-lsi-3" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatov  says that we should think about regularization a bit.  It’s a complex topic which I only partially understand, so I’ll try to explain from a couple viewpoints.
  
  Functionally . Regularization is optimizing some representation to fit the data  and  minimize some notion of predictor complexity.  This notion of complexity is often the l 1  or l 2  norm on a set of parameters, but the term can be used much more generally.  Empirically, this often works much better than simply fitting the data. 
  Statistical Learning Viewpoint  Regularization is about the failiure of statistical learning to adequately predict generalization error.  Let  e(c,D)  be the expected error rate with respect to  D  of classifier  c  and  e(c,S)  the observed error rate on a sample  S .  There are numerous bounds of the form: assuming i.i.d. samples, with high probability over the drawn samples  S ,   e(c,D) less than e(c,S) + f(complexity)  where  complexity  is some measure of the size of a s</p><p>4 0.68971443 <a title="123-lsi-4" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>Introduction: Sam Roweis ‘s comment reminds me of a more general issue that comes up in doing research: abstractions always break.  
  
 Real number’s aren’t.  Most real numbers can not be represented with any machine.  One implication of this is that many real-number based algorithms have difficulties when implemented with floating point numbers. 
 The box on your desk is not a turing machine. A turing machine can compute anything computable, given sufficient time.  A typical computer fails terribly when the state required for the computation exceeds some limit. 
 Nash equilibria aren’t equilibria.  This comes up when trying to predict human behavior based on the result of the equilibria computation.  Often, it doesn’t work. 
 The  probability  isn’t.  Probability is an abstraction expressing either our lack of knowledge (the Bayesian viewpoint) or fundamental randomization (the frequentist viewpoint).  From the frequentist viewpoint the lack of knowledge typically precludes actually knowing the fu</p><p>5 0.59981585 <a title="123-lsi-5" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these suggest that some method of saying “I prefer this predictor to that predictor” is useful and necessary.  Examples include Bayesian reasoning, prediction bounds, and online learning.   One difficulty which arises is that the manner and meaning of saying “I prefer this predictor to that predictor” differs.
  
  Prior  (Bayesian) A prior is a probability distribution over a set of distributions which expresses a belief in the probability that some distribution is the distribution generating the data. 
  “Prior”  (Prediction bounds & online learning) The “prior” is a measure over a set of classifiers which expresses the degree to which you hope the classifier will predict well. 
  Bias  (Regularization, Early termination of neural network training, etc…)  The bias is some (often implicitly specified by an algorithm) way of preferring one predictor to another. 
  
This only scratches the surface—there are yet more subt</p><p>6 0.59734684 <a title="123-lsi-6" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>7 0.58081776 <a title="123-lsi-7" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>8 0.55055481 <a title="123-lsi-8" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>9 0.5371564 <a title="123-lsi-9" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>10 0.5143851 <a title="123-lsi-10" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>11 0.51128489 <a title="123-lsi-11" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>12 0.48632535 <a title="123-lsi-12" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>13 0.48612261 <a title="123-lsi-13" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>14 0.48404714 <a title="123-lsi-14" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>15 0.47259134 <a title="123-lsi-15" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>16 0.45921981 <a title="123-lsi-16" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>17 0.4583441 <a title="123-lsi-17" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>18 0.44900832 <a title="123-lsi-18" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>19 0.44247499 <a title="123-lsi-19" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>20 0.43878752 <a title="123-lsi-20" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.043), (10, 0.033), (27, 0.22), (38, 0.071), (53, 0.018), (55, 0.079), (69, 0.287), (94, 0.075), (95, 0.077)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.90022302 <a title="123-lda-1" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and to 
prevent overfitting. Various notion of “function complexity” often 
arise: VC dimension, Rademacher complexity, comparison classes of 
experts, and program length are just a few.
 
The term “complexity” to me seems somehow misleading; the terms never 
capture something that meets my intuitive notion of complexity. The 
Bayesian notion clearly captures what’s going on. Functions aren’t 
“complex”– they’re just “surprising”: we assign to them low 
probability. Most (all?) complexity notions I know boil down 
to some (generally loose) bound on the prior probability of the function.
 
In a sense, “complexity” fundementally arises because probability 
distributions must sum to one. You can’t believe in all possibilities 
at the same time, or at least not equally. Rather you have to 
carefully spread the probability mass over the options you’d like to 
consider. Large complexity classes means that beliefs are spread 
thinly. In</p><p>2 0.66474414 <a title="123-lda-2" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,  Sanjoy   made a post  saying roughly “we should  study active learning theoretically, because not much is understood”.   
 
At the time, we did not understand basic things such as whether or not it was possible to PAC-learn with an active algorithm without making strong assumptions about the noise rate.  In other words, the fundamental question was “can we do it?”
 
The nature of the question has fundamentally changed in my mind.   The answer is to the previous question is “yes”, both information theoretically and computationally, most places where supervised learning could be applied.  
 
In many situation, the question has now changed to: “is it worth it?”  Is the programming and computational overhead low enough to make the label cost savings of active learning worthwhile?  Currently, there are situations where this question could go either way.  Much of the challenge for the future is in figuring out how to make active learning easier or more worthwhile.</p><p>3 0.66415596 <a title="123-lda-3" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but sometimes the unfairness seems particularly striking.  This is most easily seen by comparison:
  
 
 Paper 
  Banditron  
  Offset Tree  
 Notes 
 
 
 Problem Scope 
 Multiclass problems where only the loss of one choice can be probed. 
 Strictly greater: Cost sensitive multiclass problems where only the loss of one choice can be probed. 
 Often generalizations don’t matter.  That’s not the case here, since every plausible application I’ve thought of involves loss functions substantially different from 0/1. 
 
 
 What’s new 
 Analysis and Experiments 
 Algorithm, Analysis, and Experiments 
  As far as I know, the essence of the more general problem was first stated and analyzed with the  EXP4 algorithm (page 16)  (1998).  It’s also the time horizon 1 simplification of the Reinforcement Learning setting for the  random trajectory method (page 15)  (2002).  The Banditron algorithm itself is functionally identi</p><p>4 0.66204464 <a title="123-lda-4" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>Introduction: The funding of research (and machine learning research) is an issue which seems to have become more significant in the United States over the last decade.  The word “research” is applied broadly here to science, mathematics, and engineering.
 
There are two essential difficulties with funding research:
  
  Longshot  Paying a researcher is often a big gamble.  Most research projects don’t pan out, but a few big payoffs can make it all worthwhile. 
  Information Only  Much of research is about finding the right way to think about or do something.  
  
The Longshot difficulty means that there is high variance in payoffs.  This can be compensated for by funding many different research projects, reducing variance.
 
The Information-Only difficulty means that it’s hard to extract a profit directly from many types of research, so companies have difficulty justifying basic research.  (Patents are a mechanism for doing this.  They are often extraordinarily clumsy or simply not applicable.)
 
T</p><p>5 0.65833962 <a title="123-lda-5" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?
 
The most immediate measurable objective of computer science research is publishing a paper.  The most difficult aspect of publishing a paper is having reviewers accept and recommend it for publication.  The simplest mechanism for doing this is to show theoretical progress on some standard, well-known easily understood problem.
 
In doing this, we often fall into a local minima of the research process.  The basic problem in machine learning is that it is very unclear that the mathematical model is the right one for the (or some) real problem.  A good mathematical model in machine learning should have one fundamental trait: it should aid the design of effective learning algorithms.  To date, our ability to solve interesting learning problems (speech recognition, machine translation, object recognition, etc…) remains limited (although improving), so the “rightness” of our models is in doubt.
 
If our mathematical mod</p><p>6 0.655864 <a title="123-lda-6" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>7 0.65528399 <a title="123-lda-7" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>8 0.65371758 <a title="123-lda-8" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>9 0.65360808 <a title="123-lda-9" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>10 0.64950079 <a title="123-lda-10" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>11 0.64945149 <a title="123-lda-11" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>12 0.64887959 <a title="123-lda-12" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>13 0.64861834 <a title="123-lda-13" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>14 0.64856482 <a title="123-lda-14" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>15 0.64832062 <a title="123-lda-15" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>16 0.64765221 <a title="123-lda-16" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>17 0.64684385 <a title="123-lda-17" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>18 0.64607155 <a title="123-lda-18" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>19 0.64508665 <a title="123-lda-19" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>20 0.64481235 <a title="123-lda-20" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
