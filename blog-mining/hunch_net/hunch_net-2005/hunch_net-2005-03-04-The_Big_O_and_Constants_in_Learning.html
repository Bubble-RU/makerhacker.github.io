<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>35 hunch net-2005-03-04-The Big O and Constants in Learning</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-35" href="#">hunch_net-2005-35</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>35 hunch net-2005-03-04-The Big O and Constants in Learning</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-35-html" href="http://hunch.net/?p=38">html</a></p><p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there exists a constantCsuch that theg(n)is less thanCf(n). [sent-1, score-0.245]
</p><p>2 In learning theory, there are many statements about learning algorithms of the form "under assumptionsx,y, andz, the classifier learned has an error rate of at mostO(f(m))". [sent-2, score-0.461]
</p><p>3 There is one very good reason to use O(): it helps you understand the big picture and neglect the minor details which are not important in the big picture. [sent-3, score-0.836]
</p><p>4 However, there are some important reasons not to do this as well. [sent-4, score-0.091]
</p><p>5 UnspeedupIn algorithm analysis, the use of O() for time complexity is pervasive and well-justified. [sent-5, score-0.441]
</p><p>6 Determining the exact value of C is inherently computer architecture dependent. [sent-6, score-0.326]
</p><p>7 (The "C" for x86 processors might differ from the "C" on PowerPC processors. [sent-7, score-0.237]
</p><p>8 ) Since many learning theorists come from a CS theory background, the O() notation is applied to generalization error. [sent-8, score-0.477]
</p><p>9 The O() abstraction breaks here--you can not generally change learning algorithm and decrease your error rate by some constant factor. [sent-9, score-0.888]
</p><p>10 You're firedWhen you go and run a learning algorithm to acquire some predictor, the performance it achieves is a key quantity of significant interest. [sent-10, score-0.545]
</p><p>11 Using an algorithm with merely twice the error rate of a better algorithm can easily make the difference between "it works" and "it doesn't". [sent-11, score-0.968]
</p><p>12 This is not often true when programming, as evidenced by the large number of people who use computationally inefficient languages to solve problems. [sent-12, score-0.535]
</p><p>13 We can't say "never useO()", because sometimes abstracting away details is the right thing to do. [sent-13, score-0.392]
</p><p>14 However, any use ofO()should be analyzed for "reasonableness" more thoroughly than for computational complexity. [sent-14, score-0.38]
</p><p>15 Similarly, more interest should be allocated to improving constants in such analysis than is done in algorithms. [sent-15, score-0.494]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('error', 0.186), ('algorithm', 0.181), ('rate', 0.18), ('abstracting', 0.156), ('reasonableness', 0.156), ('theg', 0.156), ('constantcsuch', 0.144), ('infinity', 0.144), ('evidenced', 0.144), ('ofo', 0.144), ('theorists', 0.144), ('details', 0.141), ('constants', 0.136), ('achieves', 0.136), ('allocated', 0.136), ('architecture', 0.136), ('inefficient', 0.136), ('processors', 0.136), ('use', 0.135), ('picture', 0.13), ('breaks', 0.13), ('determining', 0.13), ('analysis', 0.128), ('pervasive', 0.125), ('acquire', 0.125), ('notation', 0.125), ('thoroughly', 0.125), ('analyzed', 0.12), ('merely', 0.12), ('languages', 0.12), ('twice', 0.12), ('however', 0.118), ('big', 0.118), ('abstraction', 0.116), ('generalization', 0.113), ('cs', 0.107), ('exact', 0.105), ('background', 0.105), ('minor', 0.103), ('quantity', 0.103), ('differ', 0.101), ('limit', 0.101), ('constant', 0.095), ('statements', 0.095), ('away', 0.095), ('theory', 0.095), ('improving', 0.094), ('important', 0.091), ('inherently', 0.085), ('programming', 0.085)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="35-tfidf-1" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>2 0.19562939 <a title="35-tfidf-2" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for thereductions
tutorialAlina,Bianca, and I are planning to do atICML. Please come, if you are
interested.Many research programs can be thought of as finding and building
new useful abstractions. The running example I'll use islearning
reductionswhere I have experience. The basic abstraction here is that we can
build a learning algorithm capable of solving classification problems up to a
small expected regret. This is used repeatedly to solve more complex
problems.In working on a new abstraction, I think you typically run into many
substantial problems of understanding, which make publishing particularly
difficult.It is difficult to seriously discuss the reason behind or mechanism
for abstraction in a conference paper with small page limits. People rarely
see such discussions and hence have little basis on which to think about new
abstractions. Another difficulty is that when building an abstraction, you
often don't know the right way to</p><p>3 0.18637145 <a title="35-tfidf-3" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>Introduction: This post is about a reductions-related problem that I find mysterious. There
are two kinds of reductions analysis currently under consideration.Error
limiting reductions. Here, the goal is to bound the error rate of the created
classifier in terms of the error rate of the binary classifiers that you
reduce to. A very simple example of this is thaterror correcting output
codeswhere it is possible to prove that for certain codes, the multiclass
error rate is at most 4 * the binary classifier error rate.Regret minimizing
reductions. Here, the goal is to bound theregretof the created classifier in
terms of theregretof the binary classifiers reduced to. The regret is the
error rate minus the minimum error rate. When the learning problem is noisy
the minimum error rate may not be0. An analagous result for reget is that for
aprobabilistic error correcting output code, multiclass regret is at most 4 *
(binary regret)0.5.The use of "regret" is more desirable than the use of error
rates, becaus</p><p>4 0.16993622 <a title="35-tfidf-4" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>Introduction: I've had serious conversations with several people who believe that the theory
in machine learning is "only useful for getting papers published". That's a
compelling statement, as I've seen many papers where the algorithm clearly
came first, and the theoretical justification for it came second, purely as a
perceived means to improve the chance of publication.Naturally, I disagree and
believe that learning theory has much more substantial applications.Even in
core learning algorithm design, I've found learning theory to be useful,
although it's application is more subtle than many realize. The most
straightforward applications can fail, because (as expectation suggests) worst
case bounds tend to be loose in practice (*). In my experience, considering
learning theory when designing an algorithm has two important effects in
practice:It can help make your algorithm behave right at a crude level of
analysis, leaving finer details to tuning or common sense. The best example I
have of this is</p><p>5 0.1574481 <a title="35-tfidf-5" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>Introduction: Jacob Abernethy and I have found a computationally tractable method for
computing an optimal (or near optimal depending on setting) master algorithm
combining expert predictions addressingthis open problem. A draft ishere.The
effect of this improvement seems to be about a factor of2decrease in the
regret (= error rate minus best possible error rate) for the low error rate
situation. (At large error rates, there may be no significant
difference.)There are some unfinished details still to consider:When we remove
all of the approximation slack from online learning, is the result a
satisfying learning algorithm, in practice? I consider online learning is one
of the more compelling methods of analyzing and deriving algorithms, but that
expectation must be either met or not by this algorithmSome extra details: The
algorithm is optimal given a small amount of side information (kin the draft).
What is the best way to remove this side information? The removal is necessary
for a practical algori</p><p>6 0.15723863 <a title="35-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>7 0.12958549 <a title="35-tfidf-7" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>8 0.11898106 <a title="35-tfidf-8" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>9 0.11735348 <a title="35-tfidf-9" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>10 0.11302381 <a title="35-tfidf-10" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>11 0.11148436 <a title="35-tfidf-11" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>12 0.11018469 <a title="35-tfidf-12" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>13 0.1087376 <a title="35-tfidf-13" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>14 0.10658763 <a title="35-tfidf-14" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>15 0.10299441 <a title="35-tfidf-15" href="../hunch_net-2006/hunch_net-2006-10-22-Exemplar_programming.html">215 hunch net-2006-10-22-Exemplar programming</a></p>
<p>16 0.10176817 <a title="35-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>17 0.099235445 <a title="35-tfidf-17" href="../hunch_net-2005/hunch_net-2005-06-22-Languages__of_Learning.html">84 hunch net-2005-06-22-Languages  of Learning</a></p>
<p>18 0.098362863 <a title="35-tfidf-18" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>19 0.097597644 <a title="35-tfidf-19" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>20 0.096194513 <a title="35-tfidf-20" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.237), (1, -0.116), (2, -0.021), (3, -0.024), (4, -0.032), (5, -0.102), (6, 0.052), (7, 0.08), (8, 0.074), (9, 0.089), (10, -0.016), (11, -0.038), (12, -0.022), (13, -0.092), (14, -0.044), (15, 0.032), (16, -0.04), (17, 0.019), (18, 0.113), (19, 0.013), (20, -0.013), (21, -0.021), (22, 0.038), (23, -0.026), (24, 0.093), (25, 0.056), (26, 0.052), (27, -0.064), (28, 0.012), (29, -0.034), (30, 0.03), (31, 0.014), (32, -0.056), (33, -0.133), (34, 0.024), (35, -0.04), (36, -0.182), (37, -0.002), (38, 0.069), (39, -0.134), (40, -0.005), (41, 0.017), (42, -0.056), (43, -0.094), (44, -0.053), (45, -0.031), (46, -0.084), (47, -0.124), (48, 0.081), (49, 0.022)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95918268 <a title="35-lsi-1" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>2 0.74213505 <a title="35-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>3 0.69118506 <a title="35-lsi-3" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>Introduction: Jacob Abernethy and I have found a computationally tractable method for
computing an optimal (or near optimal depending on setting) master algorithm
combining expert predictions addressingthis open problem. A draft ishere.The
effect of this improvement seems to be about a factor of2decrease in the
regret (= error rate minus best possible error rate) for the low error rate
situation. (At large error rates, there may be no significant
difference.)There are some unfinished details still to consider:When we remove
all of the approximation slack from online learning, is the result a
satisfying learning algorithm, in practice? I consider online learning is one
of the more compelling methods of analyzing and deriving algorithms, but that
expectation must be either met or not by this algorithmSome extra details: The
algorithm is optimal given a small amount of side information (kin the draft).
What is the best way to remove this side information? The removal is necessary
for a practical algori</p><p>4 0.63643223 <a title="35-lsi-4" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for thereductions
tutorialAlina,Bianca, and I are planning to do atICML. Please come, if you are
interested.Many research programs can be thought of as finding and building
new useful abstractions. The running example I'll use islearning
reductionswhere I have experience. The basic abstraction here is that we can
build a learning algorithm capable of solving classification problems up to a
small expected regret. This is used repeatedly to solve more complex
problems.In working on a new abstraction, I think you typically run into many
substantial problems of understanding, which make publishing particularly
difficult.It is difficult to seriously discuss the reason behind or mechanism
for abstraction in a conference paper with small page limits. People rarely
see such discussions and hence have little basis on which to think about new
abstractions. Another difficulty is that when building an abstraction, you
often don't know the right way to</p><p>5 0.60132098 <a title="35-lsi-5" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>Introduction: Machine learning algorithms have a much better chance of being widely adopted
if they are implemented in some easy-to-use code. There are several important
concerns associated with machine learning which stress programming languages
on the ease-of-use vs. speed frontier.SpeedThe rate at which data sources are
growing seems to be outstripping the rate at which computational power is
growing, so it is important that we be able to eak out every bit of
computational power. Garbage collected languages (java,ocaml,perlandpython)
often have several issues here.Garbage collection often implies that floating
point numbers are "boxed": every float is represented by a pointer to a float.
Boxing can cause an order of magnitude slowdown because an extra nonlocalized
memory reference is made, and accesses to main memory can are many CPU cycles
long.Garbage collection often implies that considerably more memory is used
than is necessary. This has a variable effect. In some circumstances it
results in</p><p>6 0.5814395 <a title="35-lsi-6" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>7 0.57192022 <a title="35-lsi-7" href="../hunch_net-2010/hunch_net-2010-04-14-MLcomp%3A_a_website_for_objectively_comparing_ML_algorithms.html">393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</a></p>
<p>8 0.56474602 <a title="35-lsi-8" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>9 0.55695617 <a title="35-lsi-9" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>10 0.55638379 <a title="35-lsi-10" href="../hunch_net-2005/hunch_net-2005-06-22-Languages__of_Learning.html">84 hunch net-2005-06-22-Languages  of Learning</a></p>
<p>11 0.55080056 <a title="35-lsi-11" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>12 0.54961818 <a title="35-lsi-12" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>13 0.544671 <a title="35-lsi-13" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>14 0.53996569 <a title="35-lsi-14" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>15 0.53303665 <a title="35-lsi-15" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>16 0.53060991 <a title="35-lsi-16" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>17 0.51170903 <a title="35-lsi-17" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>18 0.50869584 <a title="35-lsi-18" href="../hunch_net-2006/hunch_net-2006-10-22-Exemplar_programming.html">215 hunch net-2006-10-22-Exemplar programming</a></p>
<p>19 0.50543779 <a title="35-lsi-19" href="../hunch_net-2005/hunch_net-2005-02-12-ROC_vs._Accuracy_vs._AROC.html">18 hunch net-2005-02-12-ROC vs. Accuracy vs. AROC</a></p>
<p>20 0.49754095 <a title="35-lsi-20" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.013), (34, 0.38), (35, 0.029), (42, 0.238), (68, 0.067), (69, 0.017), (74, 0.11), (95, 0.057)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97229064 <a title="35-lda-1" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>Introduction: Iainnoticed that hunch.net had zero width divs hiding spammy URLs. Some
investigation reveals that the wordpress version being used (2.0.3) had
security flaws. I've upgraded to the latest, rotated passwords, and removed
the spammy URLs. I don't believe any content was lost. You can check your own
and other sites for a similar problem by greping for "width:0″ or "width: 0″
in the delivered html source.</p><p>2 0.88891768 <a title="35-lda-2" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>Introduction: I justpresentedthecross validationproblem atCOLT.The problem now has a cash
prize (up to $500) associated with it--see thepresentationfor details
.Thewrite-up for colt.</p><p>same-blog 3 0.84669244 <a title="35-lda-3" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>4 0.75370264 <a title="35-lda-4" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>Introduction: Multitask learning is the problem of jointly predicting multiple labels
simultaneously with one system. A basic question iswhether or not multitask
learning can be decomposed into one (or more) single prediction problems. It
seems the answer to this is "yes", in a fairly straightforward manner.The
basic idea is that a controlled input feature is equivalent to an extra
output. Suppose we have some process generating examples:(x,y1,y2) in
Swherey1andy2are labels for two different tasks. Then, we could reprocess the
data to the formSb(S) = {((x,i),yi): (x,y1,y2) in S, i in {1,2}}and then learn
a classifierc:X x {1,2} -> Y. Note that(x,i)is the (composite) input. At
testing time, given an inputx, we can querycfor the predicted values of y1and
y2using(x,1)and(x,2).A strong form of equivalence can be stated between these
tasks. In particular, suppose we have a multitask learning algorithmMLwhich
learns a multitask predictorm:X -> Y x Y. Then the following theorem can be
proved:For allMLfor a</p><p>5 0.58074856 <a title="35-lda-5" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>Introduction: I wanted to expand on thispostand some of the previousproblems/research
directionsabout where learning theory might make large strides.Why theory?The
essential reason for theory is "intuition extension". A very good applied
learning person can master some particular application domain yielding the
best computer algorithms for solving that problem. A very good theory can take
the intuitions discovered by this and other applied learning people and extend
them to new domains in a relatively automatic fashion. To do this, we take
these basic intuitions and try to find a mathematical model that:Explains the
basic intuitions.Makes new testable predictions about how to learn.Succeeds in
so learning.This is "intuition extension": taking what we have learned
somewhere else and applying it in new domains. It is fundamentally useful to
everyone because it increases the level of automation in solving
problems.Where next for learning theory?I like the analogy with physics. Back
before we-the-humans</p><p>6 0.57632083 <a title="35-lda-6" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>7 0.57580578 <a title="35-lda-7" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>8 0.57395685 <a title="35-lda-8" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>9 0.5733459 <a title="35-lda-9" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>10 0.5731352 <a title="35-lda-10" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>11 0.57312942 <a title="35-lda-11" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>12 0.57265419 <a title="35-lda-12" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>13 0.57265186 <a title="35-lda-13" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>14 0.57232338 <a title="35-lda-14" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>15 0.57135516 <a title="35-lda-15" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>16 0.57059026 <a title="35-lda-16" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>17 0.57013011 <a title="35-lda-17" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>18 0.56986928 <a title="35-lda-18" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>19 0.56892735 <a title="35-lda-19" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>20 0.56876296 <a title="35-lda-20" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
