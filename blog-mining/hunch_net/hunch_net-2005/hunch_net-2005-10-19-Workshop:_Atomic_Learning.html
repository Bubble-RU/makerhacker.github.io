<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>124 hunch net-2005-10-19-Workshop: Atomic Learning</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-124" href="#">hunch_net-2005-124</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>124 hunch net-2005-10-19-Workshop: Atomic Learning</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-124-html" href="http://hunch.net/?p=135">html</a></p><p>Introduction: We are planning to have a workshop on atomic learning Jan 7 & 8 at TTI-
Chicago.Details are here.The earlier request for interest ishere.The primary
deadline is abstracts due Nov. 20 to jl@tti-c.org.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('request', 0.456), ('jl', 0.411), ('abstracts', 0.411), ('earlier', 0.319), ('planning', 0.291), ('deadline', 0.274), ('primary', 0.274), ('workshop', 0.229), ('interest', 0.186), ('due', 0.173), ('learning', 0.032)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="124-tfidf-1" href="../hunch_net-2005/hunch_net-2005-10-19-Workshop%3A_Atomic_Learning.html">124 hunch net-2005-10-19-Workshop: Atomic Learning</a></p>
<p>Introduction: We are planning to have a workshop on atomic learning Jan 7 & 8 at TTI-
Chicago.Details are here.The earlier request for interest ishere.The primary
deadline is abstracts due Nov. 20 to jl@tti-c.org.</p><p>2 0.24796201 <a title="124-tfidf-2" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<p>Introduction: Many Machine Learning related events are coming up this fall.September
9,abstracts for the New York Machine Learning Symposiumare due. Send a 2 page
pdf, if interested, and note that we:widened submissions to be from anybody
rather than students.set aside a larger fraction of time for contributed
submissions.September 15, there is amachine learning meetup, where I'll be
discussing terascale learning at AOL.September 16, there is aCS&Econ; dayat New
York Academy of Sciences. This is not ML focused, but it's easy to imagine
interest.September 23 and laterNIPS workshopsubmissions start coming due. As
usual, there are too many good ones, so I won't be able to attend all those
that interest me. I do hope some workshop makers consider ICML this coming
summer, as we are increasing to a 2 day format for you. Here are a few that
interest me:Big Learningis about dealing with lots of data. Abstracts are
dueSeptember 30.TheBayes Banditsworkshop. Abstracts are dueSeptember
23.ThePersonalized Medicin</p><p>3 0.17819521 <a title="124-tfidf-3" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>Introduction: Many of theNIPS workshopshave a deadline about now, and the NIPSearly
registration deadline is Nov. 6. Several interest me:Adaptive Sensing, Active
Learning, and Experimental Designdue 10/27.Discrete Optimization in Machine
Learning: Submodularity, Sparsity & Polyhedra, due Nov. 6.Large-Scale Machine
Learning: Parallelism and Massive Datasets, due 10/23 (i.e. past)Analysis and
Design of Algorithms for Interactive Machine Learning, due 10/30.And I'm sure
many of the others interest others. Workshops are great as a mechanism for
research, so take a look if there is any chance you might be interested.</p><p>4 0.15187536 <a title="124-tfidf-4" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<p>Introduction: Adam Kalaipoints out theNew England Machine Learning DayMay 1 at MSR New
England. There is a poster session with abstracts due April 19. I understand
last year'sNEMLwent well and it's great to meet your neighbors at regional
workshops like this.</p><p>5 0.14703116 <a title="124-tfidf-5" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>Introduction: As usualICML 2007will be hosting aworkshop programto be held this year on June
24th. The success of the program depends on having researchers like you
propose interesting workshop topics and then organize the workshops. I'd like
to encourage all of you to consider sending a workshop proposal. The proposal
deadline has been extended to March 5. See the workshop web-site for
details.Organizing a workshop is a unique way to gather an international group
of researchers together to focus for an entire day on a topic of your
choosing. I've always found that the cost of organizing a workshop is not so
large, and very low compared to the benefits. The topic and format of a
workshop are limited only by your imagination (and the attractiveness to
potential participants) and need not follow the usual model of a mini-
conference on a particular ML sub-area. Hope to see some interesting proposals
rolling in.</p><p>6 0.13787416 <a title="124-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>7 0.13184729 <a title="124-tfidf-7" href="../hunch_net-2012/hunch_net-2012-07-17-MUCMD_and_BayLearn.html">470 hunch net-2012-07-17-MUCMD and BayLearn</a></p>
<p>8 0.10447001 <a title="124-tfidf-8" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>9 0.10233714 <a title="124-tfidf-9" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>10 0.10092572 <a title="124-tfidf-10" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>11 0.094567738 <a title="124-tfidf-11" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>12 0.091695286 <a title="124-tfidf-12" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>13 0.089335337 <a title="124-tfidf-13" href="../hunch_net-2006/hunch_net-2006-07-25-Upcoming_conference.html">198 hunch net-2006-07-25-Upcoming conference</a></p>
<p>14 0.085562356 <a title="124-tfidf-14" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>15 0.083411753 <a title="124-tfidf-15" href="../hunch_net-2008/hunch_net-2008-10-19-NIPS_2008_workshop_on_Kernel_Learning.html">321 hunch net-2008-10-19-NIPS 2008 workshop on Kernel Learning</a></p>
<p>16 0.079667211 <a title="124-tfidf-16" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>17 0.075931787 <a title="124-tfidf-17" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>18 0.075363286 <a title="124-tfidf-18" href="../hunch_net-2012/hunch_net-2012-02-24-ICML%2B50%25.html">456 hunch net-2012-02-24-ICML+50%</a></p>
<p>19 0.073500209 <a title="124-tfidf-19" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>20 0.071909085 <a title="124-tfidf-20" href="../hunch_net-2011/hunch_net-2011-04-23-ICML_workshops_due.html">433 hunch net-2011-04-23-ICML workshops due</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.059), (1, 0.078), (2, 0.107), (3, 0.237), (4, -0.025), (5, -0.065), (6, -0.034), (7, -0.027), (8, -0.017), (9, 0.023), (10, 0.063), (11, 0.097), (12, 0.016), (13, -0.046), (14, 0.03), (15, -0.11), (16, -0.085), (17, -0.089), (18, -0.02), (19, 0.028), (20, 0.014), (21, -0.064), (22, 0.038), (23, 0.15), (24, -0.115), (25, 0.029), (26, 0.096), (27, -0.164), (28, 0.023), (29, 0.066), (30, -0.095), (31, -0.05), (32, 0.006), (33, -0.008), (34, 0.079), (35, 0.096), (36, 0.038), (37, 0.049), (38, 0.014), (39, -0.009), (40, 0.192), (41, 0.046), (42, -0.005), (43, 0.049), (44, -0.026), (45, -0.084), (46, -0.062), (47, -0.007), (48, 0.07), (49, 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.984079 <a title="124-lsi-1" href="../hunch_net-2005/hunch_net-2005-10-19-Workshop%3A_Atomic_Learning.html">124 hunch net-2005-10-19-Workshop: Atomic Learning</a></p>
<p>Introduction: We are planning to have a workshop on atomic learning Jan 7 & 8 at TTI-
Chicago.Details are here.The earlier request for interest ishere.The primary
deadline is abstracts due Nov. 20 to jl@tti-c.org.</p><p>2 0.60883254 <a title="124-lsi-2" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<p>Introduction: Many Machine Learning related events are coming up this fall.September
9,abstracts for the New York Machine Learning Symposiumare due. Send a 2 page
pdf, if interested, and note that we:widened submissions to be from anybody
rather than students.set aside a larger fraction of time for contributed
submissions.September 15, there is amachine learning meetup, where I'll be
discussing terascale learning at AOL.September 16, there is aCS&Econ; dayat New
York Academy of Sciences. This is not ML focused, but it's easy to imagine
interest.September 23 and laterNIPS workshopsubmissions start coming due. As
usual, there are too many good ones, so I won't be able to attend all those
that interest me. I do hope some workshop makers consider ICML this coming
summer, as we are increasing to a 2 day format for you. Here are a few that
interest me:Big Learningis about dealing with lots of data. Abstracts are
dueSeptember 30.TheBayes Banditsworkshop. Abstracts are dueSeptember
23.ThePersonalized Medicin</p><p>3 0.59328306 <a title="124-lsi-3" href="../hunch_net-2012/hunch_net-2012-07-17-MUCMD_and_BayLearn.html">470 hunch net-2012-07-17-MUCMD and BayLearn</a></p>
<p>Introduction: The workshop on theMeaningful Use of Complex Medical Datais happening again,
August 9-12 in LA, nearUAIon Catalina Island August 15-17. I enjoyed my visit
last year, and expect this year to be interesting also.The firstBay Area
Machine Learning Symposiumis August 30 atGoogle. Abstracts are due July 30.</p><p>4 0.57593763 <a title="124-lsi-4" href="../hunch_net-2008/hunch_net-2008-10-19-NIPS_2008_workshop_on_Kernel_Learning.html">321 hunch net-2008-10-19-NIPS 2008 workshop on Kernel Learning</a></p>
<p>Introduction: We'd like to invite hunch.net readers to participate in the NIPS 2008 workshop
on kernel learning. While the main focus is on automatically learning kernels
from data, we are also also looking at the broader questions of feature
selection, multi-task learning and multi-view learning. There are no
restrictions on the learning problem being addressed (regression,
classification, etc), and both theoretical and applied work will be
considered. The deadline for submissions isOctober 24.More detail can be
foundhere.Corinna Cortes, Arthur Gretton, Gert Lanckriet, Mehryar Mohri,
Afshin Rostamizadeh</p><p>5 0.5645979 <a title="124-lsi-5" href="../hunch_net-2006/hunch_net-2006-07-25-Upcoming_conference.html">198 hunch net-2006-07-25-Upcoming conference</a></p>
<p>Introduction: The Workshop for Women in Machine Learning will be held in San Diego on
October 4, 2006.For details see the workshop
website:http://www.seas.upenn.edu/~wiml/</p><p>6 0.54046899 <a title="124-lsi-6" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>7 0.53607422 <a title="124-lsi-7" href="../hunch_net-2011/hunch_net-2011-04-23-ICML_workshops_due.html">433 hunch net-2011-04-23-ICML workshops due</a></p>
<p>8 0.50262064 <a title="124-lsi-8" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>9 0.49216887 <a title="124-lsi-9" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<p>10 0.47795925 <a title="124-lsi-10" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>11 0.46882284 <a title="124-lsi-11" href="../hunch_net-2010/hunch_net-2010-08-20-The_Workshop_on_Cores%2C_Clusters%2C_and_Clouds.html">404 hunch net-2010-08-20-The Workshop on Cores, Clusters, and Clouds</a></p>
<p>12 0.4645468 <a title="124-lsi-12" href="../hunch_net-2008/hunch_net-2008-10-01-NIPS_2008_workshop_on_%26%238216%3BLearning_over_Empirical_Hypothesis_Spaces%26%238217%3B.html">319 hunch net-2008-10-01-NIPS 2008 workshop on &#8216;Learning over Empirical Hypothesis Spaces&#8217;</a></p>
<p>13 0.43023035 <a title="124-lsi-13" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>14 0.42584458 <a title="124-lsi-14" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>15 0.40763813 <a title="124-lsi-15" href="../hunch_net-2007/hunch_net-2007-10-14-NIPS_workshp%3A_Learning_Problem_Design.html">265 hunch net-2007-10-14-NIPS workshp: Learning Problem Design</a></p>
<p>16 0.39786819 <a title="124-lsi-16" href="../hunch_net-2012/hunch_net-2012-03-13-The_Submodularity_workshop_and_Lucca_Professorship.html">459 hunch net-2012-03-13-The Submodularity workshop and Lucca Professorship</a></p>
<p>17 0.39187112 <a title="124-lsi-17" href="../hunch_net-2012/hunch_net-2012-02-24-ICML%2B50%25.html">456 hunch net-2012-02-24-ICML+50%</a></p>
<p>18 0.38406783 <a title="124-lsi-18" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>19 0.36117738 <a title="124-lsi-19" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">285 hunch net-2008-01-23-Why Workshop?</a></p>
<p>20 0.34455058 <a title="124-lsi-20" href="../hunch_net-2011/hunch_net-2011-01-03-Herman_Goldstine_2011.html">421 hunch net-2011-01-03-Herman Goldstine 2011</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.083), (67, 0.632), (88, 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95113581 <a title="124-lda-1" href="../hunch_net-2005/hunch_net-2005-10-19-Workshop%3A_Atomic_Learning.html">124 hunch net-2005-10-19-Workshop: Atomic Learning</a></p>
<p>Introduction: We are planning to have a workshop on atomic learning Jan 7 & 8 at TTI-
Chicago.Details are here.The earlier request for interest ishere.The primary
deadline is abstracts due Nov. 20 to jl@tti-c.org.</p><p>2 0.59830123 <a title="124-lda-2" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>Introduction: One of the most confusing things about understanding learning theory is the
vast array of differing assumptions. Some critical thought about which of
these assumptions are reasonable for real-world problems may be useful.Before
we even start thinking about assumptions, it's important to realize that the
word hasmultiple meanings. The meaning used here is "assumption = axiom" (i.e.
something you can not verify).AssumptionReasonable?Which
analysis?Example/notesIndependent and Identically Distributed
DataSometimesPAC,ERM,Prediction bounds,statisticsTheKDD cup 2004 physics
datasetis plausibly IID data. There are a number of situations which are
"almost IID" in the sense that IID analysis results in correct intuitions.
Unreasonable in adversarial situations (stock market, war, etcâ&euro;Ś)Independently
Distributed DataMore than IID, but still only sometimesonline->batch
conversionLosing "identical" can be helpful in situations where you have a
cyclic process generating data.Finite exchangeability</p><p>3 0.51862735 <a title="124-lda-3" href="../hunch_net-2011/hunch_net-2011-06-22-Ultra_LDA.html">436 hunch net-2011-06-22-Ultra LDA</a></p>
<p>Introduction: ShravanandAlex's LDA code isreleased. On a single machine, I'm not sure how it
currently compares to the online LDA inVW, but the ability to effectively
scale across very many machines is surely interesting.</p><p>4 0.29898769 <a title="124-lda-4" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>Introduction: Founding a successful new conference is extraordinarily difficult. As a
conference founder, you must manage to attract a significant number of good
papers--enough to entice the participants into participating next year and to
(generally) to grow the conference. For someone choosing to participate in a
new conference, there is a very significant decision to make: do you send a
paper to some new conference with no guarantee that the conference will work
out? Or do you send it to another (possibly less related) conference that you
are sure will work?The conference founding problem is a joint agreement
problem with a very significant barrier. Workshops are a way around this
problem, and workshops attached to conferences are a particularly effective
means for this. A workshop at a conference is sure to have people available to
speak and attend and is sure to have a large audience available. Presenting
work at a workshop is not generally exclusive: it can also be presented at a
conference. F</p><p>5 0.28813136 <a title="124-lda-5" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>Introduction: Machine Learning is a field with an impressively diverse set of reseearch
styles. Understanding this may be important in appreciating what you see at a
conference.Engineering. How can I solve this problem? People in the
engineering research style try to solve hard problems directly by any means
available and then describe how they did it. This is typical of problem-
specific conferences and communities.Scientific. What are the principles for
solving learning problems? People in this research style test techniques on
many different problems. This is fairly common at ICML and NIPS.Mathematical.
How can the learning problem be mathematically understood? People in this
research style prove theorems with implications for learning but often do not
implement (or test algorithms). COLT is a typical conference for this
style.Many people manage to cross these styles, and that is often
beneficial.Whenver we list a set of alternative, it becomes natural to think
"which is best?" In this case of le</p><p>6 0.24779312 <a title="124-lda-6" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>7 0.19721799 <a title="124-lda-7" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>8 0.16868775 <a title="124-lda-8" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>9 0.16139086 <a title="124-lda-9" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>10 0.14640278 <a title="124-lda-10" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>11 0.14459543 <a title="124-lda-11" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>12 0.14413053 <a title="124-lda-12" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>13 0.14329819 <a title="124-lda-13" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>14 0.14217977 <a title="124-lda-14" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>15 0.13940477 <a title="124-lda-15" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>16 0.13487068 <a title="124-lda-16" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>17 0.1337482 <a title="124-lda-17" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>18 0.13282731 <a title="124-lda-18" href="../hunch_net-2012/hunch_net-2012-12-29-Simons_Institute_Big_Data_Program.html">476 hunch net-2012-12-29-Simons Institute Big Data Program</a></p>
<p>19 0.13146317 <a title="124-lda-19" href="../hunch_net-2010/hunch_net-2010-08-23-Boosted_Decision_Trees_for_Deep_Learning.html">407 hunch net-2010-08-23-Boosted Decision Trees for Deep Learning</a></p>
<p>20 0.12994318 <a title="124-lda-20" href="../hunch_net-2011/hunch_net-2011-12-13-Vowpal_Wabbit_version_6.1_%26%23038%3B_the_NIPS_tutorial.html">451 hunch net-2011-12-13-Vowpal Wabbit version 6.1 &#038; the NIPS tutorial</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
