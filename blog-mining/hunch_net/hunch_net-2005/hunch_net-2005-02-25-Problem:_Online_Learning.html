<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>28 hunch net-2005-02-25-Problem: Online Learning</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-28" href="#">hunch_net-2005-28</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>28 hunch net-2005-02-25-Problem: Online Learning</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-28-html" href="http://hunch.net/?p=32">html</a></p><p>Introduction: Despite my best intentions, this is not a fully specified problem, but rather
a research direction.Competitive online learning is one of the more compelling
pieces of learning theory because typical statements of the form "this
algorithm will perform almost as well as a large set of other algorithms" rely
only on fully-observable quantities, and are therefore applicable in many
situations. Examples includeWinnow,Weighted Majority, andBinomial Weighting.
Algorithms with this property haven't taken over the world yet. Here might be
some reasons:Lack of caring. Many people working on learning theory don't care
about particular applications much. This means constants in the algorithm are
not optimized, usable code is often not produced, and empirical studies aren't
done.Inefficiency. Viewed from the perspective of other learning algorithms,
online learning is terribly inefficient. It requires that every hypothesis
(called an expert in the online learning setting) be enumerated and tested o</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('introduce', 0.238), ('discovering', 0.202), ('possibly', 0.192), ('forms', 0.177), ('efficiently', 0.177), ('perform', 0.168), ('fully', 0.156), ('mysterious', 0.142), ('payoff', 0.142), ('terribly', 0.142), ('online', 0.14), ('algorithm', 0.133), ('structure', 0.133), ('binomial', 0.132), ('similarities', 0.132), ('usable', 0.132), ('theory', 0.13), ('constants', 0.125), ('intuitive', 0.114), ('studies', 0.114)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="28-tfidf-1" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>Introduction: Despite my best intentions, this is not a fully specified problem, but rather
a research direction.Competitive online learning is one of the more compelling
pieces of learning theory because typical statements of the form "this
algorithm will perform almost as well as a large set of other algorithms" rely
only on fully-observable quantities, and are therefore applicable in many
situations. Examples includeWinnow,Weighted Majority, andBinomial Weighting.
Algorithms with this property haven't taken over the world yet. Here might be
some reasons:Lack of caring. Many people working on learning theory don't care
about particular applications much. This means constants in the algorithm are
not optimized, usable code is often not produced, and empirical studies aren't
done.Inefficiency. Viewed from the perspective of other learning algorithms,
online learning is terribly inefficient. It requires that every hypothesis
(called an expert in the online learning setting) be enumerated and tested o</p><p>2 0.19139171 <a title="28-tfidf-2" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>Introduction: I've had serious conversations with several people who believe that the theory
in machine learning is "only useful for getting papers published". That's a
compelling statement, as I've seen many papers where the algorithm clearly
came first, and the theoretical justification for it came second, purely as a
perceived means to improve the chance of publication.Naturally, I disagree and
believe that learning theory has much more substantial applications.Even in
core learning algorithm design, I've found learning theory to be useful,
although it's application is more subtle than many realize. The most
straightforward applications can fail, because (as expectation suggests) worst
case bounds tend to be loose in practice (*). In my experience, considering
learning theory when designing an algorithm has two important effects in
practice:It can help make your algorithm behave right at a crude level of
analysis, leaving finer details to tuning or common sense. The best example I
have of this is</p><p>3 0.17846932 <a title="28-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>Introduction: Suppose we have a set of classifierscmaking binary predictions from an
inputxand we see examples in an online fashion. In particular, we repeatedly
see an unlabeled examplex, make a predictiony'(possibly based on the
classifiersc), and then see the correct labely.When one of these classifiers
is perfect, there is a great algorithm available: predict according to the
majority vote over every classifier consistent with every previous example.
This is called the Halving algorithm. It makes at mostlog2|c|mistakes since on
any mistake, at least half of the classifiers are eliminated.Obviously, we
can't generally hope that the there exists a classifier which never errs.
TheBinomial Weighting algorithmis an elegant technique allowing a variant
Halving algorithm to cope with errors by creating a set of virtual classifiers
for every classifier which occasionally disagree with the original classifier.
The Halving algorithm on this set of virtual classifiers satisfies a theorem
of the form:errors</p><p>4 0.1670431 <a title="28-tfidf-4" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem. When someone screws up, do you fire them?
Or do you accept the error and let them continue? This is a very difficult
problem and we all know of stories where the wrong decision was made.Online
learning(as meant here), is a subfield of learning theory which analyzes the
online learning model.In the online learning model, there are a set of
hypotheses or "experts". On any instantancex, each expert makes a predictiony.
A master algorithmAuses these predictions to form it's own predictionyAand
then learns the correct predictiony*. This process repeats.The goal of online
learning is to find a master algorithmAwhich uses the advice of the experts to
make good predictions. In particular, we typically want to guarantee that the
master algorithm performs almost as well as the best expert. IfL(e)is the loss
of experteandL(A)is the loss of the master algorithm, it is often possible to
prove:L(A) less than mineL(e) + log(number of experts)over all sequences.In
p</p><p>5 0.13540858 <a title="28-tfidf-5" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>Introduction: One thing which is clear on a little reflection is that there exists a single
master learning problem capable of encoding essentially all learning problems.
This problem is of course a very general sort of reinforcement learning where
the world interacts with an agent as:The world announces an observationx.The
agent makes a choicea.The world announces a rewardr.The goal here is to
maximize the sum of the rewards over the time of the agent. No particular
structure relatingxtoaoratoris implied by this setting so we do not know
effective general algorithms for the agent. It's very easy to prove lower
bounds showing that an agent cannot hope to succeed here--just consider the
case where actions are unrelated to rewards. Nevertheless, there is a real
sense in which essentially all forms of life are agents operating in this
setting, somehow succeeding. The gap between these observations drives
research--How can we find tractable specializations of the master problem
general enough to provide</p><p>6 0.13213511 <a title="28-tfidf-6" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>7 0.12943918 <a title="28-tfidf-7" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>8 0.12819298 <a title="28-tfidf-8" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>9 0.12258382 <a title="28-tfidf-9" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>10 0.12111592 <a title="28-tfidf-10" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>11 0.11829069 <a title="28-tfidf-11" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>12 0.11201973 <a title="28-tfidf-12" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>13 0.10839086 <a title="28-tfidf-13" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>14 0.10827681 <a title="28-tfidf-14" href="../hunch_net-2007/hunch_net-2007-08-28-Live_ML_Class.html">261 hunch net-2007-08-28-Live ML Class</a></p>
<p>15 0.10745752 <a title="28-tfidf-15" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>16 0.10654031 <a title="28-tfidf-16" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<p>17 0.10644522 <a title="28-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>18 0.10534442 <a title="28-tfidf-18" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>19 0.10468619 <a title="28-tfidf-19" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>20 0.10421032 <a title="28-tfidf-20" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.258), (1, -0.135), (2, 0.025), (3, -0.046), (4, -0.045), (5, -0.004), (6, 0.037), (7, 0.031), (8, -0.094), (9, -0.02), (10, -0.015), (11, -0.122), (12, -0.006), (13, -0.076), (14, -0.077), (15, 0.026), (16, -0.018), (17, -0.028), (18, -0.037), (19, 0.092), (20, -0.027), (21, -0.111), (22, 0.082), (23, 0.011), (24, -0.012), (25, -0.086), (26, 0.052), (27, 0.014), (28, -0.004), (29, -0.006), (30, -0.057), (31, 0.012), (32, 0.044), (33, -0.054), (34, -0.008), (35, 0.053), (36, 0.027), (37, -0.004), (38, -0.005), (39, -0.054), (40, -0.036), (41, 0.013), (42, -0.023), (43, -0.046), (44, -0.052), (45, -0.034), (46, -0.067), (47, 0.045), (48, 0.086), (49, -0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95683235 <a title="28-lsi-1" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>Introduction: Despite my best intentions, this is not a fully specified problem, but rather
a research direction.Competitive online learning is one of the more compelling
pieces of learning theory because typical statements of the form "this
algorithm will perform almost as well as a large set of other algorithms" rely
only on fully-observable quantities, and are therefore applicable in many
situations. Examples includeWinnow,Weighted Majority, andBinomial Weighting.
Algorithms with this property haven't taken over the world yet. Here might be
some reasons:Lack of caring. Many people working on learning theory don't care
about particular applications much. This means constants in the algorithm are
not optimized, usable code is often not produced, and empirical studies aren't
done.Inefficiency. Viewed from the perspective of other learning algorithms,
online learning is terribly inefficient. It requires that every hypothesis
(called an expert in the online learning setting) be enumerated and tested o</p><p>2 0.75630504 <a title="28-lsi-2" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem. When someone screws up, do you fire them?
Or do you accept the error and let them continue? This is a very difficult
problem and we all know of stories where the wrong decision was made.Online
learning(as meant here), is a subfield of learning theory which analyzes the
online learning model.In the online learning model, there are a set of
hypotheses or "experts". On any instantancex, each expert makes a predictiony.
A master algorithmAuses these predictions to form it's own predictionyAand
then learns the correct predictiony*. This process repeats.The goal of online
learning is to find a master algorithmAwhich uses the advice of the experts to
make good predictions. In particular, we typically want to guarantee that the
master algorithm performs almost as well as the best expert. IfL(e)is the loss
of experteandL(A)is the loss of the master algorithm, it is often possible to
prove:L(A) less than mineL(e) + log(number of experts)over all sequences.In
p</p><p>3 0.7334187 <a title="28-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>Introduction: Suppose we have a set of classifierscmaking binary predictions from an
inputxand we see examples in an online fashion. In particular, we repeatedly
see an unlabeled examplex, make a predictiony'(possibly based on the
classifiersc), and then see the correct labely.When one of these classifiers
is perfect, there is a great algorithm available: predict according to the
majority vote over every classifier consistent with every previous example.
This is called the Halving algorithm. It makes at mostlog2|c|mistakes since on
any mistake, at least half of the classifiers are eliminated.Obviously, we
can't generally hope that the there exists a classifier which never errs.
TheBinomial Weighting algorithmis an elegant technique allowing a variant
Halving algorithm to cope with errors by creating a set of virtual classifiers
for every classifier which occasionally disagree with the original classifier.
The Halving algorithm on this set of virtual classifiers satisfies a theorem
of the form:errors</p><p>4 0.71739614 <a title="28-lsi-4" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>Introduction: This is about methods for phrasing and think about the scope of some theorems
in learning theory. The basic claim is that there are several different ways
of quantifying the scope which sound different yet are essentially the
same.For all sequences of examples. This is the standard quantification in
online learning analysis. Standard theorems would say something like "for all
sequences of predictions by experts, the algorithm A will perform almost as
well as the best expert."For all training sets. This is the standard
quantification for boosting analysis such asadaboostormulticlass
boosting.Standard theorems have the form "for all training sets the error rate
inequalities … hold".For all distributions over examples. This is the one that
we have been using for reductions analysis. Standard theorem statements have
the form "For all distributions over examples, the error rate inequalities …
hold".It is not quite true that each of these is equivalent. For example, in
the online learning se</p><p>5 0.69043535 <a title="28-lsi-5" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>Introduction: Exploration is one of the big unsolved problems in machine learning. This
isn't for lack of trying--there are many models of exploration which have been
analyzed in many different ways by many different groups of people. At some
point, it is worthwhile to sit back and see what has been done across these
many models.Reinforcement Learning(1). Reinforcement learning has
traditionally focused on Markov Decision Processes where the next states'is
given by a conditional distributionP(s'|s,a)given the current statesand
actiona. The typical result here is that certain specific algorithms
controlling an agent can behave withineof optimal for horizonTexcept
forpoly(1/e,T,S,A)"wasted" experiences (with high probability). This started
withE3bySatinder SinghandMichael Kearns.Sham Kakade's thesishas significant
discussion. Extensions have typically been of the form "under extra
assumptions, we can prove more", for exampleFactored-E3andMetric-E3. (It turns
out that the number of wasted samples can b</p><p>6 0.67924148 <a title="28-lsi-6" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>7 0.67205942 <a title="28-lsi-7" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>8 0.6696918 <a title="28-lsi-8" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>9 0.66526598 <a title="28-lsi-9" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>10 0.65983534 <a title="28-lsi-10" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>11 0.65585899 <a title="28-lsi-11" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>12 0.65234804 <a title="28-lsi-12" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>13 0.64886218 <a title="28-lsi-13" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>14 0.64810961 <a title="28-lsi-14" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>15 0.64786845 <a title="28-lsi-15" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>16 0.6477313 <a title="28-lsi-16" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>17 0.64529151 <a title="28-lsi-17" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>18 0.6416775 <a title="28-lsi-18" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>19 0.62343544 <a title="28-lsi-19" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>20 0.61909533 <a title="28-lsi-20" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.072), (35, 0.067), (42, 0.287), (45, 0.029), (68, 0.023), (69, 0.045), (74, 0.115), (84, 0.187), (95, 0.079)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91845405 <a title="28-lda-1" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>Introduction: Despite my best intentions, this is not a fully specified problem, but rather
a research direction.Competitive online learning is one of the more compelling
pieces of learning theory because typical statements of the form "this
algorithm will perform almost as well as a large set of other algorithms" rely
only on fully-observable quantities, and are therefore applicable in many
situations. Examples includeWinnow,Weighted Majority, andBinomial Weighting.
Algorithms with this property haven't taken over the world yet. Here might be
some reasons:Lack of caring. Many people working on learning theory don't care
about particular applications much. This means constants in the algorithm are
not optimized, usable code is often not produced, and empirical studies aren't
done.Inefficiency. Viewed from the perspective of other learning algorithms,
online learning is terribly inefficient. It requires that every hypothesis
(called an expert in the online learning setting) be enumerated and tested o</p><p>2 0.86282229 <a title="28-lda-2" href="../hunch_net-2009/hunch_net-2009-12-07-Vowpal_Wabbit_version_4.0%2C_and_a_NIPS_heresy.html">381 hunch net-2009-12-07-Vowpal Wabbit version 4.0, and a NIPS heresy</a></p>
<p>Introduction: I'm releasingversion 4.0(tarball) ofVowpal Wabbit. The biggest change (by far)
in this release is experimental support for cluster parallelism, with notable
help fromDaniel Hsu.I also took advantage of the major version number to
introduce some incompatible changes, including switching tomurmurhash 2, and
other alterations to cachefiles. You'll need to delete and regenerate them. In
addition, the precise specification for a "tag" (i.e. string that can be used
to identify an example) changed--you can't have a space between the tag and
the '|' at the beginning of the feature namespace.And, of course, we made it
faster.For the future, I put up mytodo listoutlining the major future
improvements I want to see in the code. I'm planning to discuss the current
mechanism and results of the cluster parallel implementation at thelarge scale
machine learning workshopatNIPSlater this week. Several people have asked me
to do a tutorial/walkthrough of VW, which is arranged for friday 2pm in the
works</p><p>3 0.85463142 <a title="28-lda-3" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>Introduction: Machine learning algorithms have a much better chance of being widely adopted
if they are implemented in some easy-to-use code. There are several important
concerns associated with machine learning which stress programming languages
on the ease-of-use vs. speed frontier.SpeedThe rate at which data sources are
growing seems to be outstripping the rate at which computational power is
growing, so it is important that we be able to eak out every bit of
computational power. Garbage collected languages (java,ocaml,perlandpython)
often have several issues here.Garbage collection often implies that floating
point numbers are "boxed": every float is represented by a pointer to a float.
Boxing can cause an order of magnitude slowdown because an extra nonlocalized
memory reference is made, and accesses to main memory can are many CPU cycles
long.Garbage collection often implies that considerably more memory is used
than is necessary. This has a variable effect. In some circumstances it
results in</p><p>4 0.84588206 <a title="28-lda-4" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>5 0.83904874 <a title="28-lda-5" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>Introduction: At thelast ICML,Tom Dietterichasked me to look into systems for commenting on
papers. I've been slow getting to this, but it's relevant now.The essential
observation is that we now have many tools for online collaboration, but they
are not yet much used in academic research. If we can find the right way to
use them, then perhaps great things might happen, with extra kudos to the
first conference that manages to really create an online community. Various
conferences have been poking at this. For example,UAI has setup a wiki, COLT
hasstarted usingJoomla, with some dynamic content, and AAAI has been setting
up a "student blog". Similarly,Dinoj Surendransetup a twiki for theChicago
Machine Learning Summer School, which was quite useful for coordinating events
and other things.I believe the most important thing is a willingness to
experiment. A good place to start seems to be enhancing existing conference
websites. For example, theICML 2007 papers pageis basically only useful via
grep. A mu</p><p>6 0.83688766 <a title="28-lda-6" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>7 0.83586091 <a title="28-lda-7" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>8 0.83443969 <a title="28-lda-8" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>9 0.83434951 <a title="28-lda-9" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>10 0.83434844 <a title="28-lda-10" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>11 0.83392304 <a title="28-lda-11" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>12 0.83176678 <a title="28-lda-12" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>13 0.83161861 <a title="28-lda-13" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>14 0.83006853 <a title="28-lda-14" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>15 0.83000118 <a title="28-lda-15" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>16 0.8296203 <a title="28-lda-16" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>17 0.82726228 <a title="28-lda-17" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>18 0.82699275 <a title="28-lda-18" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>19 0.82604957 <a title="28-lda-19" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>20 0.82532966 <a title="28-lda-20" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
