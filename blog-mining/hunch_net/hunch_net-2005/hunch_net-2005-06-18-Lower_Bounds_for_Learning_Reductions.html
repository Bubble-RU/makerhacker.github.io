<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-83" href="#">hunch_net-2005-83</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-83-html" href="http://hunch.net/?p=89">html</a></p><p>Introduction: Learning reductionstransform a solver of one type of learning problem into a
solver of another type of learning problem. When we analyze these for
robustness we can make statement of the form "ReductionRhas the property that
regretr(or loss) on subproblems of typeAimplies regret at mostf ( r )on the
original problem of typeB".A lower bound for a learning reduction would have
the form "for all reductionsR, there exists a learning problem of typeBand
learning algorithm for problems of typeAwhere regretron induced problems
impliesat leastregretf ( r )forB".The pursuit of lower bounds is often
questionable because, unlike upper bounds, they do not yield practical
algorithms. Nevertheless, they may be helpful as a tool for thinking about
what is learnable and how learnable it is. This has already come
uphereandhere.At the moment, there is no coherent theory of lower bounds for
learning reductions, and we have little understanding of how feasible they are
or which techniques may be useful in</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Learning reductionstransform a solver of one type of learning problem into a solver of another type of learning problem. [sent-1, score-0.973]
</p><p>2 When we analyze these for robustness we can make statement of the form "ReductionRhas the property that regretr(or loss) on subproblems of typeAimplies regret at mostf ( r )on the original problem of typeB". [sent-2, score-0.686]
</p><p>3 A lower bound for a learning reduction would have the form "for all reductionsR, there exists a learning problem of typeBand learning algorithm for problems of typeAwhere regretron induced problems impliesat leastregretf ( r )forB". [sent-3, score-0.907]
</p><p>4 The pursuit of lower bounds is often questionable because, unlike upper bounds, they do not yield practical algorithms. [sent-4, score-1.166]
</p><p>5 Nevertheless, they may be helpful as a tool for thinking about what is learnable and how learnable it is. [sent-5, score-0.618]
</p><p>6 At the moment, there is no coherent theory of lower bounds for learning reductions, and we have little understanding of how feasible they are or which techniques may be useful in proving them. [sent-7, score-1.075]
</p><p>7 Here is a rough summary of what I know:Forstructured prediction, we have a partially worked out lower bound for all reductions using the structure to only carrysingle bits. [sent-8, score-1.238]
</p><p>8 A proof for reductions using the structure in others ways seems tricky at the moment. [sent-9, score-0.505]
</p><p>9 ForReinforcement learningit may (this is unclear) be possible to prove a lower bound showing that prediction ability alone can not solve RL well. [sent-10, score-1.2]
</p><p>10 There are various results which can be thought of as lower bounds for more limited families of reductions. [sent-11, score-0.887]
</p><p>11 One example isanalyzing exactly how badly margin optimization can underperform for 0-1 loss when there is noise. [sent-12, score-0.388]
</p><p>12 Overall, this is a moderately interesting direction of research which has not been much investigated. [sent-13, score-0.195]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lower', 0.439), ('solver', 0.274), ('bounds', 0.248), ('learnable', 0.219), ('reductions', 0.209), ('bound', 0.193), ('type', 0.174), ('investigated', 0.137), ('regretr', 0.137), ('structure', 0.128), ('families', 0.127), ('learningit', 0.127), ('moderately', 0.12), ('pursuit', 0.12), ('questionable', 0.114), ('loss', 0.111), ('alone', 0.11), ('induced', 0.11), ('coherent', 0.106), ('margin', 0.103), ('feasible', 0.1), ('subproblems', 0.1), ('robustness', 0.097), ('proving', 0.097), ('summary', 0.095), ('tool', 0.095), ('rough', 0.095), ('rl', 0.092), ('tricky', 0.092), ('prediction', 0.089), ('exactly', 0.089), ('form', 0.088), ('moment', 0.085), ('unlike', 0.085), ('analyze', 0.085), ('badly', 0.085), ('showing', 0.085), ('may', 0.085), ('original', 0.084), ('upper', 0.084), ('property', 0.082), ('unclear', 0.08), ('partially', 0.079), ('problem', 0.077), ('proof', 0.076), ('yield', 0.076), ('direction', 0.075), ('statement', 0.073), ('limited', 0.073), ('prove', 0.072)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="83-tfidf-1" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductionstransform a solver of one type of learning problem into a
solver of another type of learning problem. When we analyze these for
robustness we can make statement of the form "ReductionRhas the property that
regretr(or loss) on subproblems of typeAimplies regret at mostf ( r )on the
original problem of typeB".A lower bound for a learning reduction would have
the form "for all reductionsR, there exists a learning problem of typeBand
learning algorithm for problems of typeAwhere regretron induced problems
impliesat leastregretf ( r )forB".The pursuit of lower bounds is often
questionable because, unlike upper bounds, they do not yield practical
algorithms. Nevertheless, they may be helpful as a tool for thinking about
what is learnable and how learnable it is. This has already come
uphereandhere.At the moment, there is no coherent theory of lower bounds for
learning reductions, and we have little understanding of how feasible they are
or which techniques may be useful in</p><p>2 0.21009299 <a title="83-tfidf-2" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>Introduction: What?Bounds are mathematical formulas relating observations to future error
rates assuming that data is drawn independently. In classical statistics, they
are calld confidence intervals.Why?Good Judgement. In many applications of
learning, it is desirable to know how well the learned predictor works in the
future. This helps you decide if the problem is solved or not.Learning
Essence. The form of some of these bounds helps you understand what the
essence of learning is.Algorithm Design. Some of these bounds suggest,
motivate, or even directly imply learning algorithms.What We Know NowThere are
several families of bounds, based on how information is used.Testing Bounds.
These are methods which use labeled data not used in training to estimate the
future error rate. Examples include thetest set bound,progressive
validationalsohereandhere,train and test bounds, and cross-validation (but see
thebig open problem). These techniques are the best available for goal (1)
above, but provide littl</p><p>3 0.17764722 <a title="83-tfidf-3" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a
data source (Example:X x {0,1},X x [0,1],X x {1,2,3,4,5}, etc…) and a loss
function (0/1 loss, squared error loss, cost sensitive losses, etc…). For
simplicity, we'll assume that all losses have a minimum of zero.For this post,
we can think of a learning reduction asA mappingRfrom samples of one
typeT(like multiclass classification) to another typeT'(like binary
classification).A mappingQfrom predictors for typeT'to predictors for
typeT.The simplest sort of learning reduction is a "loss reduction". The idea
in a loss reduction is to prove a statement of the form:TheoremFor all base
predictorsb, for all distributionsDover examples of typeT:E(x,y) ~
DLT(y,Q(b,x)) <= f(E(x',y')~R(D)LT'(y',b(x')))HereLTis the loss for the
typeTproblem andLT'is the loss for the typeT'problem. Also,R(D)is the
distribution over samples induced by first drawing fromDand then mapping the
sample viaR. The functionf()is the loss transf</p><p>4 0.15729724 <a title="83-tfidf-4" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>Introduction: David Mcallestergave a talk about thispaper(withPedro Felzenszwalb). I'll try
to give a high level summary of why it's interesting.Dynamic programming is
most familiar as instantiated by Viterbi decoding in a hidden markov model. It
is a general paradigm for problem solving where subproblems are solved and
used to solve larger problems. In the Viterbi decoding example, the subproblem
is "What is the most probable path ending at each state at timestept?", and
the larger problem is the same except at timestept+1. There are a few
optimizations you can do here:Dynamic Programming -> queued Dynamic
Programming. Keep track of the "cost so far" (or "most probable path") and
(carefully) only look at extensions to paths likely to yield the shortest
path. "Carefully" here is defined byDijkstra's shortest path algorithm.queued
Dynamic programming -> A*Add a lower bound on the cost to complete a path (or
an upper bound on the probability of a completion) for the priority queue of
Dijkstra's shorte</p><p>5 0.14853829 <a title="83-tfidf-5" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>Introduction: In research, it's often the case that solving a problem helps you realize that
it wasn't the right problem to solve. This is the case for the "reduce RL to
classification" problem with the solution hinted athereand turned into a
paperhere.The essential difficulty is that the method of stating and analyzing
reductions ends up being nonalgorithmic (unlike previous reductions) unless
you work with learning from teleoperated robots asGreg Grudicdoes. The
difficulty here is due to the reduction being dependent on the optimal policy
(which a human teleoperator might simulate, but which is otherwise
unavailable).So, thisproblemis "open" again with the caveat that this time we
want a more algorithmic solution.Whether or not this is feasible at all is
still unclear and evidence in either direction would greatly interest me. A
positive answer might have many practical implications in the long run.</p><p>6 0.13780296 <a title="83-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>7 0.13017699 <a title="83-tfidf-7" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>8 0.12553605 <a title="83-tfidf-8" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>9 0.12188493 <a title="83-tfidf-9" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<p>10 0.12020241 <a title="83-tfidf-10" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>11 0.11716425 <a title="83-tfidf-11" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>12 0.11300624 <a title="83-tfidf-12" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>13 0.11299225 <a title="83-tfidf-13" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>14 0.11220997 <a title="83-tfidf-14" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>15 0.11214446 <a title="83-tfidf-15" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>16 0.1114878 <a title="83-tfidf-16" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>17 0.1106525 <a title="83-tfidf-17" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>18 0.10906664 <a title="83-tfidf-18" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>19 0.10800718 <a title="83-tfidf-19" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>20 0.10758308 <a title="83-tfidf-20" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.203), (1, -0.147), (2, -0.07), (3, 0.017), (4, 0.056), (5, -0.173), (6, 0.034), (7, -0.014), (8, 0.009), (9, 0.017), (10, -0.048), (11, -0.033), (12, 0.013), (13, 0.029), (14, 0.05), (15, 0.086), (16, -0.054), (17, -0.08), (18, 0.138), (19, -0.011), (20, 0.044), (21, -0.094), (22, -0.054), (23, -0.011), (24, -0.175), (25, -0.024), (26, -0.09), (27, -0.008), (28, 0.033), (29, -0.023), (30, 0.07), (31, -0.023), (32, 0.049), (33, 0.065), (34, 0.071), (35, -0.072), (36, 0.028), (37, -0.045), (38, -0.115), (39, 0.056), (40, 0.033), (41, 0.001), (42, -0.064), (43, 0.016), (44, 0.112), (45, 0.047), (46, 0.043), (47, 0.049), (48, 0.079), (49, 0.007)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95514488 <a title="83-lsi-1" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductionstransform a solver of one type of learning problem into a
solver of another type of learning problem. When we analyze these for
robustness we can make statement of the form "ReductionRhas the property that
regretr(or loss) on subproblems of typeAimplies regret at mostf ( r )on the
original problem of typeB".A lower bound for a learning reduction would have
the form "for all reductionsR, there exists a learning problem of typeBand
learning algorithm for problems of typeAwhere regretron induced problems
impliesat leastregretf ( r )forB".The pursuit of lower bounds is often
questionable because, unlike upper bounds, they do not yield practical
algorithms. Nevertheless, they may be helpful as a tool for thinking about
what is learnable and how learnable it is. This has already come
uphereandhere.At the moment, there is no coherent theory of lower bounds for
learning reductions, and we have little understanding of how feasible they are
or which techniques may be useful in</p><p>2 0.70301455 <a title="83-lsi-2" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>Introduction: Sham Kakadepoints out that we are missing a bound.Suppose we
havemsamplesxdrawn IID from some distributionD. Through the magic of
exponential moment method we know that:If the range ofxis bounded by an
interval of sizeI, aChernoff/Hoeffding style boundgives us a bound on the
deviations likeO(I/m0.5)(at least in crude form). A proof is on page 9here.If
the range ofxis bounded, and the variance (or a bound on the variance) is
known, thenBennett's boundcan give tighter results (*). This can be a huge
improvment when the true variance small.What's missing here is a bound that
depends on the observed variance rather than a bound on the variance. This
means that many people attempt to use Bennett's bound (incorrectly) by
plugging the observed variance in as the true variance, invalidating the bound
application. Most of the time, they get away with it, but this is a dangerous
move when doing machine learning. In machine learning, we are typically trying
to find a predictor with 0 expected los</p><p>3 0.64860457 <a title="83-lsi-3" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>Introduction: I found Tong Zhang's paper onData Dependent Concentration Bounds for
Sequential Prediction Algorithmsinteresting. Roughly speaking, it states a
tight bound on the future error rate for online learning algorithms assuming
that samples are drawn independently. This bound is easily computed and will
make the progressive validation approaches usedheresignificantly more
practical.</p><p>4 0.64070177 <a title="83-lsi-4" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a
data source (Example:X x {0,1},X x [0,1],X x {1,2,3,4,5}, etc…) and a loss
function (0/1 loss, squared error loss, cost sensitive losses, etc…). For
simplicity, we'll assume that all losses have a minimum of zero.For this post,
we can think of a learning reduction asA mappingRfrom samples of one
typeT(like multiclass classification) to another typeT'(like binary
classification).A mappingQfrom predictors for typeT'to predictors for
typeT.The simplest sort of learning reduction is a "loss reduction". The idea
in a loss reduction is to prove a statement of the form:TheoremFor all base
predictorsb, for all distributionsDover examples of typeT:E(x,y) ~
DLT(y,Q(b,x)) <= f(E(x',y')~R(D)LT'(y',b(x')))HereLTis the loss for the
typeTproblem andLT'is the loss for the typeT'problem. Also,R(D)is the
distribution over samples induced by first drawing fromDand then mapping the
sample viaR. The functionf()is the loss transf</p><p>5 0.63424385 <a title="83-lsi-5" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<p>Introduction: At thePAC-Bayesworkshop earlier this week,Olivier Catonidescribed a result
that I hadn't believed was possible:a deviation bound dependingonlyon the
variance of a random variable.For people not familiar with deviation bounds,
this may be hard to appreciate. Deviation bounds, are one of the core
components for the foundations of machine learning theory, so developments
here have a potential to alter our understanding of how to learn and what is
learnable. My understanding is that the basic proof techniques started
withBernsteinand have evolved into several variants specialized for various
applications. All of the variants I knew had a dependence on the range, with
some also having a dependence on the variance of an IID or martingale random
variable. This one is the first I know of with a dependence on only the
variance.The basic idea is to use a biased estimator of the mean which is not
influenced much by outliers. Then, a deviation bound can be proved by using
the exponential moment me</p><p>6 0.63394219 <a title="83-lsi-6" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>7 0.62596369 <a title="83-lsi-7" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>8 0.62291336 <a title="83-lsi-8" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>9 0.61954486 <a title="83-lsi-9" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>10 0.56594867 <a title="83-lsi-10" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>11 0.56026846 <a title="83-lsi-11" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>12 0.54447222 <a title="83-lsi-12" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>13 0.53652173 <a title="83-lsi-13" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>14 0.51516819 <a title="83-lsi-14" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>15 0.50176311 <a title="83-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>16 0.49776828 <a title="83-lsi-16" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>17 0.47986177 <a title="83-lsi-17" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>18 0.47575998 <a title="83-lsi-18" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>19 0.4638643 <a title="83-lsi-19" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>20 0.45082903 <a title="83-lsi-20" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.227), (6, 0.033), (35, 0.033), (42, 0.286), (45, 0.116), (68, 0.058), (69, 0.029), (74, 0.085), (76, 0.03)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93938029 <a title="83-lda-1" href="../hunch_net-2006/hunch_net-2006-08-03-AOL%26%238217%3Bs_data_drop.html">200 hunch net-2006-08-03-AOL&#8217;s data drop</a></p>
<p>Introduction: AOL hasreleasedseveral large search engine related datasets. This looks like a
pretty impressive data release, and it is a big opportunity for people
everywhere to worry about search engine related learning problems, if they
want.</p><p>same-blog 2 0.90572858 <a title="83-lda-2" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductionstransform a solver of one type of learning problem into a
solver of another type of learning problem. When we analyze these for
robustness we can make statement of the form "ReductionRhas the property that
regretr(or loss) on subproblems of typeAimplies regret at mostf ( r )on the
original problem of typeB".A lower bound for a learning reduction would have
the form "for all reductionsR, there exists a learning problem of typeBand
learning algorithm for problems of typeAwhere regretron induced problems
impliesat leastregretf ( r )forB".The pursuit of lower bounds is often
questionable because, unlike upper bounds, they do not yield practical
algorithms. Nevertheless, they may be helpful as a tool for thinking about
what is learnable and how learnable it is. This has already come
uphereandhere.At the moment, there is no coherent theory of lower bounds for
learning reductions, and we have little understanding of how feasible they are
or which techniques may be useful in</p><p>3 0.90018463 <a title="83-lda-3" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect theNIPS 2006 workshopsto be quite interesting, and recommend going
for anyone interested in machine learning research. (Most or all of the
workshops webpages can be found two links deep.)</p><p>4 0.79543912 <a title="83-lda-4" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>Introduction: This post is about a confusion of mine with respect to many commonly used
machine learning algorithms.A simple example where this comes up is Bayes net
prediction. A Bayes net where a directed acyclic graph over a set of nodes
where each node is associated with a variable and the edges indicate
dependence. The joint probability distribution over the variables is given by
a set of conditional probabilities. For example, a very simple Bayes net might
express:P(A,B,C) = P(A | B,C)P(B)P(C)What I don't understand is the mechanism
commonly used to estimateP(A | B, C). If we letN(A,B,C)be the number of
instances ofA,B,Cthen people sometimes form an estimate according to:P'(A |
B,C) = N(A,B,C) / N /[N(B)/N * N(C)/N] = N(A,B,C) N /[N(B) N(C)]â&euro;Ś in other
words, people just estimateP'(A | B,C)according to observed relative
frequencies. This is a reasonable technique when you have a large number of
samples compared to the size spaceA x B x C, but it (naturally) falls apart
when this is not the case</p><p>5 0.78931528 <a title="83-lda-5" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>Introduction: Consider the contextual bandit setting where, repeatedly:A contextxis
observed.An actionais taken given the contextx.A rewardris observed, dependent
onxanda.Where the goal of a learning agent is to find a policy for step 2
achieving a large expected reward.This setting is of obvious importance,
because in the real world we typically make decisions based on some set of
information and then get feedback only about the single action taken. It also
fundamentally differs from supervised learning settings because knowing the
value of one action is not equivalent to knowing the value of all actions.A
decade ago the best machine learning techniques for this setting where
implausibly inefficient.Dean Fosteronce told me he thought the area was a
research sinkhole with little progress to be expected. Now we are on the verge
of being able to routinely attack these problems, in almost exactly the same
sense that we routinely attack bread and butter supervised learning problems.
Just as for supervis</p><p>6 0.78897899 <a title="83-lda-6" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>7 0.7855857 <a title="83-lda-7" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>8 0.78468204 <a title="83-lda-8" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>9 0.7841602 <a title="83-lda-9" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>10 0.78346425 <a title="83-lda-10" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>11 0.78116816 <a title="83-lda-11" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>12 0.78055662 <a title="83-lda-12" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>13 0.78026372 <a title="83-lda-13" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>14 0.77982682 <a title="83-lda-14" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>15 0.7796188 <a title="83-lda-15" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>16 0.77956557 <a title="83-lda-16" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>17 0.77951354 <a title="83-lda-17" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>18 0.77923644 <a title="83-lda-18" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>19 0.77916211 <a title="83-lda-19" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>20 0.77730137 <a title="83-lda-20" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
