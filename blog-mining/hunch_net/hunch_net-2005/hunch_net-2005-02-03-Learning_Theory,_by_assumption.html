<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>12 hunch net-2005-02-03-Learning Theory, by assumption</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-12" href="#">hunch_net-2005-12</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>12 hunch net-2005-02-03-Learning Theory, by assumption</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-12-html" href="http://hunch.net/?p=15">html</a></p><p>Introduction: One way to organize learning theory is by assumption (in theassumption = axiom
sense), from no assumptions to many assumptions. As you travel down this list,
the statements become stronger, but the scope of applicability decreases.No
assumptionsOnline learningThere exist a meta prediction algorithm which
compete well with the best element of any set of prediction
algorithms.Universal LearningUsing a "bias" of 2- description length of turing
machinein learning is equivalent to all other computable biases up to some
constant.ReductionsThe ability to predict well on classification problems is
equivalent to the ability to predict well on many other learning
problems.Independent and Identically Distributed (IID) DataPerformance
PredictionBased upon past performance, you can predict future
performance.Uniform ConvergencePerformance prediction works even after
choosing classifiers based on the data from large sets of classifiers.IID and
partial constraints on the data sourcePAC LearningThere</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('learningthere', 0.359), ('law', 0.206), ('equivalent', 0.189), ('constraints', 0.186), ('predict', 0.185), ('bayes', 0.178), ('data', 0.171), ('meta', 0.159), ('prediction', 0.156), ('applicability', 0.148), ('axiom', 0.148), ('computable', 0.148), ('list', 0.146), ('identically', 0.133), ('ability', 0.131), ('function', 0.126), ('biases', 0.123), ('solution', 0.12), ('length', 0.119), ('turing', 0.119)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="12-tfidf-1" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>Introduction: One way to organize learning theory is by assumption (in theassumption = axiom
sense), from no assumptions to many assumptions. As you travel down this list,
the statements become stronger, but the scope of applicability decreases.No
assumptionsOnline learningThere exist a meta prediction algorithm which
compete well with the best element of any set of prediction
algorithms.Universal LearningUsing a "bias" of 2- description length of turing
machinein learning is equivalent to all other computable biases up to some
constant.ReductionsThe ability to predict well on classification problems is
equivalent to the ability to predict well on many other learning
problems.Independent and Identically Distributed (IID) DataPerformance
PredictionBased upon past performance, you can predict future
performance.Uniform ConvergencePerformance prediction works even after
choosing classifiers based on the data from large sets of classifiers.IID and
partial constraints on the data sourcePAC LearningThere</p><p>2 0.13742569 <a title="12-tfidf-2" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>3 0.13161935 <a title="12-tfidf-3" href="../hunch_net-2005/hunch_net-2005-04-14-Families_of_Learning_Theory_Statements.html">56 hunch net-2005-04-14-Families of Learning Theory Statements</a></p>
<p>Introduction: The diagram above shows a very broad viewpoint of learning theory.arrowTypical
statementExamplesPast->PastSome prediction algorithmAdoes almost as well as
any of a set of algorithms.Weighted MajorityPast->FutureAssuming independent
samples, past performance predicts future performance.PAC analysis, ERM
analysisFuture->FutureFuture prediction performance on subproblems implies
future prediction performance using algorithmA.ECOC, ProbingA basic question
is: Are there other varieties of statements of this type?Avrimnoted that there
are also "arrows between arrows": generic methods for transforming between
Past->Past statements and Past->Future statements. Are there others?</p><p>4 0.1294124 <a title="12-tfidf-4" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>Introduction: "Assumption" is another word to be careful with in machine learning because it
is used in several ways.Assumption = BiasThere are several ways to see that
some form of 'bias' (= preferring of one solution over another) is necessary.
This is obvious in an adversarial setting. A good bit of work has been
expended explaining this in other settings with "no free lunch" theorems. This
is a usage specialized to learning which is particularly common when talking
about priors for Bayesian Learning.Assumption = "if" of a theoremThe
assumptions are the 'if' part of the 'if-then' in a theorem. This is a fairly
common usage.Assumption = AxiomThe assumptions are the things that we assume
are true, but which we cannot verify. Examples are "the IID assumption" or "my
problem is a DNF on a small number of bits". This is the usage which I
prefer.One difficulty with any use of the word "assumption" is that you often
encounter "ifassumptionthenconclusionso ifnot assumptionthennot conclusion".
This is inc</p><p>5 0.12819298 <a title="12-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>Introduction: Despite my best intentions, this is not a fully specified problem, but rather
a research direction.Competitive online learning is one of the more compelling
pieces of learning theory because typical statements of the form "this
algorithm will perform almost as well as a large set of other algorithms" rely
only on fully-observable quantities, and are therefore applicable in many
situations. Examples includeWinnow,Weighted Majority, andBinomial Weighting.
Algorithms with this property haven't taken over the world yet. Here might be
some reasons:Lack of caring. Many people working on learning theory don't care
about particular applications much. This means constants in the algorithm are
not optimized, usable code is often not produced, and empirical studies aren't
done.Inefficiency. Viewed from the perspective of other learning algorithms,
online learning is terribly inefficient. It requires that every hypothesis
(called an expert in the online learning setting) be enumerated and tested o</p><p>6 0.12813011 <a title="12-tfidf-6" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>7 0.12512718 <a title="12-tfidf-7" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>8 0.12400285 <a title="12-tfidf-8" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>9 0.12160452 <a title="12-tfidf-9" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>10 0.11789897 <a title="12-tfidf-10" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>11 0.1130419 <a title="12-tfidf-11" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>12 0.10784843 <a title="12-tfidf-12" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>13 0.10274599 <a title="12-tfidf-13" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>14 0.10245641 <a title="12-tfidf-14" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>15 0.10209211 <a title="12-tfidf-15" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>16 0.10126263 <a title="12-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>17 0.10058565 <a title="12-tfidf-17" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>18 0.10017836 <a title="12-tfidf-18" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>19 0.095780246 <a title="12-tfidf-19" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>20 0.094484568 <a title="12-tfidf-20" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.221), (1, -0.156), (2, -0.022), (3, -0.01), (4, -0.05), (5, -0.024), (6, -0.113), (7, 0.022), (8, 0.029), (9, -0.005), (10, -0.106), (11, -0.009), (12, 0.004), (13, -0.069), (14, -0.024), (15, -0.093), (16, -0.011), (17, 0.002), (18, 0.086), (19, 0.037), (20, 0.041), (21, -0.049), (22, 0.076), (23, -0.034), (24, -0.021), (25, -0.107), (26, 0.09), (27, 0.069), (28, 0.03), (29, -0.091), (30, -0.069), (31, 0.038), (32, 0.103), (33, 0.111), (34, 0.043), (35, -0.069), (36, 0.053), (37, -0.057), (38, 0.095), (39, 0.103), (40, -0.071), (41, 0.056), (42, -0.046), (43, 0.047), (44, -0.059), (45, 0.015), (46, -0.005), (47, -0.086), (48, 0.048), (49, 0.074)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95692307 <a title="12-lsi-1" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>Introduction: One way to organize learning theory is by assumption (in theassumption = axiom
sense), from no assumptions to many assumptions. As you travel down this list,
the statements become stronger, but the scope of applicability decreases.No
assumptionsOnline learningThere exist a meta prediction algorithm which
compete well with the best element of any set of prediction
algorithms.Universal LearningUsing a "bias" of 2- description length of turing
machinein learning is equivalent to all other computable biases up to some
constant.ReductionsThe ability to predict well on classification problems is
equivalent to the ability to predict well on many other learning
problems.Independent and Identically Distributed (IID) DataPerformance
PredictionBased upon past performance, you can predict future
performance.Uniform ConvergencePerformance prediction works even after
choosing classifiers based on the data from large sets of classifiers.IID and
partial constraints on the data sourcePAC LearningThere</p><p>2 0.65695018 <a title="12-lsi-2" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>Introduction: "Assumption" is another word to be careful with in machine learning because it
is used in several ways.Assumption = BiasThere are several ways to see that
some form of 'bias' (= preferring of one solution over another) is necessary.
This is obvious in an adversarial setting. A good bit of work has been
expended explaining this in other settings with "no free lunch" theorems. This
is a usage specialized to learning which is particularly common when talking
about priors for Bayesian Learning.Assumption = "if" of a theoremThe
assumptions are the 'if' part of the 'if-then' in a theorem. This is a fairly
common usage.Assumption = AxiomThe assumptions are the things that we assume
are true, but which we cannot verify. Examples are "the IID assumption" or "my
problem is a DNF on a small number of bits". This is the usage which I
prefer.One difficulty with any use of the word "assumption" is that you often
encounter "ifassumptionthenconclusionso ifnot assumptionthennot conclusion".
This is inc</p><p>3 0.62058872 <a title="12-lsi-3" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>Introduction: One of the most confusing things about understanding learning theory is the
vast array of differing assumptions. Some critical thought about which of
these assumptions are reasonable for real-world problems may be useful.Before
we even start thinking about assumptions, it's important to realize that the
word hasmultiple meanings. The meaning used here is "assumption = axiom" (i.e.
something you can not verify).AssumptionReasonable?Which
analysis?Example/notesIndependent and Identically Distributed
DataSometimesPAC,ERM,Prediction bounds,statisticsTheKDD cup 2004 physics
datasetis plausibly IID data. There are a number of situations which are
"almost IID" in the sense that IID analysis results in correct intuitions.
Unreasonable in adversarial situations (stock market, war, etcâ&euro;Ś)Independently
Distributed DataMore than IID, but still only sometimesonline->batch
conversionLosing "identical" can be helpful in situations where you have a
cyclic process generating data.Finite exchangeability</p><p>4 0.6140238 <a title="12-lsi-4" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>Introduction: Data linkage is a problem which seems to come up in various applied machine
learning problems. I have heard it mentioned in various data mining contexts,
but it seems relatively less studied for systemic reasons.A very simple
version of the data linkage problem is a cross hospital patient record merge.
Suppose a patient (John Doe) is admitted to a hospital (General Health),
treated, and released. Later, John Doe is admitted to a second hospital
(Health General), treated, and released. Given a large number of records of
this sort, it becomes very tempting to try and predict the outcomes of
treatments. This is reasonably straightforward as a machine learning problem
if there is a shared unique identifier for John Doe used by General Health and
Health General along with time stamps. We can merge the records and create
examples of the form "Given symptoms and treatment, did the patient come back
to a hospital within the next year?" These examples could be fed into a
learning algorithm, and</p><p>5 0.59457231 <a title="12-lsi-5" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>Introduction: This is about methods for phrasing and think about the scope of some theorems
in learning theory. The basic claim is that there are several different ways
of quantifying the scope which sound different yet are essentially the
same.For all sequences of examples. This is the standard quantification in
online learning analysis. Standard theorems would say something like "for all
sequences of predictions by experts, the algorithm A will perform almost as
well as the best expert."For all training sets. This is the standard
quantification for boosting analysis such asadaboostormulticlass
boosting.Standard theorems have the form "for all training sets the error rate
inequalities … hold".For all distributions over examples. This is the one that
we have been using for reductions analysis. Standard theorem statements have
the form "For all distributions over examples, the error rate inequalities …
hold".It is not quite true that each of these is equivalent. For example, in
the online learning se</p><p>6 0.58679706 <a title="12-lsi-6" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>7 0.58661276 <a title="12-lsi-7" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>8 0.58235997 <a title="12-lsi-8" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>9 0.57888937 <a title="12-lsi-9" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>10 0.57828677 <a title="12-lsi-10" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>11 0.57092375 <a title="12-lsi-11" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>12 0.56283796 <a title="12-lsi-12" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>13 0.5611521 <a title="12-lsi-13" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>14 0.554254 <a title="12-lsi-14" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>15 0.55178052 <a title="12-lsi-15" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>16 0.54630989 <a title="12-lsi-16" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>17 0.54554647 <a title="12-lsi-17" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>18 0.54388535 <a title="12-lsi-18" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>19 0.53658336 <a title="12-lsi-19" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>20 0.53584087 <a title="12-lsi-20" href="../hunch_net-2005/hunch_net-2005-04-14-Families_of_Learning_Theory_Statements.html">56 hunch net-2005-04-14-Families of Learning Theory Statements</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.041), (35, 0.049), (42, 0.33), (45, 0.056), (50, 0.018), (53, 0.241), (68, 0.044), (74, 0.091), (76, 0.032)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98077095 <a title="12-lda-1" href="../hunch_net-2006/hunch_net-2006-09-07-Objective_and_subjective_interpretations_of_probability.html">205 hunch net-2006-09-07-Objective and subjective interpretations of probability</a></p>
<p>Introduction: An amusing tidbit (reproduced without permission) from Herman Chernoff's
delightful monograph, "Sequential analysis and optimal design":The use of
randomization raises a philosophical question which is articulated by the
following probably apocryphal anecdote.The metallurgist told his friend the
statistician how he planned to test the effect of heat on the strength of a
metal bar by sawing the bar into six pieces. The first two would go into the
hot oven, the next two into the medium oven, and the last two into the cool
oven. The statistician, horrified, explained how he should randomize to avoid
the effect of a possible gradient of strength in the metal bar. The method of
randomization was applied, and it turned out that the randomized experiment
called for putting the first two pieces into the hot oven, the next two into
the medium oven, and the last two into the cool oven. "Obviously, we can't do
that," said the metallurgist. "On the contrary, you have to do that," said the
statisti</p><p>2 0.96521121 <a title="12-lda-2" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>Introduction: Attendance at theNIPS workshopsis highly recommended for both research and
learning. Unfortunately, there does not yet appear to be a public list of
workshops. However, I found the following workshop webpages of
interest:Machine Learning in FinanceLearning to RankFoundations of Active
LearningMachine Learning Based Robotics in Unstructured EnvironmentsThere
aremanymore workshops. In fact, there are so many that it is not plausible
anyone can attend every workshop they are interested in. Maybe in future years
the organizers can spread them out over more days to reduce overlap.Many of
these workshops are accepting presentation proposals (due mid-October).</p><p>3 0.950275 <a title="12-lda-3" href="../hunch_net-2009/hunch_net-2009-12-09-Inherent_Uncertainty.html">383 hunch net-2009-12-09-Inherent Uncertainty</a></p>
<p>Introduction: I'd like to point outInherent Uncertainty, which I've added to the ML blog
post scanner on the right. My understanding fromJakeis that the intention is
to have a multiauthor blog which is more specialized towards learning
theory/game theory than this one. Nevertheless, several of the posts seem to
be of wider interest.</p><p>4 0.92582726 <a title="12-lda-4" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>Introduction: Today brings a new release of theVowpal Wabbitfast online learning software.
This time, unlike the previous release, the project itself is going open
source, developing viagithub. For example, the lastest and greatest can be
downloaded via:git clone git://github.com/JohnLangford/vowpal_wabbit.gitIf you
aren't familiar withgit, it's a distributed version control system which
supports quick and easy branching, as well as reconciliation.This version of
the code is confirmed to compile without complaint on at least some flavors of
OSX as well as Linux boxes.As much of the point of this project is pushing the
limits of fast and effective machine learning, let me mention a few datapoints
from my experience.The program can effectively scale up to batch-style
training on sparse terafeature (i.e. 1012sparse feature) size datasets. The
limiting factor is typically i/o.I started using the the real datasets from
thelarge-scale learningworkshop as a convenient benchmark. The largest dataset
takes a</p><p>same-blog 5 0.90760541 <a title="12-lda-5" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>Introduction: One way to organize learning theory is by assumption (in theassumption = axiom
sense), from no assumptions to many assumptions. As you travel down this list,
the statements become stronger, but the scope of applicability decreases.No
assumptionsOnline learningThere exist a meta prediction algorithm which
compete well with the best element of any set of prediction
algorithms.Universal LearningUsing a "bias" of 2- description length of turing
machinein learning is equivalent to all other computable biases up to some
constant.ReductionsThe ability to predict well on classification problems is
equivalent to the ability to predict well on many other learning
problems.Independent and Identically Distributed (IID) DataPerformance
PredictionBased upon past performance, you can predict future
performance.Uniform ConvergencePerformance prediction works even after
choosing classifiers based on the data from large sets of classifiers.IID and
partial constraints on the data sourcePAC LearningThere</p><p>6 0.8981508 <a title="12-lda-6" href="../hunch_net-2005/hunch_net-2005-07-01-The_Role_of_Impromptu_Talks.html">88 hunch net-2005-07-01-The Role of Impromptu Talks</a></p>
<p>7 0.86844558 <a title="12-lda-7" href="../hunch_net-2010/hunch_net-2010-04-28-CI_Fellows_program_renewed.html">396 hunch net-2010-04-28-CI Fellows program renewed</a></p>
<p>8 0.81368536 <a title="12-lda-8" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>9 0.81266564 <a title="12-lda-9" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>10 0.81258523 <a title="12-lda-10" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>11 0.81064069 <a title="12-lda-11" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>12 0.80925429 <a title="12-lda-12" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>13 0.80805445 <a title="12-lda-13" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>14 0.80764651 <a title="12-lda-14" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>15 0.80758929 <a title="12-lda-15" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>16 0.80722916 <a title="12-lda-16" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>17 0.80692822 <a title="12-lda-17" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>18 0.8065418 <a title="12-lda-18" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>19 0.80615336 <a title="12-lda-19" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>20 0.80495572 <a title="12-lda-20" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
