<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-93" href="#">hunch_net-2005-93</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-93-html" href="http://hunch.net/?p=99">html</a></p><p>Introduction: Some of the “sister conference” presentations at  AAAI  have been great.  Roughly speaking, the conference organizers asked other conference organizers to come give a summary of their conference.  Many different AI-related conferences accepted.  The presenters typically discuss some of the background and goals of the conference then mention the results from a few papers they liked.  This is great because it provides a mechanism to get a digested overview of the work of several thousand researchers—something which is simply available nowhere else.
 
Based on these presentations, it looks like there is a significant component of (and opportunity for) applied machine learning in  AIIDE ,  IUI , and  ACL .
 
There was also some discussion of having a super-colocation event similar to  FCRC , but centered on AI & Learning.  This seems like a fine idea.  The field is fractured across so many different conferences that the mixing of a supercolocation seems likely helpful for research.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Some of the “sister conference” presentations at  AAAI  have been great. [sent-1, score-0.261]
</p><p>2 Roughly speaking, the conference organizers asked other conference organizers to come give a summary of their conference. [sent-2, score-1.457]
</p><p>3 The presenters typically discuss some of the background and goals of the conference then mention the results from a few papers they liked. [sent-4, score-1.134]
</p><p>4 This is great because it provides a mechanism to get a digested overview of the work of several thousand researchers—something which is simply available nowhere else. [sent-5, score-1.019]
</p><p>5 Based on these presentations, it looks like there is a significant component of (and opportunity for) applied machine learning in  AIIDE ,  IUI , and  ACL . [sent-6, score-0.646]
</p><p>6 There was also some discussion of having a super-colocation event similar to  FCRC , but centered on AI & Learning. [sent-7, score-0.439]
</p><p>7 The field is fractured across so many different conferences that the mixing of a supercolocation seems likely helpful for research. [sent-9, score-1.112]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('conference', 0.27), ('presentations', 0.261), ('organizers', 0.251), ('digested', 0.202), ('fractured', 0.202), ('presenters', 0.202), ('thousand', 0.202), ('fcrc', 0.187), ('nowhere', 0.187), ('mixing', 0.176), ('component', 0.176), ('centered', 0.168), ('overview', 0.168), ('acl', 0.162), ('conferences', 0.154), ('mention', 0.151), ('summary', 0.136), ('fine', 0.133), ('background', 0.133), ('aaai', 0.126), ('goals', 0.123), ('speaking', 0.123), ('ai', 0.121), ('looks', 0.121), ('opportunity', 0.119), ('asked', 0.119), ('roughly', 0.117), ('event', 0.116), ('discuss', 0.116), ('across', 0.108), ('different', 0.104), ('field', 0.103), ('likely', 0.099), ('researchers', 0.096), ('available', 0.088), ('provides', 0.087), ('give', 0.087), ('mechanism', 0.085), ('applied', 0.085), ('helpful', 0.084), ('seems', 0.082), ('discussion', 0.08), ('like', 0.079), ('similar', 0.075), ('come', 0.073), ('typically', 0.07), ('results', 0.069), ('significant', 0.066), ('based', 0.066), ('something', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="93-tfidf-1" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>Introduction: Some of the “sister conference” presentations at  AAAI  have been great.  Roughly speaking, the conference organizers asked other conference organizers to come give a summary of their conference.  Many different AI-related conferences accepted.  The presenters typically discuss some of the background and goals of the conference then mention the results from a few papers they liked.  This is great because it provides a mechanism to get a digested overview of the work of several thousand researchers—something which is simply available nowhere else.
 
Based on these presentations, it looks like there is a significant component of (and opportunity for) applied machine learning in  AIIDE ,  IUI , and  ACL .
 
There was also some discussion of having a super-colocation event similar to  FCRC , but centered on AI & Learning.  This seems like a fine idea.  The field is fractured across so many different conferences that the mixing of a supercolocation seems likely helpful for research.</p><p>2 0.16741844 <a title="93-tfidf-2" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>Introduction: Founding a successful new conference is extraordinarily difficult.  As a conference founder, you must manage to attract a significant number of good papers—enough to entice the participants into participating next year and to (generally) to grow the conference.  For someone choosing to participate in a new conference, there is a very significant decision to make: do you send a paper to some new conference with no guarantee that the conference will work out?  Or do you send it to another (possibly less related) conference that you are sure will work?
 
The conference founding problem is a joint agreement problem with a very significant barrier.  Workshops are a way around this problem, and workshops attached to conferences are a particularly effective means for this.  A workshop at a conference is sure to have people available to speak and attend and is sure to have a large audience available.  Presenting work at a workshop is not generally exclusive: it can also be presented at a confe</p><p>3 0.16363104 <a title="93-tfidf-3" href="../hunch_net-2005/hunch_net-2005-07-11-AAAI_blog.html">92 hunch net-2005-07-11-AAAI blog</a></p>
<p>Introduction: The  AAAI conference   is running a  student blog  which looks like a fun experiment.</p><p>4 0.136097 <a title="93-tfidf-4" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>Introduction: This is a reminder that many deadlines for summer conference registration are coming up, and attendance is a very good idea.  
  
 It’s entirely reasonable for anyone to visit a conference once, even when they don’t have a paper.  For students, visiting a conference is almost a ‘must’—there is no where else that a broad cross-section of research is on display. 
 Workshops are also a very good idea.   ICML has 11 ,  KDD has 9 , and  AAAI has 19 .  Workshops provide an opportunity to get a good understanding of some current area of research.  They are probably the forum most conducive to starting new lines of research because they are so interactive. 
 Tutorials are a good way to gain some understanding of a long-standing direction of research.  They are generally more coherent than workshops.   ICML has 7  and  AAAI has 15 .</p><p>5 0.13512428 <a title="93-tfidf-5" href="../hunch_net-2006/hunch_net-2006-01-06-MLTV.html">146 hunch net-2006-01-06-MLTV</a></p>
<p>Introduction: As part of a  PASCAL  project, the Slovenians have been filming various machine learning events and placing them on the web  here .  This includes, for example, the  Chicago 2005 Machine Learning Summer School  as well as a number of other summer schools, workshops, and conferences.
 
There are some significant caveats here—for example, I can’t access it from Linux.  Based upon the webserver logs, I expect that is a problem for most people—Computer scientists are particularly nonstandard in their choice of computing platform.
 
Nevertheless, the core idea here is excellent and details of compatibility can be fixed later.  With modern technology toys, there is no fundamental reason why the process of announcing new work at a conference should happen only once and only for the people who could make it to that room in that conference.  The problems solved include:
  
 The multitrack vs. single-track debate.  (“Sometimes the single track doesn’t interest me” vs. “When it’s multitrack I mis</p><p>6 0.13205214 <a title="93-tfidf-6" href="../hunch_net-2005/hunch_net-2005-06-10-Workshops_are_not_Conferences.html">80 hunch net-2005-06-10-Workshops are not Conferences</a></p>
<p>7 0.13054353 <a title="93-tfidf-7" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>8 0.12380194 <a title="93-tfidf-8" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>9 0.11344318 <a title="93-tfidf-9" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>10 0.11081047 <a title="93-tfidf-10" href="../hunch_net-2013/hunch_net-2013-05-04-COLT_and_ICML_registration.html">482 hunch net-2013-05-04-COLT and ICML registration</a></p>
<p>11 0.0983226 <a title="93-tfidf-11" href="../hunch_net-2010/hunch_net-2010-04-24-COLT_Treasurer_is_now_Phil_Long.html">394 hunch net-2010-04-24-COLT Treasurer is now Phil Long</a></p>
<p>12 0.09794347 <a title="93-tfidf-12" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>13 0.096718356 <a title="93-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<p>14 0.088993371 <a title="93-tfidf-14" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>15 0.088107646 <a title="93-tfidf-15" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>16 0.082517639 <a title="93-tfidf-16" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>17 0.082484432 <a title="93-tfidf-17" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>18 0.076452985 <a title="93-tfidf-18" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>19 0.075850822 <a title="93-tfidf-19" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>20 0.075414956 <a title="93-tfidf-20" href="../hunch_net-2007/hunch_net-2007-06-21-Presentation_Preparation.html">249 hunch net-2007-06-21-Presentation Preparation</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.159), (1, -0.121), (2, -0.028), (3, -0.008), (4, -0.039), (5, -0.018), (6, 0.027), (7, -0.013), (8, 0.048), (9, 0.047), (10, -0.053), (11, 0.043), (12, 0.011), (13, 0.063), (14, 0.066), (15, -0.01), (16, 0.041), (17, 0.126), (18, -0.016), (19, 0.063), (20, 0.131), (21, -0.078), (22, 0.02), (23, 0.15), (24, 0.086), (25, 0.016), (26, -0.147), (27, -0.018), (28, -0.055), (29, -0.017), (30, 0.018), (31, 0.094), (32, -0.03), (33, -0.138), (34, 0.106), (35, -0.083), (36, -0.022), (37, 0.017), (38, 0.003), (39, 0.111), (40, -0.095), (41, -0.059), (42, 0.121), (43, -0.029), (44, -0.02), (45, -0.021), (46, 0.085), (47, 0.058), (48, -0.065), (49, -0.108)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.979294 <a title="93-lsi-1" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>Introduction: Some of the “sister conference” presentations at  AAAI  have been great.  Roughly speaking, the conference organizers asked other conference organizers to come give a summary of their conference.  Many different AI-related conferences accepted.  The presenters typically discuss some of the background and goals of the conference then mention the results from a few papers they liked.  This is great because it provides a mechanism to get a digested overview of the work of several thousand researchers—something which is simply available nowhere else.
 
Based on these presentations, it looks like there is a significant component of (and opportunity for) applied machine learning in  AIIDE ,  IUI , and  ACL .
 
There was also some discussion of having a super-colocation event similar to  FCRC , but centered on AI & Learning.  This seems like a fine idea.  The field is fractured across so many different conferences that the mixing of a supercolocation seems likely helpful for research.</p><p>2 0.64457411 <a title="93-lsi-2" href="../hunch_net-2010/hunch_net-2010-10-29-To_Vidoelecture_or_not.html">416 hunch net-2010-10-29-To Vidoelecture or not</a></p>
<p>Introduction: (update:  cross-posted  on  CACM )
 
For the first time in several years,  ICML 2010  did not have  videolectures  attending.  Luckily, the  tutorial on exploration and learning  which  Alina  and I put together can  be viewed , since we also presented at  KDD 2010 , which included videolecture support. 
 
ICML didn’t cover the cost of a videolecture, because  PASCAL  didn’t provide a grant for it this year.  On the other hand, KDD covered it out of registration costs.  The cost of videolectures isn’t cheap.  For  a workshop  the baseline quote we have is 270 euro per hour, plus a similar cost for the cameraman’s travel and accomodation.  This can be reduced substantially by having a volunteer with a camera handle the cameraman duties, uploading the video and slides to be processed for a quoted 216 euro per hour.
 
 Youtube  is the most predominant free video site with a cost of $0, but it turns out to be a poor alternative.   15 minute upload limits  do not match typical talk lengths.</p><p>3 0.64007056 <a title="93-lsi-3" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>Introduction: Founding a successful new conference is extraordinarily difficult.  As a conference founder, you must manage to attract a significant number of good papers—enough to entice the participants into participating next year and to (generally) to grow the conference.  For someone choosing to participate in a new conference, there is a very significant decision to make: do you send a paper to some new conference with no guarantee that the conference will work out?  Or do you send it to another (possibly less related) conference that you are sure will work?
 
The conference founding problem is a joint agreement problem with a very significant barrier.  Workshops are a way around this problem, and workshops attached to conferences are a particularly effective means for this.  A workshop at a conference is sure to have people available to speak and attend and is sure to have a large audience available.  Presenting work at a workshop is not generally exclusive: it can also be presented at a confe</p><p>4 0.63787764 <a title="93-lsi-4" href="../hunch_net-2006/hunch_net-2006-01-06-MLTV.html">146 hunch net-2006-01-06-MLTV</a></p>
<p>Introduction: As part of a  PASCAL  project, the Slovenians have been filming various machine learning events and placing them on the web  here .  This includes, for example, the  Chicago 2005 Machine Learning Summer School  as well as a number of other summer schools, workshops, and conferences.
 
There are some significant caveats here—for example, I can’t access it from Linux.  Based upon the webserver logs, I expect that is a problem for most people—Computer scientists are particularly nonstandard in their choice of computing platform.
 
Nevertheless, the core idea here is excellent and details of compatibility can be fixed later.  With modern technology toys, there is no fundamental reason why the process of announcing new work at a conference should happen only once and only for the people who could make it to that room in that conference.  The problems solved include:
  
 The multitrack vs. single-track debate.  (“Sometimes the single track doesn’t interest me” vs. “When it’s multitrack I mis</p><p>5 0.61533332 <a title="93-lsi-5" href="../hunch_net-2007/hunch_net-2007-02-11-24.html">232 hunch net-2007-02-11-24</a></p>
<p>Introduction: To commemorate the  Twenty Fourth Annual International Conference on Machine  Learning  (ICML-07), the FOX Network has decided to  launch a new spin-off series in prime time.  Through unofficial  sources, I have obtained the  story arc  for the first season, which appears frighteningly realistic.</p><p>6 0.61355138 <a title="93-lsi-6" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>7 0.60341704 <a title="93-lsi-7" href="../hunch_net-2005/hunch_net-2005-06-10-Workshops_are_not_Conferences.html">80 hunch net-2005-06-10-Workshops are not Conferences</a></p>
<p>8 0.53007418 <a title="93-lsi-8" href="../hunch_net-2005/hunch_net-2005-07-11-AAAI_blog.html">92 hunch net-2005-07-11-AAAI blog</a></p>
<p>9 0.48902634 <a title="93-lsi-9" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>10 0.48527199 <a title="93-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<p>11 0.48487967 <a title="93-lsi-11" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>12 0.46216854 <a title="93-lsi-12" href="../hunch_net-2007/hunch_net-2007-07-13-The_View_From_China.html">255 hunch net-2007-07-13-The View From China</a></p>
<p>13 0.45617595 <a title="93-lsi-13" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>14 0.43695903 <a title="93-lsi-14" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>15 0.43177205 <a title="93-lsi-15" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>16 0.42875472 <a title="93-lsi-16" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>17 0.42346296 <a title="93-lsi-17" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>18 0.41560346 <a title="93-lsi-18" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>19 0.40672359 <a title="93-lsi-19" href="../hunch_net-2013/hunch_net-2013-05-04-COLT_and_ICML_registration.html">482 hunch net-2013-05-04-COLT and ICML registration</a></p>
<p>20 0.40179589 <a title="93-lsi-20" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.196), (53, 0.112), (55, 0.102), (88, 0.436), (94, 0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.91979432 <a title="93-lda-1" href="../hunch_net-2012/hunch_net-2012-07-09-Videolectures.html">469 hunch net-2012-07-09-Videolectures</a></p>
<p>Introduction: Yaser  points out some nicely  videotaped machine learning lectures  at  Caltech .  Yaser taught me machine learning, and I always found the lectures clear and interesting, so I expect many people can benefit from watching.  Relative to  Andrew Ng â&euro;&tilde;s  ML class  there are somewhat different areas of emphasis but the topic is the same, so picking and choosing the union may be helpful.</p><p>same-blog 2 0.85174775 <a title="93-lda-2" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>Introduction: Some of the “sister conference” presentations at  AAAI  have been great.  Roughly speaking, the conference organizers asked other conference organizers to come give a summary of their conference.  Many different AI-related conferences accepted.  The presenters typically discuss some of the background and goals of the conference then mention the results from a few papers they liked.  This is great because it provides a mechanism to get a digested overview of the work of several thousand researchers—something which is simply available nowhere else.
 
Based on these presentations, it looks like there is a significant component of (and opportunity for) applied machine learning in  AIIDE ,  IUI , and  ACL .
 
There was also some discussion of having a super-colocation event similar to  FCRC , but centered on AI & Learning.  This seems like a fine idea.  The field is fractured across so many different conferences that the mixing of a supercolocation seems likely helpful for research.</p><p>3 0.81818962 <a title="93-lda-3" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>Introduction: One of the questions facing machine learning as a field is “Can we produce a generalized learning system that can solve a wide array of standard learning problems?”  The answer is trivial: “yes, just have children”.
 
Of course, that wasn’t really the question.  The refined question is “Are there simple-to-implement generalized learning systems that can solve a wide array of standard learning problems?”  The answer to this is less clear.  The ability of animals (and people ) to learn might be due to megabytes encoded in the DNA.  If this algorithmic complexity is  necessary  to solve machine learning, the field faces a daunting task in replicating it on a computer.
 
This observation suggests a possibility: if you can show that few bits of DNA are needed for learning in animals, then this provides evidence that machine learning (as a field) has a hope of big success with relatively little effort. 
 
It is well known that specific portions of the brain have specific functionality across</p><p>4 0.80413657 <a title="93-lda-4" href="../hunch_net-2005/hunch_net-2005-02-04-JMLG.html">13 hunch net-2005-02-04-JMLG</a></p>
<p>Introduction: The  Journal of Machine Learning Gossip  has some fine satire about learning research.  In particular, the  guides  are amusing and remarkably true.
 
As in all things, itâ&euro;&trade;s easy to criticize the way things are and harder to make them better.</p><p>5 0.76188701 <a title="93-lda-5" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I’ve enjoyed the  Terminator  movies and show.  Neglecting the whacky aspects (time travel and associated paradoxes), there is an enduring topic of discussion: how do people deal with intelligent machines (and vice versa)?
 
In Terminator-land, the primary method for dealing with intelligent machines is to prevent them from being made.  This approach works pretty badly, because a new angle on building an intelligent machine keeps coming up.  This is partly a ploy for writer’s to avoid writing themselves out of a job, but there is a fundamental truth to it as well: preventing progress in research is hard.
 
The United States, has been experimenting with trying to stop research on  stem cells .  It hasn’t worked very well—the net effect has been retarding research programs a bit, and exporting some research to other countries.  Another less recent example was encryption technology, for which the United States generally did not encourage early public research and even  discouraged as a mu</p><p>6 0.60216755 <a title="93-lda-6" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>7 0.47274324 <a title="93-lda-7" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>8 0.4706338 <a title="93-lda-8" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>9 0.46777809 <a title="93-lda-9" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>10 0.46687043 <a title="93-lda-10" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>11 0.46633139 <a title="93-lda-11" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>12 0.46627674 <a title="93-lda-12" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>13 0.46528846 <a title="93-lda-13" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>14 0.46430275 <a title="93-lda-14" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>15 0.46292168 <a title="93-lda-15" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>16 0.46236417 <a title="93-lda-16" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>17 0.46235377 <a title="93-lda-17" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>18 0.4621208 <a title="93-lda-18" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>19 0.46193632 <a title="93-lda-19" href="../hunch_net-2006/hunch_net-2006-01-25-1_year.html">151 hunch net-2006-01-25-1 year</a></p>
<p>20 0.46076435 <a title="93-lda-20" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
