<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>75 hunch net-2005-05-28-Running A Machine Learning Summer School</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-75" href="#">hunch_net-2005-75</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>75 hunch net-2005-05-28-Running A Machine Learning Summer School</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-75-html" href="http://hunch.net/?p=81">html</a></p><p>Introduction: We just finished theChicago 2005 Machine Learning Summer School. The school
was 2 weeks long with about 130 (or 140 counting the speakers) participants.
For perspective, this is perhaps the largest graduate level machine learning
class I am aware of anywhere and anytime (previousMLSSs have been close).
Overall, it seemed to go well, although the students are the real authority on
this. For those who missed it, DVDs will be available from our Slovenian
friends. EmailMrs Spela Sitarof the Jozsef Stefan Institute for details.The
following are some notes for future planning and those interested.Good
DecisionsAcquiring the larger-than-necessary "Assembly Hall" atInternational
House. Our attendance came in well above our expectations, so this was a
critical early decision that made a huge difference.The invited speakers were
key. They made a huge difference in the quality of the content.Delegating
early and often was important. One key difficulty here is gauging how much a
volunteer can (or</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The school was 2 weeks long with about 130 (or 140 counting the speakers) participants. [sent-2, score-0.115]
</p><p>2 Overall, it seemed to go well, although the students are the real authority on this. [sent-4, score-0.231]
</p><p>3 Our attendance came in well above our expectations, so this was a critical early decision that made a huge difference. [sent-9, score-0.408]
</p><p>4 They made a huge difference in the quality of the content. [sent-11, score-0.092]
</p><p>5 One key difficulty here is gauging how much a volunteer can (or should) do. [sent-13, score-0.171]
</p><p>6 Many people are willing to help a little, so breaking things down into small chunks is important. [sent-14, score-0.17]
</p><p>7 Unclear DecisionsTiming (May 16-27, 2005): We wanted to take advantage of thespecial emphasis on learningquarter here. [sent-15, score-0.197]
</p><p>8 We also wanted to run the summer school in the summer. [sent-16, score-0.465]
</p><p>9 By starting as late as possible in the quarter, we were in the "summer" for universities on a semester schedule but not those on a quarter schedule. [sent-18, score-0.26]
</p><p>10 Thus, we traded some students and scheduling conflicts at University of chicago for the advantages of the learning quarter. [sent-19, score-0.566]
</p><p>11 Location in Chicago implied many locals drifted in and out. [sent-25, score-0.167]
</p><p>12 The disadvantage was that it forced talks to start relatively early. [sent-29, score-0.177]
</p><p>13 This meant that attendance at the start of the first lecture was relatively low (60-or-so), ramping up through the morning. [sent-30, score-0.288]
</p><p>14 Although some students benefitted from the workshop talks, most appeared to gain much more from the summer school. [sent-31, score-0.476]
</p><p>15 This difficulty can not be avoided, but it can be ameliorated. [sent-43, score-0.087]
</p><p>16 Having presentation slides and suggested reading well in advance helps. [sent-44, score-0.216]
</p><p>17 The bad news here is that it isverydifficult to get speakers to make materials available in advance. [sent-45, score-0.478]
</p><p>18 They naturally want to tweak slides at the last minute and include the newest cool discoveries. [sent-46, score-0.287]
</p><p>19 The FutureThere will almost certainly be future machine learning summer schools in theseriesand otherwise. [sent-48, score-0.321]
</p><p>20 My impression is that the support due to being "in series" is not critical to success, but it is considerable. [sent-49, score-0.094]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('summer', 0.245), ('speakers', 0.239), ('chicago', 0.227), ('hyde', 0.204), ('park', 0.204), ('quarter', 0.181), ('students', 0.14), ('slides', 0.132), ('series', 0.128), ('attendance', 0.117), ('school', 0.115), ('advantages', 0.115), ('early', 0.105), ('wanted', 0.105), ('talks', 0.097), ('critical', 0.094), ('advantage', 0.092), ('huge', 0.092), ('assembly', 0.091), ('authority', 0.091), ('benefitted', 0.091), ('chunks', 0.091), ('differently', 0.091), ('drifted', 0.091), ('ramping', 0.091), ('difficulty', 0.087), ('consisting', 0.084), ('backgrounds', 0.084), ('conflicts', 0.084), ('sorting', 0.084), ('suggested', 0.084), ('volunteer', 0.084), ('get', 0.083), ('start', 0.08), ('available', 0.08), ('breaking', 0.079), ('tweak', 0.079), ('avoided', 0.079), ('anytime', 0.079), ('schedule', 0.079), ('suggestion', 0.079), ('schools', 0.076), ('institute', 0.076), ('implied', 0.076), ('thechicago', 0.076), ('expectations', 0.076), ('finished', 0.076), ('materials', 0.076), ('minute', 0.076), ('posted', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9999997 <a title="75-tfidf-1" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>Introduction: We just finished theChicago 2005 Machine Learning Summer School. The school
was 2 weeks long with about 130 (or 140 counting the speakers) participants.
For perspective, this is perhaps the largest graduate level machine learning
class I am aware of anywhere and anytime (previousMLSSs have been close).
Overall, it seemed to go well, although the students are the real authority on
this. For those who missed it, DVDs will be available from our Slovenian
friends. EmailMrs Spela Sitarof the Jozsef Stefan Institute for details.The
following are some notes for future planning and those interested.Good
DecisionsAcquiring the larger-than-necessary "Assembly Hall" atInternational
House. Our attendance came in well above our expectations, so this was a
critical early decision that made a huge difference.The invited speakers were
key. They made a huge difference in the quality of the content.Delegating
early and often was important. One key difficulty here is gauging how much a
volunteer can (or</p><p>2 0.21415557 <a title="75-tfidf-2" href="../hunch_net-2005/hunch_net-2005-01-26-Summer_Schools.html">4 hunch net-2005-01-26-Summer Schools</a></p>
<p>Introduction: There are several summer schools related to machine learning.We are running a
two weekmachine learning summer schoolin Chicago, USA May 16-27.IPAM is
running a more focused three week summer school onIntelligent Extraction of
Information from Graphs and High Dimensional Datain Los Angeles, USA July
11-29.A broad one-week school onanalysis of patternswill be held in Erice,
Italy, Oct. 28-Nov 6.</p><p>3 0.21335192 <a title="75-tfidf-3" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>Introduction: The 2006 Machine Learning Summer School in Taipei, Taiwan ended on August 4,
2006. It has been a very exciting two weeks for a record crowd of 245
participants (including speakers and organizers) from 18 countries. We had a
lineup of speakers that is hard to match up for other similar events (see
ourWIKIfor more information). With this lineup, it is difficult for us as
organizers to screw it up too bad. Also, since we have pretty good
infrastructure for international meetings and experienced staff at NTUST and
Academia Sinica, plus the reputation established by previous MLSS series, it
was relatively easy for us to attract registrations and simply enjoyed this
two-week long party of machine learning.In the end of MLSS we distributed a
survey form for participants to fill in. I will report what we found from this
survey, together with the registration data and word-of-mouth from
participants.The first question is designed to find out how our participants
learned about MLSS 2006 Taipei.</p><p>4 0.16334227 <a title="75-tfidf-4" href="../hunch_net-2005/hunch_net-2005-06-13-Wikis_for_Summer_Schools_and_Workshops.html">81 hunch net-2005-06-13-Wikis for Summer Schools and Workshops</a></p>
<p>Introduction: Chicago '05ended a couple of weeks ago. This was the sixthMachine Learning
Summer School, and the second one that used awiki. (The first was Berder '04,
thanks to Gunnar Raetsch.) Wikis are relatively easy to set up, greatly aid
social interaction, and should be used a lot more at summer schools and
workshops. They can even be used as the meeting's webpage, as a permanent
record of its participants' collaborations -- see for example the wiki/website
for last year'sNVO Summer School.A basic wiki is a collection of editable
webpages, maintained by software called awiki engine. The engine used at both
Berder and Chicago wasTikiWiki-- it is well documented and gets you something
running fast. It uses PHP and MySQL, but doesn't require you to know either.
Tikiwiki has far more features than most wikis, as it is really a fullContent
Management System. (My thanks to Sebastian Stark for pointing this out.) Here
are the features we found most useful:Bulletin boards, or forums. The most-
used on</p><p>5 0.15003364 <a title="75-tfidf-5" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>Introduction: Unfortunately, I ended up sick for much of this ICML. I did manage to catch
one interesting paper:Richard Socher,Cliff Lin,Andrew Y. Ng, andChristopher D.
ManningParsing Natural Scenes and Natural Language with Recursive Neural
Networks.I invited Richard to share his list of interesting papers, so
hopefully we'll hear from him soon. In the meantime,PaulandHalhave posted some
lists.the futureJoelleand I are program chairs for ICML 2012 inEdinburgh,
which I previously enjoyed visiting in2005. This is a huge responsibility,
that we hope to accomplish well. A part of this (perhaps the most fun part),
is imagining how we can make ICML better. A key and critical constraint is
choosing things that can be accomplished. So far we have:Colocation. The first
thing we looked into was potential colocations. We quickly discovered that
many other conferences precomitted their location. For the future, getting a
colocation withACLorSIGIR, seems to require more advanced planning. If that
can be done, I</p><p>6 0.14312309 <a title="75-tfidf-6" href="../hunch_net-2005/hunch_net-2005-06-10-Workshops_are_not_Conferences.html">80 hunch net-2005-06-10-Workshops are not Conferences</a></p>
<p>7 0.13120425 <a title="75-tfidf-7" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>8 0.12887225 <a title="75-tfidf-8" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>9 0.12084866 <a title="75-tfidf-9" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>10 0.11516833 <a title="75-tfidf-10" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>11 0.11190398 <a title="75-tfidf-11" href="../hunch_net-2006/hunch_net-2006-01-06-MLTV.html">146 hunch net-2006-01-06-MLTV</a></p>
<p>12 0.10472051 <a title="75-tfidf-12" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>13 0.10040282 <a title="75-tfidf-13" href="../hunch_net-2005/hunch_net-2005-05-11-Visa_Casualties.html">69 hunch net-2005-05-11-Visa Casualties</a></p>
<p>14 0.099456176 <a title="75-tfidf-14" href="../hunch_net-2009/hunch_net-2009-05-30-Many_ways_to_Learn_this_summer.html">357 hunch net-2009-05-30-Many ways to Learn this summer</a></p>
<p>15 0.098937571 <a title="75-tfidf-15" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>16 0.095006898 <a title="75-tfidf-16" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>17 0.093575597 <a title="75-tfidf-17" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>18 0.092273869 <a title="75-tfidf-18" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>19 0.091142185 <a title="75-tfidf-19" href="../hunch_net-2005/hunch_net-2005-11-16-MLSS_2006.html">130 hunch net-2005-11-16-MLSS 2006</a></p>
<p>20 0.090680033 <a title="75-tfidf-20" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">324 hunch net-2008-11-09-A Healthy  COLT</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.213), (1, 0.115), (2, 0.138), (3, 0.08), (4, 0.064), (5, -0.009), (6, 0.006), (7, 0.049), (8, 0.012), (9, -0.037), (10, 0.027), (11, -0.002), (12, 0.013), (13, 0.005), (14, -0.212), (15, 0.068), (16, -0.023), (17, 0.14), (18, -0.059), (19, -0.143), (20, 0.151), (21, 0.115), (22, 0.087), (23, 0.022), (24, -0.068), (25, -0.045), (26, -0.159), (27, -0.02), (28, 0.089), (29, 0.074), (30, -0.033), (31, -0.063), (32, -0.0), (33, 0.046), (34, 0.022), (35, 0.063), (36, -0.022), (37, -0.037), (38, 0.001), (39, 0.049), (40, -0.081), (41, 0.021), (42, -0.096), (43, -0.013), (44, 0.008), (45, -0.006), (46, 0.003), (47, -0.07), (48, -0.084), (49, -0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96691924 <a title="75-lsi-1" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>Introduction: We just finished theChicago 2005 Machine Learning Summer School. The school
was 2 weeks long with about 130 (or 140 counting the speakers) participants.
For perspective, this is perhaps the largest graduate level machine learning
class I am aware of anywhere and anytime (previousMLSSs have been close).
Overall, it seemed to go well, although the students are the real authority on
this. For those who missed it, DVDs will be available from our Slovenian
friends. EmailMrs Spela Sitarof the Jozsef Stefan Institute for details.The
following are some notes for future planning and those interested.Good
DecisionsAcquiring the larger-than-necessary "Assembly Hall" atInternational
House. Our attendance came in well above our expectations, so this was a
critical early decision that made a huge difference.The invited speakers were
key. They made a huge difference in the quality of the content.Delegating
early and often was important. One key difficulty here is gauging how much a
volunteer can (or</p><p>2 0.80612278 <a title="75-lsi-2" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>Introduction: The 2006 Machine Learning Summer School in Taipei, Taiwan ended on August 4,
2006. It has been a very exciting two weeks for a record crowd of 245
participants (including speakers and organizers) from 18 countries. We had a
lineup of speakers that is hard to match up for other similar events (see
ourWIKIfor more information). With this lineup, it is difficult for us as
organizers to screw it up too bad. Also, since we have pretty good
infrastructure for international meetings and experienced staff at NTUST and
Academia Sinica, plus the reputation established by previous MLSS series, it
was relatively easy for us to attract registrations and simply enjoyed this
two-week long party of machine learning.In the end of MLSS we distributed a
survey form for participants to fill in. I will report what we found from this
survey, together with the registration data and word-of-mouth from
participants.The first question is designed to find out how our participants
learned about MLSS 2006 Taipei.</p><p>3 0.7271238 <a title="75-lsi-3" href="../hunch_net-2005/hunch_net-2005-01-26-Summer_Schools.html">4 hunch net-2005-01-26-Summer Schools</a></p>
<p>Introduction: There are several summer schools related to machine learning.We are running a
two weekmachine learning summer schoolin Chicago, USA May 16-27.IPAM is
running a more focused three week summer school onIntelligent Extraction of
Information from Graphs and High Dimensional Datain Los Angeles, USA July
11-29.A broad one-week school onanalysis of patternswill be held in Erice,
Italy, Oct. 28-Nov 6.</p><p>4 0.69925678 <a title="75-lsi-4" href="../hunch_net-2005/hunch_net-2005-06-13-Wikis_for_Summer_Schools_and_Workshops.html">81 hunch net-2005-06-13-Wikis for Summer Schools and Workshops</a></p>
<p>Introduction: Chicago '05ended a couple of weeks ago. This was the sixthMachine Learning
Summer School, and the second one that used awiki. (The first was Berder '04,
thanks to Gunnar Raetsch.) Wikis are relatively easy to set up, greatly aid
social interaction, and should be used a lot more at summer schools and
workshops. They can even be used as the meeting's webpage, as a permanent
record of its participants' collaborations -- see for example the wiki/website
for last year'sNVO Summer School.A basic wiki is a collection of editable
webpages, maintained by software called awiki engine. The engine used at both
Berder and Chicago wasTikiWiki-- it is well documented and gets you something
running fast. It uses PHP and MySQL, but doesn't require you to know either.
Tikiwiki has far more features than most wikis, as it is really a fullContent
Management System. (My thanks to Sebastian Stark for pointing this out.) Here
are the features we found most useful:Bulletin boards, or forums. The most-
used on</p><p>5 0.63470209 <a title="75-lsi-5" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>Introduction: Thanksgiving is perhaps my favorite holiday, because pausing your life and
giving thanks provides a needed moment of perspective.As a researcher, I am
most thankful for my education, without which I could not function. I want to
share this, because it provides some sense of how a researcher starts.My long
term memory seems to function particularly well, which makes any education I
get is particularly useful.I am naturally obsessive, which makes me chase down
details until I fully understand things. Natural obsessiveness can go wrong,
of course, but it's a great ally when you absolutely must get things right.My
childhood was all in one hometown, which was a conscious sacrifice on the part
of my father, implying disruptions from moving around were eliminated. I'm not
sure how important this was since travel has it's own benefits, but it bears
thought.I had several great teachers in grade school, and naturally gravitated
towards teachers over classmates, as they seemed more interesting. I</p><p>6 0.60278398 <a title="75-lsi-6" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>7 0.56974405 <a title="75-lsi-7" href="../hunch_net-2009/hunch_net-2009-05-30-Many_ways_to_Learn_this_summer.html">357 hunch net-2009-05-30-Many ways to Learn this summer</a></p>
<p>8 0.5604772 <a title="75-lsi-8" href="../hunch_net-2005/hunch_net-2005-05-11-Visa_Casualties.html">69 hunch net-2005-05-11-Visa Casualties</a></p>
<p>9 0.5590567 <a title="75-lsi-9" href="../hunch_net-2005/hunch_net-2005-05-03-Conference_attendance_is_mandatory.html">66 hunch net-2005-05-03-Conference attendance is mandatory</a></p>
<p>10 0.54285783 <a title="75-lsi-10" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>11 0.53635186 <a title="75-lsi-11" href="../hunch_net-2007/hunch_net-2007-06-21-Presentation_Preparation.html">249 hunch net-2007-06-21-Presentation Preparation</a></p>
<p>12 0.53344852 <a title="75-lsi-12" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>13 0.51945812 <a title="75-lsi-13" href="../hunch_net-2005/hunch_net-2005-11-16-MLSS_2006.html">130 hunch net-2005-11-16-MLSS 2006</a></p>
<p>14 0.51027942 <a title="75-lsi-14" href="../hunch_net-2006/hunch_net-2006-01-06-MLTV.html">146 hunch net-2006-01-06-MLTV</a></p>
<p>15 0.49627551 <a title="75-lsi-15" href="../hunch_net-2005/hunch_net-2005-05-17-A_Short_Guide_to_PhD_Graduate_Study.html">73 hunch net-2005-05-17-A Short Guide to PhD Graduate Study</a></p>
<p>16 0.47355652 <a title="75-lsi-16" href="../hunch_net-2005/hunch_net-2005-07-01-The_Role_of_Impromptu_Talks.html">88 hunch net-2005-07-01-The Role of Impromptu Talks</a></p>
<p>17 0.46755502 <a title="75-lsi-17" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>18 0.46513471 <a title="75-lsi-18" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>19 0.46089643 <a title="75-lsi-19" href="../hunch_net-2013/hunch_net-2013-11-09-Graduates_and_Postdocs.html">490 hunch net-2013-11-09-Graduates and Postdocs</a></p>
<p>20 0.45235804 <a title="75-lsi-20" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.016), (39, 0.029), (42, 0.152), (74, 0.641), (88, 0.04), (95, 0.04)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98910892 <a title="75-lda-1" href="../hunch_net-2007/hunch_net-2007-12-17-New_Machine_Learning_mailing_list.html">278 hunch net-2007-12-17-New Machine Learning mailing list</a></p>
<p>Introduction: IMLS(which is the nonprofit running ICML) has setup a new mailing list
forMachine Learning News. The list address is ML-news@googlegroups.com, and
signup requires a google account (which you can create). Only members can send
messages.</p><p>same-blog 2 0.96900666 <a title="75-lda-2" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>Introduction: We just finished theChicago 2005 Machine Learning Summer School. The school
was 2 weeks long with about 130 (or 140 counting the speakers) participants.
For perspective, this is perhaps the largest graduate level machine learning
class I am aware of anywhere and anytime (previousMLSSs have been close).
Overall, it seemed to go well, although the students are the real authority on
this. For those who missed it, DVDs will be available from our Slovenian
friends. EmailMrs Spela Sitarof the Jozsef Stefan Institute for details.The
following are some notes for future planning and those interested.Good
DecisionsAcquiring the larger-than-necessary "Assembly Hall" atInternational
House. Our attendance came in well above our expectations, so this was a
critical early decision that made a huge difference.The invited speakers were
key. They made a huge difference in the quality of the content.Delegating
early and often was important. One key difficulty here is gauging how much a
volunteer can (or</p><p>3 0.96785235 <a title="75-lda-3" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>4 0.96593469 <a title="75-lda-4" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>Introduction: The health ofCOLT(Conference on Learning Theory or Computational Learning
Theory depending on who you ask) has been questioned over the last few years.
Low points for the conference occurred whenEuroCOLTmerged with COLT in 2001,
and the attendance at the 2002 Sydney COLT fell to a new low. This occurred in
the general context of machine learning conferences rising in both number and
size over the last decade.Any discussion ofwhyCOLT has had difficulties is
inherently controversial as is any story about well-intentioned people making
the wrong decisions. Nevertheless, this may be worth discussing in the hope of
avoiding problems in the future and general understanding. In any such
discussion there is a strong tendency to identify with a conference/community
in a patriotic manner that is detrimental to thinking. Keep in mind that
conferences exist to further research.My understanding (I wasn't around) is
that COLT started as a subcommunity of the computer science theory community.
This i</p><p>5 0.96231401 <a title="75-lda-5" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>6 0.94500715 <a title="75-lda-6" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>7 0.92145228 <a title="75-lda-7" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>8 0.91287237 <a title="75-lda-8" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>9 0.85529119 <a title="75-lda-9" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>10 0.84896553 <a title="75-lda-10" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>11 0.83286184 <a title="75-lda-11" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>12 0.83209372 <a title="75-lda-12" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>13 0.82741708 <a title="75-lda-13" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>14 0.8268038 <a title="75-lda-14" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>15 0.82373965 <a title="75-lda-15" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>16 0.81512332 <a title="75-lda-16" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>17 0.80005914 <a title="75-lda-17" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>18 0.79681867 <a title="75-lda-18" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>19 0.78757662 <a title="75-lda-19" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>20 0.78546667 <a title="75-lda-20" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
