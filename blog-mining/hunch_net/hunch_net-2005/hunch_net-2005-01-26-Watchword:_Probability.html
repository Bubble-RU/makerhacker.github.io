<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>5 hunch net-2005-01-26-Watchword: Probability</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-5" href="#">hunch_net-2005-5</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>5 hunch net-2005-01-26-Watchword: Probability</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-5-html" href="http://hunch.net/?p=8">html</a></p><p>Introduction: Probability is one of the most confusingly used words in machine learning.  There are at least 3 distinct ways the word is used. 
  
  Bayesian  The Bayesian notion of probability is a ‘degree of belief’.   The degree of belief that some event (i.e. “stock goes up” or “stock goes down”) occurs can be measured by asking a sequence of questions of the form “Would you bet the stock goes up or down at  Y  to 1 odds?” A consistent better will switch from ‘for’ to ‘against’ at some single value of  Y .  The probability is then  Y/(Y+1) .  Bayesian probabilities express lack of knowledge rather than randomization.  They are useful in learning because we often lack knowledge and expressing that lack flexibly makes the learning algorithms work better.  Bayesian Learning uses ‘probability’ in this way exclusively. 
  Frequentist  The Frequentist notion of probability is a rate of occurence.  A rate of occurrence can be measured by doing an experiment many times.  If an event occurs  k  times in</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Probability is one of the most confusingly used words in machine learning. [sent-1, score-0.138]
</p><p>2 There are at least 3 distinct ways the word is used. [sent-2, score-0.189]
</p><p>3 Bayesian  The Bayesian notion of probability is a ‘degree of belief’. [sent-3, score-0.636]
</p><p>4 “stock goes up” or “stock goes down”) occurs can be measured by asking a sequence of questions of the form “Would you bet the stock goes up or down at  Y  to 1 odds? [sent-6, score-1.325]
</p><p>5 ” A consistent better will switch from ‘for’ to ‘against’ at some single value of  Y . [sent-7, score-0.22]
</p><p>6 Bayesian probabilities express lack of knowledge rather than randomization. [sent-9, score-0.607]
</p><p>7 They are useful in learning because we often lack knowledge and expressing that lack flexibly makes the learning algorithms work better. [sent-10, score-0.475]
</p><p>8 Frequentist  The Frequentist notion of probability is a rate of occurence. [sent-12, score-0.711]
</p><p>9 A rate of occurrence can be measured by doing an experiment many times. [sent-13, score-0.333]
</p><p>10 If an event occurs  k  times in  n  experiments then it has probability about  k/n . [sent-14, score-0.731]
</p><p>11 Frequentist probabilities can be used to measure how sure you are about something. [sent-15, score-0.313]
</p><p>12 They may be appropriate in a learning context for measuring confidence in various predictors. [sent-16, score-0.216]
</p><p>13 The frequentist notion of probability is common in physics, other sciences, and computer science theory. [sent-17, score-1.073]
</p><p>14 Estimated   The estimated notion of probability is measured by running some learning algorithm which predicts the probability of events rather than events. [sent-18, score-1.628]
</p><p>15 I tend to dislike this use of the word because it confuses the world with the model of the world. [sent-19, score-0.266]
</p><p>16 To avoid confusion, you should be careful to understand what other people mean for this word. [sent-20, score-0.117]
</p><p>17 It is helpful to always be explicit about which variables are randomized and which are constant whenever probability is used because Bayesian and Frequentist probabilities commonly switch this role. [sent-21, score-1.299]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('frequentist', 0.437), ('probability', 0.43), ('probabilities', 0.232), ('stock', 0.218), ('bayesian', 0.208), ('notion', 0.206), ('measured', 0.202), ('goes', 0.187), ('estimated', 0.167), ('switch', 0.154), ('lack', 0.147), ('occurs', 0.132), ('degree', 0.12), ('word', 0.12), ('event', 0.115), ('belief', 0.105), ('measuring', 0.1), ('knowledge', 0.098), ('sciences', 0.093), ('bet', 0.087), ('dislike', 0.087), ('whenever', 0.087), ('expressing', 0.083), ('used', 0.081), ('randomized', 0.077), ('rate', 0.075), ('odds', 0.075), ('predicts', 0.075), ('express', 0.073), ('role', 0.071), ('asking', 0.069), ('confusion', 0.069), ('distinct', 0.069), ('physics', 0.069), ('variables', 0.067), ('consistent', 0.066), ('careful', 0.063), ('events', 0.061), ('confidence', 0.06), ('tend', 0.059), ('explicit', 0.058), ('constant', 0.057), ('words', 0.057), ('rather', 0.057), ('experiment', 0.056), ('sequence', 0.056), ('appropriate', 0.056), ('commonly', 0.056), ('experiments', 0.054), ('mean', 0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="5-tfidf-1" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.  There are at least 3 distinct ways the word is used. 
  
  Bayesian  The Bayesian notion of probability is a ‘degree of belief’.   The degree of belief that some event (i.e. “stock goes up” or “stock goes down”) occurs can be measured by asking a sequence of questions of the form “Would you bet the stock goes up or down at  Y  to 1 odds?” A consistent better will switch from ‘for’ to ‘against’ at some single value of  Y .  The probability is then  Y/(Y+1) .  Bayesian probabilities express lack of knowledge rather than randomization.  They are useful in learning because we often lack knowledge and expressing that lack flexibly makes the learning algorithms work better.  Bayesian Learning uses ‘probability’ in this way exclusively. 
  Frequentist  The Frequentist notion of probability is a rate of occurence.  A rate of occurrence can be measured by doing an experiment many times.  If an event occurs  k  times in</p><p>2 0.21799894 <a title="5-tfidf-2" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>Introduction: Sam Roweis ‘s comment reminds me of a more general issue that comes up in doing research: abstractions always break.  
  
 Real number’s aren’t.  Most real numbers can not be represented with any machine.  One implication of this is that many real-number based algorithms have difficulties when implemented with floating point numbers. 
 The box on your desk is not a turing machine. A turing machine can compute anything computable, given sufficient time.  A typical computer fails terribly when the state required for the computation exceeds some limit. 
 Nash equilibria aren’t equilibria.  This comes up when trying to predict human behavior based on the result of the equilibria computation.  Often, it doesn’t work. 
 The  probability  isn’t.  Probability is an abstraction expressing either our lack of knowledge (the Bayesian viewpoint) or fundamental randomization (the frequentist viewpoint).  From the frequentist viewpoint the lack of knowledge typically precludes actually knowing the fu</p><p>3 0.17853141 <a title="5-tfidf-3" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>Introduction: A calibrated predictor is one which predicts the probability of a binary event with the property: For all predictions  p , the proportion of the time that  1  is observed is  p .
 
Since there are infinitely many  p , this definition must be “softened” to make sense for any finite number of samples.  The standard method for “softening” is to consider all predictions in a small neighborhood about each possible  p .
 
A great deal of effort has been devoted to strategies for achieving calibrated (such as  here ) prediction.  With statements like: (under minimal conditions) you can always make calibrated predictions.  
 
Given the strength of these statements, we might conclude we are done, but that would be a “confusion of ends”.  A confusion of ends arises in the following way:
  
 We want good probabilistic predictions. 
 Good probabilistic predictions are calibrated. 
 Therefore, we want calibrated predictions. 
  
The “Therefore” step misses the fact that calibration is a necessary b</p><p>4 0.1630365 <a title="5-tfidf-4" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and to 
prevent overfitting. Various notion of “function complexity” often 
arise: VC dimension, Rademacher complexity, comparison classes of 
experts, and program length are just a few.
 
The term “complexity” to me seems somehow misleading; the terms never 
capture something that meets my intuitive notion of complexity. The 
Bayesian notion clearly captures what’s going on. Functions aren’t 
“complex”– they’re just “surprising”: we assign to them low 
probability. Most (all?) complexity notions I know boil down 
to some (generally loose) bound on the prior probability of the function.
 
In a sense, “complexity” fundementally arises because probability 
distributions must sum to one. You can’t believe in all possibilities 
at the same time, or at least not equally. Rather you have to 
carefully spread the probability mass over the options you’d like to 
consider. Large complexity classes means that beliefs are spread 
thinly. In</p><p>5 0.16161557 <a title="5-tfidf-5" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>Introduction: I thought this was a very good NIPS with many excellent papers. The following are a few NIPS papers which I liked and I hope to study more carefully when I get the chance. The list is not exhaustive and in no particular order…
  
 Preconditioner Approximations for Probabilistic Graphical Models. 
Pradeeep Ravikumar and John Lafferty. 
I thought the use of preconditioner methods from solving linear systems in the context of approximate inference was novel and interesting. The results look good and I’d like to understand the limitations.
 
 Rodeo: Sparse nonparametric regression in high dimensions. 
John Lafferty and Larry Wasserman. 
A very interesting approach to feature selection in nonparametric regression from a frequentist framework. The use of lengthscale variables in each dimension reminds me a lot of  ‘Automatic Relevance Determination’ in Gaussian process regression — it would be interesting to compare Rodeo to ARD in GPs.
 
 Interpolating between types and tokens by estimating</p><p>6 0.1567149 <a title="5-tfidf-6" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>7 0.15013483 <a title="5-tfidf-7" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>8 0.13931176 <a title="5-tfidf-8" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>9 0.13572675 <a title="5-tfidf-9" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>10 0.13470075 <a title="5-tfidf-10" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>11 0.12812044 <a title="5-tfidf-11" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>12 0.11852598 <a title="5-tfidf-12" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>13 0.1039708 <a title="5-tfidf-13" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>14 0.087212659 <a title="5-tfidf-14" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>15 0.084933013 <a title="5-tfidf-15" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>16 0.084092587 <a title="5-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>17 0.081402868 <a title="5-tfidf-17" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>18 0.079260938 <a title="5-tfidf-18" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>19 0.074909851 <a title="5-tfidf-19" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>20 0.074311957 <a title="5-tfidf-20" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.144), (1, 0.095), (2, 0.02), (3, -0.004), (4, -0.035), (5, -0.03), (6, 0.018), (7, 0.055), (8, 0.147), (9, -0.087), (10, 0.014), (11, -0.044), (12, 0.062), (13, -0.118), (14, 0.055), (15, -0.076), (16, -0.179), (17, -0.03), (18, 0.117), (19, -0.003), (20, -0.098), (21, 0.116), (22, 0.118), (23, 0.135), (24, -0.031), (25, 0.035), (26, -0.012), (27, -0.059), (28, -0.074), (29, 0.094), (30, 0.036), (31, 0.085), (32, -0.018), (33, -0.014), (34, -0.086), (35, 0.02), (36, -0.039), (37, 0.041), (38, 0.053), (39, 0.089), (40, -0.037), (41, -0.019), (42, -0.039), (43, 0.135), (44, 0.01), (45, 0.152), (46, 0.059), (47, 0.022), (48, -0.12), (49, 0.189)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98110473 <a title="5-lsi-1" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.  There are at least 3 distinct ways the word is used. 
  
  Bayesian  The Bayesian notion of probability is a ‘degree of belief’.   The degree of belief that some event (i.e. “stock goes up” or “stock goes down”) occurs can be measured by asking a sequence of questions of the form “Would you bet the stock goes up or down at  Y  to 1 odds?” A consistent better will switch from ‘for’ to ‘against’ at some single value of  Y .  The probability is then  Y/(Y+1) .  Bayesian probabilities express lack of knowledge rather than randomization.  They are useful in learning because we often lack knowledge and expressing that lack flexibly makes the learning algorithms work better.  Bayesian Learning uses ‘probability’ in this way exclusively. 
  Frequentist  The Frequentist notion of probability is a rate of occurence.  A rate of occurrence can be measured by doing an experiment many times.  If an event occurs  k  times in</p><p>2 0.75535142 <a title="5-lsi-2" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>Introduction: A calibrated predictor is one which predicts the probability of a binary event with the property: For all predictions  p , the proportion of the time that  1  is observed is  p .
 
Since there are infinitely many  p , this definition must be “softened” to make sense for any finite number of samples.  The standard method for “softening” is to consider all predictions in a small neighborhood about each possible  p .
 
A great deal of effort has been devoted to strategies for achieving calibrated (such as  here ) prediction.  With statements like: (under minimal conditions) you can always make calibrated predictions.  
 
Given the strength of these statements, we might conclude we are done, but that would be a “confusion of ends”.  A confusion of ends arises in the following way:
  
 We want good probabilistic predictions. 
 Good probabilistic predictions are calibrated. 
 Therefore, we want calibrated predictions. 
  
The “Therefore” step misses the fact that calibration is a necessary b</p><p>3 0.73403347 <a title="5-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>Introduction: Sam Roweis ‘s comment reminds me of a more general issue that comes up in doing research: abstractions always break.  
  
 Real number’s aren’t.  Most real numbers can not be represented with any machine.  One implication of this is that many real-number based algorithms have difficulties when implemented with floating point numbers. 
 The box on your desk is not a turing machine. A turing machine can compute anything computable, given sufficient time.  A typical computer fails terribly when the state required for the computation exceeds some limit. 
 Nash equilibria aren’t equilibria.  This comes up when trying to predict human behavior based on the result of the equilibria computation.  Often, it doesn’t work. 
 The  probability  isn’t.  Probability is an abstraction expressing either our lack of knowledge (the Bayesian viewpoint) or fundamental randomization (the frequentist viewpoint).  From the frequentist viewpoint the lack of knowledge typically precludes actually knowing the fu</p><p>4 0.7321524 <a title="5-lsi-4" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and to 
prevent overfitting. Various notion of “function complexity” often 
arise: VC dimension, Rademacher complexity, comparison classes of 
experts, and program length are just a few.
 
The term “complexity” to me seems somehow misleading; the terms never 
capture something that meets my intuitive notion of complexity. The 
Bayesian notion clearly captures what’s going on. Functions aren’t 
“complex”– they’re just “surprising”: we assign to them low 
probability. Most (all?) complexity notions I know boil down 
to some (generally loose) bound on the prior probability of the function.
 
In a sense, “complexity” fundementally arises because probability 
distributions must sum to one. You can’t believe in all possibilities 
at the same time, or at least not equally. Rather you have to 
carefully spread the probability mass over the options you’d like to 
consider. Large complexity classes means that beliefs are spread 
thinly. In</p><p>5 0.62204212 <a title="5-lsi-5" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>Introduction: Many decision problems can be represented in the form 
FOR  n =1,2,…: 
— Reality chooses a datum  x n  . 
— Decision Maker chooses his decision  d n  . 
— Reality chooses an observation  y n  . 
— Decision Maker suffers loss   L ( y n  , d n  ). 
END FOR. 
The observation  y n   can be, for example, tomorrow’s stock price and the decision  d n   the number of shares Decision Maker chooses to buy.  The datum  x n   ideally contains all information that might be relevant in making this decision.  We do not want to assume anything about the way Reality generates the observations and data.
 
Suppose there is a good and not too complex decision rule  D  mapping each datum  x  to a decision  D ( x ).  Can we perform as well, or almost as well, as  D , without knowing it?  This is essentially a special case of the problem of  on-line learning .
 
This is a simple result of this kind.  Suppose the data  x n   are taken from [0,1] and  L ( y , d )=| y – d |.  A norm || h || of a function  h  on</p><p>6 0.58302975 <a title="5-lsi-6" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>7 0.58109385 <a title="5-lsi-7" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>8 0.55303824 <a title="5-lsi-8" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>9 0.53830951 <a title="5-lsi-9" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>10 0.5273369 <a title="5-lsi-10" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>11 0.47251076 <a title="5-lsi-11" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>12 0.46442753 <a title="5-lsi-12" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>13 0.46183863 <a title="5-lsi-13" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>14 0.45455033 <a title="5-lsi-14" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>15 0.44432926 <a title="5-lsi-15" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>16 0.4350701 <a title="5-lsi-16" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>17 0.43475404 <a title="5-lsi-17" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>18 0.40972137 <a title="5-lsi-18" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>19 0.40419224 <a title="5-lsi-19" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>20 0.39891955 <a title="5-lsi-20" href="../hunch_net-2006/hunch_net-2006-09-07-Objective_and_subjective_interpretations_of_probability.html">205 hunch net-2006-09-07-Objective and subjective interpretations of probability</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.022), (3, 0.052), (10, 0.049), (27, 0.202), (52, 0.275), (53, 0.069), (55, 0.104), (94, 0.094), (95, 0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.88349575 <a title="5-lda-1" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>Introduction: In reinforcement learning (and sometimes other settings), there is a notion of “state”.   Based upon the state various predictions are made such as “Which action should be taken next?” or “How much cumulative reward do I expect if I take some action from this state?”  Given the importance of state, it is important to examine the meaning.   There are actually several distinct options and it turns out the definition variation is very important in motivating different pieces of work.
  
 Newtonian State.  State is the physical pose of the world.  Under this definition, there are  very  many states, often too many for explicit representation.  This is also the definition typically used in games. 
 Abstracted State.  State is an abstracted physical state of the world.  “Is the door open or closed?” “Are you in room A or not?” The number of states is much smaller here.  A basic issue here is: “How do you compute the state from observations?” 
 Mathematical State.  State is a sufficient stati</p><p>same-blog 2 0.83268732 <a title="5-lda-2" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.  There are at least 3 distinct ways the word is used. 
  
  Bayesian  The Bayesian notion of probability is a ‘degree of belief’.   The degree of belief that some event (i.e. “stock goes up” or “stock goes down”) occurs can be measured by asking a sequence of questions of the form “Would you bet the stock goes up or down at  Y  to 1 odds?” A consistent better will switch from ‘for’ to ‘against’ at some single value of  Y .  The probability is then  Y/(Y+1) .  Bayesian probabilities express lack of knowledge rather than randomization.  They are useful in learning because we often lack knowledge and expressing that lack flexibly makes the learning algorithms work better.  Bayesian Learning uses ‘probability’ in this way exclusively. 
  Frequentist  The Frequentist notion of probability is a rate of occurence.  A rate of occurrence can be measured by doing an experiment many times.  If an event occurs  k  times in</p><p>3 0.73408514 <a title="5-lda-3" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>Introduction: Urs Hoelzle  from  Google  gave an invited presentation at  NIPS .  In the presentation, he strongly advocates interacting with data in a particular scalable manner which is something like the following:
  
 Make a cluster of machines. 
 Build a unified filesystem.  (Google uses GFS, but NFS or other approaches work reasonably well for smaller clusters.) 
 Interact with data via  MapReduce . 
  
Creating a cluster of machines is, by this point, relatively straightforward.  
 
Unified filesystems are a little bit tricky—GFS is capable by design of essentially unlimited speed throughput to disk.  NFS can bottleneck because all of the data has to move through one machine.  Nevertheless,  this may not be a limiting factor for smaller clusters.
 
MapReduce is a programming paradigm.  Essentially, it is a combination of a data element transform (map) and an agreggator/selector (reduce).  These operations are highly parallelizable and the claim is that they support the forms of data interacti</p><p>4 0.66334814 <a title="5-lda-4" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question is “how”?
 
Reviewing is done by paper writers just like yourself, so a good proxy for this question is asking “How can I be a better reviewer?”  Here are a few things I’ve learned by trial (and error), as a paper writer, and as a reviewer.
  
 The secret ingredient is careful thought.  There is no good substitution for a deep and careful understanding. 
 Avoid reviewing papers that you feel competitive about.  You almost certainly will be asked to review papers that feel competitive if you work on subjects of common interest.  But, the feeling of competition can easily lead to bad judgement. 
 If you feel biased for some other reason, then you should avoid reviewing.  For example… 
 Feeling angry or threatened by a paper is a form of bias.  See above. 
 Double blind yourself (avoid looking at the name even in a single-blind situation).  The significant effect of a name you recognize is making you pay close a</p><p>5 0.66225868 <a title="5-lda-5" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some conception of what good reviewing is.  As far as I can tell, this is almost always only discussed in the specific context of a paper (i.e. your rejected paper), or at most an area (i.e. what a “good paper” looks like for that area) rather than general principles.  Neither individual papers or areas are sufficiently general for a large conference—every paper differs in the details, and what if you want to build a new area and/or cross areas?
 
An unavoidable reason for reviewing is that the community of research is too large.  In particular, it is not possible for a researcher to read every paper which someone thinks might be of interest.  This reason for reviewing exists independent of constraints on rooms or scheduling formats of individual conferences.  Indeed, history suggests that physical constraints are relatively meaningless over the long term — growing conferences simply use more rooms and/or change fo</p><p>6 0.66205764 <a title="5-lda-6" href="../hunch_net-2005/hunch_net-2005-07-21-Six_Months.html">96 hunch net-2005-07-21-Six Months</a></p>
<p>7 0.66041273 <a title="5-lda-7" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>8 0.66035157 <a title="5-lda-8" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>9 0.66023535 <a title="5-lda-9" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>10 0.6599375 <a title="5-lda-10" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>11 0.65725166 <a title="5-lda-11" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>12 0.65689582 <a title="5-lda-12" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>13 0.65647691 <a title="5-lda-13" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>14 0.65312225 <a title="5-lda-14" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>15 0.65257174 <a title="5-lda-15" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>16 0.65092397 <a title="5-lda-16" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>17 0.65071911 <a title="5-lda-17" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>18 0.65035552 <a title="5-lda-18" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>19 0.64996225 <a title="5-lda-19" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>20 0.64920646 <a title="5-lda-20" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
