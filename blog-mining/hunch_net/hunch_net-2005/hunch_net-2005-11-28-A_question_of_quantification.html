<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>133 hunch net-2005-11-28-A question of quantification</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-133" href="#">hunch_net-2005-133</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>133 hunch net-2005-11-28-A question of quantification</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-133-html" href="http://hunch.net/?p=143">html</a></p><p>Introduction: This is about methods for phrasing and think about the scope of some theorems
in learning theory. The basic claim is that there are several different ways
of quantifying the scope which sound different yet are essentially the
same.For all sequences of examples. This is the standard quantification in
online learning analysis. Standard theorems would say something like "for all
sequences of predictions by experts, the algorithm A will perform almost as
well as the best expert."For all training sets. This is the standard
quantification for boosting analysis such asadaboostormulticlass
boosting.Standard theorems have the form "for all training sets the error rate
inequalities … hold".For all distributions over examples. This is the one that
we have been using for reductions analysis. Standard theorem statements have
the form "For all distributions over examples, the error rate inequalities …
hold".It is not quite true that each of these is equivalent. For example, in
the online learning se</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This is about methods for phrasing and think about the scope of some theorems in learning theory. [sent-1, score-0.488]
</p><p>2 The basic claim is that there are several different ways of quantifying the scope which sound different yet are essentially the same. [sent-2, score-0.375]
</p><p>3 This is the standard quantification in online learning analysis. [sent-4, score-0.486]
</p><p>4 Standard theorems would say something like "for all sequences of predictions by experts, the algorithm A will perform almost as well as the best expert. [sent-5, score-0.551]
</p><p>5 This is the standard quantification for boosting analysis such asadaboostormulticlass boosting. [sent-7, score-0.507]
</p><p>6 Standard theorems have the form "for all training sets the error rate inequalities … hold". [sent-8, score-0.848]
</p><p>7 Standard theorem statements have the form "For all distributions over examples, the error rate inequalities … hold". [sent-11, score-0.994]
</p><p>8 For example, in the online learning setting, quantifying "for all sequences of examples" implies "for all distributions over examples", but not vice-versa. [sent-13, score-0.984]
</p><p>9 However, in the context of either boosting or reductions these are equivalent because the algorithms operate in an element-wise fashion. [sent-14, score-0.382]
</p><p>10 To see the equivalence, note that:"For any training set" is equivalent to "For any sequence of examples" because a training set is a sequence and vice versa. [sent-15, score-1.028]
</p><p>11 "For any sequence of examples" is equivalent to "For any distribution over examples" when the theorems are about unconditional example transformations because:The uniform distribution over a sufficiently long sequence of examples can approximate any distribution we care about arbitrarily well. [sent-16, score-1.876]
</p><p>12 If the theorem holds "for all distributions", it holds for the uniform distribution over the elements in any sequence of examples. [sent-17, score-0.827]
</p><p>13 The natural debate here is "how should the theorems be quantified? [sent-18, score-0.347]
</p><p>14 " It is difficult to answer this debate based upon mathematical grounds because we just showed an equivalence. [sent-19, score-0.244]
</p><p>15 It is nevertheless important because it strongly influences how we think about algorithms and how easy it is to integrate the knowledge across different theories. [sent-20, score-0.263]
</p><p>16 Learning theory people (at least) are used to thinking about "For all sequences of examples". [sent-23, score-0.321]
</p><p>17 When the algorithm is example-conditional such as in online learning, the quantification is more general than "for all distributions". [sent-25, score-0.36]
</p><p>18 For example, a version of the adaboost theorem also applies totest setsusing thetesterror rates of the base classifiers. [sent-29, score-0.288]
</p><p>19 Distributions over examples is simply how most people think about learning problems. [sent-32, score-0.338]
</p><p>20 "For all distributions over examples" is easily and often confused with "For all distributions over examples accessed by IID draws". [sent-33, score-1.226]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('distributions', 0.444), ('sequences', 0.321), ('quantification', 0.281), ('examples', 0.271), ('theorems', 0.23), ('sequence', 0.227), ('training', 0.181), ('inequalities', 0.181), ('equivalent', 0.142), ('distribution', 0.141), ('quantifying', 0.14), ('standard', 0.126), ('theorem', 0.117), ('debate', 0.117), ('holds', 0.114), ('uniform', 0.114), ('scope', 0.111), ('hold', 0.106), ('boosting', 0.1), ('reductions', 0.082), ('draws', 0.08), ('misleadingly', 0.08), ('phrasing', 0.08), ('online', 0.079), ('form', 0.077), ('transformations', 0.07), ('equivalence', 0.07), ('adaboost', 0.07), ('influences', 0.07), ('vice', 0.07), ('think', 0.067), ('confused', 0.067), ('grounds', 0.067), ('confusion', 0.064), ('arbitrarily', 0.064), ('integrate', 0.064), ('error', 0.064), ('different', 0.062), ('rate', 0.062), ('showed', 0.06), ('operate', 0.058), ('thanks', 0.058), ('arguments', 0.055), ('encounter', 0.054), ('approximate', 0.054), ('sufficiently', 0.054), ('sets', 0.053), ('applies', 0.052), ('statements', 0.049), ('rates', 0.049)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="133-tfidf-1" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>Introduction: This is about methods for phrasing and think about the scope of some theorems
in learning theory. The basic claim is that there are several different ways
of quantifying the scope which sound different yet are essentially the
same.For all sequences of examples. This is the standard quantification in
online learning analysis. Standard theorems would say something like "for all
sequences of predictions by experts, the algorithm A will perform almost as
well as the best expert."For all training sets. This is the standard
quantification for boosting analysis such asadaboostormulticlass
boosting.Standard theorems have the form "for all training sets the error rate
inequalities … hold".For all distributions over examples. This is the one that
we have been using for reductions analysis. Standard theorem statements have
the form "For all distributions over examples, the error rate inequalities …
hold".It is not quite true that each of these is equivalent. For example, in
the online learning se</p><p>2 0.18961401 <a title="133-tfidf-2" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provostgave a talk at the ICMLmetalearning workshopon "metalearning"
and the "no free lunch theorem" which seems worth summarizing.As a review: the
no free lunch theorem is the most complicated way we know of to say that
abiasis required in order to learn. The simplest way to see this is in a
nonprobabilistic setting. If you are given examples of the form(x,y)and you
wish to predictyfromxthen any prediction mechanism errs half the time in
expectation over all sequences of examples. The proof of this is very simple:
on every example a predictor must make some prediction and by symmetry over
the set of sequences it will be wrong half the time and right half the time.
The basic idea of this proof has been applied to many other settings.The
simplistic interpretation of this theorem which many people jump to is
"machine learning is dead" since there can be no single learning algorithm
which can solve all learning problems. This is the wrong way to think about
it. In the real world, w</p><p>3 0.15731049 <a title="133-tfidf-3" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>Introduction: I'm offering a reward of $1000 for a solution to this problem. This joins
thecross validation problemwhich I'm offering a$500 rewardfor. I believe both
of these problems are hard but plausibly solvable, and plausibly with a
solution of substantial practical value. While it's unlikely these rewards are
worth your time on an hourly wage basis, the recognition for solving them
definitely should beThe ProblemThe problem is finding a general, robust, and
efficient mechanism for estimating a conditional probabilityP(y|x)where
robustness and efficiency are measured using techniques from learning
reductions.In particular, suppose we have access to a binary regression
oracleBwhich has two interfaces--one for specifying training information and
one for testing. Training information is specified asB(x',y')wherex'is a
feature vector andy'is a scalar in[0,1]with no value returned. Testing is done
according toB(x')with a value in[0,1]returned.A learning reduction consists of
two algorithmsRandR-1whi</p><p>4 0.13616538 <a title="133-tfidf-4" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>Introduction: TheExponentiated Gradientalgorithm byManfred WarmuthandJyrki Kivinencame out
just as I was starting graduate school, so I missed it both at a conference
and in class. It's a fine algorithm which has a remarkable theoretical
statement accompanying it.The essential statement holds in the "online
learning with an adversary" setting. Initially, there are of set ofnweights,
which might have values(1/n,â&euro;Ś,1/n), (or any other values from a probability
distribution). Everything happens in a round-by-round fashion. On each round,
the following happens:The world reveals a set of featuresx in {0,1}n. In the
online learning with an adversary literature, the features are called
"experts" and thought of as subpredictors, but this interpretation isn't
necessary--you can just use feature values as experts (or maybe the feature
value and the negation of the feature value as two experts).EG makes a
prediction according toy' = w . x(dot product).The world reveals the truthy in
[0,1].EG updates the weights</p><p>5 0.1350078 <a title="133-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?Reductions are machines which turn solvers for one problem into solvers
for another problem.Why?Reductions are useful for several reasons.Laziness.
Reducing a problem to classification make at least 10 learning algorithms
available to solve a problem. Inventing 10 learning algorithms is quite a bit
of work. Similarly, programming a reduction is often trivial, while
programming a learning algorithm is a great deal of work.Crystallization. The
problems we often want to solve in learning are worst-case-impossible, but
average case feasible. By reducing all problems onto one or a few primitives,
we can fine tune these primitives to perform well on real-world problems with
greater precision due to the greater number of problems to validate
on.Theoretical Organization. By studying what reductions are easy vs. hard vs.
impossible, we can learn which problems are roughly equivalent in difficulty
and which are much harder.What we know now.Typesafe reductions. In the
beginning, there was th</p><p>6 0.13290201 <a title="133-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>7 0.11142848 <a title="133-tfidf-7" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>8 0.10667667 <a title="133-tfidf-8" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>9 0.10408522 <a title="133-tfidf-9" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>10 0.1039368 <a title="133-tfidf-10" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>11 0.10294783 <a title="133-tfidf-11" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>12 0.099570535 <a title="133-tfidf-12" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>13 0.097193286 <a title="133-tfidf-13" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>14 0.097156145 <a title="133-tfidf-14" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>15 0.096569903 <a title="133-tfidf-15" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>16 0.09084814 <a title="133-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>17 0.089962423 <a title="133-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>18 0.089667261 <a title="133-tfidf-18" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>19 0.08681754 <a title="133-tfidf-19" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>20 0.084636644 <a title="133-tfidf-20" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.191), (1, -0.143), (2, -0.063), (3, -0.013), (4, -0.04), (5, -0.05), (6, -0.008), (7, 0.003), (8, -0.015), (9, -0.023), (10, 0.007), (11, -0.071), (12, -0.054), (13, -0.059), (14, -0.074), (15, 0.04), (16, 0.002), (17, -0.059), (18, -0.035), (19, 0.021), (20, -0.004), (21, 0.001), (22, 0.014), (23, -0.022), (24, 0.02), (25, -0.059), (26, 0.029), (27, 0.011), (28, -0.048), (29, -0.088), (30, -0.084), (31, -0.015), (32, -0.024), (33, -0.056), (34, -0.022), (35, -0.042), (36, 0.0), (37, -0.037), (38, 0.036), (39, 0.122), (40, -0.062), (41, 0.025), (42, 0.008), (43, -0.001), (44, -0.015), (45, -0.025), (46, -0.007), (47, 0.021), (48, 0.054), (49, 0.011)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95910299 <a title="133-lsi-1" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>Introduction: This is about methods for phrasing and think about the scope of some theorems
in learning theory. The basic claim is that there are several different ways
of quantifying the scope which sound different yet are essentially the
same.For all sequences of examples. This is the standard quantification in
online learning analysis. Standard theorems would say something like "for all
sequences of predictions by experts, the algorithm A will perform almost as
well as the best expert."For all training sets. This is the standard
quantification for boosting analysis such asadaboostormulticlass
boosting.Standard theorems have the form "for all training sets the error rate
inequalities … hold".For all distributions over examples. This is the one that
we have been using for reductions analysis. Standard theorem statements have
the form "For all distributions over examples, the error rate inequalities …
hold".It is not quite true that each of these is equivalent. For example, in
the online learning se</p><p>2 0.73535109 <a title="133-lsi-2" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provostgave a talk at the ICMLmetalearning workshopon "metalearning"
and the "no free lunch theorem" which seems worth summarizing.As a review: the
no free lunch theorem is the most complicated way we know of to say that
abiasis required in order to learn. The simplest way to see this is in a
nonprobabilistic setting. If you are given examples of the form(x,y)and you
wish to predictyfromxthen any prediction mechanism errs half the time in
expectation over all sequences of examples. The proof of this is very simple:
on every example a predictor must make some prediction and by symmetry over
the set of sequences it will be wrong half the time and right half the time.
The basic idea of this proof has been applied to many other settings.The
simplistic interpretation of this theorem which many people jump to is
"machine learning is dead" since there can be no single learning algorithm
which can solve all learning problems. This is the wrong way to think about
it. In the real world, w</p><p>3 0.6789887 <a title="133-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these
suggest that some method of saying "I prefer this predictor to that predictor"
is useful and necessary. Examples include Bayesian reasoning, prediction
bounds, and online learning. One difficulty which arises is that the manner
and meaning of saying "I prefer this predictor to that predictor"
differs.Prior(Bayesian) A prior is a probability distribution over a set of
distributions which expresses a belief in the probability that some
distribution is the distribution generating the data."Prior"(Prediction bounds
& online learning) The "prior" is a measure over a set of classifiers which
expresses the degree to which you hope the classifier will predict
well.Bias(Regularization, Early termination of neural network training, etcâ&euro;Ś)
The bias is some (often implicitly specified by an algorithm) way of
preferring one predictor to another.This only scratches the surface--there are
yet more subtleties. For example the (as</p><p>4 0.67340124 <a title="133-lsi-4" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>Introduction: TheExponentiated Gradientalgorithm byManfred WarmuthandJyrki Kivinencame out
just as I was starting graduate school, so I missed it both at a conference
and in class. It's a fine algorithm which has a remarkable theoretical
statement accompanying it.The essential statement holds in the "online
learning with an adversary" setting. Initially, there are of set ofnweights,
which might have values(1/n,â&euro;Ś,1/n), (or any other values from a probability
distribution). Everything happens in a round-by-round fashion. On each round,
the following happens:The world reveals a set of featuresx in {0,1}n. In the
online learning with an adversary literature, the features are called
"experts" and thought of as subpredictors, but this interpretation isn't
necessary--you can just use feature values as experts (or maybe the feature
value and the negation of the feature value as two experts).EG makes a
prediction according toy' = w . x(dot product).The world reveals the truthy in
[0,1].EG updates the weights</p><p>5 0.67226154 <a title="133-lsi-5" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>Introduction: Textbooks invariably seem to carry the proof that uses Markov's inequality,
moment-generating functions, and Taylor approximations. Here's an easier
way.For, letbe the KL divergence between a coin of biasand one of
bias:Theorem:Suppose you doindependent tosses of a coin of bias. The
probability of seeingheads or more, for, is at most. So is the probability of
seeingheads or less, for.Remark:By Pinsker's inequality,.ProofLet's do
thecase; the other is identical.Letbe the distribution overinduced by a coin
of bias, and likewisefor a coin of bias. Letbe the set of all sequences
oftosses which containheads or more. We'd like to show thatis unlikely
under.Pick any, with sayheads. Then:Sincefor every, we haveand we're done.</p><p>6 0.66408825 <a title="133-lsi-6" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>7 0.66103697 <a title="133-lsi-7" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>8 0.64322394 <a title="133-lsi-8" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>9 0.63981903 <a title="133-lsi-9" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>10 0.63878036 <a title="133-lsi-10" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>11 0.63460743 <a title="133-lsi-11" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>12 0.63430971 <a title="133-lsi-12" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>13 0.63395798 <a title="133-lsi-13" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>14 0.62624878 <a title="133-lsi-14" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>15 0.60803795 <a title="133-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>16 0.60467625 <a title="133-lsi-16" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>17 0.60269201 <a title="133-lsi-17" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>18 0.60257459 <a title="133-lsi-18" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>19 0.59132832 <a title="133-lsi-19" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>20 0.58332825 <a title="133-lsi-20" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.092), (38, 0.025), (42, 0.322), (68, 0.088), (69, 0.024), (74, 0.043), (76, 0.014), (98, 0.278)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95332742 <a title="133-lda-1" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>Introduction: This post is about a trick that I learned fromDale Schuurmanswhich has been
repeatedly useful for me over time.The basic trick has to do with importance
weighting for monte carlo integration. Consider the problem of finding:N = Ex
~ Df(x)given samples fromDand knowledge off.Often, we don't have samples
fromDavailable. Instead, we must make do with samples from some other
distributionQ. In that case, we can still often solve the problem, as long as
Q(x) isn't 0 when D(x) is nonzero, using the importance weighting formula:Ex ~
Qf(x) D(x)/Q(x)A basic question is: How many samples fromQare required in
order to estimateNto some precision? In general the convergence rate is not
bounded, becausef(x) D(x)/Q(x)is not bounded given the
assumptions.Nevertheless, there is one special valueQ(x) = f(x) D(x) / Nwhere
the sample complexity turns out to be1, which is typically substantially
better than the sample complexity of the original problem.This observation
underlies the motivation for voluntary</p><p>same-blog 2 0.92366707 <a title="133-lda-2" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>Introduction: This is about methods for phrasing and think about the scope of some theorems
in learning theory. The basic claim is that there are several different ways
of quantifying the scope which sound different yet are essentially the
same.For all sequences of examples. This is the standard quantification in
online learning analysis. Standard theorems would say something like "for all
sequences of predictions by experts, the algorithm A will perform almost as
well as the best expert."For all training sets. This is the standard
quantification for boosting analysis such asadaboostormulticlass
boosting.Standard theorems have the form "for all training sets the error rate
inequalities … hold".For all distributions over examples. This is the one that
we have been using for reductions analysis. Standard theorem statements have
the form "For all distributions over examples, the error rate inequalities …
hold".It is not quite true that each of these is equivalent. For example, in
the online learning se</p><p>3 0.91205847 <a title="133-lda-3" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>Introduction: Every year about now hundreds of applicants apply for a research/teaching job
with the timing governed by the university recruitment schedule. This time,
it's my turn--the hat's in the ring, I am a contender, etcâ&euro;Ś What I have heard
is that this year is good in both directions--both an increased supply and an
increased demand for machine learning expertise.I consider this post a bit of
an abuse as it is neither about general research nor machine learning. Please
forgive me this once.My hope is that I will learn about new places interested
in funding basic research--it's easy to imagine that I have overlooked
possibilities.I am not dogmatic about where I end up in any particular way.
Several earlier posts detail what I think of as a good research environment,
so I will avoid a repeat. A few more details seem important:Application. There
is often a tension between basic research and immediate application. This
tension is not as strong as might be expected in my case. As evidence, many of</p><p>4 0.87827134 <a title="133-lda-4" href="../hunch_net-2013/hunch_net-2013-11-21-Ben_Taskar_is_gone.html">491 hunch net-2013-11-21-Ben Taskar is gone</a></p>
<p>Introduction: I was not as personally close toBenasSam, but the level of tragedy is similar
and I can't help but be greatly saddened by the loss.Variousnewsstorieshave
coverage, but the synopsis is that he had a heart attack on Sunday and is
survived by his wife Anat and daughter Aviv. There is discussion of creating a
memorial fund for them, which I hope comes to fruition, and plan to contribute
to.I will remember Ben as someone who thought carefully and comprehensively
about new ways to do things, then fought hard and successfully for what he
believed in. It is an ideal we strive for, that Ben accomplished.Edit:
donationsgo here, and more information ishere.</p><p>5 0.86344522 <a title="133-lda-5" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>Introduction: A new direction of research seems to be arising in machine learning:
Interactive Machine Learning. This isn't a familiar term, although it does
include some familiar subjects.What is Interactive Machine Learning?The
fundamental requirement is (a) learning algorithms which interact with the
world and (b) learn.For our purposes, let's define learning as efficiently
competing with a large set of possible predictors. Examples include:Online
learning against an adversary (Avrim's Notes). The interaction is almost
trivial: the learning algorithm makes a prediction and then receives feedback.
The learning is choosing based upon the advice of many experts.Active
Learning. In active learning, the interaction is choosing which examples to
label, and the learning is choosing from amongst a large set of
hypotheses.Contextual Bandits. The interaction is choosing one of several
actions and learning only the value of the chosen action (weaker than active
learning feedback).More forms of interaction w</p><p>6 0.85670286 <a title="133-lda-6" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>7 0.79178798 <a title="133-lda-7" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>8 0.77477235 <a title="133-lda-8" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>9 0.77438986 <a title="133-lda-9" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>10 0.77230799 <a title="133-lda-10" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>11 0.76308966 <a title="133-lda-11" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>12 0.76210678 <a title="133-lda-12" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>13 0.76186693 <a title="133-lda-13" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>14 0.76077694 <a title="133-lda-14" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>15 0.76057357 <a title="133-lda-15" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>16 0.75992256 <a title="133-lda-16" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>17 0.75766909 <a title="133-lda-17" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>18 0.75757557 <a title="133-lda-18" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>19 0.75712395 <a title="133-lda-19" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>20 0.75619382 <a title="133-lda-20" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
