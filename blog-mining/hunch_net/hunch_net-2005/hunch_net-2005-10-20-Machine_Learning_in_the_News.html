<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>125 hunch net-2005-10-20-Machine Learning in the News</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-125" href="#">hunch_net-2005-125</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>125 hunch net-2005-10-20-Machine Learning in the News</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-125-html" href="http://hunch.net/?p=136">html</a></p><p>Introduction: The New York Times had a  short interview  about machine learning in datamining being used pervasively by the IRS and large corporations to predict who to audit and who to target for various marketing campaigns.  This is a big application area of machine learning.  It can be harmful (learning + databases = another way to invade privacy) or beneficial (as google demonstrates, better targeting of marketing campaigns is far less annoying).  This is yet more evidence that we can not rely upon “I’m just another fish in the school” logic for our expectations about treatment by government and large corporations.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The New York Times had a  short interview  about machine learning in datamining being used pervasively by the IRS and large corporations to predict who to audit and who to target for various marketing campaigns. [sent-1, score-1.905]
</p><p>2 This is a big application area of machine learning. [sent-2, score-0.313]
</p><p>3 It can be harmful (learning + databases = another way to invade privacy) or beneficial (as google demonstrates, better targeting of marketing campaigns is far less annoying). [sent-3, score-1.808]
</p><p>4 This is yet more evidence that we can not rely upon “I’m just another fish in the school” logic for our expectations about treatment by government and large corporations. [sent-4, score-1.259]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('corporations', 0.41), ('marketing', 0.41), ('demonstrates', 0.205), ('harmful', 0.205), ('interview', 0.205), ('target', 0.205), ('databases', 0.19), ('campaigns', 0.19), ('datamining', 0.19), ('annoying', 0.171), ('expectations', 0.171), ('treatment', 0.171), ('targeting', 0.164), ('beneficial', 0.158), ('government', 0.149), ('rely', 0.145), ('logic', 0.138), ('privacy', 0.133), ('school', 0.123), ('another', 0.122), ('google', 0.116), ('york', 0.113), ('upon', 0.108), ('times', 0.104), ('short', 0.097), ('large', 0.097), ('application', 0.094), ('evidence', 0.092), ('area', 0.084), ('far', 0.081), ('predict', 0.076), ('various', 0.075), ('big', 0.075), ('less', 0.069), ('yet', 0.066), ('machine', 0.06), ('used', 0.056), ('way', 0.052), ('better', 0.051), ('new', 0.036), ('learning', 0.024)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="125-tfidf-1" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>Introduction: The New York Times had a  short interview  about machine learning in datamining being used pervasively by the IRS and large corporations to predict who to audit and who to target for various marketing campaigns.  This is a big application area of machine learning.  It can be harmful (learning + databases = another way to invade privacy) or beneficial (as google demonstrates, better targeting of marketing campaigns is far less annoying).  This is yet more evidence that we can not rely upon “I’m just another fish in the school” logic for our expectations about treatment by government and large corporations.</p><p>2 0.096390948 <a title="125-tfidf-2" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>Introduction: This post is about a technology which could develop in the future.
 
Right now, a new drug might be tested by finding patients with some diagnosis and giving or not giving them a drug according to a secret randomization.  The outcome is observed, and if the average outcome for those treated is measurably better than the average outcome for those not treated, the drug might become a standard treatment.
 
Generalizing this, a filter  F  sorts people into two groups: those for treatment  A  and those not for treatment  B  based upon observations  x .  To measure the outcome, you randomize between treatment and nontreatment of group  A  and measure the relative performance of the treatment.
 
A problem often arises: in many cases the treated group does not do better than the nontreated group.  A basic question is: does this mean the treatment is bad?  With respect to the filter  F  it may mean that, but with respect to another filter  F’ , the treatment might be very effective.  For exampl</p><p>3 0.093376003 <a title="125-tfidf-3" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>Introduction: The  second Netflix prize is canceled  due to  privacy problems .  I continue to believe my original assessment of this paper, that the privacy break was somewhat overstated.  I still haven’t seen any serious privacy failures on the scale of the  AOL search log release .
 
I expect privacy concerns to continue to be a big issue when dealing with data releases by companies or governments.  The theory of maintaining privacy while using data is improving, but it is not yet in a state where the limits of what’s possible are clear let alone how to achieve these limits in a manner friendly to a prediction competition.</p><p>4 0.089444123 <a title="125-tfidf-4" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>Introduction: There were several papers that seemed fairly interesting at  KDD this year .  The ones that caught my attention are:
  
  Xin Jin , Mingyang Zhang,  Nan Zhang , and  Gautam Das ,  Versatile Publishing For Privacy Preservation .  This paper provides a conservative method for safely determining which data is publishable from any complete source of information (for example, a hospital) such that it does not violate privacy rules in a natural language.  It is not differentially private, so no external sources of join information can exist.  However, it is a mechanism for  publishing  data rather than (say) the output of a learning algorithm. 
  Arik Friedman   Assaf Schuster ,  Data Mining with Differential Privacy .  This paper shows how to create effective differentially private decision trees.  Progress in differentially private datamining is pretty impressive, as it was  defined in 2006 . 
 David Chan, Rong Ge, Ori Gershony,  Tim Hesterberg ,  Diane Lambert ,  Evaluating Online Ad Camp</p><p>5 0.069528386 <a title="125-tfidf-5" href="../hunch_net-2012/hunch_net-2012-03-24-David_Waltz.html">460 hunch net-2012-03-24-David Waltz</a></p>
<p>Introduction: has  died .   He lived a full life.  I know him personally as a founder of the  Center for Computational Learning Systems  and the  New York Machine Learning Symposium , both of which have sheltered and promoted the advancement of machine learning.  I expect much of the New York area machine learning community will miss him, as well as many others around the world.</p><p>6 0.069248423 <a title="125-tfidf-6" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>7 0.068836108 <a title="125-tfidf-7" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>8 0.067974344 <a title="125-tfidf-8" href="../hunch_net-2010/hunch_net-2010-09-21-Regretting_the_dead.html">411 hunch net-2010-09-21-Regretting the dead</a></p>
<p>9 0.056097008 <a title="125-tfidf-9" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>10 0.052452981 <a title="125-tfidf-10" href="../hunch_net-2005/hunch_net-2005-01-26-Summer_Schools.html">4 hunch net-2005-01-26-Summer Schools</a></p>
<p>11 0.050374255 <a title="125-tfidf-11" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<p>12 0.049694512 <a title="125-tfidf-12" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>13 0.049252637 <a title="125-tfidf-13" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>14 0.047934636 <a title="125-tfidf-14" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>15 0.047165532 <a title="125-tfidf-15" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>16 0.046703458 <a title="125-tfidf-16" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>17 0.042897537 <a title="125-tfidf-17" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>18 0.039693136 <a title="125-tfidf-18" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>19 0.039221328 <a title="125-tfidf-19" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>20 0.039080158 <a title="125-tfidf-20" href="../hunch_net-2012/hunch_net-2012-02-24-ICML%2B50%25.html">456 hunch net-2012-02-24-ICML+50%</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.079), (1, -0.017), (2, -0.049), (3, 0.029), (4, -0.022), (5, -0.013), (6, -0.025), (7, 0.032), (8, -0.036), (9, -0.063), (10, -0.018), (11, 0.026), (12, 0.027), (13, -0.009), (14, -0.062), (15, 0.007), (16, -0.024), (17, 0.03), (18, 0.049), (19, -0.008), (20, 0.012), (21, -0.025), (22, 0.007), (23, 0.033), (24, -0.112), (25, 0.002), (26, 0.006), (27, 0.078), (28, 0.046), (29, -0.041), (30, -0.032), (31, -0.02), (32, -0.042), (33, 0.033), (34, -0.02), (35, 0.025), (36, 0.022), (37, -0.016), (38, 0.024), (39, -0.025), (40, 0.064), (41, -0.03), (42, -0.024), (43, -0.035), (44, -0.027), (45, 0.026), (46, 0.028), (47, -0.029), (48, -0.048), (49, -0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9142009 <a title="125-lsi-1" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>Introduction: The New York Times had a  short interview  about machine learning in datamining being used pervasively by the IRS and large corporations to predict who to audit and who to target for various marketing campaigns.  This is a big application area of machine learning.  It can be harmful (learning + databases = another way to invade privacy) or beneficial (as google demonstrates, better targeting of marketing campaigns is far less annoying).  This is yet more evidence that we can not rely upon “I’m just another fish in the school” logic for our expectations about treatment by government and large corporations.</p><p>2 0.64499533 <a title="125-lsi-2" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>Introduction: Machine Learning is rising in importance because data is being collected for all sorts of tasks where it either wasn’t previously collected, or for tasks that did not previously exist.  While this is great for Machine Learning, it has a downside—the massive data collection which is so useful can also lead to substantial privacy problems.  
 
It’s important to understand that this is a much harder problem than many people appreciate.  The  AOL   data   release  is a good example.  To those doing machine learning, the following strategies might be obvious:
  
 Just delete any names or other obviously personally identifiable information.  The logic here seems to be “if I can’t easily find the person then no one can”.  That doesn’t work as demonstrated by the people who were found circumstantially from the AOL data. 
 … then just hash all the search terms!  The logic here is “if I can’t read it, then no one can”.  It’s also trivially broken by a dictionary attack—just hash all the strings</p><p>3 0.54647833 <a title="125-lsi-3" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>Introduction: The  second Netflix prize is canceled  due to  privacy problems .  I continue to believe my original assessment of this paper, that the privacy break was somewhat overstated.  I still haven’t seen any serious privacy failures on the scale of the  AOL search log release .
 
I expect privacy concerns to continue to be a big issue when dealing with data releases by companies or governments.  The theory of maintaining privacy while using data is improving, but it is not yet in a state where the limits of what’s possible are clear let alone how to achieve these limits in a manner friendly to a prediction competition.</p><p>4 0.54033381 <a title="125-lsi-4" href="../hunch_net-2012/hunch_net-2012-10-26-ML_Symposium_and_Strata-Hadoop_World.html">475 hunch net-2012-10-26-ML Symposium and Strata-Hadoop World</a></p>
<p>Introduction: The  New York ML symposium  was last Friday.  There were 303 registrations, up a bit from  last year .  I particularly enjoyed talks by  Bill Freeman  on vision and ML,  Jon Lenchner  on strategy in Jeopardy, and  Tara N. Sainath  and Brian Kingsbury on  deep learning for speech recognition .  If anyone has suggestions or thoughts for next year, please speak up.
 
I also attended  Strata + Hadoop World  for the first time.  This is primarily a trade conference rather than an academic conference, but I found it pretty interesting as a first time attendee.  This is ground zero for the  Big data  buzzword, and I see now why.  It’s about data, and the word “big” is so ambiguous that everyone can lay claim to it.  There were essentially zero academic talks.  Instead, the focus was on war stories, product announcements, and education.  The general level of education is much lower—explaining Machine Learning to the SQL educated is the primary operating point.  Nevertheless that’s happening, a</p><p>5 0.52071053 <a title="125-lsi-5" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>Introduction: I want to comment on the “Bing copies Google” discussion  here ,  here , and  here , because there are data-related issues which the general public may not understand, and some of the framing seems substantially misleading to me.
 
As a not-distant-outsider, let me mention the sources of bias I may have.  I work at  Yahoo! , which has started using  Bing .  This might predispose me towards Bing, but on the other hand I’m still at Yahoo!, and have been using  Linux  exclusively as an OS for many years, including even a couple minor kernel patches.  And,  on the gripping hand , I’ve spent quite a bit of time thinking about the basic  principles of incorporating user feedback in machine learning .  Also note, this post is not  related to official Yahoo! policy, it’s just my personal view.
 
 The issue  Google engineers inserted synthetic responses to synthetic queries on google.com, then executed the synthetic searches on google.com using Internet Explorer with the Bing toolbar and later</p><p>6 0.50702357 <a title="125-lsi-6" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>7 0.49047682 <a title="125-lsi-7" href="../hunch_net-2006/hunch_net-2006-04-09-Progress_in_Machine_Translation.html">171 hunch net-2006-04-09-Progress in Machine Translation</a></p>
<p>8 0.48704582 <a title="125-lsi-8" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>9 0.47623208 <a title="125-lsi-9" href="../hunch_net-2010/hunch_net-2010-10-28-NY_ML_Symposium_2010.html">415 hunch net-2010-10-28-NY ML Symposium 2010</a></p>
<p>10 0.47188783 <a title="125-lsi-10" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<p>11 0.46718454 <a title="125-lsi-11" href="../hunch_net-2010/hunch_net-2010-09-21-Regretting_the_dead.html">411 hunch net-2010-09-21-Regretting the dead</a></p>
<p>12 0.4664762 <a title="125-lsi-12" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>13 0.46625108 <a title="125-lsi-13" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>14 0.46440423 <a title="125-lsi-14" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>15 0.45452616 <a title="125-lsi-15" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>16 0.43524408 <a title="125-lsi-16" href="../hunch_net-2012/hunch_net-2012-03-24-David_Waltz.html">460 hunch net-2012-03-24-David Waltz</a></p>
<p>17 0.41986811 <a title="125-lsi-17" href="../hunch_net-2012/hunch_net-2012-02-20-Berkeley_Streaming_Data_Workshop.html">455 hunch net-2012-02-20-Berkeley Streaming Data Workshop</a></p>
<p>18 0.41862354 <a title="125-lsi-18" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>19 0.41857123 <a title="125-lsi-19" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>20 0.41665977 <a title="125-lsi-20" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.049), (38, 0.779), (94, 0.022)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96709025 <a title="125-lda-1" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>Introduction: The New York Times had a  short interview  about machine learning in datamining being used pervasively by the IRS and large corporations to predict who to audit and who to target for various marketing campaigns.  This is a big application area of machine learning.  It can be harmful (learning + databases = another way to invade privacy) or beneficial (as google demonstrates, better targeting of marketing campaigns is far less annoying).  This is yet more evidence that we can not rely upon “I’m just another fish in the school” logic for our expectations about treatment by government and large corporations.</p><p>2 0.91746873 <a title="125-lda-2" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>Introduction: Manik  and I are organizing the  extreme classification  workshop at NIPS this year.  We have a number of good speakers lined up, but I would further encourage anyone working in the area to submit an abstract by October 9.  I believe this is an idea whose time has now come.
 
The NIPS website doesnâ&euro;&trade;t have other workshops listed yet, but I expect several others to be of significant interest.</p><p>3 0.88776189 <a title="125-lda-3" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>Introduction: Yahoo released the  Key Scientific Challenges  program.  There is a  Machine Learning  list I worked on and a  Statistics  list which  Deepak  worked on.
 
I’m hoping this is taken quite seriously by graduate students.  The primary value, is that it gave us a chance to sit down and publicly specify directions of research which would be valuable to make progress on.  A good strategy for a beginning graduate student is to pick one of these directions, pursue it, and make substantial advances for a PhD.  The directions are sufficiently general that I’m sure any serious advance has applications well beyond Yahoo.
 
A secondary point, (which I’m sure is primary for many    ) is that there is money for graduate students here.  It’s unrestricted, so you can use it for any reasonable travel, supplies, etc…</p><p>4 0.84480524 <a title="125-lda-4" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>Introduction: This post is about an open problem in learning reductions.
 
 Background  A reduction might transform a a multiclass prediction problem where there are  k  possible labels into a binary learning problem where there are only 2 possible labels.   On this induced binary problem we might learn a binary classifier with some error rate  e .  After subtracting the minimum possible (Bayes) error rate  b , we get a regret  r = e – b .  The  PECOC (Probabilistic Error Correcting Output Code) reduction has the property that binary regret  r  implies multiclass regret at most  4r 0.5  .
 
 The problem  This is not the “rightest” answer.  Consider the  k=2  case, where we reduce binary to binary.  There exists a reduction (the identity) with the property that regret  r  implies regret  r .  This is substantially superior to the transform given by the PECOC reduction, which suggests that a better reduction may exist for general  k .  For example, we can not rule out the possibility that a reduction</p><p>5 0.83492619 <a title="125-lda-5" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductions  transform a solver of one type of learning problem into a solver of another type of learning problem.  When we analyze these for robustness we can make statement of the form “Reduction  R  has the property that regret  r  (or loss) on subproblems of type  A  implies regret at most   f ( r )  on the original problem of type  B “.
 
A lower bound for a learning reduction would have the form “for all reductions  R , there exists a learning problem of type  B  and learning algorithm for problems of type  A  where regret  r  on induced problems implies  at least  regret  f ( r )  for  B “.
 
The pursuit of lower bounds is often questionable because, unlike upper bounds, they do not yield practical algorithms.  Nevertheless, they may be helpful as a tool for thinking about what is learnable and how learnable it is.  This has already come up  here  and  here .
 
At the moment, there is no coherent theory of lower bounds for learning reductions, and we have little understa</p><p>6 0.78306961 <a title="125-lda-6" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>7 0.67269313 <a title="125-lda-7" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>8 0.662678 <a title="125-lda-8" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>9 0.61800015 <a title="125-lda-9" href="../hunch_net-2008/hunch_net-2008-01-18-Datasets.html">284 hunch net-2008-01-18-Datasets</a></p>
<p>10 0.61351597 <a title="125-lda-10" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>11 0.60429466 <a title="125-lda-11" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>12 0.59603125 <a title="125-lda-12" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>13 0.48612747 <a title="125-lda-13" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>14 0.42596897 <a title="125-lda-14" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>15 0.3903752 <a title="125-lda-15" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>16 0.38710085 <a title="125-lda-16" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>17 0.36582097 <a title="125-lda-17" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>18 0.36122549 <a title="125-lda-18" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>19 0.34542128 <a title="125-lda-19" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>20 0.3449696 <a title="125-lda-20" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
