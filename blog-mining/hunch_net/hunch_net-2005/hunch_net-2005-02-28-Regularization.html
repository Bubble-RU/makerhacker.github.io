<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>33 hunch net-2005-02-28-Regularization</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-33" href="#">hunch_net-2005-33</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>33 hunch net-2005-02-28-Regularization</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-33-html" href="http://hunch.net/?p=36">html</a></p><p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('regularizer', 0.519), ('regularization', 0.277), ('complexity', 0.269), ('thatf', 0.259), ('empirically', 0.134), ('solving', 0.129), ('measure', 0.122), ('notion', 0.119), ('shortcut', 0.115), ('smoothness', 0.115), ('empirical', 0.111), ('yaroslav', 0.107), ('constantcsuch', 0.107), ('infinity', 0.107), ('minimizes', 0.107), ('numerous', 0.107), ('regarded', 0.107), ('convexity', 0.101), ('convincingly', 0.101), ('tuning', 0.101)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="33-tfidf-1" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>2 0.15874112 <a title="33-tfidf-2" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and toprevent
overfitting. Various notion of "function complexity" oftenarise: VC dimension,
Rademacher complexity, comparison classes ofexperts, and program length are
just a few.The term "complexity" to me seems somehow misleading; the terms
nevercapture something that meets my intuitive notion of complexity.
TheBayesian notion clearly captures what's going on. Functions
aren't"complex"- they're just "surprising": we assign to them lowprobability.
Most (all?) complexity notions I know boil downto some (generally loose) bound
on the prior probability of the function.In a sense, "complexity"
fundementally arises because probabilitydistributions must sum to one. You
can't believe in all possibilitiesat the same time, or at least not equally.
Rather you have tocarefully spread the probability mass over the options you'd
like toconsider. Large complexity classes means that beliefs are spreadthinly.
In it's simplest form, this phenom</p><p>3 0.15723863 <a title="33-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>4 0.13313101 <a title="33-tfidf-4" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these
suggest that some method of saying "I prefer this predictor to that predictor"
is useful and necessary. Examples include Bayesian reasoning, prediction
bounds, and online learning. One difficulty which arises is that the manner
and meaning of saying "I prefer this predictor to that predictor"
differs.Prior(Bayesian) A prior is a probability distribution over a set of
distributions which expresses a belief in the probability that some
distribution is the distribution generating the data."Prior"(Prediction bounds
& online learning) The "prior" is a measure over a set of classifiers which
expresses the degree to which you hope the classifier will predict
well.Bias(Regularization, Early termination of neural network training, etcâ&euro;Ś)
The bias is some (often implicitly specified by an algorithm) way of
preferring one predictor to another.This only scratches the surface--there are
yet more subtleties. For example the (as</p><p>5 0.12046134 <a title="33-tfidf-5" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>Introduction: Given John's recent posts on CMU's new machine learning department and "Deep
Learning," I asked for an opportunity to give a computational learning theory
perspective on these issues.To my mind, the answer to the question "Are the
core problems from machine learning different from the core problems of
statistics?" is a clear Yes. The point of this post is to describe a core
problem in machine learning that is computational in nature and will appeal to
statistical learning folk (as an extreme example note that if P=NP- which, for
all we know, is true- then we would suddenly find almost all of our favorite
machine learning problems considerably more tractable).If the central question
of statistical learning theory were crudely summarized as "given a hypothesis
with a certain loss bound over a test set, how well will it generalize?" then
the central question of computational learning theory might be "how can we
find such a hypothesis efficently (e.g., in polynomial-time)?"With this in
min</p><p>6 0.11026118 <a title="33-tfidf-6" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>7 0.099902041 <a title="33-tfidf-7" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>8 0.09754952 <a title="33-tfidf-8" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>9 0.095707066 <a title="33-tfidf-9" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>10 0.095322534 <a title="33-tfidf-10" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>11 0.094853126 <a title="33-tfidf-11" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>12 0.093808949 <a title="33-tfidf-12" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>13 0.092703946 <a title="33-tfidf-13" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>14 0.087859504 <a title="33-tfidf-14" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>15 0.087462425 <a title="33-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>16 0.086285166 <a title="33-tfidf-16" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>17 0.086280078 <a title="33-tfidf-17" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>18 0.083444104 <a title="33-tfidf-18" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>19 0.082638331 <a title="33-tfidf-19" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>20 0.082243674 <a title="33-tfidf-20" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.192), (1, -0.129), (2, -0.041), (3, -0.017), (4, -0.017), (5, -0.074), (6, -0.048), (7, 0.013), (8, 0.039), (9, 0.004), (10, -0.051), (11, -0.028), (12, -0.064), (13, -0.071), (14, -0.034), (15, -0.016), (16, -0.001), (17, 0.03), (18, 0.039), (19, -0.017), (20, -0.03), (21, 0.017), (22, -0.063), (23, -0.062), (24, 0.032), (25, -0.013), (26, 0.005), (27, -0.09), (28, -0.086), (29, -0.027), (30, -0.041), (31, 0.0), (32, -0.033), (33, -0.082), (34, 0.087), (35, 0.026), (36, -0.086), (37, -0.091), (38, 0.007), (39, -0.089), (40, 0.029), (41, 0.019), (42, -0.01), (43, -0.047), (44, -0.021), (45, -0.04), (46, 0.002), (47, -0.11), (48, 0.05), (49, 0.008)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95350838 <a title="33-lsi-1" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>2 0.7504034 <a title="33-lsi-2" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and toprevent
overfitting. Various notion of "function complexity" oftenarise: VC dimension,
Rademacher complexity, comparison classes ofexperts, and program length are
just a few.The term "complexity" to me seems somehow misleading; the terms
nevercapture something that meets my intuitive notion of complexity.
TheBayesian notion clearly captures what's going on. Functions
aren't"complex"- they're just "surprising": we assign to them lowprobability.
Most (all?) complexity notions I know boil downto some (generally loose) bound
on the prior probability of the function.In a sense, "complexity"
fundementally arises because probabilitydistributions must sum to one. You
can't believe in all possibilitiesat the same time, or at least not equally.
Rather you have tocarefully spread the probability mass over the options you'd
like toconsider. Large complexity classes means that beliefs are spreadthinly.
In it's simplest form, this phenom</p><p>3 0.72259265 <a title="33-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>4 0.66380709 <a title="33-lsi-4" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these
suggest that some method of saying "I prefer this predictor to that predictor"
is useful and necessary. Examples include Bayesian reasoning, prediction
bounds, and online learning. One difficulty which arises is that the manner
and meaning of saying "I prefer this predictor to that predictor"
differs.Prior(Bayesian) A prior is a probability distribution over a set of
distributions which expresses a belief in the probability that some
distribution is the distribution generating the data."Prior"(Prediction bounds
& online learning) The "prior" is a measure over a set of classifiers which
expresses the degree to which you hope the classifier will predict
well.Bias(Regularization, Early termination of neural network training, etcâ&euro;Ś)
The bias is some (often implicitly specified by an algorithm) way of
preferring one predictor to another.This only scratches the surface--there are
yet more subtleties. For example the (as</p><p>5 0.65055227 <a title="33-lsi-5" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>Introduction: This post is about a trick that I learned fromDale Schuurmanswhich has been
repeatedly useful for me over time.The basic trick has to do with importance
weighting for monte carlo integration. Consider the problem of finding:N = Ex
~ Df(x)given samples fromDand knowledge off.Often, we don't have samples
fromDavailable. Instead, we must make do with samples from some other
distributionQ. In that case, we can still often solve the problem, as long as
Q(x) isn't 0 when D(x) is nonzero, using the importance weighting formula:Ex ~
Qf(x) D(x)/Q(x)A basic question is: How many samples fromQare required in
order to estimateNto some precision? In general the convergence rate is not
bounded, becausef(x) D(x)/Q(x)is not bounded given the
assumptions.Nevertheless, there is one special valueQ(x) = f(x) D(x) / Nwhere
the sample complexity turns out to be1, which is typically substantially
better than the sample complexity of the original problem.This observation
underlies the motivation for voluntary</p><p>6 0.63806289 <a title="33-lsi-6" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>7 0.62936103 <a title="33-lsi-7" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>8 0.62932587 <a title="33-lsi-8" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>9 0.6152665 <a title="33-lsi-9" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>10 0.57009542 <a title="33-lsi-10" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>11 0.55918109 <a title="33-lsi-11" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>12 0.54943216 <a title="33-lsi-12" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>13 0.54061919 <a title="33-lsi-13" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>14 0.53657848 <a title="33-lsi-14" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>15 0.53209144 <a title="33-lsi-15" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>16 0.52708447 <a title="33-lsi-16" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>17 0.52601612 <a title="33-lsi-17" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>18 0.51738125 <a title="33-lsi-18" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>19 0.51286685 <a title="33-lsi-19" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>20 0.50836408 <a title="33-lsi-20" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.066), (42, 0.277), (55, 0.016), (68, 0.084), (69, 0.048), (74, 0.082), (76, 0.035), (88, 0.035), (94, 0.256)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93113369 <a title="33-lda-1" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>Introduction: Dan Reevesintroduced me toMichael Vassarwho ran theSingularity Summitand
educated me a bit on the subject of AI safety which theSingularity
Institutehassmall grants for.I still believe thatinterstellar space travel is
necessary for long term civilization survival, and the AI is necessary for
interstellar space travel. On these grounds alone, we could judge that
developing AI is much more safe than not. Nevertheless, there is a basic
reasonable fear, as expressed by some commenters, that AI could go bad.A basic
scenario starts with someone inventing an AI and telling it to make as much
money as possible. The AI promptly starts trading in various markets to make
money. To improve, it crafts a virus that takes over most of the world's
computers using it as a surveillance network so that it can always make the
right decision. The AI also branches out into any form of distance work,
taking over the entire outsourcing process for all jobs that are entirely
digital. To further improve, the AI</p><p>same-blog 2 0.89339399 <a title="33-lda-2" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>3 0.89141989 <a title="33-lda-3" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>Introduction: This is near the one month point, so it seems appropriate to consider meta-
issues for the moment.The number of posts is a bit over 20.The number of
people speaking up in discussions is about 10.The number of people viewing the
site is somewhat more than 100.I am (naturally) dissatisfied with many
things.Many of thepotential useshaven't been realized. This is partly a matter
of opportunity (no conferences in the last month), partly a matter of will (no
open problems because it's hard to give them up), and partly a matter of
tradition. In academia, there is a strong tradition of trying to get
everything perfectly right before presentation. This is somewhat contradictory
to the nature of making many posts, and it's definitely contradictory to the
idea of doing "public research". If that sort of idea is to pay off, it must
be significantly more succesful than previous methods. In an effort to
continue experimenting, I'm going to use the next week as "open problems
week".Spam is a problem.</p><p>4 0.748465 <a title="33-lda-4" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>Introduction: "Overfitting" is traditionally defined as training some flexible
representation so that it memorizes the data but fails to predict well in the
future. For this post, I will define overfitting more generally as over-
representing the performance of systems. There are two styles of general
overfitting: overrepresenting performance on particular datasets and
(implicitly) overrepresenting performance of a method on future datasets.We
should all be aware of these methods, avoid them where possible, and take them
into account otherwise. I have used "reproblem" and "old datasets", and may
have participated in "overfitting by review"--some of these are very difficult
to avoid.NameMethodExplanationRemedyTraditional overfittingTrain a complex
predictor on too-few examples.Hold out pristine examples for testing.Use a
simpler predictor.Get more training examples.Integrate over many
predictors.Reject papers which do this.Parameter tweak overfittingUse a
learning algorithm with many parameters. Choo</p><p>5 0.74790293 <a title="33-lda-5" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>Introduction: Many learning algorithms used in practice are fairly simple. Viewed
representationally, many prediction algorithms either compute a linear
separator of basic features (perceptron, winnow, weighted majority, SVM) or
perhaps a linear separator of slightly more complex features (2-layer neural
networks or kernelized SVMs). Should we go beyond this, and start using "deep"
representations?What is deep learning?Intuitively, deep learning is about
learning to predict in ways which can involve complex dependencies between the
input (observed) features.Specifying this more rigorously turns out to be
rather difficult. Consider the following cases:SVM with Gaussian Kernel. This
is not considered deep learning, because an SVM with a gaussian kernel can't
succinctly represent certain decision surfaces. One ofYann LeCun's examples is
recognizing objects based on pixel values. An SVM will need a new support
vector for each significantly different background. Since the number of
distinct backgrounds i</p><p>6 0.74726528 <a title="33-lda-6" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>7 0.74675494 <a title="33-lda-7" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>8 0.74529833 <a title="33-lda-8" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>9 0.74497133 <a title="33-lda-9" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>10 0.7441684 <a title="33-lda-10" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>11 0.74405742 <a title="33-lda-11" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>12 0.74319154 <a title="33-lda-12" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>13 0.74258643 <a title="33-lda-13" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>14 0.74137074 <a title="33-lda-14" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>15 0.74058115 <a title="33-lda-15" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>16 0.74023241 <a title="33-lda-16" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>17 0.74017531 <a title="33-lda-17" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>18 0.74003321 <a title="33-lda-18" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>19 0.73921835 <a title="33-lda-19" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>20 0.73780519 <a title="33-lda-20" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
