<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>119 hunch net-2005-10-08-We have a winner</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-119" href="#">hunch_net-2005-119</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>119 hunch net-2005-10-08-We have a winner</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-119-html" href="http://hunch.net/?p=130">html</a></p><p>Introduction: The DARPA grandchallenge is a big contest for autonomous robot vehicle
driving. It was run once in 2004 for the first time and all teams did badly.
This year was notably different with theStanfordandCMUteams succesfully
completing the course. A number of details arehereandwikipedia has continuing
coverage.A formal winner hasn't been declared yet although Stanford completed
the course quickest.The Stanford and CMU teams deserve a large round of
applause as they have strongly demonstrated the feasibility of autonomous
vehicles.The good news for machine learning is that the Stanford team (at
least) is using some machine learning techniques.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The DARPA grandchallenge is a big contest for autonomous robot vehicle driving. [sent-1, score-0.866]
</p><p>2 It was run once in 2004 for the first time and all teams did badly. [sent-2, score-0.444]
</p><p>3 This year was notably different with theStanfordandCMUteams succesfully completing the course. [sent-3, score-0.537]
</p><p>4 A formal winner hasn't been declared yet although Stanford completed the course quickest. [sent-5, score-0.773]
</p><p>5 The Stanford and CMU teams deserve a large round of applause as they have strongly demonstrated the feasibility of autonomous vehicles. [sent-6, score-1.373]
</p><p>6 The good news for machine learning is that the Stanford team (at least) is using some machine learning techniques. [sent-7, score-0.464]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('stanford', 0.567), ('autonomous', 0.378), ('teams', 0.293), ('completing', 0.168), ('completed', 0.168), ('declared', 0.168), ('deserve', 0.168), ('vehicle', 0.168), ('darpa', 0.147), ('continuing', 0.147), ('feasibility', 0.147), ('team', 0.147), ('succesfully', 0.14), ('cmu', 0.14), ('robot', 0.134), ('notably', 0.134), ('demonstrated', 0.13), ('formal', 0.13), ('round', 0.126), ('contest', 0.122), ('winner', 0.116), ('news', 0.099), ('strongly', 0.089), ('course', 0.077), ('details', 0.076), ('run', 0.072), ('techniques', 0.072), ('big', 0.064), ('although', 0.06), ('least', 0.056), ('yet', 0.054), ('machine', 0.052), ('year', 0.052), ('first', 0.044), ('different', 0.043), ('using', 0.043), ('large', 0.042), ('number', 0.041), ('time', 0.035), ('good', 0.027), ('learning', 0.022)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="119-tfidf-1" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>Introduction: The DARPA grandchallenge is a big contest for autonomous robot vehicle
driving. It was run once in 2004 for the first time and all teams did badly.
This year was notably different with theStanfordandCMUteams succesfully
completing the course. A number of details arehereandwikipedia has continuing
coverage.A formal winner hasn't been declared yet although Stanford completed
the course quickest.The Stanford and CMU teams deserve a large round of
applause as they have strongly demonstrated the feasibility of autonomous
vehicles.The good news for machine learning is that the Stanford team (at
least) is using some machine learning techniques.</p><p>2 0.0909703 <a title="119-tfidf-2" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>Introduction: The competitors for theNetflix Prizeare tantalizingly close winning the
million dollar prize. This year,BellKorandCommendo Researchsent a combined
solution that won theprogress prize. Reading thewriteups2is instructive.
Several aspects of solutions are taken for granted including stochastic
gradient descent, ensemble prediction, and targeting residuals (a form of
boosting). Relatively to last year, it appears that many approaches have added
parameterizations, especially for the purpose of modeling through time.The big
question is: will they make the big prize? At this point, the level of
complexity in entering the competition is prohibitive, so perhaps only the
existing competitors will continue to try. (This equation might change
drastically if the teams open source their existing solutions, including
parameter settings.) One fear is that the progress is asymptoting on the wrong
side of the 10% threshold. In the first year, the teams progressed through
84.3% of the 10% gap, and in the</p><p>3 0.088991567 <a title="119-tfidf-3" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended theNetflix prizeceremony this morning. The press conference part
iscovered fine elsewhere, with the basic outcome being thatBellKor's Pragmatic
Chaoswon overThe Ensembleby 15-20minutes, because they were tied in
performance on the ultimate holdout set. I'm sure the individual participants
will have many chances to speak about the solution. One of these is Bell at
theNYAS ML symposium on Nov. 6.Several additional details may interest ML
people.The degree of overfitting exhibited by the difference in performance on
theleaderboard test setand the ultimate hold out set was small, but
determining at .02 to .03%.A tie was possible, because the rules cut off
measurements below the fourth digit based on significance concerns. In
actuality, of course, the scores do differ before rounding, but everyone I
spoke to claimed not to know how. The complete dataset has beenreleased on
UCI, so each team could compute their own score to whatever accuracy desired.I
was impressed by the slick sy</p><p>4 0.088774405 <a title="119-tfidf-4" href="../hunch_net-2005/hunch_net-2005-04-22-New_Blog%3A_%5BLowerbounds%2CUpperbounds%5D.html">59 hunch net-2005-04-22-New Blog: [Lowerbounds,Upperbounds]</a></p>
<p>Introduction: Maverick Woo and the Aladdin group at CMU have started a CS theory-related
bloghere.</p><p>5 0.073058367 <a title="119-tfidf-5" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: TheHeritage Health Prizeis potentially the largest prediction prize yet at
$3M, which is sure to get many people interested. Several elements of the
competition may be worth discussing.The most straightforward way for HPN to
deploy this predictor is in determining who to cover with insurance. This
might easily cover the costs of running the contest itself, but the value to
the health system of a whole is minimal, as people not covered still exist.
While HPN itself is a provider network, they have active relationships with a
number of insurance companies, and the right to resell any entrant. It's worth
keeping in mind that the research and development may nevertheless end up
being useful in the longer term, especially as entrants also keep the right to
their code.Thejudging metricis something I haven't seen previously. If a
patient has probability 0.5 of being in the hospital 0 days and probability
0.5 of being in the hospital ~53.6 days, the optimal prediction in expectation
is ~6.4 da</p><p>6 0.070320867 <a title="119-tfidf-6" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>7 0.062055856 <a title="119-tfidf-7" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>8 0.054731093 <a title="119-tfidf-8" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>9 0.049572963 <a title="119-tfidf-9" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>10 0.045641966 <a title="119-tfidf-10" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>11 0.045338221 <a title="119-tfidf-11" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>12 0.044943385 <a title="119-tfidf-12" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>13 0.043332733 <a title="119-tfidf-13" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>14 0.042847268 <a title="119-tfidf-14" href="../hunch_net-2011/hunch_net-2011-03-20-KDD_Cup_2011.html">427 hunch net-2011-03-20-KDD Cup 2011</a></p>
<p>15 0.033359103 <a title="119-tfidf-15" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>16 0.032455351 <a title="119-tfidf-16" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>17 0.032393552 <a title="119-tfidf-17" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>18 0.030712776 <a title="119-tfidf-18" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>19 0.029574083 <a title="119-tfidf-19" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>20 0.02935335 <a title="119-tfidf-20" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.061), (1, 0.001), (2, 0.036), (3, 0.014), (4, 0.007), (5, 0.039), (6, 0.002), (7, 0.033), (8, 0.046), (9, -0.053), (10, -0.05), (11, -0.006), (12, -0.038), (13, -0.019), (14, 0.035), (15, 0.031), (16, -0.049), (17, 0.014), (18, -0.001), (19, -0.003), (20, -0.04), (21, 0.008), (22, 0.058), (23, 0.043), (24, -0.03), (25, 0.017), (26, 0.005), (27, 0.051), (28, -0.007), (29, 0.017), (30, 0.049), (31, 0.023), (32, 0.016), (33, -0.034), (34, 0.058), (35, -0.064), (36, -0.03), (37, -0.014), (38, -0.011), (39, -0.008), (40, -0.019), (41, -0.021), (42, 0.001), (43, 0.02), (44, 0.005), (45, -0.08), (46, -0.001), (47, -0.067), (48, 0.039), (49, -0.013)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.8688193 <a title="119-lsi-1" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>Introduction: The DARPA grandchallenge is a big contest for autonomous robot vehicle
driving. It was run once in 2004 for the first time and all teams did badly.
This year was notably different with theStanfordandCMUteams succesfully
completing the course. A number of details arehereandwikipedia has continuing
coverage.A formal winner hasn't been declared yet although Stanford completed
the course quickest.The Stanford and CMU teams deserve a large round of
applause as they have strongly demonstrated the feasibility of autonomous
vehicles.The good news for machine learning is that the Stanford team (at
least) is using some machine learning techniques.</p><p>2 0.59337193 <a title="119-lsi-2" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><p>3 0.56486678 <a title="119-lsi-3" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>Introduction: The competitors for theNetflix Prizeare tantalizingly close winning the
million dollar prize. This year,BellKorandCommendo Researchsent a combined
solution that won theprogress prize. Reading thewriteups2is instructive.
Several aspects of solutions are taken for granted including stochastic
gradient descent, ensemble prediction, and targeting residuals (a form of
boosting). Relatively to last year, it appears that many approaches have added
parameterizations, especially for the purpose of modeling through time.The big
question is: will they make the big prize? At this point, the level of
complexity in entering the competition is prohibitive, so perhaps only the
existing competitors will continue to try. (This equation might change
drastically if the teams open source their existing solutions, including
parameter settings.) One fear is that the progress is asymptoting on the wrong
side of the 10% threshold. In the first year, the teams progressed through
84.3% of the 10% gap, and in the</p><p>4 0.56110865 <a title="119-lsi-4" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: TheHeritage Health Prizeis potentially the largest prediction prize yet at
$3M, which is sure to get many people interested. Several elements of the
competition may be worth discussing.The most straightforward way for HPN to
deploy this predictor is in determining who to cover with insurance. This
might easily cover the costs of running the contest itself, but the value to
the health system of a whole is minimal, as people not covered still exist.
While HPN itself is a provider network, they have active relationships with a
number of insurance companies, and the right to resell any entrant. It's worth
keeping in mind that the research and development may nevertheless end up
being useful in the longer term, especially as entrants also keep the right to
their code.Thejudging metricis something I haven't seen previously. If a
patient has probability 0.5 of being in the hospital 0 days and probability
0.5 of being in the hospital ~53.6 days, the optimal prediction in expectation
is ~6.4 da</p><p>5 0.48605621 <a title="119-lsi-5" href="../hunch_net-2011/hunch_net-2011-03-20-KDD_Cup_2011.html">427 hunch net-2011-03-20-KDD Cup 2011</a></p>
<p>Introduction: Yehudapoints outKDD-Cup 2011whichMarkusandGideonhelped setup. This is a
prediction and recommendation contest for music. In addition to being a fun
chance to show your expertise, there are cash prizes of $5K/$2K/$1K.</p><p>6 0.47598684 <a title="119-lsi-6" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>7 0.454036 <a title="119-lsi-7" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>8 0.42352742 <a title="119-lsi-8" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>9 0.40964422 <a title="119-lsi-9" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>10 0.37114355 <a title="119-lsi-10" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>11 0.36738777 <a title="119-lsi-11" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>12 0.36100492 <a title="119-lsi-12" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>13 0.33270323 <a title="119-lsi-13" href="../hunch_net-2005/hunch_net-2005-04-22-New_Blog%3A_%5BLowerbounds%2CUpperbounds%5D.html">59 hunch net-2005-04-22-New Blog: [Lowerbounds,Upperbounds]</a></p>
<p>14 0.32754779 <a title="119-lsi-14" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>15 0.32595375 <a title="119-lsi-15" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>16 0.31936088 <a title="119-lsi-16" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>17 0.31821385 <a title="119-lsi-17" href="../hunch_net-2006/hunch_net-2006-02-07-Pittsburgh_Mind_Reading_Competition.html">155 hunch net-2006-02-07-Pittsburgh Mind Reading Competition</a></p>
<p>18 0.31790027 <a title="119-lsi-18" href="../hunch_net-2006/hunch_net-2006-05-16-The_value_of_the_orthodox_view_of_Boosting.html">179 hunch net-2006-05-16-The value of the orthodox view of Boosting</a></p>
<p>19 0.31618997 <a title="119-lsi-19" href="../hunch_net-2010/hunch_net-2010-10-28-NY_ML_Symposium_2010.html">415 hunch net-2010-10-28-NY ML Symposium 2010</a></p>
<p>20 0.3148573 <a title="119-lsi-20" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.103), (69, 0.703), (74, 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98704112 <a title="119-lda-1" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>Introduction: (Unofficially, at least.) TheDeep Learning Workshopis being held the afternoon
before the rest of the workshops in Vancouver, BC. Separate registration is
needed, and open.What's happening fundamentally here is that there are too
many interesting workshops to fit into 2 days. Perhaps we can get it
officially expanded to 3 days next year.</p><p>2 0.97164226 <a title="119-lda-2" href="../hunch_net-2006/hunch_net-2006-03-24-NLPers.html">166 hunch net-2006-03-24-NLPers</a></p>
<p>Introduction: Hal Daumehas started theNLPersblog to discuss learning for language problems.</p><p>same-blog 3 0.94963199 <a title="119-lda-3" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>Introduction: The DARPA grandchallenge is a big contest for autonomous robot vehicle
driving. It was run once in 2004 for the first time and all teams did badly.
This year was notably different with theStanfordandCMUteams succesfully
completing the course. A number of details arehereandwikipedia has continuing
coverage.A formal winner hasn't been declared yet although Stanford completed
the course quickest.The Stanford and CMU teams deserve a large round of
applause as they have strongly demonstrated the feasibility of autonomous
vehicles.The good news for machine learning is that the Stanford team (at
least) is using some machine learning techniques.</p><p>4 0.84636509 <a title="119-lda-4" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>Introduction: Registration for COLT 2007 is now open.The conference will take place on 13-15
June, 2007, in San Diego, California, as part of the 2007 Federated Computing
Research Conference (FCRC), which includes STOC, Complexity, and EC.The
website for COLT: http://www.learningtheory.org/colt2007/index.htmlThe early
registration deadline is May 11, and the cutoff date for discounted hotel
rates is May 9.Before registering, take note that the fees are substantially
lower for members of ACM and/or SIGACT than for nonmembers. If you've been
contemplating joining either of these two societies (annual dues: $99 for ACM,
$18 for SIGACT), now would be a good time!</p><p>5 0.83405918 <a title="119-lda-5" href="../hunch_net-2010/hunch_net-2010-08-24-Alex_Smola_starts_a_blog.html">408 hunch net-2010-08-24-Alex Smola starts a blog</a></p>
<p>Introduction: Adventures in Data Land.</p><p>6 0.7023955 <a title="119-lda-6" href="../hunch_net-2005/hunch_net-2005-07-10-Thinking_the_Unthought.html">91 hunch net-2005-07-10-Thinking the Unthought</a></p>
<p>7 0.63526303 <a title="119-lda-7" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>8 0.62983286 <a title="119-lda-8" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>9 0.56782299 <a title="119-lda-9" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>10 0.50398499 <a title="119-lda-10" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>11 0.40427929 <a title="119-lda-11" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>12 0.38729855 <a title="119-lda-12" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>13 0.34792772 <a title="119-lda-13" href="../hunch_net-2005/hunch_net-2005-08-01-Peekaboom.html">99 hunch net-2005-08-01-Peekaboom</a></p>
<p>14 0.33667099 <a title="119-lda-14" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>15 0.30270365 <a title="119-lda-15" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>16 0.29601157 <a title="119-lda-16" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>17 0.2711347 <a title="119-lda-17" href="../hunch_net-2011/hunch_net-2011-08-20-The_Large_Scale_Learning_Survey_Tutorial.html">442 hunch net-2011-08-20-The Large Scale Learning Survey Tutorial</a></p>
<p>18 0.26597193 <a title="119-lda-18" href="../hunch_net-2006/hunch_net-2006-03-27-Gradients_everywhere.html">167 hunch net-2006-03-27-Gradients everywhere</a></p>
<p>19 0.25945154 <a title="119-lda-19" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>20 0.25849268 <a title="119-lda-20" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
