<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>78 hunch net-2005-06-06-Exact Online Learning for Classification</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-78" href="#">hunch_net-2005-78</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>78 hunch net-2005-06-06-Exact Online Learning for Classification</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-78-html" href="http://hunch.net/?p=84">html</a></p><p>Introduction: Jacob Abernethy and I have found a computationally tractable method for
computing an optimal (or near optimal depending on setting) master algorithm
combining expert predictions addressingthis open problem. A draft ishere.The
effect of this improvement seems to be about a factor of2decrease in the
regret (= error rate minus best possible error rate) for the low error rate
situation. (At large error rates, there may be no significant
difference.)There are some unfinished details still to consider:When we remove
all of the approximation slack from online learning, is the result a
satisfying learning algorithm, in practice? I consider online learning is one
of the more compelling methods of analyzing and deriving algorithms, but that
expectation must be either met or not by this algorithmSome extra details: The
algorithm is optimal given a small amount of side information (kin the draft).
What is the best way to remove this side information? The removal is necessary
for a practical algori</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Jacob Abernethy and I have found a computationally tractable method for computing an optimal (or near optimal depending on setting) master algorithm combining expert predictions addressingthis open problem. [sent-1, score-1.84]
</p><p>2 The effect of this improvement seems to be about a factor of2decrease in the regret (= error rate minus best possible error rate) for the low error rate situation. [sent-3, score-2.033]
</p><p>3 (At large error rates, there may be no significant difference. [sent-4, score-0.369]
</p><p>4 )There are some unfinished details still to consider:When we remove all of the approximation slack from online learning, is the result a satisfying learning algorithm, in practice? [sent-5, score-1.13]
</p><p>5 I consider online learning is one of the more compelling methods of analyzing and deriving algorithms, but that expectation must be either met or not by this algorithmSome extra details: The algorithm is optimal given a small amount of side information (kin the draft). [sent-6, score-1.941]
</p><p>6 What is the best way to remove this side information? [sent-7, score-0.562]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('error', 0.293), ('draft', 0.284), ('optimal', 0.268), ('remove', 0.26), ('rate', 0.213), ('side', 0.197), ('removal', 0.184), ('unfinished', 0.184), ('combining', 0.17), ('details', 0.166), ('deriving', 0.161), ('minus', 0.153), ('met', 0.138), ('analyzing', 0.13), ('satisfying', 0.13), ('consider', 0.13), ('algorithm', 0.128), ('expert', 0.124), ('master', 0.124), ('online', 0.121), ('approximation', 0.117), ('expectation', 0.117), ('rates', 0.112), ('computing', 0.111), ('depending', 0.111), ('information', 0.11), ('tractable', 0.105), ('best', 0.105), ('compelling', 0.104), ('extra', 0.104), ('improvement', 0.101), ('factor', 0.101), ('predictions', 0.094), ('near', 0.092), ('computationally', 0.092), ('regret', 0.091), ('effect', 0.089), ('practical', 0.088), ('low', 0.088), ('practice', 0.087), ('necessary', 0.086), ('amount', 0.082), ('open', 0.08), ('either', 0.079), ('mechanism', 0.078), ('result', 0.076), ('still', 0.076), ('may', 0.076), ('method', 0.073), ('methods', 0.072)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999976 <a title="78-tfidf-1" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>Introduction: Jacob Abernethy and I have found a computationally tractable method for
computing an optimal (or near optimal depending on setting) master algorithm
combining expert predictions addressingthis open problem. A draft ishere.The
effect of this improvement seems to be about a factor of2decrease in the
regret (= error rate minus best possible error rate) for the low error rate
situation. (At large error rates, there may be no significant
difference.)There are some unfinished details still to consider:When we remove
all of the approximation slack from online learning, is the result a
satisfying learning algorithm, in practice? I consider online learning is one
of the more compelling methods of analyzing and deriving algorithms, but that
expectation must be either met or not by this algorithmSome extra details: The
algorithm is optimal given a small amount of side information (kin the draft).
What is the best way to remove this side information? The removal is necessary
for a practical algori</p><p>2 0.26981786 <a title="78-tfidf-2" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>Introduction: This post is about a reductions-related problem that I find mysterious. There
are two kinds of reductions analysis currently under consideration.Error
limiting reductions. Here, the goal is to bound the error rate of the created
classifier in terms of the error rate of the binary classifiers that you
reduce to. A very simple example of this is thaterror correcting output
codeswhere it is possible to prove that for certain codes, the multiclass
error rate is at most 4 * the binary classifier error rate.Regret minimizing
reductions. Here, the goal is to bound theregretof the created classifier in
terms of theregretof the binary classifiers reduced to. The regret is the
error rate minus the minimum error rate. When the learning problem is noisy
the minimum error rate may not be0. An analagous result for reget is that for
aprobabilistic error correcting output code, multiclass regret is at most 4 *
(binary regret)0.5.The use of "regret" is more desirable than the use of error
rates, becaus</p><p>3 0.1574481 <a title="78-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>4 0.15254632 <a title="78-tfidf-4" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem. When someone screws up, do you fire them?
Or do you accept the error and let them continue? This is a very difficult
problem and we all know of stories where the wrong decision was made.Online
learning(as meant here), is a subfield of learning theory which analyzes the
online learning model.In the online learning model, there are a set of
hypotheses or "experts". On any instantancex, each expert makes a predictiony.
A master algorithmAuses these predictions to form it's own predictionyAand
then learns the correct predictiony*. This process repeats.The goal of online
learning is to find a master algorithmAwhich uses the advice of the experts to
make good predictions. In particular, we typically want to guarantee that the
master algorithm performs almost as well as the best expert. IfL(e)is the loss
of experteandL(A)is the loss of the master algorithm, it is often possible to
prove:L(A) less than mineL(e) + log(number of experts)over all sequences.In
p</p><p>5 0.1291225 <a title="78-tfidf-5" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>Introduction: One thing which is clear on a little reflection is that there exists a single
master learning problem capable of encoding essentially all learning problems.
This problem is of course a very general sort of reinforcement learning where
the world interacts with an agent as:The world announces an observationx.The
agent makes a choicea.The world announces a rewardr.The goal here is to
maximize the sum of the rewards over the time of the agent. No particular
structure relatingxtoaoratoris implied by this setting so we do not know
effective general algorithms for the agent. It's very easy to prove lower
bounds showing that an agent cannot hope to succeed here--just consider the
case where actions are unrelated to rewards. Nevertheless, there is a real
sense in which essentially all forms of life are agents operating in this
setting, somehow succeeding. The gap between these observations drives
research--How can we find tractable specializations of the master problem
general enough to provide</p><p>6 0.12516658 <a title="78-tfidf-6" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>7 0.12367518 <a title="78-tfidf-7" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>8 0.10921806 <a title="78-tfidf-8" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>9 0.10846891 <a title="78-tfidf-9" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>10 0.10548779 <a title="78-tfidf-10" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>11 0.10503161 <a title="78-tfidf-11" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>12 0.10320543 <a title="78-tfidf-12" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>13 0.096603937 <a title="78-tfidf-13" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>14 0.096151024 <a title="78-tfidf-14" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>15 0.094345897 <a title="78-tfidf-15" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>16 0.091894224 <a title="78-tfidf-16" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>17 0.091319218 <a title="78-tfidf-17" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>18 0.091032684 <a title="78-tfidf-18" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>19 0.09052372 <a title="78-tfidf-19" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>20 0.089765735 <a title="78-tfidf-20" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.201), (1, -0.13), (2, -0.048), (3, 0.002), (4, -0.025), (5, -0.131), (6, 0.165), (7, 0.066), (8, 0.078), (9, 0.024), (10, 0.026), (11, -0.1), (12, -0.075), (13, -0.062), (14, -0.045), (15, -0.03), (16, -0.015), (17, 0.024), (18, -0.055), (19, 0.03), (20, -0.076), (21, -0.035), (22, 0.029), (23, -0.043), (24, 0.041), (25, -0.008), (26, 0.101), (27, -0.051), (28, 0.046), (29, -0.029), (30, 0.014), (31, -0.03), (32, 0.048), (33, -0.072), (34, -0.021), (35, -0.059), (36, -0.119), (37, -0.014), (38, -0.037), (39, -0.082), (40, -0.097), (41, 0.041), (42, 0.045), (43, -0.022), (44, 0.006), (45, 0.065), (46, 0.011), (47, -0.032), (48, -0.018), (49, 0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97478986 <a title="78-lsi-1" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>Introduction: Jacob Abernethy and I have found a computationally tractable method for
computing an optimal (or near optimal depending on setting) master algorithm
combining expert predictions addressingthis open problem. A draft ishere.The
effect of this improvement seems to be about a factor of2decrease in the
regret (= error rate minus best possible error rate) for the low error rate
situation. (At large error rates, there may be no significant
difference.)There are some unfinished details still to consider:When we remove
all of the approximation slack from online learning, is the result a
satisfying learning algorithm, in practice? I consider online learning is one
of the more compelling methods of analyzing and deriving algorithms, but that
expectation must be either met or not by this algorithmSome extra details: The
algorithm is optimal given a small amount of side information (kin the draft).
What is the best way to remove this side information? The removal is necessary
for a practical algori</p><p>2 0.74932873 <a title="78-lsi-2" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>Introduction: This post is about a reductions-related problem that I find mysterious. There
are two kinds of reductions analysis currently under consideration.Error
limiting reductions. Here, the goal is to bound the error rate of the created
classifier in terms of the error rate of the binary classifiers that you
reduce to. A very simple example of this is thaterror correcting output
codeswhere it is possible to prove that for certain codes, the multiclass
error rate is at most 4 * the binary classifier error rate.Regret minimizing
reductions. Here, the goal is to bound theregretof the created classifier in
terms of theregretof the binary classifiers reduced to. The regret is the
error rate minus the minimum error rate. When the learning problem is noisy
the minimum error rate may not be0. An analagous result for reget is that for
aprobabilistic error correcting output code, multiclass regret is at most 4 *
(binary regret)0.5.The use of "regret" is more desirable than the use of error
rates, becaus</p><p>3 0.6708805 <a title="78-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>4 0.63646489 <a title="78-lsi-4" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>Introduction: In the online learning with experts setting, you observe a set of predictions,
make a decision, and then observe the truth. This process repeats
indefinitely. In this setting, it is possible to prove theorems of the
sort:master algorithm error count < = k* best predictor error count +
c*log(number of predictors)Is this a statement about learning or about
preservation of learning? We did some experiments to analyze the newBinning
algorithmwhich works in this setting. For several UCI datasets, we reprocessed
them so that features could be used as predictors and then applied several
master algorithms. The first graph confirms that Binning is indeed a better
algorithm according to the tightness of the upper bound.Here, "Best" is the
performance of the best expert. "V. Bound" is the bound forVovk's algorithm
(the previous best). "Bound" is the bound for the Binning algorithm. "Binning"
is the performance of the Binning algorithm. The Binning algorithm clearly has
a tighter bound, and the pe</p><p>5 0.6301676 <a title="78-lsi-5" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>Introduction: Thisproblemhas been cracked (but not quite completely solved) byAlina,Pradeep,
andI. The problem is essentially finding a better way to reduce multiclass
classification to binary classification. The solution is to use a carefully
crafted tournament, the simplest version of which is asingle elimination
tournamentwhere the "players" are the different classes. An example of the
structure is here:For the single elimination tournament, we can prove that:For
all multiclass problemsD, for all learned binary classifiersc, the regret of
an induced multiclass classifier is bounded by the regret of the binary
classifier timeslog2k. Restated:regmulticlass(D,Filter_tree_test(c)) <=
regbinary(Filter_tree_train(D),c)Here:Filter_tree_train(D)is the induced
binary classification problemFilter_tree_test(c)is the induced multiclass
classifier.regmulticlassis the multiclass regret (= difference between error
rate and minimum possible error rate)regbinaryis the binary regretThis result
has a slight depende</p><p>6 0.62807685 <a title="78-lsi-6" href="../hunch_net-2006/hunch_net-2006-09-09-How_to_solve_an_NP_hard_problem_in_quadratic_time.html">206 hunch net-2006-09-09-How to solve an NP hard problem in quadratic time</a></p>
<p>7 0.58229589 <a title="78-lsi-7" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>8 0.56176454 <a title="78-lsi-8" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>9 0.55864739 <a title="78-lsi-9" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>10 0.55267221 <a title="78-lsi-10" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>11 0.54143393 <a title="78-lsi-11" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>12 0.53496087 <a title="78-lsi-12" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>13 0.5323143 <a title="78-lsi-13" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>14 0.52159542 <a title="78-lsi-14" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>15 0.5126999 <a title="78-lsi-15" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>16 0.50322229 <a title="78-lsi-16" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>17 0.50232202 <a title="78-lsi-17" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>18 0.49734592 <a title="78-lsi-18" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>19 0.48617423 <a title="78-lsi-19" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>20 0.48427105 <a title="78-lsi-20" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.029), (42, 0.295), (45, 0.025), (68, 0.1), (69, 0.064), (72, 0.247), (74, 0.047), (95, 0.078)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.91541129 <a title="78-lda-1" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>Introduction: Yahoo released theKey Scientific Challengesprogram. There is aMachine
Learninglist I worked on and aStatisticslist whichDeepakworked on.I'm hoping
this is taken quite seriously by graduate students. The primary value, is that
it gave us a chance to sit down and publicly specify directions of research
which would be valuable to make progress on. A good strategy for a beginning
graduate student is to pick one of these directions, pursue it, and make
substantial advances for a PhD. The directions are sufficiently general that
I'm sure any serious advance has applications well beyond Yahoo.A secondary
point, (which I'm sure is primary for many) is that there is money for
graduate students here. It's unrestricted, so you can use it for any
reasonable travel, supplies, etcâ&euro;Ś</p><p>same-blog 2 0.90444672 <a title="78-lda-2" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>Introduction: Jacob Abernethy and I have found a computationally tractable method for
computing an optimal (or near optimal depending on setting) master algorithm
combining expert predictions addressingthis open problem. A draft ishere.The
effect of this improvement seems to be about a factor of2decrease in the
regret (= error rate minus best possible error rate) for the low error rate
situation. (At large error rates, there may be no significant
difference.)There are some unfinished details still to consider:When we remove
all of the approximation slack from online learning, is the result a
satisfying learning algorithm, in practice? I consider online learning is one
of the more compelling methods of analyzing and deriving algorithms, but that
expectation must be either met or not by this algorithmSome extra details: The
algorithm is optimal given a small amount of side information (kin the draft).
What is the best way to remove this side information? The removal is necessary
for a practical algori</p><p>3 0.8892566 <a title="78-lda-3" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>Introduction: This is a summary of theworkshop on Learning Problem DesignwhichAlinaand I ran
atNIPSthis year.The first question many people have is "What is learning
problem design?" This workshop is about admitting that solving learning
problems does not start with labeled data, but rather somewhere before. When
humans are hired to produce labels, this is usually not a serious problem
because you can tell them precisely what semantics you want the labels to
have, and we can fix some set of features in advance. However, when other
methods are used this becomes more problematic. This focus is important for
Machine Learning because there are very large quantities of data which are not
labeled by a hired human.The title of the workshop was a bit ambitious,
because a workshop is not long enough to synthesize a diversity of approaches
into a coherent set of principles. For me, the posters at the end of the
workshop were quite helpful in getting approaches to gel.Here are some answers
to "where do the lab</p><p>4 0.76723295 <a title="78-lda-4" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>Introduction: How do we judge success in Machine Learning? AsAaronnotes, the best way is to
use the loss imposed on you by the world. This turns out to be infeasible
sometimes for various reasons. The ones I've seen are:The learned prediction
is used in some complicated process that does not give the feedback necessary
to understand the prediction's impact on the loss.The prediction is used by
some other system which expects some semantics to the predicted value. This is
similar to the previous example, except that the issue is design modularity
rather than engineering modularity.The correct loss function is simply unknown
(and perhaps unknowable, except by experimentation).In these situations, it's
unclear what metric for evaluation should be chosen. This post has some design
advice for this murkier case. I'm using the word "metric" here to distinguish
the fact that we are considering methods forevaluatingpredictive systems
rather than a loss imposed by the real world or a loss which is optimized b</p><p>5 0.76598299 <a title="78-lda-5" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>Introduction: I recently had fun discussions with bothVikash MansinghkaandThomas Breuelabout
approaching AI with machine learning. The general interest in taking a crack
at AI with machine learning seems to be rising on many fronts
includingDARPA.As a matter of history, there was a great deal of interest in
AI which died down before I began research. There remain many projects and
conferences spawned in this earlier AI wave, as well as a good bit of
experience about what did not work, or at least did not work yet. Here are a
few examples of failure modes that people seem to run into:Supply/Product
confusion. Sometimes we think "Intelligences use X, so I'll create X and have
an Intelligence." An example of this is theCyc Projectwhich inspires some
people as "intelligences use ontologies, so I'll create an ontology and a
system using it to have an Intelligence." The flaw here is that
Intelligencescreateontologies, which they use, and without the ability to
create ontologies you don't have an Intellige</p><p>6 0.7656126 <a title="78-lda-6" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>7 0.76387954 <a title="78-lda-7" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>8 0.76324588 <a title="78-lda-8" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>9 0.76202738 <a title="78-lda-9" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>10 0.76184952 <a title="78-lda-10" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>11 0.76093823 <a title="78-lda-11" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>12 0.76077837 <a title="78-lda-12" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>13 0.76002663 <a title="78-lda-13" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>14 0.7598998 <a title="78-lda-14" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>15 0.75935495 <a title="78-lda-15" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>16 0.7592178 <a title="78-lda-16" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>17 0.75921482 <a title="78-lda-17" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>18 0.75871366 <a title="78-lda-18" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>19 0.75828308 <a title="78-lda-19" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>20 0.75696194 <a title="78-lda-20" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
