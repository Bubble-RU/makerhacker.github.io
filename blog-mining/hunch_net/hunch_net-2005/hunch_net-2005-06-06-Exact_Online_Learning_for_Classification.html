<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>78 hunch net-2005-06-06-Exact Online Learning for Classification</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-78" href="#">hunch_net-2005-78</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>78 hunch net-2005-06-06-Exact Online Learning for Classification</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-78-html" href="http://hunch.net/?p=84">html</a></p><p>Introduction: Jacob Abernethy and I have found a computationally tractable method for computing an optimal (or near optimal depending on setting) master algorithm combining expert predictions addressing  this open problem .  A draft is  here .  
 
The effect of this improvement seems to be about a factor of  2  decrease in the regret (= error rate minus best possible error rate) for the low error rate situation.  (At large error rates, there may be no significant difference.)  
 
There are some unfinished details still to consider:
  
 When we remove all of the approximation slack from online learning, is the result a satisfying learning algorithm, in practice?  I consider online learning is one of the more compelling methods of analyzing and deriving algorithms, but that expectation must be either met or not by this algorithm 
 Some extra details: The algorithm is optimal given a small amount of side information ( k  in the draft).  What is the best way to remove this side information?  The removal</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Jacob Abernethy and I have found a computationally tractable method for computing an optimal (or near optimal depending on setting) master algorithm combining expert predictions addressing  this open problem . [sent-1, score-1.833]
</p><p>2 The effect of this improvement seems to be about a factor of  2  decrease in the regret (= error rate minus best possible error rate) for the low error rate situation. [sent-3, score-2.094]
</p><p>3 (At large error rates, there may be no significant difference. [sent-4, score-0.273]
</p><p>4 )     There are some unfinished details still to consider:     When we remove all of the approximation slack from online learning, is the result a satisfying learning algorithm, in practice? [sent-5, score-1.004]
</p><p>5 I consider online learning is one of the more compelling methods of analyzing and deriving algorithms, but that expectation must be either met or not by this algorithm   Some extra details: The algorithm is optimal given a small amount of side information ( k  in the draft). [sent-6, score-1.89]
</p><p>6 What is the best way to remove this side information? [sent-7, score-0.54]
</p><p>7 The removal is necessary for a practical algorithm. [sent-8, score-0.317]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('error', 0.273), ('optimal', 0.255), ('remove', 0.25), ('draft', 0.244), ('rate', 0.2), ('side', 0.189), ('decrease', 0.177), ('jacob', 0.177), ('unfinished', 0.177), ('algorithm', 0.158), ('details', 0.155), ('removal', 0.154), ('combining', 0.154), ('deriving', 0.154), ('minus', 0.147), ('infinity', 0.147), ('met', 0.125), ('addressing', 0.125), ('satisfying', 0.125), ('consider', 0.123), ('analyzing', 0.122), ('expert', 0.119), ('master', 0.119), ('online', 0.112), ('limit', 0.112), ('approximation', 0.112), ('expectation', 0.112), ('rates', 0.106), ('depending', 0.105), ('information', 0.104), ('computing', 0.103), ('tractable', 0.101), ('best', 0.101), ('compelling', 0.1), ('extra', 0.1), ('improvement', 0.097), ('factor', 0.097), ('predictions', 0.089), ('computationally', 0.088), ('near', 0.087), ('regret', 0.087), ('effect', 0.086), ('practical', 0.085), ('practice', 0.083), ('low', 0.083), ('necessary', 0.078), ('amount', 0.078), ('mechanism', 0.075), ('open', 0.075), ('result', 0.073)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="78-tfidf-1" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>Introduction: Jacob Abernethy and I have found a computationally tractable method for computing an optimal (or near optimal depending on setting) master algorithm combining expert predictions addressing  this open problem .  A draft is  here .  
 
The effect of this improvement seems to be about a factor of  2  decrease in the regret (= error rate minus best possible error rate) for the low error rate situation.  (At large error rates, there may be no significant difference.)  
 
There are some unfinished details still to consider:
  
 When we remove all of the approximation slack from online learning, is the result a satisfying learning algorithm, in practice?  I consider online learning is one of the more compelling methods of analyzing and deriving algorithms, but that expectation must be either met or not by this algorithm 
 Some extra details: The algorithm is optimal given a small amount of side information ( k  in the draft).  What is the best way to remove this side information?  The removal</p><p>2 0.26540032 <a title="78-tfidf-2" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>Introduction: This post is about a reductions-related problem that I find mysterious.  There are two kinds of reductions analysis currently under consideration.
  
 Error limiting reductions.  Here, the goal is to bound the error rate of the created classifier in terms of the error rate of the binary classifiers that you reduce to.  A very simple example of this is that  error correcting output codes  where it is possible to prove that for certain codes, the multiclass error rate is at most 4 * the binary classifier error rate. 
 Regret minimizing reductions.  Here, the goal is to bound the  regret  of the created classifier in terms of the  regret  of the binary classifiers reduced to.  The regret is the error rate minus the minimum error rate.  When the learning problem is noisy the minimum error rate may not be  0 .  An analagous result for reget is that for a  probabilistic error correcting output code , multiclass regret is at most 4 * (binary regret) 0.5 .  
  
The use of “regret” is more desi</p><p>3 0.20278485 <a title="78-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notation  g(n) = O(f(n))  means that in the limit as  n  approaches infinity there exists a constant  C  such that the  g(n)  is less than  Cf(n) .
 
In learning theory, there are many statements about learning algorithms of the form “under assumptions  x , y , and  z , the classifier learned has an error rate of at most  O(f(m)) “.
 
There is one very good reason to use O(): it helps you understand the big picture and neglect the minor details which are not important in the big picture.  However, there are some important reasons not to do this as well.
  
  Unspeedup  In algorithm analysis, the use of O() for time complexity is pervasive and well-justified.  Determining the exact value of C is inherently computer architecture dependent.  (The “C” for x86 processors might differ from the “C” on PowerPC processors.)  Since many learning theorists come from a CS theory background, the O() notation is applied to generalization error.  The O() abstraction breaks here—you can not genera</p><p>4 0.1604041 <a title="78-tfidf-4" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem.  When someone screws up, do you fire them?  Or do you accept the error and let them continue?  This is a very difficult problem and we all know of stories where the wrong decision was made.
 
 Online learning  (as meant here), is a subfield of learning theory which analyzes the online learning model.  
 
In the online learning model, there are a set of hypotheses or “experts”.  On any instantance  x , each expert makes a prediction  y .  A master algorithm  A  uses these predictions to form it’s own prediction  y A   and then  learns the correct prediction  y *  .  This process repeats.
 
The goal of online learning is to find a master algorithm  A  which uses the advice of the experts to make good predictions.  In particular, we typically want to guarantee that the master algorithm performs almost as well as the best expert.  If  L(e)  is the loss of expert  e  and  L(A)  is the loss of the master algorithm, it is often possible to prove:   L(A) les</p><p>5 0.15093061 <a title="78-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?  Reductions are machines which turn solvers for one problem into solvers for another problem. 
 Why?  Reductions are useful for several reasons.
  
  Laziness .  Reducing a problem to classification make at least 10 learning algorithms available to solve a problem.  Inventing 10 learning algorithms is quite a bit of work.  Similarly, programming a reduction is often trivial, while programming a learning algorithm is a great deal of work. 
  Crystallization .  The problems we often want to solve in learning are worst-case-impossible, but average case feasible.  By reducing all problems onto one or a few primitives, we can fine tune these primitives to perform well on real-world problems with greater precision due to the greater number of problems to validate on. 
  Theoretical Organization .  By studying what reductions are easy vs. hard vs. impossible, we can learn which problems are roughly equivalent in difficulty and which are much harder. 
  
 What we know now .
 
 Typesafe r</p><p>6 0.12456069 <a title="78-tfidf-6" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>7 0.12320711 <a title="78-tfidf-7" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>8 0.1209332 <a title="78-tfidf-8" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>9 0.11936478 <a title="78-tfidf-9" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>10 0.118642 <a title="78-tfidf-10" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>11 0.11245245 <a title="78-tfidf-11" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>12 0.10699689 <a title="78-tfidf-12" href="../hunch_net-2005/hunch_net-2005-04-06-Structured_Regret_Minimization.html">53 hunch net-2005-04-06-Structured Regret Minimization</a></p>
<p>13 0.10589548 <a title="78-tfidf-13" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>14 0.099240184 <a title="78-tfidf-14" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>15 0.098279253 <a title="78-tfidf-15" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>16 0.093929783 <a title="78-tfidf-16" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>17 0.091317087 <a title="78-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>18 0.090545006 <a title="78-tfidf-18" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>19 0.090478964 <a title="78-tfidf-19" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>20 0.089906111 <a title="78-tfidf-20" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.2), (1, 0.135), (2, 0.04), (3, -0.053), (4, 0.01), (5, -0.064), (6, 0.116), (7, -0.05), (8, -0.134), (9, 0.057), (10, -0.03), (11, 0.056), (12, 0.087), (13, -0.087), (14, 0.051), (15, 0.017), (16, -0.028), (17, -0.062), (18, 0.003), (19, 0.021), (20, -0.077), (21, -0.045), (22, 0.029), (23, 0.073), (24, 0.017), (25, -0.001), (26, 0.088), (27, -0.022), (28, 0.072), (29, -0.062), (30, -0.018), (31, 0.026), (32, 0.042), (33, 0.002), (34, 0.034), (35, -0.061), (36, 0.152), (37, -0.147), (38, 0.024), (39, -0.025), (40, -0.098), (41, 0.031), (42, 0.031), (43, 0.053), (44, 0.005), (45, 0.011), (46, 0.007), (47, -0.024), (48, 0.089), (49, 0.022)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97755092 <a title="78-lsi-1" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>Introduction: Jacob Abernethy and I have found a computationally tractable method for computing an optimal (or near optimal depending on setting) master algorithm combining expert predictions addressing  this open problem .  A draft is  here .  
 
The effect of this improvement seems to be about a factor of  2  decrease in the regret (= error rate minus best possible error rate) for the low error rate situation.  (At large error rates, there may be no significant difference.)  
 
There are some unfinished details still to consider:
  
 When we remove all of the approximation slack from online learning, is the result a satisfying learning algorithm, in practice?  I consider online learning is one of the more compelling methods of analyzing and deriving algorithms, but that expectation must be either met or not by this algorithm 
 Some extra details: The algorithm is optimal given a small amount of side information ( k  in the draft).  What is the best way to remove this side information?  The removal</p><p>2 0.72000432 <a title="78-lsi-2" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>Introduction: This post is about a reductions-related problem that I find mysterious.  There are two kinds of reductions analysis currently under consideration.
  
 Error limiting reductions.  Here, the goal is to bound the error rate of the created classifier in terms of the error rate of the binary classifiers that you reduce to.  A very simple example of this is that  error correcting output codes  where it is possible to prove that for certain codes, the multiclass error rate is at most 4 * the binary classifier error rate. 
 Regret minimizing reductions.  Here, the goal is to bound the  regret  of the created classifier in terms of the  regret  of the binary classifiers reduced to.  The regret is the error rate minus the minimum error rate.  When the learning problem is noisy the minimum error rate may not be  0 .  An analagous result for reget is that for a  probabilistic error correcting output code , multiclass regret is at most 4 * (binary regret) 0.5 .  
  
The use of “regret” is more desi</p><p>3 0.71228862 <a title="78-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notation  g(n) = O(f(n))  means that in the limit as  n  approaches infinity there exists a constant  C  such that the  g(n)  is less than  Cf(n) .
 
In learning theory, there are many statements about learning algorithms of the form “under assumptions  x , y , and  z , the classifier learned has an error rate of at most  O(f(m)) “.
 
There is one very good reason to use O(): it helps you understand the big picture and neglect the minor details which are not important in the big picture.  However, there are some important reasons not to do this as well.
  
  Unspeedup  In algorithm analysis, the use of O() for time complexity is pervasive and well-justified.  Determining the exact value of C is inherently computer architecture dependent.  (The “C” for x86 processors might differ from the “C” on PowerPC processors.)  Since many learning theorists come from a CS theory background, the O() notation is applied to generalization error.  The O() abstraction breaks here—you can not genera</p><p>4 0.65843278 <a title="78-lsi-4" href="../hunch_net-2006/hunch_net-2006-09-09-How_to_solve_an_NP_hard_problem_in_quadratic_time.html">206 hunch net-2006-09-09-How to solve an NP hard problem in quadratic time</a></p>
<p>Introduction: This title is a lie, but it is a special lie which has a bit of truth.
 
If  n  players each play each other, you have a tournament.   How do you order the players from weakest to strongest?
 
The standard first attempt is “find the ordering which agrees with the tournament on as many player pairs as possible”.  This is called the “minimum feedback arcset” problem in the CS theory literature and it is a well known NP-hard problem.  A basic guarantee holds for the solution to this problem: if there is some “true” intrinsic ordering, and the outcome of the tournament disagrees  k  times (due to noise for instance), then the output ordering will disagree with the original ordering on at most  2k  edges (and no solution can be better).
 
One standard approach to tractably solving an NP-hard problem is to find another algorithm with an approximation guarantee.  For example,  Don Coppersmith ,  Lisa Fleischer  and  Atri Rudra  proved that  ordering players according to the number of wins is</p><p>5 0.63124412 <a title="78-lsi-5" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>Introduction: This  problem  has been cracked (but not quite completely solved) by  Alina ,  Pradeep , and  I .  The problem is essentially finding a better way to reduce multiclass classification to binary classification.  The solution is to use a carefully crafted tournament,  the simplest version of which is a  single elimination tournament  where the “players” are the different classes.  An example of the structure is here: 
    
For the single elimination tournament, we can prove that: 
 For all multiclass problems  D , for all learned binary classifiers  c , the regret of an induced multiclass classifier is bounded by the regret of the binary classifier times  log 2  k .  Restated:  
  reg multiclass (D,Filter_tree_test(c)) <= reg binary  (Filter_tree_train(D),c)    
Here:
  
   Filter_tree_train(D)  is the induced binary classification problem 
   Filter_tree_test(c)  is the induced multiclass classifier. 
   reg multiclass   is the multiclass regret (= difference between error rate and minim</p><p>6 0.62018323 <a title="78-lsi-6" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>7 0.57349575 <a title="78-lsi-7" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>8 0.57000738 <a title="78-lsi-8" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>9 0.5541622 <a title="78-lsi-9" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>10 0.55220234 <a title="78-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>11 0.54819399 <a title="78-lsi-11" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>12 0.54340696 <a title="78-lsi-12" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>13 0.54070711 <a title="78-lsi-13" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>14 0.53985196 <a title="78-lsi-14" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>15 0.53769547 <a title="78-lsi-15" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>16 0.52560771 <a title="78-lsi-16" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>17 0.49346477 <a title="78-lsi-17" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>18 0.48401108 <a title="78-lsi-18" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>19 0.47960514 <a title="78-lsi-19" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>20 0.47890148 <a title="78-lsi-20" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.076), (10, 0.024), (27, 0.197), (38, 0.068), (53, 0.103), (55, 0.063), (72, 0.223), (77, 0.027), (94, 0.111)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9134655 <a title="78-lda-1" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>Introduction: Jacob Abernethy and I have found a computationally tractable method for computing an optimal (or near optimal depending on setting) master algorithm combining expert predictions addressing  this open problem .  A draft is  here .  
 
The effect of this improvement seems to be about a factor of  2  decrease in the regret (= error rate minus best possible error rate) for the low error rate situation.  (At large error rates, there may be no significant difference.)  
 
There are some unfinished details still to consider:
  
 When we remove all of the approximation slack from online learning, is the result a satisfying learning algorithm, in practice?  I consider online learning is one of the more compelling methods of analyzing and deriving algorithms, but that expectation must be either met or not by this algorithm 
 Some extra details: The algorithm is optimal given a small amount of side information ( k  in the draft).  What is the best way to remove this side information?  The removal</p><p>2 0.84471893 <a title="78-lda-2" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>Introduction: Alina  and  Jake  point out the COLT  Call for Open Questions  due May 11.  In general, this is cool, and worth doing if you can come up with a crisp question.  In my case, I particularly enjoyed  crafting an open question  with precisely a form such that a  critic targeting my papers  would be forced to confront their fallacy or make a case for the reward.  But less esoterically, this is a way to get the attention of some very smart people focused on a problem that really matters, which is the real value.</p><p>3 0.79118663 <a title="78-lda-3" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>Introduction: Given John’s recent posts on CMU’s new machine learning department and “Deep Learning,” I asked for an opportunity to give a computational learning theory perspective on these issues.
 
To my mind, the answer to the question “Are the core problems from machine learning different from the core problems of statistics?” is a clear Yes.  The point of this post is to describe a core problem in machine learning that is computational in nature and will appeal to statistical learning folk (as an extreme example note that if P=NP– which, for all we know, is true– then we would suddenly find almost all of our favorite machine learning problems considerably more tractable).
 
If the central question of statistical learning theory were crudely summarized as “given a hypothesis with a certain loss bound over a test set, how well will it generalize?” then the central question of computational learning theory might be “how can we find such a hypothesis efficently (e.g., in polynomial-time)?”
 
With t</p><p>4 0.77650571 <a title="78-lda-4" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>Introduction: Iain  noticed that hunch.net had zero width divs hiding spammy URLs.  Some investigation reveals that the wordpress version being used (2.0.3) had security flaws.  I’ve upgraded to the latest, rotated passwords, and removed the spammy URLs.  I don’t believe any content was lost.  You can check your own and other sites for a similar problem by greping for “width:0″ or “width: 0″ in the delivered html source.</p><p>5 0.73671579 <a title="78-lda-5" href="../hunch_net-2010/hunch_net-2010-04-28-CI_Fellows_program_renewed.html">396 hunch net-2010-04-28-CI Fellows program renewed</a></p>
<p>Introduction: Lev Reyzin  points out  the  CI Fellows program is renewed .  CI Fellows are essentially  NSF  funded computer science postdocs for universities and industry research labs.  I’ve been lucky and happy to have Lev visit me for a year under  last year’s program , so I strongly recommend participating if it suits you.
 
As with last year, the application timeline is very short, with everything due by May 23.</p><p>6 0.7338444 <a title="78-lda-6" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>7 0.73036152 <a title="78-lda-7" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>8 0.72606719 <a title="78-lda-8" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>9 0.7247439 <a title="78-lda-9" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>10 0.72465068 <a title="78-lda-10" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>11 0.72449845 <a title="78-lda-11" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>12 0.72206861 <a title="78-lda-12" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>13 0.72195703 <a title="78-lda-13" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>14 0.72166681 <a title="78-lda-14" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>15 0.72116423 <a title="78-lda-15" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>16 0.72093964 <a title="78-lda-16" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>17 0.71998525 <a title="78-lda-17" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>18 0.71971262 <a title="78-lda-18" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>19 0.71551597 <a title="78-lda-19" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>20 0.71540934 <a title="78-lda-20" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
