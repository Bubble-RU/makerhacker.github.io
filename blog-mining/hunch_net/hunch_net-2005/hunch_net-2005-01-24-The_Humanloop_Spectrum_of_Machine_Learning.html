<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-3" href="#">hunch_net-2005-3</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-3-html" href="http://hunch.net/?p=5">html</a></p><p>Introduction: All branches of machine learning seem to be united in the idea of using data to make predictions.  However, people disagree to some extent about what this means.  One way to categorize these different goals is on an axis, where one extreme is “tools to aid a human in using data to do prediction” and the other extreme is “tools to do prediction with no human intervention”.  Here is my estimate of where various elements of machine learning fall on this spectrum.
  
 
 Human Necessary 
  
 Human partially necessary 
  
 Human unnecessary 
 
 
 Clustering, data visualization 
 Bayesian Learning, Probabilistic Models, Graphical Models 
 Kernel Learning (SVM’s, etc..) 
 Decision Trees? 
 Reinforcement Learning 
 
  
The exact position of each element is of course debatable.  My reasoning is that clustering and data visualization are nearly useless for prediction without a human in the loop.  Bayesian/probabilistic models/graphical models generally require a human to sit and think about what</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 All branches of machine learning seem to be united in the idea of using data to make predictions. [sent-1, score-0.373]
</p><p>2 However, people disagree to some extent about what this means. [sent-2, score-0.15]
</p><p>3 One way to categorize these different goals is on an axis, where one extreme is “tools to aid a human in using data to do prediction” and the other extreme is “tools to do prediction with no human intervention”. [sent-3, score-1.69]
</p><p>4 Here is my estimate of where various elements of machine learning fall on this spectrum. [sent-4, score-0.212]
</p><p>5 Human Necessary      Human partially necessary      Human unnecessary       Clustering, data visualization   Bayesian Learning, Probabilistic Models, Graphical Models   Kernel Learning (SVM’s, etc. [sent-5, score-0.821]
</p><p>6 Reinforcement Learning       The exact position of each element is of course debatable. [sent-8, score-0.321]
</p><p>7 My reasoning is that clustering and data visualization are nearly useless for prediction without a human in the loop. [sent-9, score-1.363]
</p><p>8 Bayesian/probabilistic models/graphical models generally require a human to sit and think about what is a good prior/structure. [sent-10, score-0.774]
</p><p>9 Kernel learning approaches have a few standard kernels which often work on simple problems, although sometimes significant kernel engineering is required. [sent-11, score-0.351]
</p><p>10 I’ve been impressed of late how ‘black box’ decision trees or boosted decision trees are. [sent-12, score-0.911]
</p><p>11 The goal of reinforcement learning (rather than perhaps the reality) is designing completely automated agents. [sent-13, score-0.324]
</p><p>12 The position in this spectrum provides some idea of what the state of progress is. [sent-14, score-0.34]
</p><p>13 Things at the ‘human necessary’ end have been succesfully used by many people to solve many learning problems. [sent-15, score-0.243]
</p><p>14 At the ‘human unnecessary’ end, the systems are finicky and often just won’t work well. [sent-16, score-0.099]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('human', 0.542), ('unnecessary', 0.282), ('visualization', 0.209), ('trees', 0.197), ('kernel', 0.186), ('position', 0.169), ('clustering', 0.156), ('necessary', 0.15), ('end', 0.149), ('models', 0.138), ('tools', 0.136), ('extreme', 0.122), ('decision', 0.116), ('data', 0.115), ('black', 0.113), ('reinforcement', 0.11), ('prediction', 0.105), ('axis', 0.105), ('boosted', 0.105), ('impressed', 0.105), ('finicky', 0.099), ('box', 0.094), ('branches', 0.094), ('sit', 0.094), ('spectrum', 0.094), ('succesfully', 0.094), ('kernels', 0.09), ('reasoning', 0.09), ('united', 0.087), ('disagree', 0.082), ('reality', 0.082), ('fall', 0.08), ('useless', 0.08), ('svm', 0.078), ('idea', 0.077), ('element', 0.076), ('exact', 0.076), ('completely', 0.075), ('engineering', 0.075), ('late', 0.075), ('aid', 0.073), ('designing', 0.072), ('goals', 0.069), ('graphical', 0.069), ('extent', 0.068), ('automated', 0.067), ('estimate', 0.067), ('nearly', 0.066), ('elements', 0.065), ('partially', 0.065)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="3-tfidf-1" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>Introduction: All branches of machine learning seem to be united in the idea of using data to make predictions.  However, people disagree to some extent about what this means.  One way to categorize these different goals is on an axis, where one extreme is “tools to aid a human in using data to do prediction” and the other extreme is “tools to do prediction with no human intervention”.  Here is my estimate of where various elements of machine learning fall on this spectrum.
  
 
 Human Necessary 
  
 Human partially necessary 
  
 Human unnecessary 
 
 
 Clustering, data visualization 
 Bayesian Learning, Probabilistic Models, Graphical Models 
 Kernel Learning (SVM’s, etc..) 
 Decision Trees? 
 Reinforcement Learning 
 
  
The exact position of each element is of course debatable.  My reasoning is that clustering and data visualization are nearly useless for prediction without a human in the loop.  Bayesian/probabilistic models/graphical models generally require a human to sit and think about what</p><p>2 0.14873375 <a title="3-tfidf-2" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>Introduction: For  his  work on the subject of human computation including  ESPGame ,  Peekaboom , and  Phetch .  The  new MacArthur fellows .</p><p>3 0.14729436 <a title="3-tfidf-3" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>Introduction: Do we have computer hardware sufficient for AI?  This question is difficult to answer, but here’s a try:
 
One way to achieve AI is by simulating a human brain.  A human brain has about 10 15  synapses which operate at about 10 2  per second implying about 10 17  bit ops per second.
 
A modern computer runs at 10 9  cycles/second and operates on 10 2  bits per cycle implying 10 11  bits processed per second.  
 
The gap here is only 6 orders of magnitude, which can be plausibly surpassed via cluster machines.  For example, the  BlueGene/L  operates 10 5  nodes (one order of magnitude short).  It’s peak recorded performance is about 0.5*10 15  FLOPS which translates to about 10 16  bit ops per second, which is nearly 10 17 .
 
There are many criticisms (both positive and negative) for this argument.
  
 Simulation of a human brain might require substantially more detail.  Perhaps an additional 10 2  is required per neuron. 
 We may not need to simulate a human brain to achieve AI.  Ther</p><p>4 0.1455791 <a title="3-tfidf-4" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>Introduction: Machine learning has a new kind of “scaling to larger problems” to worry about: scaling with the amount of contextual information.  The standard development path for a machine learning application in practice seems to be the following:
  
  Marginal . In the beginning, there was “majority vote”.  At this stage, it isn’t necessary to understand that you have a prediction problem.  People just realize that one answer is right sometimes and another answer other times.  In machine learning terms, this corresponds to making a prediction without side information. 
  First context . A clever person realizes that some bit of information  x 1   could be helpful.  If  x 1   is discrete, they condition on it and make a predictor  h(x 1 ) , typically by counting.  If they are clever, then they also do some smoothing.  If  x 1   is some real valued parameter, it’s very common to make a threshold cutoff.  Often, these tasks are simply done by hand. 
  Second . Another clever person (or perhaps the s</p><p>5 0.14144756 <a title="3-tfidf-5" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>Introduction: Watson  convincingly beat the best champion  Jeopardy!  players.  The apparent significance of this varies hugely, depending on your background knowledge about the related machine learning, NLP, and search technology.  For a random person, this might seem evidence of serious machine intelligence, while for people working on the system itself, it probably seems like a reasonably good assemblage of existing technologies with several twists to make the entire system work.
 
Above all, I think we should congratulate the people who managed to put together and execute this project—many years of effort by a diverse set of highly skilled people were needed to make this happen.  In academia, it’s pretty difficult for one professor to assemble that quantity of talent, and in industry it’s rarely the case that such a capable group has both a worthwhile project and the support needed to pursue something like this for several years before success.
 
 Alina  invited me to the Jeopardy watching party</p><p>6 0.13260588 <a title="3-tfidf-6" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>7 0.12458495 <a title="3-tfidf-7" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>8 0.11921586 <a title="3-tfidf-8" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>9 0.11817691 <a title="3-tfidf-9" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>10 0.11081503 <a title="3-tfidf-10" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>11 0.10711751 <a title="3-tfidf-11" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>12 0.10637586 <a title="3-tfidf-12" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>13 0.10612175 <a title="3-tfidf-13" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>14 0.10482782 <a title="3-tfidf-14" href="../hunch_net-2010/hunch_net-2010-08-23-Boosted_Decision_Trees_for_Deep_Learning.html">407 hunch net-2010-08-23-Boosted Decision Trees for Deep Learning</a></p>
<p>15 0.10060982 <a title="3-tfidf-15" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>16 0.096411906 <a title="3-tfidf-16" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>17 0.095221967 <a title="3-tfidf-17" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>18 0.093567505 <a title="3-tfidf-18" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>19 0.091353983 <a title="3-tfidf-19" href="../hunch_net-2006/hunch_net-2006-06-30-ICML_papers.html">188 hunch net-2006-06-30-ICML papers</a></p>
<p>20 0.090005971 <a title="3-tfidf-20" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.179), (1, 0.063), (2, -0.041), (3, 0.055), (4, 0.06), (5, -0.044), (6, -0.016), (7, 0.09), (8, 0.124), (9, -0.081), (10, -0.092), (11, -0.033), (12, -0.074), (13, -0.011), (14, -0.027), (15, 0.005), (16, 0.048), (17, -0.013), (18, 0.026), (19, -0.008), (20, 0.055), (21, -0.034), (22, -0.096), (23, 0.057), (24, 0.101), (25, 0.064), (26, -0.031), (27, -0.01), (28, 0.079), (29, -0.015), (30, 0.14), (31, -0.049), (32, -0.046), (33, -0.11), (34, 0.064), (35, 0.068), (36, 0.056), (37, -0.078), (38, 0.069), (39, -0.044), (40, 0.026), (41, -0.024), (42, -0.03), (43, 0.015), (44, 0.034), (45, 0.151), (46, 0.015), (47, 0.023), (48, 0.012), (49, -0.021)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95350838 <a title="3-lsi-1" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>Introduction: All branches of machine learning seem to be united in the idea of using data to make predictions.  However, people disagree to some extent about what this means.  One way to categorize these different goals is on an axis, where one extreme is “tools to aid a human in using data to do prediction” and the other extreme is “tools to do prediction with no human intervention”.  Here is my estimate of where various elements of machine learning fall on this spectrum.
  
 
 Human Necessary 
  
 Human partially necessary 
  
 Human unnecessary 
 
 
 Clustering, data visualization 
 Bayesian Learning, Probabilistic Models, Graphical Models 
 Kernel Learning (SVM’s, etc..) 
 Decision Trees? 
 Reinforcement Learning 
 
  
The exact position of each element is of course debatable.  My reasoning is that clustering and data visualization are nearly useless for prediction without a human in the loop.  Bayesian/probabilistic models/graphical models generally require a human to sit and think about what</p><p>2 0.62744719 <a title="3-lsi-2" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>Introduction: Do we have computer hardware sufficient for AI?  This question is difficult to answer, but here’s a try:
 
One way to achieve AI is by simulating a human brain.  A human brain has about 10 15  synapses which operate at about 10 2  per second implying about 10 17  bit ops per second.
 
A modern computer runs at 10 9  cycles/second and operates on 10 2  bits per cycle implying 10 11  bits processed per second.  
 
The gap here is only 6 orders of magnitude, which can be plausibly surpassed via cluster machines.  For example, the  BlueGene/L  operates 10 5  nodes (one order of magnitude short).  It’s peak recorded performance is about 0.5*10 15  FLOPS which translates to about 10 16  bit ops per second, which is nearly 10 17 .
 
There are many criticisms (both positive and negative) for this argument.
  
 Simulation of a human brain might require substantially more detail.  Perhaps an additional 10 2  is required per neuron. 
 We may not need to simulate a human brain to achieve AI.  Ther</p><p>3 0.56937635 <a title="3-lsi-3" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>Introduction: Watson  convincingly beat the best champion  Jeopardy!  players.  The apparent significance of this varies hugely, depending on your background knowledge about the related machine learning, NLP, and search technology.  For a random person, this might seem evidence of serious machine intelligence, while for people working on the system itself, it probably seems like a reasonably good assemblage of existing technologies with several twists to make the entire system work.
 
Above all, I think we should congratulate the people who managed to put together and execute this project—many years of effort by a diverse set of highly skilled people were needed to make this happen.  In academia, it’s pretty difficult for one professor to assemble that quantity of talent, and in industry it’s rarely the case that such a capable group has both a worthwhile project and the support needed to pursue something like this for several years before success.
 
 Alina  invited me to the Jeopardy watching party</p><p>4 0.55980158 <a title="3-lsi-4" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>Introduction: Pieter Abbeel  presented a paper with  Andrew Ng  at  ICML  on  Exploration and Apprenticeship Learning in Reinforcement Learning .  The basic idea of this algorithm is:
  
 Collect data from a human controlling a machine. 
 Build a transition model based upon the experience. 
 Build a policy which optimizes the transition model. 
 Evaluate the policy.  If it works well, halt, otherwise add the experience into the pool and go to (2). 
  
The paper proves that this technique will converge to some policy with expected performance near human expected performance assuming the  world fits certain assumptions (MDP or linear dynamics).  
 
This general idea of apprenticeship learning (i.e. incorporating data from an expert) seems very compelling because (a) humans often learn this way and (b) much harder problems can be solved.   For (a), the notion of teaching is about transferring knowledge from an expert to novices, often via demonstration. To see (b), note that we can create intricate rei</p><p>5 0.5589717 <a title="3-lsi-5" href="../hunch_net-2005/hunch_net-2005-02-27-Antilearning%3A_When_proximity_goes_bad.html">32 hunch net-2005-02-27-Antilearning: When proximity goes bad</a></p>
<p>Introduction: Joel Predd   mentioned  “ Antilearning ” by  Adam Kowalczyk , which is interesting from a foundational intuitions viewpoint.
 
There is a pervasive intuition that “nearby things tend to have the same label”.  This intuition is instantiated in SVMs, nearest neighbor classifiers, decision trees, and neural networks.  It turns out there are natural problems where this intuition is opposite of the truth.
 
One natural situation where this occurs is in competition.   For example, when  Intel  fails to meet its earnings estimate, is this evidence that  AMD  is doing badly also?  Or evidence that AMD is doing well?
 
This violation of the proximity intuition means that when the number of examples is few,  negating  a classifier which attempts to exploit proximity can provide predictive power (thus, the term “antilearning”).</p><p>6 0.53269047 <a title="3-lsi-6" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>7 0.5249837 <a title="3-lsi-7" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>8 0.52178079 <a title="3-lsi-8" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>9 0.51366103 <a title="3-lsi-9" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>10 0.50569177 <a title="3-lsi-10" href="../hunch_net-2005/hunch_net-2005-04-25-Embeddings%3A_what_are_they_good_for%3F.html">61 hunch net-2005-04-25-Embeddings: what are they good for?</a></p>
<p>11 0.50331581 <a title="3-lsi-11" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>12 0.49352315 <a title="3-lsi-12" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>13 0.47802147 <a title="3-lsi-13" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>14 0.46672922 <a title="3-lsi-14" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>15 0.46524858 <a title="3-lsi-15" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>16 0.4574708 <a title="3-lsi-16" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>17 0.45739686 <a title="3-lsi-17" href="../hunch_net-2012/hunch_net-2012-02-24-ICML%2B50%25.html">456 hunch net-2012-02-24-ICML+50%</a></p>
<p>18 0.45582968 <a title="3-lsi-18" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>19 0.45519048 <a title="3-lsi-19" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>20 0.44524103 <a title="3-lsi-20" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.012), (21, 0.336), (27, 0.221), (38, 0.077), (48, 0.015), (53, 0.123), (55, 0.03), (94, 0.063), (95, 0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9205783 <a title="3-lda-1" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>Introduction: David Mcallester  gave a talk about this  paper  (with  Pedro Felzenszwalb ).  I’ll try to give a high level summary of why it’s interesting.
 
Dynamic programming is most familiar as instantiated by Viterbi decoding in a hidden markov model.  It is a general paradigm for problem solving where subproblems are solved and used to solve larger problems.  In the Viterbi decoding example, the subproblem is “What is the most probable path ending at each state at timestep  t ?”, and the larger problem is the same except at timestep  t+1 .  There are a few optimizations you can do here:
  
  Dynamic Programming -> queued Dynamic Programming . Keep track of the “cost so far” (or “most probable path”) and (carefully) only look at extensions to paths likely to yield the shortest path.  “Carefully” here is defined by  Dijkstra’s shortest path algorithm . 
  queued Dynamic programming -> A *  Add a lower bound on the cost to complete a path (or an upper bound on the probability of a completion) for</p><p>2 0.81358445 <a title="3-lda-2" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>Introduction: The ideal of theoretical algorithm analysis is to construct an algorithm with accompanying optimality theorems proving that it is a useful algorithm.  This ideal often fails, particularly for learning algorithms and theory.  The general form of a theorem is:  If  preconditions  Then  postconditions     When we design learning algorithms it is very common to come up with precondition assumptions such as “the data is IID”, “the learning problem is drawn from a known distribution over learning problems”, or “there is a perfect classifier”.  All of these example preconditions can be false for real-world problems in ways that are not easily detectable.  This means that algorithms derived and justified by these very common forms of analysis may be prone to catastrophic failure in routine (mis)application.
 
We  can  hope for better.  Several different kinds of learning algorithm analysis have been developed some of which have fewer preconditions.  Simply demanding that these forms of analysi</p><p>same-blog 3 0.81219643 <a title="3-lda-3" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>Introduction: All branches of machine learning seem to be united in the idea of using data to make predictions.  However, people disagree to some extent about what this means.  One way to categorize these different goals is on an axis, where one extreme is “tools to aid a human in using data to do prediction” and the other extreme is “tools to do prediction with no human intervention”.  Here is my estimate of where various elements of machine learning fall on this spectrum.
  
 
 Human Necessary 
  
 Human partially necessary 
  
 Human unnecessary 
 
 
 Clustering, data visualization 
 Bayesian Learning, Probabilistic Models, Graphical Models 
 Kernel Learning (SVM’s, etc..) 
 Decision Trees? 
 Reinforcement Learning 
 
  
The exact position of each element is of course debatable.  My reasoning is that clustering and data visualization are nearly useless for prediction without a human in the loop.  Bayesian/probabilistic models/graphical models generally require a human to sit and think about what</p><p>4 0.81001854 <a title="3-lda-4" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>Introduction: Several events are happening in the NY area.
  
  Barriers in Computational Learning Theory Workshop, Aug 28.   That’s tomorrow near Princeton.  I’m looking forward to speaking at this one on “Getting around Barriers in Learning Theory”, but several other talks are of interest, particularly to the CS theory inclined. 
  Claudia Perlich  is running the  INFORMS Data Mining Contest  with a deadline of Sept. 25. This is a contest using real health record data (they partnered with  HealthCare Intelligence ) to predict transfers and mortality. In the current US health care reform debate, the case studies of high costs we hear strongly suggest machine learning & statistics can save many billions. 
  The Singularity Summit October 3&4 .  This is for the AIists out there.  Several of the talks look interesting, although unfortunately I’ll miss it for  ALT . 
  Predictive Analytics World, Oct 20-21 .  This is stretching the definition of “New York Area” a bit, but the train to DC is reasonable.</p><p>5 0.76078027 <a title="3-lda-5" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>Introduction: Online learning is in vogue, which means we should expect to see in the near future:
  
 Online boosting. 
 Online decision trees. 
 Online SVMs.  (actually, we’ve already seen) 
 Online deep learning. 
 Online parallel learning. 
 etc… 
  
There are three fundamental drivers of this trend. 
  
 Increasing size of datasets makes online algorithms attractive.   
 Online learning can simply be more efficient than batch learning.  Here is a picture from a class on online learning: 
  
The point of this picture is that even in 3 dimensions and even with linear constraints, finding the minima of a set in an online fashion can be typically faster than finding the minima in a batch fashion.  To see this, note that there is a minimal number of gradient updates (i.e. 2) required in order to reach the minima in the typical case.  Given this, it’s best to do these updates as quickly as possible, which implies doing the first update online (i.e. before seeing all the examples) is preferred.  Note</p><p>6 0.68746156 <a title="3-lda-6" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>7 0.62213182 <a title="3-lda-7" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>8 0.62028211 <a title="3-lda-8" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>9 0.6193949 <a title="3-lda-9" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>10 0.6165148 <a title="3-lda-10" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>11 0.61309612 <a title="3-lda-11" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>12 0.6096065 <a title="3-lda-12" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>13 0.60796368 <a title="3-lda-13" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>14 0.6067788 <a title="3-lda-14" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>15 0.60534072 <a title="3-lda-15" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>16 0.60514581 <a title="3-lda-16" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>17 0.60373235 <a title="3-lda-17" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>18 0.59939957 <a title="3-lda-18" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>19 0.59923321 <a title="3-lda-19" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>20 0.59886384 <a title="3-lda-20" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
