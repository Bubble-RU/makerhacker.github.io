<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>9 hunch net-2005-02-01-Watchword: Loss</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-9" href="#">hunch_net-2005-9</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>9 hunch net-2005-02-01-Watchword: Loss</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-9-html" href="http://hunch.net/?p=11">html</a></p><p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A loss function is some function which, for any example, takes a prediction and the correct prediction, and determines how much loss is incurred. [sent-1, score-1.874]
</p><p>2 (People sometimes attempt to optimize functions of more than one example such as "area under the ROC curve" or "harmonic mean of precision and recall". [sent-2, score-0.434]
</p><p>3 ) Typically we try to find predictors that minimize loss. [sent-3, score-0.141]
</p><p>4 There seems to be a strong dichotomy between two views of what "loss" means in learning. [sent-4, score-0.192]
</p><p>5 Loss is a part of the specification of the learning problem. [sent-6, score-0.09]
</p><p>6 Examples of problems specified by the loss function include "binary classification", "multiclass classification", "importance weighted classification", "l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and the view that I prefer. [sent-7, score-1.914]
</p><p>7 To solve a problem, you optimize some particular loss functionnotgiven by the problem. [sent-9, score-0.799]
</p><p>8 Examples of these loss functions are "hinge loss" (for SVMs), "log loss" (common in Bayesian Learning), and "exponential loss" (one incomplete explanation of boosting). [sent-10, score-0.986]
</p><p>9 One advantage of this viewpoint is that an appropriate choice of loss function (such as any of the above) results in a (relatively tractable) convex optimization problem. [sent-11, score-1.051]
</p><p>10 It seems (to some extent) like looking where the light is rather than where your keys fell on the ground. [sent-13, score-0.311]
</p><p>11 Many of these losses-of-convenience also seem to have behavior unlike real world problems. [sent-14, score-0.231]
</p><p>12 For example in thiscontestsomebody would have been the winner except they happened to predict one example incorrectly with very low probability. [sent-15, score-0.525]
</p><p>13 This does not seem to correspond to the intuitive notion of what the loss should be on the problem. [sent-17, score-0.92]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('loss', 0.661), ('determined', 0.204), ('function', 0.184), ('classification', 0.151), ('optimize', 0.138), ('view', 0.126), ('explanation', 0.116), ('fell', 0.116), ('incorrectly', 0.116), ('log', 0.116), ('functions', 0.116), ('determines', 0.108), ('keys', 0.108), ('recall', 0.108), ('views', 0.108), ('hinge', 0.097), ('became', 0.093), ('curve', 0.093), ('incomplete', 0.093), ('intuitive', 0.093), ('roc', 0.093), ('example', 0.093), ('correspond', 0.09), ('specification', 0.09), ('light', 0.087), ('precision', 0.087), ('svms', 0.085), ('means', 0.084), ('behavior', 0.082), ('specified', 0.082), ('happened', 0.08), ('winner', 0.08), ('prediction', 0.076), ('seem', 0.076), ('convex', 0.075), ('minimize', 0.075), ('weighted', 0.074), ('boosting', 0.073), ('unlike', 0.073), ('examples', 0.072), ('exponential', 0.071), ('extent', 0.07), ('multiclass', 0.067), ('tractable', 0.067), ('viewpoint', 0.066), ('importance', 0.066), ('predictors', 0.066), ('appropriate', 0.065), ('fully', 0.064), ('except', 0.063)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="9-tfidf-1" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>2 0.54078257 <a title="9-tfidf-2" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss:
A loss function which is much easier to optimize computationally than the loss
function imposed by the world. A canonical example is when we want to learn a
weight vectorwand predict according to a dot productfw(x)= sumiwixiwhere
optimizing squared loss(y-fw(x))2over many samples is much more tractable than
optimizing 0-1 lossI(y = Threshold(fw(x) - 0.5)).While the computational
advantages of optimizing a proxy loss are substantial, we are curious: which
proxy loss is best? The answer of course depends on what the real loss imposed
by the world is. For 0-1 loss classification, there are adherents to many
choices:Log loss. If we confine the prediction to[0,1], we can treat it as a
predicted probability that the label is1, and measure loss according tolog
1/p'(y|x)wherep'(y|x)is the predicted probability of the observed label. A
standard method for confining the prediction to[0,1]islogistic regressionwhich
expo</p><p>3 0.43915287 <a title="9-tfidf-3" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>Introduction: Halasksa very good question: "When is the right time to insert the loss
function?" In particular, should it be used at testing time or at training
time?When the world imposes a loss on us, the standard Bayesian recipe is to
predict the (conditional) probability of each possibility and then choose the
possibility which minimizes the expected loss. In contrast, as
theconfusionover "loss = money lost" or "loss = the thing you optimize" might
indicate, many people ignore the Bayesian approach and simply optimize their
loss (or a close proxy for their loss) over the representation on the training
set.The best answer I can give is "it's unclear, but I prefer optimizing the
loss at training time". My experience is that optimizing the loss in the most
direct manner possible typically yields best performance. This question is
related to a basic principle which bothYann LeCun(applied) andVladimir
Vapnik(theoretical) advocate: "solve the simplest prediction problem that
solves the problem". (One</p><p>4 0.42583004 <a title="9-tfidf-4" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner
independent of the loss function itself.Optimizing squared
losslsq(y,y')=(y-y')2means predicting the (conditional) mean ofy.Optimizing
absolute value losslav(y,y')=|y-y'|means predicting the (conditional) median
ofy. Variants canhandle other quantiles. 0/1 loss for classification is a
special case.Optimizing log lossllog(y,y')=log (1/Prz~y'(z=y))means minimizing
the description length ofy.The semantics (= meaning) of the loss are made
explicit by a theorem in each case. For squared loss, we can prove a theorem
of the form:For all distributionsDoverY, ify' = arg miny'Ey ~ Dlsq(y,y')theny'
= Ey~DySimilar theorems hold for the other examples above, and they can all be
extended to predictors ofy'for distributionsDover a contextXand a valueY.There
are 3 points to this post.Everyone doing general machine learning should be
aware of the laundry list above. They form a handy toolkit which can match
many of the problems nat</p><p>5 0.33624369 <a title="9-tfidf-5" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>Introduction: There are two prediction competitions currently in the air.ThePerformance
Prediction ChallengebyIsabelle Guyon. Good entries minimize a weighted 0/1
loss + the difference between a prediction of this loss and the observed truth
on 5 datasets. Isabelle tells me all of the problems are "real world" and the
test datasets are large enough (17K minimum) that the winner should be well
determined by ability rather than luck. This is due March 1.ThePredictive
Uncertainty ChallengebyGavin Cawley. Good entries minimize log loss on real
valued output variables for one synthetic and 3 "real" datasets related to
atmospheric prediction. The use of log loss (which can be infinite and hence
is never convergent) and smaller test sets of size 1K to 7K examples makes the
winner of this contest more luck dependent. Nevertheless, the contest may be
of some interest particularly to the branch of learning (typically Bayes
learning) which prefers to optimize log loss.May the best predictor win.</p><p>6 0.32566062 <a title="9-tfidf-6" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>7 0.30939576 <a title="9-tfidf-7" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>8 0.25434765 <a title="9-tfidf-8" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>9 0.22536552 <a title="9-tfidf-9" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>10 0.18842171 <a title="9-tfidf-10" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>11 0.1629173 <a title="9-tfidf-11" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>12 0.15770938 <a title="9-tfidf-12" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>13 0.15692213 <a title="9-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>14 0.15644918 <a title="9-tfidf-14" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>15 0.15099058 <a title="9-tfidf-15" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>16 0.14878707 <a title="9-tfidf-16" href="../hunch_net-2006/hunch_net-2006-05-16-The_value_of_the_orthodox_view_of_Boosting.html">179 hunch net-2006-05-16-The value of the orthodox view of Boosting</a></p>
<p>17 0.14859895 <a title="9-tfidf-17" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>18 0.14684238 <a title="9-tfidf-18" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>19 0.14273907 <a title="9-tfidf-19" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>20 0.1332169 <a title="9-tfidf-20" href="../hunch_net-2005/hunch_net-2005-02-12-ROC_vs._Accuracy_vs._AROC.html">18 hunch net-2005-02-12-ROC vs. Accuracy vs. AROC</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.217), (1, -0.255), (2, -0.242), (3, 0.222), (4, 0.509), (5, 0.161), (6, -0.086), (7, -0.046), (8, -0.102), (9, -0.021), (10, 0.061), (11, 0.013), (12, 0.105), (13, 0.036), (14, 0.056), (15, -0.004), (16, -0.007), (17, -0.006), (18, 0.066), (19, 0.003), (20, 0.052), (21, -0.027), (22, 0.005), (23, -0.012), (24, -0.056), (25, -0.002), (26, -0.049), (27, -0.002), (28, 0.012), (29, -0.021), (30, 0.009), (31, 0.009), (32, 0.029), (33, 0.025), (34, 0.031), (35, 0.015), (36, -0.011), (37, -0.018), (38, -0.015), (39, -0.042), (40, -0.011), (41, -0.009), (42, -0.002), (43, 0.01), (44, 0.001), (45, -0.001), (46, -0.015), (47, -0.023), (48, -0.017), (49, 0.003)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99505639 <a title="9-lsi-1" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>2 0.97859216 <a title="9-lsi-2" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss:
A loss function which is much easier to optimize computationally than the loss
function imposed by the world. A canonical example is when we want to learn a
weight vectorwand predict according to a dot productfw(x)= sumiwixiwhere
optimizing squared loss(y-fw(x))2over many samples is much more tractable than
optimizing 0-1 lossI(y = Threshold(fw(x) - 0.5)).While the computational
advantages of optimizing a proxy loss are substantial, we are curious: which
proxy loss is best? The answer of course depends on what the real loss imposed
by the world is. For 0-1 loss classification, there are adherents to many
choices:Log loss. If we confine the prediction to[0,1], we can treat it as a
predicted probability that the label is1, and measure loss according tolog
1/p'(y|x)wherep'(y|x)is the predicted probability of the observed label. A
standard method for confining the prediction to[0,1]islogistic regressionwhich
expo</p><p>3 0.96255499 <a title="9-lsi-3" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner
independent of the loss function itself.Optimizing squared
losslsq(y,y')=(y-y')2means predicting the (conditional) mean ofy.Optimizing
absolute value losslav(y,y')=|y-y'|means predicting the (conditional) median
ofy. Variants canhandle other quantiles. 0/1 loss for classification is a
special case.Optimizing log lossllog(y,y')=log (1/Prz~y'(z=y))means minimizing
the description length ofy.The semantics (= meaning) of the loss are made
explicit by a theorem in each case. For squared loss, we can prove a theorem
of the form:For all distributionsDoverY, ify' = arg miny'Ey ~ Dlsq(y,y')theny'
= Ey~DySimilar theorems hold for the other examples above, and they can all be
extended to predictors ofy'for distributionsDover a contextXand a valueY.There
are 3 points to this post.Everyone doing general machine learning should be
aware of the laundry list above. They form a handy toolkit which can match
many of the problems nat</p><p>4 0.95149714 <a title="9-lsi-4" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>Introduction: Halasksa very good question: "When is the right time to insert the loss
function?" In particular, should it be used at testing time or at training
time?When the world imposes a loss on us, the standard Bayesian recipe is to
predict the (conditional) probability of each possibility and then choose the
possibility which minimizes the expected loss. In contrast, as
theconfusionover "loss = money lost" or "loss = the thing you optimize" might
indicate, many people ignore the Bayesian approach and simply optimize their
loss (or a close proxy for their loss) over the representation on the training
set.The best answer I can give is "it's unclear, but I prefer optimizing the
loss at training time". My experience is that optimizing the loss in the most
direct manner possible typically yields best performance. This question is
related to a basic principle which bothYann LeCun(applied) andVladimir
Vapnik(theoretical) advocate: "solve the simplest prediction problem that
solves the problem". (One</p><p>5 0.88041574 <a title="9-lsi-5" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>Introduction: In theregression vs classification debate, I'm adding a new "pro" to
classification. It seems there are computational shortcuts available for
classification which simply aren't available for regression. This arises in
several situations.Inactive learningit is sometimes possible to find aneerror
classifier with justlog(e)labeled samples. Only much more modest improvements
appear to be achievable for squared loss regression. The essential reason is
that the loss function on many examples is flat with respect to large
variations in the parameter spaces of a learned classifier, which implies that
many of these classifiers do not need to be considered. In contrast, for
squared loss regression, most substantial variations in the parameter space
influence the loss at most points.In budgeted learning, where there is either
a computational time constraint or a feature cost constraint, a classifier can
sometimes be learned to very high accuracy under the constraints while a
squared loss regresso</p><p>6 0.85032415 <a title="9-lsi-6" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>7 0.79975373 <a title="9-lsi-7" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>8 0.79971385 <a title="9-lsi-8" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>9 0.79130763 <a title="9-lsi-9" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>10 0.65207756 <a title="9-lsi-10" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>11 0.54823703 <a title="9-lsi-11" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>12 0.51910257 <a title="9-lsi-12" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>13 0.51226646 <a title="9-lsi-13" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>14 0.48251003 <a title="9-lsi-14" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>15 0.46054161 <a title="9-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>16 0.4239099 <a title="9-lsi-16" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>17 0.40382361 <a title="9-lsi-17" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>18 0.40165773 <a title="9-lsi-18" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>19 0.40153146 <a title="9-lsi-19" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>20 0.38919953 <a title="9-lsi-20" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.1), (42, 0.249), (68, 0.166), (74, 0.128), (78, 0.205), (87, 0.03)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.90515733 <a title="9-lda-1" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>2 0.81769156 <a title="9-lda-2" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>Introduction: TheExponentiated Gradientalgorithm byManfred WarmuthandJyrki Kivinencame out
just as I was starting graduate school, so I missed it both at a conference
and in class. It's a fine algorithm which has a remarkable theoretical
statement accompanying it.The essential statement holds in the "online
learning with an adversary" setting. Initially, there are of set ofnweights,
which might have values(1/n,â&euro;Ś,1/n), (or any other values from a probability
distribution). Everything happens in a round-by-round fashion. On each round,
the following happens:The world reveals a set of featuresx in {0,1}n. In the
online learning with an adversary literature, the features are called
"experts" and thought of as subpredictors, but this interpretation isn't
necessary--you can just use feature values as experts (or maybe the feature
value and the negation of the feature value as two experts).EG makes a
prediction according toy' = w . x(dot product).The world reveals the truthy in
[0,1].EG updates the weights</p><p>3 0.81427526 <a title="9-lda-3" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I've enjoyed theTerminatormovies and show. Neglecting the whacky aspects (time
travel and associated paradoxes), there is an enduring topic of discussion:
how do people deal with intelligent machines (and vice versa)?In Terminator-
land, the primary method for dealing with intelligent machines is to prevent
them from being made. This approach works pretty badly, because a new angle on
building an intelligent machine keeps coming up. This is partly a ploy for
writer's to avoid writing themselves out of a job, but there is a fundamental
truth to it as well: preventing progress in research is hard.The United
States, has been experimenting with trying to stop research onstem cells. It
hasn't worked very well--the net effect has been retarding research programs a
bit, and exporting some research to other countries. Another less recent
example was encryption technology, for which the United States generally did
not encourage early public research and evendiscouraged as a munition. This
slowe</p><p>4 0.81144691 <a title="9-lda-4" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>Introduction: Maybe it's too early to call, but with four separate Neural Network sessions
at this year'sICML, it looks like Neural Networks are making a comeback. Here
are my highlights of these sessions. In general, my feeling is that these
papers both demystify deep learning and show its broader applicability.The
first observation I made is that the once disreputable "Neural" nomenclature
is being used againin lieu of"deep learning". Maybe it's because Adam Coates
et al. showed that single layer networks can work surprisingly well.An
Analysis of Single-Layer Networks in Unsupervised Feature Learning,Adam
Coates,Honglak Lee,Andrew Y. Ng(AISTATS 2011)The Importance of Encoding Versus
Training with Sparse Coding and Vector Quantization,Adam Coates,Andrew Y.
Ng(ICML 2011)Another surprising result out of Andrew Ng's group comes from
Andrew Saxe et al. who show that certain convolutional pooling architectures
can obtain close to state-of-the-art performance with random weights (that is,
without actuall</p><p>5 0.81092411 <a title="9-lda-5" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>Introduction: This is about the hard choices that graduate students must make.The cultural
definition of success in academic research is to:Produce good research which
many other people appreciate.Produce many students who go on to do the
same.There are fundamental reasons why this is success in the local culture.
Good research appreciated by others means access to jobs. Many students
succesful in the same way implies that there are a number of people who think
in a similar way and appreciate your work.In order to graduate, a phd student
must live in an academic culture for a period of several years. It is common
to adopt the culture's definition of success during this time. It's also
common for many phd students discover they are not suited to an academic
research lifestyle. This collision of values and abilities naturally results
in depression.The most fundamental advice when this happens is: change
something. Pick a new advisor. Pick a new research topic. Or leave the program
(and do something el</p><p>6 0.80084932 <a title="9-lda-6" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>7 0.79779959 <a title="9-lda-7" href="../hunch_net-2010/hunch_net-2010-08-23-Boosted_Decision_Trees_for_Deep_Learning.html">407 hunch net-2010-08-23-Boosted Decision Trees for Deep Learning</a></p>
<p>8 0.79646015 <a title="9-lda-8" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>9 0.79569346 <a title="9-lda-9" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>10 0.78747463 <a title="9-lda-10" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>11 0.78672975 <a title="9-lda-11" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>12 0.78642219 <a title="9-lda-12" href="../hunch_net-2012/hunch_net-2012-03-24-David_Waltz.html">460 hunch net-2012-03-24-David Waltz</a></p>
<p>13 0.78349364 <a title="9-lda-13" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>14 0.78254461 <a title="9-lda-14" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>15 0.77800584 <a title="9-lda-15" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>16 0.7737543 <a title="9-lda-16" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>17 0.77289379 <a title="9-lda-17" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<p>18 0.77231002 <a title="9-lda-18" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>19 0.77044183 <a title="9-lda-19" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>20 0.77009374 <a title="9-lda-20" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
