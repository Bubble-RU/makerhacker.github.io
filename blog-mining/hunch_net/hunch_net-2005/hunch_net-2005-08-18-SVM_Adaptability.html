<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>103 hunch net-2005-08-18-SVM Adaptability</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-103" href="#">hunch_net-2005-103</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>103 hunch net-2005-08-18-SVM Adaptability</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-103-html" href="http://hunch.net/?p=110">html</a></p><p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to
handle several large family loss functions.This is a good thing because it is
implausible that thelossfunction imposed by the world can not be taken into
account in the process of solving a prediction problem. Even people used to
the hard-coreBayesianapproach to learning often note that some approximations
are almost inevitable in specifying apriorand/or integrating to achieve a
posterior. Taking into account how the system will be evaluated can allow both
computational effort and design effort to be focused so as to improve
performance.A current laundry list of capabilities includes:2002multiclass SVM
including arbitrary cost matricesICML 2003Hidden Markov ModelsNIPS 2003Markov
Networks(see somediscussion)EMNLP 2004Context free grammarsICML 2004Any loss
(with much computation)ICML 2005Anyconstrained linear prediction model(that's
my own name).ICML 2005Any loss dependent on a contingency tableI am personally
in</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Several recent papers have shown that SVM-like optimizations can be used to handle several large family loss functions. [sent-1, score-0.489]
</p><p>2 This is a good thing because it is implausible that thelossfunction imposed by the world can not be taken into account in the process of solving a prediction problem. [sent-2, score-0.554]
</p><p>3 Even people used to the hard-coreBayesianapproach to learning often note that some approximations are almost inevitable in specifying apriorand/or integrating to achieve a posterior. [sent-3, score-0.429]
</p><p>4 Taking into account how the system will be evaluated can allow both computational effort and design effort to be focused so as to improve performance. [sent-4, score-0.439]
</p><p>5 ICML 2005Any loss dependent on a contingency tableI am personally interested in how this relates to thelearning reductionswork which has similar goals, but works at a different abstraction level (the learning problem rather than algorithmic mechanism). [sent-6, score-0.777]
</p><p>6 The difference in abstraction implies that anything solvable by reduction should be solvable by a direct algorithmic mechanism. [sent-7, score-1.684]
</p><p>7 However, comparing and constrasting the results I know of it seems that what is solvable via reduction to classification versus what is solvable via direct SVM-like methods is currently incomparable. [sent-8, score-1.894]
</p><p>8 Can SVMs be tuned to directly solve (example dependent) cost sensitive classification? [sent-9, score-0.555]
</p><p>9 Obviously, they can be tuned indirectly viareduction, but it is easy to imagine more tractable direct optimizations. [sent-10, score-0.508]
</p><p>10 How efficiently can learning reductions be used to solve structured prediction problems? [sent-11, score-0.7]
</p><p>11 Structured prediction problems are instances of cost sensitive classification, but the regret transform efficiency which occurs when this embedding is done is too weak to be of interest. [sent-12, score-0.943]
</p><p>12 Are there any problems efficiently solvable by SVM-like algorithms which arenotefficiently solvable via learning reductions? [sent-13, score-1.32]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('solvable', 0.487), ('direct', 0.217), ('tuned', 0.179), ('abstraction', 0.167), ('cost', 0.159), ('prediction', 0.146), ('classification', 0.144), ('algorithmic', 0.142), ('efficiently', 0.139), ('sensitive', 0.139), ('dependent', 0.136), ('loss', 0.136), ('structured', 0.132), ('via', 0.131), ('account', 0.123), ('reduction', 0.113), ('reductions', 0.113), ('embedding', 0.112), ('thelossfunction', 0.112), ('emnlp', 0.112), ('evaluated', 0.112), ('indirectly', 0.112), ('laundry', 0.112), ('relates', 0.103), ('effort', 0.102), ('implausible', 0.098), ('versus', 0.098), ('optimizations', 0.093), ('thelearning', 0.093), ('used', 0.092), ('capabilities', 0.089), ('approximations', 0.089), ('family', 0.089), ('inevitable', 0.089), ('comparing', 0.086), ('transform', 0.084), ('integrating', 0.084), ('svms', 0.081), ('svm', 0.079), ('efficiency', 0.079), ('shown', 0.079), ('solve', 0.078), ('problems', 0.076), ('specifying', 0.075), ('name', 0.075), ('imposed', 0.075), ('occurs', 0.074), ('instances', 0.074), ('anything', 0.071), ('includes', 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="103-tfidf-1" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to
handle several large family loss functions.This is a good thing because it is
implausible that thelossfunction imposed by the world can not be taken into
account in the process of solving a prediction problem. Even people used to
the hard-coreBayesianapproach to learning often note that some approximations
are almost inevitable in specifying apriorand/or integrating to achieve a
posterior. Taking into account how the system will be evaluated can allow both
computational effort and design effort to be focused so as to improve
performance.A current laundry list of capabilities includes:2002multiclass SVM
including arbitrary cost matricesICML 2003Hidden Markov ModelsNIPS 2003Markov
Networks(see somediscussion)EMNLP 2004Context free grammarsICML 2004Any loss
(with much computation)ICML 2005Anyconstrained linear prediction model(that's
my own name).ICML 2005Any loss dependent on a contingency tableI am personally
in</p><p>2 0.22141683 <a title="103-tfidf-2" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>Introduction: At an intuitive level, the question here is "Can reinforcement learning be
solved with classification?"ProblemConstruct a reinforcement learning
algorithm with near-optimal expected sum of rewards in thedirect experience
modelgiven access to a classifier learning algorithm which has a small error
rate or regret on all posed classification problems. The definition of "posed"
here is slightly murky. I consider a problem "posed" if there is an algorithm
for constructing labeled classification examples.Past WorkThere exists
areduction of reinforcement learning to classification given a generative
model.A generative model is an inherently stronger assumption than the direct
experience model.Otherwork on learning reductionsmay be important.Several
algorithms for solving reinforcement learning in the direct experience model
exist. Most, such asE3,Factored-E3, andmetric-E3andRmaxrequire that the
observation be the state. Recent workextends this approach to POMDPs.This
problem is related topred</p><p>3 0.21248543 <a title="103-tfidf-3" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for thereductions
tutorialAlina,Bianca, and I are planning to do atICML. Please come, if you are
interested.Many research programs can be thought of as finding and building
new useful abstractions. The running example I'll use islearning
reductionswhere I have experience. The basic abstraction here is that we can
build a learning algorithm capable of solving classification problems up to a
small expected regret. This is used repeatedly to solve more complex
problems.In working on a new abstraction, I think you typically run into many
substantial problems of understanding, which make publishing particularly
difficult.It is difficult to seriously discuss the reason behind or mechanism
for abstraction in a conference paper with small page limits. People rarely
see such discussions and hence have little basis on which to think about new
abstractions. Another difficulty is that when building an abstraction, you
often don't know the right way to</p><p>4 0.18310098 <a title="103-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?Reductions are machines which turn solvers for one problem into solvers
for another problem.Why?Reductions are useful for several reasons.Laziness.
Reducing a problem to classification make at least 10 learning algorithms
available to solve a problem. Inventing 10 learning algorithms is quite a bit
of work. Similarly, programming a reduction is often trivial, while
programming a learning algorithm is a great deal of work.Crystallization. The
problems we often want to solve in learning are worst-case-impossible, but
average case feasible. By reducing all problems onto one or a few primitives,
we can fine tune these primitives to perform well on real-world problems with
greater precision due to the greater number of problems to validate
on.Theoretical Organization. By studying what reductions are easy vs. hard vs.
impossible, we can learn which problems are roughly equivalent in difficulty
and which are much harder.What we know now.Typesafe reductions. In the
beginning, there was th</p><p>5 0.14859895 <a title="103-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>6 0.14157151 <a title="103-tfidf-6" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>7 0.1404928 <a title="103-tfidf-7" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>8 0.13725851 <a title="103-tfidf-8" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>9 0.13678448 <a title="103-tfidf-9" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>10 0.12298072 <a title="103-tfidf-10" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>11 0.11634604 <a title="103-tfidf-11" href="../hunch_net-2012/hunch_net-2012-09-29-Vowpal_Wabbit%2C_version_7.0.html">473 hunch net-2012-09-29-Vowpal Wabbit, version 7.0</a></p>
<p>12 0.11451695 <a title="103-tfidf-12" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>13 0.11243826 <a title="103-tfidf-13" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>14 0.10736296 <a title="103-tfidf-14" href="../hunch_net-2010/hunch_net-2010-08-23-Boosted_Decision_Trees_for_Deep_Learning.html">407 hunch net-2010-08-23-Boosted Decision Trees for Deep Learning</a></p>
<p>15 0.10552388 <a title="103-tfidf-15" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>16 0.10534667 <a title="103-tfidf-16" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>17 0.10099584 <a title="103-tfidf-17" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>18 0.099606007 <a title="103-tfidf-18" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>19 0.098659903 <a title="103-tfidf-19" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>20 0.092610434 <a title="103-tfidf-20" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.208), (1, -0.127), (2, -0.075), (3, 0.057), (4, 0.104), (5, -0.043), (6, -0.024), (7, 0.06), (8, 0.037), (9, 0.121), (10, 0.084), (11, -0.018), (12, 0.143), (13, 0.088), (14, 0.081), (15, 0.064), (16, 0.0), (17, -0.033), (18, -0.022), (19, 0.007), (20, -0.016), (21, -0.105), (22, 0.02), (23, 0.029), (24, -0.095), (25, -0.026), (26, -0.041), (27, 0.099), (28, -0.11), (29, -0.027), (30, -0.049), (31, 0.066), (32, 0.015), (33, 0.095), (34, 0.043), (35, 0.012), (36, 0.027), (37, -0.038), (38, -0.061), (39, -0.046), (40, 0.059), (41, -0.017), (42, -0.062), (43, 0.008), (44, -0.006), (45, 0.036), (46, 0.002), (47, -0.069), (48, 0.052), (49, -0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97646207 <a title="103-lsi-1" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to
handle several large family loss functions.This is a good thing because it is
implausible that thelossfunction imposed by the world can not be taken into
account in the process of solving a prediction problem. Even people used to
the hard-coreBayesianapproach to learning often note that some approximations
are almost inevitable in specifying apriorand/or integrating to achieve a
posterior. Taking into account how the system will be evaluated can allow both
computational effort and design effort to be focused so as to improve
performance.A current laundry list of capabilities includes:2002multiclass SVM
including arbitrary cost matricesICML 2003Hidden Markov ModelsNIPS 2003Markov
Networks(see somediscussion)EMNLP 2004Context free grammarsICML 2004Any loss
(with much computation)ICML 2005Anyconstrained linear prediction model(that's
my own name).ICML 2005Any loss dependent on a contingency tableI am personally
in</p><p>2 0.72785777 <a title="103-lsi-2" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a
data source (Example:X x {0,1},X x [0,1],X x {1,2,3,4,5}, etc…) and a loss
function (0/1 loss, squared error loss, cost sensitive losses, etc…). For
simplicity, we'll assume that all losses have a minimum of zero.For this post,
we can think of a learning reduction asA mappingRfrom samples of one
typeT(like multiclass classification) to another typeT'(like binary
classification).A mappingQfrom predictors for typeT'to predictors for
typeT.The simplest sort of learning reduction is a "loss reduction". The idea
in a loss reduction is to prove a statement of the form:TheoremFor all base
predictorsb, for all distributionsDover examples of typeT:E(x,y) ~
DLT(y,Q(b,x)) <= f(E(x',y')~R(D)LT'(y',b(x')))HereLTis the loss for the
typeTproblem andLT'is the loss for the typeT'problem. Also,R(D)is the
distribution over samples induced by first drawing fromDand then mapping the
sample viaR. The functionf()is the loss transf</p><p>3 0.72194171 <a title="103-lsi-3" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?Reductions are machines which turn solvers for one problem into solvers
for another problem.Why?Reductions are useful for several reasons.Laziness.
Reducing a problem to classification make at least 10 learning algorithms
available to solve a problem. Inventing 10 learning algorithms is quite a bit
of work. Similarly, programming a reduction is often trivial, while
programming a learning algorithm is a great deal of work.Crystallization. The
problems we often want to solve in learning are worst-case-impossible, but
average case feasible. By reducing all problems onto one or a few primitives,
we can fine tune these primitives to perform well on real-world problems with
greater precision due to the greater number of problems to validate
on.Theoretical Organization. By studying what reductions are easy vs. hard vs.
impossible, we can learn which problems are roughly equivalent in difficulty
and which are much harder.What we know now.Typesafe reductions. In the
beginning, there was th</p><p>4 0.67443818 <a title="103-lsi-4" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>Introduction: At an intuitive level, the question here is "Can reinforcement learning be
solved with classification?"ProblemConstruct a reinforcement learning
algorithm with near-optimal expected sum of rewards in thedirect experience
modelgiven access to a classifier learning algorithm which has a small error
rate or regret on all posed classification problems. The definition of "posed"
here is slightly murky. I consider a problem "posed" if there is an algorithm
for constructing labeled classification examples.Past WorkThere exists
areduction of reinforcement learning to classification given a generative
model.A generative model is an inherently stronger assumption than the direct
experience model.Otherwork on learning reductionsmay be important.Several
algorithms for solving reinforcement learning in the direct experience model
exist. Most, such asE3,Factored-E3, andmetric-E3andRmaxrequire that the
observation be the state. Recent workextends this approach to POMDPs.This
problem is related topred</p><p>5 0.62747967 <a title="103-lsi-5" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>Introduction: At NIPS I'm giving atutorial on Learning to Interact. In essence this is about
dealing with causality in a contextual bandit framework. Relative toprevious
tutorials, I'll be covering several new results that changed my understanding
of the nature of the problem. Note thatJudea PearlandElias Bareinboimhave
atutorial on causality. This might appear similar, but is quite different in
practice. Pearl and Bareinboim's tutorial will be about the general concepts
while mine will be about total mastery of the simplest nontrivial case,
including code. Luckily, they have the right order. I recommend going to bothI
also just released version 7.4 ofVowpal Wabbit. When I was a frustrated
learning theorist, I did not understand why people were not using learning
reductions to solve problems. I've been slowly discovering why with VW, and
addressing the issues. One of the issues is that machine learning itself was
not automatic enough, while another is that creating a very low overhead
process for do</p><p>6 0.60334557 <a title="103-lsi-6" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>7 0.60242343 <a title="103-lsi-7" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>8 0.59812784 <a title="103-lsi-8" href="../hunch_net-2012/hunch_net-2012-09-29-Vowpal_Wabbit%2C_version_7.0.html">473 hunch net-2012-09-29-Vowpal Wabbit, version 7.0</a></p>
<p>9 0.57550639 <a title="103-lsi-9" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>10 0.55538136 <a title="103-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-12-ROC_vs._Accuracy_vs._AROC.html">18 hunch net-2005-02-12-ROC vs. Accuracy vs. AROC</a></p>
<p>11 0.55426693 <a title="103-lsi-11" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>12 0.55228204 <a title="103-lsi-12" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>13 0.53939033 <a title="103-lsi-13" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>14 0.52770936 <a title="103-lsi-14" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>15 0.51345474 <a title="103-lsi-15" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>16 0.5049113 <a title="103-lsi-16" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>17 0.49276143 <a title="103-lsi-17" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>18 0.48998114 <a title="103-lsi-18" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>19 0.48599854 <a title="103-lsi-19" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>20 0.46522611 <a title="103-lsi-20" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.051), (42, 0.252), (45, 0.057), (68, 0.121), (74, 0.13), (85, 0.279), (95, 0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.91928226 <a title="103-lda-1" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>Introduction: TheNew York Machine Learning Symposiumis October 19 with a 2 page abstract
deadline due September 13 via email with subject "Machine Learning Poster
Submission" sent to physicalscience@nyas.org. Everyone is welcome to submit.
Last year's attendance was 246 and I expect more this year.The primary
experiment forICML 2013is multiple paper submission deadlines with rolling
review cycles. The key dates are October 1, December 15, and February 15. This
is an attempt to shift ICML further towards a journal style review process and
reduce peak load. The "not for proceedings" experiment from this year's ICML
is not continuing.Edit: Fixed second ICML deadline.</p><p>same-blog 2 0.9036479 <a title="103-lda-2" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to
handle several large family loss functions.This is a good thing because it is
implausible that thelossfunction imposed by the world can not be taken into
account in the process of solving a prediction problem. Even people used to
the hard-coreBayesianapproach to learning often note that some approximations
are almost inevitable in specifying apriorand/or integrating to achieve a
posterior. Taking into account how the system will be evaluated can allow both
computational effort and design effort to be focused so as to improve
performance.A current laundry list of capabilities includes:2002multiclass SVM
including arbitrary cost matricesICML 2003Hidden Markov ModelsNIPS 2003Markov
Networks(see somediscussion)EMNLP 2004Context free grammarsICML 2004Any loss
(with much computation)ICML 2005Anyconstrained linear prediction model(that's
my own name).ICML 2005Any loss dependent on a contingency tableI am personally
in</p><p>3 0.89358699 <a title="103-lda-3" href="../hunch_net-2008/hunch_net-2008-08-04-Electoralmarkets.com.html">312 hunch net-2008-08-04-Electoralmarkets.com</a></p>
<p>Introduction: Lancereminded me aboutelectoralmarketstoday, which is cool enough that I want
to point it out explicitly here.Most people stilluse pollsto predict who wins,
while electoralmarkets uses people betting real money. They might use polling
information, but any other sources of information are implicitly also allowed.
A side-by-side comparison of how polls compare to prediction markets might be
fun in a few months.</p><p>4 0.89332783 <a title="103-lda-4" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner
independent of the loss function itself.Optimizing squared
losslsq(y,y')=(y-y')2means predicting the (conditional) mean ofy.Optimizing
absolute value losslav(y,y')=|y-y'|means predicting the (conditional) median
ofy. Variants canhandle other quantiles. 0/1 loss for classification is a
special case.Optimizing log lossllog(y,y')=log (1/Prz~y'(z=y))means minimizing
the description length ofy.The semantics (= meaning) of the loss are made
explicit by a theorem in each case. For squared loss, we can prove a theorem
of the form:For all distributionsDoverY, ify' = arg miny'Ey ~ Dlsq(y,y')theny'
= Ey~DySimilar theorems hold for the other examples above, and they can all be
extended to predictors ofy'for distributionsDover a contextXand a valueY.There
are 3 points to this post.Everyone doing general machine learning should be
aware of the laundry list above. They form a handy toolkit which can match
many of the problems nat</p><p>5 0.78072172 <a title="103-lda-5" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>Introduction: The 2006 Machine Learning Summer School in Taipei, Taiwan ended on August 4,
2006. It has been a very exciting two weeks for a record crowd of 245
participants (including speakers and organizers) from 18 countries. We had a
lineup of speakers that is hard to match up for other similar events (see
ourWIKIfor more information). With this lineup, it is difficult for us as
organizers to screw it up too bad. Also, since we have pretty good
infrastructure for international meetings and experienced staff at NTUST and
Academia Sinica, plus the reputation established by previous MLSS series, it
was relatively easy for us to attract registrations and simply enjoyed this
two-week long party of machine learning.In the end of MLSS we distributed a
survey form for participants to fill in. I will report what we found from this
survey, together with the registration data and word-of-mouth from
participants.The first question is designed to find out how our participants
learned about MLSS 2006 Taipei.</p><p>6 0.73703784 <a title="103-lda-6" href="../hunch_net-2010/hunch_net-2010-08-23-Boosted_Decision_Trees_for_Deep_Learning.html">407 hunch net-2010-08-23-Boosted Decision Trees for Deep Learning</a></p>
<p>7 0.73357129 <a title="103-lda-7" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>8 0.72206837 <a title="103-lda-8" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>9 0.71898377 <a title="103-lda-9" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>10 0.71883923 <a title="103-lda-10" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>11 0.7187838 <a title="103-lda-11" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>12 0.71867913 <a title="103-lda-12" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>13 0.71736169 <a title="103-lda-13" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>14 0.71647125 <a title="103-lda-14" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>15 0.71629107 <a title="103-lda-15" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>16 0.71534878 <a title="103-lda-16" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>17 0.71533245 <a title="103-lda-17" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>18 0.71387196 <a title="103-lda-18" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>19 0.71346301 <a title="103-lda-19" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>20 0.71300727 <a title="103-lda-20" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
