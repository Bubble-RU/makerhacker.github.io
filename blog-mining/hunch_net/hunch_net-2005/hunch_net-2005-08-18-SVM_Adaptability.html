<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>103 hunch net-2005-08-18-SVM Adaptability</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-103" href="#">hunch_net-2005-103</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>103 hunch net-2005-08-18-SVM Adaptability</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-103-html" href="http://hunch.net/?p=110">html</a></p><p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to handle several large family loss functions.
 
This is a good thing because it is implausible that the  loss  function imposed by the world can not be taken into account in the process of solving a prediction problem.  Even people used to the hard-core  Bayesian  approach to learning often note that some approximations are almost inevitable in specifying a  prior  and/or integrating to achieve a posterior.  Taking into account how the system will be evaluated can allow both computational effort and design effort to be focused so as to improve performance.
 
A current laundry list of capabilities includes:
  
 2002  multiclass SVM including arbitrary cost matrices  
  ICML 2003   Hidden Markov Models  
  NIPS 2003   Markov Networks  (see some  discussion ) 
  EMNLP 2004   Context free grammars  
  ICML 2004   Any loss (with much computation)  
  ICML 2005  Any  constrained linear prediction model  (thatâ&euro;&trade;s my own</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Several recent papers have shown that SVM-like optimizations can be used to handle several large family loss functions. [sent-1, score-0.501]
</p><p>2 This is a good thing because it is implausible that the  loss  function imposed by the world can not be taken into account in the process of solving a prediction problem. [sent-2, score-0.573]
</p><p>3 Even people used to the hard-core  Bayesian  approach to learning often note that some approximations are almost inevitable in specifying a  prior  and/or integrating to achieve a posterior. [sent-3, score-0.402]
</p><p>4 Taking into account how the system will be evaluated can allow both computational effort and design effort to be focused so as to improve performance. [sent-4, score-0.409]
</p><p>5 ICML 2005   Any loss dependent on a contingency table      I am personally interested in how this relates to the  learning reductions  work which has similar goals, but works at a different abstraction level (the learning problem rather than algorithmic mechanism). [sent-6, score-0.915]
</p><p>6 The difference in abstraction implies that anything solvable by reduction should be solvable by a direct algorithmic mechanism. [sent-7, score-1.559]
</p><p>7 However, comparing and constrasting the results I know of it seems that what is solvable via reduction to classification versus what is solvable via direct SVM-like methods is currently incomparable. [sent-8, score-1.888]
</p><p>8 Can SVMs be tuned to directly solve (example dependent) cost sensitive classification? [sent-9, score-0.518]
</p><p>9 Obviously, they can be tuned indirectly via  reduction , but it is easy to imagine more tractable direct optimizations. [sent-10, score-0.786]
</p><p>10 How efficiently can learning reductions be used to solve structured prediction problems? [sent-11, score-0.753]
</p><p>11 Structured prediction problems are instances of cost sensitive classification, but the regret transform efficiency which occurs when this embedding is done is too weak to be of interest. [sent-12, score-0.8]
</p><p>12 Are there any problems efficiently solvable by SVM-like algorithms which are   not  efficiently solvable via learning reductions? [sent-13, score-1.472]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('solvable', 0.459), ('direct', 0.2), ('efficiently', 0.197), ('tuned', 0.169), ('loss', 0.168), ('via', 0.16), ('abstraction', 0.158), ('reduction', 0.152), ('reductions', 0.147), ('cost', 0.144), ('sensitive', 0.131), ('algorithmic', 0.131), ('icml', 0.131), ('prediction', 0.13), ('classification', 0.129), ('dependent', 0.129), ('markov', 0.124), ('structured', 0.119), ('account', 0.112), ('embedding', 0.105), ('grammars', 0.105), ('emnlp', 0.105), ('evaluated', 0.105), ('indirectly', 0.105), ('laundry', 0.105), ('relates', 0.098), ('effort', 0.096), ('implausible', 0.092), ('versus', 0.092), ('optimizations', 0.088), ('matrices', 0.088), ('used', 0.086), ('capabilities', 0.084), ('table', 0.084), ('approximations', 0.084), ('family', 0.084), ('inevitable', 0.084), ('constrained', 0.081), ('integrating', 0.079), ('svms', 0.077), ('transform', 0.077), ('comparing', 0.077), ('efficiency', 0.075), ('shown', 0.075), ('solve', 0.074), ('svm', 0.073), ('imposed', 0.071), ('occurs', 0.069), ('instances', 0.069), ('specifying', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="103-tfidf-1" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to handle several large family loss functions.
 
This is a good thing because it is implausible that the  loss  function imposed by the world can not be taken into account in the process of solving a prediction problem.  Even people used to the hard-core  Bayesian  approach to learning often note that some approximations are almost inevitable in specifying a  prior  and/or integrating to achieve a posterior.  Taking into account how the system will be evaluated can allow both computational effort and design effort to be focused so as to improve performance.
 
A current laundry list of capabilities includes:
  
 2002  multiclass SVM including arbitrary cost matrices  
  ICML 2003   Hidden Markov Models  
  NIPS 2003   Markov Networks  (see some  discussion ) 
  EMNLP 2004   Context free grammars  
  ICML 2004   Any loss (with much computation)  
  ICML 2005  Any  constrained linear prediction model  (thatâ&euro;&trade;s my own</p><p>2 0.23427191 <a title="103-tfidf-2" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>Introduction: At an intuitive level, the question here is “Can reinforcement learning be solved with classification?”  
 
 Problem  Construct a reinforcement learning algorithm with near-optimal expected sum of rewards in the  direct experience model  given access to a classifier learning algorithm which has a small error rate or regret on all posed classification problems.  The definition of “posed” here is slightly murky.  I consider a problem “posed” if there is an algorithm for constructing labeled classification examples.
 
 Past Work 
  
 There exists a  reduction of reinforcement learning to classification given a generative model.   A generative model is an inherently stronger assumption than the direct experience model. 
 Other  work on learning reductions  may be important. 
 Several algorithms for solving reinforcement learning in the direct experience model exist.  Most, such as  E 3  ,  Factored-E 3  , and  metric-E 3   and  Rmax  require that the observation be the state.  Recent work</p><p>3 0.21136203 <a title="103-tfidf-3" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for the  reductions tutorial   Alina ,  Bianca , and I are planning to do at  ICML .  Please come, if you are interested.
 
Many research programs can be thought of as finding and building new useful abstractions.  The running example I’ll use is  learning reductions  where I have experience.  The basic abstraction here is that we can build a learning algorithm capable of solving classification problems up to a small expected regret.   This is used repeatedly to solve more complex problems.
 
In working on a new abstraction, I think you typically run into many substantial problems of understanding, which make publishing particularly difficult.
  
 It is difficult to seriously discuss the reason behind or mechanism for abstraction in a conference paper with small page limits.  People rarely see such discussions and hence have little basis on which to think about new abstractions.    Another difficulty is that when building an abstraction, yo</p><p>4 0.1923151 <a title="103-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?  Reductions are machines which turn solvers for one problem into solvers for another problem. 
 Why?  Reductions are useful for several reasons.
  
  Laziness .  Reducing a problem to classification make at least 10 learning algorithms available to solve a problem.  Inventing 10 learning algorithms is quite a bit of work.  Similarly, programming a reduction is often trivial, while programming a learning algorithm is a great deal of work. 
  Crystallization .  The problems we often want to solve in learning are worst-case-impossible, but average case feasible.  By reducing all problems onto one or a few primitives, we can fine tune these primitives to perform well on real-world problems with greater precision due to the greater number of problems to validate on. 
  Theoretical Organization .  By studying what reductions are easy vs. hard vs. impossible, we can learn which problems are roughly equivalent in difficulty and which are much harder. 
  
 What we know now .
 
 Typesafe r</p><p>5 0.18430567 <a title="103-tfidf-5" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a data source (Example:  X x {0,1} ,  X x [0,1] ,  X x {1,2,3,4,5} , etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…).  For simplicity, we’ll assume that all losses have a minimum of zero.
 
For this post, we can think of a learning reduction as
  
 A mapping  R  from samples of one type  T  (like multiclass classification) to another type  T’  (like binary classification). 
 A mapping  Q  from predictors for type  T’  to predictors for type  T . 
  
The simplest sort of learning reduction is a “loss reduction”.  The idea in a loss reduction is to prove a statement of the form: 
 Theorem  For all base predictors  b , for all distributions  D  over examples of type  T : 
  E (x,y) ~ D  L T (y,Q(b,x)) <= f(E (x’,y’)~R(D)  L T’ (y’,b(x’)))   
Here  L T   is the loss for the type  T  problem and  L T’   is the loss for the type  T’  problem.  Also,  R(D)  is the distribution ov</p><p>6 0.18129936 <a title="103-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>7 0.17036575 <a title="103-tfidf-7" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>8 0.1606624 <a title="103-tfidf-8" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>9 0.14762935 <a title="103-tfidf-9" href="../hunch_net-2012/hunch_net-2012-09-29-Vowpal_Wabbit%2C_version_7.0.html">473 hunch net-2012-09-29-Vowpal Wabbit, version 7.0</a></p>
<p>10 0.14028075 <a title="103-tfidf-10" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>11 0.14014785 <a title="103-tfidf-11" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>12 0.13970149 <a title="103-tfidf-12" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>13 0.12782763 <a title="103-tfidf-13" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>14 0.12530644 <a title="103-tfidf-14" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>15 0.11644853 <a title="103-tfidf-15" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>16 0.11172328 <a title="103-tfidf-16" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>17 0.10939547 <a title="103-tfidf-17" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>18 0.10696791 <a title="103-tfidf-18" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>19 0.10440481 <a title="103-tfidf-19" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<p>20 0.1041511 <a title="103-tfidf-20" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.231), (1, 0.123), (2, 0.077), (3, -0.125), (4, -0.108), (5, 0.034), (6, 0.05), (7, -0.025), (8, -0.046), (9, -0.017), (10, -0.076), (11, -0.156), (12, -0.143), (13, 0.1), (14, 0.038), (15, 0.072), (16, 0.049), (17, -0.031), (18, -0.007), (19, -0.095), (20, 0.027), (21, -0.117), (22, -0.035), (23, -0.039), (24, -0.055), (25, 0.014), (26, -0.069), (27, 0.038), (28, 0.015), (29, 0.105), (30, 0.116), (31, 0.002), (32, 0.014), (33, -0.084), (34, -0.022), (35, 0.055), (36, -0.022), (37, -0.011), (38, 0.01), (39, 0.077), (40, -0.014), (41, 0.015), (42, -0.077), (43, -0.004), (44, 0.089), (45, -0.036), (46, -0.021), (47, 0.027), (48, -0.102), (49, 0.048)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97873354 <a title="103-lsi-1" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to handle several large family loss functions.
 
This is a good thing because it is implausible that the  loss  function imposed by the world can not be taken into account in the process of solving a prediction problem.  Even people used to the hard-core  Bayesian  approach to learning often note that some approximations are almost inevitable in specifying a  prior  and/or integrating to achieve a posterior.  Taking into account how the system will be evaluated can allow both computational effort and design effort to be focused so as to improve performance.
 
A current laundry list of capabilities includes:
  
 2002  multiclass SVM including arbitrary cost matrices  
  ICML 2003   Hidden Markov Models  
  NIPS 2003   Markov Networks  (see some  discussion ) 
  EMNLP 2004   Context free grammars  
  ICML 2004   Any loss (with much computation)  
  ICML 2005  Any  constrained linear prediction model  (thatâ&euro;&trade;s my own</p><p>2 0.69402146 <a title="103-lsi-2" href="../hunch_net-2012/hunch_net-2012-09-29-Vowpal_Wabbit%2C_version_7.0.html">473 hunch net-2012-09-29-Vowpal Wabbit, version 7.0</a></p>
<p>Introduction: A new version of  VW  is  out .  The primary changes are:
  
  Learning Reductions : I’ve wanted to get  learning reductions  working and we’ve finally done it.  Not everything is implemented yet, but VW now supports direct:
 
 Multiclass Classification  –oaa  or  –ect . 
 Cost Sensitive Multiclass Classification  –csoaa  or  –wap . 
 Contextual Bandit Classification  –cb . 
 Sequential Structured Prediction   –searn  or  –dagger  
 

In addition, it is now easy to build your own custom learning reductions for various plausible uses: feature diddling, custom structured prediction problems, or alternate learning reductions.  This effort is far from done, but it is now in a generally useful state.  Note that all learning reductions inherit the ability to do cluster parallel learning.

 
  Library interface :  VW now has a basic library interface.  The library provides most of the functionality of VW, with the limitation that it is monolithic and nonreentrant.  These will be improved over</p><p>3 0.68645138 <a title="103-lsi-3" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a data source (Example:  X x {0,1} ,  X x [0,1] ,  X x {1,2,3,4,5} , etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…).  For simplicity, we’ll assume that all losses have a minimum of zero.
 
For this post, we can think of a learning reduction as
  
 A mapping  R  from samples of one type  T  (like multiclass classification) to another type  T’  (like binary classification). 
 A mapping  Q  from predictors for type  T’  to predictors for type  T . 
  
The simplest sort of learning reduction is a “loss reduction”.  The idea in a loss reduction is to prove a statement of the form: 
 Theorem  For all base predictors  b , for all distributions  D  over examples of type  T : 
  E (x,y) ~ D  L T (y,Q(b,x)) <= f(E (x’,y’)~R(D)  L T’ (y’,b(x’)))   
Here  L T   is the loss for the type  T  problem and  L T’   is the loss for the type  T’  problem.  Also,  R(D)  is the distribution ov</p><p>4 0.63351929 <a title="103-lsi-4" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>Introduction: At an intuitive level, the question here is “Can reinforcement learning be solved with classification?”  
 
 Problem  Construct a reinforcement learning algorithm with near-optimal expected sum of rewards in the  direct experience model  given access to a classifier learning algorithm which has a small error rate or regret on all posed classification problems.  The definition of “posed” here is slightly murky.  I consider a problem “posed” if there is an algorithm for constructing labeled classification examples.
 
 Past Work 
  
 There exists a  reduction of reinforcement learning to classification given a generative model.   A generative model is an inherently stronger assumption than the direct experience model. 
 Other  work on learning reductions  may be important. 
 Several algorithms for solving reinforcement learning in the direct experience model exist.  Most, such as  E 3  ,  Factored-E 3  , and  metric-E 3   and  Rmax  require that the observation be the state.  Recent work</p><p>5 0.63326526 <a title="103-lsi-5" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductions  transform a solver of one type of learning problem into a solver of another type of learning problem.  When we analyze these for robustness we can make statement of the form “Reduction  R  has the property that regret  r  (or loss) on subproblems of type  A  implies regret at most   f ( r )  on the original problem of type  B “.
 
A lower bound for a learning reduction would have the form “for all reductions  R , there exists a learning problem of type  B  and learning algorithm for problems of type  A  where regret  r  on induced problems implies  at least  regret  f ( r )  for  B “.
 
The pursuit of lower bounds is often questionable because, unlike upper bounds, they do not yield practical algorithms.  Nevertheless, they may be helpful as a tool for thinking about what is learnable and how learnable it is.  This has already come up  here  and  here .
 
At the moment, there is no coherent theory of lower bounds for learning reductions, and we have little understa</p><p>6 0.62693697 <a title="103-lsi-6" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>7 0.58785003 <a title="103-lsi-7" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>8 0.577739 <a title="103-lsi-8" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>9 0.57205373 <a title="103-lsi-9" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>10 0.56609201 <a title="103-lsi-10" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>11 0.55421191 <a title="103-lsi-11" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>12 0.51156908 <a title="103-lsi-12" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>13 0.5105111 <a title="103-lsi-13" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>14 0.5059703 <a title="103-lsi-14" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>15 0.50557482 <a title="103-lsi-15" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>16 0.45902276 <a title="103-lsi-16" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>17 0.45872051 <a title="103-lsi-17" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>18 0.45487562 <a title="103-lsi-18" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<p>19 0.44999579 <a title="103-lsi-19" href="../hunch_net-2005/hunch_net-2005-09-20-Workshop_Proposal%3A_Atomic_Learning.html">114 hunch net-2005-09-20-Workshop Proposal: Atomic Learning</a></p>
<p>20 0.4460153 <a title="103-lsi-20" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.257), (38, 0.079), (53, 0.081), (55, 0.079), (77, 0.02), (91, 0.304), (94, 0.07), (95, 0.02)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.90139943 <a title="103-lda-1" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to handle several large family loss functions.
 
This is a good thing because it is implausible that the  loss  function imposed by the world can not be taken into account in the process of solving a prediction problem.  Even people used to the hard-core  Bayesian  approach to learning often note that some approximations are almost inevitable in specifying a  prior  and/or integrating to achieve a posterior.  Taking into account how the system will be evaluated can allow both computational effort and design effort to be focused so as to improve performance.
 
A current laundry list of capabilities includes:
  
 2002  multiclass SVM including arbitrary cost matrices  
  ICML 2003   Hidden Markov Models  
  NIPS 2003   Markov Networks  (see some  discussion ) 
  EMNLP 2004   Context free grammars  
  ICML 2004   Any loss (with much computation)  
  ICML 2005  Any  constrained linear prediction model  (thatâ&euro;&trade;s my own</p><p>2 0.86926252 <a title="103-lda-2" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>Introduction: Machine learning is often computationally bounded which implies that the ability to write fast code becomes important if you ever want to implement a machine learning algorithm.  Basic tactical optimizations are covered well  elsewhere , but I haven’t seen a reasonable guide to higher level optimizations, which are the most important in my experience.  Here are some of the higher level optimizations I’ve often found useful.
  
  Algorithmic Improvement First . This is Hard, but it is the most important consideration, and typically yields the most benefits.  Good optimizations here are publishable.  In the context of machine learning, you should be familiar with the arguments for online vs. batch learning. 
  Choice of Language . There are many arguments about the  choice of language .  Sometimes you don’t have a choice when interfacing with other people.  Personally, I favor C/C++ when I want to write fast code.  This (admittedly) makes me a slower programmer than when using higher lev</p><p>3 0.6967504 <a title="103-lda-3" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>Introduction: Rich Caruana ,  Alexandru Niculescu , Geoff Crew, and Alex Ksikes have done  a lot of empirical testing  which shows that  using all methods to make a prediction  is more powerful than using any single method.  This is in rough agreement with the Bayesian way of solving problems, but based upon a different (essentially empirical) motivation.  A rough summary is:
  
 Take all of {decision trees, boosted decision trees, bagged decision trees, boosted decision stumps, K nearest neighbors, neural networks, SVM} with all reasonable parameter settings. 
 Run the methods on each problem of 8 problems with a large test set, calibrating margins using either  sigmoid fitting  or  isotonic regression . 
 For each loss of {accuracy, area under the ROC curve, cross entropy, squared error, etc…} evaluate the average performance of the method. 
  
A series of conclusions can be drawn from the observations.
  
 ( Calibrated ) boosted decision trees appear to perform best, in general although support v</p><p>4 0.68953943 <a title="103-lda-4" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?  Reductions are machines which turn solvers for one problem into solvers for another problem. 
 Why?  Reductions are useful for several reasons.
  
  Laziness .  Reducing a problem to classification make at least 10 learning algorithms available to solve a problem.  Inventing 10 learning algorithms is quite a bit of work.  Similarly, programming a reduction is often trivial, while programming a learning algorithm is a great deal of work. 
  Crystallization .  The problems we often want to solve in learning are worst-case-impossible, but average case feasible.  By reducing all problems onto one or a few primitives, we can fine tune these primitives to perform well on real-world problems with greater precision due to the greater number of problems to validate on. 
  Theoretical Organization .  By studying what reductions are easy vs. hard vs. impossible, we can learn which problems are roughly equivalent in difficulty and which are much harder. 
  
 What we know now .
 
 Typesafe r</p><p>5 0.68870473 <a title="103-lda-5" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>Introduction: Given John’s recent posts on CMU’s new machine learning department and “Deep Learning,” I asked for an opportunity to give a computational learning theory perspective on these issues.
 
To my mind, the answer to the question “Are the core problems from machine learning different from the core problems of statistics?” is a clear Yes.  The point of this post is to describe a core problem in machine learning that is computational in nature and will appeal to statistical learning folk (as an extreme example note that if P=NP– which, for all we know, is true– then we would suddenly find almost all of our favorite machine learning problems considerably more tractable).
 
If the central question of statistical learning theory were crudely summarized as “given a hypothesis with a certain loss bound over a test set, how well will it generalize?” then the central question of computational learning theory might be “how can we find such a hypothesis efficently (e.g., in polynomial-time)?”
 
With t</p><p>6 0.68822795 <a title="103-lda-6" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>7 0.68643379 <a title="103-lda-7" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>8 0.6863448 <a title="103-lda-8" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>9 0.68485284 <a title="103-lda-9" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>10 0.68426323 <a title="103-lda-10" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>11 0.68327534 <a title="103-lda-11" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>12 0.68220431 <a title="103-lda-12" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>13 0.6816839 <a title="103-lda-13" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>14 0.68063408 <a title="103-lda-14" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>15 0.68061841 <a title="103-lda-15" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>16 0.68006897 <a title="103-lda-16" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>17 0.67876762 <a title="103-lda-17" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>18 0.67813551 <a title="103-lda-18" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>19 0.67598385 <a title="103-lda-19" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>20 0.67567176 <a title="103-lda-20" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
