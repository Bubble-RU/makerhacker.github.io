<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>108 hunch net-2005-09-06-A link</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-108" href="#">hunch_net-2005-108</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>108 hunch net-2005-09-06-A link</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-108-html" href="http://hunch.net/?p=116">html</a></p><p>Introduction: I read through some of the essays of  Michael Nielsen  today, and recommend them.   Principles of Effective Research  and  Extreme Thinking  are both relevant to several discussions here.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I read through some of the essays of  Michael Nielsen  today, and recommend them. [sent-1, score-0.921]
</p><p>2 Principles of Effective Research  and  Extreme Thinking  are both relevant to several discussions here. [sent-2, score-0.536]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('essays', 0.421), ('nielsen', 0.421), ('principles', 0.351), ('today', 0.298), ('recommend', 0.291), ('discussions', 0.272), ('michael', 0.241), ('extreme', 0.228), ('read', 0.209), ('effective', 0.192), ('thinking', 0.185), ('relevant', 0.183), ('research', 0.093), ('several', 0.081)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="108-tfidf-1" href="../hunch_net-2005/hunch_net-2005-09-06-A_link.html">108 hunch net-2005-09-06-A link</a></p>
<p>Introduction: I read through some of the essays of  Michael Nielsen  today, and recommend them.   Principles of Effective Research  and  Extreme Thinking  are both relevant to several discussions here.</p><p>2 0.30598086 <a title="108-tfidf-2" href="../hunch_net-2009/hunch_net-2009-01-28-Nielsen%26%238217%3Bs_talk.html">340 hunch net-2009-01-28-Nielsen&#8217;s talk</a></p>
<p>Introduction: I wanted to point to   Michael Nielsenâ&euro;&trade;s talk  about blogging science, which I found interesting.</p><p>3 0.099438258 <a title="108-tfidf-3" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect the  NIPS 2006 workshops  to be quite interesting, and recommend going for anyone interested in machine learning research.  (Most or all of the workshops webpages can be found two links deep.)</p><p>4 0.079652853 <a title="108-tfidf-4" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>Introduction: I tweaked the site in a number of ways today, including:
  
 Updating to  WordPress  1.5. 
 Installing and heavily tweaking the  Geekniche  theme.  Update: I switched back to a tweaked version of the old theme. 
 Adding the  Customizable Post Listings  plugin. 
 Installing the  StatTraq  plugin. 
 Updating some of the links.  I particularly recommend looking at the  computer research policy  blog. 
 Adding  threaded comments .  This doesn’t thread old comments obviously, but the extra structure may be helpful for new ones. 
  
Overall, I think this is an improvement, and it addresses a few of my  earlier problems .  If you have any difficulties or anything seems “not quite right”, please speak up.  A few other tweaks to the site may happen in the near future.</p><p>5 0.071457595 <a title="108-tfidf-5" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>Introduction: Machine Learning is a field with an impressively diverse set of reseearch styles.  Understanding this may be important in appreciating what you see at a conference.
  
  Engineering . How can I solve this problem?  People in the engineering research style try to solve hard problems directly by any means available and then describe how they did it.  This is typical of problem-specific conferences and communities. 
  Scientific . What are the principles for solving learning problems? People in this research style test techniques on many different problems.  This is fairly common at ICML and NIPS. 
  Mathematical . How can the learning problem be mathematically understood?  People in this research style prove theorems with implications for learning but often do not implement (or test algorithms).  COLT is a typical conference for this style. 
  
Many people manage to cross these styles, and that is often beneficial.  
 
Whenver we list a set of alternative, it becomes natural to think â&euro;&oelig;wh</p><p>6 0.071138546 <a title="108-tfidf-6" href="../hunch_net-2005/hunch_net-2005-05-29-Bad_ideas.html">76 hunch net-2005-05-29-Bad ideas</a></p>
<p>7 0.06878072 <a title="108-tfidf-7" href="../hunch_net-2005/hunch_net-2005-09-20-Workshop_Proposal%3A_Atomic_Learning.html">114 hunch net-2005-09-20-Workshop Proposal: Atomic Learning</a></p>
<p>8 0.066222727 <a title="108-tfidf-8" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>9 0.060671244 <a title="108-tfidf-9" href="../hunch_net-2012/hunch_net-2012-12-29-Simons_Institute_Big_Data_Program.html">476 hunch net-2012-12-29-Simons Institute Big Data Program</a></p>
<p>10 0.053128403 <a title="108-tfidf-10" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>11 0.052321594 <a title="108-tfidf-11" href="../hunch_net-2007/hunch_net-2007-07-13-The_View_From_China.html">255 hunch net-2007-07-13-The View From China</a></p>
<p>12 0.05195193 <a title="108-tfidf-12" href="../hunch_net-2010/hunch_net-2010-09-28-Machined_Learnings.html">412 hunch net-2010-09-28-Machined Learnings</a></p>
<p>13 0.050793968 <a title="108-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>14 0.050611243 <a title="108-tfidf-14" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>15 0.049203746 <a title="108-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>16 0.047965668 <a title="108-tfidf-16" href="../hunch_net-2010/hunch_net-2010-04-28-CI_Fellows_program_renewed.html">396 hunch net-2010-04-28-CI Fellows program renewed</a></p>
<p>17 0.047873564 <a title="108-tfidf-17" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>18 0.047825541 <a title="108-tfidf-18" href="../hunch_net-2008/hunch_net-2008-08-04-Electoralmarkets.com.html">312 hunch net-2008-08-04-Electoralmarkets.com</a></p>
<p>19 0.045918431 <a title="108-tfidf-19" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>20 0.045640871 <a title="108-tfidf-20" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.054), (1, -0.027), (2, -0.042), (3, 0.039), (4, -0.019), (5, 0.026), (6, 0.036), (7, 0.011), (8, 0.015), (9, 0.041), (10, 0.033), (11, -0.004), (12, -0.069), (13, -0.022), (14, -0.002), (15, -0.039), (16, -0.033), (17, 0.033), (18, -0.002), (19, -0.036), (20, -0.008), (21, -0.004), (22, -0.02), (23, -0.039), (24, 0.001), (25, -0.058), (26, -0.047), (27, 0.004), (28, -0.034), (29, -0.064), (30, -0.061), (31, 0.062), (32, -0.037), (33, -0.033), (34, 0.063), (35, 0.106), (36, -0.071), (37, 0.083), (38, -0.084), (39, -0.014), (40, 0.068), (41, 0.181), (42, -0.019), (43, 0.098), (44, 0.077), (45, 0.047), (46, 0.031), (47, -0.017), (48, 0.02), (49, 0.068)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96519125 <a title="108-lsi-1" href="../hunch_net-2005/hunch_net-2005-09-06-A_link.html">108 hunch net-2005-09-06-A link</a></p>
<p>Introduction: I read through some of the essays of  Michael Nielsen  today, and recommend them.   Principles of Effective Research  and  Extreme Thinking  are both relevant to several discussions here.</p><p>2 0.80032021 <a title="108-lsi-2" href="../hunch_net-2009/hunch_net-2009-01-28-Nielsen%26%238217%3Bs_talk.html">340 hunch net-2009-01-28-Nielsen&#8217;s talk</a></p>
<p>Introduction: I wanted to point to   Michael Nielsenâ&euro;&trade;s talk  about blogging science, which I found interesting.</p><p>3 0.4731189 <a title="108-lsi-3" href="../hunch_net-2008/hunch_net-2008-07-02-Proprietary_Data_in_Academic_Research%3F.html">306 hunch net-2008-07-02-Proprietary Data in Academic Research?</a></p>
<p>Introduction: Should results of experiments on proprietary datasets be in the academic research literature?
 
The arguments I can imagine in the “against” column are: 
  
  Experiments are not repeatable.  Repeatability in experiments is essential to science because it allows others to compare new methods with old and discover which is better. 
  It’s unfair.  Academics who don’t have insider access to proprietary data are at a substantial disadvantage when competing with others who do. 
  
I’m unsympathetic to argument (2).  To me, it looks like their are simply some resource constraints, and these should not prevent research progress.  For example, we wouldn’t prevent publishing about particle accelerator experiments by physicists at  CERN  because physicists at  CMU  couldn’t run their own experiments.  
 
Argument (1) seems like a real issue.
 
The argument for is: 
  
 Yes, they are another form of evidence that an algorithm is good. The degree to which they are evidence is less than for public</p><p>4 0.45943978 <a title="108-lsi-4" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>Introduction: I tweaked the site in a number of ways today, including:
  
 Updating to  WordPress  1.5. 
 Installing and heavily tweaking the  Geekniche  theme.  Update: I switched back to a tweaked version of the old theme. 
 Adding the  Customizable Post Listings  plugin. 
 Installing the  StatTraq  plugin. 
 Updating some of the links.  I particularly recommend looking at the  computer research policy  blog. 
 Adding  threaded comments .  This doesn’t thread old comments obviously, but the extra structure may be helpful for new ones. 
  
Overall, I think this is an improvement, and it addresses a few of my  earlier problems .  If you have any difficulties or anything seems “not quite right”, please speak up.  A few other tweaks to the site may happen in the near future.</p><p>5 0.45797661 <a title="108-lsi-5" href="../hunch_net-2008/hunch_net-2008-04-21-The_Science_2.0_article.html">296 hunch net-2008-04-21-The Science 2.0 article</a></p>
<p>Introduction: I found the article about  science using modern tools interesting , especially the part about ‘blogophobia’, which in my experience is often a substantial issue: many potential guest posters aren’t quite ready, because of the fear of a permanent public mistake, because it is particularly hard to write about the unknown (the essence of research), and because the system for public credit doesn’t yet really handle blog posts.
 
So far, science has been relatively resistant to discussing research on blogs.  Some things need to change to get there.  Public tolerance of the occasional mistake is essential, as is a willingness to cite (and credit) blogs as freely as papers.  
 
I’ve often run into another reason for holding back myself: I don’t want to overtalk my own research.  Nevertheless, I’m slowly changing to the opinion that I’m holding back too much: the real power of a blog in research is that it can be used to confer with many people, and that just makes research work better.</p><p>6 0.42982665 <a title="108-lsi-6" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>7 0.40233096 <a title="108-lsi-7" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>8 0.37277722 <a title="108-lsi-8" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>9 0.3711614 <a title="108-lsi-9" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>10 0.37050602 <a title="108-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>11 0.35169679 <a title="108-lsi-11" href="../hunch_net-2006/hunch_net-2006-05-21-NIPS_paper_evaluation_criteria.html">180 hunch net-2006-05-21-NIPS paper evaluation criteria</a></p>
<p>12 0.3442134 <a title="108-lsi-12" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>13 0.33408996 <a title="108-lsi-13" href="../hunch_net-2005/hunch_net-2005-05-29-Bad_ideas.html">76 hunch net-2005-05-29-Bad ideas</a></p>
<p>14 0.32654017 <a title="108-lsi-14" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>15 0.31928369 <a title="108-lsi-15" href="../hunch_net-2012/hunch_net-2012-12-29-Simons_Institute_Big_Data_Program.html">476 hunch net-2012-12-29-Simons Institute Big Data Program</a></p>
<p>16 0.31560212 <a title="108-lsi-16" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>17 0.31518701 <a title="108-lsi-17" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>18 0.31307226 <a title="108-lsi-18" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>19 0.30794191 <a title="108-lsi-19" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>20 0.30505151 <a title="108-lsi-20" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(4, 0.736), (27, 0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96429521 <a title="108-lda-1" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>Introduction: I just  presented  the  cross validation  problem at  COLT .  
 
The problem now has a cash prize (up to $500) associated with itâ&euro;&rdquo;see the  presentation  for details.
 
The  write-up for colt .</p><p>same-blog 2 0.9005726 <a title="108-lda-2" href="../hunch_net-2005/hunch_net-2005-09-06-A_link.html">108 hunch net-2005-09-06-A link</a></p>
<p>Introduction: I read through some of the essays of  Michael Nielsen  today, and recommend them.   Principles of Effective Research  and  Extreme Thinking  are both relevant to several discussions here.</p><p>3 0.6319499 <a title="108-lda-3" href="../hunch_net-2005/hunch_net-2005-07-01-The_Role_of_Impromptu_Talks.html">88 hunch net-2005-07-01-The Role of Impromptu Talks</a></p>
<p>Introduction: COLT  had an impromptu session which seemed as interesting or more interesting than any other single technical session (despite being only an hour long).  There are several roles that an impromptu session can play including:
  
 Announcing new work since the paper deadline. Letting this happen now rather than later helps aid the process of research. 
 Discussing a paper that was rejected.  Reviewers err sometimes and an impromptu session provides a means to remedy that. 
 Entertainment.  We all like to have a bit of fun. 
  
For design, the following seem important:
  
 Impromptu speakers should not have much time.  At COLT, it was 8 minutes, but I have seen even 5 work well. 
 The entire impromptu session should not last too long because the format is dense and promotes restlessness.  A half hour or hour can work well. 
  
Impromptu talks are a mechanism to let a little bit of chaos into the schedule.  They will be chaotic in content, presentation, and usefulness.  The fundamental adv</p><p>4 0.57888335 <a title="108-lda-4" href="../hunch_net-2005/hunch_net-2005-02-02-Kolmogorov_Complexity_and_Googling.html">10 hunch net-2005-02-02-Kolmogorov Complexity and Googling</a></p>
<p>Introduction: Machine learning makes the   New Scientist  . From the article: 
  

COMPUTERS can learn the meaning of words simply by plugging into Google. The finding could bring forward the day that true artificial intelligence is developedâ&euro;Ś. 
But Paul Vitanyi and Rudi Cilibrasi of the National Institute for Mathematics and Computer Science in Amsterdam, the Netherlands, realised that a Google search can be used to measure how closely two words relate to each other. For instance, imagine a computer needs to understand what a hat is.

  
You can read the paper at  KC Google .
 
Hat tip:   Kolmogorov Mailing List 
 
Any thoughts on the paper?</p><p>5 0.54288542 <a title="108-lda-5" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>Introduction: I realized that the tools needed to solve the  problem just posted  were just created.  I tried to sketch out the solution  here  (also in  .lyx  and  .tex ).  It is still quite sketchy (and probably only the few people who understand reductions well can follow).
 
One of the reasons why I started this weblog was to experiment with “research in the open”, and this is an opportunity to do so.  Over the next few days, I’ll be filling in details and trying to get things to make sense.  If you have additions or ideas, please propose them.</p><p>6 0.39838246 <a title="108-lda-6" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>7 0.32965189 <a title="108-lda-7" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>8 0.093941808 <a title="108-lda-8" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>9 0.091468528 <a title="108-lda-9" href="../hunch_net-2012/hunch_net-2012-03-06-COLT-ICML_Open_Questions_and_ICML_Instructions.html">458 hunch net-2012-03-06-COLT-ICML Open Questions and ICML Instructions</a></p>
<p>10 0.089868799 <a title="108-lda-10" href="../hunch_net-2011/hunch_net-2011-08-01-Interesting_papers_at_COLT_2011.html">439 hunch net-2011-08-01-Interesting papers at COLT 2011</a></p>
<p>11 0.086540267 <a title="108-lda-11" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>12 0.08504726 <a title="108-lda-12" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>13 0.083160579 <a title="108-lda-13" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>14 0.078645632 <a title="108-lda-14" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<p>15 0.077743091 <a title="108-lda-15" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>16 0.070938557 <a title="108-lda-16" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>17 0.070610799 <a title="108-lda-17" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>18 0.068809666 <a title="108-lda-18" href="../hunch_net-2009/hunch_net-2009-04-21-Interesting_Presentations_at_Snowbird.html">349 hunch net-2009-04-21-Interesting Presentations at Snowbird</a></p>
<p>19 0.060499962 <a title="108-lda-19" href="../hunch_net-2006/hunch_net-2006-03-24-NLPers.html">166 hunch net-2006-03-24-NLPers</a></p>
<p>20 0.060499962 <a title="108-lda-20" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
