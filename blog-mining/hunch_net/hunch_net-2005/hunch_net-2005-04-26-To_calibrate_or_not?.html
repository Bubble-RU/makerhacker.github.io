<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>62 hunch net-2005-04-26-To calibrate or not?</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-62" href="#">hunch_net-2005-62</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>62 hunch net-2005-04-26-To calibrate or not?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-62-html" href="http://hunch.net/?p=67">html</a></p><p>Introduction: A calibrated predictor is one which predicts the probability of a binary event with the property: For all predictions  p , the proportion of the time that  1  is observed is  p .
 
Since there are infinitely many  p , this definition must be “softened” to make sense for any finite number of samples.  The standard method for “softening” is to consider all predictions in a small neighborhood about each possible  p .
 
A great deal of effort has been devoted to strategies for achieving calibrated (such as  here ) prediction.  With statements like: (under minimal conditions) you can always make calibrated predictions.  
 
Given the strength of these statements, we might conclude we are done, but that would be a “confusion of ends”.  A confusion of ends arises in the following way:
  
 We want good probabilistic predictions. 
 Good probabilistic predictions are calibrated. 
 Therefore, we want calibrated predictions. 
  
The “Therefore” step misses the fact that calibration is a necessary b</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A calibrated predictor is one which predicts the probability of a binary event with the property: For all predictions  p , the proportion of the time that  1  is observed is  p . [sent-1, score-0.965]
</p><p>2 Since there are infinitely many  p , this definition must be “softened” to make sense for any finite number of samples. [sent-2, score-0.239]
</p><p>3 The standard method for “softening” is to consider all predictions in a small neighborhood about each possible  p . [sent-3, score-0.425]
</p><p>4 A great deal of effort has been devoted to strategies for achieving calibrated (such as  here ) prediction. [sent-4, score-0.729]
</p><p>5 With statements like: (under minimal conditions) you can always make calibrated predictions. [sent-5, score-0.765]
</p><p>6 Given the strength of these statements, we might conclude we are done, but that would be a “confusion of ends”. [sent-6, score-0.177]
</p><p>7 A confusion of ends arises in the following way:     We want good probabilistic predictions. [sent-7, score-0.629]
</p><p>8 The “Therefore” step misses the fact that calibration is a necessary but not a  sufficient  characterization of good probabilities. [sent-10, score-0.599]
</p><p>9 For example on the sequence “010101010…”, always predicting  p=0. [sent-11, score-0.228]
</p><p>10 This leads to the question: What is a sufficient characterization of good probabilities? [sent-13, score-0.492]
</p><p>11 Small log probability:  sum x  log (1/p x )      I don’t yet understand which of these candidates is preferrable. [sent-16, score-0.472]
</p><p>12 There is a sense in which none of them can be preferred. [sent-17, score-0.141]
</p><p>13 In any complete prediction system, the probabilities are used in some manner, and there is some loss (or utility) associated with it’s use. [sent-18, score-0.522]
</p><p>14 Depending on the sanity of the method using the probabilities, this may even imply that lieing about the probabilities is preferred. [sent-20, score-0.636]
</p><p>15 Nevertheless, we can hope for a sane use of probabilities and a sufficient mechanism for predicting good probabilities might eventually result in good performance for any sane use. [sent-21, score-1.769]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('calibrated', 0.502), ('probabilities', 0.465), ('characterization', 0.175), ('sane', 0.167), ('candidates', 0.167), ('ends', 0.161), ('predictions', 0.151), ('sufficient', 0.148), ('confusion', 0.139), ('therefore', 0.139), ('statements', 0.121), ('sum', 0.121), ('probabilistic', 0.106), ('small', 0.103), ('calibration', 0.1), ('infinitely', 0.1), ('predicting', 0.1), ('good', 0.096), ('utility', 0.093), ('proportion', 0.093), ('conclude', 0.093), ('neighborhood', 0.093), ('sanity', 0.093), ('log', 0.092), ('devoted', 0.088), ('probability', 0.086), ('strength', 0.084), ('sense', 0.081), ('misses', 0.08), ('strategies', 0.08), ('method', 0.078), ('predicts', 0.075), ('minimizing', 0.075), ('leads', 0.073), ('conditions', 0.071), ('minimal', 0.071), ('always', 0.071), ('arises', 0.068), ('eventually', 0.065), ('manner', 0.061), ('none', 0.06), ('property', 0.06), ('squared', 0.059), ('achieving', 0.059), ('depending', 0.059), ('want', 0.059), ('finite', 0.058), ('event', 0.058), ('sequence', 0.057), ('complete', 0.057)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="62-tfidf-1" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>Introduction: A calibrated predictor is one which predicts the probability of a binary event with the property: For all predictions  p , the proportion of the time that  1  is observed is  p .
 
Since there are infinitely many  p , this definition must be “softened” to make sense for any finite number of samples.  The standard method for “softening” is to consider all predictions in a small neighborhood about each possible  p .
 
A great deal of effort has been devoted to strategies for achieving calibrated (such as  here ) prediction.  With statements like: (under minimal conditions) you can always make calibrated predictions.  
 
Given the strength of these statements, we might conclude we are done, but that would be a “confusion of ends”.  A confusion of ends arises in the following way:
  
 We want good probabilistic predictions. 
 Good probabilistic predictions are calibrated. 
 Therefore, we want calibrated predictions. 
  
The “Therefore” step misses the fact that calibration is a necessary b</p><p>2 0.17853141 <a title="62-tfidf-2" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.  There are at least 3 distinct ways the word is used. 
  
  Bayesian  The Bayesian notion of probability is a ‘degree of belief’.   The degree of belief that some event (i.e. “stock goes up” or “stock goes down”) occurs can be measured by asking a sequence of questions of the form “Would you bet the stock goes up or down at  Y  to 1 odds?” A consistent better will switch from ‘for’ to ‘against’ at some single value of  Y .  The probability is then  Y/(Y+1) .  Bayesian probabilities express lack of knowledge rather than randomization.  They are useful in learning because we often lack knowledge and expressing that lack flexibly makes the learning algorithms work better.  Bayesian Learning uses ‘probability’ in this way exclusively. 
  Frequentist  The Frequentist notion of probability is a rate of occurence.  A rate of occurrence can be measured by doing an experiment many times.  If an event occurs  k  times in</p><p>3 0.17355987 <a title="62-tfidf-3" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>Introduction: This post is really for people  not  in machine learning (or related fields).  It is about a common misperception which affects people who have not thought about the process of trying to predict somethinng.  Hopefully, by precisely stating it, we can remove it.
 
Suppose we have a set of events, each described by a vector of features.
  
 
 0 
 1 
 0 
 1 
 1 
 
 
 1 
 0 
 1 
 0 
 1 
 
 
 1 
 1 
 0 
 1 
 0 
 
 
 0 
 0 
 1 
 1 
 1 
 
 
 1 
 1 
 0 
 0 
 1 
 
 
 1 
 0 
 0 
 0 
 1 
 
 
 0 
 1 
 1 
 1 
 0 
 
  
Suppose we want to predict the value of the first feature given the others.  One approach is to bin the data by  one  feature.  For the above example, we might partition the data according to feature 2, then observe that when feature 2 is 0 the label (feature 1) is mostly 1. On the other hand, when feature 2 is 1, the label (feature 1) is mostly 0.  Using this simple rule we get an observed error rate of 3/7.  
 
There are two issues here.   The first is that this is really a training</p><p>4 0.14576711 <a title="62-tfidf-4" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>Introduction: Many decision problems can be represented in the form 
FOR  n =1,2,…: 
— Reality chooses a datum  x n  . 
— Decision Maker chooses his decision  d n  . 
— Reality chooses an observation  y n  . 
— Decision Maker suffers loss   L ( y n  , d n  ). 
END FOR. 
The observation  y n   can be, for example, tomorrow’s stock price and the decision  d n   the number of shares Decision Maker chooses to buy.  The datum  x n   ideally contains all information that might be relevant in making this decision.  We do not want to assume anything about the way Reality generates the observations and data.
 
Suppose there is a good and not too complex decision rule  D  mapping each datum  x  to a decision  D ( x ).  Can we perform as well, or almost as well, as  D , without knowing it?  This is essentially a special case of the problem of  on-line learning .
 
This is a simple result of this kind.  Suppose the data  x n   are taken from [0,1] and  L ( y , d )=| y – d |.  A norm || h || of a function  h  on</p><p>5 0.1151427 <a title="62-tfidf-5" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>Introduction: This is about a design flaw in several learning algorithms such as the Naive Bayes classifier and Hidden Markov Models.  A number of people are aware of it, but it seems that not everyone is.
 
Several learning systems have the property that they estimate some conditional probabilities  P(event | other events)  either explicitly or implicitly.  Then, at prediction time, these learned probabilities are multiplied together according to some formula to produce a final prediction.  The Naive Bayes classifier for binary data is the simplest of these, so it seems like a good example.  
 
When Naive Bayes is used, a set of probabilities of the form  Pr’(feature i | label)  are estimated via counting statistics and some prior.  Predictions are made according to the label maximizing: 
  Pr’(label) * Product features i  Pr’(feature i | label)  
 
(The  Pr’  notation indicates these are estimated values.) 
 
There is nothing wrong with this method as long as (a) the prior for the sample counts is</p><p>6 0.098719992 <a title="62-tfidf-6" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>7 0.09324082 <a title="62-tfidf-7" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>8 0.083301932 <a title="62-tfidf-8" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>9 0.080391556 <a title="62-tfidf-9" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>10 0.080250919 <a title="62-tfidf-10" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>11 0.077544853 <a title="62-tfidf-11" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>12 0.077043012 <a title="62-tfidf-12" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>13 0.076706648 <a title="62-tfidf-13" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>14 0.070857711 <a title="62-tfidf-14" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>15 0.070460208 <a title="62-tfidf-15" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>16 0.070004903 <a title="62-tfidf-16" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>17 0.068431385 <a title="62-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>18 0.068343624 <a title="62-tfidf-18" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>19 0.066722199 <a title="62-tfidf-19" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>20 0.066564322 <a title="62-tfidf-20" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.147), (1, 0.099), (2, 0.051), (3, -0.02), (4, -0.079), (5, -0.003), (6, 0.011), (7, 0.043), (8, 0.043), (9, -0.035), (10, -0.038), (11, 0.006), (12, 0.031), (13, -0.045), (14, 0.033), (15, -0.012), (16, -0.097), (17, -0.015), (18, 0.077), (19, 0.029), (20, -0.089), (21, 0.026), (22, 0.094), (23, 0.054), (24, 0.003), (25, -0.0), (26, 0.038), (27, -0.034), (28, -0.032), (29, -0.031), (30, 0.032), (31, 0.049), (32, -0.054), (33, -0.013), (34, -0.052), (35, 0.023), (36, -0.021), (37, 0.077), (38, 0.095), (39, 0.036), (40, -0.022), (41, -0.039), (42, -0.063), (43, 0.095), (44, -0.055), (45, 0.067), (46, -0.02), (47, 0.035), (48, -0.06), (49, 0.087)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96512508 <a title="62-lsi-1" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>Introduction: A calibrated predictor is one which predicts the probability of a binary event with the property: For all predictions  p , the proportion of the time that  1  is observed is  p .
 
Since there are infinitely many  p , this definition must be “softened” to make sense for any finite number of samples.  The standard method for “softening” is to consider all predictions in a small neighborhood about each possible  p .
 
A great deal of effort has been devoted to strategies for achieving calibrated (such as  here ) prediction.  With statements like: (under minimal conditions) you can always make calibrated predictions.  
 
Given the strength of these statements, we might conclude we are done, but that would be a “confusion of ends”.  A confusion of ends arises in the following way:
  
 We want good probabilistic predictions. 
 Good probabilistic predictions are calibrated. 
 Therefore, we want calibrated predictions. 
  
The “Therefore” step misses the fact that calibration is a necessary b</p><p>2 0.80381107 <a title="62-lsi-2" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.  There are at least 3 distinct ways the word is used. 
  
  Bayesian  The Bayesian notion of probability is a ‘degree of belief’.   The degree of belief that some event (i.e. “stock goes up” or “stock goes down”) occurs can be measured by asking a sequence of questions of the form “Would you bet the stock goes up or down at  Y  to 1 odds?” A consistent better will switch from ‘for’ to ‘against’ at some single value of  Y .  The probability is then  Y/(Y+1) .  Bayesian probabilities express lack of knowledge rather than randomization.  They are useful in learning because we often lack knowledge and expressing that lack flexibly makes the learning algorithms work better.  Bayesian Learning uses ‘probability’ in this way exclusively. 
  Frequentist  The Frequentist notion of probability is a rate of occurence.  A rate of occurrence can be measured by doing an experiment many times.  If an event occurs  k  times in</p><p>3 0.75744909 <a title="62-lsi-3" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>Introduction: This post is really for people  not  in machine learning (or related fields).  It is about a common misperception which affects people who have not thought about the process of trying to predict somethinng.  Hopefully, by precisely stating it, we can remove it.
 
Suppose we have a set of events, each described by a vector of features.
  
 
 0 
 1 
 0 
 1 
 1 
 
 
 1 
 0 
 1 
 0 
 1 
 
 
 1 
 1 
 0 
 1 
 0 
 
 
 0 
 0 
 1 
 1 
 1 
 
 
 1 
 1 
 0 
 0 
 1 
 
 
 1 
 0 
 0 
 0 
 1 
 
 
 0 
 1 
 1 
 1 
 0 
 
  
Suppose we want to predict the value of the first feature given the others.  One approach is to bin the data by  one  feature.  For the above example, we might partition the data according to feature 2, then observe that when feature 2 is 0 the label (feature 1) is mostly 1. On the other hand, when feature 2 is 1, the label (feature 1) is mostly 0.  Using this simple rule we get an observed error rate of 3/7.  
 
There are two issues here.   The first is that this is really a training</p><p>4 0.73433542 <a title="62-lsi-4" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>Introduction: Many decision problems can be represented in the form 
FOR  n =1,2,…: 
— Reality chooses a datum  x n  . 
— Decision Maker chooses his decision  d n  . 
— Reality chooses an observation  y n  . 
— Decision Maker suffers loss   L ( y n  , d n  ). 
END FOR. 
The observation  y n   can be, for example, tomorrow’s stock price and the decision  d n   the number of shares Decision Maker chooses to buy.  The datum  x n   ideally contains all information that might be relevant in making this decision.  We do not want to assume anything about the way Reality generates the observations and data.
 
Suppose there is a good and not too complex decision rule  D  mapping each datum  x  to a decision  D ( x ).  Can we perform as well, or almost as well, as  D , without knowing it?  This is essentially a special case of the problem of  on-line learning .
 
This is a simple result of this kind.  Suppose the data  x n   are taken from [0,1] and  L ( y , d )=| y – d |.  A norm || h || of a function  h  on</p><p>5 0.63844824 <a title="62-lsi-5" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>Introduction: I’m skipping NIPS this year in favor of  Ada , but I wanted to point out  this paper  by  Andriy Mnih  and  Geoff Hinton .  The basic claim of the paper is that by carefully but automatically constructing a binary tree over words, it’s possible to predict words well with huge computational resource savings over unstructured approaches.
 
I’m interested in this beyond the application to word prediction because it is relevant to the general normalization problem: If you want to predict the probability of one of a large number of events, often you must compute a predicted score for all the events and then normalize, a computationally inefficient operation.  The problem comes up in many places using probabilistic models, but I’ve run into it with high-dimensional regression.
 
There are a couple workarounds for this computational bug:
  
 Approximate. There are many ways.  Often the approximations are uncontrolled (i.e. can be arbitrarily bad), and hence finicky in application. 
 Avoid.  Y</p><p>6 0.63583332 <a title="62-lsi-6" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>7 0.60945314 <a title="62-lsi-7" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>8 0.58989763 <a title="62-lsi-8" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>9 0.58889133 <a title="62-lsi-9" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>10 0.57972658 <a title="62-lsi-10" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>11 0.55932277 <a title="62-lsi-11" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>12 0.52849501 <a title="62-lsi-12" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>13 0.50690025 <a title="62-lsi-13" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>14 0.4597837 <a title="62-lsi-14" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>15 0.45846578 <a title="62-lsi-15" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>16 0.44294003 <a title="62-lsi-16" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>17 0.43197215 <a title="62-lsi-17" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>18 0.42715919 <a title="62-lsi-18" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>19 0.42344558 <a title="62-lsi-19" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>20 0.42330039 <a title="62-lsi-20" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.319), (1, 0.011), (3, 0.057), (10, 0.042), (27, 0.175), (53, 0.062), (55, 0.104), (94, 0.038), (95, 0.08)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.90734971 <a title="62-lda-1" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>Introduction: A calibrated predictor is one which predicts the probability of a binary event with the property: For all predictions  p , the proportion of the time that  1  is observed is  p .
 
Since there are infinitely many  p , this definition must be “softened” to make sense for any finite number of samples.  The standard method for “softening” is to consider all predictions in a small neighborhood about each possible  p .
 
A great deal of effort has been devoted to strategies for achieving calibrated (such as  here ) prediction.  With statements like: (under minimal conditions) you can always make calibrated predictions.  
 
Given the strength of these statements, we might conclude we are done, but that would be a “confusion of ends”.  A confusion of ends arises in the following way:
  
 We want good probabilistic predictions. 
 Good probabilistic predictions are calibrated. 
 Therefore, we want calibrated predictions. 
  
The “Therefore” step misses the fact that calibration is a necessary b</p><p>2 0.90235454 <a title="62-lda-2" href="../hunch_net-2012/hunch_net-2012-09-29-Vowpal_Wabbit%2C_version_7.0.html">473 hunch net-2012-09-29-Vowpal Wabbit, version 7.0</a></p>
<p>Introduction: A new version of  VW  is  out .  The primary changes are:
  
  Learning Reductions : I’ve wanted to get  learning reductions  working and we’ve finally done it.  Not everything is implemented yet, but VW now supports direct:
 
 Multiclass Classification  –oaa  or  –ect . 
 Cost Sensitive Multiclass Classification  –csoaa  or  –wap . 
 Contextual Bandit Classification  –cb . 
 Sequential Structured Prediction   –searn  or  –dagger  
 

In addition, it is now easy to build your own custom learning reductions for various plausible uses: feature diddling, custom structured prediction problems, or alternate learning reductions.  This effort is far from done, but it is now in a generally useful state.  Note that all learning reductions inherit the ability to do cluster parallel learning.

 
  Library interface :  VW now has a basic library interface.  The library provides most of the functionality of VW, with the limitation that it is monolithic and nonreentrant.  These will be improved over</p><p>3 0.86998534 <a title="62-lda-3" href="../hunch_net-2005/hunch_net-2005-06-29-Not_EM_for_clustering_at_COLT.html">87 hunch net-2005-06-29-Not EM for clustering at COLT</a></p>
<p>Introduction: One standard approach for clustering data with a set of gaussians is using EM.  Roughly speaking, you pick a set of  k  random guassians and then use alternating expectation maximization to (hopefully) find a set of guassians that “explain” the data well.  This process is difficult to work with because EM can become “stuck” in local optima.   There are various hacks like “rerun with  t  different random starting points”.
 
One cool observation is that this can often be solved via other algorithm which do  not  suffer from local optima.  This is an early  paper  which shows this.  Ravi Kannan presented a  new paper  showing this is possible in a much more adaptive setting.  
 
A very rough summary of these papers is that by projecting into a lower dimensional space, it is computationally tractable to pick out the gross  structure of the data.  It is unclear how well these algorithms work in practice, but they might be effective, especially if used as a subroutine of the form:
  
 Projec</p><p>4 0.85218239 <a title="62-lda-4" href="../hunch_net-2006/hunch_net-2006-10-22-Exemplar_programming.html">215 hunch net-2006-10-22-Exemplar programming</a></p>
<p>Introduction: There are many different abstractions for problem definition and solution.  Here are a few examples:
  
 Functional programming: a set of functions are defined.  The composed execution of these functions yields the solution. 
 Linear programming: a set of constraints and a linear objective function are defined.  An LP solver finds the constrained optimum. 
 Quadratic programming: Like linear programming, but the language is a little more flexible (and the solution slower). 
 Convex programming: like quadratic programming, but the language is more flexible (and the solutions even slower). 
 Dynamic programming: a recursive definition of the problem is defined and then solved efficiently via caching tricks. 
 SAT programming: A problem is specified as a satisfiability involving a conjunction of a disjunction of boolean variables.  A general engine attempts to find a good satisfying assignment.  For example  Kautz’s   blackbox  planner. 
  
These abstractions have different tradeoffs betw</p><p>5 0.83042288 <a title="62-lda-5" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>Introduction: …is discussed in  this nytimes article .  I generally expect such approaches to become more common since computers are getting faster, machine learning is getting better, and data is becoming more plentiful.   This is another example where machine learning technology may have a huge economic impact.  Some side notes:
  
 We-in-research know almost nothing about how these things are done (because it is typically a corporate secret). 
 … but the limited discussion in the article seem naive from a machine learning viewpoint.
 
 The learning process used apparently often fails to take into account transaction costs. 
 What little of the approaches is discussed appears modeling based.  It seems plausible that more direct prediction methods can yield an edge. 
 
 
 One difficulty with stock picking as a research topic is that it is inherently a zero sum game (for every winner, there is a loser).  Much of the rest of research is positive sum (basically, everyone wins).</p><p>6 0.80123532 <a title="62-lda-6" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>7 0.65336132 <a title="62-lda-7" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>8 0.61417341 <a title="62-lda-8" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>9 0.58914399 <a title="62-lda-9" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>10 0.58337229 <a title="62-lda-10" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>11 0.57826376 <a title="62-lda-11" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>12 0.57421452 <a title="62-lda-12" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>13 0.57396668 <a title="62-lda-13" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>14 0.57010877 <a title="62-lda-14" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>15 0.56648922 <a title="62-lda-15" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>16 0.56543761 <a title="62-lda-16" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>17 0.56536591 <a title="62-lda-17" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>18 0.56515348 <a title="62-lda-18" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>19 0.56439555 <a title="62-lda-19" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>20 0.56360579 <a title="62-lda-20" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
