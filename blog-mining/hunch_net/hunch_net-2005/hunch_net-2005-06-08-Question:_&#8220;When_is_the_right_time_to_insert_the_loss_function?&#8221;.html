<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-79" href="#">hunch_net-2005-79</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-79-html" href="http://hunch.net/?p=85">html</a></p><p>Introduction: Halasksa very good question: "When is the right time to insert the loss
function?" In particular, should it be used at testing time or at training
time?When the world imposes a loss on us, the standard Bayesian recipe is to
predict the (conditional) probability of each possibility and then choose the
possibility which minimizes the expected loss. In contrast, as
theconfusionover "loss = money lost" or "loss = the thing you optimize" might
indicate, many people ignore the Bayesian approach and simply optimize their
loss (or a close proxy for their loss) over the representation on the training
set.The best answer I can give is "it's unclear, but I prefer optimizing the
loss at training time". My experience is that optimizing the loss in the most
direct manner possible typically yields best performance. This question is
related to a basic principle which bothYann LeCun(applied) andVladimir
Vapnik(theoretical) advocate: "solve the simplest prediction problem that
solves the problem". (One</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('loss', 0.558), ('optimizing', 0.23), ('principle', 0.182), ('training', 0.17), ('possibility', 0.165), ('optimize', 0.148), ('unclear', 0.146), ('andvladimir', 0.125), ('fan', 0.125), ('lecun', 0.116), ('minimizes', 0.116), ('vapnik', 0.116), ('recipe', 0.116), ('imposes', 0.116), ('bayesian', 0.11), ('probability', 0.109), ('give', 0.109), ('proxy', 0.104), ('adds', 0.104), ('bagnell', 0.104)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="79-tfidf-1" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>Introduction: Halasksa very good question: "When is the right time to insert the loss
function?" In particular, should it be used at testing time or at training
time?When the world imposes a loss on us, the standard Bayesian recipe is to
predict the (conditional) probability of each possibility and then choose the
possibility which minimizes the expected loss. In contrast, as
theconfusionover "loss = money lost" or "loss = the thing you optimize" might
indicate, many people ignore the Bayesian approach and simply optimize their
loss (or a close proxy for their loss) over the representation on the training
set.The best answer I can give is "it's unclear, but I prefer optimizing the
loss at training time". My experience is that optimizing the loss in the most
direct manner possible typically yields best performance. This question is
related to a basic principle which bothYann LeCun(applied) andVladimir
Vapnik(theoretical) advocate: "solve the simplest prediction problem that
solves the problem". (One</p><p>2 0.44268048 <a title="79-tfidf-2" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss:
A loss function which is much easier to optimize computationally than the loss
function imposed by the world. A canonical example is when we want to learn a
weight vectorwand predict according to a dot productfw(x)= sumiwixiwhere
optimizing squared loss(y-fw(x))2over many samples is much more tractable than
optimizing 0-1 lossI(y = Threshold(fw(x) - 0.5)).While the computational
advantages of optimizing a proxy loss are substantial, we are curious: which
proxy loss is best? The answer of course depends on what the real loss imposed
by the world is. For 0-1 loss classification, there are adherents to many
choices:Log loss. If we confine the prediction to[0,1], we can treat it as a
predicted probability that the label is1, and measure loss according tolog
1/p'(y|x)wherep'(y|x)is the predicted probability of the observed label. A
standard method for confining the prediction to[0,1]islogistic regressionwhich
expo</p><p>3 0.43915287 <a title="79-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>4 0.30924526 <a title="79-tfidf-4" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner
independent of the loss function itself.Optimizing squared
losslsq(y,y')=(y-y')2means predicting the (conditional) mean ofy.Optimizing
absolute value losslav(y,y')=|y-y'|means predicting the (conditional) median
ofy. Variants canhandle other quantiles. 0/1 loss for classification is a
special case.Optimizing log lossllog(y,y')=log (1/Prz~y'(z=y))means minimizing
the description length ofy.The semantics (= meaning) of the loss are made
explicit by a theorem in each case. For squared loss, we can prove a theorem
of the form:For all distributionsDoverY, ify' = arg miny'Ey ~ Dlsq(y,y')theny'
= Ey~DySimilar theorems hold for the other examples above, and they can all be
extended to predictors ofy'for distributionsDover a contextXand a valueY.There
are 3 points to this post.Everyone doing general machine learning should be
aware of the laundry list above. They form a handy toolkit which can match
many of the problems nat</p><p>5 0.25734442 <a title="79-tfidf-5" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>Introduction: In theregression vs classification debate, I'm adding a new "pro" to
classification. It seems there are computational shortcuts available for
classification which simply aren't available for regression. This arises in
several situations.Inactive learningit is sometimes possible to find aneerror
classifier with justlog(e)labeled samples. Only much more modest improvements
appear to be achievable for squared loss regression. The essential reason is
that the loss function on many examples is flat with respect to large
variations in the parameter spaces of a learned classifier, which implies that
many of these classifiers do not need to be considered. In contrast, for
squared loss regression, most substantial variations in the parameter space
influence the loss at most points.In budgeted learning, where there is either
a computational time constraint or a feature cost constraint, a classifier can
sometimes be learned to very high accuracy under the constraints while a
squared loss regresso</p><p>6 0.23707643 <a title="79-tfidf-6" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>7 0.20172024 <a title="79-tfidf-7" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>8 0.20037697 <a title="79-tfidf-8" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>9 0.19276857 <a title="79-tfidf-9" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>10 0.17784736 <a title="79-tfidf-10" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>11 0.15704171 <a title="79-tfidf-11" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>12 0.15234566 <a title="79-tfidf-12" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>13 0.14686161 <a title="79-tfidf-13" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>14 0.14333972 <a title="79-tfidf-14" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>15 0.1404928 <a title="79-tfidf-15" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>16 0.13794678 <a title="79-tfidf-16" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>17 0.13393107 <a title="79-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>18 0.13183057 <a title="79-tfidf-18" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>19 0.12427939 <a title="79-tfidf-19" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>20 0.12337886 <a title="79-tfidf-20" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.227), (1, -0.217), (2, -0.176), (3, 0.151), (4, 0.427), (5, 0.156), (6, -0.112), (7, -0.039), (8, -0.113), (9, -0.03), (10, 0.01), (11, 0.011), (12, 0.086), (13, 0.004), (14, 0.028), (15, -0.019), (16, 0.005), (17, -0.026), (18, 0.039), (19, 0.003), (20, -0.003), (21, 0.013), (22, -0.025), (23, 0.016), (24, -0.065), (25, -0.0), (26, -0.053), (27, -0.023), (28, -0.028), (29, 0.008), (30, 0.011), (31, 0.003), (32, -0.025), (33, 0.012), (34, -0.005), (35, 0.005), (36, -0.04), (37, -0.035), (38, -0.073), (39, -0.074), (40, 0.006), (41, 0.032), (42, 0.001), (43, 0.007), (44, -0.027), (45, -0.015), (46, 0.024), (47, 0.012), (48, -0.028), (49, -0.024)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99318945 <a title="79-lsi-1" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>Introduction: Halasksa very good question: "When is the right time to insert the loss
function?" In particular, should it be used at testing time or at training
time?When the world imposes a loss on us, the standard Bayesian recipe is to
predict the (conditional) probability of each possibility and then choose the
possibility which minimizes the expected loss. In contrast, as
theconfusionover "loss = money lost" or "loss = the thing you optimize" might
indicate, many people ignore the Bayesian approach and simply optimize their
loss (or a close proxy for their loss) over the representation on the training
set.The best answer I can give is "it's unclear, but I prefer optimizing the
loss at training time". My experience is that optimizing the loss in the most
direct manner possible typically yields best performance. This question is
related to a basic principle which bothYann LeCun(applied) andVladimir
Vapnik(theoretical) advocate: "solve the simplest prediction problem that
solves the problem". (One</p><p>2 0.96273679 <a title="79-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>3 0.9496392 <a title="79-lsi-3" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss:
A loss function which is much easier to optimize computationally than the loss
function imposed by the world. A canonical example is when we want to learn a
weight vectorwand predict according to a dot productfw(x)= sumiwixiwhere
optimizing squared loss(y-fw(x))2over many samples is much more tractable than
optimizing 0-1 lossI(y = Threshold(fw(x) - 0.5)).While the computational
advantages of optimizing a proxy loss are substantial, we are curious: which
proxy loss is best? The answer of course depends on what the real loss imposed
by the world is. For 0-1 loss classification, there are adherents to many
choices:Log loss. If we confine the prediction to[0,1], we can treat it as a
predicted probability that the label is1, and measure loss according tolog
1/p'(y|x)wherep'(y|x)is the predicted probability of the observed label. A
standard method for confining the prediction to[0,1]islogistic regressionwhich
expo</p><p>4 0.91673046 <a title="79-lsi-4" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner
independent of the loss function itself.Optimizing squared
losslsq(y,y')=(y-y')2means predicting the (conditional) mean ofy.Optimizing
absolute value losslav(y,y')=|y-y'|means predicting the (conditional) median
ofy. Variants canhandle other quantiles. 0/1 loss for classification is a
special case.Optimizing log lossllog(y,y')=log (1/Prz~y'(z=y))means minimizing
the description length ofy.The semantics (= meaning) of the loss are made
explicit by a theorem in each case. For squared loss, we can prove a theorem
of the form:For all distributionsDoverY, ify' = arg miny'Ey ~ Dlsq(y,y')theny'
= Ey~DySimilar theorems hold for the other examples above, and they can all be
extended to predictors ofy'for distributionsDover a contextXand a valueY.There
are 3 points to this post.Everyone doing general machine learning should be
aware of the laundry list above. They form a handy toolkit which can match
many of the problems nat</p><p>5 0.8650164 <a title="79-lsi-5" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>Introduction: How do we judge success in Machine Learning? AsAaronnotes, the best way is to
use the loss imposed on you by the world. This turns out to be infeasible
sometimes for various reasons. The ones I've seen are:The learned prediction
is used in some complicated process that does not give the feedback necessary
to understand the prediction's impact on the loss.The prediction is used by
some other system which expects some semantics to the predicted value. This is
similar to the previous example, except that the issue is design modularity
rather than engineering modularity.The correct loss function is simply unknown
(and perhaps unknowable, except by experimentation).In these situations, it's
unclear what metric for evaluation should be chosen. This post has some design
advice for this murkier case. I'm using the word "metric" here to distinguish
the fact that we are considering methods forevaluatingpredictive systems
rather than a loss imposed by the real world or a loss which is optimized b</p><p>6 0.84139115 <a title="79-lsi-6" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>7 0.80325276 <a title="79-lsi-7" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>8 0.78844225 <a title="79-lsi-8" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>9 0.76356053 <a title="79-lsi-9" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>10 0.5909729 <a title="79-lsi-10" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>11 0.56600535 <a title="79-lsi-11" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>12 0.54069108 <a title="79-lsi-12" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>13 0.53622782 <a title="79-lsi-13" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>14 0.4779101 <a title="79-lsi-14" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>15 0.4774597 <a title="79-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>16 0.46851641 <a title="79-lsi-16" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>17 0.45198551 <a title="79-lsi-17" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>18 0.4497481 <a title="79-lsi-18" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>19 0.44473895 <a title="79-lsi-19" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>20 0.42852637 <a title="79-lsi-20" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(24, 0.181), (35, 0.024), (42, 0.314), (45, 0.016), (50, 0.056), (68, 0.143), (74, 0.121), (95, 0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94088542 <a title="79-lda-1" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<p>Introduction: Many people, especially students, haven't had an opportunity to collaborate
with other researchers. Collaboration, especially with remote people can be
tricky. Here are some observations of what has worked for me on collaborations
involving a few people.Travel and DiscussAlmost all collaborations start with
in-person discussion. This implies that travel is often necessary. We can hope
that in the future we'll have better systems for starting collaborations
remotely (such as blogs), but we aren't quite there yet.Enable your
collaborator. A collaboration can fall apart because one collaborator disables
another. This sounds stupid (and it is), but it's far easier than you might
think.Avoid Duplication. Discovering that you and a collaborator have been
editing the same thing and now need to waste time reconciling changes is
annoying. The best way to avoid this to be explicit about who has write
permission to what. Most of the time, a write lock is held for the entire
document, just to be s</p><p>same-blog 2 0.93333393 <a title="79-lda-2" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>Introduction: Halasksa very good question: "When is the right time to insert the loss
function?" In particular, should it be used at testing time or at training
time?When the world imposes a loss on us, the standard Bayesian recipe is to
predict the (conditional) probability of each possibility and then choose the
possibility which minimizes the expected loss. In contrast, as
theconfusionover "loss = money lost" or "loss = the thing you optimize" might
indicate, many people ignore the Bayesian approach and simply optimize their
loss (or a close proxy for their loss) over the representation on the training
set.The best answer I can give is "it's unclear, but I prefer optimizing the
loss at training time". My experience is that optimizing the loss in the most
direct manner possible typically yields best performance. This question is
related to a basic principle which bothYann LeCun(applied) andVladimir
Vapnik(theoretical) advocate: "solve the simplest prediction problem that
solves the problem". (One</p><p>3 0.88600808 <a title="79-lda-3" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>Introduction: This is about the hard choices that graduate students must make.The cultural
definition of success in academic research is to:Produce good research which
many other people appreciate.Produce many students who go on to do the
same.There are fundamental reasons why this is success in the local culture.
Good research appreciated by others means access to jobs. Many students
succesful in the same way implies that there are a number of people who think
in a similar way and appreciate your work.In order to graduate, a phd student
must live in an academic culture for a period of several years. It is common
to adopt the culture's definition of success during this time. It's also
common for many phd students discover they are not suited to an academic
research lifestyle. This collision of values and abilities naturally results
in depression.The most fundamental advice when this happens is: change
something. Pick a new advisor. Pick a new research topic. Or leave the program
(and do something el</p><p>4 0.86655045 <a title="79-lda-4" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>5 0.86444461 <a title="79-lda-5" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>Introduction: Many people in Machine Learning don't fully understand the impact of
computation, as demonstrated by a lack ofbig-Oanalysis of new learning
algorithms. This is important--some current active research programs are
fundamentally flawed w.r.t. computation, and other research programs are
directly motivated by it. When considering a learning algorithm, I think about
the following questions:How does the learning algorithm scale with the number
of examplesm? Any algorithm using all of the data is at leastO(m), but in many
cases this isO(m2)(naive nearest neighbor for self-prediction) or unknown
(k-means or many other optimization algorithms). The unknown case is very
common, and it can mean (for example) that the algorithm isn't convergent or
simply that the amount of computation isn't controlled.The above question can
also be asked for test cases. In some applications, test-time performance is
of great importance.How does the algorithm scale with the number of
featuresnper example? Many sec</p><p>6 0.86423463 <a title="79-lda-6" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>7 0.86178893 <a title="79-lda-7" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>8 0.85944712 <a title="79-lda-8" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>9 0.85927016 <a title="79-lda-9" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>10 0.85811794 <a title="79-lda-10" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>11 0.85627592 <a title="79-lda-11" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>12 0.85491884 <a title="79-lda-12" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>13 0.85429084 <a title="79-lda-13" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>14 0.85050911 <a title="79-lda-14" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>15 0.84989369 <a title="79-lda-15" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>16 0.84982502 <a title="79-lda-16" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<p>17 0.84831297 <a title="79-lda-17" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>18 0.84806985 <a title="79-lda-18" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>19 0.8477121 <a title="79-lda-19" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>20 0.84743571 <a title="79-lda-20" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
