<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>65 hunch net-2005-05-02-Reviewing techniques for conferences</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-65" href="#">hunch_net-2005-65</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>65 hunch net-2005-05-02-Reviewing techniques for conferences</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-65-html" href="http://hunch.net/?p=70">html</a></p><p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The many reviews following the many paper deadlines are just about over. [sent-1, score-0.218]
</p><p>2 AAAI and ICML in particular were experimenting with several reviewing techniques. [sent-2, score-0.273]
</p><p>3 Double Blind: AAAI and ICML were both double blind this year. [sent-3, score-0.612]
</p><p>4 For theoretical papers, with a lot to say, authors often leave out the proofs. [sent-5, score-0.33]
</p><p>5 This is very hard to cope with under a double blind review because (1) you can not trust the authors got the proof right but (2) a blanket "reject" hits many probably-good papers. [sent-6, score-1.289]
</p><p>6 Perhaps authors should more strongly favor proof-complete papers sent to double blind conferences. [sent-7, score-1.094]
</p><p>7 On the author side, double blind reviewing is actually somewhat disruptive to research. [sent-8, score-1.234]
</p><p>8 In particular, it discourages the author from talking about the subject, which is one of the mechanisms of research. [sent-9, score-0.42]
</p><p>9 This is not a great drawback, but it is one not previously appreciated. [sent-10, score-0.069]
</p><p>10 Author feedback: AAAI and ICML did author feedback this year. [sent-11, score-0.433]
</p><p>11 The ICML-style author feedback (more space, no requirement of attacking the review to respond), appeared somewhat more helpful and natural. [sent-13, score-1.112]
</p><p>12 It seems ok to pass a compliment from author to reviewer. [sent-14, score-0.431]
</p><p>13 Discussion Periods: AAAI seemed more natural than ICML with respect to discussion periods. [sent-15, score-0.214]
</p><p>14 For ICML, there were "dead times" when reviews were submitted but discussions amongst reviewers were not encouraged. [sent-16, score-0.35]
</p><p>15 This has the drawback of letting people forget their review before discussing it. [sent-17, score-0.588]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('aaai', 0.415), ('blind', 0.34), ('double', 0.272), ('author', 0.271), ('icml', 0.245), ('seemed', 0.214), ('authors', 0.177), ('feedback', 0.162), ('review', 0.158), ('drawback', 0.151), ('reviews', 0.134), ('disruptive', 0.119), ('somewhat', 0.118), ('reviewing', 0.114), ('attacking', 0.11), ('periods', 0.11), ('letting', 0.104), ('requirement', 0.104), ('helpful', 0.1), ('dead', 0.099), ('trust', 0.095), ('sent', 0.095), ('beneficial', 0.092), ('got', 0.092), ('respond', 0.092), ('appeared', 0.089), ('cope', 0.089), ('forget', 0.089), ('discussing', 0.086), ('deadlines', 0.084), ('leave', 0.082), ('experimenting', 0.082), ('pass', 0.082), ('favor', 0.082), ('talking', 0.08), ('discussions', 0.078), ('ok', 0.078), ('submitted', 0.078), ('particular', 0.077), ('reject', 0.074), ('lot', 0.071), ('times', 0.07), ('mechanisms', 0.069), ('previously', 0.069), ('proof', 0.066), ('papers', 0.065), ('side', 0.063), ('overall', 0.063), ('strongly', 0.063), ('amongst', 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="65-tfidf-1" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>2 0.35041702 <a title="65-tfidf-2" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>3 0.32955101 <a title="65-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>4 0.31769201 <a title="65-tfidf-4" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>Introduction: Most long conversations between academics seem to converge on the topic of
reviewing where almost no one is happy. A basic question is: Should most
people be happy?The case against is straightforward. Anyone who watches the
flow of papers realizes that most papers amount to little in the longer term.
By it's nature research is brutal, where the second-best method is worthless,
and the second person to discover things typically gets no credit. If you
think about this for a moment, it's very different from most other human
endeavors. The second best migrant laborer, construction worker, manager,
conductor, quarterback, etcâ&euro;Ś all can manage quite well. If a reviewer has even
a vaguely predictive sense of what's important in the longer term, then most
people submitting papers will be unhappy.But this argument unravels, in my
experience. Perhaps half of reviews are thoughtless or simply wrong with a
small part being simply malicious. And yet, I'm sure that most reviewers
genuinely believe th</p><p>5 0.27106988 <a title="65-tfidf-5" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>Introduction: Here's a quick reference for summer ML-related conferences sorted by due
date:ConferenceDue dateLocationReviewingKDDFeb 10August 12-16, Beijing,
ChinaSingle BlindCOLTFeb 14June 25-June 27, Edinburgh, ScotlandSingle Blind?
(historically)ICMLFeb 24June 26-July 1, Edinburgh, ScotlandDouble Blind,
author response, zeroSPOFUAIMarch 30August 15-17, Catalina Islands,
CaliforniaDouble Blind, author responseGeographically, this is greatly
dispersed and the UAI/KDD conflict is unfortunate.Machine Learning conferences
are triannual now, betweenNIPS,AIStat, andICML. This has not always been the
case: the academic default is annual summer conferences, then NIPS started
with a December conference, and now AIStat has grown into an April
conference.However, the first claim is not quite correct. NIPS and AIStat have
few competing venues while ICML implicitly competes with many other
conferences accepting machine learning related papers. SinceJoelleand I are
taking a turn as program chairs this year, I</p><p>6 0.21874897 <a title="65-tfidf-6" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>7 0.20468269 <a title="65-tfidf-7" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>8 0.20304468 <a title="65-tfidf-8" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>9 0.20150855 <a title="65-tfidf-9" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>10 0.19390193 <a title="65-tfidf-10" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>11 0.19098119 <a title="65-tfidf-11" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>12 0.18778242 <a title="65-tfidf-12" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>13 0.16430229 <a title="65-tfidf-13" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>14 0.1551418 <a title="65-tfidf-14" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>15 0.15465549 <a title="65-tfidf-15" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>16 0.15114617 <a title="65-tfidf-16" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>17 0.14055122 <a title="65-tfidf-17" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>18 0.13901156 <a title="65-tfidf-18" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>19 0.13647063 <a title="65-tfidf-19" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>20 0.13531609 <a title="65-tfidf-20" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.178), (1, 0.309), (2, -0.287), (3, -0.022), (4, -0.032), (5, 0.042), (6, -0.006), (7, 0.034), (8, 0.074), (9, -0.017), (10, -0.032), (11, -0.176), (12, 0.097), (13, -0.053), (14, 0.075), (15, -0.156), (16, -0.005), (17, 0.092), (18, 0.04), (19, 0.039), (20, 0.034), (21, -0.08), (22, -0.012), (23, 0.034), (24, -0.031), (25, -0.1), (26, 0.106), (27, 0.011), (28, -0.012), (29, 0.056), (30, 0.17), (31, -0.105), (32, -0.079), (33, -0.018), (34, -0.136), (35, -0.009), (36, 0.044), (37, 0.055), (38, -0.112), (39, 0.042), (40, 0.067), (41, 0.01), (42, -0.052), (43, -0.051), (44, 0.034), (45, 0.044), (46, 0.003), (47, -0.007), (48, -0.017), (49, -0.084)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9933461 <a title="65-lsi-1" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>2 0.90450794 <a title="65-lsi-2" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>3 0.79550922 <a title="65-lsi-3" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>Introduction: Most long conversations between academics seem to converge on the topic of
reviewing where almost no one is happy. A basic question is: Should most
people be happy?The case against is straightforward. Anyone who watches the
flow of papers realizes that most papers amount to little in the longer term.
By it's nature research is brutal, where the second-best method is worthless,
and the second person to discover things typically gets no credit. If you
think about this for a moment, it's very different from most other human
endeavors. The second best migrant laborer, construction worker, manager,
conductor, quarterback, etcâ&euro;Ś all can manage quite well. If a reviewer has even
a vaguely predictive sense of what's important in the longer term, then most
people submitting papers will be unhappy.But this argument unravels, in my
experience. Perhaps half of reviews are thoughtless or simply wrong with a
small part being simply malicious. And yet, I'm sure that most reviewers
genuinely believe th</p><p>4 0.72162974 <a title="65-lsi-4" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>5 0.65061522 <a title="65-lsi-5" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>Introduction: Just about nothing could keep me from attendingICML, except forDorawho arrived
on Monday. Consequently, I have only secondhand reports that the conference is
going well.For those who are remote (like me) or after the conference (like
everyone),Mark Reidhas setup theICML discussionsite where you can comment on
any paper or subscribe to papers. Authors are automatically subscribed to
their own papers, so it should be possible to have a discussion significantly
after the fact, as people desire.We also conducted a survey before the
conference and have thesurvey resultsnow. This can be compared with theICML
2010 survey results. Looking at the comparable questions, we can sometimes
order the answers to have scores ranging from 0 to 3 or 0 to 4 with 3 or 4
being best and 0 worst, then compute the average difference between 2012 and
2010.Glancing through them, I see:Most people found the papers they reviewed a
good fit for their expertise (-.037 w.r.t 2010). Achieving this was one of our
subgo</p><p>6 0.60731655 <a title="65-lsi-6" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>7 0.60117292 <a title="65-lsi-7" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>8 0.5903722 <a title="65-lsi-8" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>9 0.55781221 <a title="65-lsi-9" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>10 0.55206829 <a title="65-lsi-10" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>11 0.54863948 <a title="65-lsi-11" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>12 0.54443991 <a title="65-lsi-12" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>13 0.54143625 <a title="65-lsi-13" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>14 0.5379051 <a title="65-lsi-14" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>15 0.53737503 <a title="65-lsi-15" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>16 0.50576037 <a title="65-lsi-16" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>17 0.4925645 <a title="65-lsi-17" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>18 0.48613998 <a title="65-lsi-18" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>19 0.45781991 <a title="65-lsi-19" href="../hunch_net-2006/hunch_net-2006-04-17-Rexa_is_live.html">173 hunch net-2006-04-17-Rexa is live</a></p>
<p>20 0.44974181 <a title="65-lsi-20" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.105), (61, 0.042), (68, 0.043), (74, 0.139), (82, 0.549)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96383733 <a title="65-lda-1" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>2 0.92203814 <a title="65-lda-2" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>Introduction: Geoff Gordonpoints outAIStats 2011in Ft. Lauderdale, Florida. Thecall for
papersis now out, due Nov. 1. The plan is toexperiment with the review
processto encourage quality in several ways. I expect to submit a paper and
would encourage others with good research to do likewise.</p><p>3 0.83552623 <a title="65-lda-3" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>Introduction: …is discussed inthis nytimes article. I generally expect such approaches to
become more common since computers are getting faster, machine learning is
getting better, and data is becoming more plentiful. This is another example
where machine learning technology may have a huge economic impact. Some side
notes:We-in-research know almost nothing about how these things are done
(because it is typically a corporate secret).… but the limited discussion in
the article seem naive from a machine learning viewpoint.The learning process
used apparently often fails to take into account transaction costs.What little
of the approaches is discussed appears modeling based. It seems plausible that
more direct prediction methods can yield an edge.One difficulty with stock
picking as a research topic is that it is inherently a zero sum game (for
every winner, there is a loser). Much of the rest of research is positive sum
(basically, everyone wins).</p><p>4 0.81846362 <a title="65-lda-4" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>5 0.66702515 <a title="65-lda-5" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>Introduction: This post is about a technology which could develop in the future.Right now, a
new drug might be tested by finding patients with some diagnosis and giving or
not giving them a drug according to a secret randomization. The outcome is
observed, and if the average outcome for those treated is measurably better
than the average outcome for those not treated, the drug might become a
standard treatment.Generalizing this, a filterFsorts people into two groups:
those for treatmentAand those not for treatmentBbased upon observationsx. To
measure the outcome, you randomize between treatment and nontreatment of
groupAand measure the relative performance of the treatment.A problem often
arises: in many cases the treated group does not do better than the nontreated
group. A basic question is: does this mean the treatment is bad? With respect
to the filterFit may mean that, but with respect to another filterF', the
treatment might be very effective. For example, a drug might work great for
people wh</p><p>6 0.60983407 <a title="65-lda-6" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>7 0.57559341 <a title="65-lda-7" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>8 0.53438246 <a title="65-lda-8" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>9 0.50500923 <a title="65-lda-9" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>10 0.49952447 <a title="65-lda-10" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>11 0.48528332 <a title="65-lda-11" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>12 0.47693896 <a title="65-lda-12" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>13 0.47274941 <a title="65-lda-13" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>14 0.46520483 <a title="65-lda-14" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>15 0.46221131 <a title="65-lda-15" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>16 0.45877451 <a title="65-lda-16" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>17 0.45834178 <a title="65-lda-17" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>18 0.4556666 <a title="65-lda-18" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>19 0.44394073 <a title="65-lda-19" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>20 0.43494236 <a title="65-lda-20" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
