<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>39 hunch net-2005-03-10-Breaking Abstractions</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-39" href="#">hunch_net-2005-39</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>39 hunch net-2005-03-10-Breaking Abstractions</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-39-html" href="http://hunch.net/?p=43">html</a></p><p>Introduction: Sam Roweis's comment reminds me of a more general issue that comes up in doing
research: abstractions always break.Real number's aren't. Most real numbers
can not be represented with any machine. One implication of this is that many
real-number based algorithms have difficulties when implemented with floating
point numbers.The box on your desk is not a turing machine. A turing machine
can compute anything computable, given sufficient time. A typical computer
fails terribly when the state required for the computation exceeds some
limit.Nash equilibria aren't equilibria. This comes up when trying to predict
human behavior based on the result of the equilibria computation. Often, it
doesn't work.Theprobabilityisn't. Probability is an abstraction expressing
either our lack of knowledge (the Bayesian viewpoint) or fundamental
randomization (the frequentist viewpoint). From the frequentist viewpoint the
lack of knowledge typically precludes actually knowing the fundamental
randomization. Fro</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Sam Roweis's comment reminds me of a more general issue that comes up in doing research: abstractions always break. [sent-1, score-0.432]
</p><p>2 Most real numbers can not be represented with any machine. [sent-3, score-0.156]
</p><p>3 One implication of this is that many real-number based algorithms have difficulties when implemented with floating point numbers. [sent-4, score-0.415]
</p><p>4 A turing machine can compute anything computable, given sufficient time. [sent-6, score-0.318]
</p><p>5 A typical computer fails terribly when the state required for the computation exceeds some limit. [sent-7, score-0.288]
</p><p>6 This comes up when trying to predict human behavior based on the result of the equilibria computation. [sent-9, score-0.526]
</p><p>7 Probability is an abstraction expressing either our lack of knowledge (the Bayesian viewpoint) or fundamental randomization (the frequentist viewpoint). [sent-12, score-1.159]
</p><p>8 From the frequentist viewpoint the lack of knowledge typically precludes actually knowing the fundamental randomization. [sent-13, score-1.129]
</p><p>9 From the Bayesian viewpoint, precisely specifying our lack of knowledge is extremely difficult and typically not done. [sent-14, score-0.703]
</p><p>10 So, what should we do when we learn that our basic tools can break? [sent-15, score-0.279]
</p><p>11 The answer, of course is to keep using them until something better comes along. [sent-16, score-0.22]
</p><p>12 However, the uncomfortable knowledge our tools break is necessary in a few ways:When considering a new abstraction, the existence of a break does not imply that it is a useless abstraction. [sent-17, score-1.801]
</p><p>13 (Just as the existence of the breaks above does not imply that they are useless abstractions. [sent-18, score-0.573]
</p><p>14 )When using an abstraction in some new way, we must generally consider "is this a reasonable use? [sent-19, score-0.343]
</p><p>15 We should actively consider the "rate of breakage" when deciding amongst tools. [sent-21, score-0.235]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('break', 0.329), ('tools', 0.279), ('viewpoint', 0.262), ('abstraction', 0.261), ('knowledge', 0.231), ('equilibria', 0.215), ('frequentist', 0.203), ('existence', 0.186), ('lack', 0.175), ('turing', 0.174), ('useless', 0.164), ('comes', 0.151), ('imply', 0.126), ('terribly', 0.116), ('desk', 0.116), ('reminds', 0.116), ('roweis', 0.116), ('computable', 0.107), ('floating', 0.107), ('bayesian', 0.102), ('abstractions', 0.101), ('sam', 0.101), ('fundamental', 0.099), ('expressing', 0.097), ('breaks', 0.097), ('exceeds', 0.097), ('box', 0.093), ('randomization', 0.093), ('represented', 0.093), ('uncomfortable', 0.093), ('implication', 0.087), ('behavior', 0.082), ('deciding', 0.082), ('consider', 0.082), ('typically', 0.081), ('knowing', 0.078), ('specifying', 0.078), ('based', 0.078), ('implemented', 0.077), ('fails', 0.075), ('anything', 0.074), ('precisely', 0.072), ('actively', 0.071), ('compute', 0.07), ('keep', 0.069), ('extremely', 0.066), ('difficulties', 0.066), ('comment', 0.064), ('considering', 0.064), ('numbers', 0.063)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="39-tfidf-1" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>Introduction: Sam Roweis's comment reminds me of a more general issue that comes up in doing
research: abstractions always break.Real number's aren't. Most real numbers
can not be represented with any machine. One implication of this is that many
real-number based algorithms have difficulties when implemented with floating
point numbers.The box on your desk is not a turing machine. A turing machine
can compute anything computable, given sufficient time. A typical computer
fails terribly when the state required for the computation exceeds some
limit.Nash equilibria aren't equilibria. This comes up when trying to predict
human behavior based on the result of the equilibria computation. Often, it
doesn't work.Theprobabilityisn't. Probability is an abstraction expressing
either our lack of knowledge (the Bayesian viewpoint) or fundamental
randomization (the frequentist viewpoint). From the frequentist viewpoint the
lack of knowledge typically precludes actually knowing the fundamental
randomization. Fro</p><p>2 0.20294847 <a title="39-tfidf-2" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for thereductions
tutorialAlina,Bianca, and I are planning to do atICML. Please come, if you are
interested.Many research programs can be thought of as finding and building
new useful abstractions. The running example I'll use islearning
reductionswhere I have experience. The basic abstraction here is that we can
build a learning algorithm capable of solving classification problems up to a
small expected regret. This is used repeatedly to solve more complex
problems.In working on a new abstraction, I think you typically run into many
substantial problems of understanding, which make publishing particularly
difficult.It is difficult to seriously discuss the reason behind or mechanism
for abstraction in a conference paper with small page limits. People rarely
see such discussions and hence have little basis on which to think about new
abstractions. Another difficulty is that when building an abstraction, you
often don't know the right way to</p><p>3 0.19585945 <a title="39-tfidf-3" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.
There are at least 3 distinct ways the word is used.BayesianThe Bayesian
notion of probability is a 'degree of belief'. The degree of belief that some
event (i.e. "stock goes up" or "stock goes down") occurs can be measured by
asking a sequence of questions of the form "Would you bet the stock goes up or
down atYto 1 odds?" A consistent better will switch from 'for' to 'against' at
some single value ofY. The probability is thenY/(Y+1). Bayesian probabilities
express lack of knowledge rather than randomization. They are useful in
learning because we often lack knowledge and expressing that lack flexibly
makes the learning algorithms work better. Bayesian Learning uses
'probability' in this way exclusively.FrequentistThe Frequentist notion of
probability is a rate of occurence. A rate of occurrence can be measured by
doing an experiment many times. If an event occursktimes innexperiments then
it has probability ab</p><p>4 0.129926 <a title="39-tfidf-4" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>Introduction: One viewpoint on academia is that it is inherently adversarial: there are
finite research dollars, positions, and students to work with, implying a
zero-sum game between different participants. This is not a viewpoint that I
want to promote, as I consider it flawed. However, I know several people
believe strongly in this viewpoint, and I have found it to have substantial
explanatory power.For example:It explains why your paper was rejected based on
poor logic. The reviewer wasn't concerned with research quality, but rather
with rejecting a competitor.It explains why professors rarely work together.
The goal of a non-tenured professor (at least) is to get tenure, and a case
for tenure comes from a portfolio of work that is undisputably yours.It
explains why new research programs are not quickly adopted. Adopting a
competitor's program is impossible, if your career is based on the competitor
being wrong.Different academic groups subscribe to the adversarial viewpoint
in different degrees</p><p>5 0.11113199 <a title="39-tfidf-5" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>Introduction: All branches of machine learning seem to be united in the idea of using data
to make predictions. However, people disagree to some extent about what this
means. One way to categorize these different goals is on an axis, where one
extreme is "tools to aid a human in using data to do prediction" and the other
extreme is "tools to do prediction with no human intervention". Here is my
estimate of where various elements of machine learning fall on this
spectrum.Human NecessaryHuman partially necessaryHuman unnecessaryClustering,
data visualizationBayesian Learning, Probabilistic Models, Graphical
ModelsKernel Learning (SVM's, etc..)Decision Trees?Reinforcement LearningThe
exact position of each element is of course debatable. My reasoning is that
clustering and data visualization are nearly useless for prediction without a
human in the loop. Bayesian/probabilistic models/graphical models generally
require a human to sit and think about what is a good prior/structure. Kernel
learning approac</p><p>6 0.11002313 <a title="39-tfidf-6" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>7 0.10972086 <a title="39-tfidf-7" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>8 0.086181939 <a title="39-tfidf-8" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>9 0.084106594 <a title="39-tfidf-9" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>10 0.082364127 <a title="39-tfidf-10" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>11 0.082048267 <a title="39-tfidf-11" href="../hunch_net-2006/hunch_net-2006-10-22-Exemplar_programming.html">215 hunch net-2006-10-22-Exemplar programming</a></p>
<p>12 0.080148704 <a title="39-tfidf-12" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>13 0.079217359 <a title="39-tfidf-13" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>14 0.078933403 <a title="39-tfidf-14" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>15 0.075571135 <a title="39-tfidf-15" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>16 0.074753575 <a title="39-tfidf-16" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>17 0.069682084 <a title="39-tfidf-17" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>18 0.069501959 <a title="39-tfidf-18" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>19 0.069500975 <a title="39-tfidf-19" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>20 0.069372997 <a title="39-tfidf-20" href="../hunch_net-2011/hunch_net-2011-12-13-Vowpal_Wabbit_version_6.1_%26%23038%3B_the_NIPS_tutorial.html">451 hunch net-2011-12-13-Vowpal Wabbit version 6.1 &#038; the NIPS tutorial</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.158), (1, -0.05), (2, 0.041), (3, -0.093), (4, 0.021), (5, -0.002), (6, -0.066), (7, 0.007), (8, 0.024), (9, 0.023), (10, 0.004), (11, -0.037), (12, 0.029), (13, -0.092), (14, 0.006), (15, -0.047), (16, 0.052), (17, 0.005), (18, -0.062), (19, 0.008), (20, -0.034), (21, -0.014), (22, -0.05), (23, 0.049), (24, 0.072), (25, -0.105), (26, -0.01), (27, 0.024), (28, -0.013), (29, -0.045), (30, 0.011), (31, 0.025), (32, 0.057), (33, 0.036), (34, 0.085), (35, -0.019), (36, -0.057), (37, 0.02), (38, -0.051), (39, -0.154), (40, 0.005), (41, -0.049), (42, -0.082), (43, -0.011), (44, -0.024), (45, -0.082), (46, 0.006), (47, -0.104), (48, -0.034), (49, 0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97623742 <a title="39-lsi-1" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>Introduction: Sam Roweis's comment reminds me of a more general issue that comes up in doing
research: abstractions always break.Real number's aren't. Most real numbers
can not be represented with any machine. One implication of this is that many
real-number based algorithms have difficulties when implemented with floating
point numbers.The box on your desk is not a turing machine. A turing machine
can compute anything computable, given sufficient time. A typical computer
fails terribly when the state required for the computation exceeds some
limit.Nash equilibria aren't equilibria. This comes up when trying to predict
human behavior based on the result of the equilibria computation. Often, it
doesn't work.Theprobabilityisn't. Probability is an abstraction expressing
either our lack of knowledge (the Bayesian viewpoint) or fundamental
randomization (the frequentist viewpoint). From the frequentist viewpoint the
lack of knowledge typically precludes actually knowing the fundamental
randomization. Fro</p><p>2 0.6432212 <a title="39-lsi-2" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.
There are at least 3 distinct ways the word is used.BayesianThe Bayesian
notion of probability is a 'degree of belief'. The degree of belief that some
event (i.e. "stock goes up" or "stock goes down") occurs can be measured by
asking a sequence of questions of the form "Would you bet the stock goes up or
down atYto 1 odds?" A consistent better will switch from 'for' to 'against' at
some single value ofY. The probability is thenY/(Y+1). Bayesian probabilities
express lack of knowledge rather than randomization. They are useful in
learning because we often lack knowledge and expressing that lack flexibly
makes the learning algorithms work better. Bayesian Learning uses
'probability' in this way exclusively.FrequentistThe Frequentist notion of
probability is a rate of occurence. A rate of occurrence can be measured by
doing an experiment many times. If an event occursktimes innexperiments then
it has probability ab</p><p>3 0.60723197 <a title="39-lsi-3" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>Introduction: A calibrated predictor is one which predicts the probability of a binary event
with the property: For all predictionsp, the proportion of the time that1is
observed isp.Since there are infinitely manyp, this definition must be
"softened" to make sense for any finite number of samples. The standard method
for "softening" is to consider all predictions in a small neighborhood about
each possiblep.A great deal of effort has been devoted to strategies for
achieving calibrated (such ashere) prediction. With statements like: (under
minimal conditions) you can always make calibrated predictions.Given the
strength of these statements, we might conclude we are done, but that would be
a "confusion of ends". A confusion of ends arises in the following way:We want
good probabilistic predictions.Good probabilistic predictions are
calibrated.Therefore, we want calibrated predictions.The "Therefore" step
misses the fact that calibration is a necessary but not
asufficientcharacterization of good probab</p><p>4 0.5491097 <a title="39-lsi-4" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>Introduction: A few weeks ago I readthis. David Blei and I spent some time thinking hard
about this a few years back (thanks to Kary Myers for pointing us to it):In
short I was thinking that Ã¢â‚¬Å“bayesian belief updatingÃ¢â‚¬Â and
Ã¢â‚¬Å“maximum entropyÃ¢â‚¬Â were two othogonal principles. But it appear
that they are not, and that they can even be in conflict !Example (from Kass
1996); consider a Die (6 sides), consider prior knowledge E[X]=3.5.Maximum
entropy leads to P(X)= (1/6, 1/6, 1/6, 1/6, 1/6, 1/6).Now consider a new piece
of evidence A=Ã¢â‚¬ÂX is an odd numberÃ¢â‚¬ÂBayesian posterior P(X|A)=
P(A|X) P(X) = (1/3, 0, 1/3, 0, 1/3, 0).But MaxEnt with the constraints
E[X]=3.5 and E[Indicator function of A]=1 leads to (.22, 0, .32, 0, .47, 0) !!
(note that E[Indicator function of A]=P(A))Indeed, for MaxEnt, because there
is no more Ã¢â‚¬Ëœ6Ã¢â‚¬Â², big numbers must be more probable to ensure an
average of 3.5. For bayesian updating, P(X|A) doesnÃ¢â‚¬â„¢t have to have a
3.5 expectation. P(X) a</p><p>5 0.53595614 <a title="39-lsi-5" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>Introduction: I don't consider myself a "Bayesian", but I do try hard to understand why
Bayesian learning works. For the purposes of this post, Bayesian learning is a
simple process of:Specify a prior over world models.Integrate using Bayes law
with respect to all observed information to compute a posterior over world
models.Predict according to the posterior.Bayesian learning has many
advantages over other learning programs:InterpolationBayesian learning methods
interpolate all the way to pure engineering. When faced with any learning
problem, there is a choice of how much time and effort a human vs. a computer
puts in. (For example, the mars rover pathfinding algorithms are almost
entirely engineered.) When creating an engineered system, you build a model of
the world and then find a good controller in that model. Bayesian methods
interpolate to this extreme because the Bayesian prior can be a delta function
on one model of the world. What this means is that a recipe of "think harder"
(about speci</p><p>6 0.52560759 <a title="39-lsi-6" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>7 0.50215524 <a title="39-lsi-7" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>8 0.50172997 <a title="39-lsi-8" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>9 0.48479438 <a title="39-lsi-9" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>10 0.48164332 <a title="39-lsi-10" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>11 0.47753465 <a title="39-lsi-11" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>12 0.47616288 <a title="39-lsi-12" href="../hunch_net-2005/hunch_net-2005-11-05-The_design_of_a_computing_cluster.html">128 hunch net-2005-11-05-The design of a computing cluster</a></p>
<p>13 0.46758857 <a title="39-lsi-13" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>14 0.45071918 <a title="39-lsi-14" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>15 0.44361636 <a title="39-lsi-15" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>16 0.43760812 <a title="39-lsi-16" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>17 0.43596384 <a title="39-lsi-17" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>18 0.42293257 <a title="39-lsi-18" href="../hunch_net-2006/hunch_net-2006-09-07-Objective_and_subjective_interpretations_of_probability.html">205 hunch net-2006-09-07-Objective and subjective interpretations of probability</a></p>
<p>19 0.4226945 <a title="39-lsi-19" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>20 0.41763002 <a title="39-lsi-20" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(23, 0.042), (25, 0.029), (35, 0.12), (42, 0.265), (45, 0.031), (53, 0.024), (68, 0.063), (69, 0.021), (74, 0.058), (79, 0.218), (88, 0.02), (95, 0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93112761 <a title="39-lda-1" href="../hunch_net-2007/hunch_net-2007-06-23-Machine_Learning_Jobs_are_Growing_on_Trees.html">250 hunch net-2007-06-23-Machine Learning Jobs are Growing on Trees</a></p>
<p>Introduction: The consensus of several discussions at ICML is that the number of jobs for
people knowing machine learning well substantially exceeds supply. This is my
experience as well. Demand comes from many places, but I've seen particularly
strong demand from trading companies and internet startups.Like all interest
bursts, this one will probably pass because of economic recession or other
distractions. Nevertheless, the general outlook for machine learning in
business seems to be good. Machine learning is all about optimization when
there is uncertainty and lots of data. The quantity of data available is
growing quickly as computer-run processes and sensors become more common, and
the quality of the data is dropping since there is little editorial control in
it's collection. Machine Learning is a difficult subject to master (*), so
those who do should remain in demand over the long term.(*) In fact, it would
be reasonable to claim that no one has mastered it--there are just some people
who kno</p><p>same-blog 2 0.92769229 <a title="39-lda-2" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>Introduction: Sam Roweis's comment reminds me of a more general issue that comes up in doing
research: abstractions always break.Real number's aren't. Most real numbers
can not be represented with any machine. One implication of this is that many
real-number based algorithms have difficulties when implemented with floating
point numbers.The box on your desk is not a turing machine. A turing machine
can compute anything computable, given sufficient time. A typical computer
fails terribly when the state required for the computation exceeds some
limit.Nash equilibria aren't equilibria. This comes up when trying to predict
human behavior based on the result of the equilibria computation. Often, it
doesn't work.Theprobabilityisn't. Probability is an abstraction expressing
either our lack of knowledge (the Bayesian viewpoint) or fundamental
randomization (the frequentist viewpoint). From the frequentist viewpoint the
lack of knowledge typically precludes actually knowing the fundamental
randomization. Fro</p><p>3 0.78077185 <a title="39-lda-3" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>Introduction: Many learning algorithms used in practice are fairly simple. Viewed
representationally, many prediction algorithms either compute a linear
separator of basic features (perceptron, winnow, weighted majority, SVM) or
perhaps a linear separator of slightly more complex features (2-layer neural
networks or kernelized SVMs). Should we go beyond this, and start using "deep"
representations?What is deep learning?Intuitively, deep learning is about
learning to predict in ways which can involve complex dependencies between the
input (observed) features.Specifying this more rigorously turns out to be
rather difficult. Consider the following cases:SVM with Gaussian Kernel. This
is not considered deep learning, because an SVM with a gaussian kernel can't
succinctly represent certain decision surfaces. One ofYann LeCun's examples is
recognizing objects based on pixel values. An SVM will need a new support
vector for each significantly different background. Since the number of
distinct backgrounds i</p><p>4 0.7788325 <a title="39-lda-4" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>Introduction: Yahoo! laid off people. Unlike every previous time there have been layoffs,
this is serious forYahoo! Research.We had advanced warning
fromPrabhakarthrough thesimple act of leaving. Yahoo! Research was a world
class organization that Prabhakar recruited much of personally, so it is
deeply implausible that he would spontaneously decide to leave. My first
thought when I saw the news was "Uhoh,Robsaid that he knew it was serious when
the head of ATnT Research left." In this case it was even more significant,
because Prabhakar recruited me on the premise that Y!R was an experiment in
how research should be done: via a combination of high quality people and high
engagement with the company. Prabhakar's departure is a clear end to that
experiment.The result is ambiguous from a business perspective. Y!R clearly
was not capable of saving the company from its illnesses. I'm not privy to the
internal accounting of impact and this is the kind of subject where there can
easily be great disagreemen</p><p>5 0.77520168 <a title="39-lda-5" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>Introduction: This is apaperby Yann LeCun and Fu Jie Huang published atAISTAT 2005. I found
this paper very difficult to read, but it does have some point about a
computational shortcut.This paper takes for granted that the method of solving
a problem is gradient descent on parameters. Given this assumption, the
question arises: Do you want to do gradient descent on a probabilistic model
or something else?All (conditional) probabilistic models have the formp(y|x) =
f(x,y)/Z(x)whereZ(x) = sumyf(x,y)(the paper calls- log f(x,y)an "energy").
Iffis parameterized by somew, the gradient has a term forZ(x), and hence for
every value ofy. The paper claims, that such models can be optimized for
classification purposes using only the correctyand the othery' not ywhich
maximizesf(x,y). This can even be done on unnormalizable models. The paper
further claims that this can be done with an approximate maximum. These claims
are plausible based on experimental results and intuition.It wouldn't surprise
me to learn</p><p>6 0.77400935 <a title="39-lda-6" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>7 0.77398914 <a title="39-lda-7" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>8 0.7728799 <a title="39-lda-8" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>9 0.77137768 <a title="39-lda-9" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>10 0.77035707 <a title="39-lda-10" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>11 0.77010208 <a title="39-lda-11" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>12 0.76877177 <a title="39-lda-12" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>13 0.76777124 <a title="39-lda-13" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>14 0.76548451 <a title="39-lda-14" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>15 0.76534283 <a title="39-lda-15" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>16 0.76482421 <a title="39-lda-16" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>17 0.76445538 <a title="39-lda-17" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>18 0.76444817 <a title="39-lda-18" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>19 0.76435113 <a title="39-lda-19" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>20 0.76147491 <a title="39-lda-20" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
