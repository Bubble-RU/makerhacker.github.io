<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-31" href="#">hunch_net-2005-31</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-31-html" href="http://hunch.net/?p=34">html</a></p><p>Introduction: This, again, is something of a research direction rather than a single
problem.There are several metrics people care about which depend upon the
relative ranking of examples and there are sometimes good reasons to care
about such metrics. Examples includeAROC, "F1â&euro;ł, the proportion of the time
that the top ranked element is in some class, the proportion of the top 10
examples in some class (google's problem), the lowest ranked example of some
class, and the "sort distance" from a predicted ranking to a correct ranking.
Seeherefor an example of some of these.ProblemWhat does the ability to
classify well imply about performance under these metrics?Past
WorkProbabilistic classification under squared errorcan be solved with a
classifier. A counterexample shows this does not imply a good AROC.Sample
complexity bounds forAROC(andhere).A paper on "Learning to Order
Things".DifficultySeveral of these may be easy. Some of them may be
hard.ImpactPositive or negative results will broaden our under</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This, again, is something of a research direction rather than a single problem. [sent-1, score-0.273]
</p><p>2 There are several metrics people care about which depend upon the relative ranking of examples and there are sometimes good reasons to care about such metrics. [sent-2, score-1.581]
</p><p>3 Examples includeAROC, "F1â&euro;ł, the proportion of the time that the top ranked element is in some class, the proportion of the top 10 examples in some class (google's problem), the lowest ranked example of some class, and the "sort distance" from a predicted ranking to a correct ranking. [sent-3, score-2.911]
</p><p>4 ProblemWhat does the ability to classify well imply about performance under these metrics? [sent-5, score-0.484]
</p><p>5 Past WorkProbabilistic classification under squared errorcan be solved with a classifier. [sent-6, score-0.26]
</p><p>6 A counterexample shows this does not imply a good AROC. [sent-7, score-0.505]
</p><p>7 ImpactPositive or negative results will broaden our understanding of the relationship between different learning goals. [sent-12, score-0.351]
</p><p>8 It might also yield new algorithms (via the reduction) for solving these problems. [sent-13, score-0.159]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ranked', 0.386), ('proportion', 0.317), ('metrics', 0.274), ('top', 0.243), ('class', 0.242), ('ranking', 0.226), ('care', 0.199), ('imply', 0.186), ('andhere', 0.171), ('counterexample', 0.171), ('classify', 0.159), ('depend', 0.159), ('seeherefor', 0.159), ('examples', 0.158), ('relationship', 0.132), ('distance', 0.118), ('google', 0.118), ('element', 0.116), ('predicted', 0.116), ('squared', 0.105), ('negative', 0.098), ('relative', 0.098), ('yield', 0.095), ('past', 0.094), ('direction', 0.094), ('shows', 0.093), ('correct', 0.092), ('upon', 0.09), ('reduction', 0.087), ('sort', 0.086), ('solved', 0.081), ('bounds', 0.077), ('single', 0.077), ('classification', 0.074), ('may', 0.071), ('ability', 0.071), ('example', 0.069), ('reasons', 0.068), ('performance', 0.068), ('order', 0.068), ('via', 0.067), ('complexity', 0.067), ('solving', 0.064), ('understanding', 0.061), ('results', 0.06), ('good', 0.055), ('sometimes', 0.055), ('something', 0.053), ('rather', 0.049), ('things', 0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="31-tfidf-1" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>Introduction: This, again, is something of a research direction rather than a single
problem.There are several metrics people care about which depend upon the
relative ranking of examples and there are sometimes good reasons to care
about such metrics. Examples includeAROC, "F1â&euro;ł, the proportion of the time
that the top ranked element is in some class, the proportion of the top 10
examples in some class (google's problem), the lowest ranked example of some
class, and the "sort distance" from a predicted ranking to a correct ranking.
Seeherefor an example of some of these.ProblemWhat does the ability to
classify well imply about performance under these metrics?Past
WorkProbabilistic classification under squared errorcan be solved with a
classifier. A counterexample shows this does not imply a good AROC.Sample
complexity bounds forAROC(andhere).A paper on "Learning to Order
Things".DifficultySeveral of these may be easy. Some of them may be
hard.ImpactPositive or negative results will broaden our under</p><p>2 0.14023088 <a title="31-tfidf-2" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>Introduction: Yann LeCunand I are coteaching a class onLarge Scale Machine Learningstarting
late Januaryat NYU. This class will cover many tricks to get machine learning
working well on datasets with many features, examples, and classes, along with
several elements of deep learning and support systems enabling the
previous.This is not a beginning class--you really need to have taken a basic
machine learning class previously to follow along. Students will be able to
run and experiment with large scale learning algorithms sinceYahoo!has donated
servers which are being configured into a small scaleHadoopcluster. We are
planning to cover the frontier of research in scalable learning algorithms, so
good class projects could easily lead to papers.For me, this is a chance to
teach on many topics of past research. In general, it seems like researchers
should engage in at least occasional teaching of research, both as a proof of
teachability and to see their own research through that lens. More generally,
I</p><p>3 0.12141383 <a title="31-tfidf-3" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>Introduction: Let's define a learning problem as making predictions given past data. There
are several ways to attack the learning problem which seem to be equivalent to
solving the learning problem.Find the InvariantThis viewpoint says that
learning is all about learning (or incorporating) transformations of objects
that do not change the correct prediction. The best possible invariant is the
one which says "all things of the same class are the same". Finding this is
equivalent to learning. This viewpoint is particularly common when working
with image features.Feature SelectionThis viewpoint says that the way to learn
is by finding the right features to input to a learning algorithm. The best
feature is the one which is the class to predict. Finding this is equivalent
to learning for all reasonable learning algorithms. This viewpoint is common
in several applications of machine learning. SeeGilad's and Bianca's
comments.Find the RepresentationThis is almost the same as feature selection,
except int</p><p>4 0.1208004 <a title="31-tfidf-4" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>Introduction: Essentially everyone who writes research papers suffers rejections. They
always sting immediately, but upon further reflection many of these rejections
come to seem reasonable. Maybe the equations had too many typos or maybe the
topic just isn't as important as was originally thought. A few rejections do
not come to seem acceptable, and these form the basis of reviewing horror
stories, a great material for conversations. I've decided to share three of
mine, now all safely a bit distant in the past.Prediction Theory for
Classification Tutorial. This is a tutorial about tight sample complexity
bounds for classification that I submitted toJMLR. The first decision I heard
was a reject which appeared quite unjust to me--for example one of the
reviewers appeared to claim that all the content was in standard statistics
books. Upon further inquiry, several citations were given, none of which
actually covered the content. Later, I was shocked to hear the paper was
accepted. Apparently, the pape</p><p>5 0.10013504 <a title="31-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?Reductions are machines which turn solvers for one problem into solvers
for another problem.Why?Reductions are useful for several reasons.Laziness.
Reducing a problem to classification make at least 10 learning algorithms
available to solve a problem. Inventing 10 learning algorithms is quite a bit
of work. Similarly, programming a reduction is often trivial, while
programming a learning algorithm is a great deal of work.Crystallization. The
problems we often want to solve in learning are worst-case-impossible, but
average case feasible. By reducing all problems onto one or a few primitives,
we can fine tune these primitives to perform well on real-world problems with
greater precision due to the greater number of problems to validate
on.Theoretical Organization. By studying what reductions are easy vs. hard vs.
impossible, we can learn which problems are roughly equivalent in difficulty
and which are much harder.What we know now.Typesafe reductions. In the
beginning, there was th</p><p>6 0.097148277 <a title="31-tfidf-6" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>7 0.095030926 <a title="31-tfidf-7" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>8 0.094681226 <a title="31-tfidf-8" href="../hunch_net-2005/hunch_net-2005-02-12-ROC_vs._Accuracy_vs._AROC.html">18 hunch net-2005-02-12-ROC vs. Accuracy vs. AROC</a></p>
<p>9 0.091272876 <a title="31-tfidf-9" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>10 0.081606537 <a title="31-tfidf-10" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>11 0.080313429 <a title="31-tfidf-11" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>12 0.079998687 <a title="31-tfidf-12" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>13 0.079486229 <a title="31-tfidf-13" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>14 0.078548342 <a title="31-tfidf-14" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>15 0.07678894 <a title="31-tfidf-15" href="../hunch_net-2006/hunch_net-2006-09-09-How_to_solve_an_NP_hard_problem_in_quadratic_time.html">206 hunch net-2006-09-09-How to solve an NP hard problem in quadratic time</a></p>
<p>16 0.076598585 <a title="31-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>17 0.075886525 <a title="31-tfidf-17" href="../hunch_net-2009/hunch_net-2009-06-24-Interesting_papers_at_UAICMOLT_2009.html">361 hunch net-2009-06-24-Interesting papers at UAICMOLT 2009</a></p>
<p>18 0.073492341 <a title="31-tfidf-18" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>19 0.072302915 <a title="31-tfidf-19" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>20 0.069905192 <a title="31-tfidf-20" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.165), (1, -0.069), (2, -0.029), (3, -0.021), (4, 0.017), (5, -0.048), (6, 0.021), (7, 0.002), (8, -0.001), (9, -0.015), (10, 0.006), (11, 0.018), (12, 0.018), (13, 0.009), (14, 0.007), (15, 0.033), (16, -0.017), (17, -0.045), (18, 0.063), (19, -0.015), (20, 0.096), (21, -0.043), (22, 0.045), (23, -0.075), (24, 0.014), (25, -0.094), (26, -0.004), (27, 0.023), (28, -0.002), (29, -0.001), (30, -0.141), (31, 0.0), (32, -0.033), (33, 0.021), (34, 0.016), (35, -0.026), (36, 0.05), (37, -0.019), (38, 0.022), (39, 0.083), (40, 0.005), (41, -0.123), (42, 0.012), (43, 0.031), (44, 0.032), (45, -0.052), (46, -0.013), (47, -0.044), (48, 0.102), (49, 0.033)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9500286 <a title="31-lsi-1" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>Introduction: This, again, is something of a research direction rather than a single
problem.There are several metrics people care about which depend upon the
relative ranking of examples and there are sometimes good reasons to care
about such metrics. Examples includeAROC, "F1â&euro;ł, the proportion of the time
that the top ranked element is in some class, the proportion of the top 10
examples in some class (google's problem), the lowest ranked example of some
class, and the "sort distance" from a predicted ranking to a correct ranking.
Seeherefor an example of some of these.ProblemWhat does the ability to
classify well imply about performance under these metrics?Past
WorkProbabilistic classification under squared errorcan be solved with a
classifier. A counterexample shows this does not imply a good AROC.Sample
complexity bounds forAROC(andhere).A paper on "Learning to Order
Things".DifficultySeveral of these may be easy. Some of them may be
hard.ImpactPositive or negative results will broaden our under</p><p>2 0.64410055 <a title="31-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-12-ROC_vs._Accuracy_vs._AROC.html">18 hunch net-2005-02-12-ROC vs. Accuracy vs. AROC</a></p>
<p>Introduction: Foster Provostand I discussed the merits of ROC curves vs. accuracy
estimation. Here is a quick summary of our discussion.The "Receiver Operating
Characteristic" (ROC) curve is an alternative to accuracy for the evaluation
of learning algorithms on natural datasets. The ROC curve is acurveand not a
single number statistic. In particular, this means that the comparison of two
algorithms on a dataset does not always produce an obvious order.Accuracy (= 1
- error rate) is a standard method used to evaluate learning algorithms. It is
a single-number summary of performance.AROC is the area under the ROC curve.
It is a single number summary of performance.The comparison of these metrics
is a subtle affair, because in machine learning, they are compared on
different natural datasets. This makes some sense if we accept the hypothesis
"Performance on past learning problems (roughly) predicts performance on
future learning problems."The ROC vs. accuracy discussion is often conflated
with "is the</p><p>3 0.58902293 <a title="31-lsi-3" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>Introduction: Let's define a learning problem as making predictions given past data. There
are several ways to attack the learning problem which seem to be equivalent to
solving the learning problem.Find the InvariantThis viewpoint says that
learning is all about learning (or incorporating) transformations of objects
that do not change the correct prediction. The best possible invariant is the
one which says "all things of the same class are the same". Finding this is
equivalent to learning. This viewpoint is particularly common when working
with image features.Feature SelectionThis viewpoint says that the way to learn
is by finding the right features to input to a learning algorithm. The best
feature is the one which is the class to predict. Finding this is equivalent
to learning for all reasonable learning algorithms. This viewpoint is common
in several applications of machine learning. SeeGilad's and Bianca's
comments.Find the RepresentationThis is almost the same as feature selection,
except int</p><p>4 0.57694834 <a title="31-lsi-4" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>Introduction: This is about methods for phrasing and think about the scope of some theorems
in learning theory. The basic claim is that there are several different ways
of quantifying the scope which sound different yet are essentially the
same.For all sequences of examples. This is the standard quantification in
online learning analysis. Standard theorems would say something like "for all
sequences of predictions by experts, the algorithm A will perform almost as
well as the best expert."For all training sets. This is the standard
quantification for boosting analysis such asadaboostormulticlass
boosting.Standard theorems have the form "for all training sets the error rate
inequalities … hold".For all distributions over examples. This is the one that
we have been using for reductions analysis. Standard theorem statements have
the form "For all distributions over examples, the error rate inequalities …
hold".It is not quite true that each of these is equivalent. For example, in
the online learning se</p><p>5 0.54741919 <a title="31-lsi-5" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>Introduction: One way to organize learning theory is by assumption (in theassumption = axiom
sense), from no assumptions to many assumptions. As you travel down this list,
the statements become stronger, but the scope of applicability decreases.No
assumptionsOnline learningThere exist a meta prediction algorithm which
compete well with the best element of any set of prediction
algorithms.Universal LearningUsing a "bias" of 2- description length of turing
machinein learning is equivalent to all other computable biases up to some
constant.ReductionsThe ability to predict well on classification problems is
equivalent to the ability to predict well on many other learning
problems.Independent and Identically Distributed (IID) DataPerformance
PredictionBased upon past performance, you can predict future
performance.Uniform ConvergencePerformance prediction works even after
choosing classifiers based on the data from large sets of classifiers.IID and
partial constraints on the data sourcePAC LearningThere</p><p>6 0.53681749 <a title="31-lsi-6" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>7 0.52993518 <a title="31-lsi-7" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>8 0.51501375 <a title="31-lsi-8" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>9 0.51479083 <a title="31-lsi-9" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>10 0.5139491 <a title="31-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>11 0.50979233 <a title="31-lsi-11" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>12 0.50853455 <a title="31-lsi-12" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>13 0.50802374 <a title="31-lsi-13" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>14 0.50268465 <a title="31-lsi-14" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>15 0.49801332 <a title="31-lsi-15" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>16 0.49683201 <a title="31-lsi-16" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>17 0.49440148 <a title="31-lsi-17" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>18 0.49163505 <a title="31-lsi-18" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>19 0.48838112 <a title="31-lsi-19" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>20 0.48346996 <a title="31-lsi-20" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.387), (42, 0.346), (45, 0.02), (68, 0.024), (74, 0.096)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9402504 <a title="31-lda-1" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>Introduction: Suppose we have a set of classifierscmaking binary predictions from an
inputxand we see examples in an online fashion. In particular, we repeatedly
see an unlabeled examplex, make a predictiony'(possibly based on the
classifiersc), and then see the correct labely.When one of these classifiers
is perfect, there is a great algorithm available: predict according to the
majority vote over every classifier consistent with every previous example.
This is called the Halving algorithm. It makes at mostlog2|c|mistakes since on
any mistake, at least half of the classifiers are eliminated.Obviously, we
can't generally hope that the there exists a classifier which never errs.
TheBinomial Weighting algorithmis an elegant technique allowing a variant
Halving algorithm to cope with errors by creating a set of virtual classifiers
for every classifier which occasionally disagree with the original classifier.
The Halving algorithm on this set of virtual classifiers satisfies a theorem
of the form:errors</p><p>2 0.91021329 <a title="31-lda-2" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<p>Introduction: According to theNew York Times,Yahoo is releasing Project Panama shortly.
Project Panama is about better predicting which advertisements are relevant to
a search, implying a higher click through rate, implying larger income
forYahoo. There are two things that seem interesting here:A significant
portion of that improved accuracy is almost certainly machine learning at
work.The quantitative effect is huge--the estimate in the article is
$600*106.Googlealready has such improvements andMicrosoft Searchis surely
working on them, which suggest this is (perhaps) a $109per year machine
learning problem.The exact methodology under use is unlikely to be publicly
discussed in the near future because of the competitive enivironment.
Hopefully we'll have some public "war stories" at some point in the future
when this information becomes less sensitive. For now, it's reassuring to
simply note that machine learning is having a big impact.</p><p>3 0.90355057 <a title="31-lda-3" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>Introduction: In many machine learning papers experiments are done and little confidence
bars are reported for the results. This often seems quite clear, until you
actually try to figure out what it means. There are several different kinds of
'confidence' being used, and it's easy to become confused.Confidence =
Probability. For those who haven't worried about confidence for a long time,
confidence is simply the probability of some event. You are confident about
events which have a large probability. This meaning of confidence is
inadequate in many applications because we want to reason about how much more
information we have, how much more is needed, and where to get it. As an
example, a learning algorithm might predict that the probability of an event
is0.5, but it's unclear if the probability is0.5because no examples have been
provided or0.5because many examples have been provided and the event is simply
fundamentally uncertain.Classical Confidence Intervals. These are common in
learning theory.</p><p>same-blog 4 0.9010613 <a title="31-lda-4" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>Introduction: This, again, is something of a research direction rather than a single
problem.There are several metrics people care about which depend upon the
relative ranking of examples and there are sometimes good reasons to care
about such metrics. Examples includeAROC, "F1â&euro;ł, the proportion of the time
that the top ranked element is in some class, the proportion of the top 10
examples in some class (google's problem), the lowest ranked example of some
class, and the "sort distance" from a predicted ranking to a correct ranking.
Seeherefor an example of some of these.ProblemWhat does the ability to
classify well imply about performance under these metrics?Past
WorkProbabilistic classification under squared errorcan be solved with a
classifier. A counterexample shows this does not imply a good AROC.Sample
complexity bounds forAROC(andhere).A paper on "Learning to Order
Things".DifficultySeveral of these may be easy. Some of them may be
hard.ImpactPositive or negative results will broaden our under</p><p>5 0.88981086 <a title="31-lda-5" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data
sourcesD,PrS ~ D(f(D) > g(S)) > 1-dwherefis some function of the distribution
(such as the mean) andgis some function of the observed sampleS. The
constraints onDcan vary between "Independent and identically distributed (IID)
samples from a gaussian with an unknown mean" to "IID samples from an
arbitrary distributionD". There are even some confidence intervals which do
not require IID samples.Classical confidence intervals often confuse people.
They donotsay "with high probability, for my observed sample, the bounds
holds". Instead, they tell you that if you reason according to the confidence
interval in the future (and the constraints onDare satisfied), then you are
not often wrong. Restated, they tell you something about what a safe procedure
is in a stochastic world wheredis the safety parameter.There are a number of
results in theoretical machine learning which use confidence intervals. For
example,TheE3alg</p><p>6 0.79866624 <a title="31-lda-6" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>7 0.75762159 <a title="31-lda-7" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>8 0.73135662 <a title="31-lda-8" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>9 0.71898317 <a title="31-lda-9" href="../hunch_net-2008/hunch_net-2008-01-07-2008_Summer_Machine_Learning_Conference_Schedule.html">283 hunch net-2008-01-07-2008 Summer Machine Learning Conference Schedule</a></p>
<p>10 0.69175798 <a title="31-lda-10" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>11 0.69174469 <a title="31-lda-11" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>12 0.68985057 <a title="31-lda-12" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>13 0.6871435 <a title="31-lda-13" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>14 0.68524551 <a title="31-lda-14" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>15 0.68503821 <a title="31-lda-15" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>16 0.68375921 <a title="31-lda-16" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>17 0.68180555 <a title="31-lda-17" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>18 0.67791861 <a title="31-lda-18" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>19 0.67743444 <a title="31-lda-19" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>20 0.67633903 <a title="31-lda-20" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
