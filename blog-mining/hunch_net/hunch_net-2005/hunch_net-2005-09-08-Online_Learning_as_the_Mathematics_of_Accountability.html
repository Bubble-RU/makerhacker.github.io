<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-109" href="#">hunch_net-2005-109</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-109-html" href="http://hunch.net/?p=117">html</a></p><p>Introduction: Accountability is a social problem. When someone screws up, do you fire them?
Or do you accept the error and let them continue? This is a very difficult
problem and we all know of stories where the wrong decision was made.Online
learning(as meant here), is a subfield of learning theory which analyzes the
online learning model.In the online learning model, there are a set of
hypotheses or "experts". On any instantancex, each expert makes a predictiony.
A master algorithmAuses these predictions to form it's own predictionyAand
then learns the correct predictiony*. This process repeats.The goal of online
learning is to find a master algorithmAwhich uses the advice of the experts to
make good predictions. In particular, we typically want to guarantee that the
master algorithm performs almost as well as the best expert. IfL(e)is the loss
of experteandL(A)is the loss of the master algorithm, it is often possible to
prove:L(A) less than mineL(e) + log(number of experts)over all sequences.In
p</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('experts', 0.33), ('master', 0.314), ('online', 0.214), ('accountability', 0.21), ('isnoassumption', 0.21), ('predictions', 0.189), ('expert', 0.188), ('economists', 0.186), ('advice', 0.174), ('loss', 0.151), ('uncertainty', 0.126), ('drawback', 0.118), ('perform', 0.11), ('associated', 0.102), ('weakening', 0.093), ('predictiony', 0.093), ('collective', 0.093), ('handles', 0.093), ('qualities', 0.093), ('particular', 0.09)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="109-tfidf-1" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem. When someone screws up, do you fire them?
Or do you accept the error and let them continue? This is a very difficult
problem and we all know of stories where the wrong decision was made.Online
learning(as meant here), is a subfield of learning theory which analyzes the
online learning model.In the online learning model, there are a set of
hypotheses or "experts". On any instantancex, each expert makes a predictiony.
A master algorithmAuses these predictions to form it's own predictionyAand
then learns the correct predictiony*. This process repeats.The goal of online
learning is to find a master algorithmAwhich uses the advice of the experts to
make good predictions. In particular, we typically want to guarantee that the
master algorithm performs almost as well as the best expert. IfL(e)is the loss
of experteandL(A)is the loss of the master algorithm, it is often possible to
prove:L(A) less than mineL(e) + log(number of experts)over all sequences.In
p</p><p>2 0.1670431 <a title="109-tfidf-2" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>Introduction: Despite my best intentions, this is not a fully specified problem, but rather
a research direction.Competitive online learning is one of the more compelling
pieces of learning theory because typical statements of the form "this
algorithm will perform almost as well as a large set of other algorithms" rely
only on fully-observable quantities, and are therefore applicable in many
situations. Examples includeWinnow,Weighted Majority, andBinomial Weighting.
Algorithms with this property haven't taken over the world yet. Here might be
some reasons:Lack of caring. Many people working on learning theory don't care
about particular applications much. This means constants in the algorithm are
not optimized, usable code is often not produced, and empirical studies aren't
done.Inefficiency. Viewed from the perspective of other learning algorithms,
online learning is terribly inefficient. It requires that every hypothesis
(called an expert in the online learning setting) be enumerated and tested o</p><p>3 0.15278922 <a title="109-tfidf-3" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>Introduction: TheExponentiated Gradientalgorithm byManfred WarmuthandJyrki Kivinencame out
just as I was starting graduate school, so I missed it both at a conference
and in class. It's a fine algorithm which has a remarkable theoretical
statement accompanying it.The essential statement holds in the "online
learning with an adversary" setting. Initially, there are of set ofnweights,
which might have values(1/n,â&euro;Ś,1/n), (or any other values from a probability
distribution). Everything happens in a round-by-round fashion. On each round,
the following happens:The world reveals a set of featuresx in {0,1}n. In the
online learning with an adversary literature, the features are called
"experts" and thought of as subpredictors, but this interpretation isn't
necessary--you can just use feature values as experts (or maybe the feature
value and the negation of the feature value as two experts).EG makes a
prediction according toy' = w . x(dot product).The world reveals the truthy in
[0,1].EG updates the weights</p><p>4 0.15254632 <a title="109-tfidf-4" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>Introduction: Jacob Abernethy and I have found a computationally tractable method for
computing an optimal (or near optimal depending on setting) master algorithm
combining expert predictions addressingthis open problem. A draft ishere.The
effect of this improvement seems to be about a factor of2decrease in the
regret (= error rate minus best possible error rate) for the low error rate
situation. (At large error rates, there may be no significant
difference.)There are some unfinished details still to consider:When we remove
all of the approximation slack from online learning, is the result a
satisfying learning algorithm, in practice? I consider online learning is one
of the more compelling methods of analyzing and deriving algorithms, but that
expectation must be either met or not by this algorithmSome extra details: The
algorithm is optimal given a small amount of side information (kin the draft).
What is the best way to remove this side information? The removal is necessary
for a practical algori</p><p>5 0.15091822 <a title="109-tfidf-5" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>Introduction: In the online learning with experts setting, you observe a set of predictions,
make a decision, and then observe the truth. This process repeats
indefinitely. In this setting, it is possible to prove theorems of the
sort:master algorithm error count < = k* best predictor error count +
c*log(number of predictors)Is this a statement about learning or about
preservation of learning? We did some experiments to analyze the newBinning
algorithmwhich works in this setting. For several UCI datasets, we reprocessed
them so that features could be used as predictors and then applied several
master algorithms. The first graph confirms that Binning is indeed a better
algorithm according to the tightness of the upper bound.Here, "Best" is the
performance of the best expert. "V. Bound" is the bound forVovk's algorithm
(the previous best). "Bound" is the bound for the Binning algorithm. "Binning"
is the performance of the Binning algorithm. The Binning algorithm clearly has
a tighter bound, and the pe</p><p>6 0.15057364 <a title="109-tfidf-6" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>7 0.14928411 <a title="109-tfidf-7" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>8 0.14684238 <a title="109-tfidf-8" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>9 0.14364965 <a title="109-tfidf-9" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>10 0.14098899 <a title="109-tfidf-10" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>11 0.1407683 <a title="109-tfidf-11" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>12 0.13764587 <a title="109-tfidf-12" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>13 0.13569158 <a title="109-tfidf-13" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>14 0.13183057 <a title="109-tfidf-14" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>15 0.12996203 <a title="109-tfidf-15" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>16 0.12697864 <a title="109-tfidf-16" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>17 0.12585165 <a title="109-tfidf-17" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>18 0.12282198 <a title="109-tfidf-18" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>19 0.11621337 <a title="109-tfidf-19" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>20 0.11579745 <a title="109-tfidf-20" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.26), (1, -0.148), (2, -0.072), (3, 0.029), (4, 0.09), (5, 0.053), (6, 0.055), (7, -0.008), (8, -0.094), (9, -0.094), (10, 0.018), (11, -0.124), (12, -0.018), (13, -0.11), (14, -0.04), (15, 0.053), (16, -0.04), (17, 0.012), (18, -0.069), (19, 0.067), (20, 0.016), (21, -0.009), (22, 0.021), (23, 0.031), (24, -0.022), (25, -0.128), (26, 0.102), (27, -0.028), (28, 0.028), (29, -0.017), (30, -0.061), (31, -0.047), (32, 0.039), (33, -0.096), (34, -0.069), (35, -0.036), (36, -0.052), (37, -0.008), (38, -0.005), (39, -0.049), (40, -0.018), (41, -0.002), (42, 0.043), (43, -0.018), (44, 0.001), (45, 0.075), (46, -0.039), (47, 0.14), (48, -0.033), (49, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96482718 <a title="109-lsi-1" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem. When someone screws up, do you fire them?
Or do you accept the error and let them continue? This is a very difficult
problem and we all know of stories where the wrong decision was made.Online
learning(as meant here), is a subfield of learning theory which analyzes the
online learning model.In the online learning model, there are a set of
hypotheses or "experts". On any instantancex, each expert makes a predictiony.
A master algorithmAuses these predictions to form it's own predictionyAand
then learns the correct predictiony*. This process repeats.The goal of online
learning is to find a master algorithmAwhich uses the advice of the experts to
make good predictions. In particular, we typically want to guarantee that the
master algorithm performs almost as well as the best expert. IfL(e)is the loss
of experteandL(A)is the loss of the master algorithm, it is often possible to
prove:L(A) less than mineL(e) + log(number of experts)over all sequences.In
p</p><p>2 0.68566024 <a title="109-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>Introduction: Despite my best intentions, this is not a fully specified problem, but rather
a research direction.Competitive online learning is one of the more compelling
pieces of learning theory because typical statements of the form "this
algorithm will perform almost as well as a large set of other algorithms" rely
only on fully-observable quantities, and are therefore applicable in many
situations. Examples includeWinnow,Weighted Majority, andBinomial Weighting.
Algorithms with this property haven't taken over the world yet. Here might be
some reasons:Lack of caring. Many people working on learning theory don't care
about particular applications much. This means constants in the algorithm are
not optimized, usable code is often not produced, and empirical studies aren't
done.Inefficiency. Viewed from the perspective of other learning algorithms,
online learning is terribly inefficient. It requires that every hypothesis
(called an expert in the online learning setting) be enumerated and tested o</p><p>3 0.67571813 <a title="109-lsi-3" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>Introduction: TheExponentiated Gradientalgorithm byManfred WarmuthandJyrki Kivinencame out
just as I was starting graduate school, so I missed it both at a conference
and in class. It's a fine algorithm which has a remarkable theoretical
statement accompanying it.The essential statement holds in the "online
learning with an adversary" setting. Initially, there are of set ofnweights,
which might have values(1/n,â&euro;Ś,1/n), (or any other values from a probability
distribution). Everything happens in a round-by-round fashion. On each round,
the following happens:The world reveals a set of featuresx in {0,1}n. In the
online learning with an adversary literature, the features are called
"experts" and thought of as subpredictors, but this interpretation isn't
necessary--you can just use feature values as experts (or maybe the feature
value and the negation of the feature value as two experts).EG makes a
prediction according toy' = w . x(dot product).The world reveals the truthy in
[0,1].EG updates the weights</p><p>4 0.67246866 <a title="109-lsi-4" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>Introduction: It turns out that many different people use the term "Online Learning", and
often they don't have the same definition in mind. Here's a list of the
possibilities I know of.Online Information SettingOnline learning refers to
aproblemin which unlabeled data comes, a prediction is made, and then feedback
is acquired.Online Adversarial SettingOnline learning refers toalgorithmsin
the Online Information Setting which satisfy guarantees of the form: "For all
possible sequences of observations, the algorithim has regret at mostlog (
number of strategies)with respect to the best strategy in a set." This is
sometimes called online learning with experts.Online Optimization
ConstraintOnline learning refers to optimizing a predictor via a learning
algorithm tunes parameters on a per-example basis. This may or may not be
applied in the Online Information Setting, and the strategy may or may not
satisfy Adversarial setting theory.Online Computational ConstraintOnline
learning refers to an algorithmi</p><p>5 0.65449315 <a title="109-lsi-5" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>Introduction: Online learning is in vogue, which means we should expect to see in the near
future:Online boosting.Online decision trees.Online SVMs. (actually, we've
already seen)Online deep learning.Online parallel learning.etc…There are three
fundamental drivers of this trend.Increasing size of datasets makes online
algorithms attractive.Online learning can simply be more efficient than batch
learning. Here is a picture from a class on online learning:The point of this
picture is that even in 3 dimensions and even with linear constraints, finding
the minima of a set in an online fashion can be typically faster than finding
the minima in a batch fashion. To see this, note that there is a minimal
number of gradient updates (i.e. 2) required in order to reach the minima in
the typical case. Given this, it's best to do these updates as quickly as
possible, which implies doing the first update online (i.e. before seeing all
the examples) is preferred. Note that this is the simplest possible setting--
m</p><p>6 0.65003151 <a title="109-lsi-6" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>7 0.64869666 <a title="109-lsi-7" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>8 0.64799762 <a title="109-lsi-8" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>9 0.64594746 <a title="109-lsi-9" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>10 0.64427525 <a title="109-lsi-10" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>11 0.61418027 <a title="109-lsi-11" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>12 0.60827756 <a title="109-lsi-12" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>13 0.59818071 <a title="109-lsi-13" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>14 0.5959667 <a title="109-lsi-14" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>15 0.59023601 <a title="109-lsi-15" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>16 0.57786232 <a title="109-lsi-16" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>17 0.57630664 <a title="109-lsi-17" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>18 0.57409072 <a title="109-lsi-18" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>19 0.56730771 <a title="109-lsi-19" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>20 0.56493032 <a title="109-lsi-20" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(7, 0.274), (35, 0.014), (39, 0.014), (42, 0.238), (45, 0.063), (56, 0.024), (68, 0.058), (69, 0.028), (74, 0.097), (76, 0.019), (82, 0.051), (95, 0.034)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96099567 <a title="109-lda-1" href="../hunch_net-2006/hunch_net-2006-02-07-Pittsburgh_Mind_Reading_Competition.html">155 hunch net-2006-02-07-Pittsburgh Mind Reading Competition</a></p>
<p>Introduction: Francisco Pereirapoints out a funPrediction Competition. Francisco says:DARPA
is sponsoring a competition to analyze data from an unusual functional
Magnetic Resonance Imaging experiment. Subjects watch videos inside the
scanner while fMRI data are acquired. Unbeknownst to these subjects, the
videos have been seen by a panel of other subjects that labeled each instant
with labels in categories such as representation (are there tools, body parts,
motion, sound), location, presence of actors, emotional content, etc.The
challenge is to predict all of these different labels on an instant-by-instant
basis from the fMRI data. A few reasons why this is particularly
interesting:This is beyond the current state of the art, but not inconceivably
hard.This is a new type of experiment design current analysis methods cannot
deal with.This is an opportunity to work with a heavily examined and
preprocessed neuroimaging dataset.DARPA is offering prizes!</p><p>2 0.93685931 <a title="109-lda-2" href="../hunch_net-2013/hunch_net-2013-05-04-COLT_and_ICML_registration.html">482 hunch net-2013-05-04-COLT and ICML registration</a></p>
<p>Introduction: Sebastien Bubeckpoints outCOLTregistrationwith a May 13 early registration
deadline. The local organizers have done an admirable job of containing costs
with a $300 registration fee.ICMLregistrationis also available, at about an x3
higher cost. My understanding is that this is partly due to the costs of a
larger conference being harder to contain, partly due to ICML lasting twice as
long with tutorials and workshops, and partly because the conference
organizers were a bit over-conservative in various ways.</p><p>same-blog 3 0.90272713 <a title="109-lda-3" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem. When someone screws up, do you fire them?
Or do you accept the error and let them continue? This is a very difficult
problem and we all know of stories where the wrong decision was made.Online
learning(as meant here), is a subfield of learning theory which analyzes the
online learning model.In the online learning model, there are a set of
hypotheses or "experts". On any instantancex, each expert makes a predictiony.
A master algorithmAuses these predictions to form it's own predictionyAand
then learns the correct predictiony*. This process repeats.The goal of online
learning is to find a master algorithmAwhich uses the advice of the experts to
make good predictions. In particular, we typically want to guarantee that the
master algorithm performs almost as well as the best expert. IfL(e)is the loss
of experteandL(A)is the loss of the master algorithm, it is often possible to
prove:L(A) less than mineL(e) + log(number of experts)over all sequences.In
p</p><p>4 0.88019919 <a title="109-lda-4" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>Introduction: Dear Fellow Machine Learners,For the past year or so I have become
increasingly frustrated with the peer review system in our field. I constantly
get asked to review papers in which I have no interest. At the same time, as
an action editor in JMLR, I constantly have to harass people to review papers.
When I send papers to conferences and to journals I often get rejected with
reviews that, at least in my mind, make no sense. Finally, I have a very hard
time keeping up with the best new work, because I don't know where to look for
itâ&euro;ŚI decided to try an do something to improve the situation. I started a new
web site, which I decided to call "The machine learning forum" the URL
ishttp://themachinelearningforum.orgThe main idea behind this web site is to
remove anonymity from the review process. In this site, all opinions are
attributed to the actual person that expressed them. I expect that this will
improve the quality of the reviews. An obvious other effect is that there will
be fewer n</p><p>5 0.86751652 <a title="109-lda-5" href="../hunch_net-2009/hunch_net-2009-06-24-Interesting_papers_at_UAICMOLT_2009.html">361 hunch net-2009-06-24-Interesting papers at UAICMOLT 2009</a></p>
<p>Introduction: Here's a list of papers that I found interesting atICML/COLT/UAIin 2009.Elad
HazanandComandur SeshadhriEfficient learning algorithms for changing
environmentsat ICML. This paper shows how to adapt learning algorithms that
compete with fixed predictors to compete with changing policies. The
definition of regret they deal with seems particularly useful in many
situation.Hal Daume,Unsupervised Search-based Structured Predictionat ICML.
This paper shows a technique for reducing unsupervised learning to supervised
learning which (a) make a fast unsupervised learning algorithm and (b) makes
semisupervised learning both easy and highly effective.There were two papers
with similar results on active learning in the KWIK framework for linear
regression, both reducing the sample complexity to . One wasNicolo Cesa-
Bianchi,Claudio Gentile, andFrancesco OrabonaRobust Bounds for Classification
via Selective Samplingat ICML and the other wasThomas Walsh,Istvan
Szita,Carlos Diuk,Michael LittmanExplori</p><p>6 0.78839481 <a title="109-lda-6" href="../hunch_net-2005/hunch_net-2005-02-19-Machine_learning_reading_groups.html">24 hunch net-2005-02-19-Machine learning reading groups</a></p>
<p>7 0.74807769 <a title="109-lda-7" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>8 0.70181715 <a title="109-lda-8" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>9 0.69613171 <a title="109-lda-9" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>10 0.69455814 <a title="109-lda-10" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>11 0.69201571 <a title="109-lda-11" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>12 0.69038278 <a title="109-lda-12" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>13 0.68920279 <a title="109-lda-13" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>14 0.68796986 <a title="109-lda-14" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>15 0.68598777 <a title="109-lda-15" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>16 0.68574017 <a title="109-lda-16" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>17 0.68526214 <a title="109-lda-17" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>18 0.68519604 <a title="109-lda-18" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>19 0.68487662 <a title="109-lda-19" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>20 0.68481201 <a title="109-lda-20" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
