<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>hunch_net 2008 knowledge graph</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="#">hunch_net-2008</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>hunch_net 2008 knowledge graph</h1>
<br/><h3>similar blogs computed by tfidf model</h3><br/><h3>similar blogs computed by <a title="lsi-model" href="./hunch_net_lsi.html">lsi model</a></h3><br/><h3>similar blogs computed by <a title="lda-model" href="./hunch_net_lda.html">lda model</a></h3><br/><h2>blogs list:</h2><p>1 <a title="hunch_net-2008-333" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">hunch net-2008-12-27-Adversarial Academia</a></p>
<p>Introduction: One viewpoint on academia is that it is inherently adversarial: there are finite research dollars, positions, and students to work with, implying a zero-sum game between different participants.  This is not a viewpoint that I want to promote, as I consider it flawed.  However, I know several people believe strongly in this viewpoint, and I have found it to have  substantial explanatory power.
 
For example:
  
 It explains why your paper was rejected based on poor logic.  The reviewer wasn’t concerned with research quality, but rather with rejecting a competitor. 
 It explains why professors rarely work together.  The goal of a non-tenured professor (at least) is to get tenure, and a case for tenure comes from a portfolio of work that is undisputably yours. 
 It explains why new research programs are not quickly adopted.  Adopting a competitor’s program is impossible, if your career is based on the competitor being wrong. 
  
Different academic groups subscribe to the adversarial viewp</p><p>2 <a title="hunch_net-2008-332" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>Introduction: I’ve had serious conversations with several people who believe that the theory in machine learning is “only useful for getting papers published”.  That’s a compelling statement, as I’ve seen many papers where the algorithm clearly came first, and the theoretical justification for it came second, purely as a perceived means to improve the chance of publication. 
 
Naturally, I disagree and believe that learning theory has much more substantial applications.  
 
Even in core learning algorithm design, I’ve found learning theory to be useful, although it’s application is more subtle than many realize.  The most straightforward applications can fail, because (as expectation suggests) worst case bounds tend to be loose in practice (*).  In my experience, considering learning theory when designing an algorithm has two important effects in practice:
  
 It can help make your algorithm behave right at a crude level of analysis, leaving finer details to tuning or common sense.  The best example</p><p>3 <a title="hunch_net-2008-331" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here’s a handy table for the summer conferences.
  
 
 Conference 
 Deadline 
 Reviewer Targeting 
 Double Blind 
 Author Feedback 
 Location 
 Date 
 
 
  ICML  ( wrong ICML ) 
 January 26 
 Yes 
 Yes 
 Yes 
 Montreal, Canada 
 June 14-17 
 
 
  COLT  
 February 13 
 No 
 No 
 Yes 
 Montreal 
 June 19-21 
 
 
  UAI  
 March 13 
 No 
 Yes 
 No 
 Montreal 
 June 19-21 
 
 
  KDD  
 February 2/6 
 No 
 No 
 No 
 Paris, France 
 June 28-July 1 
 
  
Reviewer targeting is new this year.  The idea is that many poor decisions happen because the papers go to reviewers who are unqualified, and the hope is that allowing authors to point out who is qualified results in better decisions.  In my experience, this is a reasonable idea to test.
 
Both UAI and COLT are experimenting this year as well with double blind and author feedback, respectively.  Of the two, I believe author feedback is more important, as I’ve seen it make a difference.  However, I still consider double blind reviewing a net wi</p><p>4 <a title="hunch_net-2008-330" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">hunch net-2008-12-07-A NIPS paper</a></p>
<p>Introduction: I’m skipping NIPS this year in favor of  Ada , but I wanted to point out  this paper  by  Andriy Mnih  and  Geoff Hinton .  The basic claim of the paper is that by carefully but automatically constructing a binary tree over words, it’s possible to predict words well with huge computational resource savings over unstructured approaches.
 
I’m interested in this beyond the application to word prediction because it is relevant to the general normalization problem: If you want to predict the probability of one of a large number of events, often you must compute a predicted score for all the events and then normalize, a computationally inefficient operation.  The problem comes up in many places using probabilistic models, but I’ve run into it with high-dimensional regression.
 
There are a couple workarounds for this computational bug:
  
 Approximate. There are many ways.  Often the approximations are uncontrolled (i.e. can be arbitrarily bad), and hence finicky in application. 
 Avoid.  Y</p><p>5 <a title="hunch_net-2008-329" href="../hunch_net-2008/hunch_net-2008-11-28-A_Bumper_Crop_of_Machine_Learning_Graduates.html">hunch net-2008-11-28-A Bumper Crop of Machine Learning Graduates</a></p>
<p>Introduction: My impression is that this is a particularly strong year for machine learning graduates.  Here’s my short list of the strong graduates I know.  Analpha (for perversity’s sake) by last name:
  
  Jenn Wortmann . When Jenn visited us for the summer, she had  one ,  two ,  three ,  four  papers.  That is typical—she’s smart, capable, and follows up many directions of research.  I believe approximately all of her many papers are on different subjects. 
  Ruslan Salakhutdinov . A  Science paper on bijective dimensionality reduction , mastered and improved on deep belief nets which seems like an important flavor of nonlinear learning, and in my experience he’s very fast, capable and creative at problem solving. 
  Marc’Aurelio Ranzato .  I haven’t spoken with Marc very much, but he had a great visit at Yahoo! this summer, and has an impressive portfolio of applications and improvements on convolutional neural networks and other deep learning algorithms. 
  Lihong Li .  Lihong developed the</p><p>6 <a title="hunch_net-2008-328" href="../hunch_net-2008/hunch_net-2008-11-26-Efficient_Reinforcement_Learning_in_MDPs.html">hunch net-2008-11-26-Efficient Reinforcement Learning in MDPs</a></p>
<p>Introduction: Claude Sammut  is attempting to put together an  Encyclopedia of Machine Learning .  I volunteered to write one article on  Efficient RL in MDPs , which I would like to invite comment on.  Is something critical missing?</p><p>7 <a title="hunch_net-2008-327" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>Introduction: Dean Foster  and  Daniel Hsu  had a couple observations about reductions to regression that I wanted to share.  This will make the most sense for people familiar with error correcting output codes (see the  tutorial, page 11 ).
 
Many people are comfortable using linear regression in a one-against-all style, where you try to predict the probability of choice  i  vs other classes, yet they are not comfortable with more complex error correcting codes because they fear that they create harder problems.  This fear turns out to be mathematically incoherent under a linear representation: comfort in the linear case should imply comfort with more complex codes.
 
In particular, If there exists a set of weight vectors  w i   such that  P(i|x)=, then for any invertible error correcting output code  C , there exists weight vectors  w c   which decode to perfectly predict the probability of each class.  The proof is simple and constructive: the weight vector  w c   can be constructed acc</p><p>8 <a title="hunch_net-2008-326" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">hunch net-2008-11-11-COLT CFP</a></p>
<p>Introduction: Adam Klivans , points out the  COLT call for papers .  The important points are: 
  
 Due Feb 13. 
 Montreal, June 18-21. 
 This year, there is author feedback.</p><p>9 <a title="hunch_net-2008-325" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>Introduction: Michael Littman  and  Leon Bottou  have decided to use a franchise program chair approach to  reviewing at ICML  this year.  I’ll be one of the area chairs, so I wanted to mention a few things if you are thinking about naming me.
  
 I take reviewing seriously.  That means papers to be reviewed are read, the implications are considered, and decisions are only made after that.  I do my best to be fair, and there are zero subjects that I consider categorical rejects.  I don’t consider several  arguments for rejection-not-on-the-merits reasonable . 
 I am generally interested in papers that (a) analyze new models of machine learning, (b) provide new algorithms, and (c) show that they work empirically on plausibly real problems.  If a paper has the trifecta, I’m particularly interested. With 2 out of 3, I might be interested.  I often find papers with only one element harder to accept, including papers with just (a).  
 I’m a bit tough.  I rarely jump-up-and-down about a paper, because I b</p><p>10 <a title="hunch_net-2008-324" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">hunch net-2008-11-09-A Healthy  COLT</a></p>
<p>Introduction: A  while ago , we discussed the health of  COLT .   COLT 2008  substantially addressed my concerns.  The papers were diverse and several were interesting.  Attendance was up, which is particularly notable in Europe.  In my opinion, the colocation with UAI and ICML was the best colocation since 1998.
 
And, perhaps best of all, registration ended up being free for all students due to various grants from the  Academy of Finland ,  Google ,  IBM , and  Yahoo .
 
A basic question is: what went right?  There seem to be several answers.
  
 Cost-wise, COLT had sufficient grants to alleviate the high cost of the Euro and location at a university substantially reduces the cost compared to a hotel. 
 Organization-wise, the Finns were great with hordes of volunteers helping set everything up.  Having too many volunteers is a good failure mode. 
 Organization-wise, it was clear that all 3 program chairs were cooperating in designing the program. 
 Facilities-wise, proximity in time and space made</p><p>11 <a title="hunch_net-2008-323" href="../hunch_net-2008/hunch_net-2008-11-04-Rise_of_the_Machines.html">hunch net-2008-11-04-Rise of the Machines</a></p>
<p>Introduction: On the  enduring topic of how people deal with intelligent machines , we have this important  election bulletin .</p><p>12 <a title="hunch_net-2008-322" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>Introduction: I’m not as naturally exuberant as  Muthu   2  or  David  about  CS/Econ  day, but I believe it and  ML day  were certainly successful.
 
At the CS/Econ day, I particularly enjoyed  Toumas Sandholm’s  talk which showed a commanding depth of understanding and application in automated auctions.
 
For the machine learning day, I enjoyed several talks and posters (I better, I helped pick them.).  What stood out to me was number of people attending: 158 registered, a level qualifying as “scramble to find seats”.  My rule of thumb for workshops/conferences is that the number of attendees is often something like the number of submissions.  That isn’t the case here, where there were just 4 invited speakers and 30-or-so posters.  Presumably, the difference is due to a critical mass of Machine Learning interested people in the area and the ease of their attendance.  
 
Are there other areas where a local Machine Learning day would fly?  It’s easy to imagine something working out in the San Franci</p><p>13 <a title="hunch_net-2008-321" href="../hunch_net-2008/hunch_net-2008-10-19-NIPS_2008_workshop_on_Kernel_Learning.html">hunch net-2008-10-19-NIPS 2008 workshop on Kernel Learning</a></p>
<p>Introduction: Weâ&euro;&trade;d like to invite hunch.net readers to participate in the NIPS 2008 workshop on kernel learning.  While the main focus is on automatically learning kernels from data, we are also also looking at the broader questions of feature selection, multi-task learning and multi-view learning. There are no restrictions on the learning problem being addressed (regression, classification, etc), and both theoretical and applied work will be considered. The deadline for submissions is  October 24 .
 
More detail can be found  here .
 
Corinna Cortes, Arthur Gretton, Gert Lanckriet, Mehryar Mohri, Afshin Rostamizadeh</p><p>14 <a title="hunch_net-2008-320" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I’m greatly interested in machine learning, I think it must be admitted that there is a large amount of low quality logic being used in reviews.  The problem is bad enough that sometimes I wonder if the  Byzantine generals  limit has been exceeded.  For example, I’ve seen recent reviews where the given reasons for rejecting are:
  
 [ NIPS ] Theorem A is uninteresting because Theorem B is uninteresting. 
 [ UAI ] When you learn by memorization, the problem addressed is trivial. 
 [NIPS] The proof is in the appendix.  
 [NIPS] This has been done before.  (… but not giving any relevant citations)  
  
Just for the record I want to point out what’s wrong with these reviews.  A future world in which such reasons never come up again would be great, but I’m sure these errors will be committed many times more in the future.
  
 This is nonsense.  A theorem should be evaluated based on it’s merits, rather than the merits of another theorem. 
 Learning by memorization requires an expon</p><p>15 <a title="hunch_net-2008-319" href="../hunch_net-2008/hunch_net-2008-10-01-NIPS_2008_workshop_on_%26%238216%3BLearning_over_Empirical_Hypothesis_Spaces%26%238217%3B.html">hunch net-2008-10-01-NIPS 2008 workshop on &#8216;Learning over Empirical Hypothesis Spaces&#8217;</a></p>
<p>Introduction: This workshop asks for insights how far we may/can push the theoretical boundary of using data in the design of learning machines. Can we express our classification rule in terms of the sample, or do we have to stick to a core assumption of classical statistical learning theory, namely that the hypothesis space is to be defined independent from the sample? This workshop is particularly interested in – but not restricted to – the ‘luckiness framework’ and the recently introduced  notion of ‘compatibility functions’ in a semi-supervised learning context (more information can be found at  http://www.kuleuven.be/wehys ).</p><p>16 <a title="hunch_net-2008-318" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>Introduction: Claire  asked me to be on the SODA program committee this year, which was quite a bit of work.
 
I had a relatively light load—merely 49 theory papers.  Many of these papers were not on subjects that I was expert about, so (as is common for theory conferences) I found various reviewers that I trusted to help review the papers.  I ended up reviewing about 1/3 personally.  There were a couple instances where I ended up overruling a subreviewer whose logic seemed off, but otherwise I generally let their reviews stand.
 
There are some differences in standards for paper reviews between the machine learning and theory communities.  In machine learning it is expected that a review be detailed, while in the theory community this is often not the case.  Every paper given to me ended up with a review varying between somewhat and very detailed.  
 
I’m sure not every author was happy with the outcome.  While we did our best to make good decisions, they were difficult decisions to make.  For exam</p><p>17 <a title="hunch_net-2008-317" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>Introduction: This post is about contextual bandit problems where, repeatedly:
  
 The world chooses features  x  and rewards for each action  r 1 ,…,r k   then announces the features  x  (but not the rewards). 
 A policy chooses an action  a . 
 The world announces the reward  r a   
  
The goal in these situations is to learn a policy which maximizes  r a   in expectation efficiently.  I’m thinking about all situations which fit the above setting, whether they are drawn IID or adversarially from round to round and whether they involve past logged data or rapidly learning via interaction.
 
One common drawback of all algorithms for solving this setting, is that they have a poor dependence on the number of actions.  For example if  k  is the number of actions,  EXP4 (page 66)  has a dependence on  k 0.5  ,  epoch-greedy  (and the simpler epsilon greedy) have a dependence on  k 1/3  , and the  offset tree  has a dependence on  k-1 .  These results aren’t directly comparable because different things a</p><p>18 <a title="hunch_net-2008-316" href="../hunch_net-2008/hunch_net-2008-09-04-Fall_ML_Conferences.html">hunch net-2008-09-04-Fall ML Conferences</a></p>
<p>Introduction: If you are in the New York area and interested in machine learning, consider submitting a 2 page abstract to the  ML symposium  by tomorrow (Sept 5th) midnight.  Itâ&euro;&trade;s a fun one day affair on October 10 in an awesome location overlooking the world trade center site.
 
A bit further off (but a real conference) is the  AI and Stats  deadline on November 5, to be held in Florida April 16-19.</p><p>19 <a title="hunch_net-2008-315" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">hunch net-2008-09-03-Bidding Problems</a></p>
<p>Introduction: One way that many conferences in machine learning assign reviewers to papers is via bidding, which has steps something like:
  
 Invite people to review 
 Accept papers 
 Reviewers look at title and abstract and state the papers they are interested in reviewing. 
 Some massaging happens, but reviewers often get approximately the papers they bid for. 
  
At the ICML business meeting,  Andrew McCallum  suggested getting rid of bidding for papers.  A couple reasons were given:
  
  Privacy  The title and abstract of the entire set of papers is visible to every participating reviewer.  Some authors might be uncomfortable about this for submitted papers.  I’m not sympathetic to this reason: the point of submitting a paper to review is to publish it, so the value (if any) of not publishing a part of it a little bit earlier seems limited. 
  Cliques   A bidding system is gameable.  If you have 3 buddies and you inform each other of your submissions, you can each bid for your friend’s papers a</p><p>20 <a title="hunch_net-2008-314" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>Introduction: This post is about a technology which could develop in the future.
 
Right now, a new drug might be tested by finding patients with some diagnosis and giving or not giving them a drug according to a secret randomization.  The outcome is observed, and if the average outcome for those treated is measurably better than the average outcome for those not treated, the drug might become a standard treatment.
 
Generalizing this, a filter  F  sorts people into two groups: those for treatment  A  and those not for treatment  B  based upon observations  x .  To measure the outcome, you randomize between treatment and nontreatment of group  A  and measure the relative performance of the treatment.
 
A problem often arises: in many cases the treated group does not do better than the nontreated group.  A basic question is: does this mean the treatment is bad?  With respect to the filter  F  it may mean that, but with respect to another filter  F’ , the treatment might be very effective.  For exampl</p><p>21 <a title="hunch_net-2008-313" href="../hunch_net-2008/hunch_net-2008-08-18-Radford_Neal_starts_a_blog.html">hunch net-2008-08-18-Radford Neal starts a blog</a></p>
<p>22 <a title="hunch_net-2008-312" href="../hunch_net-2008/hunch_net-2008-08-04-Electoralmarkets.com.html">hunch net-2008-08-04-Electoralmarkets.com</a></p>
<p>23 <a title="hunch_net-2008-311" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>24 <a title="hunch_net-2008-310" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>25 <a title="hunch_net-2008-309" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>26 <a title="hunch_net-2008-308" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">hunch net-2008-07-06-To Dual or Not</a></p>
<p>27 <a title="hunch_net-2008-307" href="../hunch_net-2008/hunch_net-2008-07-04-More_Presentation_Preparation.html">hunch net-2008-07-04-More Presentation Preparation</a></p>
<p>28 <a title="hunch_net-2008-306" href="../hunch_net-2008/hunch_net-2008-07-02-Proprietary_Data_in_Academic_Research%3F.html">hunch net-2008-07-02-Proprietary Data in Academic Research?</a></p>
<p>29 <a title="hunch_net-2008-305" href="../hunch_net-2008/hunch_net-2008-06-30-ICML_has_a_comment_system.html">hunch net-2008-06-30-ICML has a comment system</a></p>
<p>30 <a title="hunch_net-2008-304" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>31 <a title="hunch_net-2008-303" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>32 <a title="hunch_net-2008-302" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>33 <a title="hunch_net-2008-301" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>34 <a title="hunch_net-2008-300" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>35 <a title="hunch_net-2008-299" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>36 <a title="hunch_net-2008-298" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>37 <a title="hunch_net-2008-297" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">hunch net-2008-04-22-Taking the next step</a></p>
<p>38 <a title="hunch_net-2008-296" href="../hunch_net-2008/hunch_net-2008-04-21-The_Science_2.0_article.html">hunch net-2008-04-21-The Science 2.0 article</a></p>
<p>39 <a title="hunch_net-2008-295" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>40 <a title="hunch_net-2008-294" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">hunch net-2008-04-12-Blog compromised</a></p>
<p>41 <a title="hunch_net-2008-293" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>42 <a title="hunch_net-2008-292" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">hunch net-2008-03-15-COLT Open Problems</a></p>
<p>43 <a title="hunch_net-2008-291" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>44 <a title="hunch_net-2008-290" href="../hunch_net-2008/hunch_net-2008-02-27-The_Stats_Handicap.html">hunch net-2008-02-27-The Stats Handicap</a></p>
<p>45 <a title="hunch_net-2008-289" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>46 <a title="hunch_net-2008-288" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">hunch net-2008-02-10-Complexity Illness</a></p>
<p>47 <a title="hunch_net-2008-287" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">hunch net-2008-01-28-Sufficient Computation</a></p>
<p>48 <a title="hunch_net-2008-286" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>49 <a title="hunch_net-2008-285" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">hunch net-2008-01-23-Why Workshop?</a></p>
<p>50 <a title="hunch_net-2008-284" href="../hunch_net-2008/hunch_net-2008-01-18-Datasets.html">hunch net-2008-01-18-Datasets</a></p>
<p>51 <a title="hunch_net-2008-283" href="../hunch_net-2008/hunch_net-2008-01-07-2008_Summer_Machine_Learning_Conference_Schedule.html">hunch net-2008-01-07-2008 Summer Machine Learning Conference Schedule</a></p>
<p>52 <a title="hunch_net-2008-282" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">hunch net-2008-01-06-Research Political Issues</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
