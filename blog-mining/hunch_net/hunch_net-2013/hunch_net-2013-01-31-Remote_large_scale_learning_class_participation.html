<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>479 hunch net-2013-01-31-Remote large scale learning class participation</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2013" href="../home/hunch_net-2013_home.html">hunch_net-2013</a> <a title="hunch_net-2013-479" href="#">hunch_net-2013-479</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>479 hunch net-2013-01-31-Remote large scale learning class participation</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2013-479-html" href="http://hunch.net/?p=2624">html</a></p><p>Introduction: Yann and I have arranged so that people who are interested in ourlarge scale
machine learning classand not able to attend in person can follow along via
two methods.Videoswill be posted with about a 1 day delay ontechtalks. This is
a side-by-side capture of video+slides fromWeyond.We are experimenting
withPiazzaas a discussion forum. Anyone is welcome to subscribe to Piazza and
ask questions there, where I will be monitoring things.update2: Sign
uphere.The first lecture is up now, including therevised version of the
slideswhich fixes a few typos and rounds out references.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('monitoring', 0.253), ('references', 0.235), ('fixes', 0.235), ('typos', 0.235), ('arranged', 0.235), ('rounds', 0.221), ('subscribe', 0.221), ('posted', 0.211), ('delay', 0.211), ('yann', 0.196), ('lecture', 0.19), ('video', 0.19), ('welcome', 0.19), ('slides', 0.184), ('attend', 0.184), ('sign', 0.179), ('experimenting', 0.175), ('capture', 0.171), ('along', 0.161), ('follow', 0.158)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="479-tfidf-1" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>Introduction: Yann and I have arranged so that people who are interested in ourlarge scale
machine learning classand not able to attend in person can follow along via
two methods.Videoswill be posted with about a 1 day delay ontechtalks. This is
a side-by-side capture of video+slides fromWeyond.We are experimenting
withPiazzaas a discussion forum. Anyone is welcome to subscribe to Piazza and
ask questions there, where I will be monitoring things.update2: Sign
uphere.The first lecture is up now, including therevised version of the
slideswhich fixes a few typos and rounds out references.</p><p>2 0.14047933 <a title="479-tfidf-2" href="../hunch_net-2007/hunch_net-2007-04-21-Videolectures.net.html">240 hunch net-2007-04-21-Videolectures.net</a></p>
<p>Introduction: Davorhas been working to setupvideolectures.netwhich is the new site for the
many lecturesmentioned here. (Tragically, they seem to only be available in
windows media format.) I went throughmy own projectsand added a few links to
the videos. The day when every result is a set of {paper, slides, video} isn't
quite here yet, but it's within sight. (For many papers, of course, code is a
4th component.)</p><p>3 0.12450161 <a title="479-tfidf-3" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>Introduction: Yann LeCunand I are coteaching a class onLarge Scale Machine Learningstarting
late Januaryat NYU. This class will cover many tricks to get machine learning
working well on datasets with many features, examples, and classes, along with
several elements of deep learning and support systems enabling the
previous.This is not a beginning class--you really need to have taken a basic
machine learning class previously to follow along. Students will be able to
run and experiment with large scale learning algorithms sinceYahoo!has donated
servers which are being configured into a small scaleHadoopcluster. We are
planning to cover the frontier of research in scalable learning algorithms, so
good class projects could easily lead to papers.For me, this is a chance to
teach on many topics of past research. In general, it seems like researchers
should engage in at least occasional teaching of research, both as a proof of
teachability and to see their own research through that lens. More generally,
I</p><p>4 0.1027412 <a title="479-tfidf-4" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>Introduction: Yesterday, there was a discussion aboutfuture publication models at
NIPS.YannandZoubinhave specific detailed proposals which I'll add links to
when I get them (Yann's proposalandZoubin's proposal).What struck me about the
discussion is that there are many simultaneous concerns as well as many
simultaneous proposals, which makes it difficult to keep all the distinctions
straight in a verbal conversation. It also seemed like people were serious
enough about this that we may see some real movement. Certainly, my personal
experience motivates that as I'veposted many timesabout the substantial flaws
in our review process, including some very poor personal experiences.Concerns
include the following:(Several) Reviewers are overloaded, boosting the noise
in decision making.(Yann) A new system should run with as little built-in
delay and friction to the process of research as possible.(Hanna
Wallach(updated)) Double-blind review is particularly important for people who
are unknown or from an un</p><p>5 0.076737911 <a title="479-tfidf-5" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>Introduction: A substantial difficulty with the 2009 and 2008ICML discussion systemwas a
communication vacuum, where authors were not informed of comments, and
commenters were not informed of responses to their comments without explicit
monitoring.Mark Reidhas setup anew discussion system for 2010with the goal of
addressing this.Mark didn't want to make it to intrusive, so you must opt-in.
As an author,find your paperand "Subscribe by email" to the comments. As a
commenter, you have the option of providing an email for follow-up
notification.</p><p>6 0.070613213 <a title="479-tfidf-6" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>7 0.070276543 <a title="479-tfidf-7" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>8 0.068003878 <a title="479-tfidf-8" href="../hunch_net-2007/hunch_net-2007-11-16-MLSS_2008.html">273 hunch net-2007-11-16-MLSS 2008</a></p>
<p>9 0.067591324 <a title="479-tfidf-9" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>10 0.067204341 <a title="479-tfidf-10" href="../hunch_net-2009/hunch_net-2009-12-07-Vowpal_Wabbit_version_4.0%2C_and_a_NIPS_heresy.html">381 hunch net-2009-12-07-Vowpal Wabbit version 4.0, and a NIPS heresy</a></p>
<p>11 0.06246946 <a title="479-tfidf-11" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>12 0.06170718 <a title="479-tfidf-12" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>13 0.060605854 <a title="479-tfidf-13" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>14 0.060337592 <a title="479-tfidf-14" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>15 0.059240855 <a title="479-tfidf-15" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>16 0.054156382 <a title="479-tfidf-16" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>17 0.052674029 <a title="479-tfidf-17" href="../hunch_net-2010/hunch_net-2010-08-21-Rob_Schapire_at_NYC_ML_Meetup.html">405 hunch net-2010-08-21-Rob Schapire at NYC ML Meetup</a></p>
<p>18 0.05227913 <a title="479-tfidf-18" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>19 0.051202781 <a title="479-tfidf-19" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>20 0.05064442 <a title="479-tfidf-20" href="../hunch_net-2010/hunch_net-2010-10-29-To_Vidoelecture_or_not.html">416 hunch net-2010-10-29-To Vidoelecture or not</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.08), (1, 0.045), (2, 0.058), (3, 0.021), (4, -0.004), (5, 0.054), (6, 0.065), (7, 0.014), (8, 0.032), (9, 0.013), (10, 0.028), (11, 0.029), (12, 0.023), (13, 0.009), (14, -0.064), (15, -0.001), (16, 0.039), (17, 0.03), (18, -0.019), (19, 0.035), (20, 0.097), (21, 0.01), (22, -0.031), (23, -0.007), (24, -0.061), (25, -0.089), (26, -0.049), (27, -0.005), (28, -0.025), (29, -0.037), (30, 0.029), (31, 0.043), (32, 0.006), (33, 0.017), (34, -0.058), (35, 0.045), (36, -0.014), (37, 0.028), (38, -0.129), (39, 0.079), (40, -0.047), (41, 0.062), (42, 0.051), (43, 0.056), (44, -0.028), (45, -0.03), (46, 0.01), (47, -0.141), (48, 0.053), (49, 0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96474016 <a title="479-lsi-1" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>Introduction: Yann and I have arranged so that people who are interested in ourlarge scale
machine learning classand not able to attend in person can follow along via
two methods.Videoswill be posted with about a 1 day delay ontechtalks. This is
a side-by-side capture of video+slides fromWeyond.We are experimenting
withPiazzaas a discussion forum. Anyone is welcome to subscribe to Piazza and
ask questions there, where I will be monitoring things.update2: Sign
uphere.The first lecture is up now, including therevised version of the
slideswhich fixes a few typos and rounds out references.</p><p>2 0.52461803 <a title="479-lsi-2" href="../hunch_net-2007/hunch_net-2007-04-21-Videolectures.net.html">240 hunch net-2007-04-21-Videolectures.net</a></p>
<p>Introduction: Davorhas been working to setupvideolectures.netwhich is the new site for the
many lecturesmentioned here. (Tragically, they seem to only be available in
windows media format.) I went throughmy own projectsand added a few links to
the videos. The day when every result is a set of {paper, slides, video} isn't
quite here yet, but it's within sight. (For many papers, of course, code is a
4th component.)</p><p>3 0.52283949 <a title="479-lsi-3" href="../hunch_net-2013/hunch_net-2013-06-10-The_Large_Scale_Learning_class_notes.html">483 hunch net-2013-06-10-The Large Scale Learning class notes</a></p>
<p>Introduction: Thelarge scale machine learning classI taught withYann LeCunhas finished. As I
expected, it took quite a bit of time. We had about 25 people attending in
person on average and 400 regularly watching therecorded lectureswhich is
substantially more sustained interest than I expected for an advanced ML
class. We also had some fun with class projects--I'm hopeful that several will
eventually turn into papers.I expect there are a number of professors
interested in lecturing on this and related topics. Everyone will have their
personal taste in subjects of course, but hopefully there will be some
convergence to common course materials as well. To help with this, I am making
thesources to my presentations available. Feel free to
use/improve/embelish/ridicule/etcâ&euro;Ś in the pursuit of the perfect course.</p><p>4 0.51937413 <a title="479-lsi-4" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>Introduction: Yann LeCunand I are coteaching a class onLarge Scale Machine Learningstarting
late Januaryat NYU. This class will cover many tricks to get machine learning
working well on datasets with many features, examples, and classes, along with
several elements of deep learning and support systems enabling the
previous.This is not a beginning class--you really need to have taken a basic
machine learning class previously to follow along. Students will be able to
run and experiment with large scale learning algorithms sinceYahoo!has donated
servers which are being configured into a small scaleHadoopcluster. We are
planning to cover the frontier of research in scalable learning algorithms, so
good class projects could easily lead to papers.For me, this is a chance to
teach on many topics of past research. In general, it seems like researchers
should engage in at least occasional teaching of research, both as a proof of
teachability and to see their own research through that lens. More generally,
I</p><p>5 0.48972574 <a title="479-lsi-5" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>Introduction: Yesterday, there was a discussion aboutfuture publication models at
NIPS.YannandZoubinhave specific detailed proposals which I'll add links to
when I get them (Yann's proposalandZoubin's proposal).What struck me about the
discussion is that there are many simultaneous concerns as well as many
simultaneous proposals, which makes it difficult to keep all the distinctions
straight in a verbal conversation. It also seemed like people were serious
enough about this that we may see some real movement. Certainly, my personal
experience motivates that as I'veposted many timesabout the substantial flaws
in our review process, including some very poor personal experiences.Concerns
include the following:(Several) Reviewers are overloaded, boosting the noise
in decision making.(Yann) A new system should run with as little built-in
delay and friction to the process of research as possible.(Hanna
Wallach(updated)) Double-blind review is particularly important for people who
are unknown or from an un</p><p>6 0.48210356 <a title="479-lsi-6" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>7 0.47628576 <a title="479-lsi-7" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>8 0.452665 <a title="479-lsi-8" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>9 0.44495785 <a title="479-lsi-9" href="../hunch_net-2013/hunch_net-2013-07-24-ICML_2012_videos_lost.html">487 hunch net-2013-07-24-ICML 2012 videos lost</a></p>
<p>10 0.42232582 <a title="479-lsi-10" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>11 0.41468266 <a title="479-lsi-11" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>12 0.39423126 <a title="479-lsi-12" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>13 0.37436813 <a title="479-lsi-13" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>14 0.37336275 <a title="479-lsi-14" href="../hunch_net-2009/hunch_net-2009-12-07-Vowpal_Wabbit_version_4.0%2C_and_a_NIPS_heresy.html">381 hunch net-2009-12-07-Vowpal Wabbit version 4.0, and a NIPS heresy</a></p>
<p>15 0.3710278 <a title="479-lsi-15" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>16 0.36975846 <a title="479-lsi-16" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>17 0.35640144 <a title="479-lsi-17" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>18 0.35561511 <a title="479-lsi-18" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>19 0.35510635 <a title="479-lsi-19" href="../hunch_net-2006/hunch_net-2006-12-06-The_Spam_Problem.html">223 hunch net-2006-12-06-The Spam Problem</a></p>
<p>20 0.35116771 <a title="479-lsi-20" href="../hunch_net-2005/hunch_net-2005-09-20-Workshop_Proposal%3A_Atomic_Learning.html">114 hunch net-2005-09-20-Workshop Proposal: Atomic Learning</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.05), (42, 0.073), (74, 0.123), (83, 0.61)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95715964 <a title="479-lda-1" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>Introduction: Yann and I have arranged so that people who are interested in ourlarge scale
machine learning classand not able to attend in person can follow along via
two methods.Videoswill be posted with about a 1 day delay ontechtalks. This is
a side-by-side capture of video+slides fromWeyond.We are experimenting
withPiazzaas a discussion forum. Anyone is welcome to subscribe to Piazza and
ask questions there, where I will be monitoring things.update2: Sign
uphere.The first lecture is up now, including therevised version of the
slideswhich fixes a few typos and rounds out references.</p><p>2 0.93574059 <a title="479-lda-2" href="../hunch_net-2012/hunch_net-2012-06-15-Normal_Deviate_and_the_UCSC_Machine_Learning_Summer_School.html">467 hunch net-2012-06-15-Normal Deviate and the UCSC Machine Learning Summer School</a></p>
<p>Introduction: Larry Wassermanhas started theNormal Deviateblog which I added to the blogroll
on the right.Manfred Warmuthpoints out theUCSC machine learning summer
schoolrunning July 9-20 which may be of particular interest to those in
silicon valley.</p><p>3 0.62566471 <a title="479-lda-3" href="../hunch_net-2009/hunch_net-2009-05-30-Many_ways_to_Learn_this_summer.html">357 hunch net-2009-05-30-Many ways to Learn this summer</a></p>
<p>Introduction: There are at least3summer schools related to machine learning this summer.The
firstis atUniversity of ChicagoJune 1-11 organized byMisha Belkin,Partha
Niyogi, andSteve Smale. Registration is closed for this one, meaning they met
their capacity limit. The format is essentially an extended Tutorial/Workshop.
I was particularly interested to seeValiantamongst the speakers. I'm also
presenting Saturday June 6, on logarithmic time prediction.Praveen
Srinivasanpoints out the second atPeking Universityin Beijing, China, July
20-27.This onediffers substantially, as it is about vision, machine learning,
and their intersection. The deadline for applications is June 10 or 15. This
is also another example of the growth of research in China, with active
support fromNSF.The third one is atCambridge, England, August 29-September 10.
It's in theMLSS series. Compared to the Chicago one, this one is more about
the Bayesian side of ML, although effort has been made to create a good cross
section of topic</p><p>4 0.62120682 <a title="479-lda-4" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>Introduction: Perhaps the biggest CS prize for research is theTuring Award, which has a
$0.25M cash prize associated with it. It appears none of the prizes so far
have been for anything like machine learning (the closest are perhaps database
awards).In CS theory, there is theGÃƒÂ¶del Prizewhich is smaller and newer,
offering a $5K prize along and perhaps (more importantly) recognition. One
such award has been given for Machine Learning, toRobert SchapireandYoav
Freundfor Adaboost.In Machine Learning, there seems to be no equivalent of
these sorts of prizes. There are several plausible reasons for this:There is
no coherent community.People drift in and out of the central conferences all
the time. Most of the author names from 10 years ago do not occur in the
conferences of today. In addition, the entire subject area is fairly new.There
are at least a core group of people who have stayed around.Machine Learning
work doesn't lastAlmost every paper is forgotten, because {the goals change,
there isn't an</p><p>5 0.57491231 <a title="479-lda-5" href="../hunch_net-2005/hunch_net-2005-04-04-Grounds_for_Rejection.html">52 hunch net-2005-04-04-Grounds for Rejection</a></p>
<p>Introduction: It's reviewing season right now, so I thought I would list (at a high level)
the sorts of problems which I see in papers. Hopefully, this will help us all
write better papers.The following flaws are fatal to any paper:Incorrect
theorem or lemma statementsA typo might be "ok", if it can be understood. Any
theorem or lemma which indicates an incorrect understanding of reality must be
rejected. Not doing so would severely harm the integrity of the conference. A
paper rejected for this reason must be fixed.Lack of UnderstandingIf a paper
is understood by none of the (typically 3) reviewers then it must be rejected
for the same reason. This is more controversial than it sounds because there
are some people who maximize paper complexity in the hope of impressing the
reviewer. The tactic sometimes succeeds with some reviewers (but not with
me).As a reviewer, I sometimes get lost for stupid reasons. This is why an
anonymizedcommunication channelwith the author can be very helpful.Bad
ideaRarel</p><p>6 0.53237075 <a title="479-lda-6" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>7 0.37427509 <a title="479-lda-7" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>8 0.26300788 <a title="479-lda-8" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>9 0.26018772 <a title="479-lda-9" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>10 0.25833917 <a title="479-lda-10" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>11 0.2546964 <a title="479-lda-11" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>12 0.24606052 <a title="479-lda-12" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>13 0.23227867 <a title="479-lda-13" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>14 0.23098075 <a title="479-lda-14" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>15 0.23057421 <a title="479-lda-15" href="../hunch_net-2011/hunch_net-2011-08-01-Interesting_papers_at_COLT_2011.html">439 hunch net-2011-08-01-Interesting papers at COLT 2011</a></p>
<p>16 0.22959834 <a title="479-lda-16" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>17 0.22954845 <a title="479-lda-17" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>18 0.22809505 <a title="479-lda-18" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>19 0.22807026 <a title="479-lda-19" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>20 0.2278828 <a title="479-lda-20" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
