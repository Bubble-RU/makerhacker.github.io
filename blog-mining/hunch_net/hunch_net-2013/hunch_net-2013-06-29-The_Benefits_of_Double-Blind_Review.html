<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>485 hunch net-2013-06-29-The Benefits of Double-Blind Review</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2013" href="../home/hunch_net-2013_home.html">hunch_net-2013</a> <a title="hunch_net-2013-485" href="#">hunch_net-2013-485</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>485 hunch net-2013-06-29-The Benefits of Double-Blind Review</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2013-485-html" href="http://hunch.net/?p=2656">html</a></p><p>Introduction: This post is a (near) transcript of a talk that I gave at theICML 2013
Workshop on Peer Review and Publishing Models. Although there's aPDF available
on my website, I've chosen to post a slightly modified version here as well in
order to better facilitate discussion.Disclaimers and ContextI want to start
with a couple of disclaimers and some context.First, I want to point out that
although I've read a lot about double-blind review, this isn't my research
area and the research discussed in this post is not my own. As a result, I
probably can't answer super detailed questions about these studies.I also want
to note that I'm not opposed to open peer review -- I was a free and open
source software developer for over ten years and I care a great deal about
openness and transparency. Rather, my motivation in writing this post is
simply to create awareness of and to initiate discussion about the benefits of
double-blind review.Lastly, and most importantly, I think it's essential to
acknowledg</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I also want to note that I'm not opposed to open peer review -- I was a free and open source software developer for over ten years and I care a great deal about openness and transparency. [sent-6, score-0.68]
</p><p>2 Lastly, and most importantly, I think it's essential to acknowledge that there's a lot of research on double-blind review out there. [sent-8, score-0.476]
</p><p>3 My goal here is therefore to draw your attention to some of the key benefits of double-blind review so that we don't lose sight of them when considering alternative reviewing models. [sent-12, score-0.575]
</p><p>4 , that double-blind review isn't really blind, so therefore there's no point in implementing it. [sent-19, score-0.473]
</p><p>5 There are several studies that directly test this assertion by asking reviewers whether authors or institutions are identifiable and, if so, to record their identities and describe the clues that led to their identification. [sent-21, score-0.848]
</p><p>6 The results are pretty interesting: when asked to guess the identities of authors or institutions, reviewers are correct only 25-42% of the time [1]. [sent-22, score-0.499]
</p><p>7 This indicates that journals, not just authors, bear some responsibility for the degree of identification clues present and can therefore influence the extent to which review is truly double-blind. [sent-25, score-0.767]
</p><p>8 , that double-blind review isn't needed because factors other than scientific quality do not affect reviewers' opinions anyway. [sent-30, score-0.667]
</p><p>9 There are many studies that address this assertion by testing the extent to which peer review can be biased against new ideas, women, junior researchers, and researchers from less prestigious universities or countries other than the US. [sent-32, score-0.922]
</p><p>10 To quote the AAUW's report [4] on the under-representation of women in science, "Even individuals who consciously refute gender and science stereotypes can still hold that belief at an unconscious level. [sent-36, score-0.689]
</p><p>11 In the context of peer review, reviewers may be more likely to recommend acceptance of incomplete or inferior papers if they are authored by more prestigious researchers. [sent-47, score-0.536]
</p><p>12 There's research [6] showing that reviewers from within the United States and reviewers from outside the United States evaluate US papers more favorably, with US reviewers showing a stronger preference for US papers than non-US reviewers. [sent-49, score-0.61]
</p><p>13 GenderOne of the most widely discussed pieces of recent work on double-blind review and gender is that of Budden et al. [sent-51, score-0.614]
</p><p>14 [1], whose research demonstrated that following the introduction of double-blind review by the journal Behavioral Ecology, there was a significant increase in papers authored by women. [sent-52, score-0.714]
</p><p>15 Stereotype threat is a phenomenon in which performance in academic contexts can be harmed by the awareness that one's behavior might be viewed through the lens of a negative stereotype about one's social group [10]. [sent-58, score-0.466]
</p><p>16 For example, studies have demonstrated that African- American students enrolled in college and female students enrolled in math and science courses score much lower on tests when they are reminded beforehand of their race or gender [10, 11]. [sent-59, score-0.656]
</p><p>17 In the case of female science students, simply having a larger ratio of men to women present in the testing situation can lower women's test scores [4]. [sent-60, score-0.429]
</p><p>18 One idea that that hasn't yet been explored in the context of peer review, but might be worth investigating, is whether requiring authors to reveal their identities during peer review induces a stereotype threat scenario. [sent-62, score-1.437]
</p><p>19 "SummaryI want to conclude by reminding you that my goal in writing this post was to create awareness about the benefits of double- blind review. [sent-67, score-0.455]
</p><p>20 "Incidence and nature of unblinding by authors: our experience at two radiology journals with double-blinded peer review policies. [sent-79, score-0.678]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('review', 0.385), ('peer', 0.223), ('women', 0.186), ('factors', 0.186), ('female', 0.175), ('stereotype', 0.175), ('studies', 0.174), ('reviewers', 0.173), ('identities', 0.172), ('authors', 0.154), ('et', 0.124), ('identification', 0.115), ('awareness', 0.105), ('budden', 0.105), ('clues', 0.105), ('gender', 0.105), ('mainguy', 0.105), ('matthew', 0.105), ('threat', 0.105), ('benefits', 0.102), ('scientific', 0.096), ('journal', 0.096), ('stereotypes', 0.093), ('research', 0.091), ('blind', 0.089), ('therefore', 0.088), ('bias', 0.088), ('post', 0.087), ('quote', 0.086), ('report', 0.081), ('phenomenon', 0.081), ('influence', 0.074), ('want', 0.072), ('beliefs', 0.072), ('demonstrated', 0.072), ('aarssen', 0.07), ('assertion', 0.07), ('authored', 0.07), ('koricheva', 0.07), ('landscape', 0.07), ('prestigious', 0.07), ('tregenza', 0.07), ('unconscious', 0.07), ('webb', 0.07), ('journals', 0.07), ('science', 0.068), ('origin', 0.062), ('applicants', 0.062), ('newcomers', 0.062), ('race', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="485-tfidf-1" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>Introduction: This post is a (near) transcript of a talk that I gave at theICML 2013
Workshop on Peer Review and Publishing Models. Although there's aPDF available
on my website, I've chosen to post a slightly modified version here as well in
order to better facilitate discussion.Disclaimers and ContextI want to start
with a couple of disclaimers and some context.First, I want to point out that
although I've read a lot about double-blind review, this isn't my research
area and the research discussed in this post is not my own. As a result, I
probably can't answer super detailed questions about these studies.I also want
to note that I'm not opposed to open peer review -- I was a free and open
source software developer for over ten years and I care a great deal about
openness and transparency. Rather, my motivation in writing this post is
simply to create awareness of and to initiate discussion about the benefits of
double-blind review.Lastly, and most importantly, I think it's essential to
acknowledg</p><p>2 0.25297025 <a title="485-tfidf-2" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>3 0.22388224 <a title="485-tfidf-3" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>4 0.19993395 <a title="485-tfidf-4" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but
sometimes the unfairness seems particularly striking. This is most easily seen
by comparison:PaperBanditronOffset TreeNotesProblem ScopeMulticlass problems
where only the loss of one choice can be probed.Strictly greater: Cost
sensitive multiclass problems where only the loss of one choice can be
probed.Often generalizations don't matter. That's not the case here, since
every plausible application I've thought of involves loss functions
substantially different from 0/1.What's newAnalysis and ExperimentsAlgorithm,
Analysis, and ExperimentsAs far as I know, the essence of the more general
problem was first stated and analyzed with theEXP4 algorithm (page 16)(1998).
It's also the time horizon 1 simplification of the Reinforcement Learning
setting for therandom trajectory method (page 15)(2002). The Banditron
algorithm itself is functionally identical toOne-Step RL with Traces (page
122)(2003) inBianca's thesis</p><p>5 0.18271014 <a title="485-tfidf-5" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>Introduction: Conferences exist as part of the process of doing research. They provide many
roles including "announcing research", "meeting people", and "point of
reference". Not all conferences are alike so a basic question is: "to what
extent do individual conferences attempt to aid research?" This question is
very difficult to answer in any satisfying way. What we can do is compare
details of the process across multiple conferences.CommentsThe average quality
of comments across conferences can vary dramatically. At one extreme, the
tradition in CS theory conferences is to provide essentially zero feedback. At
the other extreme, some conferences have a strong tradition of providing
detailed constructive feedback. Detailed feedback can give authors significant
guidance about how to improve research. This is the most subjective
entry.BlindVirtually all conferences offer single blind review where authors
do not know reviewers. Some also providedouble blindreview where reviewers do
not know authors. T</p><p>6 0.15465549 <a title="485-tfidf-6" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>7 0.14626527 <a title="485-tfidf-7" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>8 0.14487225 <a title="485-tfidf-8" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>9 0.14174792 <a title="485-tfidf-9" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>10 0.14019679 <a title="485-tfidf-10" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>11 0.13537356 <a title="485-tfidf-11" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>12 0.13035457 <a title="485-tfidf-12" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>13 0.11824964 <a title="485-tfidf-13" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>14 0.11811896 <a title="485-tfidf-14" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>15 0.11807923 <a title="485-tfidf-15" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>16 0.1172015 <a title="485-tfidf-16" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>17 0.1161745 <a title="485-tfidf-17" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>18 0.11603988 <a title="485-tfidf-18" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>19 0.11581147 <a title="485-tfidf-19" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>20 0.11432999 <a title="485-tfidf-20" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.229), (1, 0.198), (2, -0.109), (3, -0.124), (4, 0.046), (5, -0.007), (6, 0.023), (7, 0.024), (8, -0.004), (9, -0.012), (10, 0.052), (11, 0.045), (12, -0.067), (13, 0.003), (14, 0.006), (15, -0.124), (16, -0.049), (17, 0.025), (18, 0.021), (19, 0.008), (20, -0.018), (21, 0.01), (22, 0.053), (23, 0.04), (24, -0.104), (25, -0.032), (26, 0.025), (27, -0.009), (28, -0.025), (29, -0.019), (30, 0.054), (31, 0.039), (32, -0.002), (33, -0.05), (34, 0.002), (35, 0.004), (36, 0.072), (37, -0.003), (38, -0.057), (39, 0.01), (40, 0.047), (41, -0.059), (42, -0.073), (43, 0.027), (44, -0.038), (45, 0.015), (46, -0.038), (47, -0.018), (48, -0.031), (49, -0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97768724 <a title="485-lsi-1" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>Introduction: This post is a (near) transcript of a talk that I gave at theICML 2013
Workshop on Peer Review and Publishing Models. Although there's aPDF available
on my website, I've chosen to post a slightly modified version here as well in
order to better facilitate discussion.Disclaimers and ContextI want to start
with a couple of disclaimers and some context.First, I want to point out that
although I've read a lot about double-blind review, this isn't my research
area and the research discussed in this post is not my own. As a result, I
probably can't answer super detailed questions about these studies.I also want
to note that I'm not opposed to open peer review -- I was a free and open
source software developer for over ten years and I care a great deal about
openness and transparency. Rather, my motivation in writing this post is
simply to create awareness of and to initiate discussion about the benefits of
double-blind review.Lastly, and most importantly, I think it's essential to
acknowledg</p><p>2 0.80075043 <a title="485-lsi-2" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>3 0.75606811 <a title="485-lsi-3" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>4 0.73264998 <a title="485-lsi-4" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>Introduction: One viewpoint on academia is that it is inherently adversarial: there are
finite research dollars, positions, and students to work with, implying a
zero-sum game between different participants. This is not a viewpoint that I
want to promote, as I consider it flawed. However, I know several people
believe strongly in this viewpoint, and I have found it to have substantial
explanatory power.For example:It explains why your paper was rejected based on
poor logic. The reviewer wasn't concerned with research quality, but rather
with rejecting a competitor.It explains why professors rarely work together.
The goal of a non-tenured professor (at least) is to get tenure, and a case
for tenure comes from a portfolio of work that is undisputably yours.It
explains why new research programs are not quickly adopted. Adopting a
competitor's program is impossible, if your career is based on the competitor
being wrong.Different academic groups subscribe to the adversarial viewpoint
in different degrees</p><p>5 0.72628093 <a title="485-lsi-5" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>Introduction: Conferences exist as part of the process of doing research. They provide many
roles including "announcing research", "meeting people", and "point of
reference". Not all conferences are alike so a basic question is: "to what
extent do individual conferences attempt to aid research?" This question is
very difficult to answer in any satisfying way. What we can do is compare
details of the process across multiple conferences.CommentsThe average quality
of comments across conferences can vary dramatically. At one extreme, the
tradition in CS theory conferences is to provide essentially zero feedback. At
the other extreme, some conferences have a strong tradition of providing
detailed constructive feedback. Detailed feedback can give authors significant
guidance about how to improve research. This is the most subjective
entry.BlindVirtually all conferences offer single blind review where authors
do not know reviewers. Some also providedouble blindreview where reviewers do
not know authors. T</p><p>6 0.72544169 <a title="485-lsi-6" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>7 0.7185567 <a title="485-lsi-7" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>8 0.70235831 <a title="485-lsi-8" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>9 0.69517308 <a title="485-lsi-9" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>10 0.68841016 <a title="485-lsi-10" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>11 0.68770844 <a title="485-lsi-11" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>12 0.64962202 <a title="485-lsi-12" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>13 0.64115185 <a title="485-lsi-13" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>14 0.63033754 <a title="485-lsi-14" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>15 0.60770673 <a title="485-lsi-15" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>16 0.57965207 <a title="485-lsi-16" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>17 0.57217264 <a title="485-lsi-17" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>18 0.55866224 <a title="485-lsi-18" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>19 0.5553894 <a title="485-lsi-19" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>20 0.55372703 <a title="485-lsi-20" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.031), (6, 0.015), (10, 0.022), (35, 0.032), (42, 0.14), (45, 0.029), (50, 0.031), (68, 0.027), (69, 0.043), (74, 0.119), (76, 0.016), (77, 0.27), (82, 0.063), (83, 0.015), (95, 0.037), (98, 0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.89087546 <a title="485-lda-1" href="../hunch_net-2006/hunch_net-2006-05-21-NIPS_paper_evaluation_criteria.html">180 hunch net-2006-05-21-NIPS paper evaluation criteria</a></p>
<p>Introduction: John Platt, who is PC-chair forNIPS 2006has organized aNIPS paper evaluation
criteriadocument with input from theprogram committeeand others.The document
contains specific advice about what is appropriate for the various subareas
within NIPS. It may be very helpful, because the standards of evaluation for
papers varies significantly.This is a bit of an experiment: the hope is that
by carefully thinking about and stating what is important, authors can better
understand whether and where their work fits.Update: Thegeneral submission
pageandAuthor instruction including how to submit an appendix.</p><p>same-blog 2 0.86888957 <a title="485-lda-2" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>Introduction: This post is a (near) transcript of a talk that I gave at theICML 2013
Workshop on Peer Review and Publishing Models. Although there's aPDF available
on my website, I've chosen to post a slightly modified version here as well in
order to better facilitate discussion.Disclaimers and ContextI want to start
with a couple of disclaimers and some context.First, I want to point out that
although I've read a lot about double-blind review, this isn't my research
area and the research discussed in this post is not my own. As a result, I
probably can't answer super detailed questions about these studies.I also want
to note that I'm not opposed to open peer review -- I was a free and open
source software developer for over ten years and I care a great deal about
openness and transparency. Rather, my motivation in writing this post is
simply to create awareness of and to initiate discussion about the benefits of
double-blind review.Lastly, and most importantly, I think it's essential to
acknowledg</p><p>3 0.85095471 <a title="485-lda-3" href="../hunch_net-2008/hunch_net-2008-11-26-Efficient_Reinforcement_Learning_in_MDPs.html">328 hunch net-2008-11-26-Efficient Reinforcement Learning in MDPs</a></p>
<p>Introduction: Claude Sammutis attempting to put together anEncyclopedia of Machine Learning.
I volunteered to write one article onEfficient RL in MDPs, which I would like
to invite comment on. Is something critical missing?</p><p>4 0.77939421 <a title="485-lda-4" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>Introduction: Forhiswork on the subject of human computation includingESPGame,Peekaboom,
andPhetch. Thenew MacArthur fellows.</p><p>5 0.68706703 <a title="485-lda-5" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>Introduction: Essentially everyone who writes research papers suffers rejections. They
always sting immediately, but upon further reflection many of these rejections
come to seem reasonable. Maybe the equations had too many typos or maybe the
topic just isn't as important as was originally thought. A few rejections do
not come to seem acceptable, and these form the basis of reviewing horror
stories, a great material for conversations. I've decided to share three of
mine, now all safely a bit distant in the past.Prediction Theory for
Classification Tutorial. This is a tutorial about tight sample complexity
bounds for classification that I submitted toJMLR. The first decision I heard
was a reject which appeared quite unjust to me--for example one of the
reviewers appeared to claim that all the content was in standard statistics
books. Upon further inquiry, several citations were given, none of which
actually covered the content. Later, I was shocked to hear the paper was
accepted. Apparently, the pape</p><p>6 0.59652847 <a title="485-lda-6" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>7 0.58909142 <a title="485-lda-7" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>8 0.58694428 <a title="485-lda-8" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>9 0.58662426 <a title="485-lda-9" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>10 0.58245236 <a title="485-lda-10" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>11 0.58200961 <a title="485-lda-11" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>12 0.5804646 <a title="485-lda-12" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>13 0.57812184 <a title="485-lda-13" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>14 0.57784557 <a title="485-lda-14" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>15 0.57139885 <a title="485-lda-15" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>16 0.56987572 <a title="485-lda-16" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>17 0.56820804 <a title="485-lda-17" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>18 0.56801933 <a title="485-lda-18" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>19 0.56733567 <a title="485-lda-19" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>20 0.56631643 <a title="485-lda-20" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
