<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>274 hunch net-2007-11-28-Computational Consequences of Classification</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-274" href="#">hunch_net-2007-274</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>274 hunch net-2007-11-28-Computational Consequences of Classification</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-274-html" href="http://hunch.net/?p=302">html</a></p><p>Introduction: In theregression vs classification debate, I'm adding a new "pro" to
classification. It seems there are computational shortcuts available for
classification which simply aren't available for regression. This arises in
several situations.Inactive learningit is sometimes possible to find aneerror
classifier with justlog(e)labeled samples. Only much more modest improvements
appear to be achievable for squared loss regression. The essential reason is
that the loss function on many examples is flat with respect to large
variations in the parameter spaces of a learned classifier, which implies that
many of these classifiers do not need to be considered. In contrast, for
squared loss regression, most substantial variations in the parameter space
influence the loss at most points.In budgeted learning, where there is either
a computational time constraint or a feature cost constraint, a classifier can
sometimes be learned to very high accuracy under the constraints while a
squared loss regresso</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In theregression vs classification debate, I'm adding a new "pro" to classification. [sent-1, score-0.346]
</p><p>2 It seems there are computational shortcuts available for classification which simply aren't available for regression. [sent-2, score-0.615]
</p><p>3 Inactive learningit is sometimes possible to find aneerror classifier with justlog(e)labeled samples. [sent-4, score-0.484]
</p><p>4 Only much more modest improvements appear to be achievable for squared loss regression. [sent-5, score-1.087]
</p><p>5 The essential reason is that the loss function on many examples is flat with respect to large variations in the parameter spaces of a learned classifier, which implies that many of these classifiers do not need to be considered. [sent-6, score-1.502]
</p><p>6 In contrast, for squared loss regression, most substantial variations in the parameter space influence the loss at most points. [sent-7, score-1.816]
</p><p>7 In budgeted learning, where there is either a computational time constraint or a feature cost constraint, a classifier can sometimes be learned to very high accuracy under the constraints while a squared loss regressor could not. [sent-8, score-2.211]
</p><p>8 For example, if there is one feature which determines whether a binary label has probability less than or greater than 0. [sent-9, score-0.659]
</p><p>9 Because squared loss is sensitive to the exact probability, many more features may be required to learn well with respect to squared loss. [sent-11, score-1.675]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('squared', 0.429), ('loss', 0.398), ('classifier', 0.264), ('variations', 0.234), ('constraint', 0.198), ('parameter', 0.181), ('justlog', 0.14), ('shortcuts', 0.14), ('flat', 0.14), ('determines', 0.13), ('learningit', 0.13), ('vs', 0.13), ('learned', 0.127), ('available', 0.123), ('probability', 0.122), ('feature', 0.122), ('classification', 0.121), ('achievable', 0.117), ('regressor', 0.117), ('influence', 0.112), ('respect', 0.111), ('spaces', 0.108), ('computational', 0.108), ('debate', 0.102), ('exact', 0.095), ('arises', 0.095), ('adding', 0.095), ('accuracy', 0.093), ('sometimes', 0.09), ('sensitive', 0.087), ('labeled', 0.084), ('regression', 0.084), ('classifiers', 0.082), ('constraints', 0.082), ('greater', 0.08), ('contrast', 0.079), ('improvements', 0.078), ('label', 0.072), ('binary', 0.072), ('cost', 0.067), ('exists', 0.065), ('appear', 0.065), ('required', 0.065), ('space', 0.064), ('essential', 0.063), ('features', 0.061), ('whether', 0.061), ('either', 0.06), ('reason', 0.058), ('high', 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="274-tfidf-1" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>Introduction: In theregression vs classification debate, I'm adding a new "pro" to
classification. It seems there are computational shortcuts available for
classification which simply aren't available for regression. This arises in
several situations.Inactive learningit is sometimes possible to find aneerror
classifier with justlog(e)labeled samples. Only much more modest improvements
appear to be achievable for squared loss regression. The essential reason is
that the loss function on many examples is flat with respect to large
variations in the parameter spaces of a learned classifier, which implies that
many of these classifiers do not need to be considered. In contrast, for
squared loss regression, most substantial variations in the parameter space
influence the loss at most points.In budgeted learning, where there is either
a computational time constraint or a feature cost constraint, a classifier can
sometimes be learned to very high accuracy under the constraints while a
squared loss regresso</p><p>2 0.37693608 <a title="274-tfidf-2" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss:
A loss function which is much easier to optimize computationally than the loss
function imposed by the world. A canonical example is when we want to learn a
weight vectorwand predict according to a dot productfw(x)= sumiwixiwhere
optimizing squared loss(y-fw(x))2over many samples is much more tractable than
optimizing 0-1 lossI(y = Threshold(fw(x) - 0.5)).While the computational
advantages of optimizing a proxy loss are substantial, we are curious: which
proxy loss is best? The answer of course depends on what the real loss imposed
by the world is. For 0-1 loss classification, there are adherents to many
choices:Log loss. If we confine the prediction to[0,1], we can treat it as a
predicted probability that the label is1, and measure loss according tolog
1/p'(y|x)wherep'(y|x)is the predicted probability of the observed label. A
standard method for confining the prediction to[0,1]islogistic regressionwhich
expo</p><p>3 0.36705396 <a title="274-tfidf-3" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>Introduction: Forlearning reductionswe have been concentrating on reducing various complex
learning problems to binary classification. This choice needs to be actively
questioned, because it was not carefully considered.Binary clasification is
learning a classifierc:X -> {0,1}so as to minimize the probability of being
wrong,Prx,y~D(c(x)y).The primary alternative candidate seems to be squared
error regression. In squared error regression, you learn a regressors:X ->
[0,1]so as to minimize squared error,Ex,y~D(s(x)-y)2.It is difficult to judge
one primitive against another. The judgement must at least partially be made
on nontheoretical grounds because (essentially) we are evaluating a choice
between two axioms/assumptions.These two primitives are significantly related.
Classification can be reduced to regression in the obvious way: you use the
regressor to predictD(y=1|x), then threshold at0.5. For this simple reduction
a squared error regret ofrimplies a classification regret of at mostr0.5.
Regress</p><p>4 0.32566062 <a title="274-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>5 0.30851689 <a title="274-tfidf-5" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner
independent of the loss function itself.Optimizing squared
losslsq(y,y')=(y-y')2means predicting the (conditional) mean ofy.Optimizing
absolute value losslav(y,y')=|y-y'|means predicting the (conditional) median
ofy. Variants canhandle other quantiles. 0/1 loss for classification is a
special case.Optimizing log lossllog(y,y')=log (1/Prz~y'(z=y))means minimizing
the description length ofy.The semantics (= meaning) of the loss are made
explicit by a theorem in each case. For squared loss, we can prove a theorem
of the form:For all distributionsDoverY, ify' = arg miny'Ey ~ Dlsq(y,y')theny'
= Ey~DySimilar theorems hold for the other examples above, and they can all be
extended to predictors ofy'for distributionsDover a contextXand a valueY.There
are 3 points to this post.Everyone doing general machine learning should be
aware of the laundry list above. They form a handy toolkit which can match
many of the problems nat</p><p>6 0.25734442 <a title="274-tfidf-6" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>7 0.22345161 <a title="274-tfidf-7" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>8 0.18809676 <a title="274-tfidf-8" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>9 0.18142523 <a title="274-tfidf-9" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>10 0.15883902 <a title="274-tfidf-10" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>11 0.14217809 <a title="274-tfidf-11" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>12 0.141289 <a title="274-tfidf-12" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<p>13 0.13984905 <a title="274-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>14 0.13922475 <a title="274-tfidf-14" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>15 0.12324978 <a title="274-tfidf-15" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>16 0.1213684 <a title="274-tfidf-16" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>17 0.11879171 <a title="274-tfidf-17" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>18 0.11798654 <a title="274-tfidf-18" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>19 0.11300685 <a title="274-tfidf-19" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>20 0.1119636 <a title="274-tfidf-20" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.193), (1, -0.239), (2, -0.206), (3, 0.193), (4, 0.375), (5, 0.038), (6, 0.032), (7, 0.007), (8, -0.007), (9, 0.025), (10, 0.052), (11, 0.081), (12, 0.072), (13, 0.01), (14, -0.001), (15, -0.012), (16, 0.008), (17, 0.088), (18, 0.042), (19, -0.009), (20, 0.057), (21, 0.038), (22, -0.015), (23, -0.0), (24, 0.03), (25, -0.005), (26, 0.072), (27, 0.022), (28, -0.055), (29, 0.025), (30, -0.014), (31, 0.035), (32, 0.006), (33, 0.041), (34, -0.06), (35, 0.059), (36, 0.008), (37, -0.048), (38, 0.009), (39, 0.061), (40, 0.002), (41, -0.038), (42, 0.041), (43, -0.028), (44, -0.005), (45, -0.028), (46, -0.065), (47, 0.024), (48, -0.043), (49, -0.048)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9913075 <a title="274-lsi-1" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>Introduction: In theregression vs classification debate, I'm adding a new "pro" to
classification. It seems there are computational shortcuts available for
classification which simply aren't available for regression. This arises in
several situations.Inactive learningit is sometimes possible to find aneerror
classifier with justlog(e)labeled samples. Only much more modest improvements
appear to be achievable for squared loss regression. The essential reason is
that the loss function on many examples is flat with respect to large
variations in the parameter spaces of a learned classifier, which implies that
many of these classifiers do not need to be considered. In contrast, for
squared loss regression, most substantial variations in the parameter space
influence the loss at most points.In budgeted learning, where there is either
a computational time constraint or a feature cost constraint, a classifier can
sometimes be learned to very high accuracy under the constraints while a
squared loss regresso</p><p>2 0.88124228 <a title="274-lsi-2" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss:
A loss function which is much easier to optimize computationally than the loss
function imposed by the world. A canonical example is when we want to learn a
weight vectorwand predict according to a dot productfw(x)= sumiwixiwhere
optimizing squared loss(y-fw(x))2over many samples is much more tractable than
optimizing 0-1 lossI(y = Threshold(fw(x) - 0.5)).While the computational
advantages of optimizing a proxy loss are substantial, we are curious: which
proxy loss is best? The answer of course depends on what the real loss imposed
by the world is. For 0-1 loss classification, there are adherents to many
choices:Log loss. If we confine the prediction to[0,1], we can treat it as a
predicted probability that the label is1, and measure loss according tolog
1/p'(y|x)wherep'(y|x)is the predicted probability of the observed label. A
standard method for confining the prediction to[0,1]islogistic regressionwhich
expo</p><p>3 0.87326956 <a title="274-lsi-3" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner
independent of the loss function itself.Optimizing squared
losslsq(y,y')=(y-y')2means predicting the (conditional) mean ofy.Optimizing
absolute value losslav(y,y')=|y-y'|means predicting the (conditional) median
ofy. Variants canhandle other quantiles. 0/1 loss for classification is a
special case.Optimizing log lossllog(y,y')=log (1/Prz~y'(z=y))means minimizing
the description length ofy.The semantics (= meaning) of the loss are made
explicit by a theorem in each case. For squared loss, we can prove a theorem
of the form:For all distributionsDoverY, ify' = arg miny'Ey ~ Dlsq(y,y')theny'
= Ey~DySimilar theorems hold for the other examples above, and they can all be
extended to predictors ofy'for distributionsDover a contextXand a valueY.There
are 3 points to this post.Everyone doing general machine learning should be
aware of the laundry list above. They form a handy toolkit which can match
many of the problems nat</p><p>4 0.85387701 <a title="274-lsi-4" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>5 0.79849017 <a title="274-lsi-5" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>Introduction: How do we judge success in Machine Learning? AsAaronnotes, the best way is to
use the loss imposed on you by the world. This turns out to be infeasible
sometimes for various reasons. The ones I've seen are:The learned prediction
is used in some complicated process that does not give the feedback necessary
to understand the prediction's impact on the loss.The prediction is used by
some other system which expects some semantics to the predicted value. This is
similar to the previous example, except that the issue is design modularity
rather than engineering modularity.The correct loss function is simply unknown
(and perhaps unknowable, except by experimentation).In these situations, it's
unclear what metric for evaluation should be chosen. This post has some design
advice for this murkier case. I'm using the word "metric" here to distinguish
the fact that we are considering methods forevaluatingpredictive systems
rather than a loss imposed by the real world or a loss which is optimized b</p><p>6 0.79603034 <a title="274-lsi-6" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>7 0.77579266 <a title="274-lsi-7" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>8 0.7149083 <a title="274-lsi-8" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>9 0.68642694 <a title="274-lsi-9" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>10 0.66622788 <a title="274-lsi-10" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>11 0.63702536 <a title="274-lsi-11" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>12 0.51402336 <a title="274-lsi-12" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>13 0.49043575 <a title="274-lsi-13" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>14 0.48764569 <a title="274-lsi-14" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>15 0.44119218 <a title="274-lsi-15" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>16 0.42555866 <a title="274-lsi-16" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>17 0.40863228 <a title="274-lsi-17" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>18 0.40536064 <a title="274-lsi-18" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>19 0.39937505 <a title="274-lsi-19" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>20 0.39536798 <a title="274-lsi-20" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.013), (35, 0.048), (42, 0.276), (43, 0.228), (68, 0.168), (69, 0.052), (74, 0.059), (88, 0.037)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92621481 <a title="274-lda-1" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>Introduction: In theregression vs classification debate, I'm adding a new "pro" to
classification. It seems there are computational shortcuts available for
classification which simply aren't available for regression. This arises in
several situations.Inactive learningit is sometimes possible to find aneerror
classifier with justlog(e)labeled samples. Only much more modest improvements
appear to be achievable for squared loss regression. The essential reason is
that the loss function on many examples is flat with respect to large
variations in the parameter spaces of a learned classifier, which implies that
many of these classifiers do not need to be considered. In contrast, for
squared loss regression, most substantial variations in the parameter space
influence the loss at most points.In budgeted learning, where there is either
a computational time constraint or a feature cost constraint, a classifier can
sometimes be learned to very high accuracy under the constraints while a
squared loss regresso</p><p>2 0.88522357 <a title="274-lda-2" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these
suggest that some method of saying "I prefer this predictor to that predictor"
is useful and necessary. Examples include Bayesian reasoning, prediction
bounds, and online learning. One difficulty which arises is that the manner
and meaning of saying "I prefer this predictor to that predictor"
differs.Prior(Bayesian) A prior is a probability distribution over a set of
distributions which expresses a belief in the probability that some
distribution is the distribution generating the data."Prior"(Prediction bounds
& online learning) The "prior" is a measure over a set of classifiers which
expresses the degree to which you hope the classifier will predict
well.Bias(Regularization, Early termination of neural network training, etcâ&euro;Ś)
The bias is some (often implicitly specified by an algorithm) way of
preferring one predictor to another.This only scratches the surface--there are
yet more subtleties. For example the (as</p><p>3 0.8072139 <a title="274-lda-3" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provostgave a talk at the ICMLmetalearning workshopon "metalearning"
and the "no free lunch theorem" which seems worth summarizing.As a review: the
no free lunch theorem is the most complicated way we know of to say that
abiasis required in order to learn. The simplest way to see this is in a
nonprobabilistic setting. If you are given examples of the form(x,y)and you
wish to predictyfromxthen any prediction mechanism errs half the time in
expectation over all sequences of examples. The proof of this is very simple:
on every example a predictor must make some prediction and by symmetry over
the set of sequences it will be wrong half the time and right half the time.
The basic idea of this proof has been applied to many other settings.The
simplistic interpretation of this theorem which many people jump to is
"machine learning is dead" since there can be no single learning algorithm
which can solve all learning problems. This is the wrong way to think about
it. In the real world, w</p><p>4 0.80352402 <a title="274-lda-4" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I've enjoyed theTerminatormovies and show. Neglecting the whacky aspects (time
travel and associated paradoxes), there is an enduring topic of discussion:
how do people deal with intelligent machines (and vice versa)?In Terminator-
land, the primary method for dealing with intelligent machines is to prevent
them from being made. This approach works pretty badly, because a new angle on
building an intelligent machine keeps coming up. This is partly a ploy for
writer's to avoid writing themselves out of a job, but there is a fundamental
truth to it as well: preventing progress in research is hard.The United
States, has been experimenting with trying to stop research onstem cells. It
hasn't worked very well--the net effect has been retarding research programs a
bit, and exporting some research to other countries. Another less recent
example was encryption technology, for which the United States generally did
not encourage early public research and evendiscouraged as a munition. This
slowe</p><p>5 0.80309516 <a title="274-lda-5" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>Introduction: Many people in Machine Learning don't fully understand the impact of
computation, as demonstrated by a lack ofbig-Oanalysis of new learning
algorithms. This is important--some current active research programs are
fundamentally flawed w.r.t. computation, and other research programs are
directly motivated by it. When considering a learning algorithm, I think about
the following questions:How does the learning algorithm scale with the number
of examplesm? Any algorithm using all of the data is at leastO(m), but in many
cases this isO(m2)(naive nearest neighbor for self-prediction) or unknown
(k-means or many other optimization algorithms). The unknown case is very
common, and it can mean (for example) that the algorithm isn't convergent or
simply that the amount of computation isn't controlled.The above question can
also be asked for test cases. In some applications, test-time performance is
of great importance.How does the algorithm scale with the number of
featuresnper example? Many sec</p><p>6 0.79806441 <a title="274-lda-6" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>7 0.79072571 <a title="274-lda-7" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>8 0.79070449 <a title="274-lda-8" href="../hunch_net-2012/hunch_net-2012-03-24-David_Waltz.html">460 hunch net-2012-03-24-David Waltz</a></p>
<p>9 0.78976458 <a title="274-lda-9" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>10 0.78877991 <a title="274-lda-10" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>11 0.78054386 <a title="274-lda-11" href="../hunch_net-2011/hunch_net-2011-08-20-The_Large_Scale_Learning_Survey_Tutorial.html">442 hunch net-2011-08-20-The Large Scale Learning Survey Tutorial</a></p>
<p>12 0.77624214 <a title="274-lda-12" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>13 0.77399701 <a title="274-lda-13" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>14 0.77032483 <a title="274-lda-14" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>15 0.76937312 <a title="274-lda-15" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>16 0.76774025 <a title="274-lda-16" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>17 0.76490307 <a title="274-lda-17" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>18 0.76353979 <a title="274-lda-18" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>19 0.76027334 <a title="274-lda-19" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>20 0.75584215 <a title="274-lda-20" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
