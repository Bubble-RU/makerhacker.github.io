<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>245 hunch net-2007-05-12-Loss Function Semantics</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-245" href="#">hunch_net-2007-245</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>245 hunch net-2007-05-12-Loss Function Semantics</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-245-html" href="http://hunch.net/?p=269">html</a></p><p>Introduction: Some loss functions have a meaning, which can be understood in a manner independent of the loss function itself.  
  
 Optimizing squared loss  l sq (y,y’)=(y-y’) 2   means predicting the (conditional) mean of  y . 
 Optimizing absolute value loss  l av (y,y’)=|y-y’|  means predicting the (conditional) median of  y .  Variants can  handle other quantiles .  0/1 loss for classification is a special case. 
 Optimizing log loss  l log (y,y’)=log (1/Pr z~y’ (z=y))  means minimizing the description length of  y . 
  
The semantics (= meaning) of the loss are made explicit by a theorem in each case.  For squared loss, we can prove a theorem of the form: 
For all distributions  D  over  Y , if    y’ = arg min y’  E y ~ D  l sq  (y,y’)   then   y’ = E y~D  y  
 
Similar theorems hold for the other examples above, and they can all be extended to predictors of  y’  for distributions  D  over a context  X  and a value  Y .
 
There are 3 points to this post.
  
 Everyone doing general machine lear</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Some loss functions have a meaning, which can be understood in a manner independent of the loss function itself. [sent-1, score-1.276]
</p><p>2 Optimizing squared loss  l sq (y,y’)=(y-y’) 2   means predicting the (conditional) mean of  y . [sent-2, score-1.283]
</p><p>3 Optimizing absolute value loss  l av (y,y’)=|y-y’|  means predicting the (conditional) median of  y . [sent-3, score-1.14]
</p><p>4 Optimizing log loss  l log (y,y’)=log (1/Pr z~y’ (z=y))  means minimizing the description length of  y . [sent-6, score-1.153]
</p><p>5 The semantics (= meaning) of the loss are made explicit by a theorem in each case. [sent-7, score-1.009]
</p><p>6 Everyone doing general machine learning should be aware of the laundry list above. [sent-10, score-0.298]
</p><p>7 They form a handy toolkit which can match many of the problems naturally encountered. [sent-11, score-0.32]
</p><p>8 People also try to optimize a variety of other loss functions. [sent-12, score-0.686]
</p><p>9 Some of these are (effectively) a special case of the above. [sent-13, score-0.206]
</p><p>10 For example, “hinge loss” is absolute value loss when the hinge point is at the upper range. [sent-14, score-1.065]
</p><p>11 Some of the other losses do not have any known semantics. [sent-15, score-0.07]
</p><p>12 In this case, discovering a semantics could be quite valuable. [sent-16, score-0.384]
</p><p>13 The natural direction when thinking about how to solve a problem is to start with the semantics you want and then derive a loss. [sent-17, score-0.386]
</p><p>14 I don’t know of any general way to do this other than simply applying the laundry list above. [sent-18, score-0.368]
</p><p>15 As one example, what is a loss function for estimating the mean of a random variable  y  over the 5th to 95th quantile? [sent-19, score-0.874]
</p><p>16 (How do we do squared error regression which is insensitive to outliers? [sent-20, score-0.184]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('loss', 0.538), ('semantics', 0.311), ('sq', 0.234), ('laundry', 0.208), ('optimizing', 0.187), ('squared', 0.184), ('absolute', 0.181), ('hinge', 0.173), ('log', 0.142), ('special', 0.132), ('distributions', 0.129), ('meaning', 0.121), ('conditional', 0.117), ('mean', 0.112), ('means', 0.112), ('value', 0.11), ('arg', 0.104), ('toolkit', 0.104), ('predicting', 0.103), ('theorem', 0.1), ('median', 0.096), ('quantile', 0.091), ('list', 0.09), ('variety', 0.087), ('estimating', 0.08), ('extended', 0.08), ('function', 0.079), ('length', 0.078), ('match', 0.078), ('minimizing', 0.078), ('derive', 0.075), ('min', 0.075), ('case', 0.074), ('handy', 0.073), ('discovering', 0.073), ('losses', 0.07), ('applying', 0.07), ('variants', 0.07), ('hold', 0.067), ('form', 0.065), ('variable', 0.065), ('description', 0.063), ('manner', 0.063), ('upper', 0.063), ('handle', 0.062), ('optimize', 0.061), ('explicit', 0.06), ('theorems', 0.06), ('predictors', 0.058), ('independent', 0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="245-tfidf-1" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner independent of the loss function itself.  
  
 Optimizing squared loss  l sq (y,y’)=(y-y’) 2   means predicting the (conditional) mean of  y . 
 Optimizing absolute value loss  l av (y,y’)=|y-y’|  means predicting the (conditional) median of  y .  Variants can  handle other quantiles .  0/1 loss for classification is a special case. 
 Optimizing log loss  l log (y,y’)=log (1/Pr z~y’ (z=y))  means minimizing the description length of  y . 
  
The semantics (= meaning) of the loss are made explicit by a theorem in each case.  For squared loss, we can prove a theorem of the form: 
For all distributions  D  over  Y , if    y’ = arg min y’  E y ~ D  l sq  (y,y’)   then   y’ = E y~D  y  
 
Similar theorems hold for the other examples above, and they can all be extended to predictors of  y’  for distributions  D  over a context  X  and a value  Y .
 
There are 3 points to this post.
  
 Everyone doing general machine lear</p><p>2 0.57299441 <a title="245-tfidf-2" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss: A loss function which is much easier to optimize computationally than the loss function imposed by the world.  A canonical example is when we want to learn a weight vector  w  and predict according to a dot product  f w (x)= sum i  w i x i   
where optimizing squared loss  (y-f w (x)) 2   over many samples is much more tractable than optimizing 0-1 loss  I(y = Threshold(f w (x) – 0.5)) .
 
While the computational advantages of optimizing a proxy loss are substantial, we are curious: which proxy loss is best?  The answer of course depends on what the real loss imposed by the world is.  For 0-1 loss classification, there are adherents to many choices:
  
 Log loss.  If we confine the prediction to  [0,1] , we can treat it as a predicted probability that the label is  1 , and measure loss according to  log 1/p’(y|x)  where  p’(y|x)  is the predicted probability of the observed label.  A standard method for confi</p><p>3 0.48225033 <a title="245-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction and the correct prediction, and determines how much loss is incurred.  (People sometimes attempt to optimize functions of more than one example such as “area under the ROC curve” or “harmonic mean of precision and recall”.)  Typically we try to find predictors that minimize loss.  
 
There seems to be a strong dichotomy between two views of what “loss” means in learning.
  
  Loss is determined by the problem.  Loss is a part of the specification of the learning problem.  Examples of problems specified by the loss function include “binary classification”, “multiclass classification”, “importance weighted classification”, “l 2  regression”, etc…  This is the decision theory view of what loss means, and the view that I prefer. 
  Loss is determined by the solution.  To solve a problem, you optimize some particular loss function  not  given by the problem.  Examples of these loss functions are “hinge loss” (for SV</p><p>4 0.36889857 <a title="245-tfidf-4" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>Introduction: Hal  asks   a very good question: “When is the right time to insert the loss function?”  In particular, should it be used at testing time or at training time?
 
When the world imposes a loss on us, the standard Bayesian recipe is to predict the (conditional) probability of each possibility and then choose the possibility which minimizes the expected loss.  In contrast, as the  confusion  over “loss = money lost” or “loss = the thing you optimize” might indicate, many people ignore the Bayesian approach and simply optimize their loss (or a close proxy for their loss) over the representation on the training set.
 
The best answer I can give is “it’s unclear, but I prefer optimizing the loss at training time”.  My experience is that optimizing the loss in the most direct manner possible typically yields best performance.  This question is related to a basic principle which both  Yann LeCun (applied) and  Vladimir Vapnik (theoretical) advocate: “solve the simplest prediction problem that s</p><p>5 0.3286587 <a title="245-tfidf-5" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>Introduction: In the  regression vs classification debate , I’m adding a new “pro” to classification.  It seems there are computational shortcuts available for classification which simply aren’t available for regression.  This arises in several situations.
  
 In  active learning  it is sometimes possible to find an  e  error classifier with just  log(e)  labeled samples.    Only much more modest improvements appear to be achievable for squared loss regression.  The essential reason is that the loss function on many examples is flat with respect to large variations in the parameter spaces of a learned classifier, which implies that many of these classifiers do not need to be considered.  In contrast, for squared loss regression, most substantial variations in the parameter space influence the loss at most points. 
 In budgeted learning, where there is either a computational time constraint or a feature cost constraint, a classifier can sometimes be learned to very high accuracy under the constraints</p><p>6 0.31551817 <a title="245-tfidf-6" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>7 0.21577363 <a title="245-tfidf-7" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>8 0.20601578 <a title="245-tfidf-8" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>9 0.20448059 <a title="245-tfidf-9" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>10 0.19429749 <a title="245-tfidf-10" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>11 0.17718923 <a title="245-tfidf-11" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>12 0.16010006 <a title="245-tfidf-12" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>13 0.15337592 <a title="245-tfidf-13" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>14 0.14570999 <a title="245-tfidf-14" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>15 0.13970149 <a title="245-tfidf-15" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>16 0.13761508 <a title="245-tfidf-16" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>17 0.12262534 <a title="245-tfidf-17" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>18 0.12189317 <a title="245-tfidf-18" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>19 0.12109784 <a title="245-tfidf-19" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>20 0.11919262 <a title="245-tfidf-20" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.178), (1, 0.227), (2, 0.19), (3, -0.238), (4, -0.454), (5, 0.211), (6, -0.191), (7, 0.022), (8, 0.069), (9, 0.032), (10, 0.129), (11, -0.098), (12, -0.057), (13, 0.071), (14, -0.055), (15, 0.008), (16, -0.006), (17, 0.008), (18, -0.038), (19, 0.041), (20, 0.071), (21, 0.022), (22, -0.063), (23, -0.016), (24, 0.008), (25, 0.019), (26, -0.014), (27, -0.004), (28, -0.025), (29, 0.004), (30, -0.025), (31, 0.008), (32, 0.006), (33, 0.037), (34, 0.017), (35, -0.019), (36, 0.011), (37, 0.009), (38, 0.01), (39, -0.04), (40, -0.013), (41, 0.032), (42, -0.012), (43, -0.028), (44, -0.019), (45, 0.005), (46, 0.017), (47, 0.051), (48, 0.047), (49, -0.037)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99735111 <a title="245-lsi-1" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner independent of the loss function itself.  
  
 Optimizing squared loss  l sq (y,y’)=(y-y’) 2   means predicting the (conditional) mean of  y . 
 Optimizing absolute value loss  l av (y,y’)=|y-y’|  means predicting the (conditional) median of  y .  Variants can  handle other quantiles .  0/1 loss for classification is a special case. 
 Optimizing log loss  l log (y,y’)=log (1/Pr z~y’ (z=y))  means minimizing the description length of  y . 
  
The semantics (= meaning) of the loss are made explicit by a theorem in each case.  For squared loss, we can prove a theorem of the form: 
For all distributions  D  over  Y , if    y’ = arg min y’  E y ~ D  l sq  (y,y’)   then   y’ = E y~D  y  
 
Similar theorems hold for the other examples above, and they can all be extended to predictors of  y’  for distributions  D  over a context  X  and a value  Y .
 
There are 3 points to this post.
  
 Everyone doing general machine lear</p><p>2 0.97803974 <a title="245-lsi-2" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss: A loss function which is much easier to optimize computationally than the loss function imposed by the world.  A canonical example is when we want to learn a weight vector  w  and predict according to a dot product  f w (x)= sum i  w i x i   
where optimizing squared loss  (y-f w (x)) 2   over many samples is much more tractable than optimizing 0-1 loss  I(y = Threshold(f w (x) – 0.5)) .
 
While the computational advantages of optimizing a proxy loss are substantial, we are curious: which proxy loss is best?  The answer of course depends on what the real loss imposed by the world is.  For 0-1 loss classification, there are adherents to many choices:
  
 Log loss.  If we confine the prediction to  [0,1] , we can treat it as a predicted probability that the label is  1 , and measure loss according to  log 1/p’(y|x)  where  p’(y|x)  is the predicted probability of the observed label.  A standard method for confi</p><p>3 0.97165537 <a title="245-lsi-3" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction and the correct prediction, and determines how much loss is incurred.  (People sometimes attempt to optimize functions of more than one example such as “area under the ROC curve” or “harmonic mean of precision and recall”.)  Typically we try to find predictors that minimize loss.  
 
There seems to be a strong dichotomy between two views of what “loss” means in learning.
  
  Loss is determined by the problem.  Loss is a part of the specification of the learning problem.  Examples of problems specified by the loss function include “binary classification”, “multiclass classification”, “importance weighted classification”, “l 2  regression”, etc…  This is the decision theory view of what loss means, and the view that I prefer. 
  Loss is determined by the solution.  To solve a problem, you optimize some particular loss function  not  given by the problem.  Examples of these loss functions are “hinge loss” (for SV</p><p>4 0.90369725 <a title="245-lsi-4" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>Introduction: Hal  asks   a very good question: “When is the right time to insert the loss function?”  In particular, should it be used at testing time or at training time?
 
When the world imposes a loss on us, the standard Bayesian recipe is to predict the (conditional) probability of each possibility and then choose the possibility which minimizes the expected loss.  In contrast, as the  confusion  over “loss = money lost” or “loss = the thing you optimize” might indicate, many people ignore the Bayesian approach and simply optimize their loss (or a close proxy for their loss) over the representation on the training set.
 
The best answer I can give is “it’s unclear, but I prefer optimizing the loss at training time”.  My experience is that optimizing the loss in the most direct manner possible typically yields best performance.  This question is related to a basic principle which both  Yann LeCun (applied) and  Vladimir Vapnik (theoretical) advocate: “solve the simplest prediction problem that s</p><p>5 0.86192101 <a title="245-lsi-5" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>Introduction: How do we judge success in Machine Learning?  As  Aaron   notes , the best way is to use the loss imposed on you by the world.  This turns out to be infeasible sometimes for various reasons.  The ones I’ve seen are:
  
 The learned prediction is used in some complicated process that does not give the feedback necessary to understand the prediction’s impact on the loss.  
 The prediction is used by some other system which expects some semantics to the predicted value.  This is similar to the previous example, except that the issue is design modularity rather than engineering modularity. 
 The correct loss function is simply unknown (and perhaps unknowable, except by experimentation). 
  
In these situations, it’s unclear what metric for evaluation should be chosen.  This post has some design advice for this murkier case.  I’m using the word “metric” here to distinguish the fact that we are considering methods for  evaluating  predictive systems rather than a loss imposed by the real wor</p><p>6 0.85609126 <a title="245-lsi-6" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>7 0.78735673 <a title="245-lsi-7" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>8 0.74210232 <a title="245-lsi-8" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>9 0.67985022 <a title="245-lsi-9" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>10 0.51010346 <a title="245-lsi-10" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>11 0.47464883 <a title="245-lsi-11" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>12 0.47414798 <a title="245-lsi-12" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>13 0.45673493 <a title="245-lsi-13" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>14 0.4527958 <a title="245-lsi-14" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>15 0.44326064 <a title="245-lsi-15" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>16 0.4334729 <a title="245-lsi-16" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>17 0.4194034 <a title="245-lsi-17" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>18 0.40010899 <a title="245-lsi-18" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>19 0.38114065 <a title="245-lsi-19" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>20 0.36429808 <a title="245-lsi-20" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.05), (3, 0.055), (24, 0.011), (27, 0.66), (53, 0.034), (55, 0.034), (77, 0.019), (94, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99922115 <a title="245-lda-1" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner independent of the loss function itself.  
  
 Optimizing squared loss  l sq (y,y’)=(y-y’) 2   means predicting the (conditional) mean of  y . 
 Optimizing absolute value loss  l av (y,y’)=|y-y’|  means predicting the (conditional) median of  y .  Variants can  handle other quantiles .  0/1 loss for classification is a special case. 
 Optimizing log loss  l log (y,y’)=log (1/Pr z~y’ (z=y))  means minimizing the description length of  y . 
  
The semantics (= meaning) of the loss are made explicit by a theorem in each case.  For squared loss, we can prove a theorem of the form: 
For all distributions  D  over  Y , if    y’ = arg min y’  E y ~ D  l sq  (y,y’)   then   y’ = E y~D  y  
 
Similar theorems hold for the other examples above, and they can all be extended to predictors of  y’  for distributions  D  over a context  X  and a value  Y .
 
There are 3 points to this post.
  
 Everyone doing general machine lear</p><p>2 0.99186206 <a title="245-lda-2" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<p>Introduction: Here are two papers that seem particularly interesting at this year’s COLT.
  
  Gilles Blanchard  and  FranÃƒÂ§ois Fleuret ,  Occam’s Hammer .  When we are interested in very tight bounds on the true error rate of a classifier, it is tempting to use a PAC-Bayes bound which can (empirically) be  quite tight .  A disadvantage of the PAC-Bayes bound is that it applies to a classifier which is randomized over a set of base classifiers rather than a single classifier.  This paper shows that a similar bound can be proved which holds for a single classifier drawn from the set.   The ability to safely use a single classifier is very nice.  This technique applies generically to any base bound, so it has other applications covered in the paper. 
  Adam Tauman Kalai .  Learning Nested Halfspaces and Uphill Decision Trees .  Classification PAC-learning, where you prove that any problem amongst some set is polytime learnable with respect to any distribution over the input  X  is extraordinarily ch</p><p>3 0.99110299 <a title="245-lda-3" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>Introduction: In the  regression vs classification debate , I’m adding a new “pro” to classification.  It seems there are computational shortcuts available for classification which simply aren’t available for regression.  This arises in several situations.
  
 In  active learning  it is sometimes possible to find an  e  error classifier with just  log(e)  labeled samples.    Only much more modest improvements appear to be achievable for squared loss regression.  The essential reason is that the loss function on many examples is flat with respect to large variations in the parameter spaces of a learned classifier, which implies that many of these classifiers do not need to be considered.  In contrast, for squared loss regression, most substantial variations in the parameter space influence the loss at most points. 
 In budgeted learning, where there is either a computational time constraint or a feature cost constraint, a classifier can sometimes be learned to very high accuracy under the constraints</p><p>4 0.99045122 <a title="245-lda-4" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>Introduction: Yoram  and  Shai ‘s  online learning tutorial  at  ICML  brings up a question for me, “Why use the  dual ?”
 
The basic setting is learning a weight vector  w i   so that the function  f(x)= sum i  w i  x i   optimizes some convex loss function.
 
The functional view of the dual is that instead of (or in addition to) keeping track of  w i   over the feature space, you keep track of a vector  a j   over the examples and define  w i  = sum j  a j  x ji  .
 
The above view of duality makes operating in the dual appear unnecessary, because in the end a weight vector is always used.  The tutorial suggests that thinking about the dual gives a unified algorithmic font for deriving online learning algorithms.  I haven’t worked with the dual representation much myself, but I have seen a few examples where it appears helpful.
  
  Noise  When doing online optimization (i.e. online learning where you are allowed to look at individual examples multiple times), the dual representation may be helpfu</p><p>5 0.99042988 <a title="245-lda-5" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>Introduction: Consider the contextual bandit setting where, repeatedly:
  
 A context  x  is observed. 
 An action  a  is taken given the context  x .  
 A reward  r  is observed, dependent on  x  and  a . 
  
Where the goal of a learning agent is to find a policy for step 2 achieving a large expected reward.  
 
This setting is of obvious importance, because in the real world we typically make decisions based on some set of information and then get feedback only about the single action taken.  It also fundamentally differs from supervised learning settings because knowing the value of one action is not equivalent to knowing the value of all actions.
 
A decade ago the best machine learning techniques for this setting where implausibly inefficient.   Dean Foster  once told me he thought the area was a research sinkhole with little progress to be expected.  Now we are on the verge of being able to routinely attack these problems, in almost exactly the same sense that we routinely attack bread and but</p><p>6 0.99002814 <a title="245-lda-6" href="../hunch_net-2006/hunch_net-2006-03-24-NLPers.html">166 hunch net-2006-03-24-NLPers</a></p>
<p>7 0.99002814 <a title="245-lda-7" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>8 0.99002814 <a title="245-lda-8" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>9 0.98959434 <a title="245-lda-9" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>10 0.98958534 <a title="245-lda-10" href="../hunch_net-2006/hunch_net-2006-04-14-JMLR_is_a_success.html">172 hunch net-2006-04-14-JMLR is a success</a></p>
<p>11 0.98878217 <a title="245-lda-11" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>12 0.98636389 <a title="245-lda-12" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>13 0.98456502 <a title="245-lda-13" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>14 0.97516733 <a title="245-lda-14" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>15 0.97049612 <a title="245-lda-15" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>16 0.96401876 <a title="245-lda-16" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>17 0.95265198 <a title="245-lda-17" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>18 0.95264119 <a title="245-lda-18" href="../hunch_net-2013/hunch_net-2013-06-10-The_Large_Scale_Learning_class_notes.html">483 hunch net-2013-06-10-The Large Scale Learning class notes</a></p>
<p>19 0.95111877 <a title="245-lda-19" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>20 0.95056474 <a title="245-lda-20" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
