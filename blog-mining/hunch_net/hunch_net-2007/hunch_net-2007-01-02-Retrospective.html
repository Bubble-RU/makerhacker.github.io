<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>225 hunch net-2007-01-02-Retrospective</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-225" href="#">hunch_net-2007-225</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>225 hunch net-2007-01-02-Retrospective</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-225-html" href="http://hunch.net/?p=246">html</a></p><p>Introduction: It's been almost two years since this blog began. In that time, I've learned
enough to shift my expectations in several ways.Initially, the idea was for a
general purpose ML blog where different people could contribute posts. What
has actually happened is most posts come from me, with a few guest posts that
I greatly value. There are a few reasons I see for this.Overload. A couple
years ago, I had not fully appreciated just how busy life gets for a
researcher. Making a post is not simply a matter of getting to it, but rather
of prioritizing between {writing a grant, finishing an overdue review, writing
a paper, teaching a class, writing a program, etcâ&euro;Ś}. This is a substantial
transition away from what life as a graduate student is like. At some point
the question is not "when will I get to it?" but rather "will I get to it?"
and the answer starts to become "no" most of the time.Feedback failure. This
blog currently receives about 3K unique visitors per day from about 13K unique
sites p</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 It's been almost two years since this blog began. [sent-1, score-0.641]
</p><p>2 Initially, the idea was for a general purpose ML blog where different people could contribute posts. [sent-3, score-0.45]
</p><p>3 What has actually happened is most posts come from me, with a few guest posts that I greatly value. [sent-4, score-0.8]
</p><p>4 Making a post is not simply a matter of getting to it, but rather of prioritizing between {writing a grant, finishing an overdue review, writing a paper, teaching a class, writing a program, etcâ&euro;Ś}. [sent-8, score-0.671]
</p><p>5 This blog currently receives about 3K unique visitors per day from about 13K unique sites per month. [sent-14, score-1.075]
</p><p>6 This number of visitors is large enough that it scares me somewhat--having several thousand people read a post is more attention than almost all papers published in academia get. [sent-15, score-0.636]
</p><p>7 The internet has a huge untapped capacity to support content, so one of the traditional reasons for editorial control (limited space) simply no longer exists. [sent-19, score-0.407]
</p><p>8 Nevertheless, the time of readers is important and there is a focus-of-attention issue since one blog with all posts on all topics would be virtually useless. [sent-20, score-1.042]
</p><p>9 In an ideal world, the need for explicit content control would disappear and be replaced by a massive cooperative collaborative filtering process. [sent-21, score-0.477]
</p><p>10 This shift is already well underway since anyone can start their own blog and read anything they choose. [sent-22, score-0.707]
</p><p>11 Expending the effort to write clearly about them in a post is not too difficult from expending the effort to write clearly about them in a paper, which is the traditional mechanism of publishing. [sent-28, score-1.063]
</p><p>12 There is no simply way around this problem, although changing people's expectations may be helpful. [sent-29, score-0.296]
</p><p>13 For the record, I'm always happy to consider posts by others. [sent-32, score-0.298]
</p><p>14 If you are considering your own blog, trying a guest post or two is a great way to experiment. [sent-33, score-0.504]
</p><p>15 Many people don't have the time or inclination to run their own blog, so guest posts are essential. [sent-34, score-0.57]
</p><p>16 A good post is fundamentally an interesting post, but "interesting" can be broken down further. [sent-36, score-0.295]
</p><p>17 A blog strongly encourages otherwise since the backgrounds of readers are very diverse. [sent-39, score-0.725]
</p><p>18 As an example the posts of the form "interesting papers at" tend to get very few comments, but they are some of the most viewed. [sent-43, score-0.365]
</p><p>19 The most obvious way to use a blog is as a mechanism for posting finished research. [sent-45, score-0.669]
</p><p>20 It's ok for this, but the most interesting way of using the blog are for topics which could not be stated as a research paper. [sent-46, score-0.718]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('blog', 0.45), ('posts', 0.298), ('post', 0.207), ('guest', 0.204), ('visitors', 0.147), ('expending', 0.147), ('academia', 0.133), ('collaborative', 0.129), ('expectations', 0.123), ('writing', 0.121), ('clearly', 0.121), ('comments', 0.12), ('readers', 0.118), ('blogs', 0.11), ('filtering', 0.104), ('years', 0.102), ('unique', 0.102), ('life', 0.099), ('traditional', 0.097), ('shift', 0.093), ('expectation', 0.093), ('way', 0.093), ('control', 0.092), ('since', 0.089), ('interesting', 0.088), ('topics', 0.087), ('write', 0.087), ('couple', 0.086), ('content', 0.084), ('simply', 0.08), ('read', 0.075), ('thousand', 0.074), ('convoluted', 0.074), ('editorial', 0.074), ('prioritizing', 0.074), ('per', 0.071), ('backgrounds', 0.068), ('inclination', 0.068), ('akin', 0.068), ('cooperative', 0.068), ('finishing', 0.068), ('receives', 0.068), ('get', 0.067), ('effort', 0.067), ('review', 0.065), ('sites', 0.064), ('barely', 0.064), ('posting', 0.064), ('capacity', 0.064), ('mechanism', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="225-tfidf-1" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>Introduction: It's been almost two years since this blog began. In that time, I've learned
enough to shift my expectations in several ways.Initially, the idea was for a
general purpose ML blog where different people could contribute posts. What
has actually happened is most posts come from me, with a few guest posts that
I greatly value. There are a few reasons I see for this.Overload. A couple
years ago, I had not fully appreciated just how busy life gets for a
researcher. Making a post is not simply a matter of getting to it, but rather
of prioritizing between {writing a grant, finishing an overdue review, writing
a paper, teaching a class, writing a program, etcâ&euro;Ś}. This is a substantial
transition away from what life as a graduate student is like. At some point
the question is not "when will I get to it?" but rather "will I get to it?"
and the answer starts to become "no" most of the time.Feedback failure. This
blog currently receives about 3K unique visitors per day from about 13K unique
sites p</p><p>2 0.3221274 <a title="225-tfidf-2" href="../hunch_net-2009/hunch_net-2009-12-09-Inherent_Uncertainty.html">383 hunch net-2009-12-09-Inherent Uncertainty</a></p>
<p>Introduction: I'd like to point outInherent Uncertainty, which I've added to the ML blog
post scanner on the right. My understanding fromJakeis that the intention is
to have a multiauthor blog which is more specialized towards learning
theory/game theory than this one. Nevertheless, several of the posts seem to
be of wider interest.</p><p>3 0.2847437 <a title="225-tfidf-3" href="../hunch_net-2013/hunch_net-2013-07-10-Thoughts_on_Artificial_Intelligence.html">486 hunch net-2013-07-10-Thoughts on Artificial Intelligence</a></p>
<p>Introduction: David McAllesterstarts a blog.</p><p>4 0.2732017 <a title="225-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>Introduction: This is near the one month point, so it seems appropriate to consider meta-
issues for the moment.The number of posts is a bit over 20.The number of
people speaking up in discussions is about 10.The number of people viewing the
site is somewhat more than 100.I am (naturally) dissatisfied with many
things.Many of thepotential useshaven't been realized. This is partly a matter
of opportunity (no conferences in the last month), partly a matter of will (no
open problems because it's hard to give them up), and partly a matter of
tradition. In academia, there is a strong tradition of trying to get
everything perfectly right before presentation. This is somewhat contradictory
to the nature of making many posts, and it's definitely contradictory to the
idea of doing "public research". If that sort of idea is to pay off, it must
be significantly more succesful than previous methods. In an effort to
continue experimenting, I'm going to use the next week as "open problems
week".Spam is a problem.</p><p>5 0.26930878 <a title="225-tfidf-5" href="../hunch_net-2006/hunch_net-2006-10-13-David_Pennock_starts_Oddhead.html">214 hunch net-2006-10-13-David Pennock starts Oddhead</a></p>
<p>Introduction: his blog on information markets and other research topics.</p><p>6 0.25665724 <a title="225-tfidf-6" href="../hunch_net-2005/hunch_net-2005-07-21-Six_Months.html">96 hunch net-2005-07-21-Six Months</a></p>
<p>7 0.25433388 <a title="225-tfidf-7" href="../hunch_net-2006/hunch_net-2006-01-25-1_year.html">151 hunch net-2006-01-25-1 year</a></p>
<p>8 0.18276684 <a title="225-tfidf-8" href="../hunch_net-2008/hunch_net-2008-04-21-The_Science_2.0_article.html">296 hunch net-2008-04-21-The Science 2.0 article</a></p>
<p>9 0.14166504 <a title="225-tfidf-9" href="../hunch_net-2006/hunch_net-2006-06-05-Server_Shift%2C_Site_Tweaks%2C_Suggestions%3F.html">182 hunch net-2006-06-05-Server Shift, Site Tweaks, Suggestions?</a></p>
<p>10 0.13505317 <a title="225-tfidf-10" href="../hunch_net-2005/hunch_net-2005-12-09-Machine_Learning_Thoughts.html">137 hunch net-2005-12-09-Machine Learning Thoughts</a></p>
<p>11 0.12863727 <a title="225-tfidf-11" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>12 0.12095962 <a title="225-tfidf-12" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>13 0.11956158 <a title="225-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>14 0.1191828 <a title="225-tfidf-14" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>15 0.1156809 <a title="225-tfidf-15" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>16 0.10904533 <a title="225-tfidf-16" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>17 0.108624 <a title="225-tfidf-17" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>18 0.10713368 <a title="225-tfidf-18" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>19 0.09953279 <a title="225-tfidf-19" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>20 0.099352479 <a title="225-tfidf-20" href="../hunch_net-2010/hunch_net-2010-04-14-MLcomp%3A_a_website_for_objectively_comparing_ML_algorithms.html">393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.245), (1, 0.11), (2, 0.096), (3, -0.131), (4, 0.106), (5, -0.041), (6, 0.135), (7, -0.513), (8, 0.062), (9, 0.108), (10, 0.031), (11, -0.077), (12, -0.017), (13, -0.041), (14, -0.004), (15, -0.031), (16, -0.022), (17, -0.007), (18, -0.007), (19, 0.033), (20, 0.058), (21, 0.077), (22, 0.014), (23, -0.024), (24, -0.027), (25, 0.067), (26, 0.034), (27, 0.043), (28, 0.017), (29, -0.026), (30, -0.073), (31, 0.005), (32, 0.028), (33, -0.074), (34, -0.019), (35, -0.078), (36, -0.052), (37, 0.018), (38, 0.001), (39, -0.059), (40, 0.075), (41, -0.069), (42, -0.036), (43, 0.008), (44, -0.022), (45, 0.006), (46, -0.02), (47, -0.022), (48, -0.07), (49, 0.003)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97625548 <a title="225-lsi-1" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>Introduction: It's been almost two years since this blog began. In that time, I've learned
enough to shift my expectations in several ways.Initially, the idea was for a
general purpose ML blog where different people could contribute posts. What
has actually happened is most posts come from me, with a few guest posts that
I greatly value. There are a few reasons I see for this.Overload. A couple
years ago, I had not fully appreciated just how busy life gets for a
researcher. Making a post is not simply a matter of getting to it, but rather
of prioritizing between {writing a grant, finishing an overdue review, writing
a paper, teaching a class, writing a program, etcâ&euro;Ś}. This is a substantial
transition away from what life as a graduate student is like. At some point
the question is not "when will I get to it?" but rather "will I get to it?"
and the answer starts to become "no" most of the time.Feedback failure. This
blog currently receives about 3K unique visitors per day from about 13K unique
sites p</p><p>2 0.85190922 <a title="225-lsi-2" href="../hunch_net-2009/hunch_net-2009-12-09-Inherent_Uncertainty.html">383 hunch net-2009-12-09-Inherent Uncertainty</a></p>
<p>Introduction: I'd like to point outInherent Uncertainty, which I've added to the ML blog
post scanner on the right. My understanding fromJakeis that the intention is
to have a multiauthor blog which is more specialized towards learning
theory/game theory than this one. Nevertheless, several of the posts seem to
be of wider interest.</p><p>3 0.75803071 <a title="225-lsi-3" href="../hunch_net-2006/hunch_net-2006-01-25-1_year.html">151 hunch net-2006-01-25-1 year</a></p>
<p>Introduction: At the one year (+5 days) anniversary, the natural question is: "Was it
helpful for research?"Answer: Yes, and so it shall continue.Some evidence is
provided by noticing that I am about a factor of 2 more overloaded with paper
ideas than I've ever previously been. It is always hard to estimate
counterfactual worlds, but I expect that this is also a factor of 2 more than
"What if I had not started the blog?"As for "Why?", there seem to be two
primary effects.A blog is a mechanism for connecting with people who either
think like you or are interested in the same problems. This allows for
concentration of thinking which is very helpful in solving problems.The
process of stating things you don't understand publicly is very helpful in
understanding them. Sometimes you are simply forced to express them in a way
which aids understanding. Sometimes someone else says something which helps.
And sometimes you discover that someone else has already solved the
problem.There are drawbacks which shou</p><p>4 0.74076039 <a title="225-lsi-4" href="../hunch_net-2005/hunch_net-2005-07-21-Six_Months.html">96 hunch net-2005-07-21-Six Months</a></p>
<p>Introduction: This is the6 month pointin the "run a research blog" experiment, so it seems
like a good point to take stock and assess.One fundamental question is: "Is it
worth it?" The idea of running a research blog will never become widely
popular and useful unless it actually aids research. On the negative side,
composing ideas for a post and maintaining a blog takes a significant amount
of time. On the positive side, the process might yield better research because
there is an opportunity for better, faster feedback implying better, faster
thinking.My answer at the moment is a provisional "yes". Running the blog has
been incidentally helpful in several ways:It is sometimes
educational.exampleMore often, the process of composing thoughts well enough
to post simply aids thinking. This has resulted in a couple solutions to
problems ofinterest(and perhaps more over time). If you really want to solve a
problem, letting the world know is helpful. This isn't necessarily because the
world will help you s</p><p>5 0.70164669 <a title="225-lsi-5" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>Introduction: This is near the one month point, so it seems appropriate to consider meta-
issues for the moment.The number of posts is a bit over 20.The number of
people speaking up in discussions is about 10.The number of people viewing the
site is somewhat more than 100.I am (naturally) dissatisfied with many
things.Many of thepotential useshaven't been realized. This is partly a matter
of opportunity (no conferences in the last month), partly a matter of will (no
open problems because it's hard to give them up), and partly a matter of
tradition. In academia, there is a strong tradition of trying to get
everything perfectly right before presentation. This is somewhat contradictory
to the nature of making many posts, and it's definitely contradictory to the
idea of doing "public research". If that sort of idea is to pay off, it must
be significantly more succesful than previous methods. In an effort to
continue experimenting, I'm going to use the next week as "open problems
week".Spam is a problem.</p><p>6 0.65201014 <a title="225-lsi-6" href="../hunch_net-2008/hunch_net-2008-04-21-The_Science_2.0_article.html">296 hunch net-2008-04-21-The Science 2.0 article</a></p>
<p>7 0.64388812 <a title="225-lsi-7" href="../hunch_net-2006/hunch_net-2006-06-05-Server_Shift%2C_Site_Tweaks%2C_Suggestions%3F.html">182 hunch net-2006-06-05-Server Shift, Site Tweaks, Suggestions?</a></p>
<p>8 0.6244396 <a title="225-lsi-8" href="../hunch_net-2006/hunch_net-2006-10-13-David_Pennock_starts_Oddhead.html">214 hunch net-2006-10-13-David Pennock starts Oddhead</a></p>
<p>9 0.56002235 <a title="225-lsi-9" href="../hunch_net-2013/hunch_net-2013-07-10-Thoughts_on_Artificial_Intelligence.html">486 hunch net-2013-07-10-Thoughts on Artificial Intelligence</a></p>
<p>10 0.54452956 <a title="225-lsi-10" href="../hunch_net-2005/hunch_net-2005-12-09-Machine_Learning_Thoughts.html">137 hunch net-2005-12-09-Machine Learning Thoughts</a></p>
<p>11 0.49493924 <a title="225-lsi-11" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>12 0.46124047 <a title="225-lsi-12" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>13 0.4383463 <a title="225-lsi-13" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>14 0.42821664 <a title="225-lsi-14" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>15 0.41107482 <a title="225-lsi-15" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>16 0.40481663 <a title="225-lsi-16" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>17 0.39843374 <a title="225-lsi-17" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>18 0.39075181 <a title="225-lsi-18" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<p>19 0.38804138 <a title="225-lsi-19" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>20 0.38236123 <a title="225-lsi-20" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.029), (13, 0.237), (35, 0.085), (42, 0.263), (45, 0.011), (61, 0.012), (63, 0.032), (68, 0.058), (74, 0.121), (88, 0.026), (95, 0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95118874 <a title="225-lda-1" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>Introduction: Centmailis a scheme which makes charity donations have a secondary value, as a
stamp for email. When discussed onnewscientist,slashdot, and others, some of
the comments make the academic review process appear thoughtful. Some
prominent fallacies are:Costing money fallacy. Some commenters appear to
believe the system charges money per email. Instead, the basic idea is that
users get an extra benefit from donations to a charity and participation is
strictly voluntary. The solution to this fallacy is simply readingthe
details.Single solution fallacy. Some commenters seem to think this is
proposed as a complete solution to spam, and since not everyone will opt to
participate, it won't work. But a complete solution is not at all necessary or
even possible given theflag-day problem. Deployed machine learning systems for
fighting spam are great at taking advantage of a partial solution. The
solution to this fallacy is learning about machine learning. In the current
state of affairs, informed</p><p>2 0.92227226 <a title="225-lda-2" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>Introduction: The New York Times had ashort interviewabout machine learning in datamining
being used pervasively by the IRS and large corporations to predict who to
audit and who to target for various marketing campaigns. This is a big
application area of machine learning. It can be harmful (learning + databases
= another way to invade privacy) or beneficial (as google demonstrates, better
targeting of marketing campaigns is far less annoying). This is yet more
evidence that we can not rely upon "I'm just another fish in the school" logic
for our expectations about treatment by government and large corporations.</p><p>same-blog 3 0.89846116 <a title="225-lda-3" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>Introduction: It's been almost two years since this blog began. In that time, I've learned
enough to shift my expectations in several ways.Initially, the idea was for a
general purpose ML blog where different people could contribute posts. What
has actually happened is most posts come from me, with a few guest posts that
I greatly value. There are a few reasons I see for this.Overload. A couple
years ago, I had not fully appreciated just how busy life gets for a
researcher. Making a post is not simply a matter of getting to it, but rather
of prioritizing between {writing a grant, finishing an overdue review, writing
a paper, teaching a class, writing a program, etcâ&euro;Ś}. This is a substantial
transition away from what life as a graduate student is like. At some point
the question is not "when will I get to it?" but rather "will I get to it?"
and the answer starts to become "no" most of the time.Feedback failure. This
blog currently receives about 3K unique visitors per day from about 13K unique
sites p</p><p>4 0.79934043 <a title="225-lda-4" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>Introduction: "Deep learning" is used to describe learning architectures which have
significant depth (as a circuit).One claimis that shallow architectures (one
or two layers) can not concisely represent some functions while a circuit with
more depth can concisely represent these same functions. Proving lower bounds
on the size of a circuit is substantially harder than upper bounds (which are
constructive), but some results are known.Luca Trevisan'sclass notesdetail how
XOR is not concisely representable by "AC0â&euro;ł (= constant depth unbounded fan-in
AND, OR, NOT gates). This doesn't quite prove that depth is necessary for the
representations commonly used in learning (such as a thresholded weighted
sum), but it is strongly suggestive that this is so.Examples like this are a
bit disheartening because existing algorithms for deep learning (deep belief
nets, gradient descent on deep neural networks, and a perhaps decision trees
depending on who you ask) can't learn XOR very easily. Evidence so far
sugges</p><p>5 0.77406538 <a title="225-lda-5" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>Introduction: Most long conversations between academics seem to converge on the topic of
reviewing where almost no one is happy. A basic question is: Should most
people be happy?The case against is straightforward. Anyone who watches the
flow of papers realizes that most papers amount to little in the longer term.
By it's nature research is brutal, where the second-best method is worthless,
and the second person to discover things typically gets no credit. If you
think about this for a moment, it's very different from most other human
endeavors. The second best migrant laborer, construction worker, manager,
conductor, quarterback, etcâ&euro;Ś all can manage quite well. If a reviewer has even
a vaguely predictive sense of what's important in the longer term, then most
people submitting papers will be unhappy.But this argument unravels, in my
experience. Perhaps half of reviews are thoughtless or simply wrong with a
small part being simply malicious. And yet, I'm sure that most reviewers
genuinely believe th</p><p>6 0.77219003 <a title="225-lda-6" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>7 0.77113527 <a title="225-lda-7" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>8 0.77073693 <a title="225-lda-8" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>9 0.76655227 <a title="225-lda-9" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>10 0.76607841 <a title="225-lda-10" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>11 0.76599646 <a title="225-lda-11" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>12 0.76448417 <a title="225-lda-12" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>13 0.76427031 <a title="225-lda-13" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>14 0.76380271 <a title="225-lda-14" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>15 0.76288682 <a title="225-lda-15" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>16 0.76249307 <a title="225-lda-16" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>17 0.76127195 <a title="225-lda-17" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>18 0.76075417 <a title="225-lda-18" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>19 0.7595076 <a title="225-lda-19" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>20 0.75890923 <a title="225-lda-20" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
