<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-236" href="#">hunch_net-2007-236</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-236-html" href="http://hunch.net/?p=255">html</a></p><p>Introduction: A type of prediction problem is specified by the type of samples produced by a data source (Example:  X x {0,1} ,  X x [0,1] ,  X x {1,2,3,4,5} , etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…).  For simplicity, we’ll assume that all losses have a minimum of zero.
 
For this post, we can think of a learning reduction as
  
 A mapping  R  from samples of one type  T  (like multiclass classification) to another type  T’  (like binary classification). 
 A mapping  Q  from predictors for type  T’  to predictors for type  T . 
  
The simplest sort of learning reduction is a “loss reduction”.  The idea in a loss reduction is to prove a statement of the form: 
 Theorem  For all base predictors  b , for all distributions  D  over examples of type  T : 
  E (x,y) ~ D  L T (y,Q(b,x)) <= f(E (x’,y’)~R(D)  L T’ (y’,b(x’)))   
Here  L T   is the loss for the type  T  problem and  L T’   is the loss for the type  T’  problem.  Also,  R(D)  is the distribution ov</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A type of prediction problem is specified by the type of samples produced by a data source (Example:  X x {0,1} ,  X x [0,1] ,  X x {1,2,3,4,5} , etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…). [sent-1, score-1.23]
</p><p>2 For this post, we can think of a learning reduction as     A mapping  R  from samples of one type  T  (like multiclass classification) to another type  T’  (like binary classification). [sent-3, score-1.341]
</p><p>3 A mapping  Q  from predictors for type  T’  to predictors for type  T . [sent-4, score-1.569]
</p><p>4 The simplest sort of learning reduction is a “loss reduction”. [sent-5, score-0.162]
</p><p>5 Also,  R(D)  is the distribution over samples induced by first drawing from  D  and then mapping the sample via  R . [sent-7, score-0.644]
</p><p>6 The function  f()  is the loss transform function—we try to find reductions  R,Q  which minimize it’s value. [sent-8, score-0.803]
</p><p>7 If  R,Q  are deterministic, then there always exists a choice of  D,b  such that the loss rate on the right hand side is 0. [sent-9, score-0.278]
</p><p>8 However, it’s common to encounter real-world learning problems  D  which are inherently noisy, implying that the induced problem  D’  is often inherently noisy. [sent-10, score-0.342]
</p><p>9 Distinguishing between errors due to environmental noise and errors due to base predictor mistakes seems important (and experimentally, it has been). [sent-11, score-0.568]
</p><p>10 The skeletons of the theory for these families of reductions have been layed out at this point. [sent-14, score-0.474]
</p><p>11 This hope is pretty reasonable—empirically, we have observed a consistent step up in performance going from loss transform to regret transform reductions. [sent-17, score-0.867]
</p><p>12 The fact that the minimum is taken over  all  predictors in regret transforms is counterintuitive to some people, who are used to “Empirical Risk Minimization” statements where a minimum is taken over a limited set of predictors. [sent-19, score-0.993]
</p><p>13 Essentially, we limit ourselves to reductions with the property that they are reversible. [sent-24, score-0.353]
</p><p>14 Reversibility can be tested by mapping from one problem to another, and then back. [sent-25, score-0.245]
</p><p>15 There are a several variant theorem statements we could imagine. [sent-26, score-0.36]
</p><p>16 We would like it to be the case that Bayes Law and reductions compose. [sent-29, score-0.292]
</p><p>17 A theorem statement of the following form might be about right. [sent-30, score-0.43]
</p><p>18 Also,  R(P)  is the prior induced by mapping  D  to  R(D)  after drawing from  P . [sent-32, score-0.528]
</p><p>19 The two missing components for these kinds of reductions are:     Theoretical evidence that we can satisfy these definitions of reduction between interesting types of learning problems. [sent-33, score-0.454]
</p><p>20 My experience is that analyzing reductions has yielded significant insight into how to solve learning problems, so I would encourage anyone with a bit of theoretical inclination in Machine Learning to consider the above (or other) families of reductions. [sent-35, score-0.519]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('type', 0.42), ('reductions', 0.292), ('predictors', 0.268), ('transform', 0.245), ('base', 0.232), ('loss', 0.211), ('theorem', 0.208), ('mapping', 0.193), ('induced', 0.186), ('regret', 0.166), ('reduction', 0.162), ('distributions', 0.15), ('drawing', 0.149), ('min', 0.14), ('families', 0.134), ('bayes', 0.132), ('statement', 0.102), ('transforms', 0.096), ('statements', 0.087), ('minimum', 0.087), ('binary', 0.074), ('samples', 0.072), ('exists', 0.067), ('errors', 0.067), ('idea', 0.066), ('variant', 0.065), ('losses', 0.065), ('law', 0.062), ('limit', 0.061), ('form', 0.06), ('following', 0.06), ('classification', 0.059), ('noise', 0.058), ('function', 0.055), ('problem', 0.052), ('inherently', 0.052), ('taken', 0.052), ('limited', 0.05), ('counterintuitive', 0.048), ('layed', 0.048), ('yielded', 0.048), ('osindero', 0.048), ('simon', 0.048), ('environmental', 0.048), ('due', 0.048), ('empirical', 0.046), ('experimentally', 0.045), ('inclination', 0.045), ('modifications', 0.045), ('sample', 0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="236-tfidf-1" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a data source (Example:  X x {0,1} ,  X x [0,1] ,  X x {1,2,3,4,5} , etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…).  For simplicity, we’ll assume that all losses have a minimum of zero.
 
For this post, we can think of a learning reduction as
  
 A mapping  R  from samples of one type  T  (like multiclass classification) to another type  T’  (like binary classification). 
 A mapping  Q  from predictors for type  T’  to predictors for type  T . 
  
The simplest sort of learning reduction is a “loss reduction”.  The idea in a loss reduction is to prove a statement of the form: 
 Theorem  For all base predictors  b , for all distributions  D  over examples of type  T : 
  E (x,y) ~ D  L T (y,Q(b,x)) <= f(E (x’,y’)~R(D)  L T’ (y’,b(x’)))   
Here  L T   is the loss for the type  T  problem and  L T’   is the loss for the type  T’  problem.  Also,  R(D)  is the distribution ov</p><p>2 0.43694499 <a title="236-tfidf-2" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductions  transform a solver of one type of learning problem into a solver of another type of learning problem.  When we analyze these for robustness we can make statement of the form “Reduction  R  has the property that regret  r  (or loss) on subproblems of type  A  implies regret at most   f ( r )  on the original problem of type  B “.
 
A lower bound for a learning reduction would have the form “for all reductions  R , there exists a learning problem of type  B  and learning algorithm for problems of type  A  where regret  r  on induced problems implies  at least  regret  f ( r )  for  B “.
 
The pursuit of lower bounds is often questionable because, unlike upper bounds, they do not yield practical algorithms.  Nevertheless, they may be helpful as a tool for thinking about what is learnable and how learnable it is.  This has already come up  here  and  here .
 
At the moment, there is no coherent theory of lower bounds for learning reductions, and we have little understa</p><p>3 0.30574203 <a title="236-tfidf-3" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>Introduction: This post is about an open problem in learning reductions.
 
 Background  A reduction might transform a a multiclass prediction problem where there are  k  possible labels into a binary learning problem where there are only 2 possible labels.   On this induced binary problem we might learn a binary classifier with some error rate  e .  After subtracting the minimum possible (Bayes) error rate  b , we get a regret  r = e – b .  The  PECOC (Probabilistic Error Correcting Output Code) reduction has the property that binary regret  r  implies multiclass regret at most  4r 0.5  .
 
 The problem  This is not the “rightest” answer.  Consider the  k=2  case, where we reduce binary to binary.  There exists a reduction (the identity) with the property that regret  r  implies regret  r .  This is substantially superior to the transform given by the PECOC reduction, which suggests that a better reduction may exist for general  k .  For example, we can not rule out the possibility that a reduction</p><p>4 0.26801041 <a title="236-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?  Reductions are machines which turn solvers for one problem into solvers for another problem. 
 Why?  Reductions are useful for several reasons.
  
  Laziness .  Reducing a problem to classification make at least 10 learning algorithms available to solve a problem.  Inventing 10 learning algorithms is quite a bit of work.  Similarly, programming a reduction is often trivial, while programming a learning algorithm is a great deal of work. 
  Crystallization .  The problems we often want to solve in learning are worst-case-impossible, but average case feasible.  By reducing all problems onto one or a few primitives, we can fine tune these primitives to perform well on real-world problems with greater precision due to the greater number of problems to validate on. 
  Theoretical Organization .  By studying what reductions are easy vs. hard vs. impossible, we can learn which problems are roughly equivalent in difficulty and which are much harder. 
  
 What we know now .
 
 Typesafe r</p><p>5 0.23931739 <a title="236-tfidf-5" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>Introduction: This post is some combination of belaboring the obvious and speculating wildly about the future. The basic issue to be addressed is how to think about machine learning in terms given to us from Programming Language theory.
  Types and Reductions  
John’s research programme (I feel this should be in British spelling to reflect the grandiousness of the idea…) of machine learning reductions  StateOfReduction  is at some essential level type-theoretic in nature.  The fundamental elements are the classifier, a function f: alpha -> beta, and the corresponding classifier trainer g: List of (alpha,beta) -> (alpha -> beta). The research goal is to create *combinators* that produce new f’s and g’s given existing ones. John (probably quite rightly) seems unwilling at the moment to commit to any notion stronger than these combinators are correctly typed.  One way to see the result of a reduction is something typed like: (For those denied the joy of the Hindly-Milner type system, “simple” is probab</p><p>6 0.22160807 <a title="236-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>7 0.21577363 <a title="236-tfidf-7" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>8 0.20180236 <a title="236-tfidf-8" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>9 0.19682983 <a title="236-tfidf-9" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>10 0.18430567 <a title="236-tfidf-10" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>11 0.17987184 <a title="236-tfidf-11" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>12 0.17495666 <a title="236-tfidf-12" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>13 0.17052461 <a title="236-tfidf-13" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>14 0.16365212 <a title="236-tfidf-14" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>15 0.1488315 <a title="236-tfidf-15" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>16 0.13635972 <a title="236-tfidf-16" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>17 0.132715 <a title="236-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>18 0.13153504 <a title="236-tfidf-18" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>19 0.13041152 <a title="236-tfidf-19" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>20 0.12891282 <a title="236-tfidf-20" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.23), (1, 0.239), (2, 0.151), (3, -0.179), (4, -0.198), (5, 0.01), (6, 0.197), (7, -0.05), (8, -0.111), (9, -0.041), (10, -0.051), (11, -0.117), (12, -0.02), (13, 0.03), (14, 0.032), (15, 0.002), (16, 0.099), (17, -0.028), (18, 0.0), (19, -0.116), (20, 0.028), (21, -0.096), (22, -0.041), (23, -0.167), (24, -0.013), (25, -0.029), (26, -0.017), (27, 0.029), (28, 0.083), (29, 0.071), (30, 0.1), (31, -0.014), (32, -0.057), (33, 0.04), (34, -0.014), (35, -0.151), (36, -0.176), (37, 0.045), (38, -0.037), (39, 0.002), (40, -0.006), (41, 0.098), (42, 0.028), (43, -0.069), (44, -0.082), (45, 0.024), (46, -0.012), (47, 0.102), (48, -0.024), (49, 0.042)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98292619 <a title="236-lsi-1" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a data source (Example:  X x {0,1} ,  X x [0,1] ,  X x {1,2,3,4,5} , etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…).  For simplicity, we’ll assume that all losses have a minimum of zero.
 
For this post, we can think of a learning reduction as
  
 A mapping  R  from samples of one type  T  (like multiclass classification) to another type  T’  (like binary classification). 
 A mapping  Q  from predictors for type  T’  to predictors for type  T . 
  
The simplest sort of learning reduction is a “loss reduction”.  The idea in a loss reduction is to prove a statement of the form: 
 Theorem  For all base predictors  b , for all distributions  D  over examples of type  T : 
  E (x,y) ~ D  L T (y,Q(b,x)) <= f(E (x’,y’)~R(D)  L T’ (y’,b(x’)))   
Here  L T   is the loss for the type  T  problem and  L T’   is the loss for the type  T’  problem.  Also,  R(D)  is the distribution ov</p><p>2 0.85643387 <a title="236-lsi-2" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductions  transform a solver of one type of learning problem into a solver of another type of learning problem.  When we analyze these for robustness we can make statement of the form “Reduction  R  has the property that regret  r  (or loss) on subproblems of type  A  implies regret at most   f ( r )  on the original problem of type  B “.
 
A lower bound for a learning reduction would have the form “for all reductions  R , there exists a learning problem of type  B  and learning algorithm for problems of type  A  where regret  r  on induced problems implies  at least  regret  f ( r )  for  B “.
 
The pursuit of lower bounds is often questionable because, unlike upper bounds, they do not yield practical algorithms.  Nevertheless, they may be helpful as a tool for thinking about what is learnable and how learnable it is.  This has already come up  here  and  here .
 
At the moment, there is no coherent theory of lower bounds for learning reductions, and we have little understa</p><p>3 0.66543853 <a title="236-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>Introduction: This post is some combination of belaboring the obvious and speculating wildly about the future. The basic issue to be addressed is how to think about machine learning in terms given to us from Programming Language theory.
  Types and Reductions  
John’s research programme (I feel this should be in British spelling to reflect the grandiousness of the idea…) of machine learning reductions  StateOfReduction  is at some essential level type-theoretic in nature.  The fundamental elements are the classifier, a function f: alpha -> beta, and the corresponding classifier trainer g: List of (alpha,beta) -> (alpha -> beta). The research goal is to create *combinators* that produce new f’s and g’s given existing ones. John (probably quite rightly) seems unwilling at the moment to commit to any notion stronger than these combinators are correctly typed.  One way to see the result of a reduction is something typed like: (For those denied the joy of the Hindly-Milner type system, “simple” is probab</p><p>4 0.65827906 <a title="236-lsi-4" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>Introduction: This post is about an open problem in learning reductions.
 
 Background  A reduction might transform a a multiclass prediction problem where there are  k  possible labels into a binary learning problem where there are only 2 possible labels.   On this induced binary problem we might learn a binary classifier with some error rate  e .  After subtracting the minimum possible (Bayes) error rate  b , we get a regret  r = e – b .  The  PECOC (Probabilistic Error Correcting Output Code) reduction has the property that binary regret  r  implies multiclass regret at most  4r 0.5  .
 
 The problem  This is not the “rightest” answer.  Consider the  k=2  case, where we reduce binary to binary.  There exists a reduction (the identity) with the property that regret  r  implies regret  r .  This is substantially superior to the transform given by the PECOC reduction, which suggests that a better reduction may exist for general  k .  For example, we can not rule out the possibility that a reduction</p><p>5 0.63939279 <a title="236-lsi-5" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>Introduction: I’m offering a reward of $1000 for a solution to this problem.  This joins the  cross validation problem  which I’m offering a  $500 reward  for.  I believe both of these problems are hard but plausibly solvable, and plausibly with a solution of substantial practical value.  While it’s unlikely these rewards are worth your time on an hourly wage basis, the recognition for solving them definitely should be   
  The Problem  
The problem is finding a general, robust, and efficient mechanism for estimating a conditional probability  P(y|x)  where robustness and efficiency are measured using techniques from learning reductions. 
 
In particular, suppose we have access to a binary regression oracle  B  which has two interfaces—one for specifying training information and one for testing. Training information is specified as  B(x’,y’)  where  x’  is a feature vector and  y’  is a scalar in  [0,1]  with no value returned.  Testing is done according to  B(x’)  with a value in  [0,1]  returned.</p><p>6 0.63776207 <a title="236-lsi-6" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>7 0.62440503 <a title="236-lsi-7" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>8 0.54233271 <a title="236-lsi-8" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>9 0.51580757 <a title="236-lsi-9" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>10 0.51106411 <a title="236-lsi-10" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>11 0.46755531 <a title="236-lsi-11" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>12 0.46629095 <a title="236-lsi-12" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>13 0.46013463 <a title="236-lsi-13" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>14 0.4550814 <a title="236-lsi-14" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>15 0.45301351 <a title="236-lsi-15" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>16 0.44684833 <a title="236-lsi-16" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>17 0.44058239 <a title="236-lsi-17" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>18 0.43922454 <a title="236-lsi-18" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>19 0.43567586 <a title="236-lsi-19" href="../hunch_net-2012/hunch_net-2012-09-29-Vowpal_Wabbit%2C_version_7.0.html">473 hunch net-2012-09-29-Vowpal Wabbit, version 7.0</a></p>
<p>20 0.42634669 <a title="236-lsi-20" href="../hunch_net-2006/hunch_net-2006-09-09-How_to_solve_an_NP_hard_problem_in_quadratic_time.html">206 hunch net-2006-09-09-How to solve an NP hard problem in quadratic time</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.018), (3, 0.052), (17, 0.082), (27, 0.245), (38, 0.269), (53, 0.078), (55, 0.047), (77, 0.033), (94, 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96676135 <a title="236-lda-1" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a data source (Example:  X x {0,1} ,  X x [0,1] ,  X x {1,2,3,4,5} , etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…).  For simplicity, we’ll assume that all losses have a minimum of zero.
 
For this post, we can think of a learning reduction as
  
 A mapping  R  from samples of one type  T  (like multiclass classification) to another type  T’  (like binary classification). 
 A mapping  Q  from predictors for type  T’  to predictors for type  T . 
  
The simplest sort of learning reduction is a “loss reduction”.  The idea in a loss reduction is to prove a statement of the form: 
 Theorem  For all base predictors  b , for all distributions  D  over examples of type  T : 
  E (x,y) ~ D  L T (y,Q(b,x)) <= f(E (x’,y’)~R(D)  L T’ (y’,b(x’)))   
Here  L T   is the loss for the type  T  problem and  L T’   is the loss for the type  T’  problem.  Also,  R(D)  is the distribution ov</p><p>2 0.95193893 <a title="236-lda-2" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductions  transform a solver of one type of learning problem into a solver of another type of learning problem.  When we analyze these for robustness we can make statement of the form “Reduction  R  has the property that regret  r  (or loss) on subproblems of type  A  implies regret at most   f ( r )  on the original problem of type  B “.
 
A lower bound for a learning reduction would have the form “for all reductions  R , there exists a learning problem of type  B  and learning algorithm for problems of type  A  where regret  r  on induced problems implies  at least  regret  f ( r )  for  B “.
 
The pursuit of lower bounds is often questionable because, unlike upper bounds, they do not yield practical algorithms.  Nevertheless, they may be helpful as a tool for thinking about what is learnable and how learnable it is.  This has already come up  here  and  here .
 
At the moment, there is no coherent theory of lower bounds for learning reductions, and we have little understa</p><p>3 0.95070213 <a title="236-lda-3" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>Introduction: This post is about an open problem in learning reductions.
 
 Background  A reduction might transform a a multiclass prediction problem where there are  k  possible labels into a binary learning problem where there are only 2 possible labels.   On this induced binary problem we might learn a binary classifier with some error rate  e .  After subtracting the minimum possible (Bayes) error rate  b , we get a regret  r = e – b .  The  PECOC (Probabilistic Error Correcting Output Code) reduction has the property that binary regret  r  implies multiclass regret at most  4r 0.5  .
 
 The problem  This is not the “rightest” answer.  Consider the  k=2  case, where we reduce binary to binary.  There exists a reduction (the identity) with the property that regret  r  implies regret  r .  This is substantially superior to the transform given by the PECOC reduction, which suggests that a better reduction may exist for general  k .  For example, we can not rule out the possibility that a reduction</p><p>4 0.94942826 <a title="236-lda-4" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>Introduction: Normally I do not blog, but John kindly invited me to do so.  Since computability issues play a major role in Artificial Intelligence and Machine Learning, I would like to take the opportunity to comment on that and raise some questions.
 
The general attitude is that AI is about finding efficient smart algorithms. For large parts of machine learning, the same attitude is not too dangerous. If you want to concentrate on conceptual problems, simply become a statistician. There is no analogous escape for modern research on AI (as opposed to  GOFAI  rooted in logic).

 
Let me show by analogy why  limiting research to computational questions is bad for any field. 
 
Except in computer science, computational aspects play little role in the development of  fundamental  theories: Consider e.g. set theory with axiom of choice, foundations of logic, exact/full minimax for zero-sum games, quantum (field) theory, string theory, … Indeed, at least in physics, every new fundamental theory seems to</p><p>5 0.94496632 <a title="236-lda-5" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>Introduction: Nati Srebro  and  Shai Ben-David  have a  paper  at  COLT  which, in the appendix, proves something very striking: several previous error bounds are  always  greater than 1.
 
 Background  One branch of learning theory focuses on theorems which
  
 Assume samples are drawn IID from an unknown distribution  D . 
 Fix a set of classifiers 
 Find a high probability bound on the maximum true error rate (with respect to  D ) as a function of the empirical error rate on the training set.
 
  
Many of these bounds become extremely complex and hairy.

 
 Current  Everyone working on this subject wants “tighter bounds”, however there are different definitions of “tighter”.  Some groups focus on “functional tightness” (getting the right functional dependency between the size of the training set and a parameterization of the hypothesis space) while  others  focus on “practical tightness” (finding bounds which work well on practical problems).  (I am definitely in the second camp.)
 
One of the da</p><p>6 0.93741667 <a title="236-lda-6" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>7 0.9196533 <a title="236-lda-7" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>8 0.90603364 <a title="236-lda-8" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>9 0.89064574 <a title="236-lda-9" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>10 0.84545141 <a title="236-lda-10" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>11 0.838166 <a title="236-lda-11" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>12 0.83666694 <a title="236-lda-12" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>13 0.83521175 <a title="236-lda-13" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>14 0.82950783 <a title="236-lda-14" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>15 0.82672411 <a title="236-lda-15" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>16 0.82536006 <a title="236-lda-16" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>17 0.82413393 <a title="236-lda-17" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>18 0.81507337 <a title="236-lda-18" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>19 0.81049407 <a title="236-lda-19" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>20 0.80732059 <a title="236-lda-20" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
