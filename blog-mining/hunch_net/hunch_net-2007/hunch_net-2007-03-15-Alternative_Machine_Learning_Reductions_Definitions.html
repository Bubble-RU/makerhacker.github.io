<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-236" href="#">hunch_net-2007-236</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-236-html" href="http://hunch.net/?p=255">html</a></p><p>Introduction: A type of prediction problem is specified by the type of samples produced by a
data source (Example:X x {0,1},X x [0,1],X x {1,2,3,4,5}, etc…) and a loss
function (0/1 loss, squared error loss, cost sensitive losses, etc…). For
simplicity, we'll assume that all losses have a minimum of zero.For this post,
we can think of a learning reduction asA mappingRfrom samples of one
typeT(like multiclass classification) to another typeT'(like binary
classification).A mappingQfrom predictors for typeT'to predictors for
typeT.The simplest sort of learning reduction is a "loss reduction". The idea
in a loss reduction is to prove a statement of the form:TheoremFor all base
predictorsb, for all distributionsDover examples of typeT:E(x,y) ~
DLT(y,Q(b,x)) <= f(E(x',y')~R(D)LT'(y',b(x')))HereLTis the loss for the
typeTproblem andLT'is the loss for the typeT'problem. Also,R(D)is the
distribution over samples induced by first drawing fromDand then mapping the
sample viaR. The functionf()is the loss transf</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A type of prediction problem is specified by the type of samples produced by a data source (Example:X x {0,1},X x [0,1],X x {1,2,3,4,5}, etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…). [sent-1, score-0.39]
</p><p>2 For simplicity, we'll assume that all losses have a minimum of zero. [sent-2, score-0.145]
</p><p>3 For this post, we can think of a learning reduction asA mappingRfrom samples of one typeT(like multiclass classification) to another typeT'(like binary classification). [sent-3, score-0.281]
</p><p>4 The simplest sort of learning reduction is a "loss reduction". [sent-5, score-0.14]
</p><p>5 The idea in a loss reduction is to prove a statement of the form:TheoremFor all base predictorsb, for all distributionsDover examples of typeT:E(x,y) ~ DLT(y,Q(b,x)) <= f(E(x',y')~R(D)LT'(y',b(x')))HereLTis the loss for the typeTproblem andLT'is the loss for the typeT'problem. [sent-6, score-1.133]
</p><p>6 Also,R(D)is the distribution over samples induced by first drawing fromDand then mapping the sample viaR. [sent-7, score-0.52]
</p><p>7 The functionf()is the loss transform function--we try to find reductionsR,Qwhich minimize it's value. [sent-8, score-0.444]
</p><p>8 IfR,Qare deterministic, then there always exists a choice ofD,bsuch that the loss rate on the right hand side is 0. [sent-9, score-0.204]
</p><p>9 However, it's common to encounter real-world learning problemsDwhich are inherently noisy, implying that the induced problemD'is often inherently noisy. [sent-10, score-0.284]
</p><p>10 Distinguishing between errors due to environmental noise and errors due to base predictor mistakes seems important (and experimentally, it has been). [sent-11, score-0.546]
</p><p>11 The skeletons of the theory for these families of reductions have been layed out at this point. [sent-14, score-0.383]
</p><p>12 There remain some open problems, but another interesting direction to consider is other families of reductions. [sent-15, score-0.127]
</p><p>13 This hope is pretty reasonable--empirically, we have observed a consistent step up in performance going from loss transform to regret transform reductions. [sent-17, score-0.843]
</p><p>14 The fact that the minimum is taken overallpredictors in regret transforms is counterintuitive to some people, who are used to "Empirical Risk Minimization" statements where a minimum is taken over a limited set of predictors. [sent-19, score-0.599]
</p><p>15 Essentially, we limit ourselves to reductions with the property that they are reversible. [sent-24, score-0.269]
</p><p>16 There are a several variant theorem statements we could imagine. [sent-26, score-0.213]
</p><p>17 We would like it to be the case that Bayes Law and reductions compose. [sent-29, score-0.21]
</p><p>18 A theorem statement of the following form might be about right. [sent-30, score-0.281]
</p><p>19 The two missing components for these kinds of reductions are:Theoretical evidence that we can satisfy these definitions of reduction between interesting types of learning problems. [sent-33, score-0.35]
</p><p>20 My experience is that analyzing reductions has yielded significant insight into how to solve learning problems, so I would encourage anyone with a bit of theoretical inclination in Machine Learning to consider the above (or other) families of reductions. [sent-35, score-0.337]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lt', 0.361), ('dlt', 0.31), ('typet', 0.31), ('predictorsb', 0.258), ('transform', 0.24), ('base', 0.221), ('reductions', 0.21), ('loss', 0.204), ('induced', 0.184), ('regret', 0.159), ('theoremfor', 0.155), ('drawing', 0.142), ('reduction', 0.14), ('distributionsdover', 0.138), ('bayes', 0.128), ('families', 0.127), ('minb', 0.103), ('theoremthere', 0.103), ('statement', 0.098), ('statements', 0.084), ('minimum', 0.083), ('mapping', 0.08), ('predictors', 0.078), ('binary', 0.071), ('samples', 0.07), ('theorem', 0.067), ('errors', 0.063), ('idea', 0.062), ('variant', 0.062), ('losses', 0.062), ('law', 0.059), ('limit', 0.059), ('classification', 0.059), ('form', 0.059), ('type', 0.058), ('noise', 0.057), ('following', 0.057), ('inherently', 0.05), ('taken', 0.049), ('due', 0.048), ('counterintuitive', 0.046), ('layed', 0.046), ('priorp', 0.046), ('environmental', 0.046), ('asa', 0.046), ('fromd', 0.046), ('fromdand', 0.046), ('problemsd', 0.046), ('transforms', 0.046), ('sample', 0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="236-tfidf-1" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a
data source (Example:X x {0,1},X x [0,1],X x {1,2,3,4,5}, etc…) and a loss
function (0/1 loss, squared error loss, cost sensitive losses, etc…). For
simplicity, we'll assume that all losses have a minimum of zero.For this post,
we can think of a learning reduction asA mappingRfrom samples of one
typeT(like multiclass classification) to another typeT'(like binary
classification).A mappingQfrom predictors for typeT'to predictors for
typeT.The simplest sort of learning reduction is a "loss reduction". The idea
in a loss reduction is to prove a statement of the form:TheoremFor all base
predictorsb, for all distributionsDover examples of typeT:E(x,y) ~
DLT(y,Q(b,x)) <= f(E(x',y')~R(D)LT'(y',b(x')))HereLTis the loss for the
typeTproblem andLT'is the loss for the typeT'problem. Also,R(D)is the
distribution over samples induced by first drawing fromDand then mapping the
sample viaR. The functionf()is the loss transf</p><p>2 0.27154276 <a title="236-tfidf-2" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>Introduction: This post is about an open problem in learning reductions.BackgroundA
reduction might transform a a multiclass prediction problem where there
arekpossible labels into a binary learning problem where there are only 2
possible labels. On this induced binary problem we might learn a binary
classifier with some error ratee. After subtracting the minimum possible
(Bayes) error rateb, we get a regretr = e - b. ThePECOC(Probabilistic Error
Correcting Output Code) reduction has the property that binary regretrimplies
multiclass regret at most4r0.5.The problemThis is not the "rightest" answer.
Consider thek=2case, where we reduce binary to binary. There exists a
reduction (the identity) with the property that regretrimplies regretr. This
is substantially superior to the transform given by the PECOC reduction, which
suggests that a better reduction may exist for generalk. For example, we can
not rule out the possibility that a reductionRexists with regret transform
guaranteeing binary regretrimp</p><p>3 0.19263773 <a title="236-tfidf-3" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss:
A loss function which is much easier to optimize computationally than the loss
function imposed by the world. A canonical example is when we want to learn a
weight vectorwand predict according to a dot productfw(x)= sumiwixiwhere
optimizing squared loss(y-fw(x))2over many samples is much more tractable than
optimizing 0-1 lossI(y = Threshold(fw(x) - 0.5)).While the computational
advantages of optimizing a proxy loss are substantial, we are curious: which
proxy loss is best? The answer of course depends on what the real loss imposed
by the world is. For 0-1 loss classification, there are adherents to many
choices:Log loss. If we confine the prediction to[0,1], we can treat it as a
predicted probability that the label is1, and measure loss according tolog
1/p'(y|x)wherep'(y|x)is the predicted probability of the observed label. A
standard method for confining the prediction to[0,1]islogistic regressionwhich
expo</p><p>4 0.18875664 <a title="236-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?Reductions are machines which turn solvers for one problem into solvers
for another problem.Why?Reductions are useful for several reasons.Laziness.
Reducing a problem to classification make at least 10 learning algorithms
available to solve a problem. Inventing 10 learning algorithms is quite a bit
of work. Similarly, programming a reduction is often trivial, while
programming a learning algorithm is a great deal of work.Crystallization. The
problems we often want to solve in learning are worst-case-impossible, but
average case feasible. By reducing all problems onto one or a few primitives,
we can fine tune these primitives to perform well on real-world problems with
greater precision due to the greater number of problems to validate
on.Theoretical Organization. By studying what reductions are easy vs. hard vs.
impossible, we can learn which problems are roughly equivalent in difficulty
and which are much harder.What we know now.Typesafe reductions. In the
beginning, there was th</p><p>5 0.18842171 <a title="236-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>6 0.17764722 <a title="236-tfidf-6" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>7 0.17166528 <a title="236-tfidf-7" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>8 0.16356142 <a title="236-tfidf-8" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>9 0.15234566 <a title="236-tfidf-9" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>10 0.14830264 <a title="236-tfidf-10" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>11 0.14808419 <a title="236-tfidf-11" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>12 0.14157151 <a title="236-tfidf-12" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>13 0.13339615 <a title="236-tfidf-13" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>14 0.12127868 <a title="236-tfidf-14" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>15 0.11961338 <a title="236-tfidf-15" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>16 0.11879171 <a title="236-tfidf-16" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>17 0.11540791 <a title="236-tfidf-17" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>18 0.1117682 <a title="236-tfidf-18" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>19 0.11098853 <a title="236-tfidf-19" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>20 0.10948481 <a title="236-tfidf-20" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.186), (1, -0.195), (2, -0.143), (3, 0.103), (4, 0.182), (5, -0.156), (6, 0.062), (7, 0.028), (8, 0.063), (9, 0.079), (10, 0.08), (11, 0.019), (12, 0.074), (13, 0.033), (14, 0.019), (15, -0.014), (16, 0.006), (17, -0.073), (18, -0.017), (19, -0.011), (20, 0.004), (21, -0.071), (22, 0.058), (23, 0.003), (24, -0.025), (25, -0.019), (26, 0.011), (27, 0.081), (28, 0.002), (29, -0.045), (30, 0.049), (31, -0.037), (32, 0.06), (33, 0.094), (34, 0.017), (35, -0.064), (36, 0.055), (37, 0.048), (38, -0.015), (39, 0.047), (40, 0.04), (41, 0.062), (42, -0.063), (43, -0.024), (44, 0.036), (45, 0.009), (46, 0.017), (47, -0.014), (48, 0.01), (49, -0.026)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96955198 <a title="236-lsi-1" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a
data source (Example:X x {0,1},X x [0,1],X x {1,2,3,4,5}, etc…) and a loss
function (0/1 loss, squared error loss, cost sensitive losses, etc…). For
simplicity, we'll assume that all losses have a minimum of zero.For this post,
we can think of a learning reduction asA mappingRfrom samples of one
typeT(like multiclass classification) to another typeT'(like binary
classification).A mappingQfrom predictors for typeT'to predictors for
typeT.The simplest sort of learning reduction is a "loss reduction". The idea
in a loss reduction is to prove a statement of the form:TheoremFor all base
predictorsb, for all distributionsDover examples of typeT:E(x,y) ~
DLT(y,Q(b,x)) <= f(E(x',y')~R(D)LT'(y',b(x')))HereLTis the loss for the
typeTproblem andLT'is the loss for the typeT'problem. Also,R(D)is the
distribution over samples induced by first drawing fromDand then mapping the
sample viaR. The functionf()is the loss transf</p><p>2 0.76701289 <a title="236-lsi-2" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>Introduction: This post is about an open problem in learning reductions.BackgroundA
reduction might transform a a multiclass prediction problem where there
arekpossible labels into a binary learning problem where there are only 2
possible labels. On this induced binary problem we might learn a binary
classifier with some error ratee. After subtracting the minimum possible
(Bayes) error rateb, we get a regretr = e - b. ThePECOC(Probabilistic Error
Correcting Output Code) reduction has the property that binary regretrimplies
multiclass regret at most4r0.5.The problemThis is not the "rightest" answer.
Consider thek=2case, where we reduce binary to binary. There exists a
reduction (the identity) with the property that regretrimplies regretr. This
is substantially superior to the transform given by the PECOC reduction, which
suggests that a better reduction may exist for generalk. For example, we can
not rule out the possibility that a reductionRexists with regret transform
guaranteeing binary regretrimp</p><p>3 0.70829201 <a title="236-lsi-3" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>Introduction: Forlearning reductionswe have been concentrating on reducing various complex
learning problems to binary classification. This choice needs to be actively
questioned, because it was not carefully considered.Binary clasification is
learning a classifierc:X -> {0,1}so as to minimize the probability of being
wrong,Prx,y~D(c(x)y).The primary alternative candidate seems to be squared
error regression. In squared error regression, you learn a regressors:X ->
[0,1]so as to minimize squared error,Ex,y~D(s(x)-y)2.It is difficult to judge
one primitive against another. The judgement must at least partially be made
on nontheoretical grounds because (essentially) we are evaluating a choice
between two axioms/assumptions.These two primitives are significantly related.
Classification can be reduced to regression in the obvious way: you use the
regressor to predictD(y=1|x), then threshold at0.5. For this simple reduction
a squared error regret ofrimplies a classification regret of at mostr0.5.
Regress</p><p>4 0.69903851 <a title="236-lsi-4" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>Introduction: I'm offering a reward of $1000 for a solution to this problem. This joins
thecross validation problemwhich I'm offering a$500 rewardfor. I believe both
of these problems are hard but plausibly solvable, and plausibly with a
solution of substantial practical value. While it's unlikely these rewards are
worth your time on an hourly wage basis, the recognition for solving them
definitely should beThe ProblemThe problem is finding a general, robust, and
efficient mechanism for estimating a conditional probabilityP(y|x)where
robustness and efficiency are measured using techniques from learning
reductions.In particular, suppose we have access to a binary regression
oracleBwhich has two interfaces--one for specifying training information and
one for testing. Training information is specified asB(x',y')wherex'is a
feature vector andy'is a scalar in[0,1]with no value returned. Testing is done
according toB(x')with a value in[0,1]returned.A learning reduction consists of
two algorithmsRandR-1whi</p><p>5 0.6983273 <a title="236-lsi-5" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to
handle several large family loss functions.This is a good thing because it is
implausible that thelossfunction imposed by the world can not be taken into
account in the process of solving a prediction problem. Even people used to
the hard-coreBayesianapproach to learning often note that some approximations
are almost inevitable in specifying apriorand/or integrating to achieve a
posterior. Taking into account how the system will be evaluated can allow both
computational effort and design effort to be focused so as to improve
performance.A current laundry list of capabilities includes:2002multiclass SVM
including arbitrary cost matricesICML 2003Hidden Markov ModelsNIPS 2003Markov
Networks(see somediscussion)EMNLP 2004Context free grammarsICML 2004Any loss
(with much computation)ICML 2005Anyconstrained linear prediction model(that's
my own name).ICML 2005Any loss dependent on a contingency tableI am personally
in</p><p>6 0.69375223 <a title="236-lsi-6" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>7 0.67822152 <a title="236-lsi-7" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>8 0.63196313 <a title="236-lsi-8" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>9 0.62523621 <a title="236-lsi-9" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>10 0.60632151 <a title="236-lsi-10" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>11 0.58857477 <a title="236-lsi-11" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>12 0.58545494 <a title="236-lsi-12" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>13 0.55910259 <a title="236-lsi-13" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>14 0.55393142 <a title="236-lsi-14" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>15 0.54801339 <a title="236-lsi-15" href="../hunch_net-2006/hunch_net-2006-09-09-How_to_solve_an_NP_hard_problem_in_quadratic_time.html">206 hunch net-2006-09-09-How to solve an NP hard problem in quadratic time</a></p>
<p>16 0.54564464 <a title="236-lsi-16" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>17 0.50897563 <a title="236-lsi-17" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>18 0.5088532 <a title="236-lsi-18" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>19 0.49598083 <a title="236-lsi-19" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>20 0.4917064 <a title="236-lsi-20" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.013), (6, 0.033), (15, 0.28), (35, 0.024), (42, 0.253), (45, 0.018), (68, 0.09), (74, 0.074), (76, 0.039), (82, 0.014), (88, 0.044), (98, 0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.91271389 <a title="236-lda-1" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>Introduction: Many of the large machine learning conferences were in the US this summer. A
common problem which students from abroad encounter is visa issues.Just
getting a visa to visit can be pretty rough: you stand around in lines,
sometimes for days. Even worse is the timing with respect to ticket buying.
Airplane tickets typically need to be bought well in advance on nonrefundable
terms to secure a reasonable rate for air travel. When a visa is denied, as
happens reasonably often, a very expensive ticket is burnt.A serious effort is
under way to raise this as in issue in need of fixing. Over the long term,
effectively driving research conferences to locate outside of the US seems an
unwise policy.Robert Schapireis planning to talk to a congressman.Sally
Goldmansuggested putting together a list of problem cases, andPhil Longsetup
an email addressimmigration.and.confs@gmail.comto collect them.If you (or
someone you know) has had insurmountable difficulties reaching a conference in
the US, please</p><p>same-blog 2 0.88056386 <a title="236-lda-2" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a
data source (Example:X x {0,1},X x [0,1],X x {1,2,3,4,5}, etc…) and a loss
function (0/1 loss, squared error loss, cost sensitive losses, etc…). For
simplicity, we'll assume that all losses have a minimum of zero.For this post,
we can think of a learning reduction asA mappingRfrom samples of one
typeT(like multiclass classification) to another typeT'(like binary
classification).A mappingQfrom predictors for typeT'to predictors for
typeT.The simplest sort of learning reduction is a "loss reduction". The idea
in a loss reduction is to prove a statement of the form:TheoremFor all base
predictorsb, for all distributionsDover examples of typeT:E(x,y) ~
DLT(y,Q(b,x)) <= f(E(x',y')~R(D)LT'(y',b(x')))HereLTis the loss for the
typeTproblem andLT'is the loss for the typeT'problem. Also,R(D)is the
distribution over samples induced by first drawing fromDand then mapping the
sample viaR. The functionf()is the loss transf</p><p>3 0.78843367 <a title="236-lda-3" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>Introduction: It's conference season once again.ConferenceDue?When?Where?double blind?author
feedback?Workshops?AAAIFebruary 1/6 (and 27)July 22-26Vancouver, British
ColumbiaYesYesDoneUAIFebruary 28/March 2July 19-22Vancouver, British
ColumbiaNoNoNoCOLTJanuary 16June 13-15San Diego, California
(withFCRC)NoNoNoICMLFebruary 7/9June 20-24Corvallis, OregonYesYesFebruary
16KDDFebruary 23/28August 12-15San Jose, CaliforniaYesNo?February 28The
geowinner this year is the west coast of North America.Last year's geowinner
was the Northeastern US, and theyear beforeit was mostly Europe. It's notable
how tightly the conferences cluster, even when they don't colocate.</p><p>4 0.73998344 <a title="236-lda-4" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>Introduction: There area handful of basic code patternsthat I wish I was more aware of when
I started research in machine learning. Each on its own may seem pointless,
but collectively they go a long way towards making the typical research
workflow more efficient. Here they are:Separate code from data.Separate input
data, working data and output data.Save everything to disk frequently.Separate
options from parameters.Do not use global variables.Record the options used to
generate each run of the algorithm.Make it easy to sweep options.Make it easy
to execute only portions of the code.Use checkpointing.Write demos and
tests.Clickherefor discussion and examples for each item. Also seeCharles
Sutton'sandHackerNews'thoughts on the same topic.My guess is that these
patterns will not only be useful for machine learning, but also any other
computational work that involves either a) processing large amounts of data,
or b) algorithms that take a significant amount of time to execute. Share this
list with you</p><p>5 0.69928038 <a title="236-lda-5" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>Introduction: Many people in Machine Learning don't fully understand the impact of
computation, as demonstrated by a lack ofbig-Oanalysis of new learning
algorithms. This is important--some current active research programs are
fundamentally flawed w.r.t. computation, and other research programs are
directly motivated by it. When considering a learning algorithm, I think about
the following questions:How does the learning algorithm scale with the number
of examplesm? Any algorithm using all of the data is at leastO(m), but in many
cases this isO(m2)(naive nearest neighbor for self-prediction) or unknown
(k-means or many other optimization algorithms). The unknown case is very
common, and it can mean (for example) that the algorithm isn't convergent or
simply that the amount of computation isn't controlled.The above question can
also be asked for test cases. In some applications, test-time performance is
of great importance.How does the algorithm scale with the number of
featuresnper example? Many sec</p><p>6 0.69106698 <a title="236-lda-6" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>7 0.69076949 <a title="236-lda-7" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>8 0.6885978 <a title="236-lda-8" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>9 0.687971 <a title="236-lda-9" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>10 0.68719691 <a title="236-lda-10" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>11 0.68705243 <a title="236-lda-11" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>12 0.68658543 <a title="236-lda-12" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>13 0.68570858 <a title="236-lda-13" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>14 0.6846205 <a title="236-lda-14" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>15 0.68439603 <a title="236-lda-15" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>16 0.6843617 <a title="236-lda-16" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>17 0.68412 <a title="236-lda-17" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>18 0.68354285 <a title="236-lda-18" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>19 0.68037224 <a title="236-lda-19" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>20 0.67979813 <a title="236-lda-20" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
