<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-279" href="#">hunch_net-2007-279</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-279-html" href="http://hunch.net/?p=307">html</a></p><p>Introduction: I learned a number of things at  NIPS .
  
 The financial people were there in greater force than previously.   Two Sigma  sponsored NIPS while  DRW Trading  had a booth. 
 The  adversarial machine learning workshop  had a number of talks about interesting applications where an adversary really is out to try and mess up your learning algorithm.  This is very different from the situation we often think of where the world is oblivious to our learning.  This may present new and convincing applications for the learning-against-an-adversary work common at  COLT . 
 There were several interesing papers.
 
  Sanjoy Dasgupta ,  Daniel Hsu , and  Claire Monteleoni  had a paper on  General Agnostic Active Learning .  The basic idea is that active learning can be done via reduction to a form of supervised learning problem.  This is great, because we have many supervised learning algorithms from which the benefits of active learning may be derived. 
  Joseph Bradley  and  Robert Schapire  had a  P</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The financial people were there in greater force than previously. [sent-2, score-0.325]
</p><p>2 Two Sigma  sponsored NIPS while  DRW Trading  had a booth. [sent-3, score-0.135]
</p><p>3 The  adversarial machine learning workshop  had a number of talks about interesting applications where an adversary really is out to try and mess up your learning algorithm. [sent-4, score-0.899]
</p><p>4 This is very different from the situation we often think of where the world is oblivious to our learning. [sent-5, score-0.083]
</p><p>5 This may present new and convincing applications for the learning-against-an-adversary work common at  COLT . [sent-6, score-0.217]
</p><p>6 Sanjoy Dasgupta ,  Daniel Hsu , and  Claire Monteleoni  had a paper on  General Agnostic Active Learning . [sent-8, score-0.173]
</p><p>7 The basic idea is that active learning can be done via reduction to a form of supervised learning problem. [sent-9, score-0.63]
</p><p>8 This is great, because we have many supervised learning algorithms from which the benefits of active learning may be derived. [sent-10, score-0.615]
</p><p>9 Filterboost is an online boosting algorithm which I think of as the boost-by-filtration approaches in the first boosting paper updated for an adaboost-like structure. [sent-12, score-0.879]
</p><p>10 These kinds of approaches are doubtless helpful for large scale learning problems which are becoming more common. [sent-13, score-0.507]
</p><p>11 Peter Bartlett ,  Elad Hazan , and  Sasha Rakhlin  had a paper on  Adaptive Online Learning . [sent-14, score-0.173]
</p><p>12 This paper refines earlier results for online learning against an adversary via gradient descent, which is plausibly of great use in practice. [sent-15, score-0.935]
</p><p>13 I missed the workshop starting this effort at last yearâ&euro;&trade;s NIPS due to workshop overload, but open source machine learning is definitely of great and sound interest to the community. [sent-17, score-0.853]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('filterboost', 0.328), ('adversary', 0.192), ('active', 0.183), ('nips', 0.177), ('paper', 0.173), ('boosting', 0.172), ('workshop', 0.17), ('supervised', 0.146), ('mess', 0.146), ('bradley', 0.146), ('bartlett', 0.146), ('monteleoni', 0.146), ('online', 0.139), ('claire', 0.135), ('joseph', 0.135), ('sasha', 0.135), ('sponsored', 0.135), ('great', 0.133), ('doubtless', 0.121), ('financial', 0.121), ('force', 0.121), ('overload', 0.117), ('approaches', 0.114), ('applications', 0.114), ('elad', 0.112), ('hazan', 0.112), ('via', 0.111), ('updated', 0.109), ('trading', 0.109), ('dasgupta', 0.106), ('peter', 0.103), ('convincing', 0.103), ('agnostic', 0.103), ('missed', 0.1), ('hsu', 0.1), ('definitely', 0.098), ('schapire', 0.098), ('adaptive', 0.098), ('benefits', 0.096), ('robert', 0.096), ('sanjoy', 0.096), ('learning', 0.095), ('earlier', 0.092), ('becoming', 0.091), ('daniel', 0.091), ('adversarial', 0.087), ('sound', 0.087), ('kinds', 0.086), ('greater', 0.083), ('situation', 0.083)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="279-tfidf-1" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>Introduction: I learned a number of things at  NIPS .
  
 The financial people were there in greater force than previously.   Two Sigma  sponsored NIPS while  DRW Trading  had a booth. 
 The  adversarial machine learning workshop  had a number of talks about interesting applications where an adversary really is out to try and mess up your learning algorithm.  This is very different from the situation we often think of where the world is oblivious to our learning.  This may present new and convincing applications for the learning-against-an-adversary work common at  COLT . 
 There were several interesing papers.
 
  Sanjoy Dasgupta ,  Daniel Hsu , and  Claire Monteleoni  had a paper on  General Agnostic Active Learning .  The basic idea is that active learning can be done via reduction to a form of supervised learning problem.  This is great, because we have many supervised learning algorithms from which the benefits of active learning may be derived. 
  Joseph Bradley  and  Robert Schapire  had a  P</p><p>2 0.20152755 <a title="279-tfidf-2" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.
 
In selective sampling style active learning, a learning algorithm chooses which examples to label.  We now have an active learning algorithm that is:
  
  Efficient  in label complexity, unlabeled complexity, and computational complexity. 
  Competitive  with supervised learning anywhere that supervised learning works. 
  Compatible  with online learning, with any optimization-based learning algorithm, with any loss function, with offline testing, and even with changing learning algorithms. 
  Empirically  effective. 
  
The basic idea is to combine  disagreement region-based sampling  with  importance weighting : an example is selected to be labeled with probability proportional to how useful it is for distinguishing among near-optimal classifiers, and labeled examples are importance-weighted by the inverse of these probabilities.  The combination of these simple ideas removes the  sampling bias  problem that has plagued many previous he</p><p>3 0.19508386 <a title="279-tfidf-3" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,  Sanjoy   made a post  saying roughly “we should  study active learning theoretically, because not much is understood”.   
 
At the time, we did not understand basic things such as whether or not it was possible to PAC-learn with an active algorithm without making strong assumptions about the noise rate.  In other words, the fundamental question was “can we do it?”
 
The nature of the question has fundamentally changed in my mind.   The answer is to the previous question is “yes”, both information theoretically and computationally, most places where supervised learning could be applied.  
 
In many situation, the question has now changed to: “is it worth it?”  Is the programming and computational overhead low enough to make the label cost savings of active learning worthwhile?  Currently, there are situations where this question could go either way.  Much of the challenge for the future is in figuring out how to make active learning easier or more worthwhile.</p><p>4 0.16817065 <a title="279-tfidf-4" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>Introduction: Here are a few of the papers I enjoyed at ICML.
  
  Steffen Bickel , Michael BrÃƒÂ¼eckner,  Tobias Scheffer ,  Discriminative Learning for Differing Training and Test Distributions   There is a nice trick in this paper: they predict the probability that an unlabeled sample is in the training set vs. the test set, and then use this prediction to importance weight labeled samples in the training set.  This paper uses a specific parametric model, but the approach is easily generalized. 
  Steve Hanneke   A Bound on the Label Complexity of Agnostic Active Learning   This paper bounds the number of labels required by the A 2  algorithm for active learning in the agnostic case.   Last year we figured out agnostic active learning was possible.  This year, it’s quantified.  Hopefull soon, it will be practical. 
  Sylvian Gelly ,  David Silver   Combining Online and Offline Knowledge in UCT .  This paper is about techniques for improving  MoGo  with various sorts of learning.  MoGo has a fair</p><p>5 0.15647165 <a title="279-tfidf-5" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>Introduction: Several bits of progress have been made since  Sanjoy  pointed out the significant  lack of theoretical understanding of active learning .  This is an update on the progress I know of.  As a refresher, active learning as meant here is:
  
 There is a source of unlabeled data. 
 There is an oracle from which labels can be requested for unlabeled data produced by the source. 
 The goal is to perform well with minimal use of the oracle. 
  
Here is what I’ve learned:
  
 Sanjoy has developed sufficient and semi-necessary conditions for active learning given the assumptions of IID data and “realizability” (that one of the classifiers is a correct classifier). 
  Nina ,  Alina , and I developed an algorithm for active learning relying on only the assumption of IID data.  A draft is  here . 
  Nicolo ,  Claudio , and  Luca  showed that it is possible to do active learning in an entirely adversarial setting for linear threshold classifiers  here .  This was published a year or two ago and I r</p><p>6 0.14902316 <a title="279-tfidf-6" href="../hunch_net-2009/hunch_net-2009-06-24-Interesting_papers_at_UAICMOLT_2009.html">361 hunch net-2009-06-24-Interesting papers at UAICMOLT 2009</a></p>
<p>7 0.1462139 <a title="279-tfidf-7" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>8 0.14047515 <a title="279-tfidf-8" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>9 0.1391871 <a title="279-tfidf-9" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>10 0.13226046 <a title="279-tfidf-10" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>11 0.12763478 <a title="279-tfidf-11" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>12 0.12383645 <a title="279-tfidf-12" href="../hunch_net-2006/hunch_net-2006-07-26-Two_more_UAI_papers_of_interest.html">199 hunch net-2006-07-26-Two more UAI papers of interest</a></p>
<p>13 0.12240991 <a title="279-tfidf-13" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>14 0.12135119 <a title="279-tfidf-14" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>15 0.11869878 <a title="279-tfidf-15" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>16 0.11833879 <a title="279-tfidf-16" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>17 0.11699794 <a title="279-tfidf-17" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>18 0.11671025 <a title="279-tfidf-18" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>19 0.11631461 <a title="279-tfidf-19" href="../hunch_net-2006/hunch_net-2006-05-16-The_value_of_the_orthodox_view_of_Boosting.html">179 hunch net-2006-05-16-The value of the orthodox view of Boosting</a></p>
<p>20 0.1111051 <a title="279-tfidf-20" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.252), (1, -0.011), (2, -0.081), (3, -0.106), (4, 0.177), (5, 0.104), (6, -0.044), (7, -0.089), (8, -0.068), (9, 0.115), (10, 0.204), (11, -0.052), (12, -0.031), (13, 0.041), (14, -0.055), (15, 0.027), (16, 0.004), (17, 0.048), (18, -0.029), (19, -0.009), (20, -0.103), (21, 0.047), (22, 0.052), (23, -0.035), (24, 0.063), (25, -0.038), (26, 0.057), (27, 0.091), (28, -0.0), (29, 0.019), (30, 0.027), (31, 0.035), (32, -0.123), (33, -0.038), (34, -0.024), (35, -0.031), (36, -0.08), (37, -0.061), (38, -0.014), (39, 0.095), (40, 0.047), (41, -0.047), (42, 0.02), (43, -0.003), (44, -0.032), (45, -0.074), (46, -0.056), (47, -0.046), (48, 0.017), (49, -0.008)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95305538 <a title="279-lsi-1" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>Introduction: I learned a number of things at  NIPS .
  
 The financial people were there in greater force than previously.   Two Sigma  sponsored NIPS while  DRW Trading  had a booth. 
 The  adversarial machine learning workshop  had a number of talks about interesting applications where an adversary really is out to try and mess up your learning algorithm.  This is very different from the situation we often think of where the world is oblivious to our learning.  This may present new and convincing applications for the learning-against-an-adversary work common at  COLT . 
 There were several interesing papers.
 
  Sanjoy Dasgupta ,  Daniel Hsu , and  Claire Monteleoni  had a paper on  General Agnostic Active Learning .  The basic idea is that active learning can be done via reduction to a form of supervised learning problem.  This is great, because we have many supervised learning algorithms from which the benefits of active learning may be derived. 
  Joseph Bradley  and  Robert Schapire  had a  P</p><p>2 0.71686763 <a title="279-lsi-2" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>Introduction: Here are a few papers from  COLT 2008  that I found interesting.
  
  Maria-Florina Balcan ,  Steve Hanneke , and  Jenn Wortman ,  The True Sample Complexity of Active Learning .  This paper shows that in an asymptotic setting, active learning is  always  better than supervised learning (although the gap may be small).  This is evidence that the only thing in the way of universal active learning is us knowing how to do it properly. 
  Nir Ailon  and  Mehryar Mohri ,  An Efficient Reduction of Ranking to Classification .  This paper shows how to robustly rank  n  objects with  n log(n)  classifications using a quicksort based algorithm.  The result is applicable to many ranking loss functions and has implications for others. 
  Michael Kearns  and  Jennifer Wortman .  Learning from Collective Behavior .  This is about learning in a new model, where the goal is to predict how a collection of interacting agents behave.  One claim is that learning in this setting can be reduced to IID lear</p><p>3 0.67535686 <a title="279-lsi-3" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>Introduction: Here are some papers from  ICML 2008  that I found interesting.  
  
  Risi Kondor  and  Karsten Borgwardt ,  The Skew Spectrum of Graphs . This paper is about a new family of functions on graphs which is invariant under node label permutation.  They show that these quantities appear to yield good features for learning. 
  Sanjoy Dasgupta  and  Daniel Hsu .   Hierarchical sampling for active learning.   This is the first published practical consistent active learning algorithm.  The abstract is also pretty impressive. 
  Lihong Li ,  Michael Littman , and  Thomas Walsh   Knows What It Knows: A Framework For Self-Aware Learning.   This is an attempt to create learning algorithms that know when they err, (other work includes  Vovk ).  It’s not yet clear to me what the right model for  feature-dependent confidence intervals  is. 
  Novi Quadrianto ,  Alex Smola ,  TIberio Caetano , and  Quoc Viet Le   Estimating Labels from Label Proportions .  This is an example of learning in a speciali</p><p>4 0.66799152 <a title="279-lsi-4" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.
 
In selective sampling style active learning, a learning algorithm chooses which examples to label.  We now have an active learning algorithm that is:
  
  Efficient  in label complexity, unlabeled complexity, and computational complexity. 
  Competitive  with supervised learning anywhere that supervised learning works. 
  Compatible  with online learning, with any optimization-based learning algorithm, with any loss function, with offline testing, and even with changing learning algorithms. 
  Empirically  effective. 
  
The basic idea is to combine  disagreement region-based sampling  with  importance weighting : an example is selected to be labeled with probability proportional to how useful it is for distinguishing among near-optimal classifiers, and labeled examples are importance-weighted by the inverse of these probabilities.  The combination of these simple ideas removes the  sampling bias  problem that has plagued many previous he</p><p>5 0.65939248 <a title="279-lsi-5" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>Introduction: Several papers at NIPS caught my attention.
  
  Elad Hazan  and  Satyen Kale ,  Online Submodular Optimization  They define an algorithm for online optimization of submodular functions with regret guarantees.  This places submodular optimization roughly on par with online convex optimization as tractable settings for online learning.   
  Elad Hazan  and  Satyen Kale   On Stochastic and Worst-Case Models of Investing .  At it’s core, this is yet another example of modifying worst-case online learning to deal with variance, but the application to financial models is particularly cool and it seems plausibly superior other common approaches for financial modeling. 
  Mark Palatucci ,  Dean Pomerlau ,  Tom Mitchell , and  Geoff Hinton   Zero Shot Learning with Semantic Output Codes  The goal here is predicting a label in a multiclass supervised setting where the label never occurs in the training data.  They have some basic analysis and also a nice application to FMRI brain reading. 
  Sh</p><p>6 0.6586889 <a title="279-lsi-6" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>7 0.64710504 <a title="279-lsi-7" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>8 0.61650461 <a title="279-lsi-8" href="../hunch_net-2009/hunch_net-2009-06-24-Interesting_papers_at_UAICMOLT_2009.html">361 hunch net-2009-06-24-Interesting papers at UAICMOLT 2009</a></p>
<p>9 0.61209428 <a title="279-lsi-9" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>10 0.60774922 <a title="279-lsi-10" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>11 0.59443629 <a title="279-lsi-11" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>12 0.58270562 <a title="279-lsi-12" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>13 0.58230007 <a title="279-lsi-13" href="../hunch_net-2009/hunch_net-2009-12-24-Top_graduates_this_season.html">384 hunch net-2009-12-24-Top graduates this season</a></p>
<p>14 0.57266265 <a title="279-lsi-14" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>15 0.5615986 <a title="279-lsi-15" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>16 0.55880582 <a title="279-lsi-16" href="../hunch_net-2011/hunch_net-2011-08-01-Interesting_papers_at_COLT_2011.html">439 hunch net-2011-08-01-Interesting papers at COLT 2011</a></p>
<p>17 0.53882217 <a title="279-lsi-17" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>18 0.53553683 <a title="279-lsi-18" href="../hunch_net-2008/hunch_net-2008-11-28-A_Bumper_Crop_of_Machine_Learning_Graduates.html">329 hunch net-2008-11-28-A Bumper Crop of Machine Learning Graduates</a></p>
<p>19 0.53199434 <a title="279-lsi-19" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>20 0.50954318 <a title="279-lsi-20" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(10, 0.068), (23, 0.254), (27, 0.225), (38, 0.04), (53, 0.041), (55, 0.136), (94, 0.051), (95, 0.084)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.87548399 <a title="279-lda-1" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>Introduction: I learned a number of things at  NIPS .
  
 The financial people were there in greater force than previously.   Two Sigma  sponsored NIPS while  DRW Trading  had a booth. 
 The  adversarial machine learning workshop  had a number of talks about interesting applications where an adversary really is out to try and mess up your learning algorithm.  This is very different from the situation we often think of where the world is oblivious to our learning.  This may present new and convincing applications for the learning-against-an-adversary work common at  COLT . 
 There were several interesing papers.
 
  Sanjoy Dasgupta ,  Daniel Hsu , and  Claire Monteleoni  had a paper on  General Agnostic Active Learning .  The basic idea is that active learning can be done via reduction to a form of supervised learning problem.  This is great, because we have many supervised learning algorithms from which the benefits of active learning may be derived. 
  Joseph Bradley  and  Robert Schapire  had a  P</p><p>2 0.82997108 <a title="279-lda-2" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>Introduction: Pieter Abbeel  presented a paper with  Andrew Ng  at  ICML  on  Exploration and Apprenticeship Learning in Reinforcement Learning .  The basic idea of this algorithm is:
  
 Collect data from a human controlling a machine. 
 Build a transition model based upon the experience. 
 Build a policy which optimizes the transition model. 
 Evaluate the policy.  If it works well, halt, otherwise add the experience into the pool and go to (2). 
  
The paper proves that this technique will converge to some policy with expected performance near human expected performance assuming the  world fits certain assumptions (MDP or linear dynamics).  
 
This general idea of apprenticeship learning (i.e. incorporating data from an expert) seems very compelling because (a) humans often learn this way and (b) much harder problems can be solved.   For (a), the notion of teaching is about transferring knowledge from an expert to novices, often via demonstration. To see (b), note that we can create intricate rei</p><p>3 0.76037413 <a title="279-lda-3" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>Introduction: One of the remarkable things about machine learning is how diverse it is.  The viewpoints of Bayesian learning, reinforcement learning, graphical models, supervised learning, unsupervised learning, genetic programming, etc… share little enough overlap that many people can and do make their careers within one without touching, or even necessarily understanding the others.
 
There are two fundamental reasons why this is possible.
  
 For many problems, many approaches work in the sense that they do something useful.  This is true empirically, where for many problems we can observe that many different approaches yield better performance than any constant predictor.  It’s also true in theory, where we know that for any set of predictors representable in a finite amount of RAM, minimizing training error over the set of predictors does something nontrivial when there are a sufficient number of examples. 
 There is nothing like a unifying problem defining the field.  In many other areas there</p><p>4 0.73514593 <a title="279-lda-4" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>Introduction: Normally, I don’t indulge in posters for  ICML , but this year is naturally an exception for me.   If you want one, there are a small number  left here , if you sign up before February.
 
It also seems worthwhile to give some sense of the scope and reviewing criteria for ICML for authors considering submitting papers.  At ICML, the (very large) program committee does the reviewing which informs final decisions by area chairs on most papers.  Program chairs setup the process, deal with exceptions or disagreements, and provide advice for the reviewing process.  Providing advice is tricky (and easily misleading) because a conference is a community, and in the end the aggregate interests of the community determine the conference.  Nevertheless, as a program chair this year it seems worthwhile to state the overall philosophy I have and what I plan to encourage (and occasionally discourage).
 
At the highest level, I believe ICML exists to further research into machine learning, which I gene</p><p>5 0.73482531 <a title="279-lda-5" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but sometimes the unfairness seems particularly striking.  This is most easily seen by comparison:
  
 
 Paper 
  Banditron  
  Offset Tree  
 Notes 
 
 
 Problem Scope 
 Multiclass problems where only the loss of one choice can be probed. 
 Strictly greater: Cost sensitive multiclass problems where only the loss of one choice can be probed. 
 Often generalizations don’t matter.  That’s not the case here, since every plausible application I’ve thought of involves loss functions substantially different from 0/1. 
 
 
 What’s new 
 Analysis and Experiments 
 Algorithm, Analysis, and Experiments 
  As far as I know, the essence of the more general problem was first stated and analyzed with the  EXP4 algorithm (page 16)  (1998).  It’s also the time horizon 1 simplification of the Reinforcement Learning setting for the  random trajectory method (page 15)  (2002).  The Banditron algorithm itself is functionally identi</p><p>6 0.72879374 <a title="279-lda-6" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>7 0.72677666 <a title="279-lda-7" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>8 0.72407371 <a title="279-lda-8" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>9 0.72393018 <a title="279-lda-9" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>10 0.72071862 <a title="279-lda-10" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>11 0.71584606 <a title="279-lda-11" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>12 0.71480834 <a title="279-lda-12" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>13 0.71471673 <a title="279-lda-13" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>14 0.71463358 <a title="279-lda-14" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>15 0.71197474 <a title="279-lda-15" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>16 0.71157217 <a title="279-lda-16" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>17 0.71114475 <a title="279-lda-17" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>18 0.70545381 <a title="279-lda-18" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>19 0.70477182 <a title="279-lda-19" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>20 0.7043227 <a title="279-lda-20" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
