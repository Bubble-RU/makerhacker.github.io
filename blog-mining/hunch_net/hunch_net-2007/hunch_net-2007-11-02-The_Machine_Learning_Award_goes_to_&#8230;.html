<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-270" href="#">hunch_net-2007-270</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-270-html" href="http://hunch.net/?p=293">html</a></p><p>Introduction: Perhaps the biggest CS prize for research is the  Turing Award , which has a $0.25M cash prize associated with it.  It appears none of the prizes so far have been for anything like machine learning (the closest are perhaps database awards).
 
In CS theory, there is the  GÃƒÂ¶del Prize  which is smaller and newer, offering a $5K prize along and perhaps (more importantly) recognition.  One such award has been given for Machine Learning, to  Robert Schapire  and  Yoav Freund  for Adaboost.
 
In Machine Learning, there seems to be no equivalent of these sorts of prizes.  There are several plausible reasons for this:
  
 
 There is no coherent community. 
  People drift in and out of the central conferences all the time.  Most of the author names from 10 years ago do not occur in the conferences of today.  In addition, the entire subject area is fairly new. 
 There are at least a core group of people who have stayed around. 
 
 
 Machine Learning work doesn’t last 
 Almost every paper is fo</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Perhaps the biggest CS prize for research is the  Turing Award , which has a $0. [sent-1, score-0.328]
</p><p>2 It appears none of the prizes so far have been for anything like machine learning (the closest are perhaps database awards). [sent-3, score-0.431]
</p><p>3 In CS theory, there is the  GÃƒÂ¶del Prize  which is smaller and newer, offering a $5K prize along and perhaps (more importantly) recognition. [sent-4, score-0.463]
</p><p>4 One such award has been given for Machine Learning, to  Robert Schapire  and  Yoav Freund  for Adaboost. [sent-5, score-0.464]
</p><p>5 There are several plausible reasons for this:       There is no coherent community. [sent-7, score-0.151]
</p><p>6 People drift in and out of the central conferences all the time. [sent-8, score-0.278]
</p><p>7 Most of the author names from 10 years ago do not occur in the conferences of today. [sent-9, score-0.395]
</p><p>8 There are at least a core group of people who have stayed around. [sent-11, score-0.171]
</p><p>9 Machine Learning work doesn’t last   Almost every paper is forgotten, because {the goals change, there isn’t any real progress, there are no teachable foundations}. [sent-12, score-0.089]
</p><p>10 The field is fractured between many very different viewpoints—statistical, empirical, AI, and theoretical. [sent-15, score-0.17]
</p><p>11 The prioritization of results across these very different viewpoints is hard. [sent-16, score-0.42]
</p><p>12 Aspiration  Perhaps the most valuable aspect of an award is that it gives people an incentive to aim for something in the long term. [sent-20, score-0.817]
</p><p>13 The closest approximation that we have right now is “best papers” awards at individual conferences. [sent-21, score-0.406]
</p><p>14 Best paper awards have a role, but it’s not the same. [sent-22, score-0.252]
</p><p>15 10 years from now, when we look back 10 years, which papers will seem most significant? [sent-23, score-0.131]
</p><p>16 Representation  One function of an award is that tells other people what we consider good work. [sent-25, score-0.539]
</p><p>17 In an academic reference frame, it gives information of the form “this person deserves tenure”. [sent-26, score-0.206]
</p><p>18 An award has some role in furthering that process. [sent-29, score-0.6]
</p><p>19 The worst part of any award is administering it. [sent-30, score-0.464]
</p><p>20 How do you avoid wasting time and playing favorites while keeping the higher level vision of what might be useful in the long term? [sent-31, score-0.262]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('award', 0.464), ('prize', 0.254), ('awards', 0.252), ('viewpoints', 0.154), ('closest', 0.154), ('turing', 0.14), ('role', 0.136), ('cs', 0.133), ('years', 0.131), ('perhaps', 0.12), ('conferences', 0.11), ('gives', 0.11), ('across', 0.103), ('crystallization', 0.096), ('fractured', 0.096), ('deserves', 0.096), ('forgotten', 0.096), ('drift', 0.096), ('aim', 0.096), ('favorites', 0.096), ('stayed', 0.096), ('wasting', 0.096), ('prioritization', 0.089), ('offering', 0.089), ('teachable', 0.089), ('clarity', 0.084), ('consensus', 0.084), ('occur', 0.08), ('cash', 0.08), ('frame', 0.08), ('prizes', 0.08), ('tenure', 0.077), ('insight', 0.077), ('placing', 0.077), ('yoav', 0.077), ('outsiders', 0.077), ('database', 0.077), ('reasons', 0.077), ('people', 0.075), ('biggest', 0.074), ('names', 0.074), ('coherent', 0.074), ('foundations', 0.074), ('different', 0.074), ('newer', 0.072), ('freund', 0.072), ('incentive', 0.072), ('central', 0.072), ('importantly', 0.07), ('playing', 0.07)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="270-tfidf-1" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>Introduction: Perhaps the biggest CS prize for research is the  Turing Award , which has a $0.25M cash prize associated with it.  It appears none of the prizes so far have been for anything like machine learning (the closest are perhaps database awards).
 
In CS theory, there is the  GÃƒÂ¶del Prize  which is smaller and newer, offering a $5K prize along and perhaps (more importantly) recognition.  One such award has been given for Machine Learning, to  Robert Schapire  and  Yoav Freund  for Adaboost.
 
In Machine Learning, there seems to be no equivalent of these sorts of prizes.  There are several plausible reasons for this:
  
 
 There is no coherent community. 
  People drift in and out of the central conferences all the time.  Most of the author names from 10 years ago do not occur in the conferences of today.  In addition, the entire subject area is fairly new. 
 There are at least a core group of people who have stayed around. 
 
 
 Machine Learning work doesn’t last 
 Almost every paper is fo</p><p>2 0.18134223 <a title="270-tfidf-2" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>Introduction: For graduate students, the  Yahoo!   Key Scientific Challenges program  including in  machine learning  is on again,  due March 9 .  The application is easy and the $5K award is high quality “no strings attached” funding.   Consider submitting.
 
Those in Washington DC, Philadelphia, and New York, may consider attending the  Franklin Institute Symposium   April 25  which has several speakers and an award for  V .  Attendance is free with an RSVP.</p><p>3 0.13425569 <a title="270-tfidf-3" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>Introduction: I just  presented  the  cross validation  problem at  COLT .  
 
The problem now has a cash prize (up to $500) associated with itâ&euro;&rdquo;see the  presentation  for details.
 
The  write-up for colt .</p><p>4 0.12321773 <a title="270-tfidf-4" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>Introduction: The competitors for the  Netflix Prize  are tantalizingly close winning the million dollar prize.  This year,  BellKor  and  Commendo Research  sent a combined solution that won the  progress prize .  Reading the  writeups   2  is instructive.  Several aspects of solutions are taken for granted including stochastic gradient descent, ensemble prediction, and targeting residuals (a form of boosting).  Relatively to last year, it appears that many approaches have added parameterizations, especially for the purpose of modeling through time.
 
The big question is: will they make the big prize?  At this point, the level of complexity in entering the competition is prohibitive, so perhaps only the existing competitors will continue to try.  (This equation might change drastically if the teams open source their existing solutions, including parameter settings.) One fear is that the progress is asymptoting on the wrong side of the 10% threshold.  In the first year, the teams progressed through</p><p>5 0.11199456 <a title="270-tfidf-5" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended the  Netflix prize  ceremony this morning.  The press conference part is  covered fine elsewhere , with the basic outcome being that  BellKor’s Pragmatic Chaos  won over  The Ensemble  by 15-20  minutes , because they were tied in performance on the ultimate holdout set.  I’m sure the individual participants will have many chances to speak about the solution.  One of these is Bell at the  NYAS ML symposium on Nov. 6 .
 
Several additional details may interest ML people.
  
 The degree of overfitting exhibited by the difference in performance on the  leaderboard test set  and the ultimate hold out set was small, but determining at .02 to .03%. 
 A tie was possible, because the rules cut off measurements below the fourth digit based on significance concerns.  In actuality, of course, the scores do differ before rounding, but everyone I spoke to claimed not to know how.  The complete dataset has been  released on UCI , so each team could compute their own score to whatever accu</p><p>6 0.10541812 <a title="270-tfidf-6" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>7 0.09794347 <a title="270-tfidf-7" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>8 0.095053434 <a title="270-tfidf-8" href="../hunch_net-2011/hunch_net-2011-03-27-Vowpal_Wabbit%2C_v5.1.html">428 hunch net-2011-03-27-Vowpal Wabbit, v5.1</a></p>
<p>9 0.094645493 <a title="270-tfidf-9" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>10 0.094315149 <a title="270-tfidf-10" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>11 0.093174323 <a title="270-tfidf-11" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>12 0.091576211 <a title="270-tfidf-12" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>13 0.091415688 <a title="270-tfidf-13" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>14 0.089650229 <a title="270-tfidf-14" href="../hunch_net-2005/hunch_net-2005-04-22-New_Blog%3A_%5BLowerbounds%2CUpperbounds%5D.html">59 hunch net-2005-04-22-New Blog: [Lowerbounds,Upperbounds]</a></p>
<p>15 0.089266725 <a title="270-tfidf-15" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>16 0.089021489 <a title="270-tfidf-16" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>17 0.088434674 <a title="270-tfidf-17" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>18 0.088278525 <a title="270-tfidf-18" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>19 0.087732248 <a title="270-tfidf-19" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>20 0.086920686 <a title="270-tfidf-20" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.211), (1, -0.062), (2, -0.031), (3, 0.074), (4, -0.032), (5, 0.014), (6, -0.036), (7, -0.006), (8, -0.01), (9, -0.053), (10, -0.011), (11, 0.114), (12, 0.001), (13, 0.017), (14, 0.029), (15, -0.001), (16, 0.065), (17, 0.056), (18, 0.004), (19, -0.059), (20, 0.004), (21, 0.061), (22, 0.041), (23, 0.012), (24, 0.062), (25, -0.048), (26, -0.062), (27, -0.024), (28, 0.012), (29, 0.015), (30, -0.069), (31, -0.038), (32, -0.009), (33, -0.022), (34, -0.037), (35, 0.046), (36, -0.059), (37, -0.025), (38, -0.014), (39, 0.112), (40, -0.192), (41, 0.009), (42, 0.1), (43, -0.028), (44, -0.057), (45, -0.108), (46, 0.003), (47, -0.002), (48, 0.136), (49, -0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94181228 <a title="270-lsi-1" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>Introduction: Perhaps the biggest CS prize for research is the  Turing Award , which has a $0.25M cash prize associated with it.  It appears none of the prizes so far have been for anything like machine learning (the closest are perhaps database awards).
 
In CS theory, there is the  GÃƒÂ¶del Prize  which is smaller and newer, offering a $5K prize along and perhaps (more importantly) recognition.  One such award has been given for Machine Learning, to  Robert Schapire  and  Yoav Freund  for Adaboost.
 
In Machine Learning, there seems to be no equivalent of these sorts of prizes.  There are several plausible reasons for this:
  
 
 There is no coherent community. 
  People drift in and out of the central conferences all the time.  Most of the author names from 10 years ago do not occur in the conferences of today.  In addition, the entire subject area is fairly new. 
 There are at least a core group of people who have stayed around. 
 
 
 Machine Learning work doesn’t last 
 Almost every paper is fo</p><p>2 0.62432653 <a title="270-lsi-2" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>Introduction: The competitors for the  Netflix Prize  are tantalizingly close winning the million dollar prize.  This year,  BellKor  and  Commendo Research  sent a combined solution that won the  progress prize .  Reading the  writeups   2  is instructive.  Several aspects of solutions are taken for granted including stochastic gradient descent, ensemble prediction, and targeting residuals (a form of boosting).  Relatively to last year, it appears that many approaches have added parameterizations, especially for the purpose of modeling through time.
 
The big question is: will they make the big prize?  At this point, the level of complexity in entering the competition is prohibitive, so perhaps only the existing competitors will continue to try.  (This equation might change drastically if the teams open source their existing solutions, including parameter settings.) One fear is that the progress is asymptoting on the wrong side of the 10% threshold.  In the first year, the teams progressed through</p><p>3 0.51508421 <a title="270-lsi-3" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended the  Netflix prize  ceremony this morning.  The press conference part is  covered fine elsewhere , with the basic outcome being that  BellKor’s Pragmatic Chaos  won over  The Ensemble  by 15-20  minutes , because they were tied in performance on the ultimate holdout set.  I’m sure the individual participants will have many chances to speak about the solution.  One of these is Bell at the  NYAS ML symposium on Nov. 6 .
 
Several additional details may interest ML people.
  
 The degree of overfitting exhibited by the difference in performance on the  leaderboard test set  and the ultimate hold out set was small, but determining at .02 to .03%. 
 A tie was possible, because the rules cut off measurements below the fourth digit based on significance concerns.  In actuality, of course, the scores do differ before rounding, but everyone I spoke to claimed not to know how.  The complete dataset has been  released on UCI , so each team could compute their own score to whatever accu</p><p>4 0.4886224 <a title="270-lsi-4" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>Introduction: Yahoo released the  Key Scientific Challenges  program.  There is a  Machine Learning  list I worked on and a  Statistics  list which  Deepak  worked on.
 
I’m hoping this is taken quite seriously by graduate students.  The primary value, is that it gave us a chance to sit down and publicly specify directions of research which would be valuable to make progress on.  A good strategy for a beginning graduate student is to pick one of these directions, pursue it, and make substantial advances for a PhD.  The directions are sufficiently general that I’m sure any serious advance has applications well beyond Yahoo.
 
A secondary point, (which I’m sure is primary for many    ) is that there is money for graduate students here.  It’s unrestricted, so you can use it for any reasonable travel, supplies, etc…</p><p>5 0.48578727 <a title="270-lsi-5" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: The  Heritage Health Prize  is potentially the largest prediction prize yet at $3M, which is sure to get many people interested.  Several elements of the competition may be worth discussing.
  
 The most straightforward way for HPN to deploy this predictor is in determining who to cover with insurance.  This might easily cover the costs of running the contest itself, but the value to the health system of a whole is minimal, as people not covered still exist.  While HPN itself is a provider network, they have active relationships with a number of insurance companies, and the right to resell any entrant.  It’s worth keeping in mind that the research and development may nevertheless end up being useful in the longer term, especially as entrants also keep the right to their code. 
 The  judging metric  is something I haven’t seen previously.  If a patient has probability 0.5 of being in the hospital 0 days and probability 0.5 of being in the hospital ~53.6 days, the optimal prediction in e</p><p>6 0.46754417 <a title="270-lsi-6" href="../hunch_net-2011/hunch_net-2011-03-27-Vowpal_Wabbit%2C_v5.1.html">428 hunch net-2011-03-27-Vowpal Wabbit, v5.1</a></p>
<p>7 0.46424162 <a title="270-lsi-7" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>8 0.46273336 <a title="270-lsi-8" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>9 0.46266416 <a title="270-lsi-9" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>10 0.46197149 <a title="270-lsi-10" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>11 0.46172521 <a title="270-lsi-11" href="../hunch_net-2006/hunch_net-2006-04-14-JMLR_is_a_success.html">172 hunch net-2006-04-14-JMLR is a success</a></p>
<p>12 0.46146423 <a title="270-lsi-12" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<p>13 0.4595384 <a title="270-lsi-13" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>14 0.45211893 <a title="270-lsi-14" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>15 0.44594613 <a title="270-lsi-15" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>16 0.44456595 <a title="270-lsi-16" href="../hunch_net-2010/hunch_net-2010-10-17-Partha_Niyogi_has_died.html">414 hunch net-2010-10-17-Partha Niyogi has died</a></p>
<p>17 0.44320983 <a title="270-lsi-17" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>18 0.44311288 <a title="270-lsi-18" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<p>19 0.43986726 <a title="270-lsi-19" href="../hunch_net-2007/hunch_net-2007-07-28-Asking_questions.html">257 hunch net-2007-07-28-Asking questions</a></p>
<p>20 0.43926367 <a title="270-lsi-20" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.201), (38, 0.025), (53, 0.051), (55, 0.535), (68, 0.014), (77, 0.018), (94, 0.037), (95, 0.032)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99653351 <a title="270-lda-1" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>Introduction: The  New York ML symposium  was last Friday.  Attendance was 268, significantly larger than  last year .  My impression was that the event mostly still fit the space, although it was crowded.  If anyone has suggestions for next year, speak up.
 
The best student paper award went to  Sergiu Goschin  for a cool video of how his system learned to play video games (I can’t find the paper online yet).  Choosing amongst the submitted talks was pretty difficult this year, as there were many similarly good ones.
 
By coincidence all the invited talks were (at least potentially) about faster learning algorithms.   Stephen Boyd  talked about  ADMM .  Leon Bottou  spoke on single pass online learning via  averaged SGD .   Yoav Freund  talked about  parameter-free hedging .  In Yoav’s case the talk was mostly about a better theoretical learning algorithm, but it has the potential to unlock an exponential computational complexity improvement via oraclization of experts algorithms… but some serious</p><p>2 0.99518979 <a title="270-lda-2" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>Introduction: Luis von Ahn  has been running the  espgame  for awhile now.  The espgame provides a picture to two randomly paired people across the web, and asks them to agree on a label.  It hasn’t managed to label the web yet, but it has produced a  large dataset  of (image, label) pairs.  I organized the dataset so you could  explore the implied bipartite graph  (requires much bandwidth).
 
Relative to other image datasets, this one is quite large—67000 images, 358,000 labels (average of 5/image with variation from 1 to 19), and 22,000 unique labels (one every 3 images).  The dataset is also very ‘natural’, consisting of images spidered from the internet.  The multiple label characteristic is intriguing because ‘learning to learn’ and metalearning techniques may be applicable.  The ‘natural’ quality means that this dataset varies greatly in difficulty from easy (predicting “red”) to hard (predicting “funny”) and potentially more rewarding to tackle.
 
The open problem here is, of course, to make</p><p>3 0.994609 <a title="270-lda-3" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>Introduction: Suppose we had an infinitely powerful mathematician sitting in a room and proving theorems about learning.  Could he solve machine learning?
 
The answer is “no”.   This answer is both obvious and sometimes underappreciated.   
 
There are several ways to conclude that some  bias  is necessary in order to succesfully learn.  For example, suppose we are trying to solve classification.  At prediction time, we observe some features  X  and want to make a prediction of either  0  or  1 .   Bias is what makes us prefer one answer over the other based on past experience.  In order to learn we must:
  
 Have a bias.  Always predicting  0  is as likely as  1  is useless. 
 Have the “right” bias.  Predicting  1  when the answer is  0  is also not helpful. 
  
The implication of “have a bias” is that we can not design effective learning algorithms with “a uniform prior over all possibilities”.  The implication of “have the ‘right’ bias” is that our mathematician fails since “right” is defined wi</p><p>4 0.99338698 <a title="270-lda-4" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>Introduction: Reviewers and students are sometimes greatly concerned by the distinction between:
  
  An  open set  and a  closed set . 
 A  Supremum  and a  Maximum . 
 An event which happens with probability 1 and an event that always happens. 
  
I don’t appreciate this distinction in machine learning & learning theory.  All machine learning takes place (by definition) on a machine where every parameter has finite precision.  Consequently, every set is closed, a maximal element always exists, and probability 1 events always happen.
 
The fundamental issue here is that substantial parts of mathematics don’t appear well-matched to computation in the physical world, because the mathematics has concerns which are unphysical.  This mismatched mathematics makes irrelevant distinctions.  We can ask “what mathematics is appropriate to computation?”   Andrej  has convinced me that a pretty good answer to this question is  constructive mathematics .
 
So, here’s a basic challenge: Can anyone name a situati</p><p>5 0.99043882 <a title="270-lda-5" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>Introduction: The  results have been posted , with  CMU first ,  Stanford second , and  Virginia Tech Third .
 
Considering that this was an open event (at least for people in the US), this was a very strong showing for research at universities (instead of defense contractors, for example).  Some details should become public at the  NIPS workshops .
 
 Slashdot  has a  post  with many comments.</p><p>6 0.98950362 <a title="270-lda-6" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>same-blog 7 0.97332698 <a title="270-lda-7" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>8 0.97137076 <a title="270-lda-8" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>9 0.96270323 <a title="270-lda-9" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>10 0.96130502 <a title="270-lda-10" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>11 0.94450372 <a title="270-lda-11" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>12 0.92744708 <a title="270-lda-12" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>13 0.92744708 <a title="270-lda-13" href="../hunch_net-2012/hunch_net-2012-05-12-ICML_accepted_papers_and_early_registration.html">465 hunch net-2012-05-12-ICML accepted papers and early registration</a></p>
<p>14 0.91482103 <a title="270-lda-14" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>15 0.91480857 <a title="270-lda-15" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>16 0.89219302 <a title="270-lda-16" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>17 0.86712134 <a title="270-lda-17" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>18 0.85149622 <a title="270-lda-18" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>19 0.85065132 <a title="270-lda-19" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<p>20 0.84903926 <a title="270-lda-20" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
