<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-238" href="#">hunch_net-2007-238</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-238-html" href="http://hunch.net/?p=261">html</a></p><p>Introduction: Last year about this time, we received a conditional accept for thesearn
paper, which asked us to reference a paper that was not reasonable to cite
because there was strictly more relevant work by the same authors that we
already cited. We wrote a response explaining this, and didn't cite it in the
final draft, giving the SPC an excuse toreject the paper, leading to
unhappiness for all.Later,Sanjoy Dasguptasuggested that an alternative was to
talk to the PC chair instead, as soon as you see that a conditional accept is
unreasonable.William Cohenand I spoke about this by email, the relevant bit of
which is:If an SPC asks for a revision that is inappropriate, the
correctaction is to contact the chairs as soon as the decision is made,clearly
explaining what the problem is, so we can decide whether ornot to over-rule
the SPC. As you say, this is extra work for uschairs, but that's part of the
job, and we're willing to do that sortof work to improve the overall quality
of the reviewing proc</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Last year about this time, we received a conditional accept for thesearn paper, which asked us to reference a paper that was not reasonable to cite because there was strictly more relevant work by the same authors that we already cited. [sent-1, score-1.731]
</p><p>2 We wrote a response explaining this, and didn't cite it in the final draft, giving the SPC an excuse toreject the paper, leading to unhappiness for all. [sent-2, score-1.253]
</p><p>3 Later,Sanjoy Dasguptasuggested that an alternative was to talk to the PC chair instead, as soon as you see that a conditional accept is unreasonable. [sent-3, score-0.955]
</p><p>4 William Cohenand I spoke about this by email, the relevant bit of which is:If an SPC asks for a revision that is inappropriate, the correctaction is to contact the chairs as soon as the decision is made,clearly explaining what the problem is, so we can decide whether ornot to over-rule the SPC. [sent-4, score-1.21]
</p><p>5 As you say, this is extra work for uschairs, but that's part of the job, and we're willing to do that sortof work to improve the overall quality of the reviewing process andthe conference. [sent-5, score-0.754]
</p><p>6 At the time, I operated under the belief that the PC chair's job was simply too heavy to bother with something like this, but that was wrong. [sent-7, score-0.512]
</p><p>7 William invited me to post this, and I hope we all learn a little bit from it. [sent-8, score-0.172]
</p><p>8 Obviously, this should only be used if there is a real flaw in the conditions for a conditional accept paper. [sent-9, score-0.705]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cite', 0.272), ('spc', 0.272), ('conditional', 0.249), ('accept', 0.242), ('explaining', 0.213), ('pc', 0.198), ('soon', 0.194), ('chair', 0.18), ('job', 0.171), ('paper', 0.154), ('andthe', 0.147), ('spoke', 0.147), ('unhappiness', 0.147), ('bother', 0.136), ('excuse', 0.136), ('wrote', 0.136), ('sanjoy', 0.136), ('strictly', 0.136), ('william', 0.136), ('relevant', 0.13), ('heavy', 0.128), ('asks', 0.122), ('received', 0.122), ('contact', 0.118), ('draft', 0.113), ('flaw', 0.11), ('decide', 0.11), ('conditions', 0.104), ('willing', 0.104), ('leading', 0.101), ('work', 0.097), ('reference', 0.093), ('asked', 0.091), ('alternative', 0.09), ('email', 0.09), ('bit', 0.089), ('response', 0.088), ('chairs', 0.087), ('obviously', 0.084), ('invited', 0.083), ('extra', 0.083), ('giving', 0.081), ('final', 0.079), ('improve', 0.078), ('belief', 0.077), ('overall', 0.077), ('authors', 0.073), ('already', 0.072), ('short', 0.071), ('reviewing', 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="238-tfidf-1" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>Introduction: Last year about this time, we received a conditional accept for thesearn
paper, which asked us to reference a paper that was not reasonable to cite
because there was strictly more relevant work by the same authors that we
already cited. We wrote a response explaining this, and didn't cite it in the
final draft, giving the SPC an excuse toreject the paper, leading to
unhappiness for all.Later,Sanjoy Dasguptasuggested that an alternative was to
talk to the PC chair instead, as soon as you see that a conditional accept is
unreasonable.William Cohenand I spoke about this by email, the relevant bit of
which is:If an SPC asks for a revision that is inappropriate, the
correctaction is to contact the chairs as soon as the decision is made,clearly
explaining what the problem is, so we can decide whether ornot to over-rule
the SPC. As you say, this is extra work for uschairs, but that's part of the
job, and we're willing to do that sortof work to improve the overall quality
of the reviewing proc</p><p>2 0.20592406 <a title="238-tfidf-2" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>Introduction: This is a very difficult post to write, because it is about a perenially
touchy subject. Nevertheless, it is an important one which needs to be thought
about carefully.There are a few things which should be understood:The system
is changing and responsive. We-the-authors are we-the-reviewers, we-the-PC,
and even we-the-NIPS-board. NIPS has implemented 'secondary program chairs',
'author response', and 'double blind reviewing' in the last few years to help
with the decision process, and more changes may happen in the future.Agreement
creates a perception of correctness. When any PC meets and makes a group
decision about a paper, there is a strong tendency for the reinforcement
inherent in a group decision to create the perception of correctness. For the
many people who have been on the NIPS PC it's reasonable to entertain a
healthy skepticism in the face of this reinforcing certainty.This post is
about structural problems. What problems arise because of the structure of the
process? The</p><p>3 0.14866404 <a title="238-tfidf-3" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>Introduction: Conferences exist as part of the process of doing research. They provide many
roles including "announcing research", "meeting people", and "point of
reference". Not all conferences are alike so a basic question is: "to what
extent do individual conferences attempt to aid research?" This question is
very difficult to answer in any satisfying way. What we can do is compare
details of the process across multiple conferences.CommentsThe average quality
of comments across conferences can vary dramatically. At one extreme, the
tradition in CS theory conferences is to provide essentially zero feedback. At
the other extreme, some conferences have a strong tradition of providing
detailed constructive feedback. Detailed feedback can give authors significant
guidance about how to improve research. This is the most subjective
entry.BlindVirtually all conferences offer single blind review where authors
do not know reviewers. Some also providedouble blindreview where reviewers do
not know authors. T</p><p>4 0.14583479 <a title="238-tfidf-4" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>5 0.13939813 <a title="238-tfidf-5" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>6 0.12729256 <a title="238-tfidf-6" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>7 0.12081711 <a title="238-tfidf-7" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>8 0.11534817 <a title="238-tfidf-8" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>9 0.11342163 <a title="238-tfidf-9" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>10 0.10595582 <a title="238-tfidf-10" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>11 0.10458308 <a title="238-tfidf-11" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>12 0.10011102 <a title="238-tfidf-12" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>13 0.098356791 <a title="238-tfidf-13" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>14 0.09778133 <a title="238-tfidf-14" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>15 0.097310953 <a title="238-tfidf-15" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>16 0.094095327 <a title="238-tfidf-16" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>17 0.090187401 <a title="238-tfidf-17" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>18 0.079982087 <a title="238-tfidf-18" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>19 0.079653092 <a title="238-tfidf-19" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>20 0.079291649 <a title="238-tfidf-20" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.154), (1, 0.136), (2, -0.123), (3, -0.027), (4, -0.015), (5, 0.021), (6, -0.012), (7, -0.018), (8, 0.011), (9, -0.033), (10, 0.04), (11, 0.09), (12, 0.001), (13, 0.019), (14, -0.021), (15, -0.019), (16, 0.033), (17, -0.044), (18, -0.04), (19, -0.007), (20, 0.014), (21, 0.085), (22, 0.053), (23, 0.023), (24, 0.044), (25, 0.059), (26, -0.04), (27, 0.023), (28, 0.056), (29, -0.007), (30, -0.06), (31, 0.016), (32, -0.035), (33, 0.086), (34, 0.045), (35, -0.02), (36, -0.007), (37, -0.032), (38, 0.07), (39, -0.07), (40, -0.018), (41, -0.004), (42, 0.066), (43, 0.02), (44, -0.069), (45, -0.063), (46, 0.032), (47, 0.125), (48, 0.069), (49, 0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97975785 <a title="238-lsi-1" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>Introduction: Last year about this time, we received a conditional accept for thesearn
paper, which asked us to reference a paper that was not reasonable to cite
because there was strictly more relevant work by the same authors that we
already cited. We wrote a response explaining this, and didn't cite it in the
final draft, giving the SPC an excuse toreject the paper, leading to
unhappiness for all.Later,Sanjoy Dasguptasuggested that an alternative was to
talk to the PC chair instead, as soon as you see that a conditional accept is
unreasonable.William Cohenand I spoke about this by email, the relevant bit of
which is:If an SPC asks for a revision that is inappropriate, the
correctaction is to contact the chairs as soon as the decision is made,clearly
explaining what the problem is, so we can decide whether ornot to over-rule
the SPC. As you say, this is extra work for uschairs, but that's part of the
job, and we're willing to do that sortof work to improve the overall quality
of the reviewing proc</p><p>2 0.79913145 <a title="238-lsi-2" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>Introduction: This is a very difficult post to write, because it is about a perenially
touchy subject. Nevertheless, it is an important one which needs to be thought
about carefully.There are a few things which should be understood:The system
is changing and responsive. We-the-authors are we-the-reviewers, we-the-PC,
and even we-the-NIPS-board. NIPS has implemented 'secondary program chairs',
'author response', and 'double blind reviewing' in the last few years to help
with the decision process, and more changes may happen in the future.Agreement
creates a perception of correctness. When any PC meets and makes a group
decision about a paper, there is a strong tendency for the reinforcement
inherent in a group decision to create the perception of correctness. For the
many people who have been on the NIPS PC it's reasonable to entertain a
healthy skepticism in the face of this reinforcing certainty.This post is
about structural problems. What problems arise because of the structure of the
process? The</p><p>3 0.72975749 <a title="238-lsi-3" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>4 0.67440033 <a title="238-lsi-4" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>Introduction: This is a rather long post, detailing the ICML 2012 review process. The goal
is to make the process more transparent, help authors understand how we came
to a decision, and discuss the strengths and weaknesses of this process for
future conference organizers.Microsoft’s Conference Management Toolkit (CMT)We
chose to useCMTover other conference management software mainly because of its
rich toolkit. The interface is sub-optimal (to say the least!) but it has
extensive capabilities (to handle bids, author response, resubmissions, etc.),
good import/export mechanisms (to process the data elsewhere), excellent
technical support (to answer late night emails, add new functionalities).
Overall, it was the right choice, although we hope a designer will look at
that interface sometime soon!Toronto Matching System (TMS)TMSis now being used
by many major conferences in our field (including NIPS and UAI). It is an
automated system (developed byLaurent CharlinandRich Zemelat U. Toronto) to
match re</p><p>5 0.67119372 <a title="238-lsi-5" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>Introduction: Essentially everyone who writes research papers suffers rejections. They
always sting immediately, but upon further reflection many of these rejections
come to seem reasonable. Maybe the equations had too many typos or maybe the
topic just isn't as important as was originally thought. A few rejections do
not come to seem acceptable, and these form the basis of reviewing horror
stories, a great material for conversations. I've decided to share three of
mine, now all safely a bit distant in the past.Prediction Theory for
Classification Tutorial. This is a tutorial about tight sample complexity
bounds for classification that I submitted toJMLR. The first decision I heard
was a reject which appeared quite unjust to me--for example one of the
reviewers appeared to claim that all the content was in standard statistics
books. Upon further inquiry, several citations were given, none of which
actually covered the content. Later, I was shocked to hear the paper was
accepted. Apparently, the pape</p><p>6 0.65551764 <a title="238-lsi-6" href="../hunch_net-2005/hunch_net-2005-04-04-Grounds_for_Rejection.html">52 hunch net-2005-04-04-Grounds for Rejection</a></p>
<p>7 0.65117639 <a title="238-lsi-7" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>8 0.63962615 <a title="238-lsi-8" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>9 0.6315552 <a title="238-lsi-9" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>10 0.60466039 <a title="238-lsi-10" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>11 0.57930756 <a title="238-lsi-11" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>12 0.56471735 <a title="238-lsi-12" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>13 0.56036931 <a title="238-lsi-13" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>14 0.54575938 <a title="238-lsi-14" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>15 0.53933889 <a title="238-lsi-15" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>16 0.53191131 <a title="238-lsi-16" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>17 0.50975657 <a title="238-lsi-17" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>18 0.50630867 <a title="238-lsi-18" href="../hunch_net-2006/hunch_net-2006-05-21-NIPS_paper_evaluation_criteria.html">180 hunch net-2006-05-21-NIPS paper evaluation criteria</a></p>
<p>19 0.50010854 <a title="238-lsi-19" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>20 0.49926233 <a title="238-lsi-20" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(29, 0.375), (35, 0.044), (42, 0.156), (74, 0.222), (95, 0.091)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93654329 <a title="238-lda-1" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>Introduction: Last year about this time, we received a conditional accept for thesearn
paper, which asked us to reference a paper that was not reasonable to cite
because there was strictly more relevant work by the same authors that we
already cited. We wrote a response explaining this, and didn't cite it in the
final draft, giving the SPC an excuse toreject the paper, leading to
unhappiness for all.Later,Sanjoy Dasguptasuggested that an alternative was to
talk to the PC chair instead, as soon as you see that a conditional accept is
unreasonable.William Cohenand I spoke about this by email, the relevant bit of
which is:If an SPC asks for a revision that is inappropriate, the
correctaction is to contact the chairs as soon as the decision is made,clearly
explaining what the problem is, so we can decide whether ornot to over-rule
the SPC. As you say, this is extra work for uschairs, but that's part of the
job, and we're willing to do that sortof work to improve the overall quality
of the reviewing proc</p><p>2 0.90059435 <a title="238-lda-2" href="../hunch_net-2006/hunch_net-2006-07-17-A_Winner.html">197 hunch net-2006-07-17-A Winner</a></p>
<p>Introduction: Ed Snelsonwon thePredictive Uncertainty in Environmental Modelling
Competitionin the temp(erature) category usingthis algorithm. Some
characteristics of the algorithm are:Gradient descent… on about 600
parameters… with local minima… to solve regression.This bears a strong
resemblance to a neural network. The two main differences seem to be:The
system has a probabilistic interpretation (which may aid design).There are
(perhaps) fewer parameters than a typical neural network might have for the
same problem (aiding speed).</p><p>3 0.8040694 <a title="238-lda-3" href="../hunch_net-2009/hunch_net-2009-04-21-Interesting_Presentations_at_Snowbird.html">349 hunch net-2009-04-21-Interesting Presentations at Snowbird</a></p>
<p>Introduction: Here are a few of presentations interesting me at thesnowbird learningworkshop
(which, amusingly, was in Florida withAIStat).Thomas Breueldescribed machine
learning problems within OCR and an open sourceOCR software/researchplatform
with modular learning components as well has a 60Million size dataset derived
fromGoogle's scanned books.Kristen GraumanandFei-Fei Lidiscussed using active
learning with different cost labels and large datasets forimage ontology. Both
of them usedMechanical Turkas alabeling system, which looks to become routine,
at least for vision problems.Russ Tedrakediscussed using machine learning for
control, with a basic claim that it was the way to go for problems involving a
mediumReynold's numbersuch as in bird flight, where simulation is extremely
intense.Yann LeCunpresented a poster on anFPGA for convolutional neural
networksyielding a factor of 100 speedup in processing. In addition to the
graphics processor approachRajathas worked on, this seems like an effecti</p><p>4 0.79622406 <a title="238-lda-4" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><p>5 0.78669298 <a title="238-lda-5" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>Introduction: I'm skipping NIPS this year in favor ofAda, but I wanted to point outthis
paperbyAndriy MnihandGeoff Hinton. The basic claim of the paper is that by
carefully but automatically constructing a binary tree over words, it's
possible to predict words well with huge computational resource savings over
unstructured approaches.I'm interested in this beyond the application to word
prediction because it is relevant to the general normalization problem: If you
want to predict the probability of one of a large number of events, often you
must compute a predicted score for all the events and then normalize, a
computationally inefficient operation. The problem comes up in many places
using probabilistic models, but I've run into it with high-dimensional
regression.There are a couple workarounds for this computational
bug:Approximate. There are many ways. Often the approximations are
uncontrolled (i.e. can be arbitrarily bad), and hence finicky in
application.Avoid. You don't really want a probabili</p><p>6 0.65679944 <a title="238-lda-6" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>7 0.62967432 <a title="238-lda-7" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>8 0.60774219 <a title="238-lda-8" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>9 0.60586315 <a title="238-lda-9" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>10 0.58735979 <a title="238-lda-10" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>11 0.58650398 <a title="238-lda-11" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>12 0.58144647 <a title="238-lda-12" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>13 0.58127815 <a title="238-lda-13" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>14 0.57968342 <a title="238-lda-14" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>15 0.57850343 <a title="238-lda-15" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>16 0.57652432 <a title="238-lda-16" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>17 0.57623577 <a title="238-lda-17" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>18 0.57548821 <a title="238-lda-18" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>19 0.5721547 <a title="238-lda-19" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>20 0.56986755 <a title="238-lda-20" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
