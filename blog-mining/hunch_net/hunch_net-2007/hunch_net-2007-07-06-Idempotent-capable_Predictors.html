<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>253 hunch net-2007-07-06-Idempotent-capable Predictors</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-253" href="#">hunch_net-2007-253</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>253 hunch net-2007-07-06-Idempotent-capable Predictors</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-253-html" href="http://hunch.net/?p=280">html</a></p><p>Introduction: One way to distinguish different learning algorithms is by their ability or
inability to easily use an input variable as the predicted output. This is
desirable for at least two reasons:ModularityIf we want to build complex
learning systems via reuse of a subsystem, it's important to have compatible
I/O."Prior" knowledgeMachine learning is often applied in situations where we
do have some knowledge of what the right solution is, often in the form of an
existing system. In such situations, it's good to start with a learning
algorithm that can be at least as good as any existing system.When doing
classification, most learning algorithms can do this. For example, a decision
tree can split on a feature, and then classify. The real differences come up
when we attempt regression. Many of the algorithms we know and commonly use
are not idempotent predictors.Logistic regressors can not be idempotent,
because all input features are mapped through a nonlinearity.Linear regressors
can be idempote</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('idempotent', 0.573), ('input', 0.34), ('regressors', 0.236), ('split', 0.222), ('feature', 0.221), ('situations', 0.153), ('easily', 0.148), ('mapped', 0.127), ('least', 0.127), ('modular', 0.118), ('important', 0.112), ('inability', 0.111), ('features', 0.111), ('existing', 0.108), ('reuse', 0.106), ('compatible', 0.106), ('systems', 0.105), ('approaches', 0.101), ('differences', 0.092), ('distinguish', 0.09)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="253-tfidf-1" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>Introduction: One way to distinguish different learning algorithms is by their ability or
inability to easily use an input variable as the predicted output. This is
desirable for at least two reasons:ModularityIf we want to build complex
learning systems via reuse of a subsystem, it's important to have compatible
I/O."Prior" knowledgeMachine learning is often applied in situations where we
do have some knowledge of what the right solution is, often in the form of an
existing system. In such situations, it's good to start with a learning
algorithm that can be at least as good as any existing system.When doing
classification, most learning algorithms can do this. For example, a decision
tree can split on a feature, and then classify. The real differences come up
when we attempt regression. Many of the algorithms we know and commonly use
are not idempotent predictors.Logistic regressors can not be idempotent,
because all input features are mapped through a nonlinearity.Linear regressors
can be idempote</p><p>2 0.11231007 <a title="253-tfidf-2" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>Introduction: Let's suppose that we are trying to create a general purpose machine learning
box. The box is fed many examples of the function it is supposed to learn and
(hopefully) succeeds.To date, most such attempts to produce a box of this form
take a vector as input. The elements of the vector might be bits, real
numbers, or 'categorical' data (a discrete set of values).On the other hand,
there are a number of succesful applications of machine learning which do not
seem to use a vector representation as input. For example, in
vision,convolutional neural networkshave been used to solve several vision
problems. The input to the convolutional neural network is essentially the raw
camera image as amatrix. In learning for natural languages, several people
have had success on problems like parts-of-speech tagging using predictors
restricted to a window surrounding the word to be predicted.A vector window
and a matrix both imply a notion of locality which is being actively and
effectively used by thes</p><p>3 0.10414984 <a title="253-tfidf-3" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>Introduction: Let's define a learning problem as making predictions given past data. There
are several ways to attack the learning problem which seem to be equivalent to
solving the learning problem.Find the InvariantThis viewpoint says that
learning is all about learning (or incorporating) transformations of objects
that do not change the correct prediction. The best possible invariant is the
one which says "all things of the same class are the same". Finding this is
equivalent to learning. This viewpoint is particularly common when working
with image features.Feature SelectionThis viewpoint says that the way to learn
is by finding the right features to input to a learning algorithm. The best
feature is the one which is the class to predict. Finding this is equivalent
to learning for all reasonable learning algorithms. This viewpoint is common
in several applications of machine learning. SeeGilad's and Bianca's
comments.Find the RepresentationThis is almost the same as feature selection,
except int</p><p>4 0.10351089 <a title="253-tfidf-4" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>Introduction: I've had serious conversations with several people who believe that the theory
in machine learning is "only useful for getting papers published". That's a
compelling statement, as I've seen many papers where the algorithm clearly
came first, and the theoretical justification for it came second, purely as a
perceived means to improve the chance of publication.Naturally, I disagree and
believe that learning theory has much more substantial applications.Even in
core learning algorithm design, I've found learning theory to be useful,
although it's application is more subtle than many realize. The most
straightforward applications can fail, because (as expectation suggests) worst
case bounds tend to be loose in practice (*). In my experience, considering
learning theory when designing an algorithm has two important effects in
practice:It can help make your algorithm behave right at a crude level of
analysis, leaving finer details to tuning or common sense. The best example I
have of this is</p><p>5 0.10156745 <a title="253-tfidf-5" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>Introduction: One of the most confusing things about understanding learning theory is the
vast array of differing assumptions. Some critical thought about which of
these assumptions are reasonable for real-world problems may be useful.Before
we even start thinking about assumptions, it's important to realize that the
word hasmultiple meanings. The meaning used here is "assumption = axiom" (i.e.
something you can not verify).AssumptionReasonable?Which
analysis?Example/notesIndependent and Identically Distributed
DataSometimesPAC,ERM,Prediction bounds,statisticsTheKDD cup 2004 physics
datasetis plausibly IID data. There are a number of situations which are
"almost IID" in the sense that IID analysis results in correct intuitions.
Unreasonable in adversarial situations (stock market, war, etcâ&euro;Ś)Independently
Distributed DataMore than IID, but still only sometimesonline->batch
conversionLosing "identical" can be helpful in situations where you have a
cyclic process generating data.Finite exchangeability</p><p>6 0.094314389 <a title="253-tfidf-6" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>7 0.094276845 <a title="253-tfidf-7" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>8 0.093341567 <a title="253-tfidf-8" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>9 0.09127903 <a title="253-tfidf-9" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>10 0.08961606 <a title="253-tfidf-10" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>11 0.088236175 <a title="253-tfidf-11" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>12 0.088109262 <a title="253-tfidf-12" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>13 0.084196292 <a title="253-tfidf-13" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>14 0.084107101 <a title="253-tfidf-14" href="../hunch_net-2010/hunch_net-2010-08-23-Boosted_Decision_Trees_for_Deep_Learning.html">407 hunch net-2010-08-23-Boosted Decision Trees for Deep Learning</a></p>
<p>15 0.081025817 <a title="253-tfidf-15" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>16 0.080973968 <a title="253-tfidf-16" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>17 0.079321533 <a title="253-tfidf-17" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>18 0.079068944 <a title="253-tfidf-18" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>19 0.079034075 <a title="253-tfidf-19" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>20 0.079000726 <a title="253-tfidf-20" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, -0.101), (2, -0.001), (3, -0.018), (4, -0.056), (5, 0.048), (6, -0.061), (7, 0.033), (8, 0.005), (9, 0.081), (10, 0.058), (11, -0.053), (12, 0.003), (13, -0.024), (14, -0.041), (15, -0.051), (16, -0.008), (17, -0.003), (18, 0.008), (19, -0.002), (20, -0.011), (21, 0.018), (22, 0.02), (23, -0.015), (24, 0.045), (25, 0.002), (26, -0.008), (27, -0.039), (28, 0.004), (29, 0.009), (30, -0.017), (31, -0.037), (32, -0.038), (33, 0.031), (34, 0.017), (35, -0.047), (36, -0.028), (37, 0.073), (38, -0.018), (39, -0.008), (40, -0.038), (41, -0.024), (42, 0.04), (43, 0.044), (44, -0.057), (45, -0.13), (46, -0.015), (47, 0.044), (48, 0.046), (49, -0.012)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94345576 <a title="253-lsi-1" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>Introduction: One way to distinguish different learning algorithms is by their ability or
inability to easily use an input variable as the predicted output. This is
desirable for at least two reasons:ModularityIf we want to build complex
learning systems via reuse of a subsystem, it's important to have compatible
I/O."Prior" knowledgeMachine learning is often applied in situations where we
do have some knowledge of what the right solution is, often in the form of an
existing system. In such situations, it's good to start with a learning
algorithm that can be at least as good as any existing system.When doing
classification, most learning algorithms can do this. For example, a decision
tree can split on a feature, and then classify. The real differences come up
when we attempt regression. Many of the algorithms we know and commonly use
are not idempotent predictors.Logistic regressors can not be idempotent,
because all input features are mapped through a nonlinearity.Linear regressors
can be idempote</p><p>2 0.77670038 <a title="253-lsi-2" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>Introduction: One striking feature of many machine learning algorithms is the gymnastics
that designers go through to avoid symmetry breaking. In the most basic form
of machine learning, there are labeled examples composed of features. Each of
these can be treated symmetrically or asymmetrically by algorithms.feature
symmetryEvery feature is treated the same. In gradient update rules, the same
update is applied whether the feature is first or last. In metric-based
predictions, every feature is just as important in computing the
distance.example symmetryEvery example is treated the same. Batch learning
algorithms are great exemplars of this approach.label symmetryEvery label is
treated the same. This is particularly noticeable in multiclass classification
systems which predict according toarg maxlwlxbut it occurs in many other
places as well.Empirically, breaking symmetry well seems to yield great
algorithms.feature asymmetryFor those who like the "boosting is stepwise
additive regression on exponent</p><p>3 0.72762269 <a title="253-lsi-3" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>Introduction: Let's suppose that we are trying to create a general purpose machine learning
box. The box is fed many examples of the function it is supposed to learn and
(hopefully) succeeds.To date, most such attempts to produce a box of this form
take a vector as input. The elements of the vector might be bits, real
numbers, or 'categorical' data (a discrete set of values).On the other hand,
there are a number of succesful applications of machine learning which do not
seem to use a vector representation as input. For example, in
vision,convolutional neural networkshave been used to solve several vision
problems. The input to the convolutional neural network is essentially the raw
camera image as amatrix. In learning for natural languages, several people
have had success on problems like parts-of-speech tagging using predictors
restricted to a window surrounding the word to be predicted.A vector window
and a matrix both imply a notion of locality which is being actively and
effectively used by thes</p><p>4 0.70021528 <a title="253-lsi-4" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>Introduction: Let's define a learning problem as making predictions given past data. There
are several ways to attack the learning problem which seem to be equivalent to
solving the learning problem.Find the InvariantThis viewpoint says that
learning is all about learning (or incorporating) transformations of objects
that do not change the correct prediction. The best possible invariant is the
one which says "all things of the same class are the same". Finding this is
equivalent to learning. This viewpoint is particularly common when working
with image features.Feature SelectionThis viewpoint says that the way to learn
is by finding the right features to input to a learning algorithm. The best
feature is the one which is the class to predict. Finding this is equivalent
to learning for all reasonable learning algorithms. This viewpoint is common
in several applications of machine learning. SeeGilad's and Bianca's
comments.Find the RepresentationThis is almost the same as feature selection,
except int</p><p>5 0.63799328 <a title="253-lsi-5" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>Introduction: This post is about a confusion of mine with respect to many commonly used
machine learning algorithms.A simple example where this comes up is Bayes net
prediction. A Bayes net where a directed acyclic graph over a set of nodes
where each node is associated with a variable and the edges indicate
dependence. The joint probability distribution over the variables is given by
a set of conditional probabilities. For example, a very simple Bayes net might
express:P(A,B,C) = P(A | B,C)P(B)P(C)What I don't understand is the mechanism
commonly used to estimateP(A | B, C). If we letN(A,B,C)be the number of
instances ofA,B,Cthen people sometimes form an estimate according to:P'(A |
B,C) = N(A,B,C) / N /[N(B)/N * N(C)/N] = N(A,B,C) N /[N(B) N(C)]â&euro;Ś in other
words, people just estimateP'(A | B,C)according to observed relative
frequencies. This is a reasonable technique when you have a large number of
samples compared to the size spaceA x B x C, but it (naturally) falls apart
when this is not the case</p><p>6 0.63571048 <a title="253-lsi-6" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>7 0.61972874 <a title="253-lsi-7" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>8 0.61647058 <a title="253-lsi-8" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>9 0.61118841 <a title="253-lsi-9" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>10 0.61079687 <a title="253-lsi-10" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>11 0.6067608 <a title="253-lsi-11" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>12 0.59735292 <a title="253-lsi-12" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<p>13 0.59369475 <a title="253-lsi-13" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>14 0.58191979 <a title="253-lsi-14" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>15 0.58125085 <a title="253-lsi-15" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>16 0.57917941 <a title="253-lsi-16" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>17 0.56764454 <a title="253-lsi-17" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>18 0.56312299 <a title="253-lsi-18" href="../hunch_net-2005/hunch_net-2005-02-09-Intuitions_from_applied_learning.html">16 hunch net-2005-02-09-Intuitions from applied learning</a></p>
<p>19 0.55996668 <a title="253-lsi-19" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>20 0.55866659 <a title="253-lsi-20" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.033), (42, 0.261), (45, 0.493), (74, 0.074), (76, 0.012)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99769503 <a title="253-lda-1" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>Introduction: Slashdotpoints outGoogle Predict. I'm not privy to the details, but this has
the potential to be extremely useful, as in many applications simply having an
easy mechanism to apply existing learning algorithms can be extremely helpful.
This differs goalwise fromMLcomp--instead of public comparisons for research
purposes, it's about private utilization of good existing algorithms. It also
differs infrastructurally, since a system designed to do this is much less
awkward than using Amazon's cloud computing. The latter implies that datasets
several order of magnitude larger can be handled up to limits imposed by
network and storage.</p><p>2 0.99395931 <a title="253-lda-2" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>Introduction: Thesecond Netflix prize is canceleddue toprivacy problems. I continue to
believe my original assessment of this paper, that the privacy break was
somewhat overstated. I still haven't seen any serious privacy failures on the
scale of theAOL search log release.I expect privacy concerns to continue to be
a big issue when dealing with data releases by companies or governments. The
theory of maintaining privacy while using data is improving, but it is not yet
in a state where the limits of what's possible are clear let alone how to
achieve these limits in a manner friendly to a prediction competition.</p><p>3 0.99327707 <a title="253-lda-3" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>Introduction: I tweaked the site in a number of ways today, including:Updating
toWordPress1.5.Installing and heavily tweaking theGeeknichetheme. Update: I
switched back to a tweaked version of the old theme.Adding theCustomizable
Post Listingsplugin.Installing theStatTraqplugin.Updating some of the links. I
particularly recommend looking at thecomputer research
policyblog.Addingthreaded comments. This doesn't thread old comments
obviously, but the extra structure may be helpful for new ones.Overall, I
think this is an improvement, and it addresses a few of myearlier problems. If
you have any difficulties or anything seems "not quite right", please speak
up. A few other tweaks to the site may happen in the near future.</p><p>4 0.98107076 <a title="253-lda-4" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>Introduction: and I can't help but remember him.I first metSamas an undergraduate
atCaltechwhere he was TA forHopfield's class, and again when I visitedGatsby,
when he invited me to visitToronto, and at too many conferences to recount.
His personality was a combination of enthusiastic and thoughtful, with a great
ability to phrase a problem so it's solution must be understood. With respect
to my own work, Sam was the one who advised me to makemy first tutorial,
leading to others, and to other things, all of which I'm grateful to him for.
In fact, my every interaction with Sam was positive, and that was his way.His
death isbeing called a suicidewhich is so incompatible with my understanding
of Sam that it strains my credibility. But we know that his many
responsibilities were great, and it is well understood that basically all sane
researchers have legions of inner doubts. Having been depressed now and then
myself, it's helpful to understand at least intellectually that the true
darkness of the now i</p><p>5 0.97917545 <a title="253-lda-5" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>Introduction: While everyone is silently working on ICML submissions, I found this
discussion about afast physics simulatorchip interesting from a learning
viewpoint. In many cases, learning attempts to predict the outcome of physical
processes. Access to a fast simulator for these processes might be quite
helpful in predicting the outcome. Bayesian learning in particular may
directly benefit while many other algorithms (like support vector machines)
might have their speed greatly increased.The biggest drawback is that writing
software for these odd architectures is always difficult and time consuming,
but a several-orders-of-magnitude speedup might make that worthwhile.</p><p>6 0.95693815 <a title="253-lda-6" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>7 0.95401102 <a title="253-lda-7" href="../hunch_net-2009/hunch_net-2009-03-18-Parallel_ML_primitives.html">346 hunch net-2009-03-18-Parallel ML primitives</a></p>
<p>same-blog 8 0.92818767 <a title="253-lda-8" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>9 0.8927083 <a title="253-lda-9" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>10 0.68792105 <a title="253-lda-10" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>11 0.6611371 <a title="253-lda-11" href="../hunch_net-2011/hunch_net-2011-06-22-Ultra_LDA.html">436 hunch net-2011-06-22-Ultra LDA</a></p>
<p>12 0.64735329 <a title="253-lda-12" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>13 0.64603889 <a title="253-lda-13" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>14 0.63834065 <a title="253-lda-14" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>15 0.63036764 <a title="253-lda-15" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>16 0.6258347 <a title="253-lda-16" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>17 0.6214692 <a title="253-lda-17" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>18 0.62094462 <a title="253-lda-18" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>19 0.62023866 <a title="253-lda-19" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>20 0.61945987 <a title="253-lda-20" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
