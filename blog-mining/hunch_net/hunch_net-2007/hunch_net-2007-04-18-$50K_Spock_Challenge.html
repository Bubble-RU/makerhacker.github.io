<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>239 hunch net-2007-04-18-$50K Spock Challenge</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-239" href="#">hunch_net-2007-239</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>239 hunch net-2007-04-18-$50K Spock Challenge</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-239-html" href="http://hunch.net/?p=262">html</a></p><p>Introduction: Apparently, the companySpockis setting up a$50k entity resolution challenge.
$50k is much less than the Netflix challenge, but it's effectively the same as
Netflix untilsomeone reaches 10%. It's also nice that the Spock challenge has
a short duration. The (visible) test set is of size 25k and the training set
has size 75k.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Apparently, the companySpockis setting up a$50k entity resolution challenge. [sent-1, score-0.749]
</p><p>2 $50k is much less than the Netflix challenge, but it's effectively the same as Netflix untilsomeone reaches 10%. [sent-2, score-0.346]
</p><p>3 It's also nice that the Spock challenge has a short duration. [sent-3, score-0.781]
</p><p>4 The (visible) test set is of size 25k and the training set has size 75k. [sent-4, score-1.29]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('netflix', 0.459), ('challenge', 0.378), ('size', 0.326), ('entity', 0.324), ('resolution', 0.301), ('visible', 0.301), ('apparently', 0.243), ('nice', 0.186), ('set', 0.175), ('effectively', 0.169), ('short', 0.156), ('training', 0.147), ('test', 0.141), ('setting', 0.124), ('less', 0.11), ('much', 0.067), ('also', 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="239-tfidf-1" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the companySpockis setting up a$50k entity resolution challenge.
$50k is much less than the Netflix challenge, but it's effectively the same as
Netflix untilsomeone reaches 10%. It's also nice that the Spock challenge has
a short duration. The (visible) test set is of size 25k and the training set
has size 75k.</p><p>2 0.21012963 <a title="239-tfidf-2" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>Introduction: A couple security researchersclaim to have cracked the netflix dataset. The
claims of success appear somewhat overstated to me, but the method of attack
is valid and could plausibly be substantially improved so as to reveal the
movie preferences of a small fraction of Netflix users.The basic idea is to
use a heuristic similarity function between ratings in a public database (from
IMDB) and an anonymized database (Netflix) to link ratings in the private
database to public identities (in IMDB). They claim to have linked two of a
few dozen IMDB users to anonymized netflix users.The claims seem a bit
inflated to me, because (a) knowing the IMDB identity isn't equivalent to
knowing the person and (b) the claims of statistical significance are with
respect to a model of the world they created (rather than one they
created).Overall, this is another example showing that completeprivacy is
hard. It may be worth remembering that there are some substantial benefits
from the Netflix challenge as w</p><p>3 0.20036313 <a title="239-tfidf-3" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>Introduction: A $1M qualifying result was achieved on thepublic Netflix test setby a3-way
ensemble team. This is just in time forYehuda's presentation atKDD, which I'm
sure will be one of the best attended ever.This isn't quite over--there are a
few days for another super-conglomerate team to come together and there is
some small chance that the performance is nonrepresentative of the final test
set, but I expect not.Regardless of the final outcome, the biggest lesson for
ML from the Netflix contest has been the formidable performance edge of
ensemble methods.</p><p>4 0.18136796 <a title="239-tfidf-4" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>Introduction: Thespock challengefor named entity recognition waswonbyBerno Stein, Sven
Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, andMartin Potthast.</p><p>5 0.13247314 <a title="239-tfidf-5" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><p>6 0.10850404 <a title="239-tfidf-6" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>7 0.10762861 <a title="239-tfidf-7" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>8 0.098854855 <a title="239-tfidf-8" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<p>9 0.098477736 <a title="239-tfidf-9" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>10 0.094399743 <a title="239-tfidf-10" href="../hunch_net-2005/hunch_net-2005-03-28-Open_Problems_for_Colt.html">47 hunch net-2005-03-28-Open Problems for Colt</a></p>
<p>11 0.089464456 <a title="239-tfidf-11" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>12 0.077016555 <a title="239-tfidf-12" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>13 0.076885507 <a title="239-tfidf-13" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>14 0.073991254 <a title="239-tfidf-14" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>15 0.068038993 <a title="239-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>16 0.067992672 <a title="239-tfidf-16" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>17 0.065607145 <a title="239-tfidf-17" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>18 0.062942564 <a title="239-tfidf-18" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>19 0.062097184 <a title="239-tfidf-19" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>20 0.061163686 <a title="239-tfidf-20" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.076), (1, -0.044), (2, -0.005), (3, 0.025), (4, -0.014), (5, 0.08), (6, 0.043), (7, 0.019), (8, 0.068), (9, -0.083), (10, -0.197), (11, -0.012), (12, -0.174), (13, 0.04), (14, 0.07), (15, 0.097), (16, -0.069), (17, -0.056), (18, -0.09), (19, 0.027), (20, -0.017), (21, 0.139), (22, 0.054), (23, 0.006), (24, -0.115), (25, -0.023), (26, 0.018), (27, 0.005), (28, -0.093), (29, 0.124), (30, 0.056), (31, -0.001), (32, -0.035), (33, -0.024), (34, -0.019), (35, 0.054), (36, -0.01), (37, 0.066), (38, 0.044), (39, 0.07), (40, 0.101), (41, 0.008), (42, -0.061), (43, -0.013), (44, -0.076), (45, 0.089), (46, 0.07), (47, 0.026), (48, -0.043), (49, -0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9878388 <a title="239-lsi-1" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the companySpockis setting up a$50k entity resolution challenge.
$50k is much less than the Netflix challenge, but it's effectively the same as
Netflix untilsomeone reaches 10%. It's also nice that the Spock challenge has
a short duration. The (visible) test set is of size 25k and the training set
has size 75k.</p><p>2 0.75630397 <a title="239-lsi-2" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>Introduction: A $1M qualifying result was achieved on thepublic Netflix test setby a3-way
ensemble team. This is just in time forYehuda's presentation atKDD, which I'm
sure will be one of the best attended ever.This isn't quite over--there are a
few days for another super-conglomerate team to come together and there is
some small chance that the performance is nonrepresentative of the final test
set, but I expect not.Regardless of the final outcome, the biggest lesson for
ML from the Netflix contest has been the formidable performance edge of
ensemble methods.</p><p>3 0.69653457 <a title="239-lsi-3" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>Introduction: A couple security researchersclaim to have cracked the netflix dataset. The
claims of success appear somewhat overstated to me, but the method of attack
is valid and could plausibly be substantially improved so as to reveal the
movie preferences of a small fraction of Netflix users.The basic idea is to
use a heuristic similarity function between ratings in a public database (from
IMDB) and an anonymized database (Netflix) to link ratings in the private
database to public identities (in IMDB). They claim to have linked two of a
few dozen IMDB users to anonymized netflix users.The claims seem a bit
inflated to me, because (a) knowing the IMDB identity isn't equivalent to
knowing the person and (b) the claims of statistical significance are with
respect to a model of the world they created (rather than one they
created).Overall, this is another example showing that completeprivacy is
hard. It may be worth remembering that there are some substantial benefits
from the Netflix challenge as w</p><p>4 0.6024065 <a title="239-lsi-4" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><p>5 0.53861994 <a title="239-lsi-5" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>Introduction: Thespock challengefor named entity recognition waswonbyBerno Stein, Sven
Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, andMartin Potthast.</p><p>6 0.52726966 <a title="239-lsi-6" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<p>7 0.49749926 <a title="239-lsi-7" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>8 0.48235086 <a title="239-lsi-8" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>9 0.42072541 <a title="239-lsi-9" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>10 0.40971747 <a title="239-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>11 0.39447775 <a title="239-lsi-11" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>12 0.38725808 <a title="239-lsi-12" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>13 0.36922109 <a title="239-lsi-13" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>14 0.34379154 <a title="239-lsi-14" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>15 0.30847389 <a title="239-lsi-15" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>16 0.30123335 <a title="239-lsi-16" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>17 0.30044293 <a title="239-lsi-17" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>18 0.28108764 <a title="239-lsi-18" href="../hunch_net-2005/hunch_net-2005-04-14-Families_of_Learning_Theory_Statements.html">56 hunch net-2005-04-14-Families of Learning Theory Statements</a></p>
<p>19 0.26521212 <a title="239-lsi-19" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>20 0.26386771 <a title="239-lsi-20" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(12, 0.514), (35, 0.106), (42, 0.172)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91525006 <a title="239-lda-1" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the companySpockis setting up a$50k entity resolution challenge.
$50k is much less than the Netflix challenge, but it's effectively the same as
Netflix untilsomeone reaches 10%. It's also nice that the Spock challenge has
a short duration. The (visible) test set is of size 25k and the training set
has size 75k.</p><p>2 0.59199625 <a title="239-lda-2" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">324 hunch net-2008-11-09-A Healthy  COLT</a></p>
<p>Introduction: Awhile ago, we discussed the health ofCOLT.COLT 2008substantially addressed my
concerns. The papers were diverse and several were interesting. Attendance was
up, which is particularly notable in Europe. In my opinion, the colocation
with UAI and ICML was the best colocation since 1998.And, perhaps best of all,
registration ended up being free for all students due to various grants from
theAcademy of Finland,Google,IBM, andYahoo.A basic question is: what went
right? There seem to be several answers.Cost-wise, COLT had sufficient grants
to alleviate the high cost of the Euro and location at a university
substantially reduces the cost compared to a hotel.Organization-wise, the
Finns were great with hordes of volunteers helping set everything up. Having
too many volunteers is a good failure mode.Organization-wise, it was clear
that all 3 program chairs were cooperating in designing the program
.Facilities-wise, proximity in time and space made the colocation much more
real than many others</p><p>3 0.48357564 <a title="239-lda-3" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>Introduction: Hal,Daniel, and I have been working on the algorithmSearnfor structured
prediction. This was just conditionally accepted and then rejected from ICML,
and we were quite surprised. By any reasonable criteria, it seems this is an
interesting algorithm.Prediction Performance: Searn performed better than any
other algorithm on all the problems we tested against using the same feature
set. This is true even using the numbers reported by authors in their
papers.Theoretical underpinning. Searn is a reduction which comes with a
reduction guarantee: the good performance on a base classifiers implies good
performance for the overall system. No other theorem of this type has been
made for other structured prediction algorithms, as far as we know.Speed.
Searn has no problem handling much larger datasets than other algorithms we
tested against.Simplicity. Given code for a binary classifier and a problem-
specific search algorithm, only a few tens of lines are necessary to implement
Searn.Generality.</p><p>4 0.47067589 <a title="239-lda-4" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>Introduction: At NIPS I'm giving atutorial on Learning to Interact. In essence this is about
dealing with causality in a contextual bandit framework. Relative toprevious
tutorials, I'll be covering several new results that changed my understanding
of the nature of the problem. Note thatJudea PearlandElias Bareinboimhave
atutorial on causality. This might appear similar, but is quite different in
practice. Pearl and Bareinboim's tutorial will be about the general concepts
while mine will be about total mastery of the simplest nontrivial case,
including code. Luckily, they have the right order. I recommend going to bothI
also just released version 7.4 ofVowpal Wabbit. When I was a frustrated
learning theorist, I did not understand why people were not using learning
reductions to solve problems. I've been slowly discovering why with VW, and
addressing the issues. One of the issues is that machine learning itself was
not automatic enough, while another is that creating a very low overhead
process for do</p><p>5 0.35344997 <a title="239-lda-5" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>Introduction: Carnegie MellonSchool of Computer Sciencehas the first academicMachine
Learning department. This department already existed as theCenter for
Automated Learning and Discovery, but recently changed it's name.The reason
for changing the name is obvious: very few people think of themselves as
"Automated Learner and Discoverers", but there are number of people who think
of themselves as "Machine Learners". Machine learning is both more succinct
and recognizable--good properties for a name.A more interesting question is
"Should there be a Machine Learning Department?".Tom Mitchellhas a
relevantwhitepaperclaiming that machine learning is answering a different
question than other fields or departments. The fundamental debate here is "Is
machine learning different from statistics?"At a cultural level, there is no
real debate: they are different. Machine learning is characterized by several
very active large peer reviewed conferences, operating in a computer science
mode. Statistics tends to fun</p><p>6 0.34956595 <a title="239-lda-6" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>7 0.34906334 <a title="239-lda-7" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>8 0.34633842 <a title="239-lda-8" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>9 0.34473184 <a title="239-lda-9" href="../hunch_net-2006/hunch_net-2006-05-16-The_value_of_the_orthodox_view_of_Boosting.html">179 hunch net-2006-05-16-The value of the orthodox view of Boosting</a></p>
<p>10 0.33591536 <a title="239-lda-10" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>11 0.33581233 <a title="239-lda-11" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>12 0.33389992 <a title="239-lda-12" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>13 0.33088687 <a title="239-lda-13" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>14 0.33087978 <a title="239-lda-14" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>15 0.33056617 <a title="239-lda-15" href="../hunch_net-2005/hunch_net-2005-06-13-Wikis_for_Summer_Schools_and_Workshops.html">81 hunch net-2005-06-13-Wikis for Summer Schools and Workshops</a></p>
<p>16 0.32983148 <a title="239-lda-16" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>17 0.32854128 <a title="239-lda-17" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>18 0.32830983 <a title="239-lda-18" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>19 0.32736903 <a title="239-lda-19" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>20 0.3260898 <a title="239-lda-20" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
