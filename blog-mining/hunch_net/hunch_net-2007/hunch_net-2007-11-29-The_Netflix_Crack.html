<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>275 hunch net-2007-11-29-The Netflix Crack</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-275" href="#">hunch_net-2007-275</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>275 hunch net-2007-11-29-The Netflix Crack</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-275-html" href="http://hunch.net/?p=303">html</a></p><p>Introduction: A couple security researchers  claim to have cracked the netflix dataset .  The claims of success appear somewhat overstated to me, but the method of attack is valid and could plausibly be substantially improved so as to reveal the movie preferences of a small fraction of Netflix users.
 
The basic idea is to use a heuristic similarity function between ratings in a public database (from IMDB) and an anonymized database (Netflix) to link ratings in the private database to public identities (in IMDB).  They claim to have linked two of a few dozen IMDB users to anonymized netflix users.
 
The claims seem a bit inflated to me, because (a) knowing the IMDB identity isn’t equivalent to knowing the person and (b) the claims of statistical significance are with respect to a model of the world they created (rather than one they created).
 
Overall, this is another example showing that complete  privacy is hard .  It may be worth remembering that there are some substantial benefits from the Netf</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A couple security researchers  claim to have cracked the netflix dataset . [sent-1, score-0.865]
</p><p>2 The claims of success appear somewhat overstated to me, but the method of attack is valid and could plausibly be substantially improved so as to reveal the movie preferences of a small fraction of Netflix users. [sent-2, score-1.123]
</p><p>3 The basic idea is to use a heuristic similarity function between ratings in a public database (from IMDB) and an anonymized database (Netflix) to link ratings in the private database to public identities (in IMDB). [sent-3, score-2.038]
</p><p>4 They claim to have linked two of a few dozen IMDB users to anonymized netflix users. [sent-4, score-0.881]
</p><p>5 The claims seem a bit inflated to me, because (a) knowing the IMDB identity isn’t equivalent to knowing the person and (b) the claims of statistical significance are with respect to a model of the world they created (rather than one they created). [sent-5, score-1.354]
</p><p>6 Overall, this is another example showing that complete  privacy is hard . [sent-6, score-0.209]
</p><p>7 It may be worth remembering that there are some substantial benefits from the Netflix challenge as well—we (as a society) have learned something about how to do collaborative filtering which is useful beyond just recommending movies. [sent-7, score-0.548]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('imdb', 0.515), ('netflix', 0.37), ('database', 0.275), ('claims', 0.265), ('anonymized', 0.212), ('ratings', 0.2), ('knowing', 0.154), ('created', 0.124), ('public', 0.116), ('claim', 0.116), ('preferences', 0.114), ('recommending', 0.114), ('linked', 0.106), ('cracked', 0.106), ('identities', 0.106), ('movie', 0.106), ('reveal', 0.106), ('significance', 0.106), ('security', 0.095), ('similarity', 0.092), ('slashdot', 0.092), ('valid', 0.092), ('identity', 0.092), ('collaborative', 0.092), ('link', 0.088), ('society', 0.086), ('private', 0.083), ('attack', 0.081), ('filtering', 0.079), ('users', 0.077), ('benefits', 0.075), ('privacy', 0.074), ('showing', 0.07), ('beyond', 0.068), ('equivalent', 0.067), ('statistical', 0.067), ('couple', 0.066), ('fraction', 0.066), ('improved', 0.065), ('complete', 0.065), ('plausibly', 0.064), ('worth', 0.06), ('person', 0.06), ('challenge', 0.06), ('dataset', 0.058), ('overall', 0.057), ('somewhat', 0.056), ('success', 0.055), ('researchers', 0.054), ('appear', 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999976 <a title="275-tfidf-1" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>Introduction: A couple security researchers  claim to have cracked the netflix dataset .  The claims of success appear somewhat overstated to me, but the method of attack is valid and could plausibly be substantially improved so as to reveal the movie preferences of a small fraction of Netflix users.
 
The basic idea is to use a heuristic similarity function between ratings in a public database (from IMDB) and an anonymized database (Netflix) to link ratings in the private database to public identities (in IMDB).  They claim to have linked two of a few dozen IMDB users to anonymized netflix users.
 
The claims seem a bit inflated to me, because (a) knowing the IMDB identity isn’t equivalent to knowing the person and (b) the claims of statistical significance are with respect to a model of the world they created (rather than one they created).
 
Overall, this is another example showing that complete  privacy is hard .  It may be worth remembering that there are some substantial benefits from the Netf</p><p>2 0.16493101 <a title="275-tfidf-2" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced the  Netflix Prize  contest. They published a comprehensive dataset including more than 100 million movie ratings, which were performed by about 480,000 real customers on 17,770 movies. Ã‚Â   Competitors in the challenge are required to estimate a few million ratings. Ã‚Â   To win the “grand prize,” they need to deliver a 10% improvement in the prediction error compared with the results of Cinematch, Netflix’s proprietary recommender system. Best current results deliver 9.12%  improvement , which is quite close to the 10% goal, yet painfully distant. 
   Ã‚Â   The Netflix Prize breathed new life and excitement into recommender systems research. The competition allowed the wide research community to access a large scale, real life dataset. Beyond this, the competition changed the rules of the game. Claiming that your nice idea could outperform some mediocre algorithms on some toy dataset is no longer acceptable. Now researcher</p><p>3 0.14873905 <a title="275-tfidf-3" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the company  Spock  is setting up a  $50k entity resolution challenge .  $50k is much less than the Netflix challenge, but it’s effectively the same as Netflix until  someone reaches 10% .  It’s also nice that the Spock challenge has a short duration.  The (visible) test set is of size 25k and the training set has size 75k.</p><p>4 0.14548792 <a title="275-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>Introduction: This is a  paper  by Yann LeCun and Fu Jie Huang published at  AISTAT 2005 . I found this paper very difficult to read, but it does have some point about a computational shortcut.
 
This paper takes for granted that the method of solving a problem is gradient descent on parameters.  Given this assumption, the question arises: Do you want to do gradient descent on a probabilistic model or something else? 
 
All (conditional) probabilistic models have the form  p(y|x) = f(x,y)/Z(x)  where  Z(x) = sum y  f(x,y)  (the paper calls  - log f(x,y)  an “energy”).  If  f  is parameterized by some  w , the gradient has a term for  Z(x) , and hence for every value of  y .  The paper claims, that such models can be optimized for classification purposes using only the correct  y  and the other  y’ not y  which maximizes  f(x,y) .  This can even be done on unnormalizable models.  The paper further claims that this can be done with an approximate maximum.  These claims are plausible based on experimen</p><p>5 0.13639243 <a title="275-tfidf-5" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended the  Netflix prize  ceremony this morning.  The press conference part is  covered fine elsewhere , with the basic outcome being that  BellKor’s Pragmatic Chaos  won over  The Ensemble  by 15-20  minutes , because they were tied in performance on the ultimate holdout set.  I’m sure the individual participants will have many chances to speak about the solution.  One of these is Bell at the  NYAS ML symposium on Nov. 6 .
 
Several additional details may interest ML people.
  
 The degree of overfitting exhibited by the difference in performance on the  leaderboard test set  and the ultimate hold out set was small, but determining at .02 to .03%. 
 A tie was possible, because the rules cut off measurements below the fourth digit based on significance concerns.  In actuality, of course, the scores do differ before rounding, but everyone I spoke to claimed not to know how.  The complete dataset has been  released on UCI , so each team could compute their own score to whatever accu</p><p>6 0.13113762 <a title="275-tfidf-6" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>7 0.12306108 <a title="275-tfidf-7" href="../hunch_net-2009/hunch_net-2009-07-11-Interesting_papers_at_KDD.html">364 hunch net-2009-07-11-Interesting papers at KDD</a></p>
<p>8 0.098898366 <a title="275-tfidf-8" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>9 0.080913201 <a title="275-tfidf-9" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>10 0.067136906 <a title="275-tfidf-10" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>11 0.064090848 <a title="275-tfidf-11" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>12 0.063059844 <a title="275-tfidf-12" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>13 0.062750414 <a title="275-tfidf-13" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>14 0.059992932 <a title="275-tfidf-14" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>15 0.059950009 <a title="275-tfidf-15" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>16 0.055125061 <a title="275-tfidf-16" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>17 0.053820983 <a title="275-tfidf-17" href="../hunch_net-2006/hunch_net-2006-06-30-ICML_papers.html">188 hunch net-2006-06-30-ICML papers</a></p>
<p>18 0.052813735 <a title="275-tfidf-18" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>19 0.052336451 <a title="275-tfidf-19" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>20 0.051778153 <a title="275-tfidf-20" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.096), (1, -0.0), (2, -0.021), (3, 0.035), (4, -0.028), (5, 0.026), (6, -0.077), (7, 0.004), (8, -0.03), (9, -0.042), (10, -0.063), (11, 0.202), (12, -0.092), (13, 0.021), (14, -0.03), (15, 0.013), (16, -0.047), (17, 0.027), (18, 0.097), (19, -0.03), (20, -0.173), (21, -0.044), (22, -0.013), (23, -0.023), (24, -0.032), (25, -0.056), (26, -0.003), (27, -0.035), (28, -0.015), (29, 0.022), (30, 0.014), (31, -0.017), (32, -0.075), (33, 0.057), (34, -0.02), (35, -0.105), (36, 0.024), (37, -0.094), (38, 0.007), (39, -0.013), (40, 0.023), (41, -0.023), (42, -0.055), (43, 0.004), (44, -0.078), (45, -0.109), (46, 0.092), (47, -0.084), (48, -0.014), (49, 0.043)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98860395 <a title="275-lsi-1" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>Introduction: A couple security researchers  claim to have cracked the netflix dataset .  The claims of success appear somewhat overstated to me, but the method of attack is valid and could plausibly be substantially improved so as to reveal the movie preferences of a small fraction of Netflix users.
 
The basic idea is to use a heuristic similarity function between ratings in a public database (from IMDB) and an anonymized database (Netflix) to link ratings in the private database to public identities (in IMDB).  They claim to have linked two of a few dozen IMDB users to anonymized netflix users.
 
The claims seem a bit inflated to me, because (a) knowing the IMDB identity isn’t equivalent to knowing the person and (b) the claims of statistical significance are with respect to a model of the world they created (rather than one they created).
 
Overall, this is another example showing that complete  privacy is hard .  It may be worth remembering that there are some substantial benefits from the Netf</p><p>2 0.62320054 <a title="275-lsi-2" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced the  Netflix Prize  contest. They published a comprehensive dataset including more than 100 million movie ratings, which were performed by about 480,000 real customers on 17,770 movies. Ã‚Â   Competitors in the challenge are required to estimate a few million ratings. Ã‚Â   To win the “grand prize,” they need to deliver a 10% improvement in the prediction error compared with the results of Cinematch, Netflix’s proprietary recommender system. Best current results deliver 9.12%  improvement , which is quite close to the 10% goal, yet painfully distant. 
   Ã‚Â   The Netflix Prize breathed new life and excitement into recommender systems research. The competition allowed the wide research community to access a large scale, real life dataset. Beyond this, the competition changed the rules of the game. Claiming that your nice idea could outperform some mediocre algorithms on some toy dataset is no longer acceptable. Now researcher</p><p>3 0.58241904 <a title="275-lsi-3" href="../hunch_net-2009/hunch_net-2009-07-11-Interesting_papers_at_KDD.html">364 hunch net-2009-07-11-Interesting papers at KDD</a></p>
<p>Introduction: I attended  KDD  this year.  The conference has always had a strong grounding in what works based on the  KDDcup , but it has developed a halo of workshops on various subjects.  It seems that KDD has become a place where the economy meets machine learning in a stronger sense than many other conferences.
 
There were several papers that other people might like to take a look at.
  
  Yehuda Koren   Collaborative Filtering with Temporal Dynamics .  This paper describes how to incorporate temporal dynamics into a couple of collaborative filtering approaches.  This was also a best paper award. 
  D. Sculley , Robert Malkin,  Sugato Basu ,  Roberto J. Bayardo ,  Predicting Bounce Rates in Sponsored Search Advertisements .  The basic claim of this paper is that the probability people immediately leave (“bounce”) after clicking on an advertisement is predictable. 
  Frank McSherry  and  Ilya Mironov   Differentially Private Recommender Systems: Building Privacy into the Netflix Prize Contende</p><p>4 0.56636655 <a title="275-lsi-4" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the company  Spock  is setting up a  $50k entity resolution challenge .  $50k is much less than the Netflix challenge, but it’s effectively the same as Netflix until  someone reaches 10% .  It’s also nice that the Spock challenge has a short duration.  The (visible) test set is of size 25k and the training set has size 75k.</p><p>5 0.54986686 <a title="275-lsi-5" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>Introduction: A $1M qualifying result was achieved on the  public Netflix test set  by a  3-way ensemble team .  This is just in time for  Yehuda ‘s presentation at  KDD , which I’m sure will be one of the best attended ever.  
 
This isn’t quite over—there are a few days for another super-conglomerate team to come together and there is some small chance that the performance is nonrepresentative of the final test set, but I expect not.  
 
Regardless of the final outcome, the biggest lesson for ML from the Netflix contest has been the formidable performance edge of ensemble methods.</p><p>6 0.53848308 <a title="275-lsi-6" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>7 0.52801132 <a title="275-lsi-7" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>8 0.49974549 <a title="275-lsi-8" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>9 0.47595662 <a title="275-lsi-9" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>10 0.46881869 <a title="275-lsi-10" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>11 0.42573422 <a title="275-lsi-11" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>12 0.4177669 <a title="275-lsi-12" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>13 0.34961915 <a title="275-lsi-13" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>14 0.34730756 <a title="275-lsi-14" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>15 0.33960319 <a title="275-lsi-15" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>16 0.33865443 <a title="275-lsi-16" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>17 0.32307541 <a title="275-lsi-17" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>18 0.32113612 <a title="275-lsi-18" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>19 0.32098401 <a title="275-lsi-19" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>20 0.32059804 <a title="275-lsi-20" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.385), (27, 0.191), (42, 0.033), (53, 0.022), (55, 0.054), (94, 0.05), (95, 0.141)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.88914829 <a title="275-lda-1" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>Introduction: A couple security researchers  claim to have cracked the netflix dataset .  The claims of success appear somewhat overstated to me, but the method of attack is valid and could plausibly be substantially improved so as to reveal the movie preferences of a small fraction of Netflix users.
 
The basic idea is to use a heuristic similarity function between ratings in a public database (from IMDB) and an anonymized database (Netflix) to link ratings in the private database to public identities (in IMDB).  They claim to have linked two of a few dozen IMDB users to anonymized netflix users.
 
The claims seem a bit inflated to me, because (a) knowing the IMDB identity isn’t equivalent to knowing the person and (b) the claims of statistical significance are with respect to a model of the world they created (rather than one they created).
 
Overall, this is another example showing that complete  privacy is hard .  It may be worth remembering that there are some substantial benefits from the Netf</p><p>2 0.61810637 <a title="275-lda-2" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>Introduction: Here are some papers from  ICML 2008  that I found interesting.  
  
  Risi Kondor  and  Karsten Borgwardt ,  The Skew Spectrum of Graphs . This paper is about a new family of functions on graphs which is invariant under node label permutation.  They show that these quantities appear to yield good features for learning. 
  Sanjoy Dasgupta  and  Daniel Hsu .   Hierarchical sampling for active learning.   This is the first published practical consistent active learning algorithm.  The abstract is also pretty impressive. 
  Lihong Li ,  Michael Littman , and  Thomas Walsh   Knows What It Knows: A Framework For Self-Aware Learning.   This is an attempt to create learning algorithms that know when they err, (other work includes  Vovk ).  It’s not yet clear to me what the right model for  feature-dependent confidence intervals  is. 
  Novi Quadrianto ,  Alex Smola ,  TIberio Caetano , and  Quoc Viet Le   Estimating Labels from Label Proportions .  This is an example of learning in a speciali</p><p>3 0.54645926 <a title="275-lda-3" href="../hunch_net-2013/hunch_net-2013-06-10-The_Large_Scale_Learning_class_notes.html">483 hunch net-2013-06-10-The Large Scale Learning class notes</a></p>
<p>Introduction: The  large scale machine learning class  I taught with  Yann LeCun  has finished.  As I expected, it took quite a bit of time   .  We had about 25 people attending in person on average and 400 regularly watching the  recorded lectures  which is substantially more sustained interest than I expected for an advanced ML class.  We also had some fun with class projects—I’m hopeful that several will eventually turn into papers.
 
I expect there are a number of professors interested in lecturing on this and related topics.  Everyone will have their personal taste in subjects of course, but hopefully there will be some convergence to common course materials as well.  To help with this, I am making the  sources to my presentations available .  Feel free to use/improve/embelish/ridicule/etc… in the pursuit of the perfect course.</p><p>4 0.53685576 <a title="275-lda-4" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>Introduction: I have had interesting discussions about distinction between static vs. dynamic classes with  Kishore  and  Hal .  
 
The distinction arises in multiclass prediction settings.  A static set of classes is given by a set of labels  {1,…,k}  and the goal is generally to choose the most likely label given features.  The static approach is the one that we typically analyze and think about in machine learning.  
 
The dynamic setting is one that is often used in practice.  The basic idea is that the number of classes is not fixed, varying on a per example basis.  These different classes are generally defined by a choice of features.  
 
The distinction between these two settings as far as theory goes, appears to be very substantial.  For example, in the static setting, in  learning reductions land , we have techniques now for robust  O(log(k))  time prediction in many multiclass setting variants.  In the dynamic setting, the best techniques known are  O(k) , and furthermore this exponential</p><p>5 0.53402334 <a title="275-lda-5" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>Introduction: With a worldwide recession on, my impression is that the carnage in research has not been as severe as might be feared, at least in the United States.  I know of two notable negative impacts: 
  
 It’s quite difficult to get a job this year, as many companies and universities simply aren’t hiring.  This is particularly tough on graduating students. 
 Perhaps 10% of  IBM research  was fired. 
  
In contrast, around the time of the dot com bust,  ATnT Research  and  Lucent  had one or several 50% size firings wiping out much of the remainder of  Bell Labs , triggering a notable diaspora for the respected machine learning group there.  As the recession progresses, we may easily see more firings as companies in particular reach a point where they can no longer support research.
 
There are a couple positives to the recession as well.
  
 Both the implosion of Wall Street (which siphoned off smart people) and the general difficulty of getting a job coming out of an undergraduate education s</p><p>6 0.53176516 <a title="275-lda-6" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>7 0.51365405 <a title="275-lda-7" href="../hunch_net-2012/hunch_net-2012-02-24-ICML%2B50%25.html">456 hunch net-2012-02-24-ICML+50%</a></p>
<p>8 0.50668919 <a title="275-lda-8" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>9 0.49983209 <a title="275-lda-9" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>10 0.49687952 <a title="275-lda-10" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>11 0.4937253 <a title="275-lda-11" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>12 0.49267161 <a title="275-lda-12" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>13 0.49159336 <a title="275-lda-13" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>14 0.48967034 <a title="275-lda-14" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>15 0.48482695 <a title="275-lda-15" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>16 0.48334569 <a title="275-lda-16" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>17 0.48326999 <a title="275-lda-17" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>18 0.47906008 <a title="275-lda-18" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>19 0.47774753 <a title="275-lda-19" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>20 0.47745737 <a title="275-lda-20" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
