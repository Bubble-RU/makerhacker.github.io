<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-263" href="#">hunch_net-2007-263</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-263-html" href="http://hunch.net/?p=291">html</a></p><p>Introduction: I have recently completeda 500+ page-book on MDL, the first comprehensive
overview of the field (yes, this is a sneak advertisement).Chapter 17compares
MDL to a menagerie of other methods and paradigms for learning and statistics.
By far the most time (20 pages) is spent on the relation between MDL and
Bayes. My two main points here are:In sharp contrast to Bayes, MDL is by
definition based on designing universal codes for the data relative to some
given (parametric or nonparametric) probabilistic model M. By some theorems
due toAndrew Barron, MDL inferencemusttherefore be statistically consistent,
and it is immune to Bayesian inconsistency results such as those by Diaconis,
Freedman and Barron (I explain what I mean by "inconsistency" further below).
Hence, MDL must be different from Bayes!In contrast to what has sometimes been
claimed, practical MDL algorithms do have a subjective component (which in
many, but not all cases, may be implemented by something similar to a Bayesian
prior</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 My two main points here are:In sharp contrast to Bayes, MDL is by definition based on designing universal codes for the data relative to some given (parametric or nonparametric) probabilistic model M. [sent-4, score-0.771]
</p><p>2 By some theorems due toAndrew Barron, MDL inferencemusttherefore be statistically consistent, and it is immune to Bayesian inconsistency results such as those by Diaconis, Freedman and Barron (I explain what I mean by "inconsistency" further below). [sent-5, score-0.271]
</p><p>3 MDL is always based on designing a universal code L relative to some given model M. [sent-10, score-0.573]
</p><p>4 Informally this is a code such that whenever some distribution P in M can be used to compress some data set well, then L will compress this data set well as well (I'll skip the formal definition here). [sent-11, score-0.776]
</p><p>5 One method (but by no means the only method) for designing a universal code relative to model M is by taking some prior W on M and using the corresponding Shannon-Fano code, i. [sent-12, score-0.637]
</p><p>6 the code that encodes data z with lengthL(z) = - log Pbayes(z),where Pbayes(. [sent-14, score-0.238]
</p><p>7 If M is parametric, then with just about any 'smooth' prior, the Bayesian code with lengths L(z) = - log Pbayes(z) leads to a reasonable universal code. [sent-17, score-0.282]
</p><p>8 But if M is nonparametric (infinite dimensional, such as in Gaussian process regression, or histogram density estimation with an arbitrary nr of components) then many priors which are perfectly fine according to Bayesian theory are ruled out by MDL theory. [sent-18, score-0.428]
</p><p>9 The reason is that for some P in M, the Bayesian codes based on such priors do not compress data sampled from P at all, even if the amount of data tends to infinity. [sent-19, score-0.873]
</p><p>10 One can formally prove that such Bayesian codes are not "universal" according to the standard definition of universality. [sent-20, score-0.24]
</p><p>11 Now there exist two theorems by Andrew Barron (from 1991 and 1998, respectively) that directly connect data compression with frequentist statistical consistency. [sent-21, score-0.451]
</p><p>12 In essence, they imply that estimation based on universal codes mustalwaysbe statistically consistent (the theorems also directly connect the convergence rates to the amount of compression obtained). [sent-22, score-0.922]
</p><p>13 These say that, for some nonparametric models M, and with some priors on M, Bayesian inference can be inconsistent, in the sense that for some P in M, if data are i. [sent-24, score-0.52]
</p><p>14 In fact, MDL-based reasoning can also motivate certain prior choices in nonparametric contexts. [sent-29, score-0.236]
</p><p>15 Answer: because the corresponding code hasexcellentuniversal coding properties, as shown byKakade,SeegerandFoster(NIPS 2005): it has only logarithmic coding overhead if the underlying data generating process satisfies some smoothness properties; many other kernels have polynomial overhead. [sent-31, score-0.558]
</p><p>16 In general, it is often thought that different priors on M lead to codes that better compress data for some P in M, and that worse compress data for other P in M. [sent-33, score-0.915]
</p><p>17 But with nonparametric contexts, it is not like that: then there exist priors with "universally good" and "universally bad" coding properties. [sent-34, score-0.464]
</p><p>18 For example, M is the set of all Gaussian mixtures with arbitrarily many components, and P is not a Gaussian mixture, but can be arbitrarily well-approximated (in the sense of KL divergence) by a sequence of Gaussian mixtures with ever more components? [sent-40, score-0.25]
</p><p>19 it needs more data before the posterior converges than some other methods (like leave-one- out-cross-validation combined with ML estimation). [sent-43, score-0.266]
</p><p>20 Since the method is directly based on universal coding, I'm tempted to call it "MDL", but the fact that nobody in the MDL community has thought about our idea before, makes me hesitate. [sent-45, score-0.286]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mdl', 0.66), ('barron', 0.22), ('compress', 0.183), ('universal', 0.166), ('priors', 0.163), ('gaussian', 0.154), ('nonparametric', 0.146), ('bayes', 0.145), ('codes', 0.142), ('bayesian', 0.129), ('data', 0.122), ('code', 0.116), ('freedman', 0.11), ('pbayes', 0.11), ('coding', 0.109), ('inconsistency', 0.098), ('statistically', 0.098), ('compression', 0.091), ('prior', 0.09), ('consistent', 0.086), ('parametric', 0.078), ('model', 0.077), ('based', 0.076), ('relative', 0.075), ('theorems', 0.075), ('connect', 0.073), ('diaconis', 0.073), ('mixtures', 0.073), ('components', 0.073), ('estimation', 0.071), ('rbf', 0.065), ('sampled', 0.065), ('inconsistent', 0.065), ('designing', 0.063), ('kernels', 0.052), ('universally', 0.052), ('infinite', 0.052), ('arbitrarily', 0.052), ('converges', 0.052), ('corresponding', 0.05), ('converge', 0.05), ('definition', 0.05), ('according', 0.048), ('exist', 0.046), ('posterior', 0.046), ('combined', 0.046), ('properties', 0.045), ('say', 0.045), ('directly', 0.044), ('inference', 0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="263-tfidf-1" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>Introduction: I have recently completeda 500+ page-book on MDL, the first comprehensive
overview of the field (yes, this is a sneak advertisement).Chapter 17compares
MDL to a menagerie of other methods and paradigms for learning and statistics.
By far the most time (20 pages) is spent on the relation between MDL and
Bayes. My two main points here are:In sharp contrast to Bayes, MDL is by
definition based on designing universal codes for the data relative to some
given (parametric or nonparametric) probabilistic model M. By some theorems
due toAndrew Barron, MDL inferencemusttherefore be statistically consistent,
and it is immune to Bayesian inconsistency results such as those by Diaconis,
Freedman and Barron (I explain what I mean by "inconsistency" further below).
Hence, MDL must be different from Bayes!In contrast to what has sometimes been
claimed, practical MDL algorithms do have a subjective component (which in
many, but not all cases, may be implemented by something similar to a Bayesian
prior</p><p>2 0.16264668 <a title="263-tfidf-2" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>Introduction: I don't consider myself a "Bayesian", but I do try hard to understand why
Bayesian learning works. For the purposes of this post, Bayesian learning is a
simple process of:Specify a prior over world models.Integrate using Bayes law
with respect to all observed information to compute a posterior over world
models.Predict according to the posterior.Bayesian learning has many
advantages over other learning programs:InterpolationBayesian learning methods
interpolate all the way to pure engineering. When faced with any learning
problem, there is a choice of how much time and effort a human vs. a computer
puts in. (For example, the mars rover pathfinding algorithms are almost
entirely engineered.) When creating an engineered system, you build a model of
the world and then find a good controller in that model. Bayesian methods
interpolate to this extreme because the Bayesian prior can be a delta function
on one model of the world. What this means is that a recipe of "think harder"
(about speci</p><p>3 0.14124981 <a title="263-tfidf-3" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>Introduction: An argument is sometimes made that the Bayesian way is the "right" way to do
machine learning. This is a serious argument which deserves a serious reply.
The approximation argument is a serious reply for which I have not yet seen a
reply2.The idea for the Bayesian approach is quite simple, elegant, and
general. Essentially, you first specify a priorP(D)over possible
processesDproducing the data, observe the data, then condition on the data
according to Bayes law to construct a posterior:P(D|x) = P(x|D)P(D)/P(x)After
this, hard decisions are made (such as "turn left" or "turn right") by
choosing the one which minimizes the expected (with respect to the posterior)
loss.This basic idea is reused thousands of times with various choices
ofP(D)and loss functions which is unsurprising given the many nice
properties:There is an extremely strong associated guarantee: If the actual
distribution generating the data is drawn fromP(D)there is no better method.
One way to think about this is that in</p><p>4 0.12090401 <a title="263-tfidf-4" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>Introduction: I thought this was a very good NIPS with many excellent papers. The following
are a few NIPS papers which I liked and I hope to study more carefully when I
get the chance. The list is not exhaustive and in no particular
order…Preconditioner Approximations for Probabilistic Graphical
Models.Pradeeep Ravikumar and John Lafferty.I thought the use of
preconditioner methods from solving linear systems in the context of
approximate inference was novel and interesting. The results look good and I'd
like to understand the limitations.Rodeo: Sparse nonparametric regression in
high dimensions.John Lafferty and Larry Wasserman.A very interesting approach
to feature selection in nonparametric regression from a frequentist framework.
The use of lengthscale variables in each dimension reminds me a lot of
'Automatic Relevance Determination' in Gaussian process regression -- it would
be interesting to compare Rodeo to ARD in GPs.Interpolating between types and
tokens by estimating power law generators</p><p>5 0.1078155 <a title="263-tfidf-5" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>Introduction: This is about a design flaw in several learning algorithms such as the Naive
Bayes classifier and Hidden Markov Models. A number of people are aware of it,
but it seems that not everyone is.Several learning systems have the property
that they estimate some conditional probabilitiesP(event | other events)either
explicitly or implicitly. Then, at prediction time, these learned
probabilities are multiplied together according to some formula to produce a
final prediction. The Naive Bayes classifier for binary data is the simplest
of these, so it seems like a good example.When Naive Bayes is used, a set of
probabilities of the formPr'(feature i | label)are estimated via counting
statistics and some prior. Predictions are made according to the label
maximizing:Pr'(label) * Productfeatures iPr'(feature i | label)(ThePr'notation
indicates these are estimated values.)There is nothing wrong with this method
as long as (a) the prior for the sample counts is very strong and (b) the
prior (on the c</p><p>6 0.10071217 <a title="263-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>7 0.09887179 <a title="263-tfidf-7" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>8 0.097716905 <a title="263-tfidf-8" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>9 0.0929958 <a title="263-tfidf-9" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>10 0.083437614 <a title="263-tfidf-10" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>11 0.080321431 <a title="263-tfidf-11" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>12 0.076809056 <a title="263-tfidf-12" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>13 0.076070741 <a title="263-tfidf-13" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>14 0.074436598 <a title="263-tfidf-14" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>15 0.070985377 <a title="263-tfidf-15" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>16 0.069424532 <a title="263-tfidf-16" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>17 0.06739299 <a title="263-tfidf-17" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>18 0.066359356 <a title="263-tfidf-18" href="../hunch_net-2005/hunch_net-2005-04-25-Embeddings%3A_what_are_they_good_for%3F.html">61 hunch net-2005-04-25-Embeddings: what are they good for?</a></p>
<p>19 0.066254117 <a title="263-tfidf-19" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>20 0.065046571 <a title="263-tfidf-20" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.147), (1, -0.083), (2, -0.016), (3, -0.004), (4, -0.049), (5, 0.016), (6, -0.123), (7, -0.043), (8, 0.005), (9, -0.036), (10, -0.012), (11, 0.019), (12, -0.07), (13, -0.053), (14, -0.103), (15, -0.057), (16, 0.148), (17, -0.037), (18, -0.021), (19, -0.051), (20, -0.039), (21, -0.041), (22, 0.074), (23, 0.019), (24, 0.063), (25, -0.022), (26, 0.031), (27, 0.081), (28, 0.065), (29, 0.033), (30, 0.05), (31, -0.06), (32, 0.107), (33, 0.054), (34, -0.066), (35, 0.011), (36, 0.042), (37, 0.035), (38, 0.028), (39, 0.029), (40, 0.045), (41, 0.051), (42, 0.001), (43, 0.069), (44, 0.036), (45, 0.04), (46, -0.019), (47, -0.034), (48, 0.003), (49, 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9717052 <a title="263-lsi-1" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>Introduction: I have recently completeda 500+ page-book on MDL, the first comprehensive
overview of the field (yes, this is a sneak advertisement).Chapter 17compares
MDL to a menagerie of other methods and paradigms for learning and statistics.
By far the most time (20 pages) is spent on the relation between MDL and
Bayes. My two main points here are:In sharp contrast to Bayes, MDL is by
definition based on designing universal codes for the data relative to some
given (parametric or nonparametric) probabilistic model M. By some theorems
due toAndrew Barron, MDL inferencemusttherefore be statistically consistent,
and it is immune to Bayesian inconsistency results such as those by Diaconis,
Freedman and Barron (I explain what I mean by "inconsistency" further below).
Hence, MDL must be different from Bayes!In contrast to what has sometimes been
claimed, practical MDL algorithms do have a subjective component (which in
many, but not all cases, may be implemented by something similar to a Bayesian
prior</p><p>2 0.71316582 <a title="263-lsi-2" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>Introduction: Say we have two random variablesX,Ywith mutual informationI(X,Y). Let's say we
want to represent them with a bayes net of the formX< -M->Y, such that the
entropy ofMequals the mutual information, i.e.H(M)=I(X,Y). Intuitively, we
would like our hidden state to be as simple as possible (entropy wise). The
data processing inequality means thatH(M)>=I(X,Y), so the mutual information
is a lower bound on how simple theMcould be. Furthermore, if such a
construction existed it would have a nice coding interpretation -- one could
jointly codeXandYby first coding the mutual information, then codingXwith this
mutual info (withoutY) and codingYwith this mutual info (withoutX).It turns
out that such a construction does not exist in general (ThxAlina
Beygelzimerfor a counterexample! see below for the sketch).What are the
implications of this? Well, it's hard for me to say, but it does suggest to me
that the 'generative' model philosophy might be burdened with a harder
modeling task. If all we care a</p><p>3 0.7123245 <a title="263-lsi-3" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>Introduction: An argument is sometimes made that the Bayesian way is the "right" way to do
machine learning. This is a serious argument which deserves a serious reply.
The approximation argument is a serious reply for which I have not yet seen a
reply2.The idea for the Bayesian approach is quite simple, elegant, and
general. Essentially, you first specify a priorP(D)over possible
processesDproducing the data, observe the data, then condition on the data
according to Bayes law to construct a posterior:P(D|x) = P(x|D)P(D)/P(x)After
this, hard decisions are made (such as "turn left" or "turn right") by
choosing the one which minimizes the expected (with respect to the posterior)
loss.This basic idea is reused thousands of times with various choices
ofP(D)and loss functions which is unsurprising given the many nice
properties:There is an extremely strong associated guarantee: If the actual
distribution generating the data is drawn fromP(D)there is no better method.
One way to think about this is that in</p><p>4 0.69228423 <a title="263-lsi-4" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>Introduction: This is about a design flaw in several learning algorithms such as the Naive
Bayes classifier and Hidden Markov Models. A number of people are aware of it,
but it seems that not everyone is.Several learning systems have the property
that they estimate some conditional probabilitiesP(event | other events)either
explicitly or implicitly. Then, at prediction time, these learned
probabilities are multiplied together according to some formula to produce a
final prediction. The Naive Bayes classifier for binary data is the simplest
of these, so it seems like a good example.When Naive Bayes is used, a set of
probabilities of the formPr'(feature i | label)are estimated via counting
statistics and some prior. Predictions are made according to the label
maximizing:Pr'(label) * Productfeatures iPr'(feature i | label)(ThePr'notation
indicates these are estimated values.)There is nothing wrong with this method
as long as (a) the prior for the sample counts is very strong and (b) the
prior (on the c</p><p>5 0.64961284 <a title="263-lsi-5" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>Introduction: I don't consider myself a "Bayesian", but I do try hard to understand why
Bayesian learning works. For the purposes of this post, Bayesian learning is a
simple process of:Specify a prior over world models.Integrate using Bayes law
with respect to all observed information to compute a posterior over world
models.Predict according to the posterior.Bayesian learning has many
advantages over other learning programs:InterpolationBayesian learning methods
interpolate all the way to pure engineering. When faced with any learning
problem, there is a choice of how much time and effort a human vs. a computer
puts in. (For example, the mars rover pathfinding algorithms are almost
entirely engineered.) When creating an engineered system, you build a model of
the world and then find a good controller in that model. Bayesian methods
interpolate to this extreme because the Bayesian prior can be a delta function
on one model of the world. What this means is that a recipe of "think harder"
(about speci</p><p>6 0.61325473 <a title="263-lsi-6" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>7 0.59451813 <a title="263-lsi-7" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>8 0.56663311 <a title="263-lsi-8" href="../hunch_net-2005/hunch_net-2005-04-25-Embeddings%3A_what_are_they_good_for%3F.html">61 hunch net-2005-04-25-Embeddings: what are they good for?</a></p>
<p>9 0.55677706 <a title="263-lsi-9" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>10 0.5387606 <a title="263-lsi-10" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>11 0.52908111 <a title="263-lsi-11" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>12 0.52500463 <a title="263-lsi-12" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>13 0.52407938 <a title="263-lsi-13" href="../hunch_net-2010/hunch_net-2010-08-24-Alex_Smola_starts_a_blog.html">408 hunch net-2010-08-24-Alex Smola starts a blog</a></p>
<p>14 0.51066369 <a title="263-lsi-14" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>15 0.49560302 <a title="263-lsi-15" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>16 0.49113148 <a title="263-lsi-16" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>17 0.4847137 <a title="263-lsi-17" href="../hunch_net-2005/hunch_net-2005-12-11-More_NIPS_Papers.html">139 hunch net-2005-12-11-More NIPS Papers</a></p>
<p>18 0.45988926 <a title="263-lsi-18" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>19 0.45643398 <a title="263-lsi-19" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>20 0.45551246 <a title="263-lsi-20" href="../hunch_net-2012/hunch_net-2012-10-26-ML_Symposium_and_Strata-Hadoop_World.html">475 hunch net-2012-10-26-ML Symposium and Strata-Hadoop World</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.017), (23, 0.316), (35, 0.073), (42, 0.21), (45, 0.016), (63, 0.016), (68, 0.049), (69, 0.026), (74, 0.043), (76, 0.054), (92, 0.069), (95, 0.019)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.8179242 <a title="263-lda-1" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>Introduction: I have recently completeda 500+ page-book on MDL, the first comprehensive
overview of the field (yes, this is a sneak advertisement).Chapter 17compares
MDL to a menagerie of other methods and paradigms for learning and statistics.
By far the most time (20 pages) is spent on the relation between MDL and
Bayes. My two main points here are:In sharp contrast to Bayes, MDL is by
definition based on designing universal codes for the data relative to some
given (parametric or nonparametric) probabilistic model M. By some theorems
due toAndrew Barron, MDL inferencemusttherefore be statistically consistent,
and it is immune to Bayesian inconsistency results such as those by Diaconis,
Freedman and Barron (I explain what I mean by "inconsistency" further below).
Hence, MDL must be different from Bayes!In contrast to what has sometimes been
claimed, practical MDL algorithms do have a subjective component (which in
many, but not all cases, may be implemented by something similar to a Bayesian
prior</p><p>2 0.67530888 <a title="263-lda-2" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>Introduction: This is a difficult subject to talk about for many reasons, but a discussion
may be helpful.Bad reviewing is a problem in academia. The first step in
understanding this is admitting to the problem, so here is a short list of
examples of bad reviewing.Reviewer disbelieves theorem proof (ICML), or
disbelieve theorem with a trivially false counterexample. (COLT)Reviewer
internally swaps quantifiers in a theorem, concludes it has been done before
and is trivial. (NIPS)Reviewer believes a technique will not work despite
experimental validation. (COLT)Reviewers fail to notice flaw in theorem
statement (CRYPTO).Reviewer erroneously claims that it has been done before
(NIPS, SODA, JMLR)--(complete with references!)Reviewer inverts the message of
a paper and concludes it says nothing important. (NIPS*2)Reviewer fails to
distinguish between a DAG and a tree (SODA).Reviewer is enthusiastic about
paper but clearly does not understand (ICML).Reviewer erroneously believe that
the "birthday paradox"</p><p>3 0.65852976 <a title="263-lda-3" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for thereductions
tutorialAlina,Bianca, and I are planning to do atICML. Please come, if you are
interested.Many research programs can be thought of as finding and building
new useful abstractions. The running example I'll use islearning
reductionswhere I have experience. The basic abstraction here is that we can
build a learning algorithm capable of solving classification problems up to a
small expected regret. This is used repeatedly to solve more complex
problems.In working on a new abstraction, I think you typically run into many
substantial problems of understanding, which make publishing particularly
difficult.It is difficult to seriously discuss the reason behind or mechanism
for abstraction in a conference paper with small page limits. People rarely
see such discussions and hence have little basis on which to think about new
abstractions. Another difficulty is that when building an abstraction, you
often don't know the right way to</p><p>4 0.65694237 <a title="263-lda-4" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>Introduction: Exploration is one of the big unsolved problems in machine learning. This
isn't for lack of trying--there are many models of exploration which have been
analyzed in many different ways by many different groups of people. At some
point, it is worthwhile to sit back and see what has been done across these
many models.Reinforcement Learning(1). Reinforcement learning has
traditionally focused on Markov Decision Processes where the next states'is
given by a conditional distributionP(s'|s,a)given the current statesand
actiona. The typical result here is that certain specific algorithms
controlling an agent can behave withineof optimal for horizonTexcept
forpoly(1/e,T,S,A)"wasted" experiences (with high probability). This started
withE3bySatinder SinghandMichael Kearns.Sham Kakade's thesishas significant
discussion. Extensions have typically been of the form "under extra
assumptions, we can prove more", for exampleFactored-E3andMetric-E3. (It turns
out that the number of wasted samples can b</p><p>5 0.61353743 <a title="263-lda-5" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>Introduction: Sam Roweis's comment reminds me of a more general issue that comes up in doing
research: abstractions always break.Real number's aren't. Most real numbers
can not be represented with any machine. One implication of this is that many
real-number based algorithms have difficulties when implemented with floating
point numbers.The box on your desk is not a turing machine. A turing machine
can compute anything computable, given sufficient time. A typical computer
fails terribly when the state required for the computation exceeds some
limit.Nash equilibria aren't equilibria. This comes up when trying to predict
human behavior based on the result of the equilibria computation. Often, it
doesn't work.Theprobabilityisn't. Probability is an abstraction expressing
either our lack of knowledge (the Bayesian viewpoint) or fundamental
randomization (the frequentist viewpoint). From the frequentist viewpoint the
lack of knowledge typically precludes actually knowing the fundamental
randomization. Fro</p><p>6 0.59006739 <a title="263-lda-6" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>7 0.58436275 <a title="263-lda-7" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>8 0.57525843 <a title="263-lda-8" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>9 0.57247227 <a title="263-lda-9" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>10 0.57009232 <a title="263-lda-10" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>11 0.56999016 <a title="263-lda-11" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>12 0.56965488 <a title="263-lda-12" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>13 0.56901622 <a title="263-lda-13" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>14 0.56890303 <a title="263-lda-14" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>15 0.56842333 <a title="263-lda-15" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>16 0.56599659 <a title="263-lda-16" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>17 0.56415319 <a title="263-lda-17" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>18 0.56333184 <a title="263-lda-18" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>19 0.56323731 <a title="263-lda-19" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>20 0.56209248 <a title="263-lda-20" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
