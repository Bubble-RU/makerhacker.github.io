<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>276 hunch net-2007-12-10-Learning Track of International Planning Competition</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-276" href="#">hunch_net-2007-276</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>276 hunch net-2007-12-10-Learning Track of International Planning Competition</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-276-html" href="http://hunch.net/?p=304">html</a></p><p>Introduction: The  International Planning Competition  (IPC) is a biennial event organized in the context of the  International Conference on Automated Planning and Scheduling  (ICAPS). This year, for the first time, there will a learning track of the competition. For more information you can go to the competition  web-site . 
 
The competitions are typically organized around a number of planning domains that can vary from year to year, where a planning domain is simply a class of problems that share a common action schema—e.g. Blocksworld is a well-known planning domain that contains a problem instance each possible initial tower configuration and goal configuration. Some other domains have included Logistics, Airport, Freecell, PipesWorld, and many  others . For each domain the competition includes a number of problems (say 40-50) and the planners are run on each problem with a time limit for each problem (around 30 minutes). The problems are hard enough that many problems are not solved within th</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The competitions are typically organized around a number of planning domains that can vary from year to year, where a planning domain is simply a class of problems that share a common action schema—e. [sent-4, score-1.462]
</p><p>2 Blocksworld is a well-known planning domain that contains a problem instance each possible initial tower configuration and goal configuration. [sent-6, score-0.605]
</p><p>3 Some other domains have included Logistics, Airport, Freecell, PipesWorld, and many  others . [sent-7, score-0.473]
</p><p>4 For each domain the competition includes a number of problems (say 40-50) and the planners are run on each problem with a time limit for each problem (around 30 minutes). [sent-8, score-1.289]
</p><p>5 Rather, to quote Foreigner, for these planners each problem “feels like the first time”. [sent-13, score-0.543]
</p><p>6 Perhaps one reason that planners have not incorporated learning into the competition setting is that there has not been much overlap between the ICML and ICAPS communities, although that is changing. [sent-14, score-0.775]
</p><p>7 The learning track for the 2008 competition is being designed so that learning time is not counted against planners. [sent-16, score-0.599]
</p><p>8 During the learning phase the planners will be provided with the set of domains to be used in the competition and example problems from each. [sent-18, score-1.447]
</p><p>9 The evaluation phase will be conducted like the current competition, with the exception that the learning-based planners will be allowed to read in a learned domain-specific “knowledge file” when solving the problems. [sent-19, score-0.692]
</p><p>10 This structure is designed to help answer the following question:      Do we have techniques that can leverage a learning period to outperform state-of-the-art non-learning techniques across a wide range of domains? [sent-20, score-0.534]
</p><p>11 This is not because of lack of work in the area of “learning to plan” as there has been a long history dating back to some of the early planners (see my horribly outdated  resource page  for a taste). [sent-23, score-0.475]
</p><p>12 While many of the learning approaches have shown some degree of success, the evaluations have typically been very narrow, focusing on only 2 to 3 domains and often only a few problems. [sent-24, score-0.543]
</p><p>13 The hope is that the learning track of the competition will force us to take the issue of robustness seriously and soon lead to learning systems that convincingly outperform non-learning planners across a wide range of domains given proper training experience. [sent-26, score-1.766]
</p><p>14 Recall that here the domain model is provided to us, so applying RL would mean that the domain model is used as a sort of simulator in which an RL algorithm is run. [sent-30, score-0.761]
</p><p>15 RL is particularly difficult in these domains due to the challenges in developing an appropriate representation for learning value functions and/or policies—the states can be viewed as sets of ground relational atoms, rather than the more typical n-dimensional vectors common in RL. [sent-31, score-0.645]
</p><p>16 There has been some work on applying RL to IPC-style domains (e. [sent-33, score-0.518]
</p><p>17 Training data can be generated by solving example planning problems using state-of-the-art planners perhaps using significant resources. [sent-38, score-0.856]
</p><p>18 This approach has been studied under the name  max-margin planning , but applied to a very different class of planning problems. [sent-39, score-0.556]
</p><p>19 Other work has considered applying the  Learning as Search Optimization  (LaSO) framework to IPC-style domains with some  success . [sent-40, score-0.518]
</p><p>20 Some of the challenges here are to automatically produce an appropriate feature set given a planning domain and ambiguity in the training data. [sent-41, score-0.906]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('planners', 0.475), ('domains', 0.391), ('planning', 0.278), ('domain', 0.259), ('competition', 0.25), ('applying', 0.127), ('rl', 0.121), ('phase', 0.113), ('training', 0.106), ('icaps', 0.106), ('planner', 0.106), ('problems', 0.103), ('range', 0.095), ('ambiguity', 0.094), ('wide', 0.091), ('relational', 0.087), ('competitions', 0.087), ('included', 0.082), ('track', 0.081), ('plans', 0.075), ('outperform', 0.075), ('problem', 0.068), ('organized', 0.066), ('policies', 0.066), ('time', 0.066), ('solve', 0.066), ('distinct', 0.065), ('challenges', 0.065), ('provided', 0.065), ('international', 0.063), ('techniques', 0.059), ('evaluation', 0.057), ('plan', 0.056), ('approaches', 0.055), ('designed', 0.055), ('appropriate', 0.052), ('given', 0.052), ('mean', 0.051), ('learning', 0.05), ('across', 0.05), ('policy', 0.049), ('consider', 0.049), ('within', 0.047), ('evaluations', 0.047), ('airport', 0.047), ('atoms', 0.047), ('counted', 0.047), ('conducted', 0.047), ('entered', 0.047), ('logistics', 0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="276-tfidf-1" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>Introduction: The  International Planning Competition  (IPC) is a biennial event organized in the context of the  International Conference on Automated Planning and Scheduling  (ICAPS). This year, for the first time, there will a learning track of the competition. For more information you can go to the competition  web-site . 
 
The competitions are typically organized around a number of planning domains that can vary from year to year, where a planning domain is simply a class of problems that share a common action schema—e.g. Blocksworld is a well-known planning domain that contains a problem instance each possible initial tower configuration and goal configuration. Some other domains have included Logistics, Airport, Freecell, PipesWorld, and many  others . For each domain the competition includes a number of problems (say 40-50) and the planners are run on each problem with a time limit for each problem (around 30 minutes). The problems are hard enough that many problems are not solved within th</p><p>2 0.23129165 <a title="276-tfidf-2" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<p>Introduction: The Second Annual Reinforcement Learning Competition is about to get started.  The aim of the competition is to facilitate direct comparisons between various learning methods on important and realistic domains.  This yearâ&euro;&trade;s event will feature well-known benchmark domains as well as more challenging problems of real-world complexity, such as helicopter control and robot soccer keepaway.
 
The competition begins on November 1st, 2007 when training software is released.   Results must be submitted by July 1st, 2008.  The competition will culminate in an event at ICML-08 in Helsinki, Finland, at which the winners will be announced.
 
For more information, visit   the competition website.</p><p>3 0.1230561 <a title="276-tfidf-3" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>Introduction: I wanted to expand on this  post  and some of the previous  problems/research directions  about where learning theory might make large strides.  
  
  Why theory?   The essential reason for theory is “intuition extension”.  A very good applied learning person can master some particular application domain yielding the best computer algorithms for solving that problem.  A very good theory can take the intuitions discovered by this and other applied learning people and extend them to new domains in a relatively automatic fashion.  To do this, we take these basic intuitions and try to find a mathematical model that:
 
 Explains the basic intuitions. 
 Makes new testable predictions about how to learn. 
 Succeeds in so learning. 
 

This is “intuition extension”: taking what we have learned somewhere else and applying it in new domains.  It is fundamentally useful to everyone because it increases the level of automation in solving problems.

 
  Where next for learning theory?  I like the a</p><p>4 0.10959809 <a title="276-tfidf-4" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>Introduction: Watson  convincingly beat the best champion  Jeopardy!  players.  The apparent significance of this varies hugely, depending on your background knowledge about the related machine learning, NLP, and search technology.  For a random person, this might seem evidence of serious machine intelligence, while for people working on the system itself, it probably seems like a reasonably good assemblage of existing technologies with several twists to make the entire system work.
 
Above all, I think we should congratulate the people who managed to put together and execute this project—many years of effort by a diverse set of highly skilled people were needed to make this happen.  In academia, it’s pretty difficult for one professor to assemble that quantity of talent, and in industry it’s rarely the case that such a capable group has both a worthwhile project and the support needed to pursue something like this for several years before success.
 
 Alina  invited me to the Jeopardy watching party</p><p>5 0.10940952 <a title="276-tfidf-5" href="../hunch_net-2006/hunch_net-2006-06-30-ICML_papers.html">188 hunch net-2006-06-30-ICML papers</a></p>
<p>Introduction: Here are some ICML papers which interested me.
  
  Arindam Banerjee  had a  paper  which notes that PAC-Bayes bounds, a core theorem in online learning, and the optimality of Bayesian learning statements share a core inequality in their proof. 
  Pieter Abbeel ,  Morgan Quigley  and  Andrew Y. Ng  have a  paper  discussing RL techniques for learning given a bad (but not too bad) model of the world. 
  Nina Balcan  and  Avrim Blum  have a  paper  which discusses how to learn given a similarity function rather than a kernel.  A similarity function requires less structure than a kernel, implying that a learning algorithm using a similarity function might be applied in situations where no effective kernel is evident. 
  Nathan Ratliff ,  Drew Bagnell , and  Marty Zinkevich  have a  paper  describing an algorithm which attempts to fuse A *  path planning with learning of transition costs based on human demonstration. 
  
Papers (2), (3), and (4), all seem like an initial pass at solving in</p><p>6 0.096578084 <a title="276-tfidf-6" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>7 0.095347099 <a title="276-tfidf-7" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>8 0.09530782 <a title="276-tfidf-8" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>9 0.093033783 <a title="276-tfidf-9" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>10 0.08996848 <a title="276-tfidf-10" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>11 0.084231555 <a title="276-tfidf-11" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>12 0.082890198 <a title="276-tfidf-12" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>13 0.080301464 <a title="276-tfidf-13" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>14 0.079720601 <a title="276-tfidf-14" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>15 0.079489045 <a title="276-tfidf-15" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>16 0.077644512 <a title="276-tfidf-16" href="../hunch_net-2005/hunch_net-2005-11-16-MLSS_2006.html">130 hunch net-2005-11-16-MLSS 2006</a></p>
<p>17 0.076382771 <a title="276-tfidf-17" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>18 0.075832561 <a title="276-tfidf-18" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>19 0.075777538 <a title="276-tfidf-19" href="../hunch_net-2005/hunch_net-2005-10-19-Workshop%3A_Atomic_Learning.html">124 hunch net-2005-10-19-Workshop: Atomic Learning</a></p>
<p>20 0.075532392 <a title="276-tfidf-20" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.208), (1, 0.032), (2, -0.046), (3, 0.009), (4, 0.033), (5, -0.045), (6, -0.006), (7, 0.023), (8, 0.011), (9, -0.041), (10, -0.044), (11, -0.001), (12, -0.05), (13, 0.049), (14, -0.015), (15, 0.043), (16, 0.034), (17, -0.06), (18, 0.008), (19, 0.055), (20, -0.032), (21, -0.029), (22, -0.048), (23, -0.077), (24, -0.013), (25, 0.117), (26, -0.005), (27, -0.036), (28, -0.044), (29, 0.043), (30, 0.016), (31, 0.048), (32, -0.025), (33, -0.088), (34, -0.116), (35, -0.007), (36, 0.108), (37, 0.051), (38, -0.006), (39, -0.008), (40, -0.021), (41, -0.006), (42, 0.105), (43, -0.032), (44, 0.002), (45, 0.025), (46, 0.055), (47, -0.024), (48, 0.126), (49, -0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92611092 <a title="276-lsi-1" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>Introduction: The  International Planning Competition  (IPC) is a biennial event organized in the context of the  International Conference on Automated Planning and Scheduling  (ICAPS). This year, for the first time, there will a learning track of the competition. For more information you can go to the competition  web-site . 
 
The competitions are typically organized around a number of planning domains that can vary from year to year, where a planning domain is simply a class of problems that share a common action schema—e.g. Blocksworld is a well-known planning domain that contains a problem instance each possible initial tower configuration and goal configuration. Some other domains have included Logistics, Airport, Freecell, PipesWorld, and many  others . For each domain the competition includes a number of problems (say 40-50) and the planners are run on each problem with a time limit for each problem (around 30 minutes). The problems are hard enough that many problems are not solved within th</p><p>2 0.81164235 <a title="276-lsi-2" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<p>Introduction: The Second Annual Reinforcement Learning Competition is about to get started.  The aim of the competition is to facilitate direct comparisons between various learning methods on important and realistic domains.  This yearâ&euro;&trade;s event will feature well-known benchmark domains as well as more challenging problems of real-world complexity, such as helicopter control and robot soccer keepaway.
 
The competition begins on November 1st, 2007 when training software is released.   Results must be submitted by July 1st, 2008.  The competition will culminate in an event at ICML-08 in Helsinki, Finland, at which the winners will be announced.
 
For more information, visit   the competition website.</p><p>3 0.61971611 <a title="276-lsi-3" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>Introduction: Let’s define a learning problem as making predictions given past data. There are several ways to attack the learning problem which seem to be equivalent to solving the learning problem.
  
  Find the Invariant  This viewpoint says that learning is all about learning (or incorporating) transformations of objects that do not change the correct prediction. The best possible invariant is the one which says “all things of the same class are the same”.  Finding this is equivalent to learning.  This viewpoint is particularly common when working with image features.  
  Feature Selection  This viewpoint says that the way to learn is by finding the right features to input to a learning algorithm.  The best feature is the one which is the class to predict.  Finding this is equivalent to learning for all reasonable learning algorithms.  This viewpoint is common in several  applications of machine learning.  See  Gilad’s and Bianca’s comments . 
  Find the Representation  This is almost the same a</p><p>4 0.60279298 <a title="276-lsi-4" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>Introduction: A couple years ago, Drew Bagnell and I started the  RLBench project  to setup a suite of reinforcement learning benchmark problems.  We haven’t been able to touch it (due to lack of time) for a year so the project is on hold.  Luckily, there are several other projects such as  CLSquare  and  RL-Glue  with a similar goal, and we strongly endorse their continued development.
 
I would like to explain why, especially in the context of criticism of other learning benchmarks.   For example, sometimes the  UCI Machine Learning Repository  is criticized.  There are two criticisms I know of:
  
 Learning algorithms have overfit to the problems in the repository.  It is easy to imagine a mechanism for this happening unintentionally.  Strong evidence of this would be provided by learning algorithms which perform great on the UCI machine learning repository but very badly (relative to other learning algorithms) on non-UCI learning problems.  I have seen little evidence of this but it remains a po</p><p>5 0.56930149 <a title="276-lsi-5" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>Introduction: Pieter Abbeel  presented a paper with  Andrew Ng  at  ICML  on  Exploration and Apprenticeship Learning in Reinforcement Learning .  The basic idea of this algorithm is:
  
 Collect data from a human controlling a machine. 
 Build a transition model based upon the experience. 
 Build a policy which optimizes the transition model. 
 Evaluate the policy.  If it works well, halt, otherwise add the experience into the pool and go to (2). 
  
The paper proves that this technique will converge to some policy with expected performance near human expected performance assuming the  world fits certain assumptions (MDP or linear dynamics).  
 
This general idea of apprenticeship learning (i.e. incorporating data from an expert) seems very compelling because (a) humans often learn this way and (b) much harder problems can be solved.   For (a), the notion of teaching is about transferring knowledge from an expert to novices, often via demonstration. To see (b), note that we can create intricate rei</p><p>6 0.56346065 <a title="276-lsi-6" href="../hunch_net-2006/hunch_net-2006-02-07-Pittsburgh_Mind_Reading_Competition.html">155 hunch net-2006-02-07-Pittsburgh Mind Reading Competition</a></p>
<p>7 0.55808562 <a title="276-lsi-7" href="../hunch_net-2005/hunch_net-2005-04-27-DARPA_project%3A_LAGR.html">63 hunch net-2005-04-27-DARPA project: LAGR</a></p>
<p>8 0.55361527 <a title="276-lsi-8" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>9 0.53420043 <a title="276-lsi-9" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>10 0.53159076 <a title="276-lsi-10" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>11 0.52884758 <a title="276-lsi-11" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>12 0.52497405 <a title="276-lsi-12" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>13 0.52264184 <a title="276-lsi-13" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>14 0.51936775 <a title="276-lsi-14" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>15 0.51387721 <a title="276-lsi-15" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>16 0.51343858 <a title="276-lsi-16" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>17 0.5090403 <a title="276-lsi-17" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>18 0.50837004 <a title="276-lsi-18" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>19 0.50821704 <a title="276-lsi-19" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>20 0.50784624 <a title="276-lsi-20" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.011), (9, 0.017), (27, 0.195), (37, 0.017), (38, 0.049), (48, 0.021), (53, 0.042), (55, 0.053), (64, 0.022), (67, 0.016), (94, 0.427), (95, 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99025273 <a title="276-lda-1" href="../hunch_net-2005/hunch_net-2005-06-13-Wikis_for_Summer_Schools_and_Workshops.html">81 hunch net-2005-06-13-Wikis for Summer Schools and Workshops</a></p>
<p>Introduction: Chicago ’05  ended a couple of weeks ago. This was the sixth  Machine Learning Summer School , and the second one that used a  wiki . (The first was Berder ’04, thanks to Gunnar Raetsch.) Wikis are relatively easy to set up, greatly aid social interaction, and should be used a lot more at summer schools and workshops. They can even be used as the meeting’s webpage, as a permanent record of its participants’ collaborations — see for example the wiki/website for last year’s  NVO Summer School .
 
A basic wiki is a collection of editable webpages, maintained by software called a   wiki engine . The engine used at both Berder and Chicago was  TikiWiki  — it is well documented and gets you something running fast. It uses PHP and MySQL, but doesn’t require you to know either. Tikiwiki has far more features than most wikis, as it is  really a full  Content Management System . (My thanks to Sebastian Stark for pointing this out.) Here are the features we found most useful:
  



  Bulletin boa</p><p>2 0.98944551 <a title="276-lda-2" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>Introduction: “Science” has many meanings, but one common meaning is “the  scientific method ” which is a principled method for investigating the world using the following steps:
  
 Form a hypothesis about the world. 
 Use the hypothesis to make predictions. 
 Run experiments to confirm or disprove the predictions. 
  
The ordering of these steps is very important to the scientific method.  In particular, predictions  must  be made before experiments are run.  
 
Given that we all believe in the scientific method of investigation, it may be surprising to learn that cheating is very common.  This happens for many reasons, some innocent and some not.    
  
 Drug studies.  Pharmaceutical companies make predictions about the effects of their drugs and then conduct blind clinical studies to determine their effect.  Unfortunately, they have also been caught using some of the more advanced techniques for cheating  here : including “reprobleming”, “data set selection”, and probably “overfitting by review”</p><p>3 0.98713011 <a title="276-lda-3" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>Introduction: At many points in research, you face a choice: should I keep on improving some old piece of technology or should I do something new?  For example: 
  
 Should I refine bounds to make them tighter? 
 Should I take some learning theory and turn it into a learning algorithm? 
 Should I implement the learning algorithm? 
 Should I test the learning algorithm widely? 
 Should I release the algorithm as source code? 
 Should I go see what problems people actually need to solve? 
  
The universal temptation of people attracted to research is doing something new.  That is sometimes the right decision, but is also often not.  I’d like to discuss some reasons why not.
  
  Expertise  Once expertise are developed on some subject, you are the right person to refine them. 
  What is the real problem?  Continually improving a piece of technology is a mechanism forcing you to confront this question.  In many cases, this confrontation is uncomfortable because you discover that your method has fundamen</p><p>4 0.98290193 <a title="276-lda-4" href="../hunch_net-2009/hunch_net-2009-03-18-Parallel_ML_primitives.html">346 hunch net-2009-03-18-Parallel ML primitives</a></p>
<p>Introduction: Previously, we discussed  parallel machine learning  a bit.  As parallel ML is rather difficult, I’d like to describe my thinking at the moment, and ask for advice from the rest of the world.  This is particularly relevant right now, as I’m attending a workshop tomorrow on parallel ML.
 
Parallelizing slow algorithms seems uncompelling.  Parallelizing many algorithms also seems uncompelling, because the effort required to parallelize is substantial.  This leaves the question: Which one fast algorithm is the best to parallelize?  What is a substantially different second?
 
One compellingly fast simple algorithm is online gradient descent on a linear representation.  This is the core of Leon’s  sgd  code and  Vowpal Wabbit .   Antoine Bordes  showed a variant was competitive in the  large scale learning challenge .  It’s also a decades old primitive which has been reused in many algorithms, and continues to be reused.  It also applies to online  learning  rather than just online  optimiz</p><p>5 0.98085451 <a title="276-lda-5" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notation  g(n) = O(f(n))  means that in the limit as  n  approaches infinity there exists a constant  C  such that the  g(n)  is less than  Cf(n) .
 
In learning theory, there are many statements about learning algorithms of the form “under assumptions  x , y , and  z , the classifier learned has an error rate of at most  O(f(m)) “.
 
There is one very good reason to use O(): it helps you understand the big picture and neglect the minor details which are not important in the big picture.  However, there are some important reasons not to do this as well.
  
  Unspeedup  In algorithm analysis, the use of O() for time complexity is pervasive and well-justified.  Determining the exact value of C is inherently computer architecture dependent.  (The “C” for x86 processors might differ from the “C” on PowerPC processors.)  Since many learning theorists come from a CS theory background, the O() notation is applied to generalization error.  The O() abstraction breaks here—you can not genera</p><p>6 0.96498513 <a title="276-lda-6" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>same-blog 7 0.94561249 <a title="276-lda-7" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>8 0.90428913 <a title="276-lda-8" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>9 0.85825187 <a title="276-lda-9" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>10 0.84797668 <a title="276-lda-10" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>11 0.80784512 <a title="276-lda-11" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>12 0.77868694 <a title="276-lda-12" href="../hunch_net-2005/hunch_net-2005-05-17-A_Short_Guide_to_PhD_Graduate_Study.html">73 hunch net-2005-05-17-A Short Guide to PhD Graduate Study</a></p>
<p>13 0.77527314 <a title="276-lda-13" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>14 0.77264082 <a title="276-lda-14" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>15 0.77116138 <a title="276-lda-15" href="../hunch_net-2011/hunch_net-2011-08-15-Vowpal_Wabbit_6.0.html">441 hunch net-2011-08-15-Vowpal Wabbit 6.0</a></p>
<p>16 0.76882458 <a title="276-lda-16" href="../hunch_net-2008/hunch_net-2008-07-02-Proprietary_Data_in_Academic_Research%3F.html">306 hunch net-2008-07-02-Proprietary Data in Academic Research?</a></p>
<p>17 0.76220953 <a title="276-lda-17" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>18 0.76173604 <a title="276-lda-18" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>19 0.75878471 <a title="276-lda-19" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>20 0.75800705 <a title="276-lda-20" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
