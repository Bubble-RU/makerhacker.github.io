<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>276 hunch net-2007-12-10-Learning Track of International Planning Competition</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-276" href="#">hunch_net-2007-276</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>276 hunch net-2007-12-10-Learning Track of International Planning Competition</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-276-html" href="http://hunch.net/?p=304">html</a></p><p>Introduction: TheInternational Planning Competition(IPC) is a biennial event organized in
the context of theInternational Conference on Automated Planning and
Scheduling(ICAPS). This year, for the first time, there will a learning track
of the competition. For more information you can go to the competitionweb-
site.The competitions are typically organized around a number of planning
domains that can vary from year to year, where a planning domain is simply a
class of problems that share a common action schema--e.g. Blocksworld is a
well-known planning domain that contains a problem instance each possible
initial tower configuration and goal configuration. Some other domains have
included Logistics, Airport, Freecell, PipesWorld, and manyothers. For each
domain the competition includes a number of problems (say 40-50) and the
planners are run on each problem with a time limit for each problem (around 30
minutes). The problems are hard enough that many problems are not solved
within the time limit.Giv</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('planners', 0.477), ('domains', 0.393), ('planning', 0.279), ('domain', 0.26), ('competition', 0.239), ('applying', 0.13), ('rl', 0.127), ('phase', 0.118), ('problems', 0.107), ('training', 0.106), ('icaps', 0.106), ('planner', 0.106), ('theinternational', 0.106), ('range', 0.095), ('ambiguity', 0.094), ('wide', 0.093), ('competitions', 0.087), ('plans', 0.082), ('included', 0.082), ('track', 0.082)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="276-tfidf-1" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>Introduction: TheInternational Planning Competition(IPC) is a biennial event organized in
the context of theInternational Conference on Automated Planning and
Scheduling(ICAPS). This year, for the first time, there will a learning track
of the competition. For more information you can go to the competitionweb-
site.The competitions are typically organized around a number of planning
domains that can vary from year to year, where a planning domain is simply a
class of problems that share a common action schema--e.g. Blocksworld is a
well-known planning domain that contains a problem instance each possible
initial tower configuration and goal configuration. Some other domains have
included Logistics, Airport, Freecell, PipesWorld, and manyothers. For each
domain the competition includes a number of problems (say 40-50) and the
planners are run on each problem with a time limit for each problem (around 30
minutes). The problems are hard enough that many problems are not solved
within the time limit.Giv</p><p>2 0.23317544 <a title="276-tfidf-2" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<p>Introduction: The Second Annual Reinforcement Learning Competition is about to get started.
The aim of the competition is to facilitate direct comparisons between various
learning methods on important and realistic domains. This year's event will
feature well-known benchmark domains as well as more challenging problems of
real-world complexity, such as helicopter control and robot soccer
keepaway.The competition begins on November 1st, 2007 when training software
is released. Results must be submitted by July 1st, 2008. The competition will
culminate in an event at ICML-08 in Helsinki, Finland, at which the winners
will be announced.For more information, visitthe competition website.</p><p>3 0.12122467 <a title="276-tfidf-3" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>Introduction: I wanted to expand on thispostand some of the previousproblems/research
directionsabout where learning theory might make large strides.Why theory?The
essential reason for theory is "intuition extension". A very good applied
learning person can master some particular application domain yielding the
best computer algorithms for solving that problem. A very good theory can take
the intuitions discovered by this and other applied learning people and extend
them to new domains in a relatively automatic fashion. To do this, we take
these basic intuitions and try to find a mathematical model that:Explains the
basic intuitions.Makes new testable predictions about how to learn.Succeeds in
so learning.This is "intuition extension": taking what we have learned
somewhere else and applying it in new domains. It is fundamentally useful to
everyone because it increases the level of automation in solving
problems.Where next for learning theory?I like the analogy with physics. Back
before we-the-humans</p><p>4 0.11799119 <a title="276-tfidf-4" href="../hunch_net-2006/hunch_net-2006-06-30-ICML_papers.html">188 hunch net-2006-06-30-ICML papers</a></p>
<p>Introduction: Here are some ICML papers which interested me.Arindam Banerjeehad apaperwhich
notes that PAC-Bayes bounds, a core theorem in online learning, and the
optimality of Bayesian learning statements share a core inequality in their
proof.Pieter Abbeel,Morgan QuigleyandAndrew Y. Nghave apaperdiscussing RL
techniques for learning given a bad (but not too bad) model of the world.Nina
BalcanandAvrim Blumhave apaperwhich discusses how to learn given a similarity
function rather than a kernel. A similarity function requires less structure
than a kernel, implying that a learning algorithm using a similarity function
might be applied in situations where no effective kernel is evident.Nathan
Ratliff,Drew Bagnell, andMarty Zinkevichhave apaperdescribing an algorithm
which attempts to fuse A*path planning with learning of transition costs based
on human demonstration.Papers (2), (3), and (4), all seem like an initial pass
at solving interesting problems which push the domain in which learning is
applic</p><p>5 0.10978509 <a title="276-tfidf-5" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>Introduction: Watsonconvincingly beat the best championJeopardy!players. The apparent
significance of this varies hugely, depending on your background knowledge
about the related machine learning, NLP, and search technology. For a random
person, this might seem evidence of serious machine intelligence, while for
people working on the system itself, it probably seems like a reasonably good
assemblage of existing technologies with several twists to make the entire
system work.Above all, I think we should congratulate the people who managed
to put together and execute this project--many years of effort by a diverse
set of highly skilled people were needed to make this happen. In academia,
it's pretty difficult for one professor to assemble that quantity of talent,
and in industry it's rarely the case that such a capable group has both a
worthwhile project and the support needed to pursue something like this for
several years before success.Alinainvited me to the Jeopardy watching party
atIBM, which was</p><p>6 0.10021554 <a title="276-tfidf-6" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>7 0.097871311 <a title="276-tfidf-7" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>8 0.091922119 <a title="276-tfidf-8" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>9 0.089733489 <a title="276-tfidf-9" href="../hunch_net-2005/hunch_net-2005-11-16-MLSS_2006.html">130 hunch net-2005-11-16-MLSS 2006</a></p>
<p>10 0.085562356 <a title="276-tfidf-10" href="../hunch_net-2005/hunch_net-2005-10-19-Workshop%3A_Atomic_Learning.html">124 hunch net-2005-10-19-Workshop: Atomic Learning</a></p>
<p>11 0.083589464 <a title="276-tfidf-11" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>12 0.083445147 <a title="276-tfidf-12" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>13 0.08164937 <a title="276-tfidf-13" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>14 0.080625452 <a title="276-tfidf-14" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>15 0.079710521 <a title="276-tfidf-15" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>16 0.079198003 <a title="276-tfidf-16" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>17 0.078818858 <a title="276-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>18 0.077039354 <a title="276-tfidf-18" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>19 0.076510198 <a title="276-tfidf-19" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>20 0.074451074 <a title="276-tfidf-20" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.208), (1, -0.033), (2, 0.037), (3, 0.003), (4, -0.031), (5, -0.003), (6, -0.07), (7, 0.005), (8, 0.042), (9, 0.02), (10, -0.011), (11, -0.034), (12, 0.04), (13, 0.087), (14, 0.049), (15, 0.01), (16, 0.012), (17, -0.027), (18, -0.046), (19, -0.036), (20, 0.028), (21, 0.021), (22, -0.027), (23, 0.011), (24, -0.145), (25, -0.003), (26, -0.075), (27, -0.001), (28, 0.017), (29, 0.057), (30, -0.099), (31, -0.002), (32, -0.029), (33, -0.006), (34, -0.079), (35, 0.034), (36, 0.103), (37, -0.012), (38, -0.019), (39, -0.046), (40, 0.061), (41, -0.016), (42, -0.048), (43, 0.011), (44, 0.006), (45, -0.055), (46, -0.024), (47, 0.017), (48, 0.081), (49, 0.008)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92104304 <a title="276-lsi-1" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>Introduction: TheInternational Planning Competition(IPC) is a biennial event organized in
the context of theInternational Conference on Automated Planning and
Scheduling(ICAPS). This year, for the first time, there will a learning track
of the competition. For more information you can go to the competitionweb-
site.The competitions are typically organized around a number of planning
domains that can vary from year to year, where a planning domain is simply a
class of problems that share a common action schema--e.g. Blocksworld is a
well-known planning domain that contains a problem instance each possible
initial tower configuration and goal configuration. Some other domains have
included Logistics, Airport, Freecell, PipesWorld, and manyothers. For each
domain the competition includes a number of problems (say 40-50) and the
planners are run on each problem with a time limit for each problem (around 30
minutes). The problems are hard enough that many problems are not solved
within the time limit.Giv</p><p>2 0.72567528 <a title="276-lsi-2" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<p>Introduction: The Second Annual Reinforcement Learning Competition is about to get started.
The aim of the competition is to facilitate direct comparisons between various
learning methods on important and realistic domains. This year's event will
feature well-known benchmark domains as well as more challenging problems of
real-world complexity, such as helicopter control and robot soccer
keepaway.The competition begins on November 1st, 2007 when training software
is released. Results must be submitted by July 1st, 2008. The competition will
culminate in an event at ICML-08 in Helsinki, Finland, at which the winners
will be announced.For more information, visitthe competition website.</p><p>3 0.6109159 <a title="276-lsi-3" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>Introduction: A couple years ago, Drew Bagnell and I started theRLBench projectto setup a
suite of reinforcement learning benchmark problems. We haven't been able to
touch it (due to lack of time) for a year so the project is on hold. Luckily,
there are several other projects such asCLSquareandRL-Gluewith a similar goal,
and we strongly endorse their continued development.I would like to explain
why, especially in the context of criticism of other learning benchmarks. For
example, sometimes theUCI Machine Learning Repositoryis criticized. There are
two criticisms I know of:Learning algorithms have overfit to the problems in
the repository. It is easy to imagine a mechanism for this happening
unintentionally. Strong evidence of this would be provided by learning
algorithms which perform great on the UCI machine learning repository but very
badly (relative to other learning algorithms) on non-UCI learning problems. I
have seen little evidence of this but it remains a point of concern. There is
a natur</p><p>4 0.60377103 <a title="276-lsi-4" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>Introduction: Pieter Abbeelpresented a paper withAndrew NgatICMLonExploration and
Apprenticeship Learning in Reinforcement Learning. The basic idea of this
algorithm is:Collect data from a human controlling a machine.Build a
transition model based upon the experience.Build a policy which optimizes the
transition model.Evaluate the policy. If it works well, halt, otherwise add
the experience into the pool and go to (2).The paper proves that this
technique will converge to some policy with expected performance near human
expected performance assuming the world fits certain assumptions (MDP or
linear dynamics).This general idea of apprenticeship learning (i.e.
incorporating data from an expert) seems very compelling because (a) humans
often learn this way and (b) much harder problems can be solved. For (a), the
notion of teaching is about transferring knowledge from an expert to novices,
often via demonstration. To see (b), note that we can create intricate
reinforcement learning problems where a parti</p><p>5 0.58782923 <a title="276-lsi-5" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>Introduction: At an intuitive level, the question here is "Can reinforcement learning be
solved with classification?"ProblemConstruct a reinforcement learning
algorithm with near-optimal expected sum of rewards in thedirect experience
modelgiven access to a classifier learning algorithm which has a small error
rate or regret on all posed classification problems. The definition of "posed"
here is slightly murky. I consider a problem "posed" if there is an algorithm
for constructing labeled classification examples.Past WorkThere exists
areduction of reinforcement learning to classification given a generative
model.A generative model is an inherently stronger assumption than the direct
experience model.Otherwork on learning reductionsmay be important.Several
algorithms for solving reinforcement learning in the direct experience model
exist. Most, such asE3,Factored-E3, andmetric-E3andRmaxrequire that the
observation be the state. Recent workextends this approach to POMDPs.This
problem is related topred</p><p>6 0.57518995 <a title="276-lsi-6" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>7 0.56335378 <a title="276-lsi-7" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>8 0.53838581 <a title="276-lsi-8" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>9 0.5338769 <a title="276-lsi-9" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>10 0.52652603 <a title="276-lsi-10" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>11 0.52293527 <a title="276-lsi-11" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>12 0.51762319 <a title="276-lsi-12" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>13 0.51759595 <a title="276-lsi-13" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>14 0.5152747 <a title="276-lsi-14" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>15 0.51109433 <a title="276-lsi-15" href="../hunch_net-2006/hunch_net-2006-02-27-The_Peekaboom_Dataset.html">159 hunch net-2006-02-27-The Peekaboom Dataset</a></p>
<p>16 0.50734395 <a title="276-lsi-16" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>17 0.50276667 <a title="276-lsi-17" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>18 0.49339664 <a title="276-lsi-18" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>19 0.49211913 <a title="276-lsi-19" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>20 0.49109462 <a title="276-lsi-20" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(8, 0.283), (35, 0.073), (38, 0.018), (39, 0.011), (42, 0.235), (45, 0.054), (68, 0.027), (74, 0.105), (77, 0.026), (82, 0.014), (95, 0.037)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.89850068 <a title="276-lda-1" href="../hunch_net-2011/hunch_net-2011-08-01-Interesting_papers_at_COLT_2011.html">439 hunch net-2011-08-01-Interesting papers at COLT 2011</a></p>
<p>Introduction: SinceJohndid not attendCOLTthis year, I have been volunteered to report back
on the hot stuff at this year's meeting. The conference seemed to have pretty
high quality stuff this year, and I found plenty of interesting papers on all
the three days. I'm gonna pick some of my favorites going through the program
in a chronological order.The first session on matrices seemed interesting for
two reasons. First, the papers were quite nice. But more interestingly, this
is a topic that has had a lot of presence in Statistics and Compressed sensing
literature recently. So it was good to see high-dimensional matrices finally
make their entry at COLT. The paper ofOhadandShaionCollaborative Filtering
with the Trace Norm: Learning, Bounding, and Transducingprovides non-trivial
guarantees on trace norm regularization in an agnostic setup, while Rina
andNatishow how Rademacher averages can be used to get sharper results for
matrix completion problems in their paperConcentration-Based Guarantees for
Lo</p><p>same-blog 2 0.85322642 <a title="276-lda-2" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>Introduction: TheInternational Planning Competition(IPC) is a biennial event organized in
the context of theInternational Conference on Automated Planning and
Scheduling(ICAPS). This year, for the first time, there will a learning track
of the competition. For more information you can go to the competitionweb-
site.The competitions are typically organized around a number of planning
domains that can vary from year to year, where a planning domain is simply a
class of problems that share a common action schema--e.g. Blocksworld is a
well-known planning domain that contains a problem instance each possible
initial tower configuration and goal configuration. Some other domains have
included Logistics, Airport, Freecell, PipesWorld, and manyothers. For each
domain the competition includes a number of problems (say 40-50) and the
planners are run on each problem with a time limit for each problem (around 30
minutes). The problems are hard enough that many problems are not solved
within the time limit.Giv</p><p>3 0.83459175 <a title="276-lda-3" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>Introduction: Data linkage is a problem which seems to come up in various applied machine
learning problems. I have heard it mentioned in various data mining contexts,
but it seems relatively less studied for systemic reasons.A very simple
version of the data linkage problem is a cross hospital patient record merge.
Suppose a patient (John Doe) is admitted to a hospital (General Health),
treated, and released. Later, John Doe is admitted to a second hospital
(Health General), treated, and released. Given a large number of records of
this sort, it becomes very tempting to try and predict the outcomes of
treatments. This is reasonably straightforward as a machine learning problem
if there is a shared unique identifier for John Doe used by General Health and
Health General along with time stamps. We can merge the records and create
examples of the form "Given symptoms and treatment, did the patient come back
to a hospital within the next year?" These examples could be fed into a
learning algorithm, and</p><p>4 0.82988679 <a title="276-lda-4" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>Introduction: A few weeks ago I readthis. David Blei and I spent some time thinking hard
about this a few years back (thanks to Kary Myers for pointing us to it):In
short I was thinking that Ã¢â‚¬Å“bayesian belief updatingÃ¢â‚¬Â and
Ã¢â‚¬Å“maximum entropyÃ¢â‚¬Â were two othogonal principles. But it appear
that they are not, and that they can even be in conflict !Example (from Kass
1996); consider a Die (6 sides), consider prior knowledge E[X]=3.5.Maximum
entropy leads to P(X)= (1/6, 1/6, 1/6, 1/6, 1/6, 1/6).Now consider a new piece
of evidence A=Ã¢â‚¬ÂX is an odd numberÃ¢â‚¬ÂBayesian posterior P(X|A)=
P(A|X) P(X) = (1/3, 0, 1/3, 0, 1/3, 0).But MaxEnt with the constraints
E[X]=3.5 and E[Indicator function of A]=1 leads to (.22, 0, .32, 0, .47, 0) !!
(note that E[Indicator function of A]=P(A))Indeed, for MaxEnt, because there
is no more Ã¢â‚¬Ëœ6Ã¢â‚¬Â², big numbers must be more probable to ensure an
average of 3.5. For bayesian updating, P(X|A) doesnÃ¢â‚¬â„¢t have to have a
3.5 expectation. P(X) a</p><p>5 0.77010423 <a title="276-lda-5" href="../hunch_net-2009/hunch_net-2009-12-24-Top_graduates_this_season.html">384 hunch net-2009-12-24-Top graduates this season</a></p>
<p>Introduction: I would like to point out 3 graduates this season as having my confidence they
are capable of doing great things.Daniel Hsuhas diverse papers with diverse
coauthors on {active learning, mulitlabeling, temporal learning, â&euro;Ś} each
covering new algorithms and methods of analysis. He is also a capable
programmer, having helped me with some nitty-gritty details of cluster
parallelVowpal Wabbitthis summer. He has an excellent tendency to just get
things done.Nicolas Lambertdoesn't nominally work in machine learning, but
I've found his work inelicitationrelevant nevertheless. In essence, elicitable
properties are closely related to learnable properties, and the elicitation
complexity is related to a notion of learning complexity. See theSurrogate
regret bounds paperfor some related discussion. Few people successfully work
at such a general level that it crosses fields, but he's one of them.Yisong
Yueis deeply focused on interactive learning, which he has attacked at all
levels: theory, algorit</p><p>6 0.68408662 <a title="276-lda-6" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>7 0.68397129 <a title="276-lda-7" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>8 0.68345785 <a title="276-lda-8" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>9 0.6776365 <a title="276-lda-9" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>10 0.67752105 <a title="276-lda-10" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>11 0.67609513 <a title="276-lda-11" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>12 0.67589152 <a title="276-lda-12" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>13 0.67489272 <a title="276-lda-13" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>14 0.67487156 <a title="276-lda-14" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>15 0.67308486 <a title="276-lda-15" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>16 0.67269605 <a title="276-lda-16" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>17 0.67242813 <a title="276-lda-17" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>18 0.67133856 <a title="276-lda-18" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>19 0.67102247 <a title="276-lda-19" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>20 0.67098093 <a title="276-lda-20" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
