<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>266 hunch net-2007-10-15-NIPS workshops extended to 3 days</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-266" href="#">hunch_net-2007-266</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>266 hunch net-2007-10-15-NIPS workshops extended to 3 days</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-266-html" href="http://hunch.net/?p=295">html</a></p><p>Introduction: (Unofficially, at least.)  The  Deep Learning Workshop  is being held the afternoon before the rest of the workshops in Vancouver, BC.  Separate registration is needed, and open.
 
Whatâ&euro;&trade;s happening fundamentally here is that there are too many interesting workshops to fit into 2 days.  Perhaps we can get it officially expanded to 3 days next year.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 )  The  Deep Learning Workshop  is being held the afternoon before the rest of the workshops in Vancouver, BC. [sent-2, score-1.058]
</p><p>2 Whatâ&euro;&trade;s happening fundamentally here is that there are too many interesting workshops to fit into 2 days. [sent-4, score-1.057]
</p><p>3 Perhaps we can get it officially expanded to 3 days next year. [sent-5, score-1.101]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('afternoon', 0.327), ('expanded', 0.327), ('officially', 0.327), ('workshops', 0.325), ('vancouver', 0.303), ('separate', 0.232), ('held', 0.226), ('happening', 0.221), ('days', 0.212), ('registration', 0.204), ('needed', 0.2), ('fundamentally', 0.19), ('fit', 0.185), ('rest', 0.18), ('deep', 0.149), ('next', 0.138), ('workshop', 0.127), ('perhaps', 0.102), ('year', 0.099), ('get', 0.097), ('interesting', 0.096), ('many', 0.04), ('learning', 0.019)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="266-tfidf-1" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>Introduction: (Unofficially, at least.)  The  Deep Learning Workshop  is being held the afternoon before the rest of the workshops in Vancouver, BC.  Separate registration is needed, and open.
 
Whatâ&euro;&trade;s happening fundamentally here is that there are too many interesting workshops to fit into 2 days.  Perhaps we can get it officially expanded to 3 days next year.</p><p>2 0.22154887 <a title="266-tfidf-2" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">285 hunch net-2008-01-23-Why Workshop?</a></p>
<p>Introduction: I second the  call for workshops at ICML/COLT/UAI .
 
 Several   times   before , details of why and how to run a  workshop have been mentioned.  
 
There is a simple reason to prefer workshops here: attendance.  The Helsinki colocation has placed workshops  directly between ICML and COLT/UAI , which is optimal for getting attendees from any conference.  In addition,  last year ICML had relatively few workshops  and NIPS workshops were overloaded.  In addition to  those that happened  a similar number were rejected.  The overload has strange consequences—for example,  the best attended workshop  wasn’t an official NIPS workshop.  Aside from intrinsic interest, the Deep Learning workshop benefited greatly from being off schedule.</p><p>3 0.21494839 <a title="266-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>Introduction: A good workshop is often far more interesting than the papers at a conference.  This happens because a workshop has a much tighter focus than a conference.  Since you choose the workshops fitting your interest, the increased relevance can greatly enhance the level of your interest and attention.  Roughly speaking, a workshop program consists of elements related to a subject of your interest.  The main conference program consists of elements related to someoneâ&euro;&trade;s interest (which is rarely your own).  Workshops are more about doing research while conferences are more about presenting research.  
 
Several conferences have associated workshop programs, some with deadlines due shortly.
  
 
  ICML workshops  
 Due April 1 
 
 
  IJCAI workshops  
 Deadlines Vary 
 
 
 KDD workshops 
 Not yet finalized 
 
  
Anyone going to these conferences should examine the workshops and see if any are of interest.  (If none are, then maybe you should organize one next year.)</p><p>4 0.20875052 <a title="266-tfidf-4" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>Introduction: NIPS  is the big winter conference of learning.  
  
 Paper due date: June 3rd. (Tweaked thanks to  Fei Sha .) 
 Location: Vancouver (main program) Dec. 5-8 and Whistler (workshops) Dec 9-10, BC, Canada 
  
NIPS is larger than all of the other learning conferences, partly because itâ&euro;&trade;s the only one at that time of year.  I recommend the workshops which are often quite interesting and energetic.</p><p>5 0.19480948 <a title="266-tfidf-5" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>Introduction: I’m the  workshops chair  for  ICML  this year.  As such, I would like to personally encourage people to consider running a workshop.
 
My general view of workshops is that they are excellent as opportunities to discuss and develop research directions—some of my best work has come from collaborations at workshops and several workshops have substantially altered my thinking about various problems.  My experience running workshops is that setting them up and making them fly often appears much harder than it actually is, and the workshops often come off much better than expected in the end.  Submissions are due January 18, two weeks before papers.
 
Similarly,  Ben Taskar  is looking for good  tutorials , which is complementary.  Workshops are about exploring a subject, while a tutorial is about distilling it down into an easily taught essence, a vital part of the research process.  Tutorials are due February 13, two weeks after papers.</p><p>6 0.17442963 <a title="266-tfidf-6" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>7 0.14262959 <a title="266-tfidf-7" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>8 0.13926843 <a title="266-tfidf-8" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>9 0.13751197 <a title="266-tfidf-9" href="../hunch_net-2013/hunch_net-2013-05-04-COLT_and_ICML_registration.html">482 hunch net-2013-05-04-COLT and ICML registration</a></p>
<p>10 0.12561221 <a title="266-tfidf-10" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>11 0.12103271 <a title="266-tfidf-11" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>12 0.119909 <a title="266-tfidf-12" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>13 0.11402659 <a title="266-tfidf-13" href="../hunch_net-2006/hunch_net-2006-07-25-Upcoming_conference.html">198 hunch net-2006-07-25-Upcoming conference</a></p>
<p>14 0.10414782 <a title="266-tfidf-14" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>15 0.10387145 <a title="266-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>16 0.10381509 <a title="266-tfidf-16" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>17 0.1037793 <a title="266-tfidf-17" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>18 0.10299331 <a title="266-tfidf-18" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>19 0.088845603 <a title="266-tfidf-19" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>20 0.076566428 <a title="266-tfidf-20" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.088), (1, -0.135), (2, -0.141), (3, -0.189), (4, 0.032), (5, 0.17), (6, 0.153), (7, 0.085), (8, 0.124), (9, 0.06), (10, -0.065), (11, 0.033), (12, -0.012), (13, -0.081), (14, -0.002), (15, 0.07), (16, 0.012), (17, -0.001), (18, 0.018), (19, 0.033), (20, -0.005), (21, 0.028), (22, 0.026), (23, 0.01), (24, -0.043), (25, -0.044), (26, -0.028), (27, -0.03), (28, 0.098), (29, 0.016), (30, 0.052), (31, 0.031), (32, 0.011), (33, 0.001), (34, -0.055), (35, -0.04), (36, 0.102), (37, -0.036), (38, -0.08), (39, -0.069), (40, 0.005), (41, 0.0), (42, -0.049), (43, 0.022), (44, 0.068), (45, 0.06), (46, 0.004), (47, 0.029), (48, 0.065), (49, -0.052)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.986278 <a title="266-lsi-1" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>Introduction: (Unofficially, at least.)  The  Deep Learning Workshop  is being held the afternoon before the rest of the workshops in Vancouver, BC.  Separate registration is needed, and open.
 
Whatâ&euro;&trade;s happening fundamentally here is that there are too many interesting workshops to fit into 2 days.  Perhaps we can get it officially expanded to 3 days next year.</p><p>2 0.83517522 <a title="266-lsi-2" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">285 hunch net-2008-01-23-Why Workshop?</a></p>
<p>Introduction: I second the  call for workshops at ICML/COLT/UAI .
 
 Several   times   before , details of why and how to run a  workshop have been mentioned.  
 
There is a simple reason to prefer workshops here: attendance.  The Helsinki colocation has placed workshops  directly between ICML and COLT/UAI , which is optimal for getting attendees from any conference.  In addition,  last year ICML had relatively few workshops  and NIPS workshops were overloaded.  In addition to  those that happened  a similar number were rejected.  The overload has strange consequences—for example,  the best attended workshop  wasn’t an official NIPS workshop.  Aside from intrinsic interest, the Deep Learning workshop benefited greatly from being off schedule.</p><p>3 0.73891985 <a title="266-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>Introduction: A good workshop is often far more interesting than the papers at a conference.  This happens because a workshop has a much tighter focus than a conference.  Since you choose the workshops fitting your interest, the increased relevance can greatly enhance the level of your interest and attention.  Roughly speaking, a workshop program consists of elements related to a subject of your interest.  The main conference program consists of elements related to someoneâ&euro;&trade;s interest (which is rarely your own).  Workshops are more about doing research while conferences are more about presenting research.  
 
Several conferences have associated workshop programs, some with deadlines due shortly.
  
 
  ICML workshops  
 Due April 1 
 
 
  IJCAI workshops  
 Deadlines Vary 
 
 
 KDD workshops 
 Not yet finalized 
 
  
Anyone going to these conferences should examine the workshops and see if any are of interest.  (If none are, then maybe you should organize one next year.)</p><p>4 0.73472452 <a title="266-lsi-4" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect the  NIPS 2006 workshops  to be quite interesting, and recommend going for anyone interested in machine learning research.  (Most or all of the workshops webpages can be found two links deep.)</p><p>5 0.73386168 <a title="266-lsi-5" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>Introduction: NIPS  is the big winter conference of learning.  
  
 Paper due date: June 3rd. (Tweaked thanks to  Fei Sha .) 
 Location: Vancouver (main program) Dec. 5-8 and Whistler (workshops) Dec 9-10, BC, Canada 
  
NIPS is larger than all of the other learning conferences, partly because itâ&euro;&trade;s the only one at that time of year.  I recommend the workshops which are often quite interesting and energetic.</p><p>6 0.70515078 <a title="266-lsi-6" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>7 0.63132018 <a title="266-lsi-7" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>8 0.62156194 <a title="266-lsi-8" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>9 0.57510012 <a title="266-lsi-9" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>10 0.4995144 <a title="266-lsi-10" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>11 0.49910182 <a title="266-lsi-11" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>12 0.4843412 <a title="266-lsi-12" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>13 0.48333907 <a title="266-lsi-13" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>14 0.44946334 <a title="266-lsi-14" href="../hunch_net-2013/hunch_net-2013-05-04-COLT_and_ICML_registration.html">482 hunch net-2013-05-04-COLT and ICML registration</a></p>
<p>15 0.4165028 <a title="266-lsi-15" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>16 0.3584021 <a title="266-lsi-16" href="../hunch_net-2013/hunch_net-2013-01-01-Deep_Learning_2012.html">477 hunch net-2013-01-01-Deep Learning 2012</a></p>
<p>17 0.3486723 <a title="266-lsi-17" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>18 0.34434068 <a title="266-lsi-18" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>19 0.331494 <a title="266-lsi-19" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<p>20 0.32360196 <a title="266-lsi-20" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(44, 0.622), (55, 0.194)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.84949446 <a title="266-lda-1" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>Introduction: (Unofficially, at least.)  The  Deep Learning Workshop  is being held the afternoon before the rest of the workshops in Vancouver, BC.  Separate registration is needed, and open.
 
Whatâ&euro;&trade;s happening fundamentally here is that there are too many interesting workshops to fit into 2 days.  Perhaps we can get it officially expanded to 3 days next year.</p><p>2 0.72086161 <a title="266-lda-2" href="../hunch_net-2010/hunch_net-2010-08-24-Alex_Smola_starts_a_blog.html">408 hunch net-2010-08-24-Alex Smola starts a blog</a></p>
<p>Introduction: Adventures in Data Land .</p><p>3 0.2975812 <a title="266-lda-3" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>Introduction: Adam Klivans , points out the  COLT call for papers .  The important points are: 
  
 Due Feb 13. 
 Montreal, June 18-21. 
 This year, there is author feedback.</p><p>4 0.2975812 <a title="266-lda-4" href="../hunch_net-2012/hunch_net-2012-05-12-ICML_accepted_papers_and_early_registration.html">465 hunch net-2012-05-12-ICML accepted papers and early registration</a></p>
<p>Introduction: The  accepted papers  are up in full detail.  We are still struggling with the precise program itself, but thatâ&euro;&trade;s coming along.  Also note the  May 13  deadline for  early registration  and room booking.</p><p>5 0.293208 <a title="266-lda-5" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>Introduction: The  New York Machine Learning Symposium  is October 19 with a 2 page abstract deadline due September 13 via email with subject “Machine Learning Poster Submission” sent to physicalscience@nyas.org.  Everyone is welcome to submit.  Last year’s attendance was 246 and I expect more this year.
 
The primary experiment for  ICML 2013  is multiple paper submission deadlines with rolling review cycles.  The key dates are October 1, December 15, and February 15.  This is an attempt to shift ICML further towards a journal style review process and reduce peak load.   The “not for proceedings” experiment from this year’s ICML is not continuing.
 
Edit: Fixed second ICML deadline.</p><p>6 0.28553849 <a title="266-lda-6" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>7 0.28536141 <a title="266-lda-7" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>8 0.2811726 <a title="266-lda-8" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>9 0.28052199 <a title="266-lda-9" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>10 0.27919576 <a title="266-lda-10" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>11 0.26605883 <a title="266-lda-11" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>12 0.2657581 <a title="266-lda-12" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>13 0.25642058 <a title="266-lda-13" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>14 0.24405456 <a title="266-lda-14" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>15 0.23691487 <a title="266-lda-15" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>16 0.23350315 <a title="266-lda-16" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>17 0.23244703 <a title="266-lda-17" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>18 0.23210981 <a title="266-lda-18" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>19 0.22998838 <a title="266-lda-19" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>20 0.22941905 <a title="266-lda-20" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
