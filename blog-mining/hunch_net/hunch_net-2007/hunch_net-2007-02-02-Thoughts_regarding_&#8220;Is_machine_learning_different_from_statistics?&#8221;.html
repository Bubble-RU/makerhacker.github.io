<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-230" href="#">hunch_net-2007-230</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-230-html" href="http://hunch.net/?p=250">html</a></p><p>Introduction: Given John's recent posts on CMU's new machine learning department and "Deep
Learning," I asked for an opportunity to give a computational learning theory
perspective on these issues.To my mind, the answer to the question "Are the
core problems from machine learning different from the core problems of
statistics?" is a clear Yes. The point of this post is to describe a core
problem in machine learning that is computational in nature and will appeal to
statistical learning folk (as an extreme example note that if P=NP- which, for
all we know, is true- then we would suddenly find almost all of our favorite
machine learning problems considerably more tractable).If the central question
of statistical learning theory were crudely summarized as "given a hypothesis
with a certain loss bound over a test set, how well will it generalize?" then
the central question of computational learning theory might be "how can we
find such a hypothesis efficently (e.g., in polynomial-time)?"With this in
min</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('halfspace', 0.463), ('halfspaces', 0.333), ('agnostically', 0.231), ('hypothesis', 0.185), ('provably', 0.18), ('agnostic', 0.159), ('computational', 0.159), ('output', 0.139), ('efficient', 0.131), ('statistical', 0.126), ('error', 0.123), ('respect', 0.122), ('arbitrary', 0.12), ('find', 0.113), ('posts', 0.104), ('andrej', 0.103), ('xor', 0.103), ('require', 0.102), ('let', 0.101), ('labeled', 0.093)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="230-tfidf-1" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>Introduction: Given John's recent posts on CMU's new machine learning department and "Deep
Learning," I asked for an opportunity to give a computational learning theory
perspective on these issues.To my mind, the answer to the question "Are the
core problems from machine learning different from the core problems of
statistics?" is a clear Yes. The point of this post is to describe a core
problem in machine learning that is computational in nature and will appeal to
statistical learning folk (as an extreme example note that if P=NP- which, for
all we know, is true- then we would suddenly find almost all of our favorite
machine learning problems considerably more tractable).If the central question
of statistical learning theory were crudely summarized as "given a hypothesis
with a certain loss bound over a test set, how well will it generalize?" then
the central question of computational learning theory might be "how can we
find such a hypothesis efficently (e.g., in polynomial-time)?"With this in
min</p><p>2 0.16548814 <a title="230-tfidf-2" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>Introduction: Several talks seem potentially interesting to ML folks at this year's SODA
.Maria-Florina Balcan,Avrim Blum, andAnupam Gupta,Approximate Clustering
without the Approximation. This paper gives reasonable algorithms with
provable approximation guarantees for k-median and other notions of
clustering. It's conceptually interesting, because it's the second example
I've seen where NP hardness is subverted by changing the problem definition
subtle but reasonable way. Essentially, they show that if any near-
approximation to an optimal solution is good, then it's computationally easy
to find a near-optimal solution. This subtle shift bears serious thought. A
similar one occurred inour ranking paperwith respect to minimum feedback
arcset. With two known examples, it suggests that many more NP-complete
problems might be finessed into irrelevance in this style.Yury
LifshitsandShengyu Zhang,Combinatorial Algorithms for Nearest Neighbors, Near-
Duplicates, and Small-World Design. The basic idea of</p><p>3 0.14629003 <a title="230-tfidf-3" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>Introduction: "Deep learning" is used to describe learning architectures which have
significant depth (as a circuit).One claimis that shallow architectures (one
or two layers) can not concisely represent some functions while a circuit with
more depth can concisely represent these same functions. Proving lower bounds
on the size of a circuit is substantially harder than upper bounds (which are
constructive), but some results are known.Luca Trevisan'sclass notesdetail how
XOR is not concisely representable by "AC0â&euro;ł (= constant depth unbounded fan-in
AND, OR, NOT gates). This doesn't quite prove that depth is necessary for the
representations commonly used in learning (such as a thresholded weighted
sum), but it is strongly suggestive that this is so.Examples like this are a
bit disheartening because existing algorithms for deep learning (deep belief
nets, gradient descent on deep neural networks, and a perhaps decision trees
depending on who you ask) can't learn XOR very easily. Evidence so far
sugges</p><p>4 0.13929708 <a title="230-tfidf-4" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>5 0.12735958 <a title="230-tfidf-5" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthuinvited me to the workshop onalgorithms in the field, with the goal of
providing a sense of where near-term research should go. When the time came
though, I bargained for a post instead, which provides a chance for many other
people to comment.There are several things I didn't fully understand when I
went to Yahoo! about 5 years ago. I'd like to repeat them as people in
academia may not yet understand them intuitively.Almost all the big impact
algorithms operate in pseudo-linear or better time. Think about caching,
hashing, sorting, filtering, etcâ&euro;Ś and you have a sense of what some of the
most heavily used algorithms are. This matters quite a bit to Machine Learning
research, because people often work with superlinear time algorithms and
languages. Two very common examples of this are graphical models, where
inference is often a superlinear operation--think about then2dependence on the
number of states in aHidden Markov Modeland KernelizedSupport Vector
Machineswhere optimization</p><p>6 0.12272621 <a title="230-tfidf-6" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>7 0.12201538 <a title="230-tfidf-7" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>8 0.12046134 <a title="230-tfidf-8" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>9 0.12023054 <a title="230-tfidf-9" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>10 0.11663126 <a title="230-tfidf-10" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>11 0.11201761 <a title="230-tfidf-11" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>12 0.1101016 <a title="230-tfidf-12" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<p>13 0.10547794 <a title="230-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>14 0.1050595 <a title="230-tfidf-14" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>15 0.10423085 <a title="230-tfidf-15" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>16 0.10294783 <a title="230-tfidf-16" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>17 0.10219322 <a title="230-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>18 0.099859118 <a title="230-tfidf-18" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>19 0.09831506 <a title="230-tfidf-19" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>20 0.097922601 <a title="230-tfidf-20" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.246), (1, -0.143), (2, -0.016), (3, -0.003), (4, -0.059), (5, -0.073), (6, -0.014), (7, -0.048), (8, 0.058), (9, 0.001), (10, 0.026), (11, -0.014), (12, -0.002), (13, -0.032), (14, -0.019), (15, 0.039), (16, 0.019), (17, -0.014), (18, 0.102), (19, 0.022), (20, 0.008), (21, 0.022), (22, -0.068), (23, 0.001), (24, -0.001), (25, -0.032), (26, 0.081), (27, -0.056), (28, -0.035), (29, -0.002), (30, -0.0), (31, -0.005), (32, 0.029), (33, -0.098), (34, 0.023), (35, -0.008), (36, -0.062), (37, -0.082), (38, -0.014), (39, 0.028), (40, 0.023), (41, -0.054), (42, 0.046), (43, 0.029), (44, -0.008), (45, 0.038), (46, -0.063), (47, -0.039), (48, 0.028), (49, -0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91453069 <a title="230-lsi-1" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>Introduction: Given John's recent posts on CMU's new machine learning department and "Deep
Learning," I asked for an opportunity to give a computational learning theory
perspective on these issues.To my mind, the answer to the question "Are the
core problems from machine learning different from the core problems of
statistics?" is a clear Yes. The point of this post is to describe a core
problem in machine learning that is computational in nature and will appeal to
statistical learning folk (as an extreme example note that if P=NP- which, for
all we know, is true- then we would suddenly find almost all of our favorite
machine learning problems considerably more tractable).If the central question
of statistical learning theory were crudely summarized as "given a hypothesis
with a certain loss bound over a test set, how well will it generalize?" then
the central question of computational learning theory might be "how can we
find such a hypothesis efficently (e.g., in polynomial-time)?"With this in
min</p><p>2 0.75407094 <a title="230-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>3 0.66819596 <a title="230-lsi-3" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>Introduction: A common defect of many pieces of research is defining the problem in terms of
the solution. Here are some examples in learning:"The learning problem is
finding a good seperating hyperplane.""The goal of learning is to
minimize(y-p)2+ C w2wherey= the observation,p= the prediction andw= a
parameter vector."Defining thelossfunction to be the one that your algorithm
optimizes rather than the one imposed by the world.The fundamental reason why
this is a defect is that it creates artificial boundaries to problem solution.
Artificial boundaries lead to the possibility of being blind-sided. For
example, someone committing (1) or (2) above might find themselves themselves
surprised to find a decision tree working well on a problem. Example (3) might
result in someone else solving a learning problem better for real world
purposes, even if it's worse with respect to the algorithm optimization. This
defect should be avoided so as to not artificially limit your learning
kungfu.The way to avoid thi</p><p>4 0.66612023 <a title="230-lsi-4" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>5 0.65676737 <a title="230-lsi-5" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>Introduction: Nati SrebroandShai Ben-Davidhave apaperatCOLTwhich, in the appendix, proves
something very striking: several previous error bounds arealwaysgreater than
1.BackgroundOne branch of learning theory focuses on theorems whichAssume
samples are drawn IID from an unknown distributionD.Fix a set of
classifiersFind a high probability bound on the maximum true error rate (with
respect toD) as a function of the empirical error rate on the training
set.Many of these bounds become extremely complex and hairy.CurrentEveryone
working on this subject wants "tighter bounds", however there are different
definitions of "tighter". Some groups focus on "functional tightness" (getting
the right functional dependency between the size of the training set and a
parameterization of the hypothesis space) whileothersfocus on "practical
tightness" (finding bounds which work well on practical problems). (I am
definitely in the second camp.)One of the dangers of striving for "functional
tightness" is that the bound</p><p>6 0.65220839 <a title="230-lsi-6" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>7 0.65133965 <a title="230-lsi-7" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>8 0.64368773 <a title="230-lsi-8" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>9 0.63419348 <a title="230-lsi-9" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>10 0.63101196 <a title="230-lsi-10" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>11 0.62075567 <a title="230-lsi-11" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>12 0.60439026 <a title="230-lsi-12" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>13 0.60021907 <a title="230-lsi-13" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>14 0.59361833 <a title="230-lsi-14" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>15 0.5935908 <a title="230-lsi-15" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>16 0.59338653 <a title="230-lsi-16" href="../hunch_net-2009/hunch_net-2009-08-26-Another_10-year_paper_in_Machine_Learning.html">368 hunch net-2009-08-26-Another 10-year paper in Machine Learning</a></p>
<p>17 0.59238124 <a title="230-lsi-17" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>18 0.59160531 <a title="230-lsi-18" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>19 0.58892369 <a title="230-lsi-19" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>20 0.58052433 <a title="230-lsi-20" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.054), (42, 0.308), (45, 0.019), (50, 0.254), (68, 0.034), (69, 0.029), (74, 0.081), (76, 0.02), (82, 0.025), (88, 0.021), (91, 0.011), (95, 0.017), (98, 0.034)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98207998 <a title="230-lda-1" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>Introduction: Several events are happening in the NY area.Barriers in Computational Learning
Theory Workshop, Aug 28.That's tomorrow near Princeton. I'm looking forward to
speaking at this one on "Getting around Barriers in Learning Theory", but
several other talks are of interest, particularly to the CS theory
inclined.Claudia Perlichis running theINFORMS Data Mining Contestwith a
deadline of Sept. 25. This is a contest using real health record data (they
partnered withHealthCare Intelligence) to predict transfers and mortality. In
the current US health care reform debate, the case studies of high costs we
hear strongly suggest machine learning & statistics can save many billions.The
Singularity Summit October 3&4\. This is for the AIists out there. Several of
the talks look interesting, although unfortunately I'll miss it
forALT.Predictive Analytics World, Oct 20-21. This is stretching the
definition of "New York Area" a bit, but the train to DC is reasonable. This
is a conference of case studies</p><p>2 0.98136777 <a title="230-lda-2" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>Introduction: Arecent discussionindicated that one goal of this blog might be to allow
people to post comments about recent papers that they liked. I think this
could potentially be very useful, especially for those with diverse interests
but only finite time to read through conference proceedings.ACL 2005recently
completed, and here are four papers from that conference that I thought were
either good or perhaps of interest to a machine learning audience.David
Chiang,A Hierarchical Phrase-Based Model for Statistical Machine Translation.
(Best paper award.) This paper takes the standard phrase-based MT model that
is popular in our field (basically, translate a sentence by individually
translating phrases and reordering them according to a complicated statistical
model) and extends it to take into account hierarchy in phrases, so that you
can learn things like "X 's Y" -> "Y de X" in chinese, where X and Y are
arbitrary phrases. This takes a step toward linguistic syntax for MT, which
our group is wor</p><p>3 0.97799426 <a title="230-lda-3" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>Introduction: "Assumption" is another word to be careful with in machine learning because it
is used in several ways.Assumption = BiasThere are several ways to see that
some form of 'bias' (= preferring of one solution over another) is necessary.
This is obvious in an adversarial setting. A good bit of work has been
expended explaining this in other settings with "no free lunch" theorems. This
is a usage specialized to learning which is particularly common when talking
about priors for Bayesian Learning.Assumption = "if" of a theoremThe
assumptions are the 'if' part of the 'if-then' in a theorem. This is a fairly
common usage.Assumption = AxiomThe assumptions are the things that we assume
are true, but which we cannot verify. Examples are "the IID assumption" or "my
problem is a DNF on a small number of bits". This is the usage which I
prefer.One difficulty with any use of the word "assumption" is that you often
encounter "ifassumptionthenconclusionso ifnot assumptionthennot conclusion".
This is inc</p><p>4 0.97436279 <a title="230-lda-4" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>Introduction: In everyday use a model is a system which explains the behavior of some
system, hopefully at the level where some alteration of the model predicts
some alteration of the real-world system. In machine learning "model" has
several variant definitions.Everyday. The common definition is sometimes
used.Parameterized. Sometimes model is a short-hand for "parameterized model".
Here, it refers to a model with unspecified free parameters. In the Bayesian
learning approach, you typically have a prior over (everyday)
models.Predictive. Even further from everyday use is the predictive model.
Examples of this are "my model is a decision tree" or "my model is a support
vector machine". Here, there is no real sense in which an SVM explains the
underlying process. For example, an SVM tells us nothing in particular about
how alterations to the real-world system would create a change.Which
definition is being used at any particular time is important information. For
example, if it's a parameterized or p</p><p>5 0.95962161 <a title="230-lda-5" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<p>Introduction: When presenting part of theReinforcement Learning theory tutorialatICML 2006,
I was forcibly reminded of this.There are several difficulties.When creating
the presentation, the correct level of detail is tricky. With too much detail,
the proof takes too much time and people may be lost to boredom. With too
little detail, the steps of the proof involve too-great a jump. This is very
difficult to judge.What may be an easy step in the careful thought of a quiet
room is not so easy when you are occupied by the process of presentation.What
may be easy after having gone over this (and other) proofs is not so easy to
follow in the first pass by a viewer.These problems seem only correctable by
process of repeated test-and-revise.When presenting the proof, simply speaking
with sufficient precision is substantially harder than in normal conversation
(where precision is not so critical). Practice can help here.When presenting
the proof, going at the right pace for understanding is difficult. When</p><p>6 0.94054699 <a title="230-lda-6" href="../hunch_net-2008/hunch_net-2008-11-28-A_Bumper_Crop_of_Machine_Learning_Graduates.html">329 hunch net-2008-11-28-A Bumper Crop of Machine Learning Graduates</a></p>
<p>same-blog 7 0.90251875 <a title="230-lda-7" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>8 0.87662113 <a title="230-lda-8" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>9 0.81293374 <a title="230-lda-9" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>10 0.80784255 <a title="230-lda-10" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>11 0.80752051 <a title="230-lda-11" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>12 0.80739146 <a title="230-lda-12" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>13 0.80726302 <a title="230-lda-13" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>14 0.80229604 <a title="230-lda-14" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>15 0.79826969 <a title="230-lda-15" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>16 0.7975648 <a title="230-lda-16" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>17 0.79476827 <a title="230-lda-17" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>18 0.7933858 <a title="230-lda-18" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>19 0.79186475 <a title="230-lda-19" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>20 0.78965145 <a title="230-lda-20" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
