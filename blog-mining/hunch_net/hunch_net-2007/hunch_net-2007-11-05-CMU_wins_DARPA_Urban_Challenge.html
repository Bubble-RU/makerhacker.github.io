<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-271" href="#">hunch_net-2007-271</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-271-html" href="http://hunch.net/?p=299">html</a></p><p>Introduction: Theresults have been posted, withCMU first,Stanford second, andVirginia Tech
Third.Considering that this was an open event (at least for people in the US),
this was a very strong showing for research at universities (instead of
defense contractors, for example). Some details should become public at
theNIPS workshops.Slashdothas apostwith many comments.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('defense', 0.387), ('tech', 0.387), ('thenips', 0.338), ('posted', 0.323), ('universities', 0.274), ('showing', 0.241), ('event', 0.225), ('comments', 0.21), ('public', 0.202), ('details', 0.175), ('open', 0.168), ('instead', 0.162), ('become', 0.161), ('second', 0.16), ('strong', 0.155), ('least', 0.129), ('us', 0.127), ('research', 0.088), ('example', 0.077), ('people', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="271-tfidf-1" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>Introduction: Theresults have been posted, withCMU first,Stanford second, andVirginia Tech
Third.Considering that this was an open event (at least for people in the US),
this was a very strong showing for research at universities (instead of
defense contractors, for example). Some details should become public at
theNIPS workshops.Slashdothas apostwith many comments.</p><p>2 0.14688908 <a title="271-tfidf-2" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect theNIPS 2006 workshopsto be quite interesting, and recommend going
for anyone interested in machine learning research. (Most or all of the
workshops webpages can be found two links deep.)</p><p>3 0.13918461 <a title="271-tfidf-3" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>Introduction: With a worldwide recession on, my impression is that the carnage in research
has not been as severe as might be feared, at least in the United States. I
know of two notable negative impacts:It's quite difficult to get a job this
year, as many companies and universities simply aren't hiring. This is
particularly tough on graduating students.Perhaps 10% ofIBM researchwas
fired.In contrast, around the time of the dot com bust,ATnT
ResearchandLucenthad one or several 50% size firings wiping out much of the
remainder ofBell Labs, triggering a notable diaspora for the respected machine
learning group there. As the recession progresses, we may easily see more
firings as companies in particular reach a point where they can no longer
support research.There are a couple positives to the recession as well.Both
the implosion of Wall Street (which siphoned off smart people) and the general
difficulty of getting a job coming out of an undergraduate education suggest
that the quality of admitted phd</p><p>4 0.1158627 <a title="271-tfidf-4" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>Introduction: Attendance at theNIPS workshopsis highly recommended for both research and
learning. Unfortunately, there does not yet appear to be a public list of
workshops. However, I found the following workshop webpages of
interest:Machine Learning in FinanceLearning to RankFoundations of Active
LearningMachine Learning Based Robotics in Unstructured EnvironmentsThere
aremanymore workshops. In fact, there are so many that it is not plausible
anyone can attend every workshop they are interested in. Maybe in future years
the organizers can spread them out over more days to reduce overlap.Many of
these workshops are accepting presentation proposals (due mid-October).</p><p>5 0.10034941 <a title="271-tfidf-5" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>Introduction: The New York Times has an interestingarticleabout how DARPA has dropped
funding for computer science to universities by about a factor of 2 over the
last 5 years and become less directed towards basic research. Partially in
response, the number of grant submissions to NSF has grown by a factor of 3
(with the NSF budget staying approximately constant in the interim).This is
the sort of policy decision which may make sense for the defense department,
but which means a large hit for basic research on information technology
development in the US. For example "darpa funded the invention of the
internet" is reasonably correct. This policy decision is particularly painful
in the context of NSF budget cuts and the end of extensive phone monopoly
funded research at Bell labs.The good news from a learning perspective is that
(based on anecdotal evidence) much of the remaining funding is aimed at
learning and learning-related fields. Methods of making good automated
predictions obviously have a l</p><p>6 0.094137393 <a title="271-tfidf-6" href="../hunch_net-2009/hunch_net-2009-09-29-Machine_Learning_Protests_at_the_G20.html">372 hunch net-2009-09-29-Machine Learning Protests at the G20</a></p>
<p>7 0.091976151 <a title="271-tfidf-7" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>8 0.088335767 <a title="271-tfidf-8" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>9 0.084696807 <a title="271-tfidf-9" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>10 0.084586471 <a title="271-tfidf-10" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>11 0.083398081 <a title="271-tfidf-11" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>12 0.075947881 <a title="271-tfidf-12" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>13 0.071955867 <a title="271-tfidf-13" href="../hunch_net-2008/hunch_net-2008-04-21-The_Science_2.0_article.html">296 hunch net-2008-04-21-The Science 2.0 article</a></p>
<p>14 0.071902208 <a title="271-tfidf-14" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>15 0.070613213 <a title="271-tfidf-15" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>16 0.06813781 <a title="271-tfidf-16" href="../hunch_net-2007/hunch_net-2007-11-16-MLSS_2008.html">273 hunch net-2007-11-16-MLSS 2008</a></p>
<p>17 0.065678634 <a title="271-tfidf-17" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>18 0.064798787 <a title="271-tfidf-18" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>19 0.061639875 <a title="271-tfidf-19" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>20 0.061286155 <a title="271-tfidf-20" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.094), (1, 0.051), (2, 0.096), (3, -0.032), (4, 0.064), (5, -0.013), (6, 0.055), (7, 0.003), (8, 0.016), (9, 0.005), (10, 0.043), (11, 0.005), (12, -0.066), (13, 0.031), (14, 0.008), (15, -0.075), (16, 0.025), (17, 0.024), (18, -0.014), (19, 0.125), (20, 0.014), (21, 0.032), (22, -0.034), (23, 0.05), (24, -0.031), (25, 0.054), (26, 0.051), (27, 0.061), (28, -0.14), (29, 0.008), (30, 0.013), (31, -0.066), (32, 0.026), (33, 0.008), (34, -0.019), (35, -0.012), (36, -0.088), (37, 0.01), (38, -0.004), (39, -0.02), (40, -0.116), (41, 0.102), (42, -0.08), (43, 0.07), (44, 0.119), (45, -0.032), (46, -0.004), (47, -0.132), (48, 0.084), (49, 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96440136 <a title="271-lsi-1" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>Introduction: Theresults have been posted, withCMU first,Stanford second, andVirginia Tech
Third.Considering that this was an open event (at least for people in the US),
this was a very strong showing for research at universities (instead of
defense contractors, for example). Some details should become public at
theNIPS workshops.Slashdothas apostwith many comments.</p><p>2 0.5233115 <a title="271-lsi-2" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pooland I recently discussed the similarities and differences between
academia and open source programming.Similarities:Cost profileResearch and
programming share approximately the same cost profile: A large upfront effort
is required to produce something useful, and then "anyone" can use it. (The
"anyone" is not quite right for either group because only sufficiently
technical people could use it.)Wealth profileA "wealthy" academic or open
source programmer is someone who has contributed a lot to other people in
research or programs. Much of academia is a "gift culture": whoever gives the
most is most respected.ProblemsBoth academia and open source programming
suffer from similar problems.Whether or not (and which) open source program is
used are perhaps too-often personality driven rather than driven by capability
or usefulness. Similar phenomena can happen in academia with respect to
directions of research.Funding is often a problem for both groups. Academics
often invest many</p><p>3 0.48643696 <a title="271-lsi-3" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>Introduction: Centmailis a scheme which makes charity donations have a secondary value, as a
stamp for email. When discussed onnewscientist,slashdot, and others, some of
the comments make the academic review process appear thoughtful. Some
prominent fallacies are:Costing money fallacy. Some commenters appear to
believe the system charges money per email. Instead, the basic idea is that
users get an extra benefit from donations to a charity and participation is
strictly voluntary. The solution to this fallacy is simply readingthe
details.Single solution fallacy. Some commenters seem to think this is
proposed as a complete solution to spam, and since not everyone will opt to
participate, it won't work. But a complete solution is not at all necessary or
even possible given theflag-day problem. Deployed machine learning systems for
fighting spam are great at taking advantage of a partial solution. The
solution to this fallacy is learning about machine learning. In the current
state of affairs, informed</p><p>4 0.45864037 <a title="271-lsi-4" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>Introduction: The New York Times has an interestingarticleabout how DARPA has dropped
funding for computer science to universities by about a factor of 2 over the
last 5 years and become less directed towards basic research. Partially in
response, the number of grant submissions to NSF has grown by a factor of 3
(with the NSF budget staying approximately constant in the interim).This is
the sort of policy decision which may make sense for the defense department,
but which means a large hit for basic research on information technology
development in the US. For example "darpa funded the invention of the
internet" is reasonably correct. This policy decision is particularly painful
in the context of NSF budget cuts and the end of extensive phone monopoly
funded research at Bell labs.The good news from a learning perspective is that
(based on anecdotal evidence) much of the remaining funding is aimed at
learning and learning-related fields. Methods of making good automated
predictions obviously have a l</p><p>5 0.45700148 <a title="271-lsi-5" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>Introduction: At thelast ICML,Tom Dietterichasked me to look into systems for commenting on
papers. I've been slow getting to this, but it's relevant now.The essential
observation is that we now have many tools for online collaboration, but they
are not yet much used in academic research. If we can find the right way to
use them, then perhaps great things might happen, with extra kudos to the
first conference that manages to really create an online community. Various
conferences have been poking at this. For example,UAI has setup a wiki, COLT
hasstarted usingJoomla, with some dynamic content, and AAAI has been setting
up a "student blog". Similarly,Dinoj Surendransetup a twiki for theChicago
Machine Learning Summer School, which was quite useful for coordinating events
and other things.I believe the most important thing is a willingness to
experiment. A good place to start seems to be enhancing existing conference
websites. For example, theICML 2007 papers pageis basically only useful via
grep. A mu</p><p>6 0.43601987 <a title="271-lsi-6" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>7 0.43393025 <a title="271-lsi-7" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>8 0.42626026 <a title="271-lsi-8" href="../hunch_net-2005/hunch_net-2005-03-29-Academic_Mechanism_Design.html">48 hunch net-2005-03-29-Academic Mechanism Design</a></p>
<p>9 0.42521986 <a title="271-lsi-9" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>10 0.42519236 <a title="271-lsi-10" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>11 0.41468382 <a title="271-lsi-11" href="../hunch_net-2009/hunch_net-2009-09-29-Machine_Learning_Protests_at_the_G20.html">372 hunch net-2009-09-29-Machine Learning Protests at the G20</a></p>
<p>12 0.41029176 <a title="271-lsi-12" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>13 0.40882117 <a title="271-lsi-13" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>14 0.38925898 <a title="271-lsi-14" href="../hunch_net-2006/hunch_net-2006-02-04-Research_Budget_Changes.html">154 hunch net-2006-02-04-Research Budget Changes</a></p>
<p>15 0.38592842 <a title="271-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>16 0.37581939 <a title="271-lsi-16" href="../hunch_net-2013/hunch_net-2013-01-01-Deep_Learning_2012.html">477 hunch net-2013-01-01-Deep Learning 2012</a></p>
<p>17 0.37467039 <a title="271-lsi-17" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>18 0.37241057 <a title="271-lsi-18" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>19 0.36927843 <a title="271-lsi-19" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>20 0.36913225 <a title="271-lsi-20" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.185), (45, 0.174), (91, 0.451)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.90541714 <a title="271-lda-1" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>Introduction: Theresults have been posted, withCMU first,Stanford second, andVirginia Tech
Third.Considering that this was an open event (at least for people in the US),
this was a very strong showing for research at universities (instead of
defense contractors, for example). Some details should become public at
theNIPS workshops.Slashdothas apostwith many comments.</p><p>2 0.88111663 <a title="271-lda-2" href="../hunch_net-2010/hunch_net-2010-08-21-Rob_Schapire_at_NYC_ML_Meetup.html">405 hunch net-2010-08-21-Rob Schapire at NYC ML Meetup</a></p>
<p>Introduction: I've been wanting to attend theNYC ML Meetupfor some time and hope to make
itnext week on the 25th.Rob Schapireis talking about "Playing Repeated Games",
which in my experience is far more relevant to machine learning than the title
might indicate.</p><p>3 0.87116385 <a title="271-lda-3" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>Introduction: Thespock challengefor named entity recognition waswonbyBerno Stein, Sven
Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, andMartin Potthast.</p><p>4 0.72830635 <a title="271-lda-4" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>Introduction: Sham Kakadepoints out that we are missing a bound.Suppose we
havemsamplesxdrawn IID from some distributionD. Through the magic of
exponential moment method we know that:If the range ofxis bounded by an
interval of sizeI, aChernoff/Hoeffding style boundgives us a bound on the
deviations likeO(I/m0.5)(at least in crude form). A proof is on page 9here.If
the range ofxis bounded, and the variance (or a bound on the variance) is
known, thenBennett's boundcan give tighter results (*). This can be a huge
improvment when the true variance small.What's missing here is a bound that
depends on the observed variance rather than a bound on the variance. This
means that many people attempt to use Bennett's bound (incorrectly) by
plugging the observed variance in as the true variance, invalidating the bound
application. Most of the time, they get away with it, but this is a dangerous
move when doing machine learning. In machine learning, we are typically trying
to find a predictor with 0 expected los</p><p>5 0.67649996 <a title="271-lda-5" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>Introduction: This post is about a general technique for problem solving which I've never
seen taught (in full generality), but which I've found very useful.Many
problems in computer science turn out to be discretely difficult. The best
known version of such problems are NP-hard problems, but I mean 'discretely
difficult' in a much more general way, which I only know how to capture by
examples.ERMIn empirical risk minimization, you choose a minimum error rate
classifier from a set of classifiers. This is NP hard for common sets, but it
can be much harder, depending on the set.ExpertsIn the online learning with
experts setting, you try to predict well so as to compete with a set of
(adversarial) experts. Here the alternating quantifiers of you and an
adversary playing out a game can yield a dynamic programming problem that
grows exponentially.Policy IterationThe problem with policy iteration is that
you learn a new policy with respect to an old policy, which implies that
simply adopting the new polic</p><p>6 0.64604902 <a title="271-lda-6" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>7 0.56679761 <a title="271-lda-7" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>8 0.54688638 <a title="271-lda-8" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>9 0.50671494 <a title="271-lda-9" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>10 0.48338312 <a title="271-lda-10" href="../hunch_net-2009/hunch_net-2009-03-18-Parallel_ML_primitives.html">346 hunch net-2009-03-18-Parallel ML primitives</a></p>
<p>11 0.48332465 <a title="271-lda-11" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>12 0.48170206 <a title="271-lda-12" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>13 0.47328007 <a title="271-lda-13" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>14 0.46986729 <a title="271-lda-14" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>15 0.46060973 <a title="271-lda-15" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>16 0.45956776 <a title="271-lda-16" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>17 0.45515949 <a title="271-lda-17" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>18 0.4520078 <a title="271-lda-18" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>19 0.44329077 <a title="271-lda-19" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>20 0.4062098 <a title="271-lda-20" href="../hunch_net-2011/hunch_net-2011-06-22-Ultra_LDA.html">436 hunch net-2011-06-22-Ultra LDA</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
