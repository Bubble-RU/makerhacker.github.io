<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-271" href="#">hunch_net-2007-271</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-271-html" href="http://hunch.net/?p=299">html</a></p><p>Introduction: The  results have been posted , with  CMU first ,  Stanford second , and  Virginia Tech Third .
 
Considering that this was an open event (at least for people in the US), this was a very strong showing for research at universities (instead of defense contractors, for example).  Some details should become public at the  NIPS workshops .
 
 Slashdot  has a  post  with many comments.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The  results have been posted , with  CMU first ,  Stanford second , and  Virginia Tech Third . [sent-1, score-0.584]
</p><p>2 Considering that this was an open event (at least for people in the US), this was a very strong showing for research at universities (instead of defense contractors, for example). [sent-2, score-1.477]
</p><p>3 Some details should become public at the  NIPS workshops . [sent-3, score-0.622]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('defense', 0.335), ('stanford', 0.31), ('tech', 0.31), ('slashdot', 0.268), ('posted', 0.258), ('universities', 0.237), ('cmu', 0.237), ('third', 0.208), ('showing', 0.205), ('event', 0.192), ('considering', 0.181), ('comments', 0.174), ('public', 0.17), ('workshops', 0.166), ('details', 0.147), ('open', 0.142), ('become', 0.139), ('nips', 0.136), ('strong', 0.132), ('second', 0.131), ('instead', 0.131), ('post', 0.124), ('results', 0.114), ('us', 0.109), ('least', 0.108), ('first', 0.081), ('research', 0.074), ('example', 0.064), ('people', 0.052), ('many', 0.041)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="271-tfidf-1" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>Introduction: The  results have been posted , with  CMU first ,  Stanford second , and  Virginia Tech Third .
 
Considering that this was an open event (at least for people in the US), this was a very strong showing for research at universities (instead of defense contractors, for example).  Some details should become public at the  NIPS workshops .
 
 Slashdot  has a  post  with many comments.</p><p>2 0.24087399 <a title="271-tfidf-2" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>Introduction: The DARPA grandchallenge is a big contest for autonomous robot vehicle driving.  It was run once in 2004 for the first time and all teams did badly.  This year was notably different with the  Stanford  and  CMU  teams succesfully completing the course.  A number of details are  here  and  wikipedia has continuing coverage .
 
A formal winner hasnâ&euro;&trade;t been declared yet although Stanford completed the course quickest.  
 
The Stanford and CMU teams deserve a large round of applause as they have strongly demonstrated the feasibility of autonomous vehicles.
 
The good news for machine learning is that the Stanford team (at least) is using some machine learning techniques.</p><p>3 0.13663638 <a title="271-tfidf-3" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">285 hunch net-2008-01-23-Why Workshop?</a></p>
<p>Introduction: I second the  call for workshops at ICML/COLT/UAI .
 
 Several   times   before , details of why and how to run a  workshop have been mentioned.  
 
There is a simple reason to prefer workshops here: attendance.  The Helsinki colocation has placed workshops  directly between ICML and COLT/UAI , which is optimal for getting attendees from any conference.  In addition,  last year ICML had relatively few workshops  and NIPS workshops were overloaded.  In addition to  those that happened  a similar number were rejected.  The overload has strange consequences—for example,  the best attended workshop  wasn’t an official NIPS workshop.  Aside from intrinsic interest, the Deep Learning workshop benefited greatly from being off schedule.</p><p>4 0.12465922 <a title="271-tfidf-4" href="../hunch_net-2005/hunch_net-2005-04-22-New_Blog%3A_%5BLowerbounds%2CUpperbounds%5D.html">59 hunch net-2005-04-22-New Blog: [Lowerbounds,Upperbounds]</a></p>
<p>Introduction: Maverick Woo and the Aladdin group at CMU have started a CS theory-related blog  here .</p><p>5 0.12463093 <a title="271-tfidf-5" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>Introduction: Since we last discussed  the other online learning ,  Stanford  has very visibly started pushing mass teaching in  AI ,  Machine Learning , and  Databases .  In retrospect, it’s not too surprising that the next step up in serious online teaching experiments are occurring at the computer science department of a university embedded in the land of startups.  Numbers on the order of  100000  are quite significant—similar in scale to the number of  computer science undergraduate students/year  in the US.  Although these populations surely differ, the fact that they  could  overlap is worth considering for the future.  
 
It’s too soon to say how successful these classes will be and there are many easy criticisms to make:
  
  Registration != Learning   … but if only 1/10th complete these classes, the scale of teaching still surpasses the scale of any traditional process. 
  1st year excitement != nth year routine  … but if only 1/10th take future classes, the scale of teaching still surpass</p><p>6 0.11781882 <a title="271-tfidf-6" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>7 0.10953346 <a title="271-tfidf-7" href="../hunch_net-2009/hunch_net-2009-09-29-Machine_Learning_Protests_at_the_G20.html">372 hunch net-2009-09-29-Machine Learning Protests at the G20</a></p>
<p>8 0.10891369 <a title="271-tfidf-8" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>9 0.10654576 <a title="271-tfidf-9" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>10 0.10436411 <a title="271-tfidf-10" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>11 0.10431749 <a title="271-tfidf-11" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>12 0.10323177 <a title="271-tfidf-12" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>13 0.090962633 <a title="271-tfidf-13" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>14 0.090637788 <a title="271-tfidf-14" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>15 0.087696902 <a title="271-tfidf-15" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>16 0.083290868 <a title="271-tfidf-16" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>17 0.081149131 <a title="271-tfidf-17" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>18 0.079113126 <a title="271-tfidf-18" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>19 0.078494266 <a title="271-tfidf-19" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>20 0.076975025 <a title="271-tfidf-20" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.116), (1, -0.081), (2, -0.108), (3, -0.007), (4, -0.043), (5, 0.093), (6, 0.103), (7, -0.002), (8, 0.036), (9, 0.077), (10, -0.029), (11, 0.079), (12, -0.07), (13, -0.077), (14, -0.034), (15, 0.011), (16, -0.069), (17, -0.047), (18, 0.024), (19, 0.077), (20, -0.104), (21, 0.058), (22, -0.027), (23, -0.057), (24, -0.016), (25, -0.069), (26, -0.02), (27, 0.041), (28, 0.085), (29, 0.021), (30, 0.095), (31, 0.01), (32, -0.035), (33, 0.056), (34, -0.068), (35, 0.013), (36, 0.053), (37, -0.119), (38, 0.109), (39, 0.012), (40, 0.011), (41, 0.026), (42, 0.075), (43, 0.063), (44, 0.085), (45, -0.13), (46, 0.103), (47, 0.152), (48, 0.087), (49, 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97747552 <a title="271-lsi-1" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>Introduction: The  results have been posted , with  CMU first ,  Stanford second , and  Virginia Tech Third .
 
Considering that this was an open event (at least for people in the US), this was a very strong showing for research at universities (instead of defense contractors, for example).  Some details should become public at the  NIPS workshops .
 
 Slashdot  has a  post  with many comments.</p><p>2 0.68761957 <a title="271-lsi-2" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>Introduction: The DARPA grandchallenge is a big contest for autonomous robot vehicle driving.  It was run once in 2004 for the first time and all teams did badly.  This year was notably different with the  Stanford  and  CMU  teams succesfully completing the course.  A number of details are  here  and  wikipedia has continuing coverage .
 
A formal winner hasnâ&euro;&trade;t been declared yet although Stanford completed the course quickest.  
 
The Stanford and CMU teams deserve a large round of applause as they have strongly demonstrated the feasibility of autonomous vehicles.
 
The good news for machine learning is that the Stanford team (at least) is using some machine learning techniques.</p><p>3 0.51046157 <a title="271-lsi-3" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pool  and I recently discussed the similarities and differences between academia and open source programming.   
 
Similarities:
  
  Cost profile   Research and programming share approximately the same cost profile: A large upfront effort is required to produce something useful, and then “anyone” can use it.  (The “anyone” is not quite right for either group because only sufficiently technical people could use it.) 
  Wealth profile  A “wealthy” academic or open source programmer is someone who has contributed a lot to other people in research or programs.  Much of academia is a “gift culture”: whoever gives the most is most respected. 
  Problems   Both academia and open source programming suffer from similar problems.
 
 Whether or not (and which) open source program is used are perhaps too-often personality driven rather than driven by capability or usefulness.  Similar phenomena can happen in academia with respect to directions of research. 
 Funding is often a problem for</p><p>4 0.49942175 <a title="271-lsi-4" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">285 hunch net-2008-01-23-Why Workshop?</a></p>
<p>Introduction: I second the  call for workshops at ICML/COLT/UAI .
 
 Several   times   before , details of why and how to run a  workshop have been mentioned.  
 
There is a simple reason to prefer workshops here: attendance.  The Helsinki colocation has placed workshops  directly between ICML and COLT/UAI , which is optimal for getting attendees from any conference.  In addition,  last year ICML had relatively few workshops  and NIPS workshops were overloaded.  In addition to  those that happened  a similar number were rejected.  The overload has strange consequences—for example,  the best attended workshop  wasn’t an official NIPS workshop.  Aside from intrinsic interest, the Deep Learning workshop benefited greatly from being off schedule.</p><p>5 0.48241973 <a title="271-lsi-5" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>Introduction: I realized that the tools needed to solve the  problem just posted  were just created.  I tried to sketch out the solution  here  (also in  .lyx  and  .tex ).  It is still quite sketchy (and probably only the few people who understand reductions well can follow).
 
One of the reasons why I started this weblog was to experiment with “research in the open”, and this is an opportunity to do so.  Over the next few days, I’ll be filling in details and trying to get things to make sense.  If you have additions or ideas, please propose them.</p><p>6 0.47816396 <a title="271-lsi-6" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>7 0.476538 <a title="271-lsi-7" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>8 0.46855348 <a title="271-lsi-8" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>9 0.46610069 <a title="271-lsi-9" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>10 0.4657107 <a title="271-lsi-10" href="../hunch_net-2009/hunch_net-2009-09-29-Machine_Learning_Protests_at_the_G20.html">372 hunch net-2009-09-29-Machine Learning Protests at the G20</a></p>
<p>11 0.43863732 <a title="271-lsi-11" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>12 0.43760905 <a title="271-lsi-12" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>13 0.40420642 <a title="271-lsi-13" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>14 0.39654353 <a title="271-lsi-14" href="../hunch_net-2008/hunch_net-2008-04-21-The_Science_2.0_article.html">296 hunch net-2008-04-21-The Science 2.0 article</a></p>
<p>15 0.37808558 <a title="271-lsi-15" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>16 0.35923687 <a title="271-lsi-16" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>17 0.35427296 <a title="271-lsi-17" href="../hunch_net-2005/hunch_net-2005-04-22-New_Blog%3A_%5BLowerbounds%2CUpperbounds%5D.html">59 hunch net-2005-04-22-New Blog: [Lowerbounds,Upperbounds]</a></p>
<p>18 0.34918883 <a title="271-lsi-18" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>19 0.34524593 <a title="271-lsi-19" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>20 0.33506966 <a title="271-lsi-20" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.122), (55, 0.714)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9972958 <a title="271-lda-1" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>Introduction: The  New York Machine Learning Symposium  is October 19 with a 2 page abstract deadline due September 13 via email with subject “Machine Learning Poster Submission” sent to physicalscience@nyas.org.  Everyone is welcome to submit.  Last year’s attendance was 246 and I expect more this year.
 
The primary experiment for  ICML 2013  is multiple paper submission deadlines with rolling review cycles.  The key dates are October 1, December 15, and February 15.  This is an attempt to shift ICML further towards a journal style review process and reduce peak load.   The “not for proceedings” experiment from this year’s ICML is not continuing.
 
Edit: Fixed second ICML deadline.</p><p>same-blog 2 0.9928121 <a title="271-lda-2" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>Introduction: The  results have been posted , with  CMU first ,  Stanford second , and  Virginia Tech Third .
 
Considering that this was an open event (at least for people in the US), this was a very strong showing for research at universities (instead of defense contractors, for example).  Some details should become public at the  NIPS workshops .
 
 Slashdot  has a  post  with many comments.</p><p>3 0.99272448 <a title="271-lda-3" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>Introduction: Various people want to use hunch.net to announce things.  I’ve generally resisted this because I feared hunch becoming a pure announcement zone while I am much more interested contentful posts and discussion personally.  Nevertheless there is clearly some value and announcements are easy, so I’m planning to summarize announcements on Mondays.
  
  D. Sculley  points out an interesting  Semisupervised feature learning  competition, with a deadline of October 17.  
  Lihong Li  points out the  webscope user interaction dataset  which is the first high quality exploration dataset I’m aware of that is publicly available. 
 Seth Rogers points out  CrossValidated  which looks similar in conception to  metaoptimize , but directly using the  stackoverflow  interface and with a bit more of a statistics twist.</p><p>4 0.98581195 <a title="271-lda-4" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>Introduction: Adam Klivans , points out the  COLT call for papers .  The important points are: 
  
 Due Feb 13. 
 Montreal, June 18-21. 
 This year, there is author feedback.</p><p>5 0.98581195 <a title="271-lda-5" href="../hunch_net-2012/hunch_net-2012-05-12-ICML_accepted_papers_and_early_registration.html">465 hunch net-2012-05-12-ICML accepted papers and early registration</a></p>
<p>Introduction: The  accepted papers  are up in full detail.  We are still struggling with the precise program itself, but thatâ&euro;&trade;s coming along.  Also note the  May 13  deadline for  early registration  and room booking.</p><p>6 0.98572063 <a title="271-lda-6" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>7 0.98449588 <a title="271-lda-7" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>8 0.98044676 <a title="271-lda-8" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>9 0.95143706 <a title="271-lda-9" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>10 0.93012184 <a title="271-lda-10" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>11 0.89992964 <a title="271-lda-11" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>12 0.89407998 <a title="271-lda-12" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>13 0.87817848 <a title="271-lda-13" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>14 0.86516804 <a title="271-lda-14" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>15 0.83571249 <a title="271-lda-15" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>16 0.82027936 <a title="271-lda-16" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>17 0.8140713 <a title="271-lda-17" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>18 0.80232567 <a title="271-lda-18" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>19 0.78672558 <a title="271-lda-19" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>20 0.77768278 <a title="271-lda-20" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
