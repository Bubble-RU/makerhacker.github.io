<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>252 hunch net-2007-07-01-Watchword: Online Learning</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-252" href="#">hunch_net-2007-252</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>252 hunch net-2007-07-01-Watchword: Online Learning</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-252-html" href="http://hunch.net/?p=277">html</a></p><p>Introduction: It turns out that many different people use the term "Online Learning", and
often they don't have the same definition in mind. Here's a list of the
possibilities I know of.Online Information SettingOnline learning refers to
aproblemin which unlabeled data comes, a prediction is made, and then feedback
is acquired.Online Adversarial SettingOnline learning refers toalgorithmsin
the Online Information Setting which satisfy guarantees of the form: "For all
possible sequences of observations, the algorithim has regret at mostlog (
number of strategies)with respect to the best strategy in a set." This is
sometimes called online learning with experts.Online Optimization
ConstraintOnline learning refers to optimizing a predictor via a learning
algorithm tunes parameters on a per-example basis. This may or may not be
applied in the Online Information Setting, and the strategy may or may not
satisfy Adversarial setting theory.Online Computational ConstraintOnline
learning refers to an algorithmi</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('refers', 0.548), ('constraintonline', 0.296), ('settingonline', 0.296), ('setting', 0.251), ('satisfy', 0.21), ('tasks', 0.182), ('strategy', 0.182), ('online', 0.173), ('adversarial', 0.164), ('information', 0.157), ('mostlog', 0.131), ('mastered', 0.115), ('adapt', 0.11), ('may', 0.109), ('sequences', 0.105), ('strategies', 0.105), ('possibilities', 0.096), ('constraint', 0.093), ('rapidly', 0.091), ('called', 0.083)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="252-tfidf-1" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>Introduction: It turns out that many different people use the term "Online Learning", and
often they don't have the same definition in mind. Here's a list of the
possibilities I know of.Online Information SettingOnline learning refers to
aproblemin which unlabeled data comes, a prediction is made, and then feedback
is acquired.Online Adversarial SettingOnline learning refers toalgorithmsin
the Online Information Setting which satisfy guarantees of the form: "For all
possible sequences of observations, the algorithim has regret at mostlog (
number of strategies)with respect to the best strategy in a set." This is
sometimes called online learning with experts.Online Optimization
ConstraintOnline learning refers to optimizing a predictor via a learning
algorithm tunes parameters on a per-example basis. This may or may not be
applied in the Online Information Setting, and the strategy may or may not
satisfy Adversarial setting theory.Online Computational ConstraintOnline
learning refers to an algorithmi</p><p>2 0.17262055 <a title="252-tfidf-2" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>Introduction: One thing which is clear on a little reflection is that there exists a single
master learning problem capable of encoding essentially all learning problems.
This problem is of course a very general sort of reinforcement learning where
the world interacts with an agent as:The world announces an observationx.The
agent makes a choicea.The world announces a rewardr.The goal here is to
maximize the sum of the rewards over the time of the agent. No particular
structure relatingxtoaoratoris implied by this setting so we do not know
effective general algorithms for the agent. It's very easy to prove lower
bounds showing that an agent cannot hope to succeed here--just consider the
case where actions are unrelated to rewards. Nevertheless, there is a real
sense in which essentially all forms of life are agents operating in this
setting, somehow succeeding. The gap between these observations drives
research--How can we find tractable specializations of the master problem
general enough to provide</p><p>3 0.13476154 <a title="252-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>Introduction: One nice use for this blog is to consider and discuss papers that that have
appeared at recent conferences. I really enjoyed Andrew Ng and Sham Kakade's
paperOnline Bounds for Bayesian Algorithms. From the paper:The philosophy
taken in the Bayesian methodology is often at odds withthat in the online
learning community…. the online learning settingmakes rather minimal
assumptions on the conditions under which thedata are being presented to the
learner â€”usually, Nature could provideexamples in an adversarial manner. We
study the performance ofBayesian algorithms in a more adversarial setting… We
providecompetitive bounds when the cost function is the log loss, and
wecompare our performance to the best model in our model class (as inthe
experts setting).It's a very nice analysis of some of my favorite algorithms
that all hinges around a beautiful theorem:Let Q be any distribution over
parameters theta. Then for all sequences S:L_{Bayes}(S) leq L_Q(S) +
KL(Q|P)where P is our prior and th</p><p>4 0.13339415 <a title="252-tfidf-4" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>Introduction: AtICML 2003,Marty Zinkevichproposedthe online convex optimization setting and
showed that a particular gradient descent algorithm has regret O(T0.5) with
respect to the best predictor where T is the number of rounds. This seems to
be a nice model for online learning, and there has been some significant
follow-up work.AtCOLT 2006Elad Hazan,Adam Kalai,Satyen Kale, andAmit
Agarwalpresenteda modification which takes a Newton stepguaranteeing O(log T)
regret when the first and second derivatives are bounded.Then they applied
these algorithms to portfolio managementatICML 2006(withRobert Schapire)
yielding some very fun graphs.</p><p>5 0.11692493 <a title="252-tfidf-5" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>Introduction: Here are some papers fromICML 2008that I found interesting.Risi
KondorandKarsten Borgwardt,The Skew Spectrum of Graphs. This paper is about a
new family of functions on graphs which is invariant under node label
permutation. They show that these quantities appear to yield good features for
learning.Sanjoy DasguptaandDaniel Hsu.Hierarchical sampling for active
learning.This is the first published practical consistent active learning
algorithm. The abstract is also pretty impressive.Lihong Li,Michael Littman,
andThomas WalshKnows What It Knows: A Framework For Self-Aware Learning.This
is an attempt to create learning algorithms that know when they err, (other
work includesVovk). It's not yet clear to me what the right model forfeature-
dependent confidence intervalsis.Novi Quadrianto,Alex Smola,TIberio Caetano,
andQuoc Viet LeEstimating Labels from Label Proportions. This is an example of
learning in a specialization of the offline contextual bandit setting.Filip
Radlinski,Robert Kleinbe</p><p>6 0.10186628 <a title="252-tfidf-6" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>7 0.10027433 <a title="252-tfidf-7" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>8 0.092283487 <a title="252-tfidf-8" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>9 0.090560995 <a title="252-tfidf-9" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>10 0.087783188 <a title="252-tfidf-10" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>11 0.085943729 <a title="252-tfidf-11" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>12 0.084402815 <a title="252-tfidf-12" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>13 0.08428999 <a title="252-tfidf-13" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>14 0.082995459 <a title="252-tfidf-14" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>15 0.081256628 <a title="252-tfidf-15" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>16 0.078524359 <a title="252-tfidf-16" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>17 0.077611148 <a title="252-tfidf-17" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>18 0.075190343 <a title="252-tfidf-18" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>19 0.074408911 <a title="252-tfidf-19" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>20 0.072604679 <a title="252-tfidf-20" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.164), (1, -0.1), (2, -0.012), (3, 0.021), (4, -0.078), (5, 0.027), (6, 0.083), (7, -0.012), (8, -0.093), (9, -0.046), (10, -0.009), (11, -0.058), (12, 0.025), (13, -0.034), (14, -0.013), (15, -0.021), (16, -0.044), (17, 0.009), (18, -0.157), (19, 0.02), (20, -0.015), (21, -0.033), (22, 0.054), (23, -0.019), (24, -0.029), (25, -0.088), (26, 0.057), (27, -0.01), (28, 0.047), (29, -0.082), (30, 0.013), (31, 0.031), (32, 0.042), (33, -0.108), (34, -0.052), (35, -0.01), (36, 0.019), (37, -0.067), (38, 0.031), (39, 0.069), (40, 0.005), (41, 0.051), (42, 0.006), (43, -0.024), (44, 0.04), (45, 0.091), (46, 0.072), (47, 0.009), (48, -0.001), (49, 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92986012 <a title="252-lsi-1" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>Introduction: It turns out that many different people use the term "Online Learning", and
often they don't have the same definition in mind. Here's a list of the
possibilities I know of.Online Information SettingOnline learning refers to
aproblemin which unlabeled data comes, a prediction is made, and then feedback
is acquired.Online Adversarial SettingOnline learning refers toalgorithmsin
the Online Information Setting which satisfy guarantees of the form: "For all
possible sequences of observations, the algorithim has regret at mostlog (
number of strategies)with respect to the best strategy in a set." This is
sometimes called online learning with experts.Online Optimization
ConstraintOnline learning refers to optimizing a predictor via a learning
algorithm tunes parameters on a per-example basis. This may or may not be
applied in the Online Information Setting, and the strategy may or may not
satisfy Adversarial setting theory.Online Computational ConstraintOnline
learning refers to an algorithmi</p><p>2 0.71863639 <a title="252-lsi-2" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>Introduction: AtICML 2003,Marty Zinkevichproposedthe online convex optimization setting and
showed that a particular gradient descent algorithm has regret O(T0.5) with
respect to the best predictor where T is the number of rounds. This seems to
be a nice model for online learning, and there has been some significant
follow-up work.AtCOLT 2006Elad Hazan,Adam Kalai,Satyen Kale, andAmit
Agarwalpresenteda modification which takes a Newton stepguaranteeing O(log T)
regret when the first and second derivatives are bounded.Then they applied
these algorithms to portfolio managementatICML 2006(withRobert Schapire)
yielding some very fun graphs.</p><p>3 0.67526299 <a title="252-lsi-3" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>Introduction: One thing which is clear on a little reflection is that there exists a single
master learning problem capable of encoding essentially all learning problems.
This problem is of course a very general sort of reinforcement learning where
the world interacts with an agent as:The world announces an observationx.The
agent makes a choicea.The world announces a rewardr.The goal here is to
maximize the sum of the rewards over the time of the agent. No particular
structure relatingxtoaoratoris implied by this setting so we do not know
effective general algorithms for the agent. It's very easy to prove lower
bounds showing that an agent cannot hope to succeed here--just consider the
case where actions are unrelated to rewards. Nevertheless, there is a real
sense in which essentially all forms of life are agents operating in this
setting, somehow succeeding. The gap between these observations drives
research--How can we find tractable specializations of the master problem
general enough to provide</p><p>4 0.6577028 <a title="252-lsi-4" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem. When someone screws up, do you fire them?
Or do you accept the error and let them continue? This is a very difficult
problem and we all know of stories where the wrong decision was made.Online
learning(as meant here), is a subfield of learning theory which analyzes the
online learning model.In the online learning model, there are a set of
hypotheses or "experts". On any instantancex, each expert makes a predictiony.
A master algorithmAuses these predictions to form it's own predictionyAand
then learns the correct predictiony*. This process repeats.The goal of online
learning is to find a master algorithmAwhich uses the advice of the experts to
make good predictions. In particular, we typically want to guarantee that the
master algorithm performs almost as well as the best expert. IfL(e)is the loss
of experteandL(A)is the loss of the master algorithm, it is often possible to
prove:L(A) less than mineL(e) + log(number of experts)over all sequences.In
p</p><p>5 0.62490392 <a title="252-lsi-5" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>Introduction: Online learning is in vogue, which means we should expect to see in the near
future:Online boosting.Online decision trees.Online SVMs. (actually, we've
already seen)Online deep learning.Online parallel learning.etc…There are three
fundamental drivers of this trend.Increasing size of datasets makes online
algorithms attractive.Online learning can simply be more efficient than batch
learning. Here is a picture from a class on online learning:The point of this
picture is that even in 3 dimensions and even with linear constraints, finding
the minima of a set in an online fashion can be typically faster than finding
the minima in a batch fashion. To see this, note that there is a minimal
number of gradient updates (i.e. 2) required in order to reach the minima in
the typical case. Given this, it's best to do these updates as quickly as
possible, which implies doing the first update online (i.e. before seeing all
the examples) is preferred. Note that this is the simplest possible setting--
m</p><p>6 0.60934728 <a title="252-lsi-6" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>7 0.58862072 <a title="252-lsi-7" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>8 0.58538496 <a title="252-lsi-8" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>9 0.58396703 <a title="252-lsi-9" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>10 0.56416357 <a title="252-lsi-10" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>11 0.55930334 <a title="252-lsi-11" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>12 0.55669272 <a title="252-lsi-12" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>13 0.55473936 <a title="252-lsi-13" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>14 0.55009371 <a title="252-lsi-14" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>15 0.54843605 <a title="252-lsi-15" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>16 0.53810513 <a title="252-lsi-16" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>17 0.53599167 <a title="252-lsi-17" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>18 0.53011698 <a title="252-lsi-18" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>19 0.52413642 <a title="252-lsi-19" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>20 0.52193981 <a title="252-lsi-20" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.045), (41, 0.303), (42, 0.328), (45, 0.021), (68, 0.094), (74, 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.8946116 <a title="252-lda-1" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>Introduction: It turns out that many different people use the term "Online Learning", and
often they don't have the same definition in mind. Here's a list of the
possibilities I know of.Online Information SettingOnline learning refers to
aproblemin which unlabeled data comes, a prediction is made, and then feedback
is acquired.Online Adversarial SettingOnline learning refers toalgorithmsin
the Online Information Setting which satisfy guarantees of the form: "For all
possible sequences of observations, the algorithim has regret at mostlog (
number of strategies)with respect to the best strategy in a set." This is
sometimes called online learning with experts.Online Optimization
ConstraintOnline learning refers to optimizing a predictor via a learning
algorithm tunes parameters on a per-example basis. This may or may not be
applied in the Online Information Setting, and the strategy may or may not
satisfy Adversarial setting theory.Online Computational ConstraintOnline
learning refers to an algorithmi</p><p>2 0.85679013 <a title="252-lda-2" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>Introduction: Online learning is in vogue, which means we should expect to see in the near
future:Online boosting.Online decision trees.Online SVMs. (actually, we've
already seen)Online deep learning.Online parallel learning.etc…There are three
fundamental drivers of this trend.Increasing size of datasets makes online
algorithms attractive.Online learning can simply be more efficient than batch
learning. Here is a picture from a class on online learning:The point of this
picture is that even in 3 dimensions and even with linear constraints, finding
the minima of a set in an online fashion can be typically faster than finding
the minima in a batch fashion. To see this, note that there is a minimal
number of gradient updates (i.e. 2) required in order to reach the minima in
the typical case. Given this, it's best to do these updates as quickly as
possible, which implies doing the first update online (i.e. before seeing all
the examples) is preferred. Note that this is the simplest possible setting--
m</p><p>3 0.79138935 <a title="252-lda-3" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>Introduction: I've had serious conversations with several people who believe that the theory
in machine learning is "only useful for getting papers published". That's a
compelling statement, as I've seen many papers where the algorithm clearly
came first, and the theoretical justification for it came second, purely as a
perceived means to improve the chance of publication.Naturally, I disagree and
believe that learning theory has much more substantial applications.Even in
core learning algorithm design, I've found learning theory to be useful,
although it's application is more subtle than many realize. The most
straightforward applications can fail, because (as expectation suggests) worst
case bounds tend to be loose in practice (*). In my experience, considering
learning theory when designing an algorithm has two important effects in
practice:It can help make your algorithm behave right at a crude level of
analysis, leaving finer details to tuning or common sense. The best example I
have of this is</p><p>4 0.74989277 <a title="252-lda-4" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>Introduction: "Deep learning" is used to describe learning architectures which have
significant depth (as a circuit).One claimis that shallow architectures (one
or two layers) can not concisely represent some functions while a circuit with
more depth can concisely represent these same functions. Proving lower bounds
on the size of a circuit is substantially harder than upper bounds (which are
constructive), but some results are known.Luca Trevisan'sclass notesdetail how
XOR is not concisely representable by "AC0â&euro;ł (= constant depth unbounded fan-in
AND, OR, NOT gates). This doesn't quite prove that depth is necessary for the
representations commonly used in learning (such as a thresholded weighted
sum), but it is strongly suggestive that this is so.Examples like this are a
bit disheartening because existing algorithms for deep learning (deep belief
nets, gradient descent on deep neural networks, and a perhaps decision trees
depending on who you ask) can't learn XOR very easily. Evidence so far
sugges</p><p>5 0.74633414 <a title="252-lda-5" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>Introduction: Researchers are typically confronted with big problems that they have no idea
how to solve. In trying to come up with a solution, a natural approach is to
decompose the big problem into a set of subproblems whose solution yields a
solution to the larger problem. This approach can go wrong in several
ways.Decomposition failure. The solution to the decomposition does not in fact
yield a solution to the overall problem.Artificial hardness. The subproblems
created are sufficient if solved to solve the overall problem, but they are
harder than necessary.As you can see, computational complexity forms a
relatively new (in research-history) razor by which to judge an approach
sufficient but not necessary.In my experience, the artificial hardness problem
is very common. Many researchers abdicate the responsibility of choosing a
problem to work on to other people. This process starts very naturally as a
graduate student, when an incoming student might have relatively little idea
about how to do</p><p>6 0.745318 <a title="252-lda-6" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>7 0.74524289 <a title="252-lda-7" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>8 0.74403912 <a title="252-lda-8" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>9 0.74343151 <a title="252-lda-9" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>10 0.74101734 <a title="252-lda-10" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>11 0.74072409 <a title="252-lda-11" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>12 0.74008441 <a title="252-lda-12" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>13 0.73956722 <a title="252-lda-13" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>14 0.73875964 <a title="252-lda-14" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>15 0.73666185 <a title="252-lda-15" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>16 0.73616028 <a title="252-lda-16" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>17 0.73607576 <a title="252-lda-17" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>18 0.73571312 <a title="252-lda-18" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>19 0.73533052 <a title="252-lda-19" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>20 0.73522305 <a title="252-lda-20" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
