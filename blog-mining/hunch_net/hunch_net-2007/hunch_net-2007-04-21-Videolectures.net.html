<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>240 hunch net-2007-04-21-Videolectures.net</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-240" href="#">hunch_net-2007-240</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>240 hunch net-2007-04-21-Videolectures.net</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-240-html" href="http://hunch.net/?p=263">html</a></p><p>Introduction: Davorhas been working to setupvideolectures.netwhich is the new site for the
many lecturesmentioned here. (Tragically, they seem to only be available in
windows media format.) I went throughmy own projectsand added a few links to
the videos. The day when every result is a set of {paper, slides, video} isn't
quite here yet, but it's within sight. (For many papers, of course, code is a
4th component.)</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 netwhich is the new site for the many lecturesmentioned here. [sent-2, score-0.427]
</p><p>2 (Tragically, they seem to only be available in windows media format. [sent-3, score-0.708]
</p><p>3 ) I went throughmy own projectsand added a few links to the videos. [sent-4, score-0.839]
</p><p>4 The day when every result is a set of {paper, slides, video} isn't quite here yet, but it's within sight. [sent-5, score-0.956]
</p><p>5 (For many papers, of course, code is a 4th component. [sent-6, score-0.308]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('windows', 0.401), ('links', 0.321), ('video', 0.3), ('slides', 0.292), ('went', 0.277), ('site', 0.246), ('added', 0.241), ('day', 0.217), ('within', 0.204), ('code', 0.204), ('course', 0.185), ('available', 0.176), ('result', 0.167), ('every', 0.149), ('working', 0.144), ('seem', 0.131), ('yet', 0.129), ('quite', 0.111), ('papers', 0.11), ('set', 0.108), ('paper', 0.106), ('many', 0.104), ('new', 0.077)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="240-tfidf-1" href="../hunch_net-2007/hunch_net-2007-04-21-Videolectures.net.html">240 hunch net-2007-04-21-Videolectures.net</a></p>
<p>Introduction: Davorhas been working to setupvideolectures.netwhich is the new site for the
many lecturesmentioned here. (Tragically, they seem to only be available in
windows media format.) I went throughmy own projectsand added a few links to
the videos. The day when every result is a set of {paper, slides, video} isn't
quite here yet, but it's within sight. (For many papers, of course, code is a
4th component.)</p><p>2 0.14316267 <a title="240-tfidf-2" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect theNIPS 2006 workshopsto be quite interesting, and recommend going
for anyone interested in machine learning research. (Most or all of the
workshops webpages can be found two links deep.)</p><p>3 0.14047933 <a title="240-tfidf-3" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>Introduction: Yann and I have arranged so that people who are interested in ourlarge scale
machine learning classand not able to attend in person can follow along via
two methods.Videoswill be posted with about a 1 day delay ontechtalks. This is
a side-by-side capture of video+slides fromWeyond.We are experimenting
withPiazzaas a discussion forum. Anyone is welcome to subscribe to Piazza and
ask questions there, where I will be monitoring things.update2: Sign
uphere.The first lecture is up now, including therevised version of the
slideswhich fixes a few typos and rounds out references.</p><p>4 0.12700805 <a title="240-tfidf-4" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>Introduction: TheNew York ML symposiumwas last Friday. Attendance was 268, significantly
larger thanlast year. My impression was that the event mostly still fit the
space, although it was crowded. If anyone has suggestions for next year, speak
up.The best student paper award went toSergiu Goschinfor a cool video of how
his system learned to play video games (I can't find the paper online yet).
Choosing amongst the submitted talks was pretty difficult this year, as there
were many similarly good ones.By coincidence all the invited talks were (at
least potentially) about faster learning algorithms.Stephen Boydtalked
aboutADMM.Leon Bottouspoke on single pass online learning viaaveraged SGD.Yoav
Freundtalked aboutparameter-free hedging. In Yoav's case the talk was mostly
about a better theoretical learning algorithm, but it has the potential to
unlock an exponential computational complexity improvement via oraclization of
experts algorithmsâ&euro;Ś but some serious thought needs to go in this
direction.Unrelat</p><p>5 0.11035317 <a title="240-tfidf-5" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>Introduction: I'm not as naturally exuberant asMuthu2orDavidaboutCS/Econday, but I believe
it andML daywere certainly successful.At the CS/Econ day, I particularly
enjoyedToumas Sandholm'stalk which showed a commanding depth of understanding
and application in automated auctions.For the machine learning day, I enjoyed
several talks and posters (I better, I helped pick them.). What stood out to
me was number of people attending: 158 registered, a level qualifying as
"scramble to find seats". My rule of thumb for workshops/conferences is that
the number of attendees is often something like the number of submissions.
That isn't the case here, where there were just 4 invited speakers and 30-or-
so posters. Presumably, the difference is due to a critical mass of Machine
Learning interested people in the area and the ease of their attendance.Are
there other areas where a local Machine Learning day would fly? It's easy to
imagine something working out in the San Francisco bay area and possibly
Germany or E</p><p>6 0.091025442 <a title="240-tfidf-6" href="../hunch_net-2010/hunch_net-2010-10-29-To_Vidoelecture_or_not.html">416 hunch net-2010-10-29-To Vidoelecture or not</a></p>
<p>7 0.089258961 <a title="240-tfidf-7" href="../hunch_net-2005/hunch_net-2005-12-09-Machine_Learning_Thoughts.html">137 hunch net-2005-12-09-Machine Learning Thoughts</a></p>
<p>8 0.086355858 <a title="240-tfidf-8" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>9 0.086296856 <a title="240-tfidf-9" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>10 0.08441674 <a title="240-tfidf-10" href="../hunch_net-2010/hunch_net-2010-04-14-MLcomp%3A_a_website_for_objectively_comparing_ML_algorithms.html">393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</a></p>
<p>11 0.082872897 <a title="240-tfidf-11" href="../hunch_net-2012/hunch_net-2012-09-29-Vowpal_Wabbit%2C_version_7.0.html">473 hunch net-2012-09-29-Vowpal Wabbit, version 7.0</a></p>
<p>12 0.082227588 <a title="240-tfidf-12" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>13 0.081372857 <a title="240-tfidf-13" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>14 0.077906951 <a title="240-tfidf-14" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>15 0.071861163 <a title="240-tfidf-15" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>16 0.070284039 <a title="240-tfidf-16" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>17 0.068730131 <a title="240-tfidf-17" href="../hunch_net-2009/hunch_net-2009-12-09-Inherent_Uncertainty.html">383 hunch net-2009-12-09-Inherent Uncertainty</a></p>
<p>18 0.068498023 <a title="240-tfidf-18" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>19 0.068024166 <a title="240-tfidf-19" href="../hunch_net-2012/hunch_net-2012-06-15-Normal_Deviate_and_the_UCSC_Machine_Learning_Summer_School.html">467 hunch net-2012-06-15-Normal Deviate and the UCSC Machine Learning Summer School</a></p>
<p>20 0.067819215 <a title="240-tfidf-20" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.125), (1, 0.061), (2, 0.017), (3, 0.041), (4, -0.012), (5, 0.066), (6, 0.101), (7, -0.053), (8, 0.086), (9, 0.009), (10, -0.006), (11, 0.04), (12, -0.046), (13, -0.014), (14, -0.092), (15, 0.055), (16, 0.103), (17, -0.04), (18, -0.01), (19, 0.04), (20, 0.15), (21, 0.06), (22, -0.049), (23, -0.061), (24, -0.005), (25, -0.04), (26, -0.054), (27, 0.065), (28, -0.003), (29, -0.041), (30, -0.011), (31, 0.059), (32, 0.073), (33, 0.012), (34, -0.071), (35, 0.042), (36, 0.05), (37, -0.038), (38, -0.058), (39, 0.05), (40, -0.03), (41, 0.05), (42, 0.027), (43, -0.008), (44, 0.002), (45, -0.113), (46, 0.001), (47, -0.015), (48, -0.014), (49, -0.132)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97084439 <a title="240-lsi-1" href="../hunch_net-2007/hunch_net-2007-04-21-Videolectures.net.html">240 hunch net-2007-04-21-Videolectures.net</a></p>
<p>Introduction: Davorhas been working to setupvideolectures.netwhich is the new site for the
many lecturesmentioned here. (Tragically, they seem to only be available in
windows media format.) I went throughmy own projectsand added a few links to
the videos. The day when every result is a set of {paper, slides, video} isn't
quite here yet, but it's within sight. (For many papers, of course, code is a
4th component.)</p><p>2 0.61666024 <a title="240-lsi-2" href="../hunch_net-2013/hunch_net-2013-07-24-ICML_2012_videos_lost.html">487 hunch net-2013-07-24-ICML 2012 videos lost</a></p>
<p>Introduction: A big ouch--all the videos for ICML 2012 were lost in a shuffle. Rajnish sends
the below, but if anyone can help that would be greatly appreciated.
----------------------------------------------------Sincere apologies to ICML
community for loosing 2012 archived videosWhat happened: In order to publish
2013 videos, we decided to move 2012 videos to another server. We have a
weekly backup service from the provider but after removing the videos from the
current server, when we tried to retrieve the 2012 videos from backup service,
the backup did not work because of provider-specific requirements that we had
ignored while removing the data from previous server.What are we doing about
this: At this point, we are still looking into raw footage to find if we can
retrieve some of the videos, but following are the steps we are taking to make
sure this does not happen again in future:(1) We are going to create a channel
on Vimeo (and potentially on YouTube) and we will publish there the p-in-p-</p><p>3 0.59788018 <a title="240-lsi-3" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>Introduction: I tweaked the site in a number of ways today, including:Updating
toWordPress1.5.Installing and heavily tweaking theGeeknichetheme. Update: I
switched back to a tweaked version of the old theme.Adding theCustomizable
Post Listingsplugin.Installing theStatTraqplugin.Updating some of the links. I
particularly recommend looking at thecomputer research
policyblog.Addingthreaded comments. This doesn't thread old comments
obviously, but the extra structure may be helpful for new ones.Overall, I
think this is an improvement, and it addresses a few of myearlier problems. If
you have any difficulties or anything seems "not quite right", please speak
up. A few other tweaks to the site may happen in the near future.</p><p>4 0.59165293 <a title="240-lsi-4" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>Introduction: The hunch.net server has been updated. I've taken the opportunity to upgrade
the version of wordpress which caused cascading changes.Old threaded comments
are now flattened. The system we used to use (Brian's threaded comments)
appears incompatible with the new threading system built into wordpress. I
haven't yet figured out a workaround.I setup afeedburner account.I added an
RSS aggregator for both Machine Learning and other research blogs that I like
to follow. This is something that I've wanted to do for awhile.Many other
minor changes in font and format, with some help fromAlina.If you have any
suggestions for site tweaks, please speak up.</p><p>5 0.57446486 <a title="240-lsi-5" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>Introduction: Yann and I have arranged so that people who are interested in ourlarge scale
machine learning classand not able to attend in person can follow along via
two methods.Videoswill be posted with about a 1 day delay ontechtalks. This is
a side-by-side capture of video+slides fromWeyond.We are experimenting
withPiazzaas a discussion forum. Anyone is welcome to subscribe to Piazza and
ask questions there, where I will be monitoring things.update2: Sign
uphere.The first lecture is up now, including therevised version of the
slideswhich fixes a few typos and rounds out references.</p><p>6 0.48558396 <a title="240-lsi-6" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>7 0.4532716 <a title="240-lsi-7" href="../hunch_net-2013/hunch_net-2013-06-10-The_Large_Scale_Learning_class_notes.html">483 hunch net-2013-06-10-The Large Scale Learning class notes</a></p>
<p>8 0.45324689 <a title="240-lsi-8" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>9 0.44602558 <a title="240-lsi-9" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>10 0.43742809 <a title="240-lsi-10" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>11 0.43506265 <a title="240-lsi-11" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>12 0.43142477 <a title="240-lsi-12" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>13 0.42736706 <a title="240-lsi-13" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>14 0.4179818 <a title="240-lsi-14" href="../hunch_net-2006/hunch_net-2006-06-05-Server_Shift%2C_Site_Tweaks%2C_Suggestions%3F.html">182 hunch net-2006-06-05-Server Shift, Site Tweaks, Suggestions?</a></p>
<p>15 0.41087741 <a title="240-lsi-15" href="../hunch_net-2005/hunch_net-2005-06-13-Wikis_for_Summer_Schools_and_Workshops.html">81 hunch net-2005-06-13-Wikis for Summer Schools and Workshops</a></p>
<p>16 0.41011515 <a title="240-lsi-16" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>17 0.40922025 <a title="240-lsi-17" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>18 0.40746993 <a title="240-lsi-18" href="../hunch_net-2006/hunch_net-2006-04-14-JMLR_is_a_success.html">172 hunch net-2006-04-14-JMLR is a success</a></p>
<p>19 0.39918903 <a title="240-lsi-19" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>20 0.39096093 <a title="240-lsi-20" href="../hunch_net-2010/hunch_net-2010-04-14-MLcomp%3A_a_website_for_objectively_comparing_ML_algorithms.html">393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.218), (74, 0.256), (90, 0.346)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91970295 <a title="240-lda-1" href="../hunch_net-2007/hunch_net-2007-04-21-Videolectures.net.html">240 hunch net-2007-04-21-Videolectures.net</a></p>
<p>Introduction: Davorhas been working to setupvideolectures.netwhich is the new site for the
many lecturesmentioned here. (Tragically, they seem to only be available in
windows media format.) I went throughmy own projectsand added a few links to
the videos. The day when every result is a set of {paper, slides, video} isn't
quite here yet, but it's within sight. (For many papers, of course, code is a
4th component.)</p><p>2 0.85386688 <a title="240-lda-2" href="../hunch_net-2006/hunch_net-2006-05-01-A_conversation_between_Theo_and_Pat.html">176 hunch net-2006-05-01-A conversation between Theo and Pat</a></p>
<p>Introduction: Pat (the practitioner)I need to do multiclass classification and I only have a
decision tree.Theo (the thoeretician)Use anerror correcting output code.PatOh,
that's cool. But the created binary problems seem unintuitive. I'm not sure
the decision tree can solve them.TheoOh? Is your problem a decision
list?PatNo, I don't think so.TheoHmm. Are the classes well separated by axis
aligned splits?PatErr, maybe. I'm not sure.TheoWell, if they are, under the
IID assumption I can tell you how many samples you need.PatIID? The data is
definitely not IID.TheoOh dear.PatCan we get back to the choice of ECOC? I
suspect we need to build it dynamically in response to which subsets of the
labels are empirically separable from each other.TheoOk. What do you know
about your problem?PatNot much. My friend just gave me the dataset.TheoThen,
no one can help you.Pat(What a fuzzy thinker. Theo keeps jumping to
assumptions that just aren't true.)Theo(What a fuzzy thinker. Pat's problem is
unsolvable without m</p><p>3 0.72093511 <a title="240-lda-3" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>Introduction: At thelast ICML,Tom Dietterichasked me to look into systems for commenting on
papers. I've been slow getting to this, but it's relevant now.The essential
observation is that we now have many tools for online collaboration, but they
are not yet much used in academic research. If we can find the right way to
use them, then perhaps great things might happen, with extra kudos to the
first conference that manages to really create an online community. Various
conferences have been poking at this. For example,UAI has setup a wiki, COLT
hasstarted usingJoomla, with some dynamic content, and AAAI has been setting
up a "student blog". Similarly,Dinoj Surendransetup a twiki for theChicago
Machine Learning Summer School, which was quite useful for coordinating events
and other things.I believe the most important thing is a willingness to
experiment. A good place to start seems to be enhancing existing conference
websites. For example, theICML 2007 papers pageis basically only useful via
grep. A mu</p><p>4 0.69296587 <a title="240-lda-4" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>Introduction: One of the common trends in machine learning has been an emphasis on the use
of unlabeled data. The argument goes something like "there aren't many labeled
web pages out there, but there are ahugenumber of web pages, so we must find a
way to take advantage of them." There are several standard approaches for
doing this:Unsupervised Learning. You use only unlabeled data. In a typical
application, you cluster the data and hope that the clusters somehow
correspond to what you care about.Semisupervised Learning. You use both
unlabeled and labeled data to build a predictor. The unlabeled data influences
the learned predictor in some way.Active Learning. You have unlabeled data and
access to a labeling oracle. You interactively choose which examples to label
so as to optimize prediction accuracy.It seems there is a fourth approach
worth serious investigation--automated labeling. The approach goes as
follows:Identify some subset of observed values to predict from the
others.Build a predictor.U</p><p>5 0.69037944 <a title="240-lda-5" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>Introduction: Parallel machine learning is a subject rarely addressed at machine learning
conferences. Nevertheless, it seems likely to increase in importance
because:Data set sizes appear to be growing substantially faster than
computation. Essentially, this happens because more and more sensors of
various sorts are being hooked up to the internet.Serial speedups of
processors seem are relatively stalled. The new trend is to make processors
more powerful by making themmulticore.BothAMDandIntelare making dual core
designs standard, with plans for more parallelism in the future.IBM'sCell
processorhas (essentially) 9 cores.Modern graphics chips can have an order of
magnitude more separate execution units.The meaning of 'core' varies a bit
from processor to processor, but the overall trend seems quite clear.So, how
do we parallelize machine learning algorithms?The simplest and most common
technique is to simply run the same learning algorithm with different
parameters on different processors. Cluster m</p><p>6 0.68778944 <a title="240-lda-6" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>7 0.6799947 <a title="240-lda-7" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>8 0.67745 <a title="240-lda-8" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>9 0.67734241 <a title="240-lda-9" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>10 0.67521954 <a title="240-lda-10" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>11 0.66916913 <a title="240-lda-11" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>12 0.66503739 <a title="240-lda-12" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>13 0.66045916 <a title="240-lda-13" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>14 0.65784889 <a title="240-lda-14" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>15 0.64926279 <a title="240-lda-15" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>16 0.64925373 <a title="240-lda-16" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>17 0.64923334 <a title="240-lda-17" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>18 0.6487872 <a title="240-lda-18" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>19 0.6485703 <a title="240-lda-19" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>20 0.64766443 <a title="240-lda-20" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
