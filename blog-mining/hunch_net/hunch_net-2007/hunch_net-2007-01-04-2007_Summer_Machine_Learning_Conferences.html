<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-226" href="#">hunch_net-2007-226</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-226-html" href="http://hunch.net/?p=247">html</a></p><p>Introduction: It's conference season once again.ConferenceDue?When?Where?double blind?author
feedback?Workshops?AAAIFebruary 1/6 (and 27)July 22-26Vancouver, British
ColumbiaYesYesDoneUAIFebruary 28/March 2July 19-22Vancouver, British
ColumbiaNoNoNoCOLTJanuary 16June 13-15San Diego, California
(withFCRC)NoNoNoICMLFebruary 7/9June 20-24Corvallis, OregonYesYesFebruary
16KDDFebruary 23/28August 12-15San Jose, CaliforniaYesNo?February 28The
geowinner this year is the west coast of North America.Last year's geowinner
was the Northeastern US, and theyear beforeit was mostly Europe. It's notable
how tightly the conferences cluster, even when they don't colocate.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('geowinner', 0.518), ('british', 0.426), ('northeastern', 0.23), ('coast', 0.23), ('west', 0.23), ('diego', 0.201), ('season', 0.192), ('tightly', 0.192), ('california', 0.192), ('july', 0.172), ('february', 0.172), ('notable', 0.167), ('cluster', 0.149), ('year', 0.142), ('mostly', 0.134), ('blind', 0.132), ('double', 0.132), ('workshops', 0.118), ('feedback', 0.105), ('author', 0.105)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="226-tfidf-1" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>Introduction: It's conference season once again.ConferenceDue?When?Where?double blind?author
feedback?Workshops?AAAIFebruary 1/6 (and 27)July 22-26Vancouver, British
ColumbiaYesYesDoneUAIFebruary 28/March 2July 19-22Vancouver, British
ColumbiaNoNoNoCOLTJanuary 16June 13-15San Diego, California
(withFCRC)NoNoNoICMLFebruary 7/9June 20-24Corvallis, OregonYesYesFebruary
16KDDFebruary 23/28August 12-15San Jose, CaliforniaYesNo?February 28The
geowinner this year is the west coast of North America.Last year's geowinner
was the Northeastern US, and theyear beforeit was mostly Europe. It's notable
how tightly the conferences cluster, even when they don't colocate.</p><p>2 0.32009581 <a title="226-tfidf-2" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>Introduction: Machine learning always welcomes the new year with paper deadlines for summer
conferences. This year, we have:ConferencePaper DeadlineWhen/WhereDouble
blind?Author Feedback?NotesICMLFebruary 1June 28-July 2, Bellevue, Washington,
USAYYWeak colocation withACLCOLTFebruary 11July 9-July 11, Budapest,
HungaryNNcolocated withFOCMKDDFebruary 11/18August 21-24, San Diego,
California, USANNUAIMarch 18July 14-17, Barcelona, SpainYNThe larger
conferences are on the west coast in the United States, while the smaller ones
are in Europe.</p><p>3 0.22806975 <a title="226-tfidf-3" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>Introduction: Many conference deadlines are coming soon.DeadlineDouble Blind / Author
FeedbackTime/PlaceICMLJanuary 18((workshops) / February 1 (Papers) / February
13 (Tutorials)Y/YHaifa, Israel, June 21-25KDDFebruary 1(Workshops) / February
2&5 (Papers) / February 26 (Tutorials & Panels)) / April 17
(Demos)N/SWashington DC, July 25-28COLTJanuary 18 (Workshops) / February 19
(Papers)N/SHaifa, Israel, June 25-29UAIMarch 11 (Papers)N?/YCatalina Island,
California, July 8-11ICML continues to experiment with the reviewing process,
although perhaps less so than last year.The S "sort-of" for COLT is because
author feedback occurs only after decisions are made.KDD is notable for being
the most comprehensive in terms of {Tutorials, Workshops, Challenges, Panels,
Papers (two tracks), Demos}. The S for KDD is because there is sometimes
author feedback at the decision of the SPC.The (past) January 18 deadline for
workshops at ICML is nominal, as I (as workshop chair) almost missed it myself
and we have space f</p><p>4 0.14858666 <a title="226-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>Introduction: It's conference season, and smell of budding papers is in the air.IJCAI 2005,
January 21COLT 2005, February 2KDD 2005, February 18ICML 2005, March 8UAI
2005, March 16AAAI 2005, March 18</p><p>5 0.12962508 <a title="226-tfidf-5" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>6 0.12608162 <a title="226-tfidf-6" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>7 0.11308911 <a title="226-tfidf-7" href="../hunch_net-2005/hunch_net-2005-11-16-MLSS_2006.html">130 hunch net-2005-11-16-MLSS 2006</a></p>
<p>8 0.10368221 <a title="226-tfidf-8" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>9 0.094654359 <a title="226-tfidf-9" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>10 0.094304636 <a title="226-tfidf-10" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>11 0.09421996 <a title="226-tfidf-11" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>12 0.081728652 <a title="226-tfidf-12" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>13 0.076075472 <a title="226-tfidf-13" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>14 0.075447284 <a title="226-tfidf-14" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>15 0.074906364 <a title="226-tfidf-15" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>16 0.074179411 <a title="226-tfidf-16" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>17 0.072803631 <a title="226-tfidf-17" href="../hunch_net-2006/hunch_net-2006-07-25-Upcoming_conference.html">198 hunch net-2006-07-25-Upcoming conference</a></p>
<p>18 0.066625454 <a title="226-tfidf-18" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>19 0.064304441 <a title="226-tfidf-19" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>20 0.061921664 <a title="226-tfidf-20" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.062), (1, 0.149), (2, -0.021), (3, 0.148), (4, -0.009), (5, -0.055), (6, -0.034), (7, 0.055), (8, 0.003), (9, 0.003), (10, -0.025), (11, -0.214), (12, 0.025), (13, -0.06), (14, 0.087), (15, -0.105), (16, 0.065), (17, 0.092), (18, 0.011), (19, -0.152), (20, -0.014), (21, 0.026), (22, -0.056), (23, 0.033), (24, -0.075), (25, -0.022), (26, 0.091), (27, 0.081), (28, -0.016), (29, 0.07), (30, 0.068), (31, 0.002), (32, -0.07), (33, -0.029), (34, -0.091), (35, -0.091), (36, 0.021), (37, -0.037), (38, -0.025), (39, -0.03), (40, -0.003), (41, -0.031), (42, 0.122), (43, -0.07), (44, -0.023), (45, -0.088), (46, 0.01), (47, 0.073), (48, 0.024), (49, -0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98498112 <a title="226-lsi-1" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>Introduction: It's conference season once again.ConferenceDue?When?Where?double blind?author
feedback?Workshops?AAAIFebruary 1/6 (and 27)July 22-26Vancouver, British
ColumbiaYesYesDoneUAIFebruary 28/March 2July 19-22Vancouver, British
ColumbiaNoNoNoCOLTJanuary 16June 13-15San Diego, California
(withFCRC)NoNoNoICMLFebruary 7/9June 20-24Corvallis, OregonYesYesFebruary
16KDDFebruary 23/28August 12-15San Jose, CaliforniaYesNo?February 28The
geowinner this year is the west coast of North America.Last year's geowinner
was the Northeastern US, and theyear beforeit was mostly Europe. It's notable
how tightly the conferences cluster, even when they don't colocate.</p><p>2 0.8098467 <a title="226-lsi-2" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>Introduction: Machine learning always welcomes the new year with paper deadlines for summer
conferences. This year, we have:ConferencePaper DeadlineWhen/WhereDouble
blind?Author Feedback?NotesICMLFebruary 1June 28-July 2, Bellevue, Washington,
USAYYWeak colocation withACLCOLTFebruary 11July 9-July 11, Budapest,
HungaryNNcolocated withFOCMKDDFebruary 11/18August 21-24, San Diego,
California, USANNUAIMarch 18July 14-17, Barcelona, SpainYNThe larger
conferences are on the west coast in the United States, while the smaller ones
are in Europe.</p><p>3 0.68552625 <a title="226-lsi-3" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>Introduction: Many conference deadlines are coming soon.DeadlineDouble Blind / Author
FeedbackTime/PlaceICMLJanuary 18((workshops) / February 1 (Papers) / February
13 (Tutorials)Y/YHaifa, Israel, June 21-25KDDFebruary 1(Workshops) / February
2&5 (Papers) / February 26 (Tutorials & Panels)) / April 17
(Demos)N/SWashington DC, July 25-28COLTJanuary 18 (Workshops) / February 19
(Papers)N/SHaifa, Israel, June 25-29UAIMarch 11 (Papers)N?/YCatalina Island,
California, July 8-11ICML continues to experiment with the reviewing process,
although perhaps less so than last year.The S "sort-of" for COLT is because
author feedback occurs only after decisions are made.KDD is notable for being
the most comprehensive in terms of {Tutorials, Workshops, Challenges, Panels,
Papers (two tracks), Demos}. The S for KDD is because there is sometimes
author feedback at the decision of the SPC.The (past) January 18 deadline for
workshops at ICML is nominal, as I (as workshop chair) almost missed it myself
and we have space f</p><p>4 0.58501989 <a title="226-lsi-4" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>5 0.49471095 <a title="226-lsi-5" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>6 0.48656517 <a title="226-lsi-6" href="../hunch_net-2005/hunch_net-2005-11-16-MLSS_2006.html">130 hunch net-2005-11-16-MLSS 2006</a></p>
<p>7 0.41776666 <a title="226-lsi-7" href="../hunch_net-2012/hunch_net-2012-07-17-MUCMD_and_BayLearn.html">470 hunch net-2012-07-17-MUCMD and BayLearn</a></p>
<p>8 0.40043828 <a title="226-lsi-8" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>9 0.38920611 <a title="226-lsi-9" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>10 0.38717452 <a title="226-lsi-10" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>11 0.38096708 <a title="226-lsi-11" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>12 0.36055377 <a title="226-lsi-12" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>13 0.35445443 <a title="226-lsi-13" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>14 0.33684868 <a title="226-lsi-14" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>15 0.33122692 <a title="226-lsi-15" href="../hunch_net-2012/hunch_net-2012-06-15-Normal_Deviate_and_the_UCSC_Machine_Learning_Summer_School.html">467 hunch net-2012-06-15-Normal Deviate and the UCSC Machine Learning Summer School</a></p>
<p>16 0.32363483 <a title="226-lsi-16" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>17 0.32198098 <a title="226-lsi-17" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>18 0.31930453 <a title="226-lsi-18" href="../hunch_net-2006/hunch_net-2006-06-15-IJCAI_is_out_of_season.html">184 hunch net-2006-06-15-IJCAI is out of season</a></p>
<p>19 0.30339733 <a title="226-lsi-19" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>20 0.30161986 <a title="226-lsi-20" href="../hunch_net-2006/hunch_net-2006-04-17-Rexa_is_live.html">173 hunch net-2006-04-17-Rexa is live</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(15, 0.55), (42, 0.043), (74, 0.1), (82, 0.124)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94846934 <a title="226-lda-1" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>Introduction: It's conference season once again.ConferenceDue?When?Where?double blind?author
feedback?Workshops?AAAIFebruary 1/6 (and 27)July 22-26Vancouver, British
ColumbiaYesYesDoneUAIFebruary 28/March 2July 19-22Vancouver, British
ColumbiaNoNoNoCOLTJanuary 16June 13-15San Diego, California
(withFCRC)NoNoNoICMLFebruary 7/9June 20-24Corvallis, OregonYesYesFebruary
16KDDFebruary 23/28August 12-15San Jose, CaliforniaYesNo?February 28The
geowinner this year is the west coast of North America.Last year's geowinner
was the Northeastern US, and theyear beforeit was mostly Europe. It's notable
how tightly the conferences cluster, even when they don't colocate.</p><p>2 0.55278224 <a title="226-lda-2" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>Introduction: Many of the large machine learning conferences were in the US this summer. A
common problem which students from abroad encounter is visa issues.Just
getting a visa to visit can be pretty rough: you stand around in lines,
sometimes for days. Even worse is the timing with respect to ticket buying.
Airplane tickets typically need to be bought well in advance on nonrefundable
terms to secure a reasonable rate for air travel. When a visa is denied, as
happens reasonably often, a very expensive ticket is burnt.A serious effort is
under way to raise this as in issue in need of fixing. Over the long term,
effectively driving research conferences to locate outside of the US seems an
unwise policy.Robert Schapireis planning to talk to a congressman.Sally
Goldmansuggested putting together a list of problem cases, andPhil Longsetup
an email addressimmigration.and.confs@gmail.comto collect them.If you (or
someone you know) has had insurmountable difficulties reaching a conference in
the US, please</p><p>3 0.411194 <a title="226-lda-3" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>Introduction: There area handful of basic code patternsthat I wish I was more aware of when
I started research in machine learning. Each on its own may seem pointless,
but collectively they go a long way towards making the typical research
workflow more efficient. Here they are:Separate code from data.Separate input
data, working data and output data.Save everything to disk frequently.Separate
options from parameters.Do not use global variables.Record the options used to
generate each run of the algorithm.Make it easy to sweep options.Make it easy
to execute only portions of the code.Use checkpointing.Write demos and
tests.Clickherefor discussion and examples for each item. Also seeCharles
Sutton'sandHackerNews'thoughts on the same topic.My guess is that these
patterns will not only be useful for machine learning, but also any other
computational work that involves either a) processing large amounts of data,
or b) algorithms that take a significant amount of time to execute. Share this
list with you</p><p>4 0.38838431 <a title="226-lda-4" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a
data source (Example:X x {0,1},X x [0,1],X x {1,2,3,4,5}, etc…) and a loss
function (0/1 loss, squared error loss, cost sensitive losses, etc…). For
simplicity, we'll assume that all losses have a minimum of zero.For this post,
we can think of a learning reduction asA mappingRfrom samples of one
typeT(like multiclass classification) to another typeT'(like binary
classification).A mappingQfrom predictors for typeT'to predictors for
typeT.The simplest sort of learning reduction is a "loss reduction". The idea
in a loss reduction is to prove a statement of the form:TheoremFor all base
predictorsb, for all distributionsDover examples of typeT:E(x,y) ~
DLT(y,Q(b,x)) <= f(E(x',y')~R(D)LT'(y',b(x')))HereLTis the loss for the
typeTproblem andLT'is the loss for the typeT'problem. Also,R(D)is the
distribution over samples induced by first drawing fromDand then mapping the
sample viaR. The functionf()is the loss transf</p><p>5 0.27555269 <a title="226-lda-5" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>6 0.26500094 <a title="226-lda-6" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>7 0.2553457 <a title="226-lda-7" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>8 0.25139415 <a title="226-lda-8" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>9 0.23934694 <a title="226-lda-9" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>10 0.22094609 <a title="226-lda-10" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>11 0.21453987 <a title="226-lda-11" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>12 0.21173435 <a title="226-lda-12" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>13 0.20522782 <a title="226-lda-13" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>14 0.20240888 <a title="226-lda-14" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>15 0.19866866 <a title="226-lda-15" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>16 0.19732884 <a title="226-lda-16" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>17 0.19592978 <a title="226-lda-17" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>18 0.19446376 <a title="226-lda-18" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>19 0.19233996 <a title="226-lda-19" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>20 0.19166499 <a title="226-lda-20" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
