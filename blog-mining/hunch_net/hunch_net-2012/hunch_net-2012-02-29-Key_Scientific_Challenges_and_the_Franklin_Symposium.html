<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2012" href="../home/hunch_net-2012_home.html">hunch_net-2012</a> <a title="hunch_net-2012-457" href="#">hunch_net-2012-457</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2012-457-html" href="http://hunch.net/?p=2308">html</a></p><p>Introduction: For graduate students, the  Yahoo!   Key Scientific Challenges program  including in  machine learning  is on again,  due March 9 .  The application is easy and the $5K award is high quality “no strings attached” funding.   Consider submitting.
 
Those in Washington DC, Philadelphia, and New York, may consider attending the  Franklin Institute Symposium   April 25  which has several speakers and an award for  V .  Attendance is free with an RSVP.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Key Scientific Challenges program  including in  machine learning  is on again,  due March 9 . [sent-2, score-0.354]
</p><p>2 The application is easy and the $5K award is high quality “no strings attached” funding. [sent-3, score-1.033]
</p><p>3 Those in Washington DC, Philadelphia, and New York, may consider attending the  Franklin Institute Symposium   April 25  which has several speakers and an award for  V . [sent-5, score-1.01]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('award', 0.37), ('philadelphia', 0.268), ('attached', 0.248), ('dc', 0.248), ('washington', 0.248), ('strings', 0.234), ('institute', 0.214), ('april', 0.2), ('scientific', 0.195), ('consider', 0.186), ('challenges', 0.185), ('speakers', 0.177), ('attendance', 0.173), ('graduate', 0.173), ('attending', 0.173), ('march', 0.164), ('symposium', 0.161), ('yahoo', 0.156), ('york', 0.147), ('key', 0.138), ('students', 0.138), ('free', 0.123), ('application', 0.122), ('quality', 0.121), ('including', 0.108), ('high', 0.106), ('program', 0.103), ('due', 0.088), ('easy', 0.08), ('may', 0.053), ('several', 0.051), ('new', 0.047), ('machine', 0.039), ('learning', 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="457-tfidf-1" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>Introduction: For graduate students, the  Yahoo!   Key Scientific Challenges program  including in  machine learning  is on again,  due March 9 .  The application is easy and the $5K award is high quality “no strings attached” funding.   Consider submitting.
 
Those in Washington DC, Philadelphia, and New York, may consider attending the  Franklin Institute Symposium   April 25  which has several speakers and an award for  V .  Attendance is free with an RSVP.</p><p>2 0.27593055 <a title="457-tfidf-2" href="../hunch_net-2011/hunch_net-2011-02-25-Yahoo%21_Machine_Learning_grant_due_March_11.html">425 hunch net-2011-02-25-Yahoo! Machine Learning grant due March 11</a></p>
<p>Introduction: Yahoo!’s  Key Scientific Challenges  for  Machine Learning  grant applications are due March 11.  If you are a student working on relevant research, please consider applying.  It’s for $5K of unrestricted funding.</p><p>3 0.18134223 <a title="457-tfidf-3" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>Introduction: Perhaps the biggest CS prize for research is the  Turing Award , which has a $0.25M cash prize associated with it.  It appears none of the prizes so far have been for anything like machine learning (the closest are perhaps database awards).
 
In CS theory, there is the  GÃƒÂ¶del Prize  which is smaller and newer, offering a $5K prize along and perhaps (more importantly) recognition.  One such award has been given for Machine Learning, to  Robert Schapire  and  Yoav Freund  for Adaboost.
 
In Machine Learning, there seems to be no equivalent of these sorts of prizes.  There are several plausible reasons for this:
  
 
 There is no coherent community. 
  People drift in and out of the central conferences all the time.  Most of the author names from 10 years ago do not occur in the conferences of today.  In addition, the entire subject area is fairly new. 
 There are at least a core group of people who have stayed around. 
 
 
 Machine Learning work doesn’t last 
 Almost every paper is fo</p><p>4 0.16203298 <a title="457-tfidf-4" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>Introduction: Yahoo! is sponsoring two machine learning events that might interest people.  
  
 The  Key Scientific Challenges  program (due March 5) for  Machine Learning  and  Statistics  offers $5K (plus bonuses) for graduate students working on a core problem of interest to Y!  If you are already working on one of these problems, there is no reason not to submit, and if you arenâ&euro;&trade;t you might want to think about it for next year, as I am confident they all press the boundary of the possible in Machine Learning.   There are 7 days left. 
 The  Learning to Rank challenge  (due May 31) offers an $8K first prize for the best ranking algorithm on a real (and really used) dataset for search ranking, with presentations at an ICML workshop.  Unlike the Netflix competition, there are prizes for 2nd, 3rd, and 4th place, perhaps avoiding the heartbreak  the ensemble  encountered.  If you think you know how to rank, you should give it a try, and we might all learn something.  There are 3 months left.</p><p>5 0.16170736 <a title="457-tfidf-5" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>Introduction: Yahoo released the  Key Scientific Challenges  program.  There is a  Machine Learning  list I worked on and a  Statistics  list which  Deepak  worked on.
 
I’m hoping this is taken quite seriously by graduate students.  The primary value, is that it gave us a chance to sit down and publicly specify directions of research which would be valuable to make progress on.  A good strategy for a beginning graduate student is to pick one of these directions, pursue it, and make substantial advances for a PhD.  The directions are sufficiently general that I’m sure any serious advance has applications well beyond Yahoo.
 
A secondary point, (which I’m sure is primary for many    ) is that there is money for graduate students here.  It’s unrestricted, so you can use it for any reasonable travel, supplies, etc…</p><p>6 0.13365734 <a title="457-tfidf-6" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>7 0.12784587 <a title="457-tfidf-7" href="../hunch_net-2012/hunch_net-2012-12-29-Simons_Institute_Big_Data_Program.html">476 hunch net-2012-12-29-Simons Institute Big Data Program</a></p>
<p>8 0.12594301 <a title="457-tfidf-8" href="../hunch_net-2013/hunch_net-2013-09-20-No_NY_ML_Symposium_in_2013%2C_and_some_good_news.html">489 hunch net-2013-09-20-No NY ML Symposium in 2013, and some good news</a></p>
<p>9 0.12373532 <a title="457-tfidf-9" href="../hunch_net-2011/hunch_net-2011-04-23-ICML_workshops_due.html">433 hunch net-2011-04-23-ICML workshops due</a></p>
<p>10 0.11709286 <a title="457-tfidf-10" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>11 0.10972799 <a title="457-tfidf-11" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>12 0.10945767 <a title="457-tfidf-12" href="../hunch_net-2008/hunch_net-2008-09-04-Fall_ML_Conferences.html">316 hunch net-2008-09-04-Fall ML Conferences</a></p>
<p>13 0.10649548 <a title="457-tfidf-13" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>14 0.10503451 <a title="457-tfidf-14" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>15 0.10198723 <a title="457-tfidf-15" href="../hunch_net-2012/hunch_net-2012-03-24-David_Waltz.html">460 hunch net-2012-03-24-David Waltz</a></p>
<p>16 0.099067137 <a title="457-tfidf-16" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>17 0.098125309 <a title="457-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>18 0.09609957 <a title="457-tfidf-18" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>19 0.091749005 <a title="457-tfidf-19" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>20 0.090914845 <a title="457-tfidf-20" href="../hunch_net-2007/hunch_net-2007-11-16-MLSS_2008.html">273 hunch net-2007-11-16-MLSS 2008</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.099), (1, -0.116), (2, -0.137), (3, -0.06), (4, -0.076), (5, -0.037), (6, -0.036), (7, 0.066), (8, -0.167), (9, -0.185), (10, 0.143), (11, 0.003), (12, 0.103), (13, -0.014), (14, 0.042), (15, 0.102), (16, -0.064), (17, -0.054), (18, -0.057), (19, -0.132), (20, 0.078), (21, 0.068), (22, 0.094), (23, -0.093), (24, 0.129), (25, 0.12), (26, -0.019), (27, -0.126), (28, 0.092), (29, -0.002), (30, -0.132), (31, 0.098), (32, 0.049), (33, -0.046), (34, 0.019), (35, 0.068), (36, -0.048), (37, 0.046), (38, -0.042), (39, 0.02), (40, -0.054), (41, 0.014), (42, 0.125), (43, -0.006), (44, -0.017), (45, 0.023), (46, 0.03), (47, -0.042), (48, 0.017), (49, -0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98146707 <a title="457-lsi-1" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>Introduction: For graduate students, the  Yahoo!   Key Scientific Challenges program  including in  machine learning  is on again,  due March 9 .  The application is easy and the $5K award is high quality “no strings attached” funding.   Consider submitting.
 
Those in Washington DC, Philadelphia, and New York, may consider attending the  Franklin Institute Symposium   April 25  which has several speakers and an award for  V .  Attendance is free with an RSVP.</p><p>2 0.81348455 <a title="457-lsi-2" href="../hunch_net-2011/hunch_net-2011-02-25-Yahoo%21_Machine_Learning_grant_due_March_11.html">425 hunch net-2011-02-25-Yahoo! Machine Learning grant due March 11</a></p>
<p>Introduction: Yahoo!’s  Key Scientific Challenges  for  Machine Learning  grant applications are due March 11.  If you are a student working on relevant research, please consider applying.  It’s for $5K of unrestricted funding.</p><p>3 0.71343958 <a title="457-lsi-3" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>Introduction: Yahoo released the  Key Scientific Challenges  program.  There is a  Machine Learning  list I worked on and a  Statistics  list which  Deepak  worked on.
 
I’m hoping this is taken quite seriously by graduate students.  The primary value, is that it gave us a chance to sit down and publicly specify directions of research which would be valuable to make progress on.  A good strategy for a beginning graduate student is to pick one of these directions, pursue it, and make substantial advances for a PhD.  The directions are sufficiently general that I’m sure any serious advance has applications well beyond Yahoo.
 
A secondary point, (which I’m sure is primary for many    ) is that there is money for graduate students here.  It’s unrestricted, so you can use it for any reasonable travel, supplies, etc…</p><p>4 0.63659406 <a title="457-lsi-4" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>Introduction: Yahoo! is sponsoring two machine learning events that might interest people.  
  
 The  Key Scientific Challenges  program (due March 5) for  Machine Learning  and  Statistics  offers $5K (plus bonuses) for graduate students working on a core problem of interest to Y!  If you are already working on one of these problems, there is no reason not to submit, and if you arenâ&euro;&trade;t you might want to think about it for next year, as I am confident they all press the boundary of the possible in Machine Learning.   There are 7 days left. 
 The  Learning to Rank challenge  (due May 31) offers an $8K first prize for the best ranking algorithm on a real (and really used) dataset for search ranking, with presentations at an ICML workshop.  Unlike the Netflix competition, there are prizes for 2nd, 3rd, and 4th place, perhaps avoiding the heartbreak  the ensemble  encountered.  If you think you know how to rank, you should give it a try, and we might all learn something.  There are 3 months left.</p><p>5 0.49621996 <a title="457-lsi-5" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>Introduction: I will join  Yahoo Research  (in New York) after my contract ends at  TTI-Chicago .
 
The deciding reasons are:
  
 Yahoo is running into many hard learning problems.  This is precisely the situation where basic research might hope to have the greatest impact. 
 Yahoo Research understands research including publishing, conferences, etc… 
 Yahoo Research is growing, so there is a chance I can help it grow well. 
 Yahoo understands the internet, including (but not at all limited to) experimenting with research blogs. 
  
In the end, Yahoo Research seems like the place where I might have a chance to make the greatest difference.  
 
Yahoo (as a company) has made a strong bet on Yahoo Research.  We-the-researchers all hope that bet will pay off, and this seems plausible.  I’ll certainly have fun trying.</p><p>6 0.47164696 <a title="457-lsi-6" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>7 0.46409738 <a title="457-lsi-7" href="../hunch_net-2012/hunch_net-2012-12-29-Simons_Institute_Big_Data_Program.html">476 hunch net-2012-12-29-Simons Institute Big Data Program</a></p>
<p>8 0.44636652 <a title="457-lsi-8" href="../hunch_net-2012/hunch_net-2012-10-18-7th_Annual_Machine_Learning_Symposium.html">474 hunch net-2012-10-18-7th Annual Machine Learning Symposium</a></p>
<p>9 0.42639333 <a title="457-lsi-9" href="../hunch_net-2008/hunch_net-2008-09-04-Fall_ML_Conferences.html">316 hunch net-2008-09-04-Fall ML Conferences</a></p>
<p>10 0.42078176 <a title="457-lsi-10" href="../hunch_net-2008/hunch_net-2008-02-27-The_Stats_Handicap.html">290 hunch net-2008-02-27-The Stats Handicap</a></p>
<p>11 0.40021577 <a title="457-lsi-11" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>12 0.39513671 <a title="457-lsi-12" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<p>13 0.39383948 <a title="457-lsi-13" href="../hunch_net-2013/hunch_net-2013-09-20-No_NY_ML_Symposium_in_2013%2C_and_some_good_news.html">489 hunch net-2013-09-20-No NY ML Symposium in 2013, and some good news</a></p>
<p>14 0.38825393 <a title="457-lsi-14" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>15 0.37601528 <a title="457-lsi-15" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>16 0.37510017 <a title="457-lsi-16" href="../hunch_net-2007/hunch_net-2007-11-16-MLSS_2008.html">273 hunch net-2007-11-16-MLSS 2008</a></p>
<p>17 0.36848804 <a title="457-lsi-17" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>18 0.36478367 <a title="457-lsi-18" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>19 0.35332367 <a title="457-lsi-19" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>20 0.34559929 <a title="457-lsi-20" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.066), (34, 0.421), (55, 0.261), (95, 0.099)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.85710007 <a title="457-lda-1" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>Introduction: For graduate students, the  Yahoo!   Key Scientific Challenges program  including in  machine learning  is on again,  due March 9 .  The application is easy and the $5K award is high quality “no strings attached” funding.   Consider submitting.
 
Those in Washington DC, Philadelphia, and New York, may consider attending the  Franklin Institute Symposium   April 25  which has several speakers and an award for  V .  Attendance is free with an RSVP.</p><p>2 0.82670122 <a title="457-lda-2" href="../hunch_net-2005/hunch_net-2005-02-08-Some_Links.html">15 hunch net-2005-02-08-Some Links</a></p>
<p>Introduction: Yaroslav Bulatov collects some  links   to other technical blogs.</p><p>3 0.82071519 <a title="457-lda-3" href="../hunch_net-2010/hunch_net-2010-10-28-NY_ML_Symposium_2010.html">415 hunch net-2010-10-28-NY ML Symposium 2010</a></p>
<p>Introduction: About 200 people attended the  2010 NYAS ML Symposium  this year.  (It was  about 170 last year .)  I particularly enjoyed several talks.
  
  Yann  has a new live demo of (limited) real-time object recognition learning.  
  Sanjoy  gave a fairly convincing and comprehensible explanation of why a  modified form of single-linkage clustering  is consistent in higher dimensions, and why consistency is a critical feature for clustering algorithms.  I’m curious how well this algorithm works in practice. 
  Matt Hoffman ‘s poster covering online LDA seemed pretty convincing to me as an algorithmic improvement. 
  
This year, we allocated more time towards posters & poster spotlights.  
 
For next year, we are considering some further changes.  The format has traditionally been 4 invited Professor speakers, with posters and poster spotlight for students.  Demand from other parties to participate is growing, for example from postdocs and startups in the area.  Another growing concern is the fa</p><p>4 0.67022651 <a title="457-lda-4" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>Introduction: In the AI-related parts of machine learning, it is often tempting to examine how  you  do things in order to imagine how a machine should do things.  This is introspection, and it can easily go awry.  I will call introspection gone awry introspectionism.
 
Introspectionism is almost unique to AI (and the AI-related parts of machine learning) and it can lead to huge wasted effort in research.  It’s easiest to show how introspectionism arises by an example.
 
Suppose we want to solve the problem of navigating a robot from point A to point B given a camera.  Then, the following research action plan might seem natural when you examine your own capabilities:
  
 Build an edge detector for still images. 
 Build an object recognition system given the edge detector. 
 Build a system to predict distance and orientation to objects given the object recognition system. 
 Build a system to plan a path through the scene you construct from {object identification, distance, orientation} predictions.</p><p>5 0.59178692 <a title="457-lda-5" href="../hunch_net-2006/hunch_net-2006-06-30-ICML_papers.html">188 hunch net-2006-06-30-ICML papers</a></p>
<p>Introduction: Here are some ICML papers which interested me.
  
  Arindam Banerjee  had a  paper  which notes that PAC-Bayes bounds, a core theorem in online learning, and the optimality of Bayesian learning statements share a core inequality in their proof. 
  Pieter Abbeel ,  Morgan Quigley  and  Andrew Y. Ng  have a  paper  discussing RL techniques for learning given a bad (but not too bad) model of the world. 
  Nina Balcan  and  Avrim Blum  have a  paper  which discusses how to learn given a similarity function rather than a kernel.  A similarity function requires less structure than a kernel, implying that a learning algorithm using a similarity function might be applied in situations where no effective kernel is evident. 
  Nathan Ratliff ,  Drew Bagnell , and  Marty Zinkevich  have a  paper  describing an algorithm which attempts to fuse A *  path planning with learning of transition costs based on human demonstration. 
  
Papers (2), (3), and (4), all seem like an initial pass at solving in</p><p>6 0.56269735 <a title="457-lda-6" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>7 0.53693664 <a title="457-lda-7" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>8 0.53114146 <a title="457-lda-8" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>9 0.53049535 <a title="457-lda-9" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>10 0.52715063 <a title="457-lda-10" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>11 0.52707243 <a title="457-lda-11" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>12 0.52481341 <a title="457-lda-12" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>13 0.51985508 <a title="457-lda-13" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>14 0.51485336 <a title="457-lda-14" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>15 0.51181018 <a title="457-lda-15" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>16 0.51181018 <a title="457-lda-16" href="../hunch_net-2012/hunch_net-2012-05-12-ICML_accepted_papers_and_early_registration.html">465 hunch net-2012-05-12-ICML accepted papers and early registration</a></p>
<p>17 0.50371772 <a title="457-lda-17" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>18 0.50003266 <a title="457-lda-18" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>19 0.49550676 <a title="457-lda-19" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>20 0.49110642 <a title="457-lda-20" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
