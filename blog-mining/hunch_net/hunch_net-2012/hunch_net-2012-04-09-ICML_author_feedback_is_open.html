<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>461 hunch net-2012-04-09-ICML author feedback is open</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2012" href="../home/hunch_net-2012_home.html">hunch_net-2012</a> <a title="hunch_net-2012-461" href="#">hunch_net-2012-461</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>461 hunch net-2012-04-09-ICML author feedback is open</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2012-461-html" href="http://hunch.net/?p=2389">html</a></p><p>Introduction: as of last night, late.When the reviewing deadline passed Wednesday night 15%
of reviews were still missing, much higher than I expected. Between late
reviews coming in, ACs working overtime through the weekend, and people
willing to help in the pinch another ~390 reviews came in, reducing the
missing mass to 0.2%. Nailing that last bit and a similar quantity of papers
with uniformly low confidence reviews is what remains to be done in terms of
basic reviews. We are trying to make all of those happen this week so authors
have some chance to respond.I was surprised by the quantity of late reviews,
and I think that's an area where ICML needs to improve in future years. Good
reviews are not done in a rush--they are done by setting aside time (like an
afternoon), and carefully reading the paper while thinking about implications.
Many reviewers do this well but a significant minority aren't good at
scheduling their personal time. In this situation there are several ways to
fail:Give early w</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 When the reviewing deadline passed Wednesday night 15% of reviews were still missing, much higher than I expected. [sent-2, score-0.68]
</p><p>2 Between late reviews coming in, ACs working overtime through the weekend, and people willing to help in the pinch another ~390 reviews came in, reducing the missing mass to 0. [sent-3, score-0.927]
</p><p>3 Nailing that last bit and a similar quantity of papers with uniformly low confidence reviews is what remains to be done in terms of basic reviews. [sent-5, score-0.665]
</p><p>4 We are trying to make all of those happen this week so authors have some chance to respond. [sent-6, score-0.27]
</p><p>5 Good reviews are not done in a rush--they are done by setting aside time (like an afternoon), and carefully reading the paper while thinking about implications. [sent-8, score-0.637]
</p><p>6 Many reviewers do this well but a significant minority aren't good at scheduling their personal time. [sent-9, score-0.432]
</p><p>7 The worst failure mode by far is the last one for Program Chairs and Area Chairs, because they must catch and fix all the failures at the last minute. [sent-13, score-0.518]
</p><p>8 I expect the second failure mode also impacts the quality of reviews because high speed reviewing of a deep paper often doesn't work. [sent-14, score-0.949]
</p><p>9 To do this, we're going to pass a flake list for failure mode 3 to future program chairs who will hopefully further encourage people to schedule time well and review carefully. [sent-16, score-0.604]
</p><p>10 If my experience is any guide, plenty of authors will feel disappointed by the reviews. [sent-17, score-0.27]
</p><p>11 And part of it may be that the authors simply are far more expert in their subject than reviewers. [sent-21, score-0.333]
</p><p>12 In author responses, my personal tendency is to be blunter than most people when reviewers make errors. [sent-22, score-0.46]
</p><p>13 You should be sympathetic to reviewers who have voluntarily put significant time into reviewing your paper, but you should also use the channel to communicate real information. [sent-24, score-0.699]
</p><p>14 Remotivating your paper almost never works, so concentrate on getting across errors in understanding by reviewers or answer their direct questions. [sent-25, score-0.363]
</p><p>15 We did not include reviewer scores in author feedback, although we do plan to include them when the decision is made. [sent-26, score-0.552]
</p><p>16 Scores should not be regarded as final by any party, since author feedback and discussion can significantly alter a reviewer's understanding of the paper. [sent-27, score-0.547]
</p><p>17 Encouraging reviewers to incorporate this additional information well before settling on a final score is one of my goals. [sent-28, score-0.274]
</p><p>18 We did allow resubmission of the paper with the author response, similar to whatGeoff Gordondid as program chair forAIStat. [sent-29, score-0.466]
</p><p>19 This solves two problems: It helps authors create a more polished draft, and it avoids forcing an overly constrained channel in the communication. [sent-30, score-0.511]
</p><p>20 If an equation has a bug, you can write it out bug free in mathematical notation rather than trying to describe by reference how to alter the equation in author response. [sent-31, score-0.804]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reviews', 0.363), ('warning', 0.211), ('authors', 0.2), ('reviewers', 0.187), ('author', 0.183), ('mode', 0.167), ('channel', 0.161), ('equation', 0.149), ('chairs', 0.143), ('night', 0.134), ('part', 0.133), ('alter', 0.129), ('failure', 0.127), ('bug', 0.124), ('scores', 0.124), ('reviewing', 0.116), ('last', 0.112), ('late', 0.109), ('quantity', 0.106), ('paper', 0.106), ('program', 0.097), ('missing', 0.092), ('personal', 0.09), ('final', 0.087), ('done', 0.084), ('reviewer', 0.083), ('include', 0.081), ('adjusted', 0.08), ('wednesday', 0.08), ('afternoon', 0.08), ('resubmission', 0.08), ('voluntarily', 0.08), ('polished', 0.08), ('weekend', 0.08), ('significant', 0.08), ('regarded', 0.075), ('sympathetic', 0.075), ('minority', 0.075), ('feedback', 0.073), ('concentrate', 0.07), ('forcing', 0.07), ('finish', 0.07), ('schedule', 0.07), ('disappointed', 0.07), ('impacts', 0.07), ('responses', 0.07), ('acs', 0.07), ('trying', 0.07), ('communicating', 0.067), ('passed', 0.067)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="461-tfidf-1" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>Introduction: as of last night, late.When the reviewing deadline passed Wednesday night 15%
of reviews were still missing, much higher than I expected. Between late
reviews coming in, ACs working overtime through the weekend, and people
willing to help in the pinch another ~390 reviews came in, reducing the
missing mass to 0.2%. Nailing that last bit and a similar quantity of papers
with uniformly low confidence reviews is what remains to be done in terms of
basic reviews. We are trying to make all of those happen this week so authors
have some chance to respond.I was surprised by the quantity of late reviews,
and I think that's an area where ICML needs to improve in future years. Good
reviews are not done in a rush--they are done by setting aside time (like an
afternoon), and carefully reading the paper while thinking about implications.
Many reviewers do this well but a significant minority aren't good at
scheduling their personal time. In this situation there are several ways to
fail:Give early w</p><p>2 0.37129653 <a title="461-tfidf-2" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>3 0.29937485 <a title="461-tfidf-3" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>4 0.27068639 <a title="461-tfidf-4" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>5 0.24710257 <a title="461-tfidf-5" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>Introduction: One way that many conferences in machine learning assign reviewers to papers
is via bidding, which has steps something like:Invite people to reviewAccept
papersReviewers look at title and abstract and state the papers they are
interested in reviewing.Some massaging happens, but reviewers often get
approximately the papers they bid for.At the ICML business meeting,Andrew
McCallumsuggested getting rid of bidding for papers. A couple reasons were
given:PrivacyThe title and abstract of the entire set of papers is visible to
every participating reviewer. Some authors might be uncomfortable about this
for submitted papers. I'm not sympathetic to this reason: the point of
submitting a paper to review is to publish it, so the value (if any) of not
publishing a part of it a little bit earlier seems limited.CliquesA bidding
system is gameable. If you have 3 buddies and you inform each other of your
submissions, you can each bid for your friend's papers and express a
disinterest in others. There</p><p>6 0.23743607 <a title="461-tfidf-6" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>7 0.23430018 <a title="461-tfidf-7" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>8 0.21971744 <a title="461-tfidf-8" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>9 0.21101603 <a title="461-tfidf-9" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>10 0.2063729 <a title="461-tfidf-10" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>11 0.20489851 <a title="461-tfidf-11" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>12 0.20150855 <a title="461-tfidf-12" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>13 0.197851 <a title="461-tfidf-13" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>14 0.19698641 <a title="461-tfidf-14" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>15 0.18782428 <a title="461-tfidf-15" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>16 0.17639789 <a title="461-tfidf-16" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>17 0.16571903 <a title="461-tfidf-17" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>18 0.16275391 <a title="461-tfidf-18" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>19 0.15082739 <a title="461-tfidf-19" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>20 0.14734858 <a title="461-tfidf-20" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.267), (1, 0.31), (2, -0.248), (3, -0.072), (4, -0.015), (5, 0.044), (6, -0.002), (7, 0.057), (8, 0.028), (9, 0.011), (10, 0.024), (11, 0.037), (12, 0.029), (13, -0.083), (14, -0.017), (15, -0.053), (16, -0.074), (17, 0.002), (18, 0.012), (19, 0.015), (20, -0.017), (21, 0.02), (22, 0.028), (23, 0.033), (24, -0.028), (25, 0.023), (26, -0.079), (27, 0.06), (28, 0.013), (29, 0.036), (30, -0.016), (31, -0.069), (32, 0.0), (33, -0.047), (34, 0.023), (35, 0.042), (36, -0.016), (37, -0.119), (38, 0.004), (39, 0.026), (40, 0.024), (41, 0.026), (42, -0.065), (43, -0.072), (44, 0.059), (45, 0.076), (46, 0.012), (47, 0.039), (48, 0.031), (49, 0.011)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98417336 <a title="461-lsi-1" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>Introduction: as of last night, late.When the reviewing deadline passed Wednesday night 15%
of reviews were still missing, much higher than I expected. Between late
reviews coming in, ACs working overtime through the weekend, and people
willing to help in the pinch another ~390 reviews came in, reducing the
missing mass to 0.2%. Nailing that last bit and a similar quantity of papers
with uniformly low confidence reviews is what remains to be done in terms of
basic reviews. We are trying to make all of those happen this week so authors
have some chance to respond.I was surprised by the quantity of late reviews,
and I think that's an area where ICML needs to improve in future years. Good
reviews are not done in a rush--they are done by setting aside time (like an
afternoon), and carefully reading the paper while thinking about implications.
Many reviewers do this well but a significant minority aren't good at
scheduling their personal time. In this situation there are several ways to
fail:Give early w</p><p>2 0.9082675 <a title="461-lsi-2" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>3 0.82434553 <a title="461-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>4 0.82382768 <a title="461-lsi-4" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>Introduction: Reviewing is a fairly formal process which is integral to the way academia is
run. Given this integral nature, the quality of reviewing is often
frustrating. I've seen plenty of examples of false statements, misbeliefs,
reading what isn't written, etcâ&euro;Ś, and I'm sure many other people have as
well.Recently, mechanisms like double blind review and author feedback have
been introduced to try to make the process more fair and accurate in many
machine learning (and related) conferences. My personal experience is that
these mechanisms help, especially the author feedback. Nevertheless, some
problems remain.The game theory take on reviewing is that the incentive for
truthful reviewing isn't there. Since reviewers are also authors, there are
sometimes perverse incentives created and acted upon. (Incidentially, these
incentives can be both positive and negative.)Setting up a truthful reviewing
system is tricky because their is no final reference truth available in any
acceptable (say: subyear)</p><p>5 0.81599969 <a title="461-lsi-5" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>Introduction: One way that many conferences in machine learning assign reviewers to papers
is via bidding, which has steps something like:Invite people to reviewAccept
papersReviewers look at title and abstract and state the papers they are
interested in reviewing.Some massaging happens, but reviewers often get
approximately the papers they bid for.At the ICML business meeting,Andrew
McCallumsuggested getting rid of bidding for papers. A couple reasons were
given:PrivacyThe title and abstract of the entire set of papers is visible to
every participating reviewer. Some authors might be uncomfortable about this
for submitted papers. I'm not sympathetic to this reason: the point of
submitting a paper to review is to publish it, so the value (if any) of not
publishing a part of it a little bit earlier seems limited.CliquesA bidding
system is gameable. If you have 3 buddies and you inform each other of your
submissions, you can each bid for your friend's papers and express a
disinterest in others. There</p><p>6 0.80474353 <a title="461-lsi-6" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>7 0.78539085 <a title="461-lsi-7" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>8 0.74886215 <a title="461-lsi-8" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>9 0.74648321 <a title="461-lsi-9" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>10 0.74275857 <a title="461-lsi-10" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>11 0.72088468 <a title="461-lsi-11" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>12 0.7189998 <a title="461-lsi-12" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>13 0.71778995 <a title="461-lsi-13" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>14 0.69257462 <a title="461-lsi-14" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>15 0.69236434 <a title="461-lsi-15" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>16 0.69166988 <a title="461-lsi-16" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>17 0.68809384 <a title="461-lsi-17" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>18 0.67433661 <a title="461-lsi-18" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>19 0.65469438 <a title="461-lsi-19" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>20 0.64285582 <a title="461-lsi-20" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(29, 0.02), (35, 0.02), (42, 0.167), (45, 0.011), (69, 0.03), (74, 0.228), (82, 0.078), (95, 0.367)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95417321 <a title="461-lda-1" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>Introduction: I'm theworkshops chairforICMLthis year. As such, I would like to personally
encourage people to consider running a workshop.My general view of workshops
is that they are excellent as opportunities to discuss and develop research
directions--some of my best work has come from collaborations at workshops and
several workshops have substantially altered my thinking about various
problems. My experience running workshops is that setting them up and making
them fly often appears much harder than it actually is, and the workshops
often come off much better than expected in the end. Submissions are due
January 18, two weeks before papers.Similarly,Ben Taskaris looking for
goodtutorials, which is complementary. Workshops are about exploring a
subject, while a tutorial is about distilling it down into an easily taught
essence, a vital part of the research process. Tutorials are due February 13,
two weeks after papers.</p><p>same-blog 2 0.9521637 <a title="461-lda-2" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>Introduction: as of last night, late.When the reviewing deadline passed Wednesday night 15%
of reviews were still missing, much higher than I expected. Between late
reviews coming in, ACs working overtime through the weekend, and people
willing to help in the pinch another ~390 reviews came in, reducing the
missing mass to 0.2%. Nailing that last bit and a similar quantity of papers
with uniformly low confidence reviews is what remains to be done in terms of
basic reviews. We are trying to make all of those happen this week so authors
have some chance to respond.I was surprised by the quantity of late reviews,
and I think that's an area where ICML needs to improve in future years. Good
reviews are not done in a rush--they are done by setting aside time (like an
afternoon), and carefully reading the paper while thinking about implications.
Many reviewers do this well but a significant minority aren't good at
scheduling their personal time. In this situation there are several ways to
fail:Give early w</p><p>3 0.95098084 <a title="461-lda-3" href="../hunch_net-2008/hunch_net-2008-07-04-More_Presentation_Preparation.html">307 hunch net-2008-07-04-More Presentation Preparation</a></p>
<p>Introduction: We've discussedpresentation preparation before, but I have one more thing to
add:transitioning. For a research presentation, it is substantially helpful
for the audience if transitions are clear. A common outline for a research
presentation in machine leanring is:The problem. Presentations which don't
describe the problem almost immediately lose people, because the context is
missing to understand the detail.Prior relevant work. In many cases, a paper
builds on some previous bit of work which must be understood in order to
understand what the paper does. A common failure mode seems to be spending too
much time on prior work. Discuss just the relevant aspects of prior work in
the language of your work. Sometimes this is missing when unneeded.What we
did. For theory papers in particular, it is often not possible to really cover
the details. Prioritizing what you present can be very important.How it
worked. Many papers in Machine Learning have some sort of experimental test of
the algorit</p><p>4 0.93562829 <a title="461-lda-4" href="../hunch_net-2006/hunch_net-2006-01-08-Debugging_Your_Brain.html">147 hunch net-2006-01-08-Debugging Your Brain</a></p>
<p>Introduction: One part of doing research is debugging your understanding of reality. This is
hard work: How do you even discover where you misunderstand? If you discover a
misunderstanding, how do you go about removing it?The process of debugging
computer programs is quite analogous to debugging reality misunderstandings.
This is natural--a bug in a computer program is a misunderstanding between you
and the computer about what you said. Many of the familiar techniques from
debugging have exact parallels.DetailsWhen programming, there are often signs
that some bug exists like: "the graph my program output is shifted a little
bit" = maybe you have an indexing error. In debugging yourself, we often have
some impression that something is "not right". These impressions should be
addressed directly and immediately. (Some people have the habit of suppressing
worries in favor of excess certainty. That's not healthy for research.)Corner
CasesA "corner case" is an input to a program which is extreme in some w</p><p>5 0.89081877 <a title="461-lda-5" href="../hunch_net-2010/hunch_net-2010-11-18-ICML_2011_%26%238211%3B_Call_for_Tutorials.html">417 hunch net-2010-11-18-ICML 2011 &#8211; Call for Tutorials</a></p>
<p>Introduction: I would like to encourage people to consider giving a tutorial at next years
ICML. The ideal tutorial attracts a wide audience, provides a gentle and
easily taught introduction to the chosen research area, and also covers the
most important contributions in depth.Submissions are due January 14 Â (about
two weeks before paper
deadline).http://www.icml-2011.org/tutorials.phpRegards,Ulf</p><p>6 0.87540668 <a title="461-lda-6" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>7 0.8522976 <a title="461-lda-7" href="../hunch_net-2007/hunch_net-2007-02-11-24.html">232 hunch net-2007-02-11-24</a></p>
<p>8 0.82031345 <a title="461-lda-8" href="../hunch_net-2006/hunch_net-2006-10-22-Exemplar_programming.html">215 hunch net-2006-10-22-Exemplar programming</a></p>
<p>9 0.80872935 <a title="461-lda-9" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<p>10 0.77045608 <a title="461-lda-10" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>11 0.76858604 <a title="461-lda-11" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>12 0.76471382 <a title="461-lda-12" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>13 0.7429077 <a title="461-lda-13" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>14 0.72264344 <a title="461-lda-14" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>15 0.71895444 <a title="461-lda-15" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">324 hunch net-2008-11-09-A Healthy  COLT</a></p>
<p>16 0.71101356 <a title="461-lda-16" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>17 0.7094177 <a title="461-lda-17" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>18 0.7066853 <a title="461-lda-18" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>19 0.70553654 <a title="461-lda-19" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>20 0.70489532 <a title="461-lda-20" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
