<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>469 hunch net-2012-07-09-Videolectures</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2012" href="../home/hunch_net-2012_home.html">hunch_net-2012</a> <a title="hunch_net-2012-469" href="#">hunch_net-2012-469</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>469 hunch net-2012-07-09-Videolectures</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2012-469-html" href="http://hunch.net/?p=2546">html</a></p><p>Introduction: Yaser  points out some nicely  videotaped machine learning lectures  at  Caltech .  Yaser taught me machine learning, and I always found the lectures clear and interesting, so I expect many people can benefit from watching.  Relative to  Andrew Ng â&euro;&tilde;s  ML class  there are somewhat different areas of emphasis but the topic is the same, so picking and choosing the union may be helpful.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Yaser  points out some nicely  videotaped machine learning lectures  at  Caltech . [sent-1, score-1.042]
</p><p>2 Yaser taught me machine learning, and I always found the lectures clear and interesting, so I expect many people can benefit from watching. [sent-2, score-1.211]
</p><p>3 Relative to  Andrew Ng â&euro;&tilde;s  ML class  there are somewhat different areas of emphasis but the topic is the same, so picking and choosing the union may be helpful. [sent-3, score-1.33]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('yaser', 0.547), ('lectures', 0.376), ('union', 0.243), ('videotaped', 0.243), ('nicely', 0.225), ('caltech', 0.195), ('ng', 0.177), ('emphasis', 0.172), ('picking', 0.172), ('taught', 0.172), ('andrew', 0.154), ('benefit', 0.154), ('areas', 0.149), ('relative', 0.135), ('choosing', 0.133), ('topic', 0.124), ('somewhat', 0.119), ('ml', 0.11), ('class', 0.108), ('clear', 0.102), ('helpful', 0.101), ('points', 0.098), ('expect', 0.093), ('found', 0.089), ('always', 0.086), ('interesting', 0.071), ('machine', 0.071), ('different', 0.062), ('may', 0.048), ('people', 0.038), ('many', 0.03), ('learning', 0.029)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="469-tfidf-1" href="../hunch_net-2012/hunch_net-2012-07-09-Videolectures.html">469 hunch net-2012-07-09-Videolectures</a></p>
<p>Introduction: Yaser  points out some nicely  videotaped machine learning lectures  at  Caltech .  Yaser taught me machine learning, and I always found the lectures clear and interesting, so I expect many people can benefit from watching.  Relative to  Andrew Ng â&euro;&tilde;s  ML class  there are somewhat different areas of emphasis but the topic is the same, so picking and choosing the union may be helpful.</p><p>2 0.13356975 <a title="469-tfidf-2" href="../hunch_net-2013/hunch_net-2013-06-10-The_Large_Scale_Learning_class_notes.html">483 hunch net-2013-06-10-The Large Scale Learning class notes</a></p>
<p>Introduction: The  large scale machine learning class  I taught with  Yann LeCun  has finished.  As I expected, it took quite a bit of time   .  We had about 25 people attending in person on average and 400 regularly watching the  recorded lectures  which is substantially more sustained interest than I expected for an advanced ML class.  We also had some fun with class projects—I’m hopeful that several will eventually turn into papers.
 
I expect there are a number of professors interested in lecturing on this and related topics.  Everyone will have their personal taste in subjects of course, but hopefully there will be some convergence to common course materials as well.  To help with this, I am making the  sources to my presentations available .  Feel free to use/improve/embelish/ridicule/etc… in the pursuit of the perfect course.</p><p>3 0.11769047 <a title="469-tfidf-3" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>Introduction: Yann LeCun  and I are coteaching a class on  Large Scale Machine Learning  starting late January  at NYU .  This class will cover many tricks to get machine learning working well on datasets with many features, examples, and classes, along with several elements of deep learning and support systems enabling the previous.
 
This is not a beginning class—you really need to have taken a basic machine learning class previously to follow along.  Students will be able to run and experiment with large scale learning algorithms since  Yahoo!  has donated servers which are being configured into a small scale  Hadoop  cluster.   We are planning to cover the frontier of research in scalable learning algorithms, so good class projects could easily lead to papers.
 
For me, this is a chance to teach on many topics of past research.  In general, it seems like researchers should engage in at least occasional teaching of research, both as a proof of teachability and to see their own research through th</p><p>4 0.10057291 <a title="469-tfidf-4" href="../hunch_net-2007/hunch_net-2007-04-21-Videolectures.net.html">240 hunch net-2007-04-21-Videolectures.net</a></p>
<p>Introduction: Davor  has been working to setup  videolectures.net  which is the new site for the many lectures  mentioned here .  (Tragically, they seem to only be available in windows media format.) I went through  my own projects  and added a few links to the videos.  The day when every result is a set of {paper, slides, video} isn’t quite here yet, but it’s within sight.  (For many papers, of course, code is a 4th component.)</p><p>5 0.09373609 <a title="469-tfidf-5" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>Introduction: Maybe it’s too early to call, but with four separate Neural Network sessions at this year’s  ICML ,  it looks like Neural Networks are making a comeback. Here are my  highlights of these sessions. In general, my feeling is that these  papers both demystify deep learning and show its broader applicability.
 
The first observation I made is that the once disreputable “Neural” nomenclature is being used again  in lieu of  “deep learning”. Maybe it’s because Adam Coates et al. showed that single layer networks can work surprisingly well.
  
  An Analysis of Single-Layer Networks in Unsupervised Feature       Learning ,  Adam Coates ,  Honglak Lee ,  Andrew Y. Ng  (AISTATS 2011) 
  The Importance of Encoding Versus Training with Sparse Coding and Vector Quantization ,  Adam Coates ,  Andrew Y. Ng  (ICML 2011) 
  
Another surprising result out of Andrew Ng’s group comes from Andrew  Saxe et al. who show that certain convolutional pooling architectures  can obtain close to state-of-the-art pe</p><p>6 0.076802664 <a title="469-tfidf-6" href="../hunch_net-2009/hunch_net-2009-11-06-Yisong_Yue_on_Self-improving_Systems.html">376 hunch net-2009-11-06-Yisong Yue on Self-improving Systems</a></p>
<p>7 0.073437467 <a title="469-tfidf-7" href="../hunch_net-2006/hunch_net-2006-02-04-Research_Budget_Changes.html">154 hunch net-2006-02-04-Research Budget Changes</a></p>
<p>8 0.065522827 <a title="469-tfidf-8" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>9 0.064552449 <a title="469-tfidf-9" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>10 0.058494005 <a title="469-tfidf-10" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>11 0.056269906 <a title="469-tfidf-11" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>12 0.056173902 <a title="469-tfidf-12" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>13 0.05552689 <a title="469-tfidf-13" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>14 0.054168031 <a title="469-tfidf-14" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>15 0.050213732 <a title="469-tfidf-15" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>16 0.050074078 <a title="469-tfidf-16" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>17 0.049599599 <a title="469-tfidf-17" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>18 0.049290311 <a title="469-tfidf-18" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>19 0.048584692 <a title="469-tfidf-19" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>20 0.046516772 <a title="469-tfidf-20" href="../hunch_net-2005/hunch_net-2005-06-13-Wikis_for_Summer_Schools_and_Workshops.html">81 hunch net-2005-06-13-Wikis for Summer Schools and Workshops</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.08), (1, -0.024), (2, -0.058), (3, 0.011), (4, 0.003), (5, 0.016), (6, -0.015), (7, -0.023), (8, -0.004), (9, -0.057), (10, 0.024), (11, -0.019), (12, 0.011), (13, -0.03), (14, 0.016), (15, 0.012), (16, 0.002), (17, 0.008), (18, 0.038), (19, 0.047), (20, 0.064), (21, -0.034), (22, -0.052), (23, -0.01), (24, 0.075), (25, -0.061), (26, 0.028), (27, 0.08), (28, -0.131), (29, 0.119), (30, -0.019), (31, -0.129), (32, 0.013), (33, -0.06), (34, 0.023), (35, -0.065), (36, 0.002), (37, 0.049), (38, 0.006), (39, -0.079), (40, 0.029), (41, -0.043), (42, 0.038), (43, 0.049), (44, 0.03), (45, -0.028), (46, -0.055), (47, -0.081), (48, 0.0), (49, 0.084)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93654484 <a title="469-lsi-1" href="../hunch_net-2012/hunch_net-2012-07-09-Videolectures.html">469 hunch net-2012-07-09-Videolectures</a></p>
<p>Introduction: Yaser  points out some nicely  videotaped machine learning lectures  at  Caltech .  Yaser taught me machine learning, and I always found the lectures clear and interesting, so I expect many people can benefit from watching.  Relative to  Andrew Ng â&euro;&tilde;s  ML class  there are somewhat different areas of emphasis but the topic is the same, so picking and choosing the union may be helpful.</p><p>2 0.78146553 <a title="469-lsi-2" href="../hunch_net-2013/hunch_net-2013-06-10-The_Large_Scale_Learning_class_notes.html">483 hunch net-2013-06-10-The Large Scale Learning class notes</a></p>
<p>Introduction: The  large scale machine learning class  I taught with  Yann LeCun  has finished.  As I expected, it took quite a bit of time   .  We had about 25 people attending in person on average and 400 regularly watching the  recorded lectures  which is substantially more sustained interest than I expected for an advanced ML class.  We also had some fun with class projects—I’m hopeful that several will eventually turn into papers.
 
I expect there are a number of professors interested in lecturing on this and related topics.  Everyone will have their personal taste in subjects of course, but hopefully there will be some convergence to common course materials as well.  To help with this, I am making the  sources to my presentations available .  Feel free to use/improve/embelish/ridicule/etc… in the pursuit of the perfect course.</p><p>3 0.66396505 <a title="469-lsi-3" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>Introduction: Yann LeCun  and I are coteaching a class on  Large Scale Machine Learning  starting late January  at NYU .  This class will cover many tricks to get machine learning working well on datasets with many features, examples, and classes, along with several elements of deep learning and support systems enabling the previous.
 
This is not a beginning class—you really need to have taken a basic machine learning class previously to follow along.  Students will be able to run and experiment with large scale learning algorithms since  Yahoo!  has donated servers which are being configured into a small scale  Hadoop  cluster.   We are planning to cover the frontier of research in scalable learning algorithms, so good class projects could easily lead to papers.
 
For me, this is a chance to teach on many topics of past research.  In general, it seems like researchers should engage in at least occasional teaching of research, both as a proof of teachability and to see their own research through th</p><p>4 0.64421368 <a title="469-lsi-4" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>Introduction: Yann and I have arranged so that people who are interested in our  large scale machine learning class  and not able to attend in person can follow along via two methods.
  
  Videos  will be posted with about a 1 day delay on  techtalks .  This is a side-by-side capture of video+slides from  Weyond . 
 We are experimenting with  Piazza  as a discussion forum.  Anyone is welcome to subscribe to Piazza and ask questions there, where I will be monitoring things.   update2 : Sign up  here . 
  
The first lecture is up now, including the  revised version of the slides  which fixes a few typos and rounds out references.</p><p>5 0.49473524 <a title="469-lsi-5" href="../hunch_net-2007/hunch_net-2007-04-21-Videolectures.net.html">240 hunch net-2007-04-21-Videolectures.net</a></p>
<p>Introduction: Davor  has been working to setup  videolectures.net  which is the new site for the many lectures  mentioned here .  (Tragically, they seem to only be available in windows media format.) I went through  my own projects  and added a few links to the videos.  The day when every result is a set of {paper, slides, video} isn’t quite here yet, but it’s within sight.  (For many papers, of course, code is a 4th component.)</p><p>6 0.4485437 <a title="469-lsi-6" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>7 0.44226155 <a title="469-lsi-7" href="../hunch_net-2005/hunch_net-2005-02-04-JMLG.html">13 hunch net-2005-02-04-JMLG</a></p>
<p>8 0.43307763 <a title="469-lsi-8" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>9 0.42010522 <a title="469-lsi-9" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>10 0.41739857 <a title="469-lsi-10" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>11 0.40698919 <a title="469-lsi-11" href="../hunch_net-2007/hunch_net-2007-08-28-Live_ML_Class.html">261 hunch net-2007-08-28-Live ML Class</a></p>
<p>12 0.3952764 <a title="469-lsi-12" href="../hunch_net-2007/hunch_net-2007-06-23-Machine_Learning_Jobs_are_Growing_on_Trees.html">250 hunch net-2007-06-23-Machine Learning Jobs are Growing on Trees</a></p>
<p>13 0.39524409 <a title="469-lsi-13" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>14 0.39051011 <a title="469-lsi-14" href="../hunch_net-2010/hunch_net-2010-08-21-Rob_Schapire_at_NYC_ML_Meetup.html">405 hunch net-2010-08-21-Rob Schapire at NYC ML Meetup</a></p>
<p>15 0.38516778 <a title="469-lsi-15" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>16 0.38105381 <a title="469-lsi-16" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>17 0.36747065 <a title="469-lsi-17" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>18 0.36609352 <a title="469-lsi-18" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>19 0.35917374 <a title="469-lsi-19" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>20 0.35343546 <a title="469-lsi-20" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(53, 0.099), (55, 0.161), (88, 0.517), (95, 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.84368432 <a title="469-lda-1" href="../hunch_net-2012/hunch_net-2012-07-09-Videolectures.html">469 hunch net-2012-07-09-Videolectures</a></p>
<p>Introduction: Yaser  points out some nicely  videotaped machine learning lectures  at  Caltech .  Yaser taught me machine learning, and I always found the lectures clear and interesting, so I expect many people can benefit from watching.  Relative to  Andrew Ng â&euro;&tilde;s  ML class  there are somewhat different areas of emphasis but the topic is the same, so picking and choosing the union may be helpful.</p><p>2 0.6167869 <a title="469-lda-2" href="../hunch_net-2005/hunch_net-2005-02-04-JMLG.html">13 hunch net-2005-02-04-JMLG</a></p>
<p>Introduction: The  Journal of Machine Learning Gossip  has some fine satire about learning research.  In particular, the  guides  are amusing and remarkably true.
 
As in all things, itâ&euro;&trade;s easy to criticize the way things are and harder to make them better.</p><p>3 0.61057943 <a title="469-lda-3" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>Introduction: Some of the “sister conference” presentations at  AAAI  have been great.  Roughly speaking, the conference organizers asked other conference organizers to come give a summary of their conference.  Many different AI-related conferences accepted.  The presenters typically discuss some of the background and goals of the conference then mention the results from a few papers they liked.  This is great because it provides a mechanism to get a digested overview of the work of several thousand researchers—something which is simply available nowhere else.
 
Based on these presentations, it looks like there is a significant component of (and opportunity for) applied machine learning in  AIIDE ,  IUI , and  ACL .
 
There was also some discussion of having a super-colocation event similar to  FCRC , but centered on AI & Learning.  This seems like a fine idea.  The field is fractured across so many different conferences that the mixing of a supercolocation seems likely helpful for research.</p><p>4 0.55143255 <a title="469-lda-4" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>Introduction: One of the questions facing machine learning as a field is “Can we produce a generalized learning system that can solve a wide array of standard learning problems?”  The answer is trivial: “yes, just have children”.
 
Of course, that wasn’t really the question.  The refined question is “Are there simple-to-implement generalized learning systems that can solve a wide array of standard learning problems?”  The answer to this is less clear.  The ability of animals (and people ) to learn might be due to megabytes encoded in the DNA.  If this algorithmic complexity is  necessary  to solve machine learning, the field faces a daunting task in replicating it on a computer.
 
This observation suggests a possibility: if you can show that few bits of DNA are needed for learning in animals, then this provides evidence that machine learning (as a field) has a hope of big success with relatively little effort. 
 
It is well known that specific portions of the brain have specific functionality across</p><p>5 0.49523267 <a title="469-lda-5" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I’ve enjoyed the  Terminator  movies and show.  Neglecting the whacky aspects (time travel and associated paradoxes), there is an enduring topic of discussion: how do people deal with intelligent machines (and vice versa)?
 
In Terminator-land, the primary method for dealing with intelligent machines is to prevent them from being made.  This approach works pretty badly, because a new angle on building an intelligent machine keeps coming up.  This is partly a ploy for writer’s to avoid writing themselves out of a job, but there is a fundamental truth to it as well: preventing progress in research is hard.
 
The United States, has been experimenting with trying to stop research on  stem cells .  It hasn’t worked very well—the net effect has been retarding research programs a bit, and exporting some research to other countries.  Another less recent example was encryption technology, for which the United States generally did not encourage early public research and even  discouraged as a mu</p><p>6 0.31601262 <a title="469-lda-6" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>7 0.29988012 <a title="469-lda-7" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>8 0.29607552 <a title="469-lda-8" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>9 0.29188189 <a title="469-lda-9" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>10 0.28993824 <a title="469-lda-10" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>11 0.28993824 <a title="469-lda-11" href="../hunch_net-2012/hunch_net-2012-05-12-ICML_accepted_papers_and_early_registration.html">465 hunch net-2012-05-12-ICML accepted papers and early registration</a></p>
<p>12 0.28677675 <a title="469-lda-12" href="../hunch_net-2006/hunch_net-2006-02-27-The_Peekaboom_Dataset.html">159 hunch net-2006-02-27-The Peekaboom Dataset</a></p>
<p>13 0.28671896 <a title="469-lda-13" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>14 0.28455934 <a title="469-lda-14" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>15 0.2827971 <a title="469-lda-15" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>16 0.28140786 <a title="469-lda-16" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>17 0.28064004 <a title="469-lda-17" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>18 0.27844989 <a title="469-lda-18" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>19 0.2780323 <a title="469-lda-19" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>20 0.27786645 <a title="469-lda-20" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
