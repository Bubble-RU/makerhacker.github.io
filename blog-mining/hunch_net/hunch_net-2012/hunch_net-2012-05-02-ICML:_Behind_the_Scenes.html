<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>463 hunch net-2012-05-02-ICML: Behind the Scenes</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2012" href="../home/hunch_net-2012_home.html">hunch_net-2012</a> <a title="hunch_net-2012-463" href="#">hunch_net-2012-463</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>463 hunch net-2012-05-02-ICML: Behind the Scenes</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2012-463-html" href="http://hunch.net/?p=2407">html</a></p><p>Introduction: This is a rather long post, detailing the ICML 2012 review process. The goal
is to make the process more transparent, help authors understand how we came
to a decision, and discuss the strengths and weaknesses of this process for
future conference organizers.Microsoft’s Conference Management Toolkit (CMT)We
chose to useCMTover other conference management software mainly because of its
rich toolkit. The interface is sub-optimal (to say the least!) but it has
extensive capabilities (to handle bids, author response, resubmissions, etc.),
good import/export mechanisms (to process the data elsewhere), excellent
technical support (to answer late night emails, add new functionalities).
Overall, it was the right choice, although we hope a designer will look at
that interface sometime soon!Toronto Matching System (TMS)TMSis now being used
by many major conferences in our field (including NIPS and UAI). It is an
automated system (developed byLaurent CharlinandRich Zemelat U. Toronto) to
match re</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tms', 0.456), ('cmt', 0.38), ('bid', 0.235), ('list', 0.231), ('reviewers', 0.2), ('chairs', 0.18), ('area', 0.179), ('bids', 0.171), ('papers', 0.16), ('reviewer', 0.143), ('received', 0.106), ('pc', 0.103), ('matching', 0.101), ('group', 0.097), ('reviews', 0.086), ('paper', 0.08), ('asked', 0.079), ('bidding', 0.078), ('scores', 0.078), ('manually', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="463-tfidf-1" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>Introduction: This is a rather long post, detailing the ICML 2012 review process. The goal
is to make the process more transparent, help authors understand how we came
to a decision, and discuss the strengths and weaknesses of this process for
future conference organizers.Microsoft’s Conference Management Toolkit (CMT)We
chose to useCMTover other conference management software mainly because of its
rich toolkit. The interface is sub-optimal (to say the least!) but it has
extensive capabilities (to handle bids, author response, resubmissions, etc.),
good import/export mechanisms (to process the data elsewhere), excellent
technical support (to answer late night emails, add new functionalities).
Overall, it was the right choice, although we hope a designer will look at
that interface sometime soon!Toronto Matching System (TMS)TMSis now being used
by many major conferences in our field (including NIPS and UAI). It is an
automated system (developed byLaurent CharlinandRich Zemelat U. Toronto) to
match re</p><p>2 0.29780555 <a title="463-tfidf-2" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>Introduction: One way that many conferences in machine learning assign reviewers to papers
is via bidding, which has steps something like:Invite people to reviewAccept
papersReviewers look at title and abstract and state the papers they are
interested in reviewing.Some massaging happens, but reviewers often get
approximately the papers they bid for.At the ICML business meeting,Andrew
McCallumsuggested getting rid of bidding for papers. A couple reasons were
given:PrivacyThe title and abstract of the entire set of papers is visible to
every participating reviewer. Some authors might be uncomfortable about this
for submitted papers. I'm not sympathetic to this reason: the point of
submitting a paper to review is to publish it, so the value (if any) of not
publishing a part of it a little bit earlier seems limited.CliquesA bidding
system is gameable. If you have 3 buddies and you inform each other of your
submissions, you can each bid for your friend's papers and express a
disinterest in others. There</p><p>3 0.28802302 <a title="463-tfidf-3" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>4 0.2232579 <a title="463-tfidf-4" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>Introduction: Everyone should have received notice forNY ML Symposiumabstracts. Check
carefully, as one was lost by our system.The event itself is October 21, next
week.Leon Bottou,Stephen Boyd, andYoav Freundare giving the invited talks this
year, and there are many spotlights on local work spread throughout the
day.Chris Wigginshas setup 6(!) ML-interested startups to follow the
symposium, which should be of substantial interest to the employment
interested.I also wanted to give an update onICML 2012. Unlike last year, our
deadline is coordinated withAIStat(which is due this Friday). The paper
deadline for ICML has been pushed back to February 24 which should allow
significant time for finishing up papers after the winter break. Other details
may interest people as well:We settled on usingCMTafter checking out the
possibilities. I wasn't looking for this, because I've often found CMT clunky
in terms of easy access to the right information. Nevertheless, the breadth of
features and willingness to s</p><p>5 0.22222933 <a title="463-tfidf-5" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but
sometimes the unfairness seems particularly striking. This is most easily seen
by comparison:PaperBanditronOffset TreeNotesProblem ScopeMulticlass problems
where only the loss of one choice can be probed.Strictly greater: Cost
sensitive multiclass problems where only the loss of one choice can be
probed.Often generalizations don't matter. That's not the case here, since
every plausible application I've thought of involves loss functions
substantially different from 0/1.What's newAnalysis and ExperimentsAlgorithm,
Analysis, and ExperimentsAs far as I know, the essence of the more general
problem was first stated and analyzed with theEXP4 algorithm (page 16)(1998).
It's also the time horizon 1 simplification of the Reinforcement Learning
setting for therandom trajectory method (page 15)(2002). The Banditron
algorithm itself is functionally identical toOne-Step RL with Traces (page
122)(2003) inBianca's thesis</p><p>6 0.21971744 <a title="463-tfidf-6" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>7 0.21686776 <a title="463-tfidf-7" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>8 0.20794134 <a title="463-tfidf-8" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>9 0.19790164 <a title="463-tfidf-9" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>10 0.19205599 <a title="463-tfidf-10" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>11 0.17421587 <a title="463-tfidf-11" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>12 0.16351715 <a title="463-tfidf-12" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>13 0.16014597 <a title="463-tfidf-13" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>14 0.15934375 <a title="463-tfidf-14" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>15 0.15374647 <a title="463-tfidf-15" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>16 0.14835575 <a title="463-tfidf-16" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>17 0.13390304 <a title="463-tfidf-17" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>18 0.13326845 <a title="463-tfidf-18" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>19 0.130576 <a title="463-tfidf-19" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>20 0.13001247 <a title="463-tfidf-20" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.238), (1, 0.246), (2, -0.226), (3, -0.01), (4, -0.067), (5, 0.052), (6, 0.021), (7, 0.003), (8, 0.023), (9, -0.012), (10, 0.012), (11, 0.12), (12, 0.016), (13, -0.015), (14, -0.039), (15, -0.029), (16, -0.035), (17, -0.041), (18, 0.002), (19, -0.008), (20, -0.004), (21, 0.02), (22, 0.042), (23, 0.03), (24, -0.01), (25, -0.019), (26, -0.066), (27, 0.009), (28, -0.017), (29, -0.033), (30, -0.048), (31, 0.067), (32, 0.043), (33, -0.024), (34, 0.069), (35, 0.049), (36, 0.008), (37, -0.076), (38, 0.186), (39, -0.004), (40, -0.037), (41, -0.001), (42, 0.022), (43, 0.037), (44, 0.083), (45, 0.013), (46, 0.013), (47, 0.026), (48, 0.018), (49, 0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97729462 <a title="463-lsi-1" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>Introduction: This is a rather long post, detailing the ICML 2012 review process. The goal
is to make the process more transparent, help authors understand how we came
to a decision, and discuss the strengths and weaknesses of this process for
future conference organizers.Microsoft’s Conference Management Toolkit (CMT)We
chose to useCMTover other conference management software mainly because of its
rich toolkit. The interface is sub-optimal (to say the least!) but it has
extensive capabilities (to handle bids, author response, resubmissions, etc.),
good import/export mechanisms (to process the data elsewhere), excellent
technical support (to answer late night emails, add new functionalities).
Overall, it was the right choice, although we hope a designer will look at
that interface sometime soon!Toronto Matching System (TMS)TMSis now being used
by many major conferences in our field (including NIPS and UAI). It is an
automated system (developed byLaurent CharlinandRich Zemelat U. Toronto) to
match re</p><p>2 0.84926319 <a title="463-lsi-2" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>Introduction: One way that many conferences in machine learning assign reviewers to papers
is via bidding, which has steps something like:Invite people to reviewAccept
papersReviewers look at title and abstract and state the papers they are
interested in reviewing.Some massaging happens, but reviewers often get
approximately the papers they bid for.At the ICML business meeting,Andrew
McCallumsuggested getting rid of bidding for papers. A couple reasons were
given:PrivacyThe title and abstract of the entire set of papers is visible to
every participating reviewer. Some authors might be uncomfortable about this
for submitted papers. I'm not sympathetic to this reason: the point of
submitting a paper to review is to publish it, so the value (if any) of not
publishing a part of it a little bit earlier seems limited.CliquesA bidding
system is gameable. If you have 3 buddies and you inform each other of your
submissions, you can each bid for your friend's papers and express a
disinterest in others. There</p><p>3 0.82038641 <a title="463-lsi-3" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>4 0.8092801 <a title="463-lsi-4" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>5 0.78831947 <a title="463-lsi-5" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>Introduction: as of last night, late.When the reviewing deadline passed Wednesday night 15%
of reviews were still missing, much higher than I expected. Between late
reviews coming in, ACs working overtime through the weekend, and people
willing to help in the pinch another ~390 reviews came in, reducing the
missing mass to 0.2%. Nailing that last bit and a similar quantity of papers
with uniformly low confidence reviews is what remains to be done in terms of
basic reviews. We are trying to make all of those happen this week so authors
have some chance to respond.I was surprised by the quantity of late reviews,
and I think that's an area where ICML needs to improve in future years. Good
reviews are not done in a rush--they are done by setting aside time (like an
afternoon), and carefully reading the paper while thinking about implications.
Many reviewers do this well but a significant minority aren't good at
scheduling their personal time. In this situation there are several ways to
fail:Give early w</p><p>6 0.76913196 <a title="463-lsi-6" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>7 0.76598525 <a title="463-lsi-7" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>8 0.73470008 <a title="463-lsi-8" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>9 0.72826219 <a title="463-lsi-9" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>10 0.72161466 <a title="463-lsi-10" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>11 0.71568692 <a title="463-lsi-11" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>12 0.71303248 <a title="463-lsi-12" href="../hunch_net-2005/hunch_net-2005-04-04-Grounds_for_Rejection.html">52 hunch net-2005-04-04-Grounds for Rejection</a></p>
<p>13 0.69225055 <a title="463-lsi-13" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>14 0.67611265 <a title="463-lsi-14" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>15 0.67431164 <a title="463-lsi-15" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>16 0.6738221 <a title="463-lsi-16" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>17 0.63489848 <a title="463-lsi-17" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>18 0.63068813 <a title="463-lsi-18" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>19 0.6125685 <a title="463-lsi-19" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>20 0.60289448 <a title="463-lsi-20" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.01), (6, 0.015), (29, 0.037), (35, 0.051), (39, 0.016), (42, 0.118), (45, 0.021), (47, 0.212), (48, 0.024), (55, 0.017), (68, 0.032), (69, 0.037), (74, 0.209), (82, 0.037), (95, 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93628132 <a title="463-lda-1" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>Introduction: Makc asked a goodquestionin comments--"Why bother to make a paper, at all?"
There are several reasons for writing papers which may not be immediately
obvious to people not in academia.The basic idea is that papers have
considerably more utility than the obvious "present an idea".Papers are a
formalized units of work. Academics (especially young ones) are often judged
on the number of papers they produce.Papers have a formalized method of citing
and crediting other--the bibliography. Academics (especially older ones) are
often judged on the number of citations they receive.Papers enable a "more
fair" anonymous review. Conferences receivemanypapers, from which a subset are
selected. Discussion forums are inherently not anonymous for anyone who wants
to build a reputation for good work.Papers are an excuse to meet your friends.
Papers are the content of conferences, but much of what you do is talk to
friends about interesting problems while there. Sometimes you even solve
them.Papers are</p><p>same-blog 2 0.90930033 <a title="463-lda-2" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>Introduction: This is a rather long post, detailing the ICML 2012 review process. The goal
is to make the process more transparent, help authors understand how we came
to a decision, and discuss the strengths and weaknesses of this process for
future conference organizers.Microsoft’s Conference Management Toolkit (CMT)We
chose to useCMTover other conference management software mainly because of its
rich toolkit. The interface is sub-optimal (to say the least!) but it has
extensive capabilities (to handle bids, author response, resubmissions, etc.),
good import/export mechanisms (to process the data elsewhere), excellent
technical support (to answer late night emails, add new functionalities).
Overall, it was the right choice, although we hope a designer will look at
that interface sometime soon!Toronto Matching System (TMS)TMSis now being used
by many major conferences in our field (including NIPS and UAI). It is an
automated system (developed byLaurent CharlinandRich Zemelat U. Toronto) to
match re</p><p>3 0.87965465 <a title="463-lda-3" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>Introduction: If you have been disappointed by the lack of a post for the last month,
considercontributing your own(I've been busy+uninspired). Also, keep in mind
that there is a community of machine learning blogs (see the sidebar).</p><p>4 0.80026382 <a title="463-lda-4" href="../hunch_net-2013/hunch_net-2013-11-09-Graduates_and_Postdocs.html">490 hunch net-2013-11-09-Graduates and Postdocs</a></p>
<p>Introduction: Several strong graduates are on the job market this year.Alekh Agarwalmade
themost scalable public learning algorithmas an intern two years ago. He has a
deep and broad understanding of optimization and learning as well as the
ability and will to make things happen programming-wise. I've been privileged
to have Alekh visiting me in NY where he will be sorely missed.John
DuchicreatedAdagradwhich is a commonly helpful improvement over online
gradient descent that is seeing wide adoption, including inVowpal Wabbit. He
has a similarly deep and broad understanding of optimization and learning with
significant industry experience atGoogle. Alekh and John have often coauthored
together.Stephane Rossvisited me a year ago over the summer, implementing many
new algorithms and working out the firstscale free online update rulewhich is
now the default in Vowpal Wabbit. Stephane isnoton the market--Google robbed
the cradle successfullyI'm sure that he will do great things.Anna
Choromanskavisited me</p><p>5 0.7596783 <a title="463-lda-5" href="../hunch_net-2012/hunch_net-2012-10-18-7th_Annual_Machine_Learning_Symposium.html">474 hunch net-2012-10-18-7th Annual Machine Learning Symposium</a></p>
<p>Introduction: A reminder that theNew York Academy of Scienceswill be hosting the7th Annual
Machine Learning Symposiumtomorrow from 9:30am.The main program will feature
invited talks fromPeter Bartlett,William Freeman, andVladimir Vapnik, along
with numerous spotlight talks and a poster session. Following the main
program,hackNYandMicrosoft Researchare sponsoring a networking hour with talks
from machine learning practitioners at NYC startups
(specificallybit.ly,Buzzfeed,Chartbeat, andSense Networks,Visual Revenue).
This should be of great interest to everyone considering working in machine
learning.</p><p>6 0.74784786 <a title="463-lda-6" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>7 0.73413134 <a title="463-lda-7" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>8 0.73370522 <a title="463-lda-8" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>9 0.72710204 <a title="463-lda-9" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>10 0.7267487 <a title="463-lda-10" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>11 0.72340232 <a title="463-lda-11" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>12 0.72147679 <a title="463-lda-12" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>13 0.72075486 <a title="463-lda-13" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>14 0.7194134 <a title="463-lda-14" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>15 0.71328658 <a title="463-lda-15" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>16 0.71011412 <a title="463-lda-16" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>17 0.70760709 <a title="463-lda-17" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>18 0.70599127 <a title="463-lda-18" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>19 0.70568615 <a title="463-lda-19" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>20 0.70547724 <a title="463-lda-20" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
