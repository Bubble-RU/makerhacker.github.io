<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>466 hunch net-2012-06-05-ICML acceptance statistics</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2012" href="../home/hunch_net-2012_home.html">hunch_net-2012</a> <a title="hunch_net-2012-466" href="#">hunch_net-2012-466</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>466 hunch net-2012-06-05-ICML acceptance statistics</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2012-466-html" href="http://hunch.net/?p=2517">html</a></p><p>Introduction: People are naturally interested in slicing the ICML acceptance statistics in
various ways. Here's a rundown for the top categories.18/66 = 0.27in
(0.18,0.36)Reinforcement Learning10/52 = 0.19in (0.17,0.37)Supervised
Learning9/51 = 0.18not in (0.18, 0.37)Clustering12/46 = 0.26in (0.17,
0.37)Kernel Methods11/40 = 0.28in (0.15, 0.4)Optimization Algorithms8/33 =
0.24in (0.15, 0.39)Learning Theory14/33 = 0.42not in (0.15, 0.39)Graphical
Models10/32 = 0.31in (0.15, 0.41)Applications (+5 invited)8/29 = 0.28in (0.14,
0.41])Probabilistic Models13/29 = 0.45not in (0.14, 0.41)NN & Deep
Learning8/26 = 0.31in (0.12, 0.42)Transfer and Multi-Task Learning13/25 =
0.52not in (0.12, 0.44)Online Learning5/25 = 0.20in (0.12, 0.44)Active
Learning6/22 = 0.27in (0.14, 0.41)Semi-Supervised Learning7/20 = 0.35in (0.1,
0.45)Statistical Methods4/20 = 0.20in (0.1, 0.45)Sparsity and Compressed
Sensing1/19 = 0.05not in (0.11, 0.42)Ensemble Methods5/18 = 0.28in (0.11,
0.44)Structured Output Prediction4/18 = 0.22in (</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('weak', 0.411), ('reject', 0.283), ('accept', 0.28), ('strong', 0.251), ('accepts', 0.158), ('acs', 0.149), ('average', 0.144), ('reviews', 0.128), ('treating', 0.128), ('acceptance', 0.127), ('discussion', 0.119), ('decision', 0.118), ('gaussian', 0.115), ('score', 0.115), ('tail', 0.114), ('pretend', 0.114), ('ac', 0.114), ('rarely', 0.11), ('deviation', 0.105), ('feedback', 0.104)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999964 <a title="466-tfidf-1" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>Introduction: People are naturally interested in slicing the ICML acceptance statistics in
various ways. Here's a rundown for the top categories.18/66 = 0.27in
(0.18,0.36)Reinforcement Learning10/52 = 0.19in (0.17,0.37)Supervised
Learning9/51 = 0.18not in (0.18, 0.37)Clustering12/46 = 0.26in (0.17,
0.37)Kernel Methods11/40 = 0.28in (0.15, 0.4)Optimization Algorithms8/33 =
0.24in (0.15, 0.39)Learning Theory14/33 = 0.42not in (0.15, 0.39)Graphical
Models10/32 = 0.31in (0.15, 0.41)Applications (+5 invited)8/29 = 0.28in (0.14,
0.41])Probabilistic Models13/29 = 0.45not in (0.14, 0.41)NN & Deep
Learning8/26 = 0.31in (0.12, 0.42)Transfer and Multi-Task Learning13/25 =
0.52not in (0.12, 0.44)Online Learning5/25 = 0.20in (0.12, 0.44)Active
Learning6/22 = 0.27in (0.14, 0.41)Semi-Supervised Learning7/20 = 0.35in (0.1,
0.45)Statistical Methods4/20 = 0.20in (0.1, 0.45)Sparsity and Compressed
Sensing1/19 = 0.05not in (0.11, 0.42)Ensemble Methods5/18 = 0.28in (0.11,
0.44)Structured Output Prediction4/18 = 0.22in (</p><p>2 0.19563615 <a title="466-tfidf-2" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>3 0.19160163 <a title="466-tfidf-3" href="../hunch_net-2012/hunch_net-2012-02-24-ICML%2B50%25.html">456 hunch net-2012-02-24-ICML+50%</a></p>
<p>Introduction: TheICMLpaper deadline has passed.Joelleand I were surprised to see the number
of submissions jump from last year by about 50% to around 900 submissions. A
tiny portion of these are immediate rejects(*), so this is a much larger set
of papers than expected. The number of workshop submissions also doubled
compared to last year, so ICML may grow significantly this year, if we can
manage to handle the load well. The prospect of making 900 good decisions is
fundamentally daunting, and success will rely heavily on theprogram
committeeandarea chairsat this point.For those who want to rubberneck a bit
more, here's a breakdown of submissions by primary topic of submitted
papers:66 Reinforcement Learning 52 Supervised Learning 51 Clustering 46
Kernel Methods 40 Optimization Algorithms 39 Feature Selection and
Dimensionality Reduction 33 Learning Theory 33 Graphical Models 33
Applications 29 Probabilistic Models 29 NN & Deep Learning 26 Transfer and
Multi-Task Learning 25 Online Learning 25 Activ</p><p>4 0.1843095 <a title="466-tfidf-4" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but
sometimes the unfairness seems particularly striking. This is most easily seen
by comparison:PaperBanditronOffset TreeNotesProblem ScopeMulticlass problems
where only the loss of one choice can be probed.Strictly greater: Cost
sensitive multiclass problems where only the loss of one choice can be
probed.Often generalizations don't matter. That's not the case here, since
every plausible application I've thought of involves loss functions
substantially different from 0/1.What's newAnalysis and ExperimentsAlgorithm,
Analysis, and ExperimentsAs far as I know, the essence of the more general
problem was first stated and analyzed with theEXP4 algorithm (page 16)(1998).
It's also the time horizon 1 simplification of the Reinforcement Learning
setting for therandom trajectory method (page 15)(2002). The Banditron
algorithm itself is functionally identical toOne-Step RL with Traces (page
122)(2003) inBianca's thesis</p><p>5 0.18185741 <a title="466-tfidf-5" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>Introduction: Just about nothing could keep me from attendingICML, except forDorawho arrived
on Monday. Consequently, I have only secondhand reports that the conference is
going well.For those who are remote (like me) or after the conference (like
everyone),Mark Reidhas setup theICML discussionsite where you can comment on
any paper or subscribe to papers. Authors are automatically subscribed to
their own papers, so it should be possible to have a discussion significantly
after the fact, as people desire.We also conducted a survey before the
conference and have thesurvey resultsnow. This can be compared with theICML
2010 survey results. Looking at the comparable questions, we can sometimes
order the answers to have scores ranging from 0 to 3 or 0 to 4 with 3 or 4
being best and 0 worst, then compute the average difference between 2012 and
2010.Glancing through them, I see:Most people found the papers they reviewed a
good fit for their expertise (-.037 w.r.t 2010). Achieving this was one of our
subgo</p><p>6 0.18071507 <a title="466-tfidf-6" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>7 0.17301154 <a title="466-tfidf-7" href="../hunch_net-2006/hunch_net-2006-05-16-The_value_of_the_orthodox_view_of_Boosting.html">179 hunch net-2006-05-16-The value of the orthodox view of Boosting</a></p>
<p>8 0.16275391 <a title="466-tfidf-8" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>9 0.1604268 <a title="466-tfidf-9" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>10 0.15856782 <a title="466-tfidf-10" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>11 0.15667053 <a title="466-tfidf-11" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>12 0.14550065 <a title="466-tfidf-12" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>13 0.13939868 <a title="466-tfidf-13" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>14 0.13647063 <a title="466-tfidf-14" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>15 0.13313024 <a title="466-tfidf-15" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>16 0.13189842 <a title="466-tfidf-16" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>17 0.12869154 <a title="466-tfidf-17" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>18 0.12423431 <a title="466-tfidf-18" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>19 0.11636244 <a title="466-tfidf-19" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>20 0.11278933 <a title="466-tfidf-20" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.226), (1, 0.144), (2, -0.194), (3, -0.039), (4, -0.09), (5, 0.053), (6, -0.055), (7, -0.006), (8, 0.047), (9, -0.033), (10, 0.111), (11, 0.022), (12, -0.083), (13, 0.062), (14, 0.067), (15, -0.031), (16, -0.089), (17, 0.021), (18, 0.015), (19, -0.018), (20, 0.017), (21, 0.003), (22, 0.016), (23, 0.005), (24, -0.025), (25, 0.047), (26, 0.043), (27, 0.144), (28, 0.053), (29, -0.024), (30, -0.001), (31, -0.066), (32, 0.005), (33, 0.024), (34, 0.116), (35, 0.1), (36, -0.025), (37, 0.001), (38, -0.029), (39, -0.007), (40, -0.012), (41, -0.034), (42, 0.017), (43, 0.077), (44, 0.015), (45, 0.029), (46, 0.063), (47, 0.017), (48, -0.0), (49, 0.079)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98259819 <a title="466-lsi-1" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>Introduction: People are naturally interested in slicing the ICML acceptance statistics in
various ways. Here's a rundown for the top categories.18/66 = 0.27in
(0.18,0.36)Reinforcement Learning10/52 = 0.19in (0.17,0.37)Supervised
Learning9/51 = 0.18not in (0.18, 0.37)Clustering12/46 = 0.26in (0.17,
0.37)Kernel Methods11/40 = 0.28in (0.15, 0.4)Optimization Algorithms8/33 =
0.24in (0.15, 0.39)Learning Theory14/33 = 0.42not in (0.15, 0.39)Graphical
Models10/32 = 0.31in (0.15, 0.41)Applications (+5 invited)8/29 = 0.28in (0.14,
0.41])Probabilistic Models13/29 = 0.45not in (0.14, 0.41)NN & Deep
Learning8/26 = 0.31in (0.12, 0.42)Transfer and Multi-Task Learning13/25 =
0.52not in (0.12, 0.44)Online Learning5/25 = 0.20in (0.12, 0.44)Active
Learning6/22 = 0.27in (0.14, 0.41)Semi-Supervised Learning7/20 = 0.35in (0.1,
0.45)Statistical Methods4/20 = 0.20in (0.1, 0.45)Sparsity and Compressed
Sensing1/19 = 0.05not in (0.11, 0.42)Ensemble Methods5/18 = 0.28in (0.11,
0.44)Structured Output Prediction4/18 = 0.22in (</p><p>2 0.67410833 <a title="466-lsi-2" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>Introduction: Just about nothing could keep me from attendingICML, except forDorawho arrived
on Monday. Consequently, I have only secondhand reports that the conference is
going well.For those who are remote (like me) or after the conference (like
everyone),Mark Reidhas setup theICML discussionsite where you can comment on
any paper or subscribe to papers. Authors are automatically subscribed to
their own papers, so it should be possible to have a discussion significantly
after the fact, as people desire.We also conducted a survey before the
conference and have thesurvey resultsnow. This can be compared with theICML
2010 survey results. Looking at the comparable questions, we can sometimes
order the answers to have scores ranging from 0 to 3 or 0 to 4 with 3 or 4
being best and 0 worst, then compute the average difference between 2012 and
2010.Glancing through them, I see:Most people found the papers they reviewed a
good fit for their expertise (-.037 w.r.t 2010). Achieving this was one of our
subgo</p><p>3 0.67369068 <a title="466-lsi-3" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>Introduction: Claireasked me to be on the SODA program committee this year, which was quite
a bit of work.I had a relatively light load--merely 49 theory papers. Many of
these papers were not on subjects that I was expert about, so (as is common
for theory conferences) I found various reviewers that I trusted to help
review the papers. I ended up reviewing about 1/3 personally. There were a
couple instances where I ended up overruling a subreviewer whose logic seemed
off, but otherwise I generally let their reviews stand.There are some
differences in standards for paper reviews between the machine learning and
theory communities. In machine learning it is expected that a review be
detailed, while in the theory community this is often not the case. Every
paper given to me ended up with a review varying between somewhat and very
detailed.I'm sure not every author was happy with the outcome. While we did
our best to make good decisions, they were difficult decisions to make. For
example, if there is a</p><p>4 0.66235948 <a title="466-lsi-4" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>5 0.6510461 <a title="466-lsi-5" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>Introduction: as of last night, late.When the reviewing deadline passed Wednesday night 15%
of reviews were still missing, much higher than I expected. Between late
reviews coming in, ACs working overtime through the weekend, and people
willing to help in the pinch another ~390 reviews came in, reducing the
missing mass to 0.2%. Nailing that last bit and a similar quantity of papers
with uniformly low confidence reviews is what remains to be done in terms of
basic reviews. We are trying to make all of those happen this week so authors
have some chance to respond.I was surprised by the quantity of late reviews,
and I think that's an area where ICML needs to improve in future years. Good
reviews are not done in a rush--they are done by setting aside time (like an
afternoon), and carefully reading the paper while thinking about implications.
Many reviewers do this well but a significant minority aren't good at
scheduling their personal time. In this situation there are several ways to
fail:Give early w</p><p>6 0.6472556 <a title="466-lsi-6" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>7 0.64384484 <a title="466-lsi-7" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>8 0.64062327 <a title="466-lsi-8" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>9 0.63736486 <a title="466-lsi-9" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>10 0.63290381 <a title="466-lsi-10" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>11 0.62748808 <a title="466-lsi-11" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>12 0.61716455 <a title="466-lsi-12" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>13 0.61206836 <a title="466-lsi-13" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>14 0.60518229 <a title="466-lsi-14" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>15 0.54092503 <a title="466-lsi-15" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>16 0.53343648 <a title="466-lsi-16" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>17 0.53257465 <a title="466-lsi-17" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>18 0.53097409 <a title="466-lsi-18" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>19 0.52630162 <a title="466-lsi-19" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>20 0.52138817 <a title="466-lsi-20" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.023), (6, 0.023), (29, 0.048), (35, 0.1), (42, 0.139), (45, 0.038), (57, 0.163), (68, 0.022), (69, 0.017), (74, 0.157), (82, 0.079), (91, 0.011), (92, 0.027), (95, 0.028), (97, 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.88931435 <a title="466-lda-1" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>Introduction: People are naturally interested in slicing the ICML acceptance statistics in
various ways. Here's a rundown for the top categories.18/66 = 0.27in
(0.18,0.36)Reinforcement Learning10/52 = 0.19in (0.17,0.37)Supervised
Learning9/51 = 0.18not in (0.18, 0.37)Clustering12/46 = 0.26in (0.17,
0.37)Kernel Methods11/40 = 0.28in (0.15, 0.4)Optimization Algorithms8/33 =
0.24in (0.15, 0.39)Learning Theory14/33 = 0.42not in (0.15, 0.39)Graphical
Models10/32 = 0.31in (0.15, 0.41)Applications (+5 invited)8/29 = 0.28in (0.14,
0.41])Probabilistic Models13/29 = 0.45not in (0.14, 0.41)NN & Deep
Learning8/26 = 0.31in (0.12, 0.42)Transfer and Multi-Task Learning13/25 =
0.52not in (0.12, 0.44)Online Learning5/25 = 0.20in (0.12, 0.44)Active
Learning6/22 = 0.27in (0.14, 0.41)Semi-Supervised Learning7/20 = 0.35in (0.1,
0.45)Statistical Methods4/20 = 0.20in (0.1, 0.45)Sparsity and Compressed
Sensing1/19 = 0.05not in (0.11, 0.42)Ensemble Methods5/18 = 0.28in (0.11,
0.44)Structured Output Prediction4/18 = 0.22in (</p><p>2 0.85830951 <a title="466-lda-2" href="../hunch_net-2006/hunch_net-2006-12-05-Recruitment_Conferences.html">222 hunch net-2006-12-05-Recruitment Conferences</a></p>
<p>Introduction: One of the subsidiary roles of conferences is recruitment.NIPSis optimally
placed in time for this because it falls right before the major recruitment
season.I personally found job hunting embarrassing, and was relatively inept
at it. I expect this is true of many people, because it is not something done
often.The basic rule is: make the plausible hirers aware of your interest.
Anycorporate sponsoris a "plausible", regardless of whether or not there is a
booth.CRAand theacm job centerare other reasonable sources.There are
substantial differences between the different possibilities. Putting some
effort into understanding the distinctions is a good idea, although you should
always remember where the other person is coming from.</p><p>3 0.81886363 <a title="466-lda-3" href="../hunch_net-2012/hunch_net-2012-07-17-MUCMD_and_BayLearn.html">470 hunch net-2012-07-17-MUCMD and BayLearn</a></p>
<p>Introduction: The workshop on theMeaningful Use of Complex Medical Datais happening again,
August 9-12 in LA, nearUAIon Catalina Island August 15-17. I enjoyed my visit
last year, and expect this year to be interesting also.The firstBay Area
Machine Learning Symposiumis August 30 atGoogle. Abstracts are due July 30.</p><p>4 0.77700335 <a title="466-lda-4" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>Introduction: Conferences exist as part of the process of doing research. They provide many
roles including "announcing research", "meeting people", and "point of
reference". Not all conferences are alike so a basic question is: "to what
extent do individual conferences attempt to aid research?" This question is
very difficult to answer in any satisfying way. What we can do is compare
details of the process across multiple conferences.CommentsThe average quality
of comments across conferences can vary dramatically. At one extreme, the
tradition in CS theory conferences is to provide essentially zero feedback. At
the other extreme, some conferences have a strong tradition of providing
detailed constructive feedback. Detailed feedback can give authors significant
guidance about how to improve research. This is the most subjective
entry.BlindVirtually all conferences offer single blind review where authors
do not know reviewers. Some also providedouble blindreview where reviewers do
not know authors. T</p><p>5 0.76531184 <a title="466-lda-5" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>6 0.75104505 <a title="466-lda-6" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>7 0.75066006 <a title="466-lda-7" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>8 0.74778402 <a title="466-lda-8" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>9 0.74636137 <a title="466-lda-9" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>10 0.74517846 <a title="466-lda-10" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>11 0.74273014 <a title="466-lda-11" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>12 0.73919398 <a title="466-lda-12" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>13 0.7371285 <a title="466-lda-13" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>14 0.73064578 <a title="466-lda-14" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>15 0.72953659 <a title="466-lda-15" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>16 0.72361308 <a title="466-lda-16" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>17 0.7229467 <a title="466-lda-17" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>18 0.72126067 <a title="466-lda-18" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>19 0.721111 <a title="466-lda-19" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>20 0.71900016 <a title="466-lda-20" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
