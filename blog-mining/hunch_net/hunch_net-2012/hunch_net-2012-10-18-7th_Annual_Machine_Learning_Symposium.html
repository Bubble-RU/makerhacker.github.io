<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>474 hunch net-2012-10-18-7th Annual Machine Learning Symposium</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2012" href="../home/hunch_net-2012_home.html">hunch_net-2012</a> <a title="hunch_net-2012-474" href="#">hunch_net-2012-474</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>474 hunch net-2012-10-18-7th Annual Machine Learning Symposium</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2012-474-html" href="http://hunch.net/?p=2586">html</a></p><p>Introduction: A reminder that theNew York Academy of Scienceswill be hosting the7th Annual
Machine Learning Symposiumtomorrow from 9:30am.The main program will feature
invited talks fromPeter Bartlett,William Freeman, andVladimir Vapnik, along
with numerous spotlight talks and a poster session. Following the main
program,hackNYandMicrosoft Researchare sponsoring a networking hour with talks
from machine learning practitioners at NYC startups
(specificallybit.ly,Buzzfeed,Chartbeat, andSense Networks,Visual Revenue).
This should be of great interest to everyone considering working in machine
learning.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('talks', 0.356), ('main', 0.272), ('andvladimir', 0.222), ('networking', 0.222), ('freeman', 0.222), ('hosting', 0.222), ('revenue', 0.222), ('numerous', 0.206), ('vapnik', 0.206), ('practitioners', 0.206), ('academy', 0.206), ('sponsoring', 0.194), ('reminder', 0.194), ('spotlight', 0.194), ('hour', 0.185), ('startups', 0.178), ('annual', 0.172), ('poster', 0.147), ('thenew', 0.141), ('along', 0.141)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="474-tfidf-1" href="../hunch_net-2012/hunch_net-2012-10-18-7th_Annual_Machine_Learning_Symposium.html">474 hunch net-2012-10-18-7th Annual Machine Learning Symposium</a></p>
<p>Introduction: A reminder that theNew York Academy of Scienceswill be hosting the7th Annual
Machine Learning Symposiumtomorrow from 9:30am.The main program will feature
invited talks fromPeter Bartlett,William Freeman, andVladimir Vapnik, along
with numerous spotlight talks and a poster session. Following the main
program,hackNYandMicrosoft Researchare sponsoring a networking hour with talks
from machine learning practitioners at NYC startups
(specificallybit.ly,Buzzfeed,Chartbeat, andSense Networks,Visual Revenue).
This should be of great interest to everyone considering working in machine
learning.</p><p>2 0.10828131 <a title="474-tfidf-2" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>Introduction: The 201314 isNew York Machine Learning Symposiumis finally happening on March
28th at theNew York Academy of Science. Every invited speaker interests me
personally. They are:Rayid Ghani(Chief Scientist at Obama 2012)Brian
Kingsbury(Speech Recognition @ IBM)Jorge Nocedal(who did LBFGS)We've been
somewhat disorganized in advertising this. As a consequence, anyone who has
not submitted an abstract but would like to do so may send one directly to me
(jl@hunch.net title NYASMLS) by Friday March 14. I will forward them to the
rest of the committee for consideration.</p><p>3 0.10031781 <a title="474-tfidf-3" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>Introduction: TheNew York ML symposiumwas last Friday. Attendance was 268, significantly
larger thanlast year. My impression was that the event mostly still fit the
space, although it was crowded. If anyone has suggestions for next year, speak
up.The best student paper award went toSergiu Goschinfor a cool video of how
his system learned to play video games (I can't find the paper online yet).
Choosing amongst the submitted talks was pretty difficult this year, as there
were many similarly good ones.By coincidence all the invited talks were (at
least potentially) about faster learning algorithms.Stephen Boydtalked
aboutADMM.Leon Bottouspoke on single pass online learning viaaveraged SGD.Yoav
Freundtalked aboutparameter-free hedging. In Yoav's case the talk was mostly
about a better theoretical learning algorithm, but it has the potential to
unlock an exponential computational complexity improvement via oraclization of
experts algorithmsâ&euro;Ś but some serious thought needs to go in this
direction.Unrelat</p><p>4 0.099723071 <a title="474-tfidf-4" href="../hunch_net-2012/hunch_net-2012-03-24-David_Waltz.html">460 hunch net-2012-03-24-David Waltz</a></p>
<p>Introduction: hasdied. He lived a full life. I know him personally as a founder of theCenter
for Computational Learning Systemsand theNew York Machine Learning Symposium,
both of which have sheltered and promoted the advancement of machine learning.
I expect much of the New York area machine learning community will miss him,
as well as many others around the world.</p><p>5 0.096894793 <a title="474-tfidf-5" href="../hunch_net-2005/hunch_net-2005-07-01-The_Role_of_Impromptu_Talks.html">88 hunch net-2005-07-01-The Role of Impromptu Talks</a></p>
<p>Introduction: COLThad an impromptu session which seemed as interesting or more interesting
than any other single technical session (despite being only an hour long).
There are several roles that an impromptu session can play
including:Announcing new work since the paper deadline. Letting this happen
now rather than later helps aid the process of research.Discussing a paper
that was rejected. Reviewers err sometimes and an impromptu session provides a
means to remedy that.Entertainment. We all like to have a bit of fun.For
design, the following seem important:Impromptu speakers should not have much
time. At COLT, it was 8 minutes, but I have seen even 5 work well.The entire
impromptu session should not last too long because the format is dense and
promotes restlessness. A half hour or hour can work well.Impromptu talks are a
mechanism to let a little bit of chaos into the schedule. They will be chaotic
in content, presentation, and usefulness. The fundamental advantage of this
chaos is that it provid</p><p>6 0.096369073 <a title="474-tfidf-6" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>7 0.094944283 <a title="474-tfidf-7" href="../hunch_net-2012/hunch_net-2012-10-26-ML_Symposium_and_Strata-Hadoop_World.html">475 hunch net-2012-10-26-ML Symposium and Strata-Hadoop World</a></p>
<p>8 0.094791204 <a title="474-tfidf-8" href="../hunch_net-2010/hunch_net-2010-10-28-NY_ML_Symposium_2010.html">415 hunch net-2010-10-28-NY ML Symposium 2010</a></p>
<p>9 0.09016408 <a title="474-tfidf-9" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>10 0.086479619 <a title="474-tfidf-10" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>11 0.086347267 <a title="474-tfidf-11" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>12 0.084659129 <a title="474-tfidf-12" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<p>13 0.083653525 <a title="474-tfidf-13" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>14 0.082608581 <a title="474-tfidf-14" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>15 0.079171665 <a title="474-tfidf-15" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>16 0.071554646 <a title="474-tfidf-16" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>17 0.070487536 <a title="474-tfidf-17" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<p>18 0.068936884 <a title="474-tfidf-18" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>19 0.068018422 <a title="474-tfidf-19" href="../hunch_net-2008/hunch_net-2008-10-19-NIPS_2008_workshop_on_Kernel_Learning.html">321 hunch net-2008-10-19-NIPS 2008 workshop on Kernel Learning</a></p>
<p>20 0.065684229 <a title="474-tfidf-20" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.072), (1, 0.055), (2, 0.078), (3, 0.126), (4, 0.005), (5, 0.026), (6, -0.031), (7, -0.012), (8, 0.083), (9, -0.088), (10, 0.074), (11, 0.106), (12, 0.058), (13, -0.083), (14, -0.12), (15, 0.063), (16, -0.062), (17, 0.016), (18, -0.006), (19, 0.011), (20, 0.006), (21, -0.051), (22, 0.013), (23, -0.127), (24, -0.02), (25, 0.041), (26, 0.007), (27, -0.045), (28, -0.051), (29, 0.026), (30, 0.021), (31, -0.022), (32, -0.015), (33, 0.048), (34, -0.026), (35, 0.007), (36, 0.027), (37, -0.059), (38, -0.022), (39, -0.039), (40, -0.028), (41, -0.037), (42, -0.046), (43, -0.043), (44, 0.047), (45, -0.015), (46, 0.077), (47, -0.009), (48, 0.005), (49, 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91645944 <a title="474-lsi-1" href="../hunch_net-2012/hunch_net-2012-10-18-7th_Annual_Machine_Learning_Symposium.html">474 hunch net-2012-10-18-7th Annual Machine Learning Symposium</a></p>
<p>Introduction: A reminder that theNew York Academy of Scienceswill be hosting the7th Annual
Machine Learning Symposiumtomorrow from 9:30am.The main program will feature
invited talks fromPeter Bartlett,William Freeman, andVladimir Vapnik, along
with numerous spotlight talks and a poster session. Following the main
program,hackNYandMicrosoft Researchare sponsoring a networking hour with talks
from machine learning practitioners at NYC startups
(specificallybit.ly,Buzzfeed,Chartbeat, andSense Networks,Visual Revenue).
This should be of great interest to everyone considering working in machine
learning.</p><p>2 0.74107987 <a title="474-lsi-2" href="../hunch_net-2010/hunch_net-2010-10-28-NY_ML_Symposium_2010.html">415 hunch net-2010-10-28-NY ML Symposium 2010</a></p>
<p>Introduction: About 200 people attended the2010 NYAS ML Symposiumthis year. (It wasabout 170
last year.) I particularly enjoyed several talks.Yannhas a new live demo of
(limited) real-time object recognition learning.Sanjoygave a fairly convincing
and comprehensible explanation of why amodified form of single-linkage
clusteringis consistent in higher dimensions, and why consistency is a
critical feature for clustering algorithms. I'm curious how well this
algorithm works in practice.Matt Hoffman's poster covering online LDA seemed
pretty convincing to me as an algorithmic improvement.This year, we allocated
more time towards posters & poster spotlights.For next year, we are
considering some further changes. The format has traditionally been 4 invited
Professor speakers, with posters and poster spotlight for students. Demand
from other parties to participate is growing, for example from postdocs and
startups in the area. Another growing concern is the facility--the location is
exceptional, but fittin</p><p>3 0.71165526 <a title="474-lsi-3" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>Introduction: I'm not as naturally exuberant asMuthu2orDavidaboutCS/Econday, but I believe
it andML daywere certainly successful.At the CS/Econ day, I particularly
enjoyedToumas Sandholm'stalk which showed a commanding depth of understanding
and application in automated auctions.For the machine learning day, I enjoyed
several talks and posters (I better, I helped pick them.). What stood out to
me was number of people attending: 158 registered, a level qualifying as
"scramble to find seats". My rule of thumb for workshops/conferences is that
the number of attendees is often something like the number of submissions.
That isn't the case here, where there were just 4 invited speakers and 30-or-
so posters. Presumably, the difference is due to a critical mass of Machine
Learning interested people in the area and the ease of their attendance.Are
there other areas where a local Machine Learning day would fly? It's easy to
imagine something working out in the San Francisco bay area and possibly
Germany or E</p><p>4 0.69819611 <a title="474-lsi-4" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>Introduction: May 16 in Cambridge, is theNew England Machine Learning Day, a first regional
workshop/symposium on machine learning. To present a poster, submit an
abstract byMay 5.May 19 in New York,STOCis coming to town and rather
surprisingly havingworkshopswhich should be quite a bit of fun. I'll be
speaking atAlgorithms for Distributed and Streaming Data.</p><p>5 0.6864987 <a title="474-lsi-5" href="../hunch_net-2012/hunch_net-2012-03-24-David_Waltz.html">460 hunch net-2012-03-24-David Waltz</a></p>
<p>Introduction: hasdied. He lived a full life. I know him personally as a founder of theCenter
for Computational Learning Systemsand theNew York Machine Learning Symposium,
both of which have sheltered and promoted the advancement of machine learning.
I expect much of the New York area machine learning community will miss him,
as well as many others around the world.</p><p>6 0.65646988 <a title="474-lsi-6" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>7 0.63170713 <a title="474-lsi-7" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<p>8 0.60405123 <a title="474-lsi-8" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>9 0.57606548 <a title="474-lsi-9" href="../hunch_net-2008/hunch_net-2008-09-04-Fall_ML_Conferences.html">316 hunch net-2008-09-04-Fall ML Conferences</a></p>
<p>10 0.57490879 <a title="474-lsi-10" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<p>11 0.54620302 <a title="474-lsi-11" href="../hunch_net-2012/hunch_net-2012-10-26-ML_Symposium_and_Strata-Hadoop_World.html">475 hunch net-2012-10-26-ML Symposium and Strata-Hadoop World</a></p>
<p>12 0.52714759 <a title="474-lsi-12" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>13 0.52464175 <a title="474-lsi-13" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<p>14 0.49820346 <a title="474-lsi-14" href="../hunch_net-2006/hunch_net-2006-04-09-Progress_in_Machine_Translation.html">171 hunch net-2006-04-09-Progress in Machine Translation</a></p>
<p>15 0.47979197 <a title="474-lsi-15" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>16 0.46551263 <a title="474-lsi-16" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>17 0.43250892 <a title="474-lsi-17" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>18 0.42485055 <a title="474-lsi-18" href="../hunch_net-2009/hunch_net-2009-04-23-Jonathan_Chang_at_Slycoder.html">350 hunch net-2009-04-23-Jonathan Chang at Slycoder</a></p>
<p>19 0.4230026 <a title="474-lsi-19" href="../hunch_net-2005/hunch_net-2005-07-01-The_Role_of_Impromptu_Talks.html">88 hunch net-2005-07-01-The Role of Impromptu Talks</a></p>
<p>20 0.41152942 <a title="474-lsi-20" href="../hunch_net-2007/hunch_net-2007-02-11-24.html">232 hunch net-2007-02-11-24</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.088), (47, 0.755)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99323434 <a title="474-lda-1" href="../hunch_net-2007/hunch_net-2007-08-28-Live_ML_Class.html">261 hunch net-2007-08-28-Live ML Class</a></p>
<p>Introduction: Davor andChunnanpoint out thatMLSS 2007 in Tuebingenhaslive videofor the
majority of the world that is not there (heh).</p><p>same-blog 2 0.88165748 <a title="474-lda-2" href="../hunch_net-2012/hunch_net-2012-10-18-7th_Annual_Machine_Learning_Symposium.html">474 hunch net-2012-10-18-7th Annual Machine Learning Symposium</a></p>
<p>Introduction: A reminder that theNew York Academy of Scienceswill be hosting the7th Annual
Machine Learning Symposiumtomorrow from 9:30am.The main program will feature
invited talks fromPeter Bartlett,William Freeman, andVladimir Vapnik, along
with numerous spotlight talks and a poster session. Following the main
program,hackNYandMicrosoft Researchare sponsoring a networking hour with talks
from machine learning practitioners at NYC startups
(specificallybit.ly,Buzzfeed,Chartbeat, andSense Networks,Visual Revenue).
This should be of great interest to everyone considering working in machine
learning.</p><p>3 0.83218628 <a title="474-lda-3" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>Introduction: If you have been disappointed by the lack of a post for the last month,
considercontributing your own(I've been busy+uninspired). Also, keep in mind
that there is a community of machine learning blogs (see the sidebar).</p><p>4 0.51593643 <a title="474-lda-4" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>Introduction: Makc asked a goodquestionin comments--"Why bother to make a paper, at all?"
There are several reasons for writing papers which may not be immediately
obvious to people not in academia.The basic idea is that papers have
considerably more utility than the obvious "present an idea".Papers are a
formalized units of work. Academics (especially young ones) are often judged
on the number of papers they produce.Papers have a formalized method of citing
and crediting other--the bibliography. Academics (especially older ones) are
often judged on the number of citations they receive.Papers enable a "more
fair" anonymous review. Conferences receivemanypapers, from which a subset are
selected. Discussion forums are inherently not anonymous for anyone who wants
to build a reputation for good work.Papers are an excuse to meet your friends.
Papers are the content of conferences, but much of what you do is talk to
friends about interesting problems while there. Sometimes you even solve
them.Papers are</p><p>5 0.49431586 <a title="474-lda-5" href="../hunch_net-2013/hunch_net-2013-11-09-Graduates_and_Postdocs.html">490 hunch net-2013-11-09-Graduates and Postdocs</a></p>
<p>Introduction: Several strong graduates are on the job market this year.Alekh Agarwalmade
themost scalable public learning algorithmas an intern two years ago. He has a
deep and broad understanding of optimization and learning as well as the
ability and will to make things happen programming-wise. I've been privileged
to have Alekh visiting me in NY where he will be sorely missed.John
DuchicreatedAdagradwhich is a commonly helpful improvement over online
gradient descent that is seeing wide adoption, including inVowpal Wabbit. He
has a similarly deep and broad understanding of optimization and learning with
significant industry experience atGoogle. Alekh and John have often coauthored
together.Stephane Rossvisited me a year ago over the summer, implementing many
new algorithms and working out the firstscale free online update rulewhich is
now the default in Vowpal Wabbit. Stephane isnoton the market--Google robbed
the cradle successfullyI'm sure that he will do great things.Anna
Choromanskavisited me</p><p>6 0.33133236 <a title="474-lda-6" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>7 0.3147985 <a title="474-lda-7" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>8 0.15378922 <a title="474-lda-8" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>9 0.14470497 <a title="474-lda-9" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>10 0.13290153 <a title="474-lda-10" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>11 0.13278396 <a title="474-lda-11" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<p>12 0.12956668 <a title="474-lda-12" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>13 0.12655708 <a title="474-lda-13" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>14 0.12601103 <a title="474-lda-14" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>15 0.12535736 <a title="474-lda-15" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>16 0.12499413 <a title="474-lda-16" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<p>17 0.12445237 <a title="474-lda-17" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<p>18 0.12055877 <a title="474-lda-18" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>19 0.11611776 <a title="474-lda-19" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>20 0.11603392 <a title="474-lda-20" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
