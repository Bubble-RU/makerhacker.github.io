<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>336 hunch net-2009-01-19-Netflix prize within epsilon</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-336" href="#">hunch_net-2009-336</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>336 hunch net-2009-01-19-Netflix prize within epsilon</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-336-html" href="http://hunch.net/?p=527">html</a></p><p>Introduction: The competitors for the  Netflix Prize  are tantalizingly close winning the million dollar prize.  This year,  BellKor  and  Commendo Research  sent a combined solution that won the  progress prize .  Reading the  writeups   2  is instructive.  Several aspects of solutions are taken for granted including stochastic gradient descent, ensemble prediction, and targeting residuals (a form of boosting).  Relatively to last year, it appears that many approaches have added parameterizations, especially for the purpose of modeling through time.
 
The big question is: will they make the big prize?  At this point, the level of complexity in entering the competition is prohibitive, so perhaps only the existing competitors will continue to try.  (This equation might change drastically if the teams open source their existing solutions, including parameter settings.) One fear is that the progress is asymptoting on the wrong side of the 10% threshold.  In the first year, the teams progressed through</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The competitors for the  Netflix Prize  are tantalizingly close winning the million dollar prize. [sent-1, score-0.778]
</p><p>2 This year,  BellKor  and  Commendo Research  sent a combined solution that won the  progress prize . [sent-2, score-0.816]
</p><p>3 Several aspects of solutions are taken for granted including stochastic gradient descent, ensemble prediction, and targeting residuals (a form of boosting). [sent-4, score-0.726]
</p><p>4 Relatively to last year, it appears that many approaches have added parameterizations, especially for the purpose of modeling through time. [sent-5, score-0.246]
</p><p>5 The big question is: will they make the big prize? [sent-6, score-0.292]
</p><p>6 At this point, the level of complexity in entering the competition is prohibitive, so perhaps only the existing competitors will continue to try. [sent-7, score-0.652]
</p><p>7 (This equation might change drastically if the teams open source their existing solutions, including parameter settings. [sent-8, score-0.77]
</p><p>8 ) One fear is that the progress is asymptoting on the wrong side of the 10% threshold. [sent-9, score-0.553]
</p><p>9 In the first year, the teams progressed through 84. [sent-10, score-0.529]
</p><p>10 3% of the 10% gap, and in the second year, they progressed through just 64. [sent-11, score-0.298]
</p><p>11 While these numbers suggest an asymptote on the wrong side, in the month since the progress prize another 34. [sent-13, score-0.838]
</p><p>12 Itâ&euro;&trade;s remarkable that itâ&euro;&trade;s too close to call, with just a 0. [sent-15, score-0.26]
</p><p>13 Clever people finding just the right parameterization might very well succeed. [sent-17, score-0.122]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('prize', 0.349), ('progressed', 0.298), ('competitors', 0.264), ('teams', 0.231), ('progress', 0.199), ('gap', 0.187), ('year', 0.159), ('close', 0.154), ('big', 0.146), ('side', 0.141), ('solutions', 0.136), ('prohibitive', 0.132), ('granted', 0.122), ('dollar', 0.122), ('parameterization', 0.122), ('drastically', 0.122), ('bellkor', 0.122), ('million', 0.122), ('remainder', 0.122), ('wrong', 0.117), ('entering', 0.116), ('winning', 0.116), ('equation', 0.116), ('remaining', 0.11), ('existing', 0.11), ('including', 0.107), ('remarkable', 0.106), ('targeting', 0.106), ('sent', 0.102), ('clever', 0.099), ('month', 0.096), ('win', 0.096), ('fear', 0.096), ('modeling', 0.091), ('combined', 0.091), ('ensemble', 0.091), ('succeed', 0.087), ('netflix', 0.085), ('parameter', 0.084), ('continue', 0.084), ('stochastic', 0.082), ('aspects', 0.082), ('call', 0.079), ('boosting', 0.078), ('purpose', 0.078), ('competition', 0.078), ('suggest', 0.077), ('added', 0.077), ('won', 0.075), ('improvement', 0.073)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="336-tfidf-1" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>Introduction: The competitors for the  Netflix Prize  are tantalizingly close winning the million dollar prize.  This year,  BellKor  and  Commendo Research  sent a combined solution that won the  progress prize .  Reading the  writeups   2  is instructive.  Several aspects of solutions are taken for granted including stochastic gradient descent, ensemble prediction, and targeting residuals (a form of boosting).  Relatively to last year, it appears that many approaches have added parameterizations, especially for the purpose of modeling through time.
 
The big question is: will they make the big prize?  At this point, the level of complexity in entering the competition is prohibitive, so perhaps only the existing competitors will continue to try.  (This equation might change drastically if the teams open source their existing solutions, including parameter settings.) One fear is that the progress is asymptoting on the wrong side of the 10% threshold.  In the first year, the teams progressed through</p><p>2 0.15195422 <a title="336-tfidf-2" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended the  Netflix prize  ceremony this morning.  The press conference part is  covered fine elsewhere , with the basic outcome being that  BellKor’s Pragmatic Chaos  won over  The Ensemble  by 15-20  minutes , because they were tied in performance on the ultimate holdout set.  I’m sure the individual participants will have many chances to speak about the solution.  One of these is Bell at the  NYAS ML symposium on Nov. 6 .
 
Several additional details may interest ML people.
  
 The degree of overfitting exhibited by the difference in performance on the  leaderboard test set  and the ultimate hold out set was small, but determining at .02 to .03%. 
 A tie was possible, because the rules cut off measurements below the fourth digit based on significance concerns.  In actuality, of course, the scores do differ before rounding, but everyone I spoke to claimed not to know how.  The complete dataset has been  released on UCI , so each team could compute their own score to whatever accu</p><p>3 0.14966567 <a title="336-tfidf-3" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced the  Netflix Prize  contest. They published a comprehensive dataset including more than 100 million movie ratings, which were performed by about 480,000 real customers on 17,770 movies. Ã‚Â   Competitors in the challenge are required to estimate a few million ratings. Ã‚Â   To win the “grand prize,” they need to deliver a 10% improvement in the prediction error compared with the results of Cinematch, Netflix’s proprietary recommender system. Best current results deliver 9.12%  improvement , which is quite close to the 10% goal, yet painfully distant. 
   Ã‚Â   The Netflix Prize breathed new life and excitement into recommender systems research. The competition allowed the wide research community to access a large scale, real life dataset. Beyond this, the competition changed the rules of the game. Claiming that your nice idea could outperform some mediocre algorithms on some toy dataset is no longer acceptable. Now researcher</p><p>4 0.12321773 <a title="336-tfidf-4" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>Introduction: Perhaps the biggest CS prize for research is the  Turing Award , which has a $0.25M cash prize associated with it.  It appears none of the prizes so far have been for anything like machine learning (the closest are perhaps database awards).
 
In CS theory, there is the  GÃƒÂ¶del Prize  which is smaller and newer, offering a $5K prize along and perhaps (more importantly) recognition.  One such award has been given for Machine Learning, to  Robert Schapire  and  Yoav Freund  for Adaboost.
 
In Machine Learning, there seems to be no equivalent of these sorts of prizes.  There are several plausible reasons for this:
  
 
 There is no coherent community. 
  People drift in and out of the central conferences all the time.  Most of the author names from 10 years ago do not occur in the conferences of today.  In addition, the entire subject area is fairly new. 
 There are at least a core group of people who have stayed around. 
 
 
 Machine Learning work doesn’t last 
 Almost every paper is fo</p><p>5 0.11756071 <a title="336-tfidf-5" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>Introduction: I just  presented  the  cross validation  problem at  COLT .  
 
The problem now has a cash prize (up to $500) associated with itâ&euro;&rdquo;see the  presentation  for details.
 
The  write-up for colt .</p><p>6 0.115925 <a title="336-tfidf-6" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>7 0.11197491 <a title="336-tfidf-7" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>8 0.11011219 <a title="336-tfidf-8" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>9 0.10754501 <a title="336-tfidf-9" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>10 0.10263103 <a title="336-tfidf-10" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>11 0.096719794 <a title="336-tfidf-11" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>12 0.090444826 <a title="336-tfidf-12" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>13 0.082135141 <a title="336-tfidf-13" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>14 0.066806421 <a title="336-tfidf-14" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>15 0.06556274 <a title="336-tfidf-15" href="../hunch_net-2005/hunch_net-2005-07-21-Six_Months.html">96 hunch net-2005-07-21-Six Months</a></p>
<p>16 0.064277962 <a title="336-tfidf-16" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>17 0.061399776 <a title="336-tfidf-17" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>18 0.061098631 <a title="336-tfidf-18" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<p>19 0.060241453 <a title="336-tfidf-19" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>20 0.060038034 <a title="336-tfidf-20" href="../hunch_net-2013/hunch_net-2013-01-01-Deep_Learning_2012.html">477 hunch net-2013-01-01-Deep Learning 2012</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.139), (1, -0.006), (2, -0.057), (3, 0.024), (4, -0.035), (5, -0.014), (6, -0.096), (7, 0.005), (8, -0.035), (9, -0.038), (10, -0.073), (11, 0.178), (12, -0.062), (13, -0.023), (14, -0.028), (15, -0.008), (16, 0.054), (17, -0.029), (18, 0.024), (19, -0.055), (20, -0.181), (21, 0.041), (22, 0.06), (23, -0.047), (24, -0.005), (25, -0.058), (26, 0.002), (27, 0.051), (28, 0.045), (29, 0.03), (30, -0.028), (31, -0.037), (32, -0.121), (33, -0.064), (34, -0.111), (35, 0.036), (36, 0.009), (37, -0.072), (38, -0.062), (39, 0.018), (40, -0.118), (41, -0.039), (42, 0.006), (43, -0.034), (44, -0.041), (45, 0.027), (46, -0.055), (47, 0.04), (48, 0.142), (49, -0.018)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98282862 <a title="336-lsi-1" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>Introduction: The competitors for the  Netflix Prize  are tantalizingly close winning the million dollar prize.  This year,  BellKor  and  Commendo Research  sent a combined solution that won the  progress prize .  Reading the  writeups   2  is instructive.  Several aspects of solutions are taken for granted including stochastic gradient descent, ensemble prediction, and targeting residuals (a form of boosting).  Relatively to last year, it appears that many approaches have added parameterizations, especially for the purpose of modeling through time.
 
The big question is: will they make the big prize?  At this point, the level of complexity in entering the competition is prohibitive, so perhaps only the existing competitors will continue to try.  (This equation might change drastically if the teams open source their existing solutions, including parameter settings.) One fear is that the progress is asymptoting on the wrong side of the 10% threshold.  In the first year, the teams progressed through</p><p>2 0.6458174 <a title="336-lsi-2" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: The  Heritage Health Prize  is potentially the largest prediction prize yet at $3M, which is sure to get many people interested.  Several elements of the competition may be worth discussing.
  
 The most straightforward way for HPN to deploy this predictor is in determining who to cover with insurance.  This might easily cover the costs of running the contest itself, but the value to the health system of a whole is minimal, as people not covered still exist.  While HPN itself is a provider network, they have active relationships with a number of insurance companies, and the right to resell any entrant.  It’s worth keeping in mind that the research and development may nevertheless end up being useful in the longer term, especially as entrants also keep the right to their code. 
 The  judging metric  is something I haven’t seen previously.  If a patient has probability 0.5 of being in the hospital 0 days and probability 0.5 of being in the hospital ~53.6 days, the optimal prediction in e</p><p>3 0.5522539 <a title="336-lsi-3" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced the  Netflix Prize  contest. They published a comprehensive dataset including more than 100 million movie ratings, which were performed by about 480,000 real customers on 17,770 movies. Ã‚Â   Competitors in the challenge are required to estimate a few million ratings. Ã‚Â   To win the “grand prize,” they need to deliver a 10% improvement in the prediction error compared with the results of Cinematch, Netflix’s proprietary recommender system. Best current results deliver 9.12%  improvement , which is quite close to the 10% goal, yet painfully distant. 
   Ã‚Â   The Netflix Prize breathed new life and excitement into recommender systems research. The competition allowed the wide research community to access a large scale, real life dataset. Beyond this, the competition changed the rules of the game. Claiming that your nice idea could outperform some mediocre algorithms on some toy dataset is no longer acceptable. Now researcher</p><p>4 0.54976195 <a title="336-lsi-4" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>Introduction: … but only the little prize.  The  BellKor team  focused on integrating predictions from many different methods.  The base methods consist of:
  
 Nearest Neighbor Methods 
 Matrix Factorization Methods (asymmetric and symmetric) 
 Linear Regression on various feature spaces 
 Restricted Boltzman Machines 
  
The final predictor was an ensemble (as was reasonable to expect), although it’s a little bit more complicated than just a weighted average—it’s essentially a customized learning algorithm.  Base approaches (1)-(3) seem like relatively well-known approaches (although I haven’t seen the asymmetric factorization variant before).  RBMs are the new approach.
 
The  writeup  is pretty clear for more details.
 
The contestants are close to reaching the big prize, but the last 1.5% is probably at least as hard as what’s been done.  A few new structurally different methods for making predictions may need to be discovered and added into the mixture.  In other words, research may be require</p><p>5 0.54463911 <a title="336-lsi-5" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>Introduction: The DARPA grandchallenge is a big contest for autonomous robot vehicle driving.  It was run once in 2004 for the first time and all teams did badly.  This year was notably different with the  Stanford  and  CMU  teams succesfully completing the course.  A number of details are  here  and  wikipedia has continuing coverage .
 
A formal winner hasnâ&euro;&trade;t been declared yet although Stanford completed the course quickest.  
 
The Stanford and CMU teams deserve a large round of applause as they have strongly demonstrated the feasibility of autonomous vehicles.
 
The good news for machine learning is that the Stanford team (at least) is using some machine learning techniques.</p><p>6 0.53639489 <a title="336-lsi-6" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>7 0.53129089 <a title="336-lsi-7" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>8 0.49655181 <a title="336-lsi-8" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>9 0.47097152 <a title="336-lsi-9" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>10 0.46055201 <a title="336-lsi-10" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>11 0.41839311 <a title="336-lsi-11" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>12 0.41171998 <a title="336-lsi-12" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>13 0.41129732 <a title="336-lsi-13" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<p>14 0.38671559 <a title="336-lsi-14" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>15 0.38579711 <a title="336-lsi-15" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>16 0.36630097 <a title="336-lsi-16" href="../hunch_net-2006/hunch_net-2006-07-17-A_Winner.html">197 hunch net-2006-07-17-A Winner</a></p>
<p>17 0.35005447 <a title="336-lsi-17" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>18 0.34994951 <a title="336-lsi-18" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>19 0.34967315 <a title="336-lsi-19" href="../hunch_net-2006/hunch_net-2006-03-27-Gradients_everywhere.html">167 hunch net-2006-03-27-Gradients everywhere</a></p>
<p>20 0.3482264 <a title="336-lsi-20" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.219), (54, 0.408), (55, 0.075), (94, 0.082), (95, 0.088), (98, 0.021)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96286792 <a title="336-lda-1" href="../hunch_net-2009/hunch_net-2009-11-06-Yisong_Yue_on_Self-improving_Systems.html">376 hunch net-2009-11-06-Yisong Yue on Self-improving Systems</a></p>
<p>Introduction: I’d like to point out  Yisong Yue ‘s  post on Self-improving systems , which is a nicely readable description of the necessity and potential of interactive learning to deal with the information overload problem that is endemic to the modern internet.</p><p>2 0.90778339 <a title="336-lda-2" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>Introduction: The 20 13 14 is  New York Machine Learning Symposium  is finally happening on March 28th at the  New York Academy of Science .  Every invited speaker interests me personally.  They are:
  
  Rayid Ghani  (Chief Scientist at Obama 2012) 
  Brian Kingsbury  (Speech Recognition @ IBM) 
  Jorge Nocedal  (who did LBFGS) 
  
Weâ&euro;&trade;ve been somewhat disorganized in advertising this.  As a consequence, anyone who has not submitted an abstract but would like to do so may send one directly to me (jl@hunch.net title NYASMLS) by Friday March 14.  I will forward them to the rest of the committee for consideration.</p><p>same-blog 3 0.89038795 <a title="336-lda-3" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>Introduction: The competitors for the  Netflix Prize  are tantalizingly close winning the million dollar prize.  This year,  BellKor  and  Commendo Research  sent a combined solution that won the  progress prize .  Reading the  writeups   2  is instructive.  Several aspects of solutions are taken for granted including stochastic gradient descent, ensemble prediction, and targeting residuals (a form of boosting).  Relatively to last year, it appears that many approaches have added parameterizations, especially for the purpose of modeling through time.
 
The big question is: will they make the big prize?  At this point, the level of complexity in entering the competition is prohibitive, so perhaps only the existing competitors will continue to try.  (This equation might change drastically if the teams open source their existing solutions, including parameter settings.) One fear is that the progress is asymptoting on the wrong side of the 10% threshold.  In the first year, the teams progressed through</p><p>4 0.8767485 <a title="336-lda-4" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>Introduction: Carla Vicens and  Eric Siegel  contacted me about  Predictive Analytics World  in San Francisco February 18&19, which I wasn’t familiar with.  A quick look at the  agenda  reveals several people I know working on applications of machine learning in businesses, covering deployed applications topics.  It’s interesting to see a business-focused machine learning conference, as it says that we are succeeding as a field.  If you are interested in deployed applications, you might attend.
 
Eric and I did a quick interview by email.
 
John > 
I’ve mostly published and participated in academic machine learning conferences like ICML, COLT, and NIPS.   When I look at the  set of speakers and subjects  for your conference  I think “machine learning for business”.  Is that your understanding of things? What I’m trying to ask is: what do you view as the primary goal for this conference?
 
Eric > 
 You got it.  This is the business event focused on the commercial deployment of technology developed at</p><p>5 0.7073648 <a title="336-lda-5" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatov  says that we should think about regularization a bit.  It’s a complex topic which I only partially understand, so I’ll try to explain from a couple viewpoints.
  
  Functionally . Regularization is optimizing some representation to fit the data  and  minimize some notion of predictor complexity.  This notion of complexity is often the l 1  or l 2  norm on a set of parameters, but the term can be used much more generally.  Empirically, this often works much better than simply fitting the data. 
  Statistical Learning Viewpoint  Regularization is about the failiure of statistical learning to adequately predict generalization error.  Let  e(c,D)  be the expected error rate with respect to  D  of classifier  c  and  e(c,S)  the observed error rate on a sample  S .  There are numerous bounds of the form: assuming i.i.d. samples, with high probability over the drawn samples  S ,   e(c,D) less than e(c,S) + f(complexity)  where  complexity  is some measure of the size of a s</p><p>6 0.70505989 <a title="336-lda-6" href="../hunch_net-2012/hunch_net-2012-03-06-COLT-ICML_Open_Questions_and_ICML_Instructions.html">458 hunch net-2012-03-06-COLT-ICML Open Questions and ICML Instructions</a></p>
<p>7 0.54696321 <a title="336-lda-7" href="../hunch_net-2005/hunch_net-2005-02-02-Kolmogorov_Complexity_and_Googling.html">10 hunch net-2005-02-02-Kolmogorov Complexity and Googling</a></p>
<p>8 0.52088743 <a title="336-lda-8" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>9 0.51511657 <a title="336-lda-9" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>10 0.51150084 <a title="336-lda-10" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>11 0.51018816 <a title="336-lda-11" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>12 0.50824797 <a title="336-lda-12" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>13 0.50738561 <a title="336-lda-13" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>14 0.50736052 <a title="336-lda-14" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>15 0.50508285 <a title="336-lda-15" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>16 0.50405234 <a title="336-lda-16" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>17 0.5026238 <a title="336-lda-17" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>18 0.50254405 <a title="336-lda-18" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>19 0.50186408 <a title="336-lda-19" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>20 0.50176919 <a title="336-lda-20" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
