<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-359" href="#">hunch_net-2009-359</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-359-html" href="http://hunch.net/?p=777">html</a></p><p>Introduction: Suppose we have a set of observations over time  x 1 ,x 2 ,…,x t   and want to predict some future event  y t+1  .  An inevitable problem arises, because learning a predictor  h(x 1 ,…,x t )  of  y t+1   is generically intractable due to the size of the input.  To make this problem tractable, what’s necessary is a method for summarizing the relevant information in past observations for the purpose of prediction in the future.  In other words, state is required.
 
Existing approaches for deriving state have some limitations.
  
  Hidden Markov models  learned with EM suffer from local minima, use tabular learning approaches which provide dubious generalization ability, and often require substantial a.priori specification of the observations. 
  Kalman Filters  and  Particle Filters  are very parametric in the sense that substantial information must be specified up front. 
 Dynamic Bayesian Networks ( graphical models  through time) require substantial a.priori specification and often re</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Suppose we have a set of observations over time  x 1 ,x 2 ,…,x t   and want to predict some future event  y t+1  . [sent-1, score-0.166]
</p><p>2 An inevitable problem arises, because learning a predictor  h(x 1 ,…,x t )  of  y t+1   is generically intractable due to the size of the input. [sent-2, score-0.327]
</p><p>3 To make this problem tractable, what’s necessary is a method for summarizing the relevant information in past observations for the purpose of prediction in the future. [sent-3, score-0.466]
</p><p>4 Existing approaches for deriving state have some limitations. [sent-5, score-0.223]
</p><p>5 Hidden Markov models  learned with EM suffer from local minima, use tabular learning approaches which provide dubious generalization ability, and often require substantial a. [sent-6, score-0.773]
</p><p>6 Kalman Filters  and  Particle Filters  are very parametric in the sense that substantial information must be specified up front. [sent-8, score-0.346]
</p><p>7 Dynamic Bayesian Networks ( graphical models  through time) require substantial a. [sent-9, score-0.418]
</p><p>8 priori specification and often require the solution of difficult computational problems to use. [sent-10, score-0.462]
</p><p>9 The  Subspace-ID  approach from control theory uses a linear representation, with the basic claim that it works well when all transformations are linear, but not so well when things are nonlinear. [sent-12, score-0.535]
</p><p>10 )  In making this post, I ran across  this two day tutorial  which discusses extensions of this idea to nonlinear systems. [sent-14, score-0.419]
</p><p>11 The point of  this paper  at  ICML  is that some dynamic systems (those which are “invertible”), can be decomposed into separate bounded resource prediction problems which, when solved, create an implicit definition of state. [sent-16, score-0.382]
</p><p>12 This allows us to use any general purpose supervised learning algorithm to solve the  state formation problem  without requiring linearity or any specific representation. [sent-17, score-0.588]
</p><p>13 It doesn’t require lots of prior specification & information when you have lots of data. [sent-20, score-0.812]
</p><p>14 It leverages the huge amount of work that has gone into supervised learning algorithm design. [sent-21, score-0.181]
</p><p>15 It works in controlled systems also, where the control is simply another observation. [sent-22, score-0.393]
</p><p>16 It works with generalization from the start, rather than requiring the (often awkward) addition of generalization later. [sent-23, score-0.788]
</p><p>17 It doesn’t require predicting everything in order to predict what you want. [sent-24, score-0.235]
</p><p>18 It can work with very large observation spaces, and can even work better the larger the observation space, because larger observations imply more invertibility. [sent-25, score-0.678]
</p><p>19 For those who aren’t note that this is (in some sense) a generalization of subspace ID, and hence that there are other applications of the approach known to work in practice. [sent-28, score-0.606]
</p><p>20 It’s relatively rare to have a paper about a new approach to solving a problem as intractable as nonlinear dynamics has proved to be, so if you see a flaw please speak up. [sent-30, score-0.39]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('generalization', 0.264), ('require', 0.235), ('specification', 0.227), ('observations', 0.166), ('intractable', 0.163), ('filters', 0.151), ('requiring', 0.146), ('dynamic', 0.139), ('nonlinear', 0.139), ('state', 0.137), ('lots', 0.132), ('linear', 0.125), ('control', 0.122), ('doesn', 0.116), ('purpose', 0.116), ('works', 0.114), ('tutorial', 0.112), ('substantial', 0.103), ('supervised', 0.098), ('summarizing', 0.098), ('invertible', 0.098), ('kalman', 0.098), ('subspace', 0.091), ('formation', 0.091), ('dubious', 0.091), ('particle', 0.091), ('observation', 0.089), ('approach', 0.088), ('information', 0.086), ('transformations', 0.086), ('decomposed', 0.086), ('extensions', 0.086), ('deriving', 0.086), ('generically', 0.086), ('disappointed', 0.086), ('larger', 0.084), ('work', 0.083), ('discusses', 0.082), ('em', 0.082), ('representational', 0.082), ('models', 0.08), ('known', 0.08), ('systems', 0.079), ('sense', 0.079), ('dead', 0.078), ('inevitable', 0.078), ('resource', 0.078), ('controlled', 0.078), ('parametric', 0.078), ('minima', 0.078)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="359-tfidf-1" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>Introduction: Suppose we have a set of observations over time  x 1 ,x 2 ,…,x t   and want to predict some future event  y t+1  .  An inevitable problem arises, because learning a predictor  h(x 1 ,…,x t )  of  y t+1   is generically intractable due to the size of the input.  To make this problem tractable, what’s necessary is a method for summarizing the relevant information in past observations for the purpose of prediction in the future.  In other words, state is required.
 
Existing approaches for deriving state have some limitations.
  
  Hidden Markov models  learned with EM suffer from local minima, use tabular learning approaches which provide dubious generalization ability, and often require substantial a.priori specification of the observations. 
  Kalman Filters  and  Particle Filters  are very parametric in the sense that substantial information must be specified up front. 
 Dynamic Bayesian Networks ( graphical models  through time) require substantial a.priori specification and often re</p><p>2 0.18504468 <a title="359-tfidf-2" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>Introduction: One thing which is clear on a little reflection is that there exists a single master learning problem capable of encoding essentially all learning problems.  This problem is of course a very general sort of reinforcement learning where the world interacts with an agent as:
  
 The world announces an observation  x . 
 The agent makes a choice  a . 
 The world announces a reward  r . 
  
The goal here is to maximize the sum of the rewards over the time of the agent.  No particular structure relating  x  to  a  or  a  to  r  is implied by this setting so we do not know effective general algorithms for the agent.  It’s very easy to prove lower bounds showing that an agent cannot hope to succeed here—just consider the case where actions are unrelated to rewards.  Nevertheless, there is a real sense in which essentially all forms of life are agents operating in this setting, somehow succeeding.  The gap between these observations drives research—How can we find tractable specializations of</p><p>3 0.17596497 <a title="359-tfidf-3" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>Introduction: One conventional wisdom is that learning algorithms with linear representations are sufficient to solve natural learning  problems.  This conventional wisdom appears unsupported by empirical evidence as far as I can tell.  In nearly all vision, language, robotics, and speech applications I know where machine learning is effectively applied, the approach involves either a linear representation on hand crafted features capturing substantial nonlinearities or learning directly on nonlinear representations.  
 
There are a few exceptions to this—for example, if the problem of interest to you is predicting the next word given previous words, n-gram methods have been shown effective.  Viewed the right way, n-gram methods are essentially linear predictors on an enormous sparse feature space, learned from an enormous number of examples.  Hal’s post  here  describes some of this in more detail.
 
In contrast, if you go to a machine learning conference, a large number of the new algorithms are v</p><p>4 0.16065863 <a title="359-tfidf-4" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthu  invited me to the workshop on  algorithms in the field , with the goal of providing a sense of where near-term research should go.  When the time came though, I bargained for a post instead, which provides a chance for many other people to comment.
 
There are several things I didn’t fully understand when I went to Yahoo! about 5 years ago.  I’d like to repeat them as people in academia may not yet understand them intuitively.
  
 Almost all the big impact algorithms operate in pseudo-linear or better time.  Think about caching, hashing, sorting, filtering, etc… and you have a sense of what some of the most heavily used algorithms are.  This matters quite a bit to Machine Learning research, because people often work with superlinear time algorithms and languages.  Two very common examples of this are graphical models, where inference is often a superlinear operation—think about the  n 2   dependence on the number of states in a  Hidden Markov Model  and Kernelized  Support Vecto</p><p>5 0.14836198 <a title="359-tfidf-5" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>Introduction: In reinforcement learning (and sometimes other settings), there is a notion of “state”.   Based upon the state various predictions are made such as “Which action should be taken next?” or “How much cumulative reward do I expect if I take some action from this state?”  Given the importance of state, it is important to examine the meaning.   There are actually several distinct options and it turns out the definition variation is very important in motivating different pieces of work.
  
 Newtonian State.  State is the physical pose of the world.  Under this definition, there are  very  many states, often too many for explicit representation.  This is also the definition typically used in games. 
 Abstracted State.  State is an abstracted physical state of the world.  “Is the door open or closed?” “Are you in room A or not?” The number of states is much smaller here.  A basic issue here is: “How do you compute the state from observations?” 
 Mathematical State.  State is a sufficient stati</p><p>6 0.14680529 <a title="359-tfidf-6" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>7 0.13758403 <a title="359-tfidf-7" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>8 0.13203353 <a title="359-tfidf-8" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>9 0.12823269 <a title="359-tfidf-9" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>10 0.12539865 <a title="359-tfidf-10" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>11 0.11767701 <a title="359-tfidf-11" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>12 0.11549646 <a title="359-tfidf-12" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>13 0.11260829 <a title="359-tfidf-13" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>14 0.10524583 <a title="359-tfidf-14" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>15 0.1032688 <a title="359-tfidf-15" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>16 0.10272788 <a title="359-tfidf-16" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>17 0.1023219 <a title="359-tfidf-17" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>18 0.10194097 <a title="359-tfidf-18" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>19 0.10002732 <a title="359-tfidf-19" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>20 0.099302508 <a title="359-tfidf-20" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.282), (1, 0.084), (2, -0.017), (3, 0.027), (4, 0.086), (5, -0.026), (6, -0.007), (7, 0.035), (8, 0.065), (9, -0.025), (10, -0.021), (11, -0.059), (12, -0.037), (13, 0.08), (14, -0.021), (15, 0.011), (16, -0.01), (17, -0.034), (18, 0.064), (19, -0.01), (20, -0.044), (21, 0.056), (22, -0.004), (23, 0.031), (24, -0.078), (25, 0.047), (26, -0.039), (27, -0.038), (28, -0.055), (29, 0.021), (30, -0.028), (31, 0.01), (32, 0.091), (33, 0.026), (34, -0.053), (35, 0.074), (36, 0.067), (37, 0.031), (38, -0.049), (39, -0.003), (40, 0.011), (41, 0.041), (42, 0.007), (43, 0.043), (44, 0.033), (45, 0.045), (46, -0.098), (47, 0.034), (48, -0.049), (49, -0.137)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97181594 <a title="359-lsi-1" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>Introduction: Suppose we have a set of observations over time  x 1 ,x 2 ,…,x t   and want to predict some future event  y t+1  .  An inevitable problem arises, because learning a predictor  h(x 1 ,…,x t )  of  y t+1   is generically intractable due to the size of the input.  To make this problem tractable, what’s necessary is a method for summarizing the relevant information in past observations for the purpose of prediction in the future.  In other words, state is required.
 
Existing approaches for deriving state have some limitations.
  
  Hidden Markov models  learned with EM suffer from local minima, use tabular learning approaches which provide dubious generalization ability, and often require substantial a.priori specification of the observations. 
  Kalman Filters  and  Particle Filters  are very parametric in the sense that substantial information must be specified up front. 
 Dynamic Bayesian Networks ( graphical models  through time) require substantial a.priori specification and often re</p><p>2 0.7616694 <a title="359-lsi-2" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>Introduction: One conventional wisdom is that learning algorithms with linear representations are sufficient to solve natural learning  problems.  This conventional wisdom appears unsupported by empirical evidence as far as I can tell.  In nearly all vision, language, robotics, and speech applications I know where machine learning is effectively applied, the approach involves either a linear representation on hand crafted features capturing substantial nonlinearities or learning directly on nonlinear representations.  
 
There are a few exceptions to this—for example, if the problem of interest to you is predicting the next word given previous words, n-gram methods have been shown effective.  Viewed the right way, n-gram methods are essentially linear predictors on an enormous sparse feature space, learned from an enormous number of examples.  Hal’s post  here  describes some of this in more detail.
 
In contrast, if you go to a machine learning conference, a large number of the new algorithms are v</p><p>3 0.73399675 <a title="359-lsi-3" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthu  invited me to the workshop on  algorithms in the field , with the goal of providing a sense of where near-term research should go.  When the time came though, I bargained for a post instead, which provides a chance for many other people to comment.
 
There are several things I didn’t fully understand when I went to Yahoo! about 5 years ago.  I’d like to repeat them as people in academia may not yet understand them intuitively.
  
 Almost all the big impact algorithms operate in pseudo-linear or better time.  Think about caching, hashing, sorting, filtering, etc… and you have a sense of what some of the most heavily used algorithms are.  This matters quite a bit to Machine Learning research, because people often work with superlinear time algorithms and languages.  Two very common examples of this are graphical models, where inference is often a superlinear operation—think about the  n 2   dependence on the number of states in a  Hidden Markov Model  and Kernelized  Support Vecto</p><p>4 0.69933248 <a title="359-lsi-4" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>Introduction: In reinforcement learning (and sometimes other settings), there is a notion of “state”.   Based upon the state various predictions are made such as “Which action should be taken next?” or “How much cumulative reward do I expect if I take some action from this state?”  Given the importance of state, it is important to examine the meaning.   There are actually several distinct options and it turns out the definition variation is very important in motivating different pieces of work.
  
 Newtonian State.  State is the physical pose of the world.  Under this definition, there are  very  many states, often too many for explicit representation.  This is also the definition typically used in games. 
 Abstracted State.  State is an abstracted physical state of the world.  “Is the door open or closed?” “Are you in room A or not?” The number of states is much smaller here.  A basic issue here is: “How do you compute the state from observations?” 
 Mathematical State.  State is a sufficient stati</p><p>5 0.6631338 <a title="359-lsi-5" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>Introduction: In the AI-related parts of machine learning, it is often tempting to examine how  you  do things in order to imagine how a machine should do things.  This is introspection, and it can easily go awry.  I will call introspection gone awry introspectionism.
 
Introspectionism is almost unique to AI (and the AI-related parts of machine learning) and it can lead to huge wasted effort in research.  It’s easiest to show how introspectionism arises by an example.
 
Suppose we want to solve the problem of navigating a robot from point A to point B given a camera.  Then, the following research action plan might seem natural when you examine your own capabilities:
  
 Build an edge detector for still images. 
 Build an object recognition system given the edge detector. 
 Build a system to predict distance and orientation to objects given the object recognition system. 
 Build a system to plan a path through the scene you construct from {object identification, distance, orientation} predictions.</p><p>6 0.65924823 <a title="359-lsi-6" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>7 0.65086764 <a title="359-lsi-7" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>8 0.62815011 <a title="359-lsi-8" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>9 0.62414956 <a title="359-lsi-9" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>10 0.61067313 <a title="359-lsi-10" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>11 0.61036235 <a title="359-lsi-11" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>12 0.60519868 <a title="359-lsi-12" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>13 0.60482395 <a title="359-lsi-13" href="../hunch_net-2006/hunch_net-2006-10-22-Exemplar_programming.html">215 hunch net-2006-10-22-Exemplar programming</a></p>
<p>14 0.60408992 <a title="359-lsi-14" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>15 0.60370946 <a title="359-lsi-15" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>16 0.60284871 <a title="359-lsi-16" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<p>17 0.59956998 <a title="359-lsi-17" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>18 0.59835821 <a title="359-lsi-18" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>19 0.597633 <a title="359-lsi-19" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>20 0.59742808 <a title="359-lsi-20" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.025), (3, 0.017), (9, 0.022), (10, 0.014), (21, 0.025), (27, 0.249), (37, 0.016), (38, 0.066), (48, 0.031), (49, 0.103), (53, 0.085), (55, 0.072), (78, 0.013), (94, 0.131), (95, 0.052)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98085141 <a title="359-lda-1" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>Introduction: Suppose we have a set of observations over time  x 1 ,x 2 ,…,x t   and want to predict some future event  y t+1  .  An inevitable problem arises, because learning a predictor  h(x 1 ,…,x t )  of  y t+1   is generically intractable due to the size of the input.  To make this problem tractable, what’s necessary is a method for summarizing the relevant information in past observations for the purpose of prediction in the future.  In other words, state is required.
 
Existing approaches for deriving state have some limitations.
  
  Hidden Markov models  learned with EM suffer from local minima, use tabular learning approaches which provide dubious generalization ability, and often require substantial a.priori specification of the observations. 
  Kalman Filters  and  Particle Filters  are very parametric in the sense that substantial information must be specified up front. 
 Dynamic Bayesian Networks ( graphical models  through time) require substantial a.priori specification and often re</p><p>2 0.96547651 <a title="359-lda-2" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>Introduction: One striking feature of many machine learning algorithms is the gymnastics that designers go through to avoid symmetry breaking.  In the most basic form of machine learning, there are labeled examples composed of features.  Each of these can be treated symmetrically or asymmetrically by algorithms.
  
  feature symmetry   Every feature is treated the same.   In gradient update rules, the same update is applied whether the feature is first or last.  In metric-based predictions, every feature is just as important in computing the distance.   
  example symmetry   Every example is treated the same.  Batch learning algorithms are great exemplars of this approach. 
  label symmetry   Every label is treated the same.  This is particularly noticeable in multiclass classification systems which predict according to  arg max l  w l  x  but it occurs in many other places as well. 
  
Empirically, breaking symmetry well seems to yield great algorithms.
  
  feature asymmetry   For those who like t</p><p>3 0.96545208 <a title="359-lda-3" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>Introduction: Today brings a new release of the  Vowpal Wabbit  fast online learning software.  This time, unlike the previous release, the project itself is going open source, developing via  github .  For example, the lastest and greatest can be downloaded via:
  
git clone git://github.com/JohnLangford/vowpal_wabbit.git
  
If you aren’t familiar with  git , it’s a distributed version control system which supports quick and easy branching, as well as reconciliation.
 
This version of the code is confirmed to compile without complaint on at least some flavors of OSX as well as Linux boxes.
 
As much of the point of this project is pushing the limits of fast and effective machine learning, let me mention a few datapoints from my experience.
  
 The program can effectively scale up to batch-style training on sparse terafeature (i.e. 10 12  sparse feature) size datasets.  The limiting factor is typically i/o. 
 I started using the the real datasets from the  large-scale learning  workshop as a conve</p><p>4 0.93759161 <a title="359-lda-4" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>Introduction: This is a  paper  by Yann LeCun and Fu Jie Huang published at  AISTAT 2005 . I found this paper very difficult to read, but it does have some point about a computational shortcut.
 
This paper takes for granted that the method of solving a problem is gradient descent on parameters.  Given this assumption, the question arises: Do you want to do gradient descent on a probabilistic model or something else? 
 
All (conditional) probabilistic models have the form  p(y|x) = f(x,y)/Z(x)  where  Z(x) = sum y  f(x,y)  (the paper calls  - log f(x,y)  an “energy”).  If  f  is parameterized by some  w , the gradient has a term for  Z(x) , and hence for every value of  y .  The paper claims, that such models can be optimized for classification purposes using only the correct  y  and the other  y’ not y  which maximizes  f(x,y) .  This can even be done on unnormalizable models.  The paper further claims that this can be done with an approximate maximum.  These claims are plausible based on experimen</p><p>5 0.93490434 <a title="359-lda-5" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>Introduction: While everyone is silently working on ICML submissions, I found this discussion about a  fast physics simulator  chip interesting from a learning viewpoint.  In many cases, learning attempts to predict the outcome of physical processes.  Access to a fast simulator for these processes might be quite helpful in predicting the outcome.  Bayesian learning in particular may directly benefit while many other algorithms (like support vector machines) might have their speed greatly increased.
 
The biggest drawback is that writing software for these odd architectures is always difficult and time consuming, but a several-orders-of-magnitude speedup might make that worthwhile.</p><p>6 0.93030369 <a title="359-lda-6" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>7 0.92789447 <a title="359-lda-7" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>8 0.92276192 <a title="359-lda-8" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>9 0.92075431 <a title="359-lda-9" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>10 0.91807038 <a title="359-lda-10" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>11 0.91477436 <a title="359-lda-11" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>12 0.91350758 <a title="359-lda-12" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>13 0.91332567 <a title="359-lda-13" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>14 0.91295534 <a title="359-lda-14" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>15 0.91219151 <a title="359-lda-15" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>16 0.91218013 <a title="359-lda-16" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>17 0.91124988 <a title="359-lda-17" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>18 0.91089123 <a title="359-lda-18" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>19 0.91035008 <a title="359-lda-19" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>20 0.90907711 <a title="359-lda-20" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
