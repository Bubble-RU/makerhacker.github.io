<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>385 hunch net-2009-12-27-Interesting things at NIPS 2009</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-385" href="#">hunch_net-2009-385</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>385 hunch net-2009-12-27-Interesting things at NIPS 2009</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-385-html" href="http://hunch.net/?p=1152">html</a></p><p>Introduction: Several papers at NIPS caught my attention.
  
  Elad Hazan  and  Satyen Kale ,  Online Submodular Optimization  They define an algorithm for online optimization of submodular functions with regret guarantees.  This places submodular optimization roughly on par with online convex optimization as tractable settings for online learning.   
  Elad Hazan  and  Satyen Kale   On Stochastic and Worst-Case Models of Investing .  At it’s core, this is yet another example of modifying worst-case online learning to deal with variance, but the application to financial models is particularly cool and it seems plausibly superior other common approaches for financial modeling. 
  Mark Palatucci ,  Dean Pomerlau ,  Tom Mitchell , and  Geoff Hinton   Zero Shot Learning with Semantic Output Codes  The goal here is predicting a label in a multiclass supervised setting where the label never occurs in the training data.  They have some basic analysis and also a nice application to FMRI brain reading. 
  Sh</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Elad Hazan  and  Satyen Kale ,  Online Submodular Optimization  They define an algorithm for online optimization of submodular functions with regret guarantees. [sent-2, score-0.75]
</p><p>2 This places submodular optimization roughly on par with online convex optimization as tractable settings for online learning. [sent-3, score-0.972]
</p><p>3 At it’s core, this is yet another example of modifying worst-case online learning to deal with variance, but the application to financial models is particularly cool and it seems plausibly superior other common approaches for financial modeling. [sent-5, score-0.724]
</p><p>4 Mark Palatucci ,  Dean Pomerlau ,  Tom Mitchell , and  Geoff Hinton   Zero Shot Learning with Semantic Output Codes  The goal here is predicting a label in a multiclass supervised setting where the label never occurs in the training data. [sent-6, score-0.164]
</p><p>5 They have some basic analysis and also a nice application to FMRI brain reading. [sent-7, score-0.076]
</p><p>6 Kamalika Chaudhuri ,  Daniel Hsu , and  Yoav Freund ,  A Parameter Free Hedging Algorithm   This paper is about eliminating the learning rate parameter from online learning algorithms. [sent-11, score-0.291]
</p><p>7 While that’s certainly useful, the approach taken involves a double-exponential rather than a single exponential potential, which is strange and potentially useful in many other places. [sent-12, score-0.212]
</p><p>8 Bing Bai ,  Jason Weston ,  David Grangier ,  Ronan Collobert ,  Kunihiko Sadamasa ,  Yanjun Qi ,  Corinna Cortes ,    Polynomial Semantic Indexing   This is about an empirically improved algorithm for learning ranking functions based on (query,document) content. [sent-13, score-0.205]
</p><p>9 The sexy Semantic name is justified because it is not based on syntactic matching of query to document. [sent-14, score-0.331]
</p><p>10 I also found the  future publication models  discussion interesting. [sent-15, score-0.102]
</p><p>11 At the workshops, I was deeply confronted with the problem of too many interesting workshops to attend in the given amount of time. [sent-17, score-0.166]
</p><p>12 Two talks stood out for me:      Carlos Guestrin  gave a talk in the  interactive machine learning workshop  on  Turning Down the Noise in the Blogosphere  by  Khalid El-Arini ,  Gaurav Veda ,  Dafna Shahaf , and  Carlos Guestrin   which I missed at  KDD  this year. [sent-18, score-0.215]
</p><p>13 The paper discusses the use exponential weight online learning algorithms to rerank blog posts based on user-specific interests. [sent-19, score-0.369]
</p><p>14 It comes with a  demonstration website  where you can test it out. [sent-20, score-0.155]
</p><p>15 Leslie Valiant  gave a talk on representations and operations on concepts in a brain-like fashion. [sent-21, score-0.321]
</p><p>16 The style of representation and algorithm involves distributed representations on sparse graphs, an approach which is relatively unfamiliar. [sent-22, score-0.216]
</p><p>17 Bloom filters  and in machine learning experience with  learning through hashing functions  has sharpened my intuition a bit. [sent-23, score-0.123]
</p><p>18 The talk seemed to cover  Memorization and Association on a Realistic Neural Model  at  Neural Computation  as well as  A First Experimental Demonstration of Massive Knowledge Infusion  at  KR . [sent-24, score-0.109]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('submodular', 0.282), ('semantic', 0.219), ('guestrin', 0.188), ('online', 0.185), ('optimization', 0.16), ('demonstration', 0.155), ('kale', 0.155), ('satyen', 0.155), ('carlos', 0.146), ('financial', 0.139), ('elad', 0.129), ('hazan', 0.129), ('functions', 0.123), ('involves', 0.11), ('talk', 0.109), ('parameter', 0.106), ('representations', 0.106), ('gave', 0.106), ('models', 0.102), ('exponential', 0.102), ('neural', 0.087), ('justified', 0.083), ('sexy', 0.083), ('fmri', 0.083), ('weston', 0.083), ('modifying', 0.083), ('syntactic', 0.083), ('corinna', 0.083), ('cortes', 0.083), ('chaudhuri', 0.083), ('kamalika', 0.083), ('confronted', 0.083), ('activity', 0.083), ('bing', 0.083), ('hedging', 0.083), ('oliver', 0.083), ('workshops', 0.083), ('based', 0.082), ('label', 0.082), ('jason', 0.077), ('association', 0.077), ('indexing', 0.077), ('collobert', 0.077), ('ronan', 0.077), ('mitchell', 0.077), ('realistic', 0.077), ('investing', 0.077), ('valiant', 0.077), ('bloom', 0.077), ('application', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999964 <a title="385-tfidf-1" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>Introduction: Several papers at NIPS caught my attention.
  
  Elad Hazan  and  Satyen Kale ,  Online Submodular Optimization  They define an algorithm for online optimization of submodular functions with regret guarantees.  This places submodular optimization roughly on par with online convex optimization as tractable settings for online learning.   
  Elad Hazan  and  Satyen Kale   On Stochastic and Worst-Case Models of Investing .  At it’s core, this is yet another example of modifying worst-case online learning to deal with variance, but the application to financial models is particularly cool and it seems plausibly superior other common approaches for financial modeling. 
  Mark Palatucci ,  Dean Pomerlau ,  Tom Mitchell , and  Geoff Hinton   Zero Shot Learning with Semantic Output Codes  The goal here is predicting a label in a multiclass supervised setting where the label never occurs in the training data.  They have some basic analysis and also a nice application to FMRI brain reading. 
  Sh</p><p>2 0.19300878 <a title="385-tfidf-2" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>Introduction: At  ICML 2003 ,  Marty Zinkevich   proposed  the online convex optimization setting and showed that a particular gradient descent algorithm has regret O(T 0.5 ) with respect to the best predictor where T is the number of rounds. This seems to be a nice model for online learning, and there has been some significant follow-up work.
 
At  COLT 2006   Elad Hazan ,  Adam Kalai ,  Satyen Kale , and  Amit Agarwal  presented  a modification which takes a Newton step  guaranteeing O(log T) regret when the first and second derivatives are bounded.  Then they applied these algorithms to portfolio management  at  ICML 2006  (with  Robert Schapire ) yielding some very fun graphs.</p><p>3 0.1462139 <a title="385-tfidf-3" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>Introduction: I learned a number of things at  NIPS .
  
 The financial people were there in greater force than previously.   Two Sigma  sponsored NIPS while  DRW Trading  had a booth. 
 The  adversarial machine learning workshop  had a number of talks about interesting applications where an adversary really is out to try and mess up your learning algorithm.  This is very different from the situation we often think of where the world is oblivious to our learning.  This may present new and convincing applications for the learning-against-an-adversary work common at  COLT . 
 There were several interesing papers.
 
  Sanjoy Dasgupta ,  Daniel Hsu , and  Claire Monteleoni  had a paper on  General Agnostic Active Learning .  The basic idea is that active learning can be done via reduction to a form of supervised learning problem.  This is great, because we have many supervised learning algorithms from which the benefits of active learning may be derived. 
  Joseph Bradley  and  Robert Schapire  had a  P</p><p>4 0.13716364 <a title="385-tfidf-4" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>Introduction: The papers which interested me most at  ICML  and  COLT  2010 were:
  
  Thomas Walsh ,  Kaushik Subramanian ,  Michael Littman  and  Carlos Diuk   Generalizing Apprenticeship Learning across Hypothesis Classes .  This paper formalizes and provides algorithms with guarantees for mixed-mode apprenticeship and traditional reinforcement learning algorithms, allowing RL algorithms that perform better than for either setting alone. 
  István Szita  and  Csaba Szepesvári   Model-based reinforcement learning with nearly tight exploration complexity bounds .  This paper and  another represent the frontier of best-known algorithm for Reinforcement Learning in a Markov Decision Process. 
  James Martens   Deep learning via Hessian-free optimization .  About a new not-quite-online second order gradient algorithm for learning deep functional structures.  Potentially this is very powerful because while people have often talked about end-to-end learning, it has rarely worked in practice. 
  Chrisoph</p><p>5 0.13576025 <a title="385-tfidf-5" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>Introduction: Several talks seem potentially interesting to ML folks at this year’s SODA.
  
  Maria-Florina Balcan ,  Avrim Blum , and  Anupam Gupta ,  Approximate Clustering without the Approximation .  This paper gives reasonable algorithms with provable approximation guarantees for k-median and other notions of clustering.  It’s conceptually interesting, because it’s the second example I’ve seen where NP hardness is subverted by changing the problem definition subtle but reasonable way.  Essentially, they show that if any near-approximation to an optimal solution is good, then it’s computationally easy to find a near-optimal solution.  This subtle shift bears serious thought.  A similar one occurred in  our ranking paper  with respect to minimum feedback arcset.  With two known examples, it suggests that many more NP-complete problems might be finessed into irrelevance in this style. 
  Yury Lifshits  and  Shengyu Zhang ,  Combinatorial Algorithms for Nearest Neighbors, Near-Duplicates, and Smal</p><p>6 0.1294793 <a title="385-tfidf-6" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>7 0.12327261 <a title="385-tfidf-7" href="../hunch_net-2009/hunch_net-2009-06-24-Interesting_papers_at_UAICMOLT_2009.html">361 hunch net-2009-06-24-Interesting papers at UAICMOLT 2009</a></p>
<p>8 0.11756741 <a title="385-tfidf-8" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>9 0.11611968 <a title="385-tfidf-9" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>10 0.11295186 <a title="385-tfidf-10" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>11 0.10392161 <a title="385-tfidf-11" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>12 0.10389647 <a title="385-tfidf-12" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>13 0.10229196 <a title="385-tfidf-13" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>14 0.10149378 <a title="385-tfidf-14" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>15 0.1000608 <a title="385-tfidf-15" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>16 0.098983444 <a title="385-tfidf-16" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>17 0.096732065 <a title="385-tfidf-17" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>18 0.096415795 <a title="385-tfidf-18" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>19 0.095374085 <a title="385-tfidf-19" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>20 0.092677757 <a title="385-tfidf-20" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.227), (1, 0.051), (2, -0.048), (3, -0.098), (4, 0.146), (5, 0.057), (6, -0.014), (7, -0.123), (8, -0.001), (9, 0.078), (10, 0.072), (11, 0.03), (12, -0.082), (13, -0.075), (14, 0.045), (15, 0.084), (16, -0.036), (17, 0.008), (18, 0.077), (19, 0.021), (20, -0.019), (21, -0.069), (22, -0.004), (23, 0.031), (24, 0.09), (25, 0.033), (26, 0.052), (27, 0.015), (28, 0.0), (29, 0.038), (30, -0.079), (31, 0.049), (32, -0.007), (33, 0.02), (34, -0.041), (35, -0.017), (36, -0.015), (37, -0.035), (38, -0.065), (39, -0.086), (40, 0.045), (41, -0.013), (42, 0.02), (43, 0.068), (44, -0.043), (45, -0.007), (46, -0.069), (47, -0.019), (48, -0.007), (49, -0.079)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95257366 <a title="385-lsi-1" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>Introduction: Several papers at NIPS caught my attention.
  
  Elad Hazan  and  Satyen Kale ,  Online Submodular Optimization  They define an algorithm for online optimization of submodular functions with regret guarantees.  This places submodular optimization roughly on par with online convex optimization as tractable settings for online learning.   
  Elad Hazan  and  Satyen Kale   On Stochastic and Worst-Case Models of Investing .  At it’s core, this is yet another example of modifying worst-case online learning to deal with variance, but the application to financial models is particularly cool and it seems plausibly superior other common approaches for financial modeling. 
  Mark Palatucci ,  Dean Pomerlau ,  Tom Mitchell , and  Geoff Hinton   Zero Shot Learning with Semantic Output Codes  The goal here is predicting a label in a multiclass supervised setting where the label never occurs in the training data.  They have some basic analysis and also a nice application to FMRI brain reading. 
  Sh</p><p>2 0.70762134 <a title="385-lsi-2" href="../hunch_net-2009/hunch_net-2009-06-24-Interesting_papers_at_UAICMOLT_2009.html">361 hunch net-2009-06-24-Interesting papers at UAICMOLT 2009</a></p>
<p>Introduction: Here’s a list of papers that I found interesting at  ICML / COLT / UAI  in 2009.
  
  Elad Hazan  and  Comandur Seshadhri   Efficient learning algorithms for changing environments  at ICML.  This paper shows how to adapt learning algorithms that compete with fixed predictors to compete with changing policies.  The definition of regret they deal with seems particularly useful in many situation. 
  Hal Daume ,  Unsupervised Search-based Structured Prediction  at ICML.  This paper shows a technique for reducing unsupervised learning to supervised learning which (a) make a fast unsupervised learning algorithm and (b)  makes semisupervised learning both easy and highly effective.  
 There were two papers with similar results on active learning in the KWIK framework for linear regression, both reducing the sample complexity to .  One was  Nicolo Cesa-Bianchi ,  Claudio Gentile , and  Francesco Orabona   Robust Bounds for Classification via Selective Sampling  at ICML and the other was  Thoma</p><p>3 0.70580584 <a title="385-lsi-3" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>Introduction: At  ICML 2003 ,  Marty Zinkevich   proposed  the online convex optimization setting and showed that a particular gradient descent algorithm has regret O(T 0.5 ) with respect to the best predictor where T is the number of rounds. This seems to be a nice model for online learning, and there has been some significant follow-up work.
 
At  COLT 2006   Elad Hazan ,  Adam Kalai ,  Satyen Kale , and  Amit Agarwal  presented  a modification which takes a Newton step  guaranteeing O(log T) regret when the first and second derivatives are bounded.  Then they applied these algorithms to portfolio management  at  ICML 2006  (with  Robert Schapire ) yielding some very fun graphs.</p><p>4 0.67170346 <a title="385-lsi-4" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>Introduction: It turns out that many different people use the term “Online Learning”, and often they don’t have the same definition in mind.  Here’s a list of the possibilities I know of.  
  
  Online Information Setting   Online learning refers to a  problem  in which unlabeled data comes, a prediction is made, and then feedback is acquired. 
  Online Adversarial Setting  Online learning refers to  algorithms  in the Online Information Setting which satisfy guarantees of the form: “For all possible sequences of observations, the algorithim has regret at most  log ( number of strategies)  with respect to the best strategy in a set.”  This is sometimes called online learning with experts. 
  Online Optimization Constraint  Online learning refers to optimizing a predictor via a learning algorithm tunes parameters on a per-example basis.  This may or may not be applied in the Online Information Setting, and the strategy may or may not satisfy Adversarial setting theory. 
  Online Computational Constra</p><p>5 0.66879678 <a title="385-lsi-5" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>Introduction: Yoram  and  Shai ‘s  online learning tutorial  at  ICML  brings up a question for me, “Why use the  dual ?”
 
The basic setting is learning a weight vector  w i   so that the function  f(x)= sum i  w i  x i   optimizes some convex loss function.
 
The functional view of the dual is that instead of (or in addition to) keeping track of  w i   over the feature space, you keep track of a vector  a j   over the examples and define  w i  = sum j  a j  x ji  .
 
The above view of duality makes operating in the dual appear unnecessary, because in the end a weight vector is always used.  The tutorial suggests that thinking about the dual gives a unified algorithmic font for deriving online learning algorithms.  I haven’t worked with the dual representation much myself, but I have seen a few examples where it appears helpful.
  
  Noise  When doing online optimization (i.e. online learning where you are allowed to look at individual examples multiple times), the dual representation may be helpfu</p><p>6 0.64866143 <a title="385-lsi-6" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>7 0.63424194 <a title="385-lsi-7" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>8 0.62439358 <a title="385-lsi-8" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>9 0.61541647 <a title="385-lsi-9" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>10 0.60963786 <a title="385-lsi-10" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>11 0.59952158 <a title="385-lsi-11" href="../hunch_net-2011/hunch_net-2011-08-01-Interesting_papers_at_COLT_2011.html">439 hunch net-2011-08-01-Interesting papers at COLT 2011</a></p>
<p>12 0.59945786 <a title="385-lsi-12" href="../hunch_net-2006/hunch_net-2006-06-30-ICML_papers.html">188 hunch net-2006-06-30-ICML papers</a></p>
<p>13 0.57564288 <a title="385-lsi-13" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>14 0.56837064 <a title="385-lsi-14" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>15 0.5618102 <a title="385-lsi-15" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>16 0.55485618 <a title="385-lsi-16" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>17 0.54903322 <a title="385-lsi-17" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>18 0.53765643 <a title="385-lsi-18" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>19 0.53338575 <a title="385-lsi-19" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>20 0.53060675 <a title="385-lsi-20" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.022), (10, 0.023), (27, 0.211), (30, 0.014), (38, 0.059), (48, 0.011), (49, 0.012), (53, 0.039), (55, 0.091), (64, 0.015), (66, 0.332), (77, 0.015), (83, 0.013), (94, 0.041), (95, 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.8539905 <a title="385-lda-1" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>Introduction: I attended  ALT  (“Algorithmic Learning Theory”) for the first time this year.  My impression is ALT = 0.5 COLT, by attendance and also by some more intangible “what do I get from it?” measure.  There are many differences which can’t quite be described this way though.  The program for ALT seems to be substantially more diverse than COLT, which is both a weakness and a strength.  
 
One paper that might interest people generally is:
 
 Alexey Chernov  and  Vladimir Vovk ,  Prediction with Expert Evaluators’ Advice .  The basic observation here is that in the online learning with experts setting you can simultaneously compete with several compatible loss functions simultaneously.  Restated, debating between competing with log loss and squared loss is a waste of breath, because it’s almost free to compete with them both simultaneously.  This might interest anyone who has run into “which loss function?” debates that come up periodically.</p><p>same-blog 2 0.8511315 <a title="385-lda-2" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>Introduction: Several papers at NIPS caught my attention.
  
  Elad Hazan  and  Satyen Kale ,  Online Submodular Optimization  They define an algorithm for online optimization of submodular functions with regret guarantees.  This places submodular optimization roughly on par with online convex optimization as tractable settings for online learning.   
  Elad Hazan  and  Satyen Kale   On Stochastic and Worst-Case Models of Investing .  At it’s core, this is yet another example of modifying worst-case online learning to deal with variance, but the application to financial models is particularly cool and it seems plausibly superior other common approaches for financial modeling. 
  Mark Palatucci ,  Dean Pomerlau ,  Tom Mitchell , and  Geoff Hinton   Zero Shot Learning with Semantic Output Codes  The goal here is predicting a label in a multiclass supervised setting where the label never occurs in the training data.  They have some basic analysis and also a nice application to FMRI brain reading. 
  Sh</p><p>3 0.76388383 <a title="385-lda-3" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>Introduction: A few weeks ago I read  this . David Blei and I spent some time thinking hard about this a few years back (thanks to Kary Myers for pointing us to it):
 
 In short I was thinking that Ã¢â‚¬Å“bayesian belief updatingÃ¢â‚¬Â and Ã¢â‚¬Å“maximum entropyÃ¢â‚¬Â were two othogonal principles. But it appear that they are not, and that they can even be in conflict ! 
Example (from Kass 1996); consider a Die (6 sides), consider prior knowledge E[X]=3.5. 
Maximum entropy leads to P(X)= (1/6, 1/6, 1/6, 1/6, 1/6, 1/6). 
Now consider a new piece of evidence A=Ã¢â‚¬ÂX is an odd numberÃ¢â‚¬Â 
Bayesian posterior P(X|A)= P(A|X) P(X) = (1/3, 0, 1/3, 0, 1/3, 0). 
But MaxEnt with the constraints E[X]=3.5 and E[Indicator function of A]=1 leads to (.22, 0, .32, 0, .47, 0) !! (note that E[Indicator function of A]=P(A)) 
Indeed, for MaxEnt, because there is no more Ã¢â‚¬Ëœ6Ã¢â‚¬Â², big numbers must be more probable to ensure an average of 3.5. For bayesian updating, P(X|A) doesnÃ¢â‚¬â„¢t have to have a 3.5</p><p>4 0.59015518 <a title="385-lda-4" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but sometimes the unfairness seems particularly striking.  This is most easily seen by comparison:
  
 
 Paper 
  Banditron  
  Offset Tree  
 Notes 
 
 
 Problem Scope 
 Multiclass problems where only the loss of one choice can be probed. 
 Strictly greater: Cost sensitive multiclass problems where only the loss of one choice can be probed. 
 Often generalizations don’t matter.  That’s not the case here, since every plausible application I’ve thought of involves loss functions substantially different from 0/1. 
 
 
 What’s new 
 Analysis and Experiments 
 Algorithm, Analysis, and Experiments 
  As far as I know, the essence of the more general problem was first stated and analyzed with the  EXP4 algorithm (page 16)  (1998).  It’s also the time horizon 1 simplification of the Reinforcement Learning setting for the  random trajectory method (page 15)  (2002).  The Banditron algorithm itself is functionally identi</p><p>5 0.58589244 <a title="385-lda-5" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?
 
The most immediate measurable objective of computer science research is publishing a paper.  The most difficult aspect of publishing a paper is having reviewers accept and recommend it for publication.  The simplest mechanism for doing this is to show theoretical progress on some standard, well-known easily understood problem.
 
In doing this, we often fall into a local minima of the research process.  The basic problem in machine learning is that it is very unclear that the mathematical model is the right one for the (or some) real problem.  A good mathematical model in machine learning should have one fundamental trait: it should aid the design of effective learning algorithms.  To date, our ability to solve interesting learning problems (speech recognition, machine translation, object recognition, etc…) remains limited (although improving), so the “rightness” of our models is in doubt.
 
If our mathematical mod</p><p>6 0.58031714 <a title="385-lda-6" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>7 0.57809931 <a title="385-lda-7" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>8 0.57804847 <a title="385-lda-8" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>9 0.57744044 <a title="385-lda-9" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>10 0.57678455 <a title="385-lda-10" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>11 0.57654732 <a title="385-lda-11" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>12 0.57636714 <a title="385-lda-12" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>13 0.57568818 <a title="385-lda-13" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>14 0.57539463 <a title="385-lda-14" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>15 0.57510328 <a title="385-lda-15" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>16 0.57481891 <a title="385-lda-16" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>17 0.57432818 <a title="385-lda-17" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>18 0.57360005 <a title="385-lda-18" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>19 0.57299435 <a title="385-lda-19" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>20 0.57286024 <a title="385-lda-20" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
