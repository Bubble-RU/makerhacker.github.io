<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>343 hunch net-2009-02-18-Decision by Vetocracy</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-343" href="#">hunch_net-2009-343</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>343 hunch net-2009-02-18-Decision by Vetocracy</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-343-html" href="http://hunch.net/?p=558">html</a></p><p>Introduction: Few would mistake the process of academic paper review for a fair process, but
sometimes the unfairness seems particularly striking. This is most easily seen
by comparison:PaperBanditronOffset TreeNotesProblem ScopeMulticlass problems
where only the loss of one choice can be probed.Strictly greater: Cost
sensitive multiclass problems where only the loss of one choice can be
probed.Often generalizations don't matter. That's not the case here, since
every plausible application I've thought of involves loss functions
substantially different from 0/1.What's newAnalysis and ExperimentsAlgorithm,
Analysis, and ExperimentsAs far as I know, the essence of the more general
problem was first stated and analyzed with theEXP4 algorithm (page 16)(1998).
It's also the time horizon 1 simplification of the Reinforcement Learning
setting for therandom trajectory method (page 15)(2002). The Banditron
algorithm itself is functionally identical toOne-Step RL with Traces (page
122)(2003) inBianca's thesis</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reviewer', 0.321), ('vetocracy', 0.296), ('reviewers', 0.229), ('review', 0.175), ('workshop', 0.153), ('survive', 0.148), ('offset', 0.144), ('analysis', 0.135), ('veto', 0.131), ('responsibility', 0.123), ('reduction', 0.117), ('paper', 0.112), ('sabotage', 0.111), ('bidding', 0.102), ('cranky', 0.099), ('vacuous', 0.099), ('decision', 0.091), ('tree', 0.09), ('lower', 0.088), ('process', 0.087)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999893 <a title="343-tfidf-1" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but
sometimes the unfairness seems particularly striking. This is most easily seen
by comparison:PaperBanditronOffset TreeNotesProblem ScopeMulticlass problems
where only the loss of one choice can be probed.Strictly greater: Cost
sensitive multiclass problems where only the loss of one choice can be
probed.Often generalizations don't matter. That's not the case here, since
every plausible application I've thought of involves loss functions
substantially different from 0/1.What's newAnalysis and ExperimentsAlgorithm,
Analysis, and ExperimentsAs far as I know, the essence of the more general
problem was first stated and analyzed with theEXP4 algorithm (page 16)(1998).
It's also the time horizon 1 simplification of the Reinforcement Learning
setting for therandom trajectory method (page 15)(2002). The Banditron
algorithm itself is functionally identical toOne-Step RL with Traces (page
122)(2003) inBianca's thesis</p><p>2 0.35756713 <a title="343-tfidf-2" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>3 0.31677985 <a title="343-tfidf-3" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>Introduction: One way that many conferences in machine learning assign reviewers to papers
is via bidding, which has steps something like:Invite people to reviewAccept
papersReviewers look at title and abstract and state the papers they are
interested in reviewing.Some massaging happens, but reviewers often get
approximately the papers they bid for.At the ICML business meeting,Andrew
McCallumsuggested getting rid of bidding for papers. A couple reasons were
given:PrivacyThe title and abstract of the entire set of papers is visible to
every participating reviewer. Some authors might be uncomfortable about this
for submitted papers. I'm not sympathetic to this reason: the point of
submitting a paper to review is to publish it, so the value (if any) of not
publishing a part of it a little bit earlier seems limited.CliquesA bidding
system is gameable. If you have 3 buddies and you inform each other of your
submissions, you can each bid for your friend's papers and express a
disinterest in others. There</p><p>4 0.3078216 <a title="343-tfidf-4" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>5 0.24891502 <a title="343-tfidf-5" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>Introduction: This is a difficult subject to talk about for many reasons, but a discussion
may be helpful.Bad reviewing is a problem in academia. The first step in
understanding this is admitting to the problem, so here is a short list of
examples of bad reviewing.Reviewer disbelieves theorem proof (ICML), or
disbelieve theorem with a trivially false counterexample. (COLT)Reviewer
internally swaps quantifiers in a theorem, concludes it has been done before
and is trivial. (NIPS)Reviewer believes a technique will not work despite
experimental validation. (COLT)Reviewers fail to notice flaw in theorem
statement (CRYPTO).Reviewer erroneously claims that it has been done before
(NIPS, SODA, JMLR)--(complete with references!)Reviewer inverts the message of
a paper and concludes it says nothing important. (NIPS*2)Reviewer fails to
distinguish between a DAG and a tree (SODA).Reviewer is enthusiastic about
paper but clearly does not understand (ICML).Reviewer erroneously believe that
the "birthday paradox"</p><p>6 0.24499372 <a title="343-tfidf-6" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>7 0.24421822 <a title="343-tfidf-7" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>8 0.24043639 <a title="343-tfidf-8" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>9 0.2327653 <a title="343-tfidf-9" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>10 0.22812013 <a title="343-tfidf-10" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>11 0.22300071 <a title="343-tfidf-11" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>12 0.22222933 <a title="343-tfidf-12" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>13 0.21733686 <a title="343-tfidf-13" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>14 0.21404298 <a title="343-tfidf-14" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>15 0.21101603 <a title="343-tfidf-15" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>16 0.20470655 <a title="343-tfidf-16" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>17 0.19993395 <a title="343-tfidf-17" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>18 0.19946733 <a title="343-tfidf-18" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>19 0.19381058 <a title="343-tfidf-19" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>20 0.19240662 <a title="343-tfidf-20" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.434), (1, 0.209), (2, -0.239), (3, -0.036), (4, 0.005), (5, -0.06), (6, 0.069), (7, 0.018), (8, -0.129), (9, 0.074), (10, 0.032), (11, 0.117), (12, -0.023), (13, 0.003), (14, 0.0), (15, -0.059), (16, -0.131), (17, -0.042), (18, -0.036), (19, 0.01), (20, -0.061), (21, -0.001), (22, -0.001), (23, 0.071), (24, -0.105), (25, -0.011), (26, -0.034), (27, 0.044), (28, 0.03), (29, -0.002), (30, 0.014), (31, 0.028), (32, -0.003), (33, -0.033), (34, 0.036), (35, -0.033), (36, -0.052), (37, -0.028), (38, -0.002), (39, -0.048), (40, -0.006), (41, -0.023), (42, 0.019), (43, 0.073), (44, 0.017), (45, -0.002), (46, -0.012), (47, -0.006), (48, 0.005), (49, 0.004)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97183019 <a title="343-lsi-1" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but
sometimes the unfairness seems particularly striking. This is most easily seen
by comparison:PaperBanditronOffset TreeNotesProblem ScopeMulticlass problems
where only the loss of one choice can be probed.Strictly greater: Cost
sensitive multiclass problems where only the loss of one choice can be
probed.Often generalizations don't matter. That's not the case here, since
every plausible application I've thought of involves loss functions
substantially different from 0/1.What's newAnalysis and ExperimentsAlgorithm,
Analysis, and ExperimentsAs far as I know, the essence of the more general
problem was first stated and analyzed with theEXP4 algorithm (page 16)(1998).
It's also the time horizon 1 simplification of the Reinforcement Learning
setting for therandom trajectory method (page 15)(2002). The Banditron
algorithm itself is functionally identical toOne-Step RL with Traces (page
122)(2003) inBianca's thesis</p><p>2 0.86641616 <a title="343-lsi-2" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>3 0.8535251 <a title="343-lsi-3" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>4 0.85087079 <a title="343-lsi-4" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>Introduction: One way that many conferences in machine learning assign reviewers to papers
is via bidding, which has steps something like:Invite people to reviewAccept
papersReviewers look at title and abstract and state the papers they are
interested in reviewing.Some massaging happens, but reviewers often get
approximately the papers they bid for.At the ICML business meeting,Andrew
McCallumsuggested getting rid of bidding for papers. A couple reasons were
given:PrivacyThe title and abstract of the entire set of papers is visible to
every participating reviewer. Some authors might be uncomfortable about this
for submitted papers. I'm not sympathetic to this reason: the point of
submitting a paper to review is to publish it, so the value (if any) of not
publishing a part of it a little bit earlier seems limited.CliquesA bidding
system is gameable. If you have 3 buddies and you inform each other of your
submissions, you can each bid for your friend's papers and express a
disinterest in others. There</p><p>5 0.79681104 <a title="343-lsi-5" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>Introduction: Reviewing is a fairly formal process which is integral to the way academia is
run. Given this integral nature, the quality of reviewing is often
frustrating. I've seen plenty of examples of false statements, misbeliefs,
reading what isn't written, etcâ&euro;Ś, and I'm sure many other people have as
well.Recently, mechanisms like double blind review and author feedback have
been introduced to try to make the process more fair and accurate in many
machine learning (and related) conferences. My personal experience is that
these mechanisms help, especially the author feedback. Nevertheless, some
problems remain.The game theory take on reviewing is that the incentive for
truthful reviewing isn't there. Since reviewers are also authors, there are
sometimes perverse incentives created and acted upon. (Incidentially, these
incentives can be both positive and negative.)Setting up a truthful reviewing
system is tricky because their is no final reference truth available in any
acceptable (say: subyear)</p><p>6 0.78160161 <a title="343-lsi-6" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>7 0.77833343 <a title="343-lsi-7" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>8 0.7751025 <a title="343-lsi-8" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>9 0.7727161 <a title="343-lsi-9" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>10 0.77070194 <a title="343-lsi-10" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>11 0.76549536 <a title="343-lsi-11" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>12 0.76261383 <a title="343-lsi-12" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>13 0.75884837 <a title="343-lsi-13" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>14 0.75278378 <a title="343-lsi-14" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>15 0.73302102 <a title="343-lsi-15" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>16 0.72803652 <a title="343-lsi-16" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>17 0.71502191 <a title="343-lsi-17" href="../hunch_net-2005/hunch_net-2005-04-04-Grounds_for_Rejection.html">52 hunch net-2005-04-04-Grounds for Rejection</a></p>
<p>18 0.7140981 <a title="343-lsi-18" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>19 0.70529199 <a title="343-lsi-19" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>20 0.69148713 <a title="343-lsi-20" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.013), (6, 0.024), (7, 0.015), (29, 0.017), (35, 0.042), (42, 0.253), (45, 0.036), (55, 0.011), (63, 0.018), (67, 0.128), (68, 0.041), (69, 0.039), (74, 0.184), (82, 0.043), (95, 0.039), (98, 0.011)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94821966 <a title="343-lda-1" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but
sometimes the unfairness seems particularly striking. This is most easily seen
by comparison:PaperBanditronOffset TreeNotesProblem ScopeMulticlass problems
where only the loss of one choice can be probed.Strictly greater: Cost
sensitive multiclass problems where only the loss of one choice can be
probed.Often generalizations don't matter. That's not the case here, since
every plausible application I've thought of involves loss functions
substantially different from 0/1.What's newAnalysis and ExperimentsAlgorithm,
Analysis, and ExperimentsAs far as I know, the essence of the more general
problem was first stated and analyzed with theEXP4 algorithm (page 16)(1998).
It's also the time horizon 1 simplification of the Reinforcement Learning
setting for therandom trajectory method (page 15)(2002). The Banditron
algorithm itself is functionally identical toOne-Step RL with Traces (page
122)(2003) inBianca's thesis</p><p>2 0.93667191 <a title="343-lda-2" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>Introduction: One of the most confusing things about understanding learning theory is the
vast array of differing assumptions. Some critical thought about which of
these assumptions are reasonable for real-world problems may be useful.Before
we even start thinking about assumptions, it's important to realize that the
word hasmultiple meanings. The meaning used here is "assumption = axiom" (i.e.
something you can not verify).AssumptionReasonable?Which
analysis?Example/notesIndependent and Identically Distributed
DataSometimesPAC,ERM,Prediction bounds,statisticsTheKDD cup 2004 physics
datasetis plausibly IID data. There are a number of situations which are
"almost IID" in the sense that IID analysis results in correct intuitions.
Unreasonable in adversarial situations (stock market, war, etcâ&euro;Ś)Independently
Distributed DataMore than IID, but still only sometimesonline->batch
conversionLosing "identical" can be helpful in situations where you have a
cyclic process generating data.Finite exchangeability</p><p>3 0.92937964 <a title="343-lda-3" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>Introduction: Founding a successful new conference is extraordinarily difficult. As a
conference founder, you must manage to attract a significant number of good
papers--enough to entice the participants into participating next year and to
(generally) to grow the conference. For someone choosing to participate in a
new conference, there is a very significant decision to make: do you send a
paper to some new conference with no guarantee that the conference will work
out? Or do you send it to another (possibly less related) conference that you
are sure will work?The conference founding problem is a joint agreement
problem with a very significant barrier. Workshops are a way around this
problem, and workshops attached to conferences are a particularly effective
means for this. A workshop at a conference is sure to have people available to
speak and attend and is sure to have a large audience available. Presenting
work at a workshop is not generally exclusive: it can also be presented at a
conference. F</p><p>4 0.91630107 <a title="343-lda-4" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>Introduction: Essentially everyone who writes research papers suffers rejections. They
always sting immediately, but upon further reflection many of these rejections
come to seem reasonable. Maybe the equations had too many typos or maybe the
topic just isn't as important as was originally thought. A few rejections do
not come to seem acceptable, and these form the basis of reviewing horror
stories, a great material for conversations. I've decided to share three of
mine, now all safely a bit distant in the past.Prediction Theory for
Classification Tutorial. This is a tutorial about tight sample complexity
bounds for classification that I submitted toJMLR. The first decision I heard
was a reject which appeared quite unjust to me--for example one of the
reviewers appeared to claim that all the content was in standard statistics
books. Upon further inquiry, several citations were given, none of which
actually covered the content. Later, I was shocked to hear the paper was
accepted. Apparently, the pape</p><p>5 0.91100949 <a title="343-lda-5" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>Introduction: Unfortunately, I ended up sick for much of this ICML. I did manage to catch
one interesting paper:Richard Socher,Cliff Lin,Andrew Y. Ng, andChristopher D.
ManningParsing Natural Scenes and Natural Language with Recursive Neural
Networks.I invited Richard to share his list of interesting papers, so
hopefully we'll hear from him soon. In the meantime,PaulandHalhave posted some
lists.the futureJoelleand I are program chairs for ICML 2012 inEdinburgh,
which I previously enjoyed visiting in2005. This is a huge responsibility,
that we hope to accomplish well. A part of this (perhaps the most fun part),
is imagining how we can make ICML better. A key and critical constraint is
choosing things that can be accomplished. So far we have:Colocation. The first
thing we looked into was potential colocations. We quickly discovered that
many other conferences precomitted their location. For the future, getting a
colocation withACLorSIGIR, seems to require more advanced planning. If that
can be done, I</p><p>6 0.90998209 <a title="343-lda-6" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>7 0.90986174 <a title="343-lda-7" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>8 0.90780401 <a title="343-lda-8" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>9 0.90259993 <a title="343-lda-9" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>10 0.90218067 <a title="343-lda-10" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>11 0.9019807 <a title="343-lda-11" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>12 0.90188861 <a title="343-lda-12" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>13 0.90187913 <a title="343-lda-13" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>14 0.89797986 <a title="343-lda-14" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>15 0.89615959 <a title="343-lda-15" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>16 0.89568555 <a title="343-lda-16" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>17 0.89555991 <a title="343-lda-17" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>18 0.89305246 <a title="343-lda-18" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>19 0.89260429 <a title="343-lda-19" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>20 0.89249516 <a title="343-lda-20" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
