<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>371 hunch net-2009-09-21-Netflix finishes (and starts)</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-371" href="#">hunch_net-2009-371</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>371 hunch net-2009-09-21-Netflix finishes (and starts)</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-371-html" href="http://hunch.net/?p=949">html</a></p><p>Introduction: I attended the  Netflix prize  ceremony this morning.  The press conference part is  covered fine elsewhere , with the basic outcome being that  BellKor’s Pragmatic Chaos  won over  The Ensemble  by 15-20  minutes , because they were tied in performance on the ultimate holdout set.  I’m sure the individual participants will have many chances to speak about the solution.  One of these is Bell at the  NYAS ML symposium on Nov. 6 .
 
Several additional details may interest ML people.
  
 The degree of overfitting exhibited by the difference in performance on the  leaderboard test set  and the ultimate hold out set was small, but determining at .02 to .03%. 
 A tie was possible, because the rules cut off measurements below the fourth digit based on significance concerns.  In actuality, of course, the scores do differ before rounding, but everyone I spoke to claimed not to know how.  The complete dataset has been  released on UCI , so each team could compute their own score to whatever accu</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The press conference part is  covered fine elsewhere , with the basic outcome being that  BellKor’s Pragmatic Chaos  won over  The Ensemble  by 15-20  minutes , because they were tied in performance on the ultimate holdout set. [sent-2, score-0.454]
</p><p>2 The degree of overfitting exhibited by the difference in performance on the  leaderboard test set  and the ultimate hold out set was small, but determining at . [sent-7, score-0.501]
</p><p>3 The amount of programming and time which went into this contest was pretty shocking. [sent-14, score-0.599]
</p><p>4 I was particularly impressed with the amount of effort that went into various techniques for blending results from different systems. [sent-15, score-0.298]
</p><p>5 In this respect, the lack of release of the source code is a little bit disappointing. [sent-16, score-0.357]
</p><p>6 Because squared loss is convex, any two different solutions of similar performance can be linearly blended to yield a mixed solution of superior performance. [sent-20, score-0.475]
</p><p>7 This brings up a basic issue: How should a contest be designed? [sent-24, score-0.412]
</p><p>8 In the main, the finished Netflix contest seems to have been well designed. [sent-25, score-0.412]
</p><p>9 One improvement they are already implementing is asymptopia removal—the contest will award $0. [sent-27, score-0.472]
</p><p>10 Metric   One criticism is that squared loss does not very directly reflect the actual value to Netflix of a particular set of recommendations. [sent-31, score-0.512]
</p><p>11 The degree to which suboptimal squared loss prediction controls suboptimality of a recommendation loss is weak, but it should kick in when squared loss is deeply optimized as happened in this contest. [sent-33, score-0.927]
</p><p>12 So my basic take is that the squared loss metric seems “ok”, with the proviso that it could be done better if you start the data collection with some amount of random exploration. [sent-37, score-0.627]
</p><p>13 A good case can be made that this isn’t optimal design for a contest where we are trying to learn new things. [sent-39, score-0.469]
</p><p>14 This essentially corresponds to having a “softmax” prize distribution where the distribution to a participant  p  is according to  e -C(winner – p)   where  C  is a problem dependent constant. [sent-42, score-0.453]
</p><p>15 This introduces the possibility of a  sybil attack , but that appears acceptably controllable, especially if the prize distribution is limited to the top few participants. [sent-43, score-0.297]
</p><p>16 Source Code  After the Netflix prize was going for some time, the programming-time complexity of entering the contest became very formidable. [sent-44, score-0.609]
</p><p>17 The use of convex loss function and requiring participants to publish helped some with this, but it remained quite difficult. [sent-45, score-0.386]
</p><p>18 If the contest required the release of source code as well, I could imagine both lowering the barrier to late entry, and helping advance the field a bit more. [sent-46, score-0.769]
</p><p>19 Of course, it’s hard to go halfway with this—if you really want to guarantee that the source code works, you need to make the information exchange interface be the source code itself  (which is then compiled and run in a sandbox), rather than labels. [sent-47, score-0.665]
</p><p>20 For the Netflix contest in particular, the contest has educated me a bit about ensemble and SVD-style techniques, and I’m sure it’s generally helped crystallize out a set of applicable ML technologies for many people, which I expect to see widely used elsewhere in the future. [sent-50, score-1.226]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('contest', 0.412), ('netflix', 0.232), ('prize', 0.197), ('squared', 0.177), ('loss', 0.167), ('ensemble', 0.165), ('code', 0.145), ('source', 0.13), ('contests', 0.119), ('ultimate', 0.119), ('holdout', 0.119), ('metric', 0.116), ('impressed', 0.111), ('amount', 0.106), ('distribution', 0.1), ('criticism', 0.089), ('elsewhere', 0.085), ('release', 0.082), ('ml', 0.081), ('overfitting', 0.081), ('users', 0.081), ('went', 0.081), ('set', 0.079), ('convex', 0.076), ('mentioned', 0.074), ('helped', 0.073), ('degree', 0.072), ('performance', 0.071), ('participants', 0.07), ('experts', 0.068), ('data', 0.061), ('claimed', 0.06), ('chances', 0.06), ('svd', 0.06), ('halfway', 0.06), ('qualitative', 0.06), ('asymptopia', 0.06), ('anonymization', 0.06), ('blended', 0.06), ('functioning', 0.06), ('joins', 0.06), ('press', 0.06), ('race', 0.06), ('optimal', 0.057), ('according', 0.056), ('chaos', 0.055), ('recommended', 0.055), ('compiled', 0.055), ('leap', 0.055), ('pragmatic', 0.055)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="371-tfidf-1" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended the  Netflix prize  ceremony this morning.  The press conference part is  covered fine elsewhere , with the basic outcome being that  BellKor’s Pragmatic Chaos  won over  The Ensemble  by 15-20  minutes , because they were tied in performance on the ultimate holdout set.  I’m sure the individual participants will have many chances to speak about the solution.  One of these is Bell at the  NYAS ML symposium on Nov. 6 .
 
Several additional details may interest ML people.
  
 The degree of overfitting exhibited by the difference in performance on the  leaderboard test set  and the ultimate hold out set was small, but determining at .02 to .03%. 
 A tie was possible, because the rules cut off measurements below the fourth digit based on significance concerns.  In actuality, of course, the scores do differ before rounding, but everyone I spoke to claimed not to know how.  The complete dataset has been  released on UCI , so each team could compute their own score to whatever accu</p><p>2 0.30039462 <a title="371-tfidf-2" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix is  running a contest  to improve recommender prediction systems.   A 10% improvement over their current system yields a $1M prize.  Failing that, the best smaller improvement yields a smaller $50K prize.  This contest looks quite real, and the $50K prize money is almost certainly achievable with a bit of thought.  The contest also comes with a dataset which is apparently 2 orders of magnitude larger than any other public recommendation system datasets.</p><p>3 0.27364221 <a title="371-tfidf-3" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>Introduction: A $1M qualifying result was achieved on the  public Netflix test set  by a  3-way ensemble team .  This is just in time for  Yehuda ‘s presentation at  KDD , which I’m sure will be one of the best attended ever.  
 
This isn’t quite over—there are a few days for another super-conglomerate team to come together and there is some small chance that the performance is nonrepresentative of the final test set, but I expect not.  
 
Regardless of the final outcome, the biggest lesson for ML from the Netflix contest has been the formidable performance edge of ensemble methods.</p><p>4 0.26074764 <a title="371-tfidf-4" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: The  Heritage Health Prize  is potentially the largest prediction prize yet at $3M, which is sure to get many people interested.  Several elements of the competition may be worth discussing.
  
 The most straightforward way for HPN to deploy this predictor is in determining who to cover with insurance.  This might easily cover the costs of running the contest itself, but the value to the health system of a whole is minimal, as people not covered still exist.  While HPN itself is a provider network, they have active relationships with a number of insurance companies, and the right to resell any entrant.  It’s worth keeping in mind that the research and development may nevertheless end up being useful in the longer term, especially as entrants also keep the right to their code. 
 The  judging metric  is something I haven’t seen previously.  If a patient has probability 0.5 of being in the hospital 0 days and probability 0.5 of being in the hospital ~53.6 days, the optimal prediction in e</p><p>5 0.20669644 <a title="371-tfidf-5" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>Introduction: How do we judge success in Machine Learning?  As  Aaron   notes , the best way is to use the loss imposed on you by the world.  This turns out to be infeasible sometimes for various reasons.  The ones I’ve seen are:
  
 The learned prediction is used in some complicated process that does not give the feedback necessary to understand the prediction’s impact on the loss.  
 The prediction is used by some other system which expects some semantics to the predicted value.  This is similar to the previous example, except that the issue is design modularity rather than engineering modularity. 
 The correct loss function is simply unknown (and perhaps unknowable, except by experimentation). 
  
In these situations, it’s unclear what metric for evaluation should be chosen.  This post has some design advice for this murkier case.  I’m using the word “metric” here to distinguish the fact that we are considering methods for  evaluating  predictive systems rather than a loss imposed by the real wor</p><p>6 0.18689083 <a title="371-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>7 0.18395722 <a title="371-tfidf-7" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>8 0.17712553 <a title="371-tfidf-8" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>9 0.17219251 <a title="371-tfidf-9" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>10 0.17166072 <a title="371-tfidf-10" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>11 0.15337592 <a title="371-tfidf-11" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>12 0.15195422 <a title="371-tfidf-12" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>13 0.15026163 <a title="371-tfidf-13" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>14 0.14300765 <a title="371-tfidf-14" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>15 0.14014338 <a title="371-tfidf-15" href="../hunch_net-2011/hunch_net-2011-03-20-KDD_Cup_2011.html">427 hunch net-2011-03-20-KDD Cup 2011</a></p>
<p>16 0.13639243 <a title="371-tfidf-16" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>17 0.13231359 <a title="371-tfidf-17" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>18 0.13128421 <a title="371-tfidf-18" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>19 0.12852216 <a title="371-tfidf-19" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>20 0.12409467 <a title="371-tfidf-20" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.292), (1, 0.092), (2, -0.009), (3, -0.067), (4, -0.19), (5, 0.122), (6, -0.238), (7, 0.009), (8, -0.057), (9, -0.086), (10, -0.106), (11, 0.329), (12, 0.037), (13, 0.049), (14, -0.012), (15, -0.007), (16, 0.038), (17, 0.009), (18, 0.038), (19, -0.009), (20, -0.11), (21, -0.034), (22, 0.028), (23, -0.061), (24, 0.013), (25, -0.12), (26, -0.126), (27, -0.035), (28, 0.04), (29, 0.068), (30, -0.021), (31, -0.105), (32, 0.054), (33, 0.036), (34, 0.024), (35, 0.009), (36, 0.017), (37, -0.035), (38, -0.028), (39, 0.008), (40, -0.082), (41, 0.01), (42, 0.01), (43, 0.083), (44, -0.008), (45, 0.012), (46, -0.057), (47, 0.014), (48, 0.036), (49, -0.005)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96898699 <a title="371-lsi-1" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended the  Netflix prize  ceremony this morning.  The press conference part is  covered fine elsewhere , with the basic outcome being that  BellKor’s Pragmatic Chaos  won over  The Ensemble  by 15-20  minutes , because they were tied in performance on the ultimate holdout set.  I’m sure the individual participants will have many chances to speak about the solution.  One of these is Bell at the  NYAS ML symposium on Nov. 6 .
 
Several additional details may interest ML people.
  
 The degree of overfitting exhibited by the difference in performance on the  leaderboard test set  and the ultimate hold out set was small, but determining at .02 to .03%. 
 A tie was possible, because the rules cut off measurements below the fourth digit based on significance concerns.  In actuality, of course, the scores do differ before rounding, but everyone I spoke to claimed not to know how.  The complete dataset has been  released on UCI , so each team could compute their own score to whatever accu</p><p>2 0.8337065 <a title="371-lsi-2" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: The  Heritage Health Prize  is potentially the largest prediction prize yet at $3M, which is sure to get many people interested.  Several elements of the competition may be worth discussing.
  
 The most straightforward way for HPN to deploy this predictor is in determining who to cover with insurance.  This might easily cover the costs of running the contest itself, but the value to the health system of a whole is minimal, as people not covered still exist.  While HPN itself is a provider network, they have active relationships with a number of insurance companies, and the right to resell any entrant.  It’s worth keeping in mind that the research and development may nevertheless end up being useful in the longer term, especially as entrants also keep the right to their code. 
 The  judging metric  is something I haven’t seen previously.  If a patient has probability 0.5 of being in the hospital 0 days and probability 0.5 of being in the hospital ~53.6 days, the optimal prediction in e</p><p>3 0.79650849 <a title="371-lsi-3" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>Introduction: A $1M qualifying result was achieved on the  public Netflix test set  by a  3-way ensemble team .  This is just in time for  Yehuda ‘s presentation at  KDD , which I’m sure will be one of the best attended ever.  
 
This isn’t quite over—there are a few days for another super-conglomerate team to come together and there is some small chance that the performance is nonrepresentative of the final test set, but I expect not.  
 
Regardless of the final outcome, the biggest lesson for ML from the Netflix contest has been the formidable performance edge of ensemble methods.</p><p>4 0.78657377 <a title="371-lsi-4" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix is  running a contest  to improve recommender prediction systems.   A 10% improvement over their current system yields a $1M prize.  Failing that, the best smaller improvement yields a smaller $50K prize.  This contest looks quite real, and the $50K prize money is almost certainly achievable with a bit of thought.  The contest also comes with a dataset which is apparently 2 orders of magnitude larger than any other public recommendation system datasets.</p><p>5 0.63780975 <a title="371-lsi-5" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>Introduction: There are two prediction competitions currently in the air.  
  
 The  Performance Prediction Challenge   by  Isabelle Guyon .  Good entries minimize a weighted 0/1 loss + the difference between a prediction of this loss and the observed truth on 5 datasets.  Isabelle tells me all of the problems are “real world” and the test datasets are large enough (17K minimum) that the winner should be well determined by ability rather than luck.  This is due March 1. 
 The  Predictive Uncertainty Challenge  by  Gavin Cawley .  Good entries minimize log loss on real valued output variables for one synthetic and 3 “real” datasets related to atmospheric prediction. The use of log loss (which can be infinite and hence is never convergent) and smaller test sets of size 1K to 7K examples makes the winner of this contest more luck dependent.  Nevertheless, the contest may be of some interest particularly to the branch of learning (typically Bayes learning) which prefers to optimize log loss. 
  
May the</p><p>6 0.59219348 <a title="371-lsi-6" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>7 0.58251196 <a title="371-lsi-7" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>8 0.58191955 <a title="371-lsi-8" href="../hunch_net-2011/hunch_net-2011-03-20-KDD_Cup_2011.html">427 hunch net-2011-03-20-KDD Cup 2011</a></p>
<p>9 0.56870377 <a title="371-lsi-9" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>10 0.52575946 <a title="371-lsi-10" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>11 0.49674603 <a title="371-lsi-11" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>12 0.47652665 <a title="371-lsi-12" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>13 0.47106653 <a title="371-lsi-13" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>14 0.46445525 <a title="371-lsi-14" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>15 0.44016811 <a title="371-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>16 0.43882781 <a title="371-lsi-16" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>17 0.43357623 <a title="371-lsi-17" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>18 0.42907482 <a title="371-lsi-18" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>19 0.41538143 <a title="371-lsi-19" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>20 0.40321136 <a title="371-lsi-20" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.019), (16, 0.015), (27, 0.223), (38, 0.04), (39, 0.022), (48, 0.016), (53, 0.06), (55, 0.092), (64, 0.017), (88, 0.203), (92, 0.012), (94, 0.119), (95, 0.078)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96126133 <a title="371-lda-1" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>Introduction: Some of the “sister conference” presentations at  AAAI  have been great.  Roughly speaking, the conference organizers asked other conference organizers to come give a summary of their conference.  Many different AI-related conferences accepted.  The presenters typically discuss some of the background and goals of the conference then mention the results from a few papers they liked.  This is great because it provides a mechanism to get a digested overview of the work of several thousand researchers—something which is simply available nowhere else.
 
Based on these presentations, it looks like there is a significant component of (and opportunity for) applied machine learning in  AIIDE ,  IUI , and  ACL .
 
There was also some discussion of having a super-colocation event similar to  FCRC , but centered on AI & Learning.  This seems like a fine idea.  The field is fractured across so many different conferences that the mixing of a supercolocation seems likely helpful for research.</p><p>2 0.94661355 <a title="371-lda-2" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I’ve enjoyed the  Terminator  movies and show.  Neglecting the whacky aspects (time travel and associated paradoxes), there is an enduring topic of discussion: how do people deal with intelligent machines (and vice versa)?
 
In Terminator-land, the primary method for dealing with intelligent machines is to prevent them from being made.  This approach works pretty badly, because a new angle on building an intelligent machine keeps coming up.  This is partly a ploy for writer’s to avoid writing themselves out of a job, but there is a fundamental truth to it as well: preventing progress in research is hard.
 
The United States, has been experimenting with trying to stop research on  stem cells .  It hasn’t worked very well—the net effect has been retarding research programs a bit, and exporting some research to other countries.  Another less recent example was encryption technology, for which the United States generally did not encourage early public research and even  discouraged as a mu</p><p>3 0.93993086 <a title="371-lda-3" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>Introduction: One of the questions facing machine learning as a field is “Can we produce a generalized learning system that can solve a wide array of standard learning problems?”  The answer is trivial: “yes, just have children”.
 
Of course, that wasn’t really the question.  The refined question is “Are there simple-to-implement generalized learning systems that can solve a wide array of standard learning problems?”  The answer to this is less clear.  The ability of animals (and people ) to learn might be due to megabytes encoded in the DNA.  If this algorithmic complexity is  necessary  to solve machine learning, the field faces a daunting task in replicating it on a computer.
 
This observation suggests a possibility: if you can show that few bits of DNA are needed for learning in animals, then this provides evidence that machine learning (as a field) has a hope of big success with relatively little effort. 
 
It is well known that specific portions of the brain have specific functionality across</p><p>same-blog 4 0.90243888 <a title="371-lda-4" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended the  Netflix prize  ceremony this morning.  The press conference part is  covered fine elsewhere , with the basic outcome being that  BellKor’s Pragmatic Chaos  won over  The Ensemble  by 15-20  minutes , because they were tied in performance on the ultimate holdout set.  I’m sure the individual participants will have many chances to speak about the solution.  One of these is Bell at the  NYAS ML symposium on Nov. 6 .
 
Several additional details may interest ML people.
  
 The degree of overfitting exhibited by the difference in performance on the  leaderboard test set  and the ultimate hold out set was small, but determining at .02 to .03%. 
 A tie was possible, because the rules cut off measurements below the fourth digit based on significance concerns.  In actuality, of course, the scores do differ before rounding, but everyone I spoke to claimed not to know how.  The complete dataset has been  released on UCI , so each team could compute their own score to whatever accu</p><p>5 0.90189141 <a title="371-lda-5" href="../hunch_net-2005/hunch_net-2005-02-04-JMLG.html">13 hunch net-2005-02-04-JMLG</a></p>
<p>Introduction: The  Journal of Machine Learning Gossip  has some fine satire about learning research.  In particular, the  guides  are amusing and remarkably true.
 
As in all things, itâ&euro;&trade;s easy to criticize the way things are and harder to make them better.</p><p>6 0.86904824 <a title="371-lda-6" href="../hunch_net-2012/hunch_net-2012-07-09-Videolectures.html">469 hunch net-2012-07-09-Videolectures</a></p>
<p>7 0.79849356 <a title="371-lda-7" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>8 0.79723889 <a title="371-lda-8" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>9 0.79382706 <a title="371-lda-9" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>10 0.79174638 <a title="371-lda-10" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>11 0.79060191 <a title="371-lda-11" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>12 0.78879666 <a title="371-lda-12" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>13 0.78837842 <a title="371-lda-13" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>14 0.78744614 <a title="371-lda-14" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>15 0.78707451 <a title="371-lda-15" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>16 0.78402501 <a title="371-lda-16" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>17 0.78257531 <a title="371-lda-17" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>18 0.77980196 <a title="371-lda-18" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>19 0.77930492 <a title="371-lda-19" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>20 0.77898973 <a title="371-lda-20" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
