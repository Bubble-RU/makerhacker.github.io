<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>370 hunch net-2009-09-18-Necessary and Sufficient Research</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-370" href="#">hunch_net-2009-370</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>370 hunch net-2009-09-18-Necessary and Sufficient Research</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-370-html" href="http://hunch.net/?p=935">html</a></p><p>Introduction: Researchers are typically confronted with big problems that they have no idea
how to solve. In trying to come up with a solution, a natural approach is to
decompose the big problem into a set of subproblems whose solution yields a
solution to the larger problem. This approach can go wrong in several
ways.Decomposition failure. The solution to the decomposition does not in fact
yield a solution to the overall problem.Artificial hardness. The subproblems
created are sufficient if solved to solve the overall problem, but they are
harder than necessary.As you can see, computational complexity forms a
relatively new (in research-history) razor by which to judge an approach
sufficient but not necessary.In my experience, the artificial hardness problem
is very common. Many researchers abdicate the responsibility of choosing a
problem to work on to other people. This process starts very naturally as a
graduate student, when an incoming student might have relatively little idea
about how to do</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('greater', 0.38), ('necessary', 0.309), ('subgoal', 0.249), ('sufficient', 0.247), ('subgoals', 0.221), ('necessity', 0.213), ('solve', 0.155), ('solution', 0.146), ('goal', 0.138), ('design', 0.138), ('abdicate', 0.124), ('research', 0.113), ('compositional', 0.111), ('problem', 0.104), ('animals', 0.102), ('decompose', 0.097), ('student', 0.096), ('artificial', 0.092), ('hardness', 0.092), ('ability', 0.091)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="370-tfidf-1" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>Introduction: Researchers are typically confronted with big problems that they have no idea
how to solve. In trying to come up with a solution, a natural approach is to
decompose the big problem into a set of subproblems whose solution yields a
solution to the larger problem. This approach can go wrong in several
ways.Decomposition failure. The solution to the decomposition does not in fact
yield a solution to the overall problem.Artificial hardness. The subproblems
created are sufficient if solved to solve the overall problem, but they are
harder than necessary.As you can see, computational complexity forms a
relatively new (in research-history) razor by which to judge an approach
sufficient but not necessary.In my experience, the artificial hardness problem
is very common. Many researchers abdicate the responsibility of choosing a
problem to work on to other people. This process starts very naturally as a
graduate student, when an incoming student might have relatively little idea
about how to do</p><p>2 0.16649503 <a title="370-tfidf-2" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>Introduction: How do you create an optimal environment for research? Here are some essential
ingredients that I see.Stability. University-based research is relatively good
at this. On any particular day, researchers face choices in what they will
work on. A very common tradeoff is between:easy smalldifficult bigFor
researchers without stability, the 'easy small' option wins. This is often
"ok"--a series of incremental improvements on the state of the art can add up
to something very beneficial. However, it misses one of the big potentials of
research: finding entirely new and better ways of doing things.Stability comes
in many forms. The prototypical example is tenure at a university--a tenured
professor is almost imposssible to fire which means that the professor has the
freedom to consider far horizon activities. An iron-clad guarantee of a
paycheck is not necessary--industrial research labs have succeeded well with
research positions of indefinite duration. Atnt research was a great example
of th</p><p>3 0.15958847 <a title="370-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>Introduction: I want to try to describe what doing research means, especially from the point
of view of an undergraduate. The shift from a class-taking mentality to a
research mentality is very significant and not easy.Problem PosingPosing the
right problem is often as important as solving them. Many people can get by in
research by solving problems others have posed, but that's not sufficient for
really inspiring research. For learning in particular, there is a strong
feeling that we just haven't figured out which questions are the right ones to
ask. You can see this, because the answers we have do not seem
convincing.Gambling your lifeWhen you do research, you think very hard about
new ways of solving problems, new problems, and new solutions. Many
conversations are of the form "I wonder what would happen if…" These processes
can be short (days or weeks) or years-long endeavours. The worst part is that
you'll only know if you were succesful at the end of the process (and
sometimes not even then be</p><p>4 0.14177421 <a title="370-tfidf-4" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthuinvited me to the workshop onalgorithms in the field, with the goal of
providing a sense of where near-term research should go. When the time came
though, I bargained for a post instead, which provides a chance for many other
people to comment.There are several things I didn't fully understand when I
went to Yahoo! about 5 years ago. I'd like to repeat them as people in
academia may not yet understand them intuitively.Almost all the big impact
algorithms operate in pseudo-linear or better time. Think about caching,
hashing, sorting, filtering, etcâ&euro;Ś and you have a sense of what some of the
most heavily used algorithms are. This matters quite a bit to Machine Learning
research, because people often work with superlinear time algorithms and
languages. Two very common examples of this are graphical models, where
inference is often a superlinear operation--think about then2dependence on the
number of states in aHidden Markov Modeland KernelizedSupport Vector
Machineswhere optimization</p><p>5 0.13693486 <a title="370-tfidf-5" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>Introduction: Normally, I don't indulge in posters forICML, but this year is naturally an
exception for me. If you want one, there are a small numberleft here, if you
sign up before February.It also seems worthwhile to give some sense of the
scope and reviewing criteria for ICML for authors considering submitting
papers. At ICML, the (very large) program committee does the reviewing which
informs final decisions by area chairs on most papers. Program chairs setup
the process, deal with exceptions or disagreements, and provide advice for the
reviewing process. Providing advice is tricky (and easily misleading) because
a conference is a community, and in the end the aggregate interests of the
community determine the conference. Nevertheless, as a program chair this year
it seems worthwhile to state the overall philosophy I have and what I plan to
encourage (and occasionally discourage).At the highest level, I believe ICML
exists to further research into machine learning, which I generally think of
as</p><p>6 0.13477124 <a title="370-tfidf-6" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>7 0.12805352 <a title="370-tfidf-7" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>8 0.12748197 <a title="370-tfidf-8" href="../hunch_net-2010/hunch_net-2010-09-28-Machined_Learnings.html">412 hunch net-2010-09-28-Machined Learnings</a></p>
<p>9 0.11987065 <a title="370-tfidf-9" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>10 0.11767694 <a title="370-tfidf-10" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>11 0.11523017 <a title="370-tfidf-11" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<p>12 0.11516085 <a title="370-tfidf-12" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>13 0.11410458 <a title="370-tfidf-13" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>14 0.11293519 <a title="370-tfidf-14" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>15 0.11161844 <a title="370-tfidf-15" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>16 0.11122604 <a title="370-tfidf-16" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>17 0.11112511 <a title="370-tfidf-17" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>18 0.1100546 <a title="370-tfidf-18" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>19 0.10855605 <a title="370-tfidf-19" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>20 0.1084669 <a title="370-tfidf-20" href="../hunch_net-2008/hunch_net-2008-07-02-Proprietary_Data_in_Academic_Research%3F.html">306 hunch net-2008-07-02-Proprietary Data in Academic Research?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.297), (1, -0.037), (2, 0.098), (3, -0.132), (4, 0.031), (5, -0.044), (6, -0.028), (7, 0.065), (8, -0.07), (9, 0.062), (10, 0.008), (11, -0.018), (12, 0.082), (13, 0.036), (14, 0.01), (15, 0.034), (16, -0.079), (17, -0.013), (18, 0.055), (19, 0.012), (20, -0.007), (21, 0.036), (22, -0.033), (23, 0.008), (24, 0.014), (25, 0.023), (26, 0.008), (27, -0.085), (28, 0.016), (29, 0.014), (30, 0.002), (31, 0.029), (32, -0.06), (33, 0.045), (34, 0.033), (35, -0.003), (36, 0.029), (37, -0.031), (38, -0.005), (39, -0.056), (40, 0.005), (41, -0.024), (42, 0.096), (43, 0.03), (44, -0.047), (45, 0.007), (46, 0.026), (47, 0.018), (48, -0.098), (49, -0.073)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97446787 <a title="370-lsi-1" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>Introduction: Researchers are typically confronted with big problems that they have no idea
how to solve. In trying to come up with a solution, a natural approach is to
decompose the big problem into a set of subproblems whose solution yields a
solution to the larger problem. This approach can go wrong in several
ways.Decomposition failure. The solution to the decomposition does not in fact
yield a solution to the overall problem.Artificial hardness. The subproblems
created are sufficient if solved to solve the overall problem, but they are
harder than necessary.As you can see, computational complexity forms a
relatively new (in research-history) razor by which to judge an approach
sufficient but not necessary.In my experience, the artificial hardness problem
is very common. Many researchers abdicate the responsibility of choosing a
problem to work on to other people. This process starts very naturally as a
graduate student, when an incoming student might have relatively little idea
about how to do</p><p>2 0.84518659 <a title="370-lsi-2" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>Introduction: There are many ways that interesting research gets done. For example it's
common at a conference for someone to discuss a problem with a partial
solution, and for someone else to know how to solve a piece of it, resulting
in a paper. In some sense, these are the easiest results we can achieve, so we
should ask: Can all research be this easy?The answer is certainly no for
fields where research inherently requires experimentation to discover how the
real world works. However, mathematics, including parts of physics, computer
science, statistics, etcâ&euro;Ś which are effectively mathematics don't require
experimentation. In effect, a paper can be simply a pure expression of
thinking. Can all mathematical-style research be this easy?What's going on
here is research-by-communication. Someone knows something, someone knows
something else, and as soon as someone knows both things, a problem is solved.
The interesting thing about research-by-communication is that it is becoming
radically easier with</p><p>3 0.741557 <a title="370-lsi-3" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthuinvited me to the workshop onalgorithms in the field, with the goal of
providing a sense of where near-term research should go. When the time came
though, I bargained for a post instead, which provides a chance for many other
people to comment.There are several things I didn't fully understand when I
went to Yahoo! about 5 years ago. I'd like to repeat them as people in
academia may not yet understand them intuitively.Almost all the big impact
algorithms operate in pseudo-linear or better time. Think about caching,
hashing, sorting, filtering, etcâ&euro;Ś and you have a sense of what some of the
most heavily used algorithms are. This matters quite a bit to Machine Learning
research, because people often work with superlinear time algorithms and
languages. Two very common examples of this are graphical models, where
inference is often a superlinear operation--think about then2dependence on the
number of states in aHidden Markov Modeland KernelizedSupport Vector
Machineswhere optimization</p><p>4 0.73134673 <a title="370-lsi-4" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>Introduction: Suppose we have a set of observations over timex1,x2,…,xtand want to predict
some future eventyt+1. An inevitable problem arises, because learning a
predictorh(x1,…,xt)ofyt+1is generically intractable due to the size of the
input. To make this problem tractable, what's necessary is a method for
summarizing the relevant information in past observations for the purpose of
prediction in the future. In other words, state is required.Existing
approaches for deriving state have some limitations.Hidden Markov
modelslearned with EM suffer from local minima, use tabular learning
approaches which provide dubious generalization ability, and often require
substantial a.priori specification of the observations.Kalman
FiltersandParticle Filtersare very parametric in the sense that substantial
information must be specified up front.Dynamic Bayesian Networks (graphical
modelsthrough time) require substantial a.priori specification and often
require the solution of difficult computational problems to u</p><p>5 0.72205263 <a title="370-lsi-5" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>Introduction: I want to try to describe what doing research means, especially from the point
of view of an undergraduate. The shift from a class-taking mentality to a
research mentality is very significant and not easy.Problem PosingPosing the
right problem is often as important as solving them. Many people can get by in
research by solving problems others have posed, but that's not sufficient for
really inspiring research. For learning in particular, there is a strong
feeling that we just haven't figured out which questions are the right ones to
ask. You can see this, because the answers we have do not seem
convincing.Gambling your lifeWhen you do research, you think very hard about
new ways of solving problems, new problems, and new solutions. Many
conversations are of the form "I wonder what would happen if…" These processes
can be short (days or weeks) or years-long endeavours. The worst part is that
you'll only know if you were succesful at the end of the process (and
sometimes not even then be</p><p>6 0.6888538 <a title="370-lsi-6" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>7 0.68781674 <a title="370-lsi-7" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>8 0.68420988 <a title="370-lsi-8" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>9 0.68416369 <a title="370-lsi-9" href="../hunch_net-2006/hunch_net-2006-01-08-Debugging_Your_Brain.html">147 hunch net-2006-01-08-Debugging Your Brain</a></p>
<p>10 0.68062758 <a title="370-lsi-10" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<p>11 0.67880028 <a title="370-lsi-11" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>12 0.67400831 <a title="370-lsi-12" href="../hunch_net-2005/hunch_net-2005-05-29-Bad_ideas.html">76 hunch net-2005-05-29-Bad ideas</a></p>
<p>13 0.66824859 <a title="370-lsi-13" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>14 0.66216606 <a title="370-lsi-14" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>15 0.65598935 <a title="370-lsi-15" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>16 0.65594661 <a title="370-lsi-16" href="../hunch_net-2005/hunch_net-2005-07-10-Thinking_the_Unthought.html">91 hunch net-2005-07-10-Thinking the Unthought</a></p>
<p>17 0.64731055 <a title="370-lsi-17" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>18 0.64513373 <a title="370-lsi-18" href="../hunch_net-2008/hunch_net-2008-07-02-Proprietary_Data_in_Academic_Research%3F.html">306 hunch net-2008-07-02-Proprietary Data in Academic Research?</a></p>
<p>19 0.64114416 <a title="370-lsi-19" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>20 0.63832098 <a title="370-lsi-20" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.014), (35, 0.051), (42, 0.332), (45, 0.04), (52, 0.154), (68, 0.1), (69, 0.013), (74, 0.131), (76, 0.018), (95, 0.037), (98, 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96036357 <a title="370-lda-1" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>Introduction: Nic Schaudolphhas been developing a fast gradient descent algorithm
calledStochastic Meta-Descent(SMD).Gradient descent is currently untrendy in
the machine learning community, but there remains a large number of people
using gradient descent on neural networks or other architectures from when it
was trendy in the early 1990s. There are three problems with gradient
descent.Gradient descent does not necessarily produce easily reproduced
results. Typical algorithms start with "set the initial parameters to small
random values".The design of the representation that gradient descent is
applied to is often nontrivial. In particular, knowing exactly how to build a
large neural network so that it will perform well requires knowledge which has
not been made easily applicable.Gradient descent can be slow. Obviously,
taking infinitesimal steps in the direction of the gradient would take
forever, so some finite step size must be used. What exactly this step size
should be is unclear. Many people</p><p>2 0.95686799 <a title="370-lda-2" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>Introduction: There weretwopapersat ICML presenting learning algorithms for acontextual
bandit-style setting, where the loss for all labels is not known, but the loss
for one label is known. (The first might require aexploration
scavengingviewpoint to understand if the experimental assignment was
nonrandom.) I strongly approve of these papers and further work in this
setting and its variants, because I expect it to become more important than
supervised learning. As a quick review, we are thinking about situations where
repeatedly:The world reveals feature values (aka context information).A policy
chooses an action.The world provides a reward.Sometimes this is done in an
online fashion where the policy can change based on immediate feedback and
sometimes it's done in a batch setting where many samples are collected before
the policy can change. If you haven't spent time thinking about the setting,
you might want to because there are many natural applications.I'm going to
pick on the Banditron paper (</p><p>same-blog 3 0.9507913 <a title="370-lda-3" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>Introduction: Researchers are typically confronted with big problems that they have no idea
how to solve. In trying to come up with a solution, a natural approach is to
decompose the big problem into a set of subproblems whose solution yields a
solution to the larger problem. This approach can go wrong in several
ways.Decomposition failure. The solution to the decomposition does not in fact
yield a solution to the overall problem.Artificial hardness. The subproblems
created are sufficient if solved to solve the overall problem, but they are
harder than necessary.As you can see, computational complexity forms a
relatively new (in research-history) razor by which to judge an approach
sufficient but not necessary.In my experience, the artificial hardness problem
is very common. Many researchers abdicate the responsibility of choosing a
problem to work on to other people. This process starts very naturally as a
graduate student, when an incoming student might have relatively little idea
about how to do</p><p>4 0.91283083 <a title="370-lda-4" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>Introduction: Exploration is one of the big unsolved problems in machine learning. This
isn't for lack of trying--there are many models of exploration which have been
analyzed in many different ways by many different groups of people. At some
point, it is worthwhile to sit back and see what has been done across these
many models.Reinforcement Learning(1). Reinforcement learning has
traditionally focused on Markov Decision Processes where the next states'is
given by a conditional distributionP(s'|s,a)given the current statesand
actiona. The typical result here is that certain specific algorithms
controlling an agent can behave withineof optimal for horizonTexcept
forpoly(1/e,T,S,A)"wasted" experiences (with high probability). This started
withE3bySatinder SinghandMichael Kearns.Sham Kakade's thesishas significant
discussion. Extensions have typically been of the form "under extra
assumptions, we can prove more", for exampleFactored-E3andMetric-E3. (It turns
out that the number of wasted samples can b</p><p>5 0.91272455 <a title="370-lda-5" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>Introduction: "Overfitting" is traditionally defined as training some flexible
representation so that it memorizes the data but fails to predict well in the
future. For this post, I will define overfitting more generally as over-
representing the performance of systems. There are two styles of general
overfitting: overrepresenting performance on particular datasets and
(implicitly) overrepresenting performance of a method on future datasets.We
should all be aware of these methods, avoid them where possible, and take them
into account otherwise. I have used "reproblem" and "old datasets", and may
have participated in "overfitting by review"--some of these are very difficult
to avoid.NameMethodExplanationRemedyTraditional overfittingTrain a complex
predictor on too-few examples.Hold out pristine examples for testing.Use a
simpler predictor.Get more training examples.Integrate over many
predictors.Reject papers which do this.Parameter tweak overfittingUse a
learning algorithm with many parameters. Choo</p><p>6 0.90876979 <a title="370-lda-6" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>7 0.90608424 <a title="370-lda-7" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>8 0.90528822 <a title="370-lda-8" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>9 0.90409368 <a title="370-lda-9" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>10 0.90368843 <a title="370-lda-10" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>11 0.9035607 <a title="370-lda-11" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>12 0.90268904 <a title="370-lda-12" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>13 0.90260303 <a title="370-lda-13" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>14 0.90242141 <a title="370-lda-14" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>15 0.90226078 <a title="370-lda-15" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>16 0.90107298 <a title="370-lda-16" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>17 0.90029436 <a title="370-lda-17" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>18 0.89726853 <a title="370-lda-18" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>19 0.89720517 <a title="370-lda-19" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>20 0.89549601 <a title="370-lda-20" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
