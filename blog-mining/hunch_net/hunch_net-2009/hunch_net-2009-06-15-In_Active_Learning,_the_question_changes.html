<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>360 hunch net-2009-06-15-In Active Learning, the question changes</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-360" href="#">hunch_net-2009-360</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>360 hunch net-2009-06-15-In Active Learning, the question changes</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-360-html" href="http://hunch.net/?p=805">html</a></p><p>Introduction: A little over 4 years ago,Sanjoymade a postsaying roughly "we should study
active learning theoretically, because not much is understood".At the time, we
did not understand basic things such as whether or not it was possible to PAC-
learn with an active algorithm without making strong assumptions about the
noise rate. In other words, the fundamental question was "can we do it?"The
nature of the question has fundamentally changed in my mind. The answer is to
the previous question is "yes", both information theoretically and
computationally, most places where supervised learning could be applied.In
many situation, the question has now changed to: "is it worth it?" Is the
programming and computational overhead low enough to make the label cost
savings of active learning worthwhile? Currently, there are situations where
this question could go either way. Much of the challenge for the future is in
figuring out how to make active learning easier or more worthwhile.At
theactive learning tutor</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('active', 0.416), ('supervised', 0.236), ('oracles', 0.215), ('question', 0.189), ('worth', 0.184), ('theoretically', 0.169), ('cost', 0.166), ('changed', 0.157), ('questions', 0.154), ('succeed', 0.153), ('adversarial', 0.145), ('situations', 0.14), ('robust', 0.137), ('fully', 0.127), ('reduction', 0.118), ('efficient', 0.118), ('succeeding', 0.116), ('empirical', 0.112), ('savings', 0.108), ('moved', 0.108)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="360-tfidf-1" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,Sanjoymade a postsaying roughly "we should study
active learning theoretically, because not much is understood".At the time, we
did not understand basic things such as whether or not it was possible to PAC-
learn with an active algorithm without making strong assumptions about the
noise rate. In other words, the fundamental question was "can we do it?"The
nature of the question has fundamentally changed in my mind. The answer is to
the previous question is "yes", both information theoretically and
computationally, most places where supervised learning could be applied.In
many situation, the question has now changed to: "is it worth it?" Is the
programming and computational overhead low enough to make the label cost
savings of active learning worthwhile? Currently, there are situations where
this question could go either way. Much of the challenge for the future is in
figuring out how to make active learning easier or more worthwhile.At
theactive learning tutor</p><p>2 0.36089107 <a title="360-tfidf-2" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.In selective sampling style
active learning, a learning algorithm chooses which examples to label. We now
have an active learning algorithm that is:Efficientin label complexity,
unlabeled complexity, and computational complexity.Competitivewith supervised
learning anywhere that supervised learning works.Compatiblewith online
learning, with any optimization-based learning algorithm, with any loss
function, with offline testing, and even with changing learning
algorithms.Empiricallyeffective.The basic idea is to combinedisagreement
region-based samplingwithimportance weighting: an example is selected to be
labeled with probability proportional to how useful it is for distinguishing
among near-optimal classifiers, and labeled examples are importance-weighted
by the inverse of these probabilities. The combination of these simple ideas
removes thesampling biasproblem that has plagued many previous heuristics for
active learning, and yet leads to</p><p>3 0.28533301 <a title="360-tfidf-3" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>Introduction: Several bits of progress have been made sinceSanjoypointed out the
significantlack of theoretical understanding of active learning. This is an
update on the progress I know of. As a refresher, active learning as meant
here is:There is a source of unlabeled data.There is an oracle from which
labels can be requested for unlabeled data produced by the source.The goal is
to perform well with minimal use of the oracle.Here is what I've
learned:Sanjoy has developed sufficient and semi-necessary conditions for
active learning given the assumptions of IID data and "realizability" (that
one of the classifiers is a correct classifier).Nina,Alina, and I developed an
algorithm for active learning relying on only the assumption of IID data. A
draft ishere.Nicolo,Claudio, andLucashowed that it is possible to do active
learning in an entirely adversarial setting for linear threshold
classifiershere. This was published a year or two ago and I recently learned
about it.All of these results are relative</p><p>4 0.2245484 <a title="360-tfidf-4" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>Introduction: I learned a number of things atNIPS.The financial people were there in greater
force than previously.Two Sigmasponsored NIPS whileDRW Tradinghad a
booth.Theadversarial machine learning workshophad a number of talks about
interesting applications where an adversary really is out to try and mess up
your learning algorithm. This is very different from the situation we often
think of where the world is oblivious to our learning. This may present new
and convincing applications for the learning-against-an-adversary work common
atCOLT.There were several interesing papers.Sanjoy Dasgupta,Daniel Hsu,
andClaire Monteleonihad a paper onGeneral Agnostic Active Learning. The basic
idea is that active learning can be done via reduction to a form of supervised
learning problem. This is great, because we have many supervised learning
algorithms from which the benefits of active learning may be derived.Joseph
BradleyandRobert Schapirehad aPaper on Filterboost. Filterboost is an online
boosting algorit</p><p>5 0.16768393 <a title="360-tfidf-5" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>Introduction: Here are a few papers fromCOLT 2008that I found interesting.Maria-Florina
Balcan,Steve Hanneke, andJenn Wortman,The True Sample Complexity of Active
Learning. This paper shows that in an asymptotic setting, active learning
isalwaysbetter than supervised learning (although the gap may be small). This
is evidence that the only thing in the way of universal active learning is us
knowing how to do it properly.Nir AilonandMehryar Mohri,An Efficient Reduction
of Ranking to Classification. This paper shows how to robustly ranknobjects
withn log(n)classifications using a quicksort based algorithm. The result is
applicable to many ranking loss functions and has implications for
others.Michael KearnsandJennifer Wortman.Learning from Collective Behavior.
This is about learning in a new model, where the goal is to predict how a
collection of interacting agents behave. One claim is that learning in this
setting can be reduced to IID learning.Due to the relation withMetric-E3, I
was particularly int</p><p>6 0.15385604 <a title="360-tfidf-6" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>7 0.14756097 <a title="360-tfidf-7" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>8 0.14465971 <a title="360-tfidf-8" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>9 0.14257137 <a title="360-tfidf-9" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>10 0.13486059 <a title="360-tfidf-10" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>11 0.13471204 <a title="360-tfidf-11" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>12 0.13223957 <a title="360-tfidf-12" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>13 0.12407981 <a title="360-tfidf-13" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>14 0.12105369 <a title="360-tfidf-14" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>15 0.11759809 <a title="360-tfidf-15" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>16 0.11589333 <a title="360-tfidf-16" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>17 0.11320436 <a title="360-tfidf-17" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>18 0.11084855 <a title="360-tfidf-18" href="../hunch_net-2007/hunch_net-2007-07-28-Asking_questions.html">257 hunch net-2007-07-28-Asking questions</a></p>
<p>19 0.10827331 <a title="360-tfidf-19" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>20 0.10635499 <a title="360-tfidf-20" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.255), (1, -0.106), (2, 0.046), (3, 0.007), (4, -0.155), (5, 0.002), (6, 0.13), (7, -0.04), (8, -0.21), (9, -0.091), (10, -0.045), (11, 0.047), (12, 0.205), (13, 0.107), (14, 0.106), (15, -0.104), (16, -0.013), (17, 0.052), (18, 0.045), (19, -0.002), (20, 0.044), (21, 0.121), (22, 0.072), (23, 0.084), (24, 0.109), (25, 0.036), (26, 0.026), (27, 0.02), (28, -0.159), (29, -0.024), (30, -0.012), (31, 0.009), (32, -0.055), (33, 0.065), (34, 0.094), (35, 0.013), (36, -0.144), (37, -0.049), (38, -0.111), (39, 0.026), (40, 0.014), (41, -0.028), (42, -0.083), (43, -0.028), (44, -0.038), (45, 0.031), (46, 0.04), (47, -0.037), (48, -0.007), (49, 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96200424 <a title="360-lsi-1" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,Sanjoymade a postsaying roughly "we should study
active learning theoretically, because not much is understood".At the time, we
did not understand basic things such as whether or not it was possible to PAC-
learn with an active algorithm without making strong assumptions about the
noise rate. In other words, the fundamental question was "can we do it?"The
nature of the question has fundamentally changed in my mind. The answer is to
the previous question is "yes", both information theoretically and
computationally, most places where supervised learning could be applied.In
many situation, the question has now changed to: "is it worth it?" Is the
programming and computational overhead low enough to make the label cost
savings of active learning worthwhile? Currently, there are situations where
this question could go either way. Much of the challenge for the future is in
figuring out how to make active learning easier or more worthwhile.At
theactive learning tutor</p><p>2 0.89522833 <a title="360-lsi-2" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.In selective sampling style
active learning, a learning algorithm chooses which examples to label. We now
have an active learning algorithm that is:Efficientin label complexity,
unlabeled complexity, and computational complexity.Competitivewith supervised
learning anywhere that supervised learning works.Compatiblewith online
learning, with any optimization-based learning algorithm, with any loss
function, with offline testing, and even with changing learning
algorithms.Empiricallyeffective.The basic idea is to combinedisagreement
region-based samplingwithimportance weighting: an example is selected to be
labeled with probability proportional to how useful it is for distinguishing
among near-optimal classifiers, and labeled examples are importance-weighted
by the inverse of these probabilities. The combination of these simple ideas
removes thesampling biasproblem that has plagued many previous heuristics for
active learning, and yet leads to</p><p>3 0.81517142 <a title="360-lsi-3" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>Introduction: Several bits of progress have been made sinceSanjoypointed out the
significantlack of theoretical understanding of active learning. This is an
update on the progress I know of. As a refresher, active learning as meant
here is:There is a source of unlabeled data.There is an oracle from which
labels can be requested for unlabeled data produced by the source.The goal is
to perform well with minimal use of the oracle.Here is what I've
learned:Sanjoy has developed sufficient and semi-necessary conditions for
active learning given the assumptions of IID data and "realizability" (that
one of the classifiers is a correct classifier).Nina,Alina, and I developed an
algorithm for active learning relying on only the assumption of IID data. A
draft ishere.Nicolo,Claudio, andLucashowed that it is possible to do active
learning in an entirely adversarial setting for linear threshold
classifiershere. This was published a year or two ago and I recently learned
about it.All of these results are relative</p><p>4 0.73829061 <a title="360-lsi-4" href="../hunch_net-2009/hunch_net-2009-01-23-An_Active_Learning_Survey.html">338 hunch net-2009-01-23-An Active Learning Survey</a></p>
<p>Introduction: Burr Settleswrote a fairly comprehensivesurvey of active learning. He intends
to maintain and update the survey, so send him any suggestions you have.</p><p>5 0.73498201 <a title="360-lsi-5" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>Introduction: Here are a few papers fromCOLT 2008that I found interesting.Maria-Florina
Balcan,Steve Hanneke, andJenn Wortman,The True Sample Complexity of Active
Learning. This paper shows that in an asymptotic setting, active learning
isalwaysbetter than supervised learning (although the gap may be small). This
is evidence that the only thing in the way of universal active learning is us
knowing how to do it properly.Nir AilonandMehryar Mohri,An Efficient Reduction
of Ranking to Classification. This paper shows how to robustly ranknobjects
withn log(n)classifications using a quicksort based algorithm. The result is
applicable to many ranking loss functions and has implications for
others.Michael KearnsandJennifer Wortman.Learning from Collective Behavior.
This is about learning in a new model, where the goal is to predict how a
collection of interacting agents behave. One claim is that learning in this
setting can be reduced to IID learning.Due to the relation withMetric-E3, I
was particularly int</p><p>6 0.72438085 <a title="360-lsi-6" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>7 0.63678735 <a title="360-lsi-7" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>8 0.63288128 <a title="360-lsi-8" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>9 0.58840281 <a title="360-lsi-9" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>10 0.57288641 <a title="360-lsi-10" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>11 0.57255077 <a title="360-lsi-11" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>12 0.53103262 <a title="360-lsi-12" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>13 0.52290815 <a title="360-lsi-13" href="../hunch_net-2009/hunch_net-2009-04-21-Interesting_Presentations_at_Snowbird.html">349 hunch net-2009-04-21-Interesting Presentations at Snowbird</a></p>
<p>14 0.49175537 <a title="360-lsi-14" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>15 0.49037674 <a title="360-lsi-15" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>16 0.48565498 <a title="360-lsi-16" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>17 0.48276716 <a title="360-lsi-17" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>18 0.47737592 <a title="360-lsi-18" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>19 0.47665009 <a title="360-lsi-19" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>20 0.45868221 <a title="360-lsi-20" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.038), (11, 0.118), (35, 0.042), (42, 0.384), (45, 0.057), (61, 0.022), (69, 0.054), (74, 0.099), (76, 0.014), (88, 0.026), (95, 0.059)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97185922 <a title="360-lda-1" href="../hunch_net-2007/hunch_net-2007-07-28-Asking_questions.html">257 hunch net-2007-07-28-Asking questions</a></p>
<p>Introduction: There are very substantial differences in how question asking is viewed
culturally. For example, all of the following are common:If no one asks a
question, then no one is paying attention.To ask a question is disrespectful
of the speaker.Asking a question is admitting your own ignorance.The first
view seems to be the right one for research, for several reasons.Research is
quite hard--it's difficult to guess how people won't understand something in
advance while preparing a presentation. Consequently, it's very common to lose
people. No worthwhile presenter wants that.Real understanding is precious. By
asking a question, you are really declaring "I want to understand", and
everyone should respect that.Asking a question wakes you up. I don't mean from
"asleep" to "awake" but from "awake" to "really awake". It's easy to drift
through something sort-of-understanding. When you ask a question, especially
because you are on the spot, you will do much better.Some of these effects
might seem mi</p><p>same-blog 2 0.97076768 <a title="360-lda-2" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,Sanjoymade a postsaying roughly "we should study
active learning theoretically, because not much is understood".At the time, we
did not understand basic things such as whether or not it was possible to PAC-
learn with an active algorithm without making strong assumptions about the
noise rate. In other words, the fundamental question was "can we do it?"The
nature of the question has fundamentally changed in my mind. The answer is to
the previous question is "yes", both information theoretically and
computationally, most places where supervised learning could be applied.In
many situation, the question has now changed to: "is it worth it?" Is the
programming and computational overhead low enough to make the label cost
savings of active learning worthwhile? Currently, there are situations where
this question could go either way. Much of the challenge for the future is in
figuring out how to make active learning easier or more worthwhile.At
theactive learning tutor</p><p>3 0.95937848 <a title="360-lda-3" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>Introduction: There are many ways that interesting research gets done. For example it's
common at a conference for someone to discuss a problem with a partial
solution, and for someone else to know how to solve a piece of it, resulting
in a paper. In some sense, these are the easiest results we can achieve, so we
should ask: Can all research be this easy?The answer is certainly no for
fields where research inherently requires experimentation to discover how the
real world works. However, mathematics, including parts of physics, computer
science, statistics, etcâ&euro;Ś which are effectively mathematics don't require
experimentation. In effect, a paper can be simply a pure expression of
thinking. Can all mathematical-style research be this easy?What's going on
here is research-by-communication. Someone knows something, someone knows
something else, and as soon as someone knows both things, a problem is solved.
The interesting thing about research-by-communication is that it is becoming
radically easier with</p><p>4 0.94068807 <a title="360-lda-4" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>Introduction: Despite my best intentions, this is not a fully specified problem, but rather
a research direction.Competitive online learning is one of the more compelling
pieces of learning theory because typical statements of the form "this
algorithm will perform almost as well as a large set of other algorithms" rely
only on fully-observable quantities, and are therefore applicable in many
situations. Examples includeWinnow,Weighted Majority, andBinomial Weighting.
Algorithms with this property haven't taken over the world yet. Here might be
some reasons:Lack of caring. Many people working on learning theory don't care
about particular applications much. This means constants in the algorithm are
not optimized, usable code is often not produced, and empirical studies aren't
done.Inefficiency. Viewed from the perspective of other learning algorithms,
online learning is terribly inefficient. It requires that every hypothesis
(called an expert in the online learning setting) be enumerated and tested o</p><p>5 0.93869668 <a title="360-lda-5" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>Introduction: Consider the contextual bandit setting where, repeatedly:A contextxis
observed.An actionais taken given the contextx.A rewardris observed, dependent
onxanda.Where the goal of a learning agent is to find a policy for step 2
achieving a large expected reward.This setting is of obvious importance,
because in the real world we typically make decisions based on some set of
information and then get feedback only about the single action taken. It also
fundamentally differs from supervised learning settings because knowing the
value of one action is not equivalent to knowing the value of all actions.A
decade ago the best machine learning techniques for this setting where
implausibly inefficient.Dean Fosteronce told me he thought the area was a
research sinkhole with little progress to be expected. Now we are on the verge
of being able to routinely attack these problems, in almost exactly the same
sense that we routinely attack bread and butter supervised learning problems.
Just as for supervis</p><p>6 0.93737149 <a title="360-lda-6" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>7 0.93682313 <a title="360-lda-7" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>8 0.93603444 <a title="360-lda-8" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>9 0.9358083 <a title="360-lda-9" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>10 0.93287796 <a title="360-lda-10" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>11 0.9322449 <a title="360-lda-11" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>12 0.9321081 <a title="360-lda-12" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>13 0.93142188 <a title="360-lda-13" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>14 0.93031472 <a title="360-lda-14" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>15 0.93027496 <a title="360-lda-15" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>16 0.93005735 <a title="360-lda-16" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>17 0.92935997 <a title="360-lda-17" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>18 0.92911482 <a title="360-lda-18" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>19 0.92825031 <a title="360-lda-19" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>20 0.92817825 <a title="360-lda-20" href="../hunch_net-2006/hunch_net-2006-02-11-Yahoo%26%238217%3Bs_Learning_Problems..html">156 hunch net-2006-02-11-Yahoo&#8217;s Learning Problems.</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
