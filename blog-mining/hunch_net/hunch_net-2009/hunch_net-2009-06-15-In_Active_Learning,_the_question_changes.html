<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>360 hunch net-2009-06-15-In Active Learning, the question changes</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-360" href="#">hunch_net-2009-360</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>360 hunch net-2009-06-15-In Active Learning, the question changes</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-360-html" href="http://hunch.net/?p=805">html</a></p><p>Introduction: A little over 4 years ago,  Sanjoy   made a post  saying roughly “we should  study active learning theoretically, because not much is understood”.   
 
At the time, we did not understand basic things such as whether or not it was possible to PAC-learn with an active algorithm without making strong assumptions about the noise rate.  In other words, the fundamental question was “can we do it?”
 
The nature of the question has fundamentally changed in my mind.   The answer is to the previous question is “yes”, both information theoretically and computationally, most places where supervised learning could be applied.  
 
In many situation, the question has now changed to: “is it worth it?”  Is the programming and computational overhead low enough to make the label cost savings of active learning worthwhile?  Currently, there are situations where this question could go either way.  Much of the challenge for the future is in figuring out how to make active learning easier or more worthwhile.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A little over 4 years ago,  Sanjoy   made a post  saying roughly “we should  study active learning theoretically, because not much is understood”. [sent-1, score-0.671]
</p><p>2 At the time, we did not understand basic things such as whether or not it was possible to PAC-learn with an active algorithm without making strong assumptions about the noise rate. [sent-2, score-0.576]
</p><p>3 ”   The nature of the question has fundamentally changed in my mind. [sent-4, score-0.328]
</p><p>4 The answer is to the previous question is “yes”, both information theoretically and computationally, most places where supervised learning could be applied. [sent-5, score-0.744]
</p><p>5 In many situation, the question has now changed to: “is it worth it? [sent-6, score-0.508]
</p><p>6 ”  Is the programming and computational overhead low enough to make the label cost savings of active learning worthwhile? [sent-7, score-0.865]
</p><p>7 Currently, there are situations where this question could go either way. [sent-8, score-0.402]
</p><p>8 Much of the challenge for the future is in figuring out how to make active learning easier or more worthwhile. [sent-9, score-0.599]
</p><p>9 At the  active learning tutorial , I stated a set of somewhat more precise research questions that I don’t yet have answer to, and which I believe are worth answering. [sent-10, score-1.003]
</p><p>10 Is active learning possible in a fully adversarial setting? [sent-12, score-0.85]
</p><p>11 By fully adversarial, I mean when an adversary controls all the algorithms observations. [sent-13, score-0.369]
</p><p>12 Is there an efficient and effective reduction of active learning to supervised learning? [sent-15, score-1.071]
</p><p>13 The  bootstrap IWAL  approach is efficient but not effective in some situations where other approaches can succeed. [sent-16, score-0.54]
</p><p>14 The  algorithm  here  is a reduction to a special kind of supervised learning where you can specify both examples and constraints. [sent-17, score-0.575]
</p><p>15 For many supervised learning algorithms, adding constraints seems problematic. [sent-18, score-0.392]
</p><p>16 Can active learning succeed with alternate labeling oracles? [sent-19, score-0.842]
</p><p>17 The ones I see people trying to use in practice often differ because they can provide answers of varying specificity and cost, or because some oracles are good for some questions, but not good for others. [sent-20, score-0.427]
</p><p>18 At this point, there have been several successful applications of active learning, but that’s not the same thing as succeeding with more robust algorithms. [sent-21, score-0.748]
</p><p>19 Can we succeed empirically with more robust algorithms? [sent-22, score-0.281]
</p><p>20 And is the empirical cost of additional robustness worth the empirical peace-of-mind that your learning algorithm won’t go astray where other more aggressive approaches may do so? [sent-23, score-0.975]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('active', 0.43), ('supervised', 0.229), ('oracles', 0.199), ('worth', 0.18), ('question', 0.178), ('theoretically', 0.166), ('cost', 0.156), ('changed', 0.15), ('succeed', 0.15), ('questions', 0.149), ('adversarial', 0.137), ('situations', 0.137), ('robust', 0.131), ('fully', 0.125), ('reduction', 0.11), ('empirical', 0.11), ('efficient', 0.11), ('succeeding', 0.106), ('savings', 0.106), ('moved', 0.106), ('effective', 0.104), ('nicolo', 0.1), ('bootstrap', 0.1), ('alternate', 0.095), ('claudio', 0.095), ('controls', 0.091), ('solid', 0.091), ('approaches', 0.089), ('learning', 0.088), ('go', 0.087), ('overhead', 0.085), ('answer', 0.083), ('saying', 0.083), ('varying', 0.083), ('figuring', 0.081), ('successful', 0.081), ('robustness', 0.079), ('labeling', 0.079), ('algorithms', 0.078), ('algorithm', 0.076), ('sanjoy', 0.075), ('adding', 0.075), ('adversary', 0.075), ('differ', 0.074), ('yet', 0.073), ('special', 0.072), ('answers', 0.071), ('possible', 0.07), ('study', 0.07), ('worthwhile', 0.07)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="360-tfidf-1" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,  Sanjoy   made a post  saying roughly “we should  study active learning theoretically, because not much is understood”.   
 
At the time, we did not understand basic things such as whether or not it was possible to PAC-learn with an active algorithm without making strong assumptions about the noise rate.  In other words, the fundamental question was “can we do it?”
 
The nature of the question has fundamentally changed in my mind.   The answer is to the previous question is “yes”, both information theoretically and computationally, most places where supervised learning could be applied.  
 
In many situation, the question has now changed to: “is it worth it?”  Is the programming and computational overhead low enough to make the label cost savings of active learning worthwhile?  Currently, there are situations where this question could go either way.  Much of the challenge for the future is in figuring out how to make active learning easier or more worthwhile.</p><p>2 0.36828837 <a title="360-tfidf-2" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.
 
In selective sampling style active learning, a learning algorithm chooses which examples to label.  We now have an active learning algorithm that is:
  
  Efficient  in label complexity, unlabeled complexity, and computational complexity. 
  Competitive  with supervised learning anywhere that supervised learning works. 
  Compatible  with online learning, with any optimization-based learning algorithm, with any loss function, with offline testing, and even with changing learning algorithms. 
  Empirically  effective. 
  
The basic idea is to combine  disagreement region-based sampling  with  importance weighting : an example is selected to be labeled with probability proportional to how useful it is for distinguishing among near-optimal classifiers, and labeled examples are importance-weighted by the inverse of these probabilities.  The combination of these simple ideas removes the  sampling bias  problem that has plagued many previous he</p><p>3 0.30489388 <a title="360-tfidf-3" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>Introduction: Several bits of progress have been made since  Sanjoy  pointed out the significant  lack of theoretical understanding of active learning .  This is an update on the progress I know of.  As a refresher, active learning as meant here is:
  
 There is a source of unlabeled data. 
 There is an oracle from which labels can be requested for unlabeled data produced by the source. 
 The goal is to perform well with minimal use of the oracle. 
  
Here is what I’ve learned:
  
 Sanjoy has developed sufficient and semi-necessary conditions for active learning given the assumptions of IID data and “realizability” (that one of the classifiers is a correct classifier). 
  Nina ,  Alina , and I developed an algorithm for active learning relying on only the assumption of IID data.  A draft is  here . 
  Nicolo ,  Claudio , and  Luca  showed that it is possible to do active learning in an entirely adversarial setting for linear threshold classifiers  here .  This was published a year or two ago and I r</p><p>4 0.19508386 <a title="360-tfidf-4" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>Introduction: I learned a number of things at  NIPS .
  
 The financial people were there in greater force than previously.   Two Sigma  sponsored NIPS while  DRW Trading  had a booth. 
 The  adversarial machine learning workshop  had a number of talks about interesting applications where an adversary really is out to try and mess up your learning algorithm.  This is very different from the situation we often think of where the world is oblivious to our learning.  This may present new and convincing applications for the learning-against-an-adversary work common at  COLT . 
 There were several interesing papers.
 
  Sanjoy Dasgupta ,  Daniel Hsu , and  Claire Monteleoni  had a paper on  General Agnostic Active Learning .  The basic idea is that active learning can be done via reduction to a form of supervised learning problem.  This is great, because we have many supervised learning algorithms from which the benefits of active learning may be derived. 
  Joseph Bradley  and  Robert Schapire  had a  P</p><p>5 0.16934831 <a title="360-tfidf-5" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>Introduction: A new direction of research seems to be arising in machine learning: Interactive Machine Learning.  This isn’t a familiar term, although it does include some familiar subjects.
 
 What is Interactive Machine Learning?   The fundamental requirement is (a) learning algorithms which interact with the world and (b) learn.  
 
For our purposes, let’s define learning as efficiently competing with a large set of possible predictors.  Examples include:
  
 Online learning against an adversary ( Avrim’s Notes ).  The interaction is almost trivial: the learning algorithm makes a prediction and then receives feedback. The learning is choosing based upon the advice of many experts. 
   Active Learning  .  In active learning, the interaction is choosing which examples to label, and the learning is choosing from amongst a large set of hypotheses. 
   Contextual Bandits  .  The interaction is choosing one of several actions and learning only the value of the chosen action (weaker than active learning</p><p>6 0.14019001 <a title="360-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>7 0.13958345 <a title="360-tfidf-7" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>8 0.13342255 <a title="360-tfidf-8" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>9 0.13230559 <a title="360-tfidf-9" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>10 0.13092586 <a title="360-tfidf-10" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>11 0.13039866 <a title="360-tfidf-11" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>12 0.12976898 <a title="360-tfidf-12" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>13 0.12842715 <a title="360-tfidf-13" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>14 0.12779605 <a title="360-tfidf-14" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>15 0.12483842 <a title="360-tfidf-15" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>16 0.1213557 <a title="360-tfidf-16" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>17 0.11953881 <a title="360-tfidf-17" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>18 0.1180876 <a title="360-tfidf-18" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>19 0.11616437 <a title="360-tfidf-19" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>20 0.10774988 <a title="360-tfidf-20" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.253), (1, 0.101), (2, -0.05), (3, -0.01), (4, 0.15), (5, -0.044), (6, 0.002), (7, -0.034), (8, 0.015), (9, 0.118), (10, 0.194), (11, -0.024), (12, -0.051), (13, 0.216), (14, -0.191), (15, 0.018), (16, -0.01), (17, 0.022), (18, -0.062), (19, 0.009), (20, -0.024), (21, 0.063), (22, 0.135), (23, -0.047), (24, 0.033), (25, -0.23), (26, 0.077), (27, -0.025), (28, 0.017), (29, 0.0), (30, 0.108), (31, 0.035), (32, 0.005), (33, -0.039), (34, 0.018), (35, 0.019), (36, -0.005), (37, -0.05), (38, -0.073), (39, 0.088), (40, 0.006), (41, -0.108), (42, -0.063), (43, -0.047), (44, 0.018), (45, -0.002), (46, 0.095), (47, -0.037), (48, -0.023), (49, 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97012073 <a title="360-lsi-1" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,  Sanjoy   made a post  saying roughly “we should  study active learning theoretically, because not much is understood”.   
 
At the time, we did not understand basic things such as whether or not it was possible to PAC-learn with an active algorithm without making strong assumptions about the noise rate.  In other words, the fundamental question was “can we do it?”
 
The nature of the question has fundamentally changed in my mind.   The answer is to the previous question is “yes”, both information theoretically and computationally, most places where supervised learning could be applied.  
 
In many situation, the question has now changed to: “is it worth it?”  Is the programming and computational overhead low enough to make the label cost savings of active learning worthwhile?  Currently, there are situations where this question could go either way.  Much of the challenge for the future is in figuring out how to make active learning easier or more worthwhile.</p><p>2 0.90009862 <a title="360-lsi-2" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.
 
In selective sampling style active learning, a learning algorithm chooses which examples to label.  We now have an active learning algorithm that is:
  
  Efficient  in label complexity, unlabeled complexity, and computational complexity. 
  Competitive  with supervised learning anywhere that supervised learning works. 
  Compatible  with online learning, with any optimization-based learning algorithm, with any loss function, with offline testing, and even with changing learning algorithms. 
  Empirically  effective. 
  
The basic idea is to combine  disagreement region-based sampling  with  importance weighting : an example is selected to be labeled with probability proportional to how useful it is for distinguishing among near-optimal classifiers, and labeled examples are importance-weighted by the inverse of these probabilities.  The combination of these simple ideas removes the  sampling bias  problem that has plagued many previous he</p><p>3 0.84360266 <a title="360-lsi-3" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>Introduction: Several bits of progress have been made since  Sanjoy  pointed out the significant  lack of theoretical understanding of active learning .  This is an update on the progress I know of.  As a refresher, active learning as meant here is:
  
 There is a source of unlabeled data. 
 There is an oracle from which labels can be requested for unlabeled data produced by the source. 
 The goal is to perform well with minimal use of the oracle. 
  
Here is what I’ve learned:
  
 Sanjoy has developed sufficient and semi-necessary conditions for active learning given the assumptions of IID data and “realizability” (that one of the classifiers is a correct classifier). 
  Nina ,  Alina , and I developed an algorithm for active learning relying on only the assumption of IID data.  A draft is  here . 
  Nicolo ,  Claudio , and  Luca  showed that it is possible to do active learning in an entirely adversarial setting for linear threshold classifiers  here .  This was published a year or two ago and I r</p><p>4 0.73069507 <a title="360-lsi-4" href="../hunch_net-2009/hunch_net-2009-01-23-An_Active_Learning_Survey.html">338 hunch net-2009-01-23-An Active Learning Survey</a></p>
<p>Introduction: Burr Settles  wrote a fairly comprehensive  survey of active learning .  He intends to maintain and update the survey, so send him any suggestions you have.</p><p>5 0.69374698 <a title="360-lsi-5" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>Introduction: A new direction of research seems to be arising in machine learning: Interactive Machine Learning.  This isn’t a familiar term, although it does include some familiar subjects.
 
 What is Interactive Machine Learning?   The fundamental requirement is (a) learning algorithms which interact with the world and (b) learn.  
 
For our purposes, let’s define learning as efficiently competing with a large set of possible predictors.  Examples include:
  
 Online learning against an adversary ( Avrim’s Notes ).  The interaction is almost trivial: the learning algorithm makes a prediction and then receives feedback. The learning is choosing based upon the advice of many experts. 
   Active Learning  .  In active learning, the interaction is choosing which examples to label, and the learning is choosing from amongst a large set of hypotheses. 
   Contextual Bandits  .  The interaction is choosing one of several actions and learning only the value of the chosen action (weaker than active learning</p><p>6 0.68911827 <a title="360-lsi-6" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>7 0.6632024 <a title="360-lsi-7" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>8 0.63139623 <a title="360-lsi-8" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>9 0.62177938 <a title="360-lsi-9" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>10 0.60774577 <a title="360-lsi-10" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>11 0.57973647 <a title="360-lsi-11" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>12 0.57965142 <a title="360-lsi-12" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>13 0.54382104 <a title="360-lsi-13" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>14 0.53485501 <a title="360-lsi-14" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>15 0.49027687 <a title="360-lsi-15" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>16 0.48141646 <a title="360-lsi-16" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>17 0.48095065 <a title="360-lsi-17" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>18 0.47777477 <a title="360-lsi-18" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>19 0.47557172 <a title="360-lsi-19" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>20 0.4730598 <a title="360-lsi-20" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.043), (10, 0.037), (15, 0.103), (27, 0.28), (38, 0.059), (53, 0.058), (55, 0.097), (64, 0.021), (94, 0.1), (95, 0.115)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95538187 <a title="360-lda-1" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,  Sanjoy   made a post  saying roughly “we should  study active learning theoretically, because not much is understood”.   
 
At the time, we did not understand basic things such as whether or not it was possible to PAC-learn with an active algorithm without making strong assumptions about the noise rate.  In other words, the fundamental question was “can we do it?”
 
The nature of the question has fundamentally changed in my mind.   The answer is to the previous question is “yes”, both information theoretically and computationally, most places where supervised learning could be applied.  
 
In many situation, the question has now changed to: “is it worth it?”  Is the programming and computational overhead low enough to make the label cost savings of active learning worthwhile?  Currently, there are situations where this question could go either way.  Much of the challenge for the future is in figuring out how to make active learning easier or more worthwhile.</p><p>2 0.92881894 <a title="360-lda-2" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but sometimes the unfairness seems particularly striking.  This is most easily seen by comparison:
  
 
 Paper 
  Banditron  
  Offset Tree  
 Notes 
 
 
 Problem Scope 
 Multiclass problems where only the loss of one choice can be probed. 
 Strictly greater: Cost sensitive multiclass problems where only the loss of one choice can be probed. 
 Often generalizations don’t matter.  That’s not the case here, since every plausible application I’ve thought of involves loss functions substantially different from 0/1. 
 
 
 What’s new 
 Analysis and Experiments 
 Algorithm, Analysis, and Experiments 
  As far as I know, the essence of the more general problem was first stated and analyzed with the  EXP4 algorithm (page 16)  (1998).  It’s also the time horizon 1 simplification of the Reinforcement Learning setting for the  random trajectory method (page 15)  (2002).  The Banditron algorithm itself is functionally identi</p><p>3 0.92648685 <a title="360-lda-3" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>Introduction: How do you create an optimal environment for research?  Here are some essential ingredients that I see.  
  
  Stability .  University-based research is relatively good at this.  On any particular day, researchers face choices in what they will work on.  A very common tradeoff is between:
 
 easy small 
 difficult big 
 

For researchers without stability, the ‘easy small’ option wins.  This is often “ok”—a series of incremental improvements on the state of the art can add up to something very beneficial.  However, it misses one of the big potentials of research: finding entirely new and better ways of doing things.


Stability comes in many forms.  The prototypical example is tenure at a university—a tenured professor is almost imposssible to fire which means that the professor has the freedom to consider far horizon activities.  An iron-clad guarantee of a paycheck is not necessary—industrial research labs have succeeded well with research positions of indefinite duration.  Atnt rese</p><p>4 0.92322189 <a title="360-lda-4" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>Introduction: The funding of research (and machine learning research) is an issue which seems to have become more significant in the United States over the last decade.  The word “research” is applied broadly here to science, mathematics, and engineering.
 
There are two essential difficulties with funding research:
  
  Longshot  Paying a researcher is often a big gamble.  Most research projects don’t pan out, but a few big payoffs can make it all worthwhile. 
  Information Only  Much of research is about finding the right way to think about or do something.  
  
The Longshot difficulty means that there is high variance in payoffs.  This can be compensated for by funding many different research projects, reducing variance.
 
The Information-Only difficulty means that it’s hard to extract a profit directly from many types of research, so companies have difficulty justifying basic research.  (Patents are a mechanism for doing this.  They are often extraordinarily clumsy or simply not applicable.)
 
T</p><p>5 0.91749138 <a title="360-lda-5" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given framework or mathematical model.  It turns out that all of these models are significantly flawed for the purpose of studying machine learning.  I’ve created a table (below) outlining the major flaws in some common models of machine learning.
 
The point here is not simply “woe unto us”.  There are several implications which seem important.
  
 The multitude of models is a point of continuing confusion.  It is common for people to learn about machine learning within one framework which often becomes there “home framework” through which they attempt to filter all machine learning.  (Have you met people who can only think in terms of kernels?  Only via Bayes Law? Only via PAC Learning?)  Explicitly understanding the existence of these other frameworks can help resolve the confusion.  This is particularly important when reviewing and particularly important for students. 
 Algorithms which conform to multiple approaches c</p><p>6 0.91635358 <a title="360-lda-6" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>7 0.91609025 <a title="360-lda-7" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>8 0.91474438 <a title="360-lda-8" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>9 0.91437918 <a title="360-lda-9" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>10 0.91362375 <a title="360-lda-10" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>11 0.91031325 <a title="360-lda-11" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>12 0.90900457 <a title="360-lda-12" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>13 0.90819567 <a title="360-lda-13" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>14 0.9070704 <a title="360-lda-14" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>15 0.9066515 <a title="360-lda-15" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>16 0.9066084 <a title="360-lda-16" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>17 0.90613049 <a title="360-lda-17" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>18 0.90288293 <a title="360-lda-18" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>19 0.90258443 <a title="360-lda-19" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>20 0.90222239 <a title="360-lda-20" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
