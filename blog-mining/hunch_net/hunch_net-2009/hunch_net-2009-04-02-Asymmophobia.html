<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>348 hunch net-2009-04-02-Asymmophobia</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-348" href="#">hunch_net-2009-348</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>348 hunch net-2009-04-02-Asymmophobia</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-348-html" href="http://hunch.net/?p=632">html</a></p><p>Introduction: One striking feature of many machine learning algorithms is the gymnastics
that designers go through to avoid symmetry breaking. In the most basic form
of machine learning, there are labeled examples composed of features. Each of
these can be treated symmetrically or asymmetrically by algorithms.feature
symmetryEvery feature is treated the same. In gradient update rules, the same
update is applied whether the feature is first or last. In metric-based
predictions, every feature is just as important in computing the
distance.example symmetryEvery example is treated the same. Batch learning
algorithms are great exemplars of this approach.label symmetryEvery label is
treated the same. This is particularly noticeable in multiclass classification
systems which predict according toarg maxlwlxbut it occurs in many other
places as well.Empirically, breaking symmetry well seems to yield great
algorithms.feature asymmetryFor those who like the "boosting is stepwise
additive regression on exponent</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 One striking feature of many machine learning algorithms is the gymnastics that designers go through to avoid symmetry breaking. [sent-1, score-0.972]
</p><p>2 Each of these can be treated symmetrically or asymmetrically by algorithms. [sent-3, score-0.181]
</p><p>3 In gradient update rules, the same update is applied whether the feature is first or last. [sent-5, score-0.207]
</p><p>4 feature asymmetryFor those who like the "boosting is stepwise additive regression on exponential loss" viewpoint (I don't entirely), boosting is an example of symmetry breaking on features. [sent-12, score-1.557]
</p><p>5 label asymmetryTree structured algorithms are good instances of example asymmetry. [sent-15, score-0.117]
</p><p>6 These approaches are exponentially faster in the number of labels than more symmetric approaches. [sent-18, score-0.291]
</p><p>7 The examples above are notably important, with good symmetry breaking approaches yielding substantially improved prediction or computational performance. [sent-19, score-1.41]
</p><p>8 Given such strong evidence that symmetry breaking is a desirable property, a basic question is: Why isn't it more prevalent, and more thoroughly studied? [sent-20, score-1.237]
</p><p>9 One reasonable answer is that doing symmetry breaking well requires more serious thought about learning algorithm design, so researchers simply haven't gotten to it. [sent-21, score-1.349]
</p><p>10 A more complete answer is that many researchers seem to reflexively avoid symmetry breaking. [sent-23, score-0.788]
</p><p>11 A simple reason for this is the now pervasive use ofMatlabin machine learning. [sent-24, score-0.139]
</p><p>12 Matlab is a handy tool for fast prototyping of learning algorithms, but it has an intrinsic language-level bias towards symmetric approaches since there are builtin primitives for matrix operations. [sent-25, score-0.332]
</p><p>13 A more complex reason is a pervasive reflex belief in fairness. [sent-26, score-0.139]
</p><p>14 A third related reason seems to be a fear of doing unmotivated things. [sent-28, score-0.156]
</p><p>15 Anytime symmetry breaking is undertaken, the method for symmetry breaking is in question, and many people feel uncomfortable without a theorem suggesting the method is the right one. [sent-29, score-2.478]
</p><p>16 Since there are few theorems motivating symmetry breaking methods, it is often avoided. [sent-30, score-1.241]
</p><p>17 Arbitrary symmetry breaking is something like random, except there is no randomness--you simply declare this feature/label/example comes first and that one second. [sent-37, score-1.287]
</p><p>18 Boosting is a good example where a data-driven approach drives symmetry breaking (over features). [sent-40, score-1.335]
</p><p>19 Data-driven approaches for symmetry breaking seem the most sound, as they can result in improved performance. [sent-41, score-1.35]
</p><p>20 While there are examples of learning algorithms doing symmetry breaking for features, labels, and examples individually, there aren't any I know which do all three, well. [sent-42, score-1.386]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('symmetry', 0.642), ('breaking', 0.556), ('treated', 0.181), ('symmetryevery', 0.165), ('symmetric', 0.098), ('approaches', 0.097), ('boosting', 0.091), ('feature', 0.085), ('pervasive', 0.078), ('algorithms', 0.068), ('update', 0.061), ('reason', 0.061), ('examples', 0.06), ('entirely', 0.056), ('labels', 0.055), ('improved', 0.055), ('answer', 0.054), ('seems', 0.05), ('example', 0.049), ('builtin', 0.049), ('gotten', 0.049), ('initialize', 0.049), ('gymnastics', 0.049), ('additive', 0.049), ('admirable', 0.049), ('declare', 0.049), ('prototyping', 0.049), ('researchers', 0.048), ('composed', 0.045), ('designers', 0.045), ('stepwise', 0.045), ('mildly', 0.045), ('unmotivated', 0.045), ('introduces', 0.045), ('approach', 0.045), ('avoid', 0.044), ('anytime', 0.043), ('drives', 0.043), ('motivating', 0.043), ('suggesting', 0.043), ('features', 0.043), ('exponentially', 0.041), ('like', 0.04), ('primitives', 0.039), ('thoroughly', 0.039), ('randomization', 0.039), ('uncomfortable', 0.039), ('striking', 0.039), ('individually', 0.039), ('prevalent', 0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999964 <a title="348-tfidf-1" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>Introduction: One striking feature of many machine learning algorithms is the gymnastics
that designers go through to avoid symmetry breaking. In the most basic form
of machine learning, there are labeled examples composed of features. Each of
these can be treated symmetrically or asymmetrically by algorithms.feature
symmetryEvery feature is treated the same. In gradient update rules, the same
update is applied whether the feature is first or last. In metric-based
predictions, every feature is just as important in computing the
distance.example symmetryEvery example is treated the same. Batch learning
algorithms are great exemplars of this approach.label symmetryEvery label is
treated the same. This is particularly noticeable in multiclass classification
systems which predict according toarg maxlwlxbut it occurs in many other
places as well.Empirically, breaking symmetry well seems to yield great
algorithms.feature asymmetryFor those who like the "boosting is stepwise
additive regression on exponent</p><p>2 0.12081188 <a title="348-tfidf-2" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<p>Introduction: There are a number of learning algorithms which explicitly incorporate
randomness into their execution. This includes at amongst others:Neural
Networks. Neural networks use randomization to assign initial
weights.Boltzmann Machines/Deep Belief Networks. Boltzmann machines are
something like a stochastic version of multinode logistic regression. The use
of randomness is more essential in Boltzmann machines, because the predicted
value at test time also uses randomness.Bagging. Bagging is a process where a
learning algorithm is run several different times on several different
datasets, creating a final predictor which makes a majority vote.Policy
descent. Several algorithms in reinforcement learning such asConservative
Policy Iterationuse random bits to create stochastic policies.Experts
algorithms. Randomized weighted majority use random bits as a part of the
prediction process to achieve better theoretical guarantees.A basic question
is: "Should there be explicit randomization in learn</p><p>3 0.11257152 <a title="348-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-09-Intuitions_from_applied_learning.html">16 hunch net-2005-02-09-Intuitions from applied learning</a></p>
<p>Introduction: Since learning is far from an exact science, it's good to pay attention to
basic intuitions of applied learning. Here are a few I've
collected.IntegrationIn Bayesian learning, the posterior is computed by an
integral, and the optimal thing to do is to predict according to this
integral. This phenomena seems to be far more general. Bagging, Boosting,
SVMs, and Neural Networks all take advantage of this idea to some extent. The
phenomena is more general: you can average over many differentclassification
predictorsto improve performance.
Sources:Zoubin,CaruanaDifferentiationDifferent pieces of an average should
differentiate to achieve good performance by different methods. This is know
as the 'symmetry breaking' problem for neural networks, and it's why weights
are initialized randomly. Boosting explicitly attempts to achieve good
differentiation by creating new, different, learning problems. Sources:Yann
LeCun,Phil LongDeep RepresentationHaving a deep representation is necessary
for hav</p><p>4 0.10318358 <a title="348-tfidf-4" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provostgave a talk at the ICMLmetalearning workshopon "metalearning"
and the "no free lunch theorem" which seems worth summarizing.As a review: the
no free lunch theorem is the most complicated way we know of to say that
abiasis required in order to learn. The simplest way to see this is in a
nonprobabilistic setting. If you are given examples of the form(x,y)and you
wish to predictyfromxthen any prediction mechanism errs half the time in
expectation over all sequences of examples. The proof of this is very simple:
on every example a predictor must make some prediction and by symmetry over
the set of sequences it will be wrong half the time and right half the time.
The basic idea of this proof has been applied to many other settings.The
simplistic interpretation of this theorem which many people jump to is
"machine learning is dead" since there can be no single learning algorithm
which can solve all learning problems. This is the wrong way to think about
it. In the real world, w</p><p>5 0.093519665 <a title="348-tfidf-5" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>Introduction: Machine learning has a new kind of "scaling to larger problems" to worry
about: scaling with the amount of contextual information. The standard
development path for a machine learning application in practice seems to be
the following:Marginal. In the beginning, there was "majority vote". At this
stage, it isn't necessary to understand that you have a prediction problem.
People just realize that one answer is right sometimes and another answer
other times. In machine learning terms, this corresponds to making a
prediction without side information.First context. A clever person realizes
that some bit of informationx1could be helpful. Ifx1is discrete, they
condition on it and make a predictorh(x1), typically by counting. If they are
clever, then they also do some smoothing. Ifx1is some real valued parameter,
it's very common to make a threshold cutoff. Often, these tasks are simply
done by hand.Second. Another clever person (or perhaps the same one) realizes
that some other bit of informa</p><p>6 0.076313287 <a title="348-tfidf-6" href="../hunch_net-2006/hunch_net-2006-05-16-The_value_of_the_orthodox_view_of_Boosting.html">179 hunch net-2006-05-16-The value of the orthodox view of Boosting</a></p>
<p>7 0.075562119 <a title="348-tfidf-7" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>8 0.074875377 <a title="348-tfidf-8" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>9 0.074775018 <a title="348-tfidf-9" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>10 0.070254937 <a title="348-tfidf-10" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>11 0.068416305 <a title="348-tfidf-11" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>12 0.065300852 <a title="348-tfidf-12" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>13 0.064766608 <a title="348-tfidf-13" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>14 0.063037887 <a title="348-tfidf-14" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>15 0.062892765 <a title="348-tfidf-15" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>16 0.06255576 <a title="348-tfidf-16" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>17 0.060843267 <a title="348-tfidf-17" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>18 0.060749859 <a title="348-tfidf-18" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>19 0.059745446 <a title="348-tfidf-19" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>20 0.059717953 <a title="348-tfidf-20" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.152), (1, -0.067), (2, -0.0), (3, 0.0), (4, -0.018), (5, 0.042), (6, -0.018), (7, 0.023), (8, 0.002), (9, 0.031), (10, 0.04), (11, -0.004), (12, -0.018), (13, -0.008), (14, -0.037), (15, -0.028), (16, -0.051), (17, 0.045), (18, -0.019), (19, -0.038), (20, 0.017), (21, 0.031), (22, 0.0), (23, 0.007), (24, 0.016), (25, -0.018), (26, 0.01), (27, -0.021), (28, -0.008), (29, -0.038), (30, -0.002), (31, -0.007), (32, -0.056), (33, -0.002), (34, 0.049), (35, -0.06), (36, 0.018), (37, 0.024), (38, -0.074), (39, 0.031), (40, -0.045), (41, -0.034), (42, 0.013), (43, 0.054), (44, -0.021), (45, -0.053), (46, 0.024), (47, -0.019), (48, 0.053), (49, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.90468735 <a title="348-lsi-1" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>Introduction: One striking feature of many machine learning algorithms is the gymnastics
that designers go through to avoid symmetry breaking. In the most basic form
of machine learning, there are labeled examples composed of features. Each of
these can be treated symmetrically or asymmetrically by algorithms.feature
symmetryEvery feature is treated the same. In gradient update rules, the same
update is applied whether the feature is first or last. In metric-based
predictions, every feature is just as important in computing the
distance.example symmetryEvery example is treated the same. Batch learning
algorithms are great exemplars of this approach.label symmetryEvery label is
treated the same. This is particularly noticeable in multiclass classification
systems which predict according toarg maxlwlxbut it occurs in many other
places as well.Empirically, breaking symmetry well seems to yield great
algorithms.feature asymmetryFor those who like the "boosting is stepwise
additive regression on exponent</p><p>2 0.74783748 <a title="348-lsi-2" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>Introduction: One way to distinguish different learning algorithms is by their ability or
inability to easily use an input variable as the predicted output. This is
desirable for at least two reasons:ModularityIf we want to build complex
learning systems via reuse of a subsystem, it's important to have compatible
I/O."Prior" knowledgeMachine learning is often applied in situations where we
do have some knowledge of what the right solution is, often in the form of an
existing system. In such situations, it's good to start with a learning
algorithm that can be at least as good as any existing system.When doing
classification, most learning algorithms can do this. For example, a decision
tree can split on a feature, and then classify. The real differences come up
when we attempt regression. Many of the algorithms we know and commonly use
are not idempotent predictors.Logistic regressors can not be idempotent,
because all input features are mapped through a nonlinearity.Linear regressors
can be idempote</p><p>3 0.6705265 <a title="348-lsi-3" href="../hunch_net-2006/hunch_net-2006-05-16-The_value_of_the_orthodox_view_of_Boosting.html">179 hunch net-2006-05-16-The value of the orthodox view of Boosting</a></p>
<p>Introduction: The term "boosting" comes from the idea of using a meta-algorithm which takes
"weak" learners (that may be able to only barely predict slightly better than
random) and turn them into strongly capable learners (which predict very
well).Adaboostin 1995 was the first widely used (and useful) boosting
algorithm, although there were theoretical boosting algorithms floating around
since 1990 (see the bottom ofthis page).Since then, many different
interpretations of why boosting works have arisen. There is significant
discussion about these different views in theannals of statistics, including
aresponsebyYoav FreundandRobert Schapire.I believe there is a great deal of
value to be found in the original view of boosting (meta-algorithm for
creating a strong learner from a weak learner). This is not a claim that one
particular viewpoint obviates the value of all others, but rather that no
other viewpoint seems to really capture important properties.Comparing with
all other views of boosting is t</p><p>4 0.65707374 <a title="348-lsi-4" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>Introduction: Multitask learning is the problem of jointly predicting multiple labels
simultaneously with one system. A basic question iswhether or not multitask
learning can be decomposed into one (or more) single prediction problems. It
seems the answer to this is "yes", in a fairly straightforward manner.The
basic idea is that a controlled input feature is equivalent to an extra
output. Suppose we have some process generating examples:(x,y1,y2) in
Swherey1andy2are labels for two different tasks. Then, we could reprocess the
data to the formSb(S) = {((x,i),yi): (x,y1,y2) in S, i in {1,2}}and then learn
a classifierc:X x {1,2} -> Y. Note that(x,i)is the (composite) input. At
testing time, given an inputx, we can querycfor the predicted values of y1and
y2using(x,1)and(x,2).A strong form of equivalence can be stated between these
tasks. In particular, suppose we have a multitask learning algorithmMLwhich
learns a multitask predictorm:X -> Y x Y. Then the following theorem can be
proved:For allMLfor a</p><p>5 0.65496773 <a title="348-lsi-5" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>Introduction: Multitask learning is the learning to predict multiple outputs given the same
input. Mathematically, we might think of this as trying to learn a functionf:X
-> {0,1}n. Structured learning is similar at this level of abstraction. Many
people have worked on solving multitask learning (for exampleRich Caruana)
using methods which share an internal representation. On other words, the the
computation and learning of theith prediction is shared with the computation
and learning of thejth prediction. Another way to ask this question is: can we
avoid sharing the internal representation?For example, itmightbe feasible to
solve multitask learning by some process feeding theith predictionf(x)iinto
thejth predictorf(x,f(x)i)j,If the answer is "no", then it implies we can not
take binary classification as a basic primitive in the process of solving
prediction problems. If the answer is "yes", then we can reuse binary
classification algorithms to solve multitask learning problems.Finding a
satisfyin</p><p>6 0.63665193 <a title="348-lsi-6" href="../hunch_net-2005/hunch_net-2005-02-09-Intuitions_from_applied_learning.html">16 hunch net-2005-02-09-Intuitions from applied learning</a></p>
<p>7 0.61316806 <a title="348-lsi-7" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>8 0.61230981 <a title="348-lsi-8" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<p>9 0.59455138 <a title="348-lsi-9" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>10 0.59280127 <a title="348-lsi-10" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>11 0.58804023 <a title="348-lsi-11" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>12 0.58556914 <a title="348-lsi-12" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>13 0.58454239 <a title="348-lsi-13" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>14 0.57536113 <a title="348-lsi-14" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>15 0.56937569 <a title="348-lsi-15" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>16 0.56400323 <a title="348-lsi-16" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>17 0.55110437 <a title="348-lsi-17" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>18 0.54679525 <a title="348-lsi-18" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>19 0.54118717 <a title="348-lsi-19" href="../hunch_net-2007/hunch_net-2007-07-28-Asking_questions.html">257 hunch net-2007-07-28-Asking questions</a></p>
<p>20 0.53959256 <a title="348-lsi-20" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(29, 0.013), (35, 0.063), (42, 0.255), (45, 0.034), (63, 0.01), (68, 0.05), (69, 0.037), (74, 0.082), (81, 0.011), (95, 0.027), (99, 0.275)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.91628766 <a title="348-lda-1" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and toprevent
overfitting. Various notion of "function complexity" oftenarise: VC dimension,
Rademacher complexity, comparison classes ofexperts, and program length are
just a few.The term "complexity" to me seems somehow misleading; the terms
nevercapture something that meets my intuitive notion of complexity.
TheBayesian notion clearly captures what's going on. Functions
aren't"complex"- they're just "surprising": we assign to them lowprobability.
Most (all?) complexity notions I know boil downto some (generally loose) bound
on the prior probability of the function.In a sense, "complexity"
fundementally arises because probabilitydistributions must sum to one. You
can't believe in all possibilitiesat the same time, or at least not equally.
Rather you have tocarefully spread the probability mass over the options you'd
like toconsider. Large complexity classes means that beliefs are spreadthinly.
In it's simplest form, this phenom</p><p>2 0.87465179 <a title="348-lda-2" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>Introduction: I have had interesting discussions about distinction between static vs.
dynamic classes withKishoreandHal.The distinction arises in multiclass
prediction settings. A static set of classes is given by a set of
labels{1,â&euro;Ś,k}and the goal is generally to choose the most likely label given
features. The static approach is the one that we typically analyze and think
about in machine learning.The dynamic setting is one that is often used in
practice. The basic idea is that the number of classes is not fixed, varying
on a per example basis. These different classes are generally defined by a
choice of features.The distinction between these two settings as far as theory
goes, appears to be very substantial. For example, in the static setting,
inlearning reductions land, we have techniques now for robustO(log(k))time
prediction in many multiclass setting variants. In the dynamic setting, the
best techniques known areO(k), and furthermore this exponential gap may be
essential, at least without fur</p><p>same-blog 3 0.87412137 <a title="348-lda-3" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>Introduction: One striking feature of many machine learning algorithms is the gymnastics
that designers go through to avoid symmetry breaking. In the most basic form
of machine learning, there are labeled examples composed of features. Each of
these can be treated symmetrically or asymmetrically by algorithms.feature
symmetryEvery feature is treated the same. In gradient update rules, the same
update is applied whether the feature is first or last. In metric-based
predictions, every feature is just as important in computing the
distance.example symmetryEvery example is treated the same. Batch learning
algorithms are great exemplars of this approach.label symmetryEvery label is
treated the same. This is particularly noticeable in multiclass classification
systems which predict according toarg maxlwlxbut it occurs in many other
places as well.Empirically, breaking symmetry well seems to yield great
algorithms.feature asymmetryFor those who like the "boosting is stepwise
additive regression on exponent</p><p>4 0.70777994 <a title="348-lda-4" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>Introduction: "Overfitting" is traditionally defined as training some flexible
representation so that it memorizes the data but fails to predict well in the
future. For this post, I will define overfitting more generally as over-
representing the performance of systems. There are two styles of general
overfitting: overrepresenting performance on particular datasets and
(implicitly) overrepresenting performance of a method on future datasets.We
should all be aware of these methods, avoid them where possible, and take them
into account otherwise. I have used "reproblem" and "old datasets", and may
have participated in "overfitting by review"--some of these are very difficult
to avoid.NameMethodExplanationRemedyTraditional overfittingTrain a complex
predictor on too-few examples.Hold out pristine examples for testing.Use a
simpler predictor.Get more training examples.Integrate over many
predictors.Reject papers which do this.Parameter tweak overfittingUse a
learning algorithm with many parameters. Choo</p><p>5 0.70718724 <a title="348-lda-5" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>Introduction: Suppose you have a dataset with 2 terafeatures (we only count nonzero entries
in a datamatrix), and want to learn a good linear predictor in a reasonable
amount of time. How do you do it? As a learning theorist, the first thing you
do is pray that this is too much data for the number of parameters--but that's
not the case, there are around 16 billion examples, 16 million parameters, and
people really care about a high quality predictor, so subsampling is not a
good strategy.Alekhvisited us last summer, and we had a breakthrough
(seeherefor details), coming up with the first learning algorithm I've seen
that is provably faster thanany futuresingle machine learning algorithm. The
proof of this is simple: We can output a optimal-up-to-precision linear
predictor faster than the data can be streamed through the network interface
of any single machine involved in the computation.It is necessary but not
sufficient to have an effective communication infrastructure. It is necessary
but not suff</p><p>6 0.70566559 <a title="348-lda-6" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>7 0.70525885 <a title="348-lda-7" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>8 0.70524311 <a title="348-lda-8" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>9 0.7041772 <a title="348-lda-9" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>10 0.70315236 <a title="348-lda-10" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>11 0.7026841 <a title="348-lda-11" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>12 0.7026751 <a title="348-lda-12" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>13 0.7016573 <a title="348-lda-13" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>14 0.70164162 <a title="348-lda-14" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>15 0.70088863 <a title="348-lda-15" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>16 0.70051384 <a title="348-lda-16" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>17 0.6990546 <a title="348-lda-17" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>18 0.69845355 <a title="348-lda-18" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>19 0.69839287 <a title="348-lda-19" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>20 0.69834691 <a title="348-lda-20" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
