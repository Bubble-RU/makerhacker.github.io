<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>340 hunch net-2009-01-28-Nielsen&#8217;s talk</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-340" href="#">hunch_net-2009-340</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>340 hunch net-2009-01-28-Nielsen&#8217;s talk</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-340-html" href="http://hunch.net/?p=545">html</a></p><p>Introduction: I wanted to point to   Michael Nielsenâ&euro;&trade;s talk  about blogging science, which I found interesting.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I wanted to point to   Michael Nielsenâ&euro;&trade;s talk  about blogging science, which I found interesting. [sent-1, score-1.467]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nielsen', 0.547), ('blogging', 0.547), ('wanted', 0.318), ('michael', 0.313), ('talk', 0.238), ('science', 0.231), ('found', 0.201), ('point', 0.163), ('interesting', 0.161)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="340-tfidf-1" href="../hunch_net-2009/hunch_net-2009-01-28-Nielsen%26%238217%3Bs_talk.html">340 hunch net-2009-01-28-Nielsen&#8217;s talk</a></p>
<p>Introduction: I wanted to point to   Michael Nielsenâ&euro;&trade;s talk  about blogging science, which I found interesting.</p><p>2 0.30598086 <a title="340-tfidf-2" href="../hunch_net-2005/hunch_net-2005-09-06-A_link.html">108 hunch net-2005-09-06-A link</a></p>
<p>Introduction: I read through some of the essays of  Michael Nielsen  today, and recommend them.   Principles of Effective Research  and  Extreme Thinking  are both relevant to several discussions here.</p><p>3 0.089465827 <a title="340-tfidf-3" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>Introduction: A big part of doing research is imagining how things could be different, and then trying to figure out how to get there.  
 
A big part of science fiction is imagining how things could be different, and then working through the implications.  
 
Because of the similarity here, reading science fiction can sometimes be helpful in understanding and doing research.  (And, hey, it’s fun.)  Here’s some list of science fiction books I enjoyed which seem particularly relevant to computer science and (sometimes) learning systems:
  
 Vernor Vinge, “True Names”, “A Fire Upon the Deep” 
 Marc Stiegler, “David’s Sling”, “Earthweb” 
 Charles Stross, “Singularity Sky” 
 Greg Egan, “Diaspora” 
 Joe Haldeman, “Forever Peace” 
  
(There are surely many others.)  
 
Incidentally, the nature of science fiction itself has changed.  Decades ago, science fiction projected great increases in the power humans control (example: E.E. Smith Lensman series).  That didn’t really happen in the last 50 years.  Inste</p><p>4 0.081264623 <a title="340-tfidf-4" href="../hunch_net-2007/hunch_net-2007-07-12-ICML_Trends.html">254 hunch net-2007-07-12-ICML Trends</a></p>
<p>Introduction: Mark Reid  did a post on  ICML trends  that I found interesting.</p><p>5 0.0784183 <a title="340-tfidf-5" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>Introduction: Here are a few papers from  COLT 2008  that I found interesting.
  
  Maria-Florina Balcan ,  Steve Hanneke , and  Jenn Wortman ,  The True Sample Complexity of Active Learning .  This paper shows that in an asymptotic setting, active learning is  always  better than supervised learning (although the gap may be small).  This is evidence that the only thing in the way of universal active learning is us knowing how to do it properly. 
  Nir Ailon  and  Mehryar Mohri ,  An Efficient Reduction of Ranking to Classification .  This paper shows how to robustly rank  n  objects with  n log(n)  classifications using a quicksort based algorithm.  The result is applicable to many ranking loss functions and has implications for others. 
  Michael Kearns  and  Jennifer Wortman .  Learning from Collective Behavior .  This is about learning in a new model, where the goal is to predict how a collection of interacting agents behave.  One claim is that learning in this setting can be reduced to IID lear</p><p>6 0.075053237 <a title="340-tfidf-6" href="../hunch_net-2012/hunch_net-2012-12-29-Simons_Institute_Big_Data_Program.html">476 hunch net-2012-12-29-Simons Institute Big Data Program</a></p>
<p>7 0.072572485 <a title="340-tfidf-7" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>8 0.066307798 <a title="340-tfidf-8" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>9 0.059998631 <a title="340-tfidf-9" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>10 0.054528255 <a title="340-tfidf-10" href="../hunch_net-2008/hunch_net-2008-04-21-The_Science_2.0_article.html">296 hunch net-2008-04-21-The Science 2.0 article</a></p>
<p>11 0.053739119 <a title="340-tfidf-11" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>12 0.053429507 <a title="340-tfidf-12" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>13 0.053334702 <a title="340-tfidf-13" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>14 0.047946706 <a title="340-tfidf-14" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>15 0.043461725 <a title="340-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-10-Conferences%2C_Dates%2C_Locations.html">17 hunch net-2005-02-10-Conferences, Dates, Locations</a></p>
<p>16 0.042314634 <a title="340-tfidf-16" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>17 0.041989781 <a title="340-tfidf-17" href="../hunch_net-2007/hunch_net-2007-10-14-NIPS_workshp%3A_Learning_Problem_Design.html">265 hunch net-2007-10-14-NIPS workshp: Learning Problem Design</a></p>
<p>18 0.040430248 <a title="340-tfidf-18" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>19 0.040408123 <a title="340-tfidf-19" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>20 0.039228745 <a title="340-tfidf-20" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.051), (1, -0.024), (2, -0.033), (3, 0.014), (4, 0.007), (5, 0.02), (6, 0.007), (7, -0.016), (8, 0.0), (9, -0.016), (10, 0.052), (11, 0.006), (12, -0.09), (13, -0.048), (14, 0.018), (15, -0.079), (16, -0.058), (17, 0.093), (18, 0.029), (19, 0.03), (20, -0.034), (21, -0.032), (22, -0.047), (23, 0.018), (24, -0.002), (25, -0.096), (26, -0.003), (27, 0.013), (28, 0.008), (29, -0.001), (30, -0.11), (31, 0.05), (32, -0.026), (33, -0.052), (34, 0.038), (35, 0.07), (36, -0.117), (37, 0.078), (38, -0.047), (39, -0.05), (40, 0.039), (41, 0.18), (42, -0.016), (43, 0.095), (44, 0.092), (45, 0.099), (46, 0.026), (47, -0.035), (48, 0.053), (49, 0.067)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98966426 <a title="340-lsi-1" href="../hunch_net-2009/hunch_net-2009-01-28-Nielsen%26%238217%3Bs_talk.html">340 hunch net-2009-01-28-Nielsen&#8217;s talk</a></p>
<p>Introduction: I wanted to point to   Michael Nielsenâ&euro;&trade;s talk  about blogging science, which I found interesting.</p><p>2 0.74219579 <a title="340-lsi-2" href="../hunch_net-2005/hunch_net-2005-09-06-A_link.html">108 hunch net-2005-09-06-A link</a></p>
<p>Introduction: I read through some of the essays of  Michael Nielsen  today, and recommend them.   Principles of Effective Research  and  Extreme Thinking  are both relevant to several discussions here.</p><p>3 0.5318169 <a title="340-lsi-3" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>Introduction: A big part of doing research is imagining how things could be different, and then trying to figure out how to get there.  
 
A big part of science fiction is imagining how things could be different, and then working through the implications.  
 
Because of the similarity here, reading science fiction can sometimes be helpful in understanding and doing research.  (And, hey, it’s fun.)  Here’s some list of science fiction books I enjoyed which seem particularly relevant to computer science and (sometimes) learning systems:
  
 Vernor Vinge, “True Names”, “A Fire Upon the Deep” 
 Marc Stiegler, “David’s Sling”, “Earthweb” 
 Charles Stross, “Singularity Sky” 
 Greg Egan, “Diaspora” 
 Joe Haldeman, “Forever Peace” 
  
(There are surely many others.)  
 
Incidentally, the nature of science fiction itself has changed.  Decades ago, science fiction projected great increases in the power humans control (example: E.E. Smith Lensman series).  That didn’t really happen in the last 50 years.  Inste</p><p>4 0.45479208 <a title="340-lsi-4" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>Introduction: I’ve avoided discussing politics here, although not for lack of interest.  The problem with discussing politics is that it’s customary for people to say much based upon little information.  Nevertheless, politics can have a substantial impact on science (and we might hope for the vice-versa).  It’s primary election time in the United States, so the topic is timely, although the issues are not.
 
There are several policy decisions which substantially effect development of science and technology in the US.
  
  Education  The US has great contrasts in education.  The top universities are very good places, yet the grade school education system produces mediocre results.  For me, the contrast between a  public education  and  Caltech  was bracing.  For many others attending Caltech, it clearly was not.  Upgrading the k-12 education system in the US is a long-standing chronic problem which I know relatively little about.  My own experience is that a basic attitude of “no child unrealized” i</p><p>5 0.40273938 <a title="340-lsi-5" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>Introduction: I only managed to make it out to the NIPS workshops this year so 
I’ll give my comments on what I saw there.  
 
The Learing and Robotics workshops lives again. I hope it 
continues and gets more high quality papers in the future. The 
most interesting talk for me was Larry Jackel’s on the LAGR 
program (see John’s previous post on said program). I got some 
ideas as to what progress has been made. Larry really explained 
the types of benchmarks and the tradeoffs that had to be made to 
make the goals achievable but challenging. 
 
Hal Daume gave a very interesting talk about structured 
prediction using RL techniques, something near and dear to my own 
heart. He achieved rather impressive results using only a very 
greedy search.
 
The non-parametric Bayes workshop was great. I enjoyed the entire 
morning session I spent there, and particularly (the usually 
desultory) discussion periods. One interesting topic was the 
Gibbs/Variational inference divide. I won’t try to summarize 
espe</p><p>6 0.38258246 <a title="340-lsi-6" href="../hunch_net-2008/hunch_net-2008-04-21-The_Science_2.0_article.html">296 hunch net-2008-04-21-The Science 2.0 article</a></p>
<p>7 0.37696451 <a title="340-lsi-7" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>8 0.37360567 <a title="340-lsi-8" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>9 0.36347461 <a title="340-lsi-9" href="../hunch_net-2013/hunch_net-2013-07-24-ICML_2012_videos_lost.html">487 hunch net-2013-07-24-ICML 2012 videos lost</a></p>
<p>10 0.34379774 <a title="340-lsi-10" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>11 0.34072289 <a title="340-lsi-11" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>12 0.33259374 <a title="340-lsi-12" href="../hunch_net-2007/hunch_net-2007-10-14-NIPS_workshp%3A_Learning_Problem_Design.html">265 hunch net-2007-10-14-NIPS workshp: Learning Problem Design</a></p>
<p>13 0.31367338 <a title="340-lsi-13" href="../hunch_net-2007/hunch_net-2007-07-12-ICML_Trends.html">254 hunch net-2007-07-12-ICML Trends</a></p>
<p>14 0.30593613 <a title="340-lsi-14" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>15 0.30423242 <a title="340-lsi-15" href="../hunch_net-2008/hunch_net-2008-07-02-Proprietary_Data_in_Academic_Research%3F.html">306 hunch net-2008-07-02-Proprietary Data in Academic Research?</a></p>
<p>16 0.29538 <a title="340-lsi-16" href="../hunch_net-2010/hunch_net-2010-09-21-Regretting_the_dead.html">411 hunch net-2010-09-21-Regretting the dead</a></p>
<p>17 0.29270023 <a title="340-lsi-17" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>18 0.28184295 <a title="340-lsi-18" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>19 0.27855292 <a title="340-lsi-19" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>20 0.2683447 <a title="340-lsi-20" href="../hunch_net-2005/hunch_net-2005-07-01-The_Role_of_Impromptu_Talks.html">88 hunch net-2005-07-01-The Role of Impromptu Talks</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(90, 0.734)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.92294157 <a title="340-lda-1" href="../hunch_net-2008/hunch_net-2008-11-04-Rise_of_the_Machines.html">323 hunch net-2008-11-04-Rise of the Machines</a></p>
<p>Introduction: On the  enduring topic of how people deal with intelligent machines , we have this important  election bulletin .</p><p>same-blog 2 0.89859974 <a title="340-lda-2" href="../hunch_net-2009/hunch_net-2009-01-28-Nielsen%26%238217%3Bs_talk.html">340 hunch net-2009-01-28-Nielsen&#8217;s talk</a></p>
<p>Introduction: I wanted to point to   Michael Nielsenâ&euro;&trade;s talk  about blogging science, which I found interesting.</p><p>3 0.78501713 <a title="340-lda-3" href="../hunch_net-2008/hunch_net-2008-01-18-Datasets.html">284 hunch net-2008-01-18-Datasets</a></p>
<p>Introduction: David Pennock  notes the impressive  set of datasets  at  datawrangling .</p><p>4 0.7049492 <a title="340-lda-4" href="../hunch_net-2005/hunch_net-2005-02-27-Antilearning%3A_When_proximity_goes_bad.html">32 hunch net-2005-02-27-Antilearning: When proximity goes bad</a></p>
<p>Introduction: Joel Predd   mentioned  “ Antilearning ” by  Adam Kowalczyk , which is interesting from a foundational intuitions viewpoint.
 
There is a pervasive intuition that “nearby things tend to have the same label”.  This intuition is instantiated in SVMs, nearest neighbor classifiers, decision trees, and neural networks.  It turns out there are natural problems where this intuition is opposite of the truth.
 
One natural situation where this occurs is in competition.   For example, when  Intel  fails to meet its earnings estimate, is this evidence that  AMD  is doing badly also?  Or evidence that AMD is doing well?
 
This violation of the proximity intuition means that when the number of examples is few,  negating  a classifier which attempts to exploit proximity can provide predictive power (thus, the term “antilearning”).</p><p>5 0.68387479 <a title="340-lda-5" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the company  Spock  is setting up a  $50k entity resolution challenge .  $50k is much less than the Netflix challenge, but it’s effectively the same as Netflix until  someone reaches 10% .  It’s also nice that the Spock challenge has a short duration.  The (visible) test set is of size 25k and the training set has size 75k.</p><p>6 0.52578551 <a title="340-lda-6" href="../hunch_net-2005/hunch_net-2005-12-11-More_NIPS_Papers.html">139 hunch net-2005-12-11-More NIPS Papers</a></p>
<p>7 0.48276007 <a title="340-lda-7" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>8 0.28467268 <a title="340-lda-8" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>9 0.037052784 <a title="340-lda-9" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>10 0.032866511 <a title="340-lda-10" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>11 0.024599608 <a title="340-lda-11" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>12 0.0 <a title="340-lda-12" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<p>13 0.0 <a title="340-lda-13" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>14 0.0 <a title="340-lda-14" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>15 0.0 <a title="340-lda-15" href="../hunch_net-2005/hunch_net-2005-01-26-Summer_Schools.html">4 hunch net-2005-01-26-Summer Schools</a></p>
<p>16 0.0 <a title="340-lda-16" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>17 0.0 <a title="340-lda-17" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>18 0.0 <a title="340-lda-18" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>19 0.0 <a title="340-lda-19" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>20 0.0 <a title="340-lda-20" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
