<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>351 hunch net-2009-05-02-Wielding a New Abstraction</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-351" href="#">hunch_net-2009-351</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>351 hunch net-2009-05-02-Wielding a New Abstraction</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-351-html" href="http://hunch.net/?p=501">html</a></p><p>Introduction: This post is partly meant as an advertisement for the  reductions tutorial   Alina ,  Bianca , and I are planning to do at  ICML .  Please come, if you are interested.
 
Many research programs can be thought of as finding and building new useful abstractions.  The running example I’ll use is  learning reductions  where I have experience.  The basic abstraction here is that we can build a learning algorithm capable of solving classification problems up to a small expected regret.   This is used repeatedly to solve more complex problems.
 
In working on a new abstraction, I think you typically run into many substantial problems of understanding, which make publishing particularly difficult.
  
 It is difficult to seriously discuss the reason behind or mechanism for abstraction in a conference paper with small page limits.  People rarely see such discussions and hence have little basis on which to think about new abstractions.    Another difficulty is that when building an abstraction, yo</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The basic abstraction here is that we can build a learning algorithm capable of solving classification problems up to a small expected regret. [sent-5, score-0.692]
</p><p>2 It is difficult to seriously discuss the reason behind or mechanism for abstraction in a conference paper with small page limits. [sent-8, score-0.598]
</p><p>3 Here’s my current attempt: The process of abstraction for learning reductions can start with sample complexity bounds (or online learning against an adversary analysis). [sent-11, score-0.812]
</p><p>4 The impact of this complexity is that it is difficult to effectively use these bounds in practical learning algorithm design, particularly in solving more complex learning problems where much more than one bit of prediction is required. [sent-15, score-0.532]
</p><p>5 The abstraction in the learning reduction setting is:     You throw away  d , because it only has a logarithmic dependence anyways. [sent-18, score-0.747]
</p><p>6 This abstraction is radical in some sense, but something radical was needed to yield tractable and useful analysis on the complex problems people need to solve in practice. [sent-21, score-1.07]
</p><p>7 Once you get past the lack of familiarity and misunderstandings, there is a feeling that the new abstraction is cheating. [sent-26, score-0.723]
</p><p>8 The TCP abstraction is broken when the network is too unreliable for it to recover, such as on sketchy wireless networks where the programmer built for the TCP abstraction which wasn’t delivered. [sent-35, score-1.143]
</p><p>9 The basic idea is to just look at the units when estimating some quantity and combine them to get the right unit answer. [sent-37, score-0.276]
</p><p>10 For example, to compute the distance  d  traveled after time  t  with acceleration  a , you simply use  at 2  , since that formula is the only way to combine  a  with units of  distance/time 2   and  t  with units of  time  to get units of  distance . [sent-38, score-0.802]
</p><p>11 This property that abstractions can be abused is generically essential to the process of abstraction itself. [sent-45, score-0.815]
</p><p>12 Abstraction is about neglecting details, and when these details are not neglectable, the abstraction is abused or ineffective. [sent-46, score-0.75]
</p><p>13 Because of this, any abstraction is insufficient for analyzing and solving real problems where the neglected details matter. [sent-47, score-0.757]
</p><p>14 A good abstraction can capture a more complete specification of the problem. [sent-53, score-0.534]
</p><p>15 As an example, the sample complexity view of learning is broken in practice, because when insufficient performance is achieved people choose a different set of hypotheses  H  by throwing in additional features or choosing a different learning algorithm. [sent-54, score-0.368]
</p><p>16 A higher level abstraction can let you accidentally solve problems in other areas as well. [sent-59, score-0.682]
</p><p>17 Perhaps the most interesting effect is that the new abstraction can aid you in finding effective solutions to new problems. [sent-63, score-0.731]
</p><p>18 Given training-time access to a good policy oracle,  Searn  provides a method for decomposing   any  complex prediction problem into simple problems, such that low regret solutions to the simple problems imply a low regret solution to the original problem. [sent-65, score-0.451]
</p><p>19 More generally, when I learn about the details of other complex prediction systems for machine translation or vision, the base algorithms are tweaked, typically in ways that Searn would suggest. [sent-69, score-0.293]
</p><p>20 Furthermore, they are composable by design, so they should stay relevant (and perhaps even become more so), when people use an online active deep semisupervised probabilistic convolutional algorithm to solve a problem, particularly for complex problems. [sent-86, score-0.348]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('abstraction', 0.534), ('tcp', 0.211), ('units', 0.15), ('abused', 0.15), ('complex', 0.146), ('searn', 0.133), ('abstractions', 0.131), ('reduction', 0.126), ('reductions', 0.105), ('analysis', 0.102), ('logarithmic', 0.087), ('complexity', 0.087), ('sample', 0.086), ('breakages', 0.085), ('pathetic', 0.085), ('problems', 0.082), ('iid', 0.081), ('prediction', 0.081), ('distance', 0.078), ('solutions', 0.077), ('algorithm', 0.076), ('insufficient', 0.075), ('unreliable', 0.075), ('example', 0.072), ('bianca', 0.07), ('radical', 0.07), ('tournament', 0.07), ('eps', 0.07), ('hiding', 0.07), ('time', 0.068), ('details', 0.066), ('feeling', 0.066), ('constants', 0.066), ('elimination', 0.066), ('unit', 0.066), ('tournaments', 0.066), ('architecting', 0.066), ('solve', 0.066), ('provides', 0.065), ('compelling', 0.064), ('mechanism', 0.064), ('familiarity', 0.063), ('used', 0.061), ('particularly', 0.06), ('view', 0.06), ('combine', 0.06), ('hypotheses', 0.06), ('new', 0.06), ('thesis', 0.058), ('eliminate', 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000006 <a title="351-tfidf-1" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for the  reductions tutorial   Alina ,  Bianca , and I are planning to do at  ICML .  Please come, if you are interested.
 
Many research programs can be thought of as finding and building new useful abstractions.  The running example I’ll use is  learning reductions  where I have experience.  The basic abstraction here is that we can build a learning algorithm capable of solving classification problems up to a small expected regret.   This is used repeatedly to solve more complex problems.
 
In working on a new abstraction, I think you typically run into many substantial problems of understanding, which make publishing particularly difficult.
  
 It is difficult to seriously discuss the reason behind or mechanism for abstraction in a conference paper with small page limits.  People rarely see such discussions and hence have little basis on which to think about new abstractions.    Another difficulty is that when building an abstraction, yo</p><p>2 0.21136203 <a title="351-tfidf-2" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>Introduction: Several recent papers have shown that SVM-like optimizations can be used to handle several large family loss functions.
 
This is a good thing because it is implausible that the  loss  function imposed by the world can not be taken into account in the process of solving a prediction problem.  Even people used to the hard-core  Bayesian  approach to learning often note that some approximations are almost inevitable in specifying a  prior  and/or integrating to achieve a posterior.  Taking into account how the system will be evaluated can allow both computational effort and design effort to be focused so as to improve performance.
 
A current laundry list of capabilities includes:
  
 2002  multiclass SVM including arbitrary cost matrices  
  ICML 2003   Hidden Markov Models  
  NIPS 2003   Markov Networks  (see some  discussion ) 
  EMNLP 2004   Context free grammars  
  ICML 2004   Any loss (with much computation)  
  ICML 2005  Any  constrained linear prediction model  (thatâ&euro;&trade;s my own</p><p>3 0.2057671 <a title="351-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notation  g(n) = O(f(n))  means that in the limit as  n  approaches infinity there exists a constant  C  such that the  g(n)  is less than  Cf(n) .
 
In learning theory, there are many statements about learning algorithms of the form “under assumptions  x , y , and  z , the classifier learned has an error rate of at most  O(f(m)) “.
 
There is one very good reason to use O(): it helps you understand the big picture and neglect the minor details which are not important in the big picture.  However, there are some important reasons not to do this as well.
  
  Unspeedup  In algorithm analysis, the use of O() for time complexity is pervasive and well-justified.  Determining the exact value of C is inherently computer architecture dependent.  (The “C” for x86 processors might differ from the “C” on PowerPC processors.)  Since many learning theorists come from a CS theory background, the O() notation is applied to generalization error.  The O() abstraction breaks here—you can not genera</p><p>4 0.19296248 <a title="351-tfidf-4" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>Introduction: Sam Roweis ‘s comment reminds me of a more general issue that comes up in doing research: abstractions always break.  
  
 Real number’s aren’t.  Most real numbers can not be represented with any machine.  One implication of this is that many real-number based algorithms have difficulties when implemented with floating point numbers. 
 The box on your desk is not a turing machine. A turing machine can compute anything computable, given sufficient time.  A typical computer fails terribly when the state required for the computation exceeds some limit. 
 Nash equilibria aren’t equilibria.  This comes up when trying to predict human behavior based on the result of the equilibria computation.  Often, it doesn’t work. 
 The  probability  isn’t.  Probability is an abstraction expressing either our lack of knowledge (the Bayesian viewpoint) or fundamental randomization (the frequentist viewpoint).  From the frequentist viewpoint the lack of knowledge typically precludes actually knowing the fu</p><p>5 0.17869347 <a title="351-tfidf-5" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthu  invited me to the workshop on  algorithms in the field , with the goal of providing a sense of where near-term research should go.  When the time came though, I bargained for a post instead, which provides a chance for many other people to comment.
 
There are several things I didn’t fully understand when I went to Yahoo! about 5 years ago.  I’d like to repeat them as people in academia may not yet understand them intuitively.
  
 Almost all the big impact algorithms operate in pseudo-linear or better time.  Think about caching, hashing, sorting, filtering, etc… and you have a sense of what some of the most heavily used algorithms are.  This matters quite a bit to Machine Learning research, because people often work with superlinear time algorithms and languages.  Two very common examples of this are graphical models, where inference is often a superlinear operation—think about the  n 2   dependence on the number of states in a  Hidden Markov Model  and Kernelized  Support Vecto</p><p>6 0.1766326 <a title="351-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>7 0.1732568 <a title="351-tfidf-7" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>8 0.16602181 <a title="351-tfidf-8" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>9 0.16589342 <a title="351-tfidf-9" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>10 0.15670927 <a title="351-tfidf-10" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>11 0.155986 <a title="351-tfidf-11" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>12 0.14277193 <a title="351-tfidf-12" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>13 0.1425297 <a title="351-tfidf-13" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>14 0.13758403 <a title="351-tfidf-14" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>15 0.13694756 <a title="351-tfidf-15" href="../hunch_net-2006/hunch_net-2006-10-22-Exemplar_programming.html">215 hunch net-2006-10-22-Exemplar programming</a></p>
<p>16 0.13619636 <a title="351-tfidf-16" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>17 0.13593148 <a title="351-tfidf-17" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>18 0.13581567 <a title="351-tfidf-18" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>19 0.13518371 <a title="351-tfidf-19" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>20 0.13182136 <a title="351-tfidf-20" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.36), (1, 0.146), (2, 0.024), (3, -0.004), (4, 0.022), (5, -0.065), (6, 0.129), (7, -0.007), (8, -0.021), (9, 0.011), (10, -0.065), (11, -0.036), (12, -0.003), (13, 0.077), (14, -0.013), (15, 0.0), (16, 0.015), (17, -0.003), (18, -0.027), (19, -0.012), (20, 0.017), (21, -0.007), (22, -0.011), (23, -0.021), (24, -0.055), (25, -0.027), (26, -0.05), (27, -0.009), (28, 0.015), (29, 0.014), (30, 0.013), (31, -0.04), (32, 0.053), (33, 0.007), (34, -0.086), (35, -0.003), (36, 0.034), (37, -0.01), (38, -0.005), (39, 0.105), (40, -0.044), (41, 0.021), (42, 0.011), (43, -0.059), (44, 0.093), (45, 0.012), (46, -0.017), (47, 0.017), (48, -0.054), (49, 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95803779 <a title="351-lsi-1" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for the  reductions tutorial   Alina ,  Bianca , and I are planning to do at  ICML .  Please come, if you are interested.
 
Many research programs can be thought of as finding and building new useful abstractions.  The running example I’ll use is  learning reductions  where I have experience.  The basic abstraction here is that we can build a learning algorithm capable of solving classification problems up to a small expected regret.   This is used repeatedly to solve more complex problems.
 
In working on a new abstraction, I think you typically run into many substantial problems of understanding, which make publishing particularly difficult.
  
 It is difficult to seriously discuss the reason behind or mechanism for abstraction in a conference paper with small page limits.  People rarely see such discussions and hence have little basis on which to think about new abstractions.    Another difficulty is that when building an abstraction, yo</p><p>2 0.76782387 <a title="351-lsi-2" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>Introduction: There were  two   papers  at ICML presenting learning algorithms for a  contextual bandit -style setting, where the loss for all labels is not known, but the loss for one label is known.  (The first might require a  exploration scavenging  viewpoint to understand if the experimental assignment was nonrandom.)  I strongly approve of these papers and further work in this setting and its variants, because I expect it to become more important than supervised learning.  As a quick review, we are thinking about situations where repeatedly:
  
 The world reveals feature values (aka context information). 
 A policy chooses an action. 
 The world provides a reward. 
  
Sometimes this is done in an online fashion where the policy can change based on immediate feedback and sometimes it’s done in a batch setting where many samples are collected before the policy can change.  If you haven’t spent time thinking about the setting, you might want to because there are many natural applications.
 
I’m g</p><p>3 0.74882913 <a title="351-lsi-3" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthu  invited me to the workshop on  algorithms in the field , with the goal of providing a sense of where near-term research should go.  When the time came though, I bargained for a post instead, which provides a chance for many other people to comment.
 
There are several things I didn’t fully understand when I went to Yahoo! about 5 years ago.  I’d like to repeat them as people in academia may not yet understand them intuitively.
  
 Almost all the big impact algorithms operate in pseudo-linear or better time.  Think about caching, hashing, sorting, filtering, etc… and you have a sense of what some of the most heavily used algorithms are.  This matters quite a bit to Machine Learning research, because people often work with superlinear time algorithms and languages.  Two very common examples of this are graphical models, where inference is often a superlinear operation—think about the  n 2   dependence on the number of states in a  Hidden Markov Model  and Kernelized  Support Vecto</p><p>4 0.72638851 <a title="351-lsi-4" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?  Reductions are machines which turn solvers for one problem into solvers for another problem. 
 Why?  Reductions are useful for several reasons.
  
  Laziness .  Reducing a problem to classification make at least 10 learning algorithms available to solve a problem.  Inventing 10 learning algorithms is quite a bit of work.  Similarly, programming a reduction is often trivial, while programming a learning algorithm is a great deal of work. 
  Crystallization .  The problems we often want to solve in learning are worst-case-impossible, but average case feasible.  By reducing all problems onto one or a few primitives, we can fine tune these primitives to perform well on real-world problems with greater precision due to the greater number of problems to validate on. 
  Theoretical Organization .  By studying what reductions are easy vs. hard vs. impossible, we can learn which problems are roughly equivalent in difficulty and which are much harder. 
  
 What we know now .
 
 Typesafe r</p><p>5 0.72589481 <a title="351-lsi-5" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>Introduction: I’m offering a reward of $1000 for a solution to this problem.  This joins the  cross validation problem  which I’m offering a  $500 reward  for.  I believe both of these problems are hard but plausibly solvable, and plausibly with a solution of substantial practical value.  While it’s unlikely these rewards are worth your time on an hourly wage basis, the recognition for solving them definitely should be   
  The Problem  
The problem is finding a general, robust, and efficient mechanism for estimating a conditional probability  P(y|x)  where robustness and efficiency are measured using techniques from learning reductions. 
 
In particular, suppose we have access to a binary regression oracle  B  which has two interfaces—one for specifying training information and one for testing. Training information is specified as  B(x’,y’)  where  x’  is a feature vector and  y’  is a scalar in  [0,1]  with no value returned.  Testing is done according to  B(x’)  with a value in  [0,1]  returned.</p><p>6 0.70002329 <a title="351-lsi-6" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>7 0.69922251 <a title="351-lsi-7" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>8 0.69723088 <a title="351-lsi-8" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>9 0.69674659 <a title="351-lsi-9" href="../hunch_net-2006/hunch_net-2006-05-01-A_conversation_between_Theo_and_Pat.html">176 hunch net-2006-05-01-A conversation between Theo and Pat</a></p>
<p>10 0.69343191 <a title="351-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>11 0.68437672 <a title="351-lsi-11" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>12 0.67982656 <a title="351-lsi-12" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>13 0.6784265 <a title="351-lsi-13" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>14 0.67441261 <a title="351-lsi-14" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>15 0.67396975 <a title="351-lsi-15" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>16 0.66962785 <a title="351-lsi-16" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>17 0.66601473 <a title="351-lsi-17" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>18 0.65160996 <a title="351-lsi-18" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>19 0.64734745 <a title="351-lsi-19" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>20 0.64722991 <a title="351-lsi-20" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.047), (16, 0.011), (20, 0.138), (27, 0.247), (37, 0.011), (38, 0.056), (48, 0.014), (53, 0.083), (55, 0.067), (64, 0.035), (77, 0.025), (92, 0.015), (94, 0.115), (95, 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9545275 <a title="351-lda-1" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>Introduction: The internet has recently made the research process much smoother: papers are easy to obtain, citations are easy to follow, and unpublished “tutorials” are often available. Yet, new research fields can look very complicated to outsiders or newcomers. Every paper is like a small piece of an unfinished jigsaw puzzle: to understand just one publication, a researcher without experience in the field will typically have to follow several layers of citations, and many of the papers he encounters have a great deal of repeated information. Furthermore, from one publication to the next, notation and terminology may not be consistent which can further confuse the reader.
 
But the internet is now proving to be an extremely useful medium for collaboration and knowledge aggregation. Online forums allow users to ask and answer questions and to share ideas. The recent phenomenon of Wikipedia provides a proof-of-concept for the “anyone can edit” system. Can such models be used to facilitate research a</p><p>2 0.94149852 <a title="351-lda-2" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>Introduction: “Assumption” is another word to be careful with in machine learning because it is used in several ways.
  
  Assumption = Bias  There are several ways to see that some form of ‘bias’ (= preferring of one solution over another) is necessary.   This is obvious in an adversarial setting.  A good bit of work has been expended explaining this in other settings with “ no free lunch ” theorems.  This is a usage specialized to learning which is particularly common when talking about priors for Bayesian Learning. 
  Assumption = “if” of a theorem  The assumptions are the ‘if’ part of the ‘if-then’ in a theorem.  This is a fairly common usage. 
  Assumption = Axiom  The assumptions are the things that we assume are true, but which we cannot verify.  Examples are “the IID assumption” or “my problem is a DNF on a small number of bits”.  This is the usage which I prefer. 
  
One difficulty with any use of the word “assumption” is that you often encounter “if  assumption  then  conclusion  so if  no</p><p>same-blog 3 0.94038433 <a title="351-lda-3" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for the  reductions tutorial   Alina ,  Bianca , and I are planning to do at  ICML .  Please come, if you are interested.
 
Many research programs can be thought of as finding and building new useful abstractions.  The running example I’ll use is  learning reductions  where I have experience.  The basic abstraction here is that we can build a learning algorithm capable of solving classification problems up to a small expected regret.   This is used repeatedly to solve more complex problems.
 
In working on a new abstraction, I think you typically run into many substantial problems of understanding, which make publishing particularly difficult.
  
 It is difficult to seriously discuss the reason behind or mechanism for abstraction in a conference paper with small page limits.  People rarely see such discussions and hence have little basis on which to think about new abstractions.    Another difficulty is that when building an abstraction, yo</p><p>4 0.92205745 <a title="351-lda-4" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>Introduction: Alan Fern  points out the  second branch prediction challenge  (due September 29) which is a follow up to the  first branch prediction competition .  Branch prediction is one of the fundamental learning problems of the computer age: without it our computers might run an order of magnitude slower.  This is a tough problem since there are sharp constraints on time and space complexity in an online environment.  For machine learning, the “idealistic track” may fit well.  Essentially, they remove these constraints to gain a weak upper bound on what might be done.</p><p>5 0.89192963 <a title="351-lda-5" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthu  invited me to the workshop on  algorithms in the field , with the goal of providing a sense of where near-term research should go.  When the time came though, I bargained for a post instead, which provides a chance for many other people to comment.
 
There are several things I didn’t fully understand when I went to Yahoo! about 5 years ago.  I’d like to repeat them as people in academia may not yet understand them intuitively.
  
 Almost all the big impact algorithms operate in pseudo-linear or better time.  Think about caching, hashing, sorting, filtering, etc… and you have a sense of what some of the most heavily used algorithms are.  This matters quite a bit to Machine Learning research, because people often work with superlinear time algorithms and languages.  Two very common examples of this are graphical models, where inference is often a superlinear operation—think about the  n 2   dependence on the number of states in a  Hidden Markov Model  and Kernelized  Support Vecto</p><p>6 0.88774848 <a title="351-lda-6" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>7 0.8823474 <a title="351-lda-7" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>8 0.88184655 <a title="351-lda-8" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>9 0.88075978 <a title="351-lda-9" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>10 0.88025928 <a title="351-lda-10" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>11 0.87772745 <a title="351-lda-11" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>12 0.87594068 <a title="351-lda-12" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>13 0.87539071 <a title="351-lda-13" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>14 0.87502766 <a title="351-lda-14" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>15 0.87472373 <a title="351-lda-15" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>16 0.87448823 <a title="351-lda-16" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>17 0.87430096 <a title="351-lda-17" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>18 0.87421221 <a title="351-lda-18" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>19 0.87419051 <a title="351-lda-19" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>20 0.87413943 <a title="351-lda-20" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
