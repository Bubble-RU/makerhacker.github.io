<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>374 hunch net-2009-10-10-ALT 2009</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-374" href="#">hunch_net-2009-374</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>374 hunch net-2009-10-10-ALT 2009</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-374-html" href="http://hunch.net/?p=992">html</a></p><p>Introduction: I attended  ALT  (“Algorithmic Learning Theory”) for the first time this year.  My impression is ALT = 0.5 COLT, by attendance and also by some more intangible “what do I get from it?” measure.  There are many differences which can’t quite be described this way though.  The program for ALT seems to be substantially more diverse than COLT, which is both a weakness and a strength.  
 
One paper that might interest people generally is:
 
 Alexey Chernov  and  Vladimir Vovk ,  Prediction with Expert Evaluators’ Advice .  The basic observation here is that in the online learning with experts setting you can simultaneously compete with several compatible loss functions simultaneously.  Restated, debating between competing with log loss and squared loss is a waste of breath, because it’s almost free to compete with them both simultaneously.  This might interest anyone who has run into “which loss function?” debates that come up periodically.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I attended  ALT  (“Algorithmic Learning Theory”) for the first time this year. [sent-1, score-0.16]
</p><p>2 5 COLT, by attendance and also by some more intangible “what do I get from it? [sent-3, score-0.174]
</p><p>3 There are many differences which can’t quite be described this way though. [sent-5, score-0.365]
</p><p>4 The program for ALT seems to be substantially more diverse than COLT, which is both a weakness and a strength. [sent-6, score-0.431]
</p><p>5 One paper that might interest people generally is:    Alexey Chernov  and  Vladimir Vovk ,  Prediction with Expert Evaluators’ Advice . [sent-7, score-0.331]
</p><p>6 The basic observation here is that in the online learning with experts setting you can simultaneously compete with several compatible loss functions simultaneously. [sent-8, score-1.271]
</p><p>7 Restated, debating between competing with log loss and squared loss is a waste of breath, because it’s almost free to compete with them both simultaneously. [sent-9, score-1.676]
</p><p>8 This might interest anyone who has run into “which loss function? [sent-10, score-0.665]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('alt', 0.512), ('loss', 0.294), ('compete', 0.254), ('breath', 0.184), ('periodically', 0.184), ('debating', 0.184), ('weakness', 0.171), ('waste', 0.171), ('vladimir', 0.154), ('vovk', 0.154), ('colt', 0.152), ('compatible', 0.147), ('interest', 0.138), ('differences', 0.134), ('described', 0.134), ('competing', 0.134), ('restated', 0.127), ('expert', 0.124), ('simultaneously', 0.122), ('impression', 0.119), ('attendance', 0.119), ('algorithmic', 0.115), ('attended', 0.115), ('advice', 0.113), ('diverse', 0.113), ('squared', 0.109), ('experts', 0.106), ('functions', 0.09), ('free', 0.085), ('observation', 0.084), ('log', 0.084), ('might', 0.08), ('run', 0.077), ('anyone', 0.076), ('substantially', 0.076), ('program', 0.071), ('function', 0.07), ('generally', 0.069), ('setting', 0.068), ('almost', 0.067), ('come', 0.066), ('online', 0.058), ('prediction', 0.057), ('theory', 0.055), ('get', 0.055), ('quite', 0.051), ('basic', 0.048), ('way', 0.046), ('first', 0.045), ('paper', 0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="374-tfidf-1" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>Introduction: I attended  ALT  (“Algorithmic Learning Theory”) for the first time this year.  My impression is ALT = 0.5 COLT, by attendance and also by some more intangible “what do I get from it?” measure.  There are many differences which can’t quite be described this way though.  The program for ALT seems to be substantially more diverse than COLT, which is both a weakness and a strength.  
 
One paper that might interest people generally is:
 
 Alexey Chernov  and  Vladimir Vovk ,  Prediction with Expert Evaluators’ Advice .  The basic observation here is that in the online learning with experts setting you can simultaneously compete with several compatible loss functions simultaneously.  Restated, debating between competing with log loss and squared loss is a waste of breath, because it’s almost free to compete with them both simultaneously.  This might interest anyone who has run into “which loss function?” debates that come up periodically.</p><p>2 0.25236672 <a title="374-tfidf-2" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction and the correct prediction, and determines how much loss is incurred.  (People sometimes attempt to optimize functions of more than one example such as “area under the ROC curve” or “harmonic mean of precision and recall”.)  Typically we try to find predictors that minimize loss.  
 
There seems to be a strong dichotomy between two views of what “loss” means in learning.
  
  Loss is determined by the problem.  Loss is a part of the specification of the learning problem.  Examples of problems specified by the loss function include “binary classification”, “multiclass classification”, “importance weighted classification”, “l 2  regression”, etc…  This is the decision theory view of what loss means, and the view that I prefer. 
  Loss is determined by the solution.  To solve a problem, you optimize some particular loss function  not  given by the problem.  Examples of these loss functions are “hinge loss” (for SV</p><p>3 0.23644122 <a title="374-tfidf-3" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss: A loss function which is much easier to optimize computationally than the loss function imposed by the world.  A canonical example is when we want to learn a weight vector  w  and predict according to a dot product  f w (x)= sum i  w i x i   
where optimizing squared loss  (y-f w (x)) 2   over many samples is much more tractable than optimizing 0-1 loss  I(y = Threshold(f w (x) – 0.5)) .
 
While the computational advantages of optimizing a proxy loss are substantial, we are curious: which proxy loss is best?  The answer of course depends on what the real loss imposed by the world is.  For 0-1 loss classification, there are adherents to many choices:
  
 Log loss.  If we confine the prediction to  [0,1] , we can treat it as a predicted probability that the label is  1 , and measure loss according to  log 1/p’(y|x)  where  p’(y|x)  is the predicted probability of the observed label.  A standard method for confi</p><p>4 0.20448059 <a title="374-tfidf-4" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner independent of the loss function itself.  
  
 Optimizing squared loss  l sq (y,y’)=(y-y’) 2   means predicting the (conditional) mean of  y . 
 Optimizing absolute value loss  l av (y,y’)=|y-y’|  means predicting the (conditional) median of  y .  Variants can  handle other quantiles .  0/1 loss for classification is a special case. 
 Optimizing log loss  l log (y,y’)=log (1/Pr z~y’ (z=y))  means minimizing the description length of  y . 
  
The semantics (= meaning) of the loss are made explicit by a theorem in each case.  For squared loss, we can prove a theorem of the form: 
For all distributions  D  over  Y , if    y’ = arg min y’  E y ~ D  l sq  (y,y’)   then   y’ = E y~D  y  
 
Similar theorems hold for the other examples above, and they can all be extended to predictors of  y’  for distributions  D  over a context  X  and a value  Y .
 
There are 3 points to this post.
  
 Everyone doing general machine lear</p><p>5 0.19773073 <a title="374-tfidf-5" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>Introduction: Hal  asks   a very good question: “When is the right time to insert the loss function?”  In particular, should it be used at testing time or at training time?
 
When the world imposes a loss on us, the standard Bayesian recipe is to predict the (conditional) probability of each possibility and then choose the possibility which minimizes the expected loss.  In contrast, as the  confusion  over “loss = money lost” or “loss = the thing you optimize” might indicate, many people ignore the Bayesian approach and simply optimize their loss (or a close proxy for their loss) over the representation on the training set.
 
The best answer I can give is “it’s unclear, but I prefer optimizing the loss at training time”.  My experience is that optimizing the loss in the most direct manner possible typically yields best performance.  This question is related to a basic principle which both  Yann LeCun (applied) and  Vladimir Vapnik (theoretical) advocate: “solve the simplest prediction problem that s</p><p>6 0.17838493 <a title="374-tfidf-6" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>7 0.16606721 <a title="374-tfidf-7" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>8 0.15340567 <a title="374-tfidf-8" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>9 0.1128419 <a title="374-tfidf-9" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>10 0.1111318 <a title="374-tfidf-10" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>11 0.10867538 <a title="374-tfidf-11" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>12 0.10817245 <a title="374-tfidf-12" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>13 0.1059173 <a title="374-tfidf-13" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>14 0.096015528 <a title="374-tfidf-14" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">324 hunch net-2008-11-09-A Healthy  COLT</a></p>
<p>15 0.093759723 <a title="374-tfidf-15" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>16 0.091276579 <a title="374-tfidf-16" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>17 0.087232515 <a title="374-tfidf-17" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>18 0.086109951 <a title="374-tfidf-18" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>19 0.085313641 <a title="374-tfidf-19" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>20 0.084548347 <a title="374-tfidf-20" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.162), (1, 0.064), (2, 0.077), (3, -0.164), (4, -0.216), (5, 0.129), (6, -0.152), (7, -0.018), (8, 0.017), (9, 0.063), (10, 0.155), (11, -0.01), (12, -0.034), (13, 0.062), (14, 0.062), (15, 0.007), (16, 0.122), (17, -0.034), (18, -0.016), (19, 0.047), (20, 0.053), (21, 0.043), (22, 0.015), (23, 0.047), (24, -0.001), (25, 0.031), (26, 0.009), (27, 0.044), (28, 0.044), (29, 0.006), (30, -0.019), (31, -0.011), (32, 0.007), (33, 0.058), (34, 0.004), (35, -0.013), (36, 0.044), (37, 0.03), (38, 0.006), (39, -0.074), (40, -0.035), (41, 0.065), (42, -0.023), (43, -0.013), (44, -0.047), (45, -0.089), (46, 0.044), (47, -0.092), (48, -0.012), (49, 0.022)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98313642 <a title="374-lsi-1" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>Introduction: I attended  ALT  (“Algorithmic Learning Theory”) for the first time this year.  My impression is ALT = 0.5 COLT, by attendance and also by some more intangible “what do I get from it?” measure.  There are many differences which can’t quite be described this way though.  The program for ALT seems to be substantially more diverse than COLT, which is both a weakness and a strength.  
 
One paper that might interest people generally is:
 
 Alexey Chernov  and  Vladimir Vovk ,  Prediction with Expert Evaluators’ Advice .  The basic observation here is that in the online learning with experts setting you can simultaneously compete with several compatible loss functions simultaneously.  Restated, debating between competing with log loss and squared loss is a waste of breath, because it’s almost free to compete with them both simultaneously.  This might interest anyone who has run into “which loss function?” debates that come up periodically.</p><p>2 0.78256971 <a title="374-lsi-2" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>Introduction: Many people in machine learning take advantage of the notion of a proxy loss: A loss function which is much easier to optimize computationally than the loss function imposed by the world.  A canonical example is when we want to learn a weight vector  w  and predict according to a dot product  f w (x)= sum i  w i x i   
where optimizing squared loss  (y-f w (x)) 2   over many samples is much more tractable than optimizing 0-1 loss  I(y = Threshold(f w (x) – 0.5)) .
 
While the computational advantages of optimizing a proxy loss are substantial, we are curious: which proxy loss is best?  The answer of course depends on what the real loss imposed by the world is.  For 0-1 loss classification, there are adherents to many choices:
  
 Log loss.  If we confine the prediction to  [0,1] , we can treat it as a predicted probability that the label is  1 , and measure loss according to  log 1/p’(y|x)  where  p’(y|x)  is the predicted probability of the observed label.  A standard method for confi</p><p>3 0.78147089 <a title="374-lsi-3" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>Introduction: Some loss functions have a meaning, which can be understood in a manner independent of the loss function itself.  
  
 Optimizing squared loss  l sq (y,y’)=(y-y’) 2   means predicting the (conditional) mean of  y . 
 Optimizing absolute value loss  l av (y,y’)=|y-y’|  means predicting the (conditional) median of  y .  Variants can  handle other quantiles .  0/1 loss for classification is a special case. 
 Optimizing log loss  l log (y,y’)=log (1/Pr z~y’ (z=y))  means minimizing the description length of  y . 
  
The semantics (= meaning) of the loss are made explicit by a theorem in each case.  For squared loss, we can prove a theorem of the form: 
For all distributions  D  over  Y , if    y’ = arg min y’  E y ~ D  l sq  (y,y’)   then   y’ = E y~D  y  
 
Similar theorems hold for the other examples above, and they can all be extended to predictors of  y’  for distributions  D  over a context  X  and a value  Y .
 
There are 3 points to this post.
  
 Everyone doing general machine lear</p><p>4 0.77808797 <a title="374-lsi-4" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction and the correct prediction, and determines how much loss is incurred.  (People sometimes attempt to optimize functions of more than one example such as “area under the ROC curve” or “harmonic mean of precision and recall”.)  Typically we try to find predictors that minimize loss.  
 
There seems to be a strong dichotomy between two views of what “loss” means in learning.
  
  Loss is determined by the problem.  Loss is a part of the specification of the learning problem.  Examples of problems specified by the loss function include “binary classification”, “multiclass classification”, “importance weighted classification”, “l 2  regression”, etc…  This is the decision theory view of what loss means, and the view that I prefer. 
  Loss is determined by the solution.  To solve a problem, you optimize some particular loss function  not  given by the problem.  Examples of these loss functions are “hinge loss” (for SV</p><p>5 0.77128899 <a title="374-lsi-5" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>Introduction: Hal  asks   a very good question: “When is the right time to insert the loss function?”  In particular, should it be used at testing time or at training time?
 
When the world imposes a loss on us, the standard Bayesian recipe is to predict the (conditional) probability of each possibility and then choose the possibility which minimizes the expected loss.  In contrast, as the  confusion  over “loss = money lost” or “loss = the thing you optimize” might indicate, many people ignore the Bayesian approach and simply optimize their loss (or a close proxy for their loss) over the representation on the training set.
 
The best answer I can give is “it’s unclear, but I prefer optimizing the loss at training time”.  My experience is that optimizing the loss in the most direct manner possible typically yields best performance.  This question is related to a basic principle which both  Yann LeCun (applied) and  Vladimir Vapnik (theoretical) advocate: “solve the simplest prediction problem that s</p><p>6 0.68184906 <a title="374-lsi-6" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>7 0.65597433 <a title="374-lsi-7" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>8 0.58000916 <a title="374-lsi-8" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>9 0.5646323 <a title="374-lsi-9" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>10 0.50845367 <a title="374-lsi-10" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>11 0.48573151 <a title="374-lsi-11" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">324 hunch net-2008-11-09-A Healthy  COLT</a></p>
<p>12 0.4552497 <a title="374-lsi-12" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>13 0.43294153 <a title="374-lsi-13" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>14 0.42382172 <a title="374-lsi-14" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>15 0.4189176 <a title="374-lsi-15" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>16 0.41030249 <a title="374-lsi-16" href="../hunch_net-2010/hunch_net-2010-04-24-COLT_Treasurer_is_now_Phil_Long.html">394 hunch net-2010-04-24-COLT Treasurer is now Phil Long</a></p>
<p>17 0.4032664 <a title="374-lsi-17" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>18 0.40160882 <a title="374-lsi-18" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>19 0.39608616 <a title="374-lsi-19" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>20 0.39553446 <a title="374-lsi-20" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.27), (55, 0.113), (66, 0.413), (94, 0.07)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.87971866 <a title="374-lda-1" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>Introduction: I attended  ALT  (“Algorithmic Learning Theory”) for the first time this year.  My impression is ALT = 0.5 COLT, by attendance and also by some more intangible “what do I get from it?” measure.  There are many differences which can’t quite be described this way though.  The program for ALT seems to be substantially more diverse than COLT, which is both a weakness and a strength.  
 
One paper that might interest people generally is:
 
 Alexey Chernov  and  Vladimir Vovk ,  Prediction with Expert Evaluators’ Advice .  The basic observation here is that in the online learning with experts setting you can simultaneously compete with several compatible loss functions simultaneously.  Restated, debating between competing with log loss and squared loss is a waste of breath, because it’s almost free to compete with them both simultaneously.  This might interest anyone who has run into “which loss function?” debates that come up periodically.</p><p>2 0.82918537 <a title="374-lda-2" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>Introduction: Several papers at NIPS caught my attention.
  
  Elad Hazan  and  Satyen Kale ,  Online Submodular Optimization  They define an algorithm for online optimization of submodular functions with regret guarantees.  This places submodular optimization roughly on par with online convex optimization as tractable settings for online learning.   
  Elad Hazan  and  Satyen Kale   On Stochastic and Worst-Case Models of Investing .  At it’s core, this is yet another example of modifying worst-case online learning to deal with variance, but the application to financial models is particularly cool and it seems plausibly superior other common approaches for financial modeling. 
  Mark Palatucci ,  Dean Pomerlau ,  Tom Mitchell , and  Geoff Hinton   Zero Shot Learning with Semantic Output Codes  The goal here is predicting a label in a multiclass supervised setting where the label never occurs in the training data.  They have some basic analysis and also a nice application to FMRI brain reading. 
  Sh</p><p>3 0.70735401 <a title="374-lda-3" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>Introduction: A few weeks ago I read  this . David Blei and I spent some time thinking hard about this a few years back (thanks to Kary Myers for pointing us to it):
 
 In short I was thinking that Ã¢â‚¬Å“bayesian belief updatingÃ¢â‚¬Â and Ã¢â‚¬Å“maximum entropyÃ¢â‚¬Â were two othogonal principles. But it appear that they are not, and that they can even be in conflict ! 
Example (from Kass 1996); consider a Die (6 sides), consider prior knowledge E[X]=3.5. 
Maximum entropy leads to P(X)= (1/6, 1/6, 1/6, 1/6, 1/6, 1/6). 
Now consider a new piece of evidence A=Ã¢â‚¬ÂX is an odd numberÃ¢â‚¬Â 
Bayesian posterior P(X|A)= P(A|X) P(X) = (1/3, 0, 1/3, 0, 1/3, 0). 
But MaxEnt with the constraints E[X]=3.5 and E[Indicator function of A]=1 leads to (.22, 0, .32, 0, .47, 0) !! (note that E[Indicator function of A]=P(A)) 
Indeed, for MaxEnt, because there is no more Ã¢â‚¬Ëœ6Ã¢â‚¬Â², big numbers must be more probable to ensure an average of 3.5. For bayesian updating, P(X|A) doesnÃ¢â‚¬â„¢t have to have a 3.5</p><p>4 0.57454956 <a title="374-lda-4" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>Introduction: Essentially everyone who writes research papers suffers rejections.  They always sting immediately, but upon further reflection many of these rejections come to seem reasonable.  Maybe the equations had too many typos or maybe the topic just isn’t as important as was originally thought.  A few rejections do not come to seem acceptable, and these form the basis of reviewing horror stories, a great material for conversations.  I’ve decided to share three of mine, now all safely a bit distant in the past.
  
  Prediction Theory for Classification Tutorial .  This is a tutorial about tight sample complexity bounds for classification that I submitted to  JMLR .  The first decision I heard was a reject which appeared quite unjust to me—for example one of the reviewers appeared to claim that all the content was in standard statistics books.  Upon further inquiry, several citations were given, none of which actually covered the content.  Later, I was shocked to hear the paper was accepted. App</p><p>5 0.5705235 <a title="374-lda-5" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>Introduction: Michael Littman  and  Leon Bottou  have decided to use a franchise program chair approach to  reviewing at ICML  this year.  I’ll be one of the area chairs, so I wanted to mention a few things if you are thinking about naming me.
  
 I take reviewing seriously.  That means papers to be reviewed are read, the implications are considered, and decisions are only made after that.  I do my best to be fair, and there are zero subjects that I consider categorical rejects.  I don’t consider several  arguments for rejection-not-on-the-merits reasonable . 
 I am generally interested in papers that (a) analyze new models of machine learning, (b) provide new algorithms, and (c) show that they work empirically on plausibly real problems.  If a paper has the trifecta, I’m particularly interested. With 2 out of 3, I might be interested.  I often find papers with only one element harder to accept, including papers with just (a).  
 I’m a bit tough.  I rarely jump-up-and-down about a paper, because I b</p><p>6 0.5667389 <a title="374-lda-6" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>7 0.56359649 <a title="374-lda-7" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>8 0.56354171 <a title="374-lda-8" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>9 0.5631007 <a title="374-lda-9" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>10 0.5628202 <a title="374-lda-10" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>11 0.56174225 <a title="374-lda-11" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>12 0.55975986 <a title="374-lda-12" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>13 0.55880141 <a title="374-lda-13" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>14 0.55773151 <a title="374-lda-14" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>15 0.55772555 <a title="374-lda-15" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>16 0.55735236 <a title="374-lda-16" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>17 0.55464315 <a title="374-lda-17" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>18 0.55449986 <a title="374-lda-18" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>19 0.55435747 <a title="374-lda-19" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>20 0.55345732 <a title="374-lda-20" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
