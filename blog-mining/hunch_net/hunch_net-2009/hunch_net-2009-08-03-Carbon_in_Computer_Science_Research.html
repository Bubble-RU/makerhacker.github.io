<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>366 hunch net-2009-08-03-Carbon in Computer Science Research</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-366" href="#">hunch_net-2009-366</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>366 hunch net-2009-08-03-Carbon in Computer Science Research</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-366-html" href="http://hunch.net/?p=875">html</a></p><p>Introduction: Al Gore'sfilmand gradually more assertive and thorough science has managed to
mostly shift the debate on climate change from "Is it happening?" to "What
should be done?" In that context, it's worthwhile to think a bit about what
can be done within computer science research.There are two things we can think
about:Doing ResearchAt a cartoon level, computer science research consists of
some combination of commuting to&from; work, writing programs, running them on
computers, writing papers, and presenting them at conferences. A typical
computer has a power usage on the order of 100 Watts, which works out to 2.4
kiloWatt-hours/day. Looking upDavid MacKay'sreference on power usage per
person, it becomes clear that this is a relatively minor part of the
lifestyle, although it could become substantial if many more computers are
required. Much larger costs are associated with commuting (which is in common
with many people) and attending conferences. Since local commuting is common
across many pe</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 " In that context, it's worthwhile to think a bit about what can be done within computer science research. [sent-3, score-0.291]
</p><p>2 There are two things we can think about:Doing ResearchAt a cartoon level, computer science research consists of some combination of commuting to&from; work, writing programs, running them on computers, writing papers, and presenting them at conferences. [sent-4, score-0.794]
</p><p>3 A typical computer has a power usage on the order of 100 Watts, which works out to 2. [sent-5, score-0.461]
</p><p>4 Looking upDavid MacKay'sreference on power usage per person, it becomes clear that this is a relatively minor part of the lifestyle, although it could become substantial if many more computers are required. [sent-7, score-0.364]
</p><p>5 Much larger costs are associated with commuting (which is in common with many people) and attending conferences. [sent-8, score-0.429]
</p><p>6 Since local commuting is common across many people, and there are known approaches (typically public transportation) for more efficient commuting, I expect researchers can piggyback on improvements in public transportation to reduce commuting costs. [sent-9, score-1.634]
</p><p>7 In fact, the situation for researchers may be better in general, as the nature of the job may make commuting avoidable, at least on some days. [sent-10, score-0.491]
</p><p>8 Presenting at conferences is the remaining problem area, essentially due to travel by airplane to and from a conference. [sent-11, score-0.511]
</p><p>9 Travel by airplane has an energy costsimilar to travel by carover the same distance, but we typically take airplanes for very long distances. [sent-12, score-0.839]
</p><p>10 Unlike cars, typical airplane usage requires stored energy in a dense form. [sent-13, score-0.811]
</p><p>11 For example, there are no serious proposals I'm aware of for battery-powered airplanes, because all existing rechargeable batteries have a power density around 1/10th that of hydrocarbon fuel (which makes sense given that about 3/4 of the mass for a hydrocarbon fire is oxygen in the air). [sent-14, score-0.519]
</p><p>12 This suggests airplane transport may be particularly difficult to adapt towards low or zero carbon usage. [sent-15, score-0.543]
</p><p>13 If these aren't developed, it seems we should expect fewer conferences, more regional conferences, Europe with it's extensive fast train network to be less impacted, and more serious effort towards distributed conferences. [sent-18, score-0.387]
</p><p>14 For the last, it's easy to imagine with existing technology having simultaneous regional conferences which are mutually videoconferenced, and we aren't far from being able to handle a fully interactive videobroadcast amongst an indefinitely large number of participants. [sent-19, score-0.545]
</p><p>15 In computer science, there have been a few algorithms (such asquicksortandhashing) developed which substantially and broadly improved real-world efficiency, but the real driver of efficiency so far is the hardware development, which has phenomenally improved efficiency for several decades. [sent-22, score-1.142]
</p><p>16 Many of the efficiency improvements are sure to remain hardware based, but software is becoming an essential component. [sent-23, score-0.451]
</p><p>17 One basic observation about efficient algorithms is that for problems admitting an efficient parallel solution (counting is a great example), the parallel algorithm is generally more efficient, because energy use is typically superlinear in clock speed. [sent-24, score-1.127]
</p><p>18 As an extreme example, the human brain which is deeply optimized by evolution for energy efficiency typically runs at at 100Hz or 100KHz. [sent-25, score-0.635]
</p><p>19 Although efficiency suggests parallel algorithms, this should not be done blindly. [sent-26, score-0.592]
</p><p>20 A substantial difficulty with parallel algorithms is the programming itself. [sent-28, score-0.284]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('commuting', 0.429), ('efficiency', 0.269), ('airplane', 0.254), ('energy', 0.196), ('efficient', 0.194), ('usage', 0.176), ('parallel', 0.155), ('airplanes', 0.143), ('hydrocarbon', 0.143), ('transportation', 0.143), ('travel', 0.135), ('conferences', 0.122), ('computer', 0.114), ('science', 0.111), ('hardware', 0.111), ('regional', 0.111), ('typically', 0.111), ('power', 0.108), ('suggests', 0.102), ('approaches', 0.101), ('far', 0.1), ('interactive', 0.086), ('computers', 0.08), ('fewer', 0.08), ('developed', 0.076), ('expect', 0.073), ('improved', 0.072), ('improvements', 0.071), ('programming', 0.07), ('writing', 0.07), ('public', 0.066), ('done', 0.066), ('example', 0.063), ('isnot', 0.063), ('dense', 0.063), ('mutually', 0.063), ('electricity', 0.063), ('carbon', 0.063), ('hydrogen', 0.063), ('oxygen', 0.063), ('indefinitely', 0.063), ('transport', 0.063), ('superlinear', 0.063), ('typical', 0.063), ('researchers', 0.062), ('serious', 0.062), ('towards', 0.061), ('algorithms', 0.059), ('stored', 0.059), ('evolution', 0.059)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="366-tfidf-1" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>Introduction: Al Gore'sfilmand gradually more assertive and thorough science has managed to
mostly shift the debate on climate change from "Is it happening?" to "What
should be done?" In that context, it's worthwhile to think a bit about what
can be done within computer science research.There are two things we can think
about:Doing ResearchAt a cartoon level, computer science research consists of
some combination of commuting to&from; work, writing programs, running them on
computers, writing papers, and presenting them at conferences. A typical
computer has a power usage on the order of 100 Watts, which works out to 2.4
kiloWatt-hours/day. Looking upDavid MacKay'sreference on power usage per
person, it becomes clear that this is a relatively minor part of the
lifestyle, although it could become substantial if many more computers are
required. Much larger costs are associated with commuting (which is in common
with many people) and attending conferences. Since local commuting is common
across many pe</p><p>2 0.12910064 <a title="366-tfidf-2" href="../hunch_net-2010/hunch_net-2010-08-20-The_Workshop_on_Cores%2C_Clusters%2C_and_Clouds.html">404 hunch net-2010-08-20-The Workshop on Cores, Clusters, and Clouds</a></p>
<p>Introduction: Alekh,John,Ofer, and I are organizing aworkshopatNIPSthis year on learning in
parallel and distributed environments. The general interest level in parallel
learning seems to be growing rapidly, so I expect quite a bit of attendance.
Please join us if you are parallel-interested.And, if you are working in the
area of parallel learning, please considersubmitting an abstractdue Oct. 17
for presentation at the workshop.</p><p>3 0.12554316 <a title="366-tfidf-3" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I've enjoyed theTerminatormovies and show. Neglecting the whacky aspects (time
travel and associated paradoxes), there is an enduring topic of discussion:
how do people deal with intelligent machines (and vice versa)?In Terminator-
land, the primary method for dealing with intelligent machines is to prevent
them from being made. This approach works pretty badly, because a new angle on
building an intelligent machine keeps coming up. This is partly a ploy for
writer's to avoid writing themselves out of a job, but there is a fundamental
truth to it as well: preventing progress in research is hard.The United
States, has been experimenting with trying to stop research onstem cells. It
hasn't worked very well--the net effect has been retarding research programs a
bit, and exporting some research to other countries. Another less recent
example was encryption technology, for which the United States generally did
not encourage early public research and evendiscouraged as a munition. This
slowe</p><p>4 0.12533239 <a title="366-tfidf-4" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthuinvited me to the workshop onalgorithms in the field, with the goal of
providing a sense of where near-term research should go. When the time came
though, I bargained for a post instead, which provides a chance for many other
people to comment.There are several things I didn't fully understand when I
went to Yahoo! about 5 years ago. I'd like to repeat them as people in
academia may not yet understand them intuitively.Almost all the big impact
algorithms operate in pseudo-linear or better time. Think about caching,
hashing, sorting, filtering, etcâ&euro;Ś and you have a sense of what some of the
most heavily used algorithms are. This matters quite a bit to Machine Learning
research, because people often work with superlinear time algorithms and
languages. Two very common examples of this are graphical models, where
inference is often a superlinear operation--think about then2dependence on the
number of states in aHidden Markov Modeland KernelizedSupport Vector
Machineswhere optimization</p><p>5 0.12456465 <a title="366-tfidf-5" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>Introduction: I've avoided discussing politics here, although not for lack of interest. The
problem with discussing politics is that it's customary for people to say much
based upon little information. Nevertheless, politics can have a substantial
impact on science (and we might hope for the vice-versa). It's primary
election time in the United States, so the topic is timely, although the
issues are not.There are several policy decisions which substantially effect
development of science and technology in the US.EducationThe US has great
contrasts in education. The top universities are very good places, yet the
grade school education system produces mediocre results. For me, the contrast
between apublic educationandCaltechwas bracing. For many others attending
Caltech, it clearly was not. Upgrading the k-12 education system in the US is
a long-standing chronic problem which I know relatively little about. My own
experience is that a basic attitude of "no child unrealized" is better than
"no child lef</p><p>6 0.115463 <a title="366-tfidf-6" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>7 0.11405004 <a title="366-tfidf-7" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>8 0.11212301 <a title="366-tfidf-8" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>9 0.11137855 <a title="366-tfidf-9" href="../hunch_net-2009/hunch_net-2009-03-18-Parallel_ML_primitives.html">346 hunch net-2009-03-18-Parallel ML primitives</a></p>
<p>10 0.10959999 <a title="366-tfidf-10" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>11 0.10075242 <a title="366-tfidf-11" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>12 0.098275431 <a title="366-tfidf-12" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>13 0.096663833 <a title="366-tfidf-13" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>14 0.096260995 <a title="366-tfidf-14" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>15 0.095668837 <a title="366-tfidf-15" href="../hunch_net-2011/hunch_net-2011-12-13-Vowpal_Wabbit_version_6.1_%26%23038%3B_the_NIPS_tutorial.html">451 hunch net-2011-12-13-Vowpal Wabbit version 6.1 &#038; the NIPS tutorial</a></p>
<p>16 0.095055819 <a title="366-tfidf-16" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>17 0.092772573 <a title="366-tfidf-17" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>18 0.092353314 <a title="366-tfidf-18" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>19 0.090511128 <a title="366-tfidf-19" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>20 0.087976031 <a title="366-tfidf-20" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.222), (1, 0.013), (2, 0.13), (3, -0.042), (4, 0.008), (5, 0.06), (6, 0.025), (7, 0.047), (8, -0.045), (9, 0.06), (10, 0.013), (11, 0.068), (12, 0.039), (13, -0.117), (14, 0.065), (15, 0.021), (16, 0.024), (17, 0.047), (18, 0.033), (19, -0.034), (20, -0.082), (21, 0.002), (22, -0.059), (23, 0.017), (24, 0.003), (25, 0.046), (26, 0.067), (27, 0.016), (28, 0.023), (29, -0.023), (30, 0.067), (31, 0.048), (32, 0.052), (33, 0.086), (34, 0.125), (35, -0.023), (36, -0.05), (37, 0.01), (38, 0.069), (39, 0.039), (40, 0.05), (41, -0.039), (42, 0.074), (43, 0.043), (44, 0.022), (45, -0.016), (46, -0.011), (47, 0.056), (48, -0.024), (49, -0.068)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96178818 <a title="366-lsi-1" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>Introduction: Al Gore'sfilmand gradually more assertive and thorough science has managed to
mostly shift the debate on climate change from "Is it happening?" to "What
should be done?" In that context, it's worthwhile to think a bit about what
can be done within computer science research.There are two things we can think
about:Doing ResearchAt a cartoon level, computer science research consists of
some combination of commuting to&from; work, writing programs, running them on
computers, writing papers, and presenting them at conferences. A typical
computer has a power usage on the order of 100 Watts, which works out to 2.4
kiloWatt-hours/day. Looking upDavid MacKay'sreference on power usage per
person, it becomes clear that this is a relatively minor part of the
lifestyle, although it could become substantial if many more computers are
required. Much larger costs are associated with commuting (which is in common
with many people) and attending conferences. Since local commuting is common
across many pe</p><p>2 0.64822984 <a title="366-lsi-2" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I've enjoyed theTerminatormovies and show. Neglecting the whacky aspects (time
travel and associated paradoxes), there is an enduring topic of discussion:
how do people deal with intelligent machines (and vice versa)?In Terminator-
land, the primary method for dealing with intelligent machines is to prevent
them from being made. This approach works pretty badly, because a new angle on
building an intelligent machine keeps coming up. This is partly a ploy for
writer's to avoid writing themselves out of a job, but there is a fundamental
truth to it as well: preventing progress in research is hard.The United
States, has been experimenting with trying to stop research onstem cells. It
hasn't worked very well--the net effect has been retarding research programs a
bit, and exporting some research to other countries. Another less recent
example was encryption technology, for which the United States generally did
not encourage early public research and evendiscouraged as a munition. This
slowe</p><p>3 0.64354759 <a title="366-lsi-3" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>Introduction: Parallel machine learning is a subject rarely addressed at machine learning
conferences. Nevertheless, it seems likely to increase in importance
because:Data set sizes appear to be growing substantially faster than
computation. Essentially, this happens because more and more sensors of
various sorts are being hooked up to the internet.Serial speedups of
processors seem are relatively stalled. The new trend is to make processors
more powerful by making themmulticore.BothAMDandIntelare making dual core
designs standard, with plans for more parallelism in the future.IBM'sCell
processorhas (essentially) 9 cores.Modern graphics chips can have an order of
magnitude more separate execution units.The meaning of 'core' varies a bit
from processor to processor, but the overall trend seems quite clear.So, how
do we parallelize machine learning algorithms?The simplest and most common
technique is to simply run the same learning algorithm with different
parameters on different processors. Cluster m</p><p>4 0.61908102 <a title="366-lsi-4" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>Introduction: I've avoided discussing politics here, although not for lack of interest. The
problem with discussing politics is that it's customary for people to say much
based upon little information. Nevertheless, politics can have a substantial
impact on science (and we might hope for the vice-versa). It's primary
election time in the United States, so the topic is timely, although the
issues are not.There are several policy decisions which substantially effect
development of science and technology in the US.EducationThe US has great
contrasts in education. The top universities are very good places, yet the
grade school education system produces mediocre results. For me, the contrast
between apublic educationandCaltechwas bracing. For many others attending
Caltech, it clearly was not. Upgrading the k-12 education system in the US is
a long-standing chronic problem which I know relatively little about. My own
experience is that a basic attitude of "no child unrealized" is better than
"no child lef</p><p>5 0.61484945 <a title="366-lsi-5" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>Introduction: A big part of doing research is imagining how things could be different, and
then trying to figure out how to get there.A big part of science fiction is
imagining how things could be different, and then working through the
implications.Because of the similarity here, reading science fiction can
sometimes be helpful in understanding and doing research. (And, hey, it's
fun.) Here's some list of science fiction books I enjoyed which seem
particularly relevant to computer science and (sometimes) learning
systems:Vernor Vinge, "True Names", "A Fire Upon the Deep"Marc Stiegler,
"David's Sling", "Earthweb"Charles Stross, "Singularity Sky"Greg Egan,
"Diaspora"Joe Haldeman, "Forever Peace"(There are surely many
others.)Incidentally, the nature of science fiction itself has changed.
Decades ago, science fiction projected great increases in the power humans
control (example: E.E. Smith Lensman series). That didn't really happen in the
last 50 years. Instead, we gradually refined the degree to whi</p><p>6 0.60932916 <a title="366-lsi-6" href="../hunch_net-2005/hunch_net-2005-11-05-The_design_of_a_computing_cluster.html">128 hunch net-2005-11-05-The design of a computing cluster</a></p>
<p>7 0.60272461 <a title="366-lsi-7" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>8 0.60089469 <a title="366-lsi-8" href="../hunch_net-2006/hunch_net-2006-12-05-Recruitment_Conferences.html">222 hunch net-2006-12-05-Recruitment Conferences</a></p>
<p>9 0.59216744 <a title="366-lsi-9" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>10 0.59094226 <a title="366-lsi-10" href="../hunch_net-2005/hunch_net-2005-05-11-Visa_Casualties.html">69 hunch net-2005-05-11-Visa Casualties</a></p>
<p>11 0.57437199 <a title="366-lsi-11" href="../hunch_net-2007/hunch_net-2007-07-13-The_View_From_China.html">255 hunch net-2007-07-13-The View From China</a></p>
<p>12 0.57314205 <a title="366-lsi-12" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>13 0.56070417 <a title="366-lsi-13" href="../hunch_net-2009/hunch_net-2009-03-18-Parallel_ML_primitives.html">346 hunch net-2009-03-18-Parallel ML primitives</a></p>
<p>14 0.55992562 <a title="366-lsi-14" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>15 0.5476191 <a title="366-lsi-15" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>16 0.54532713 <a title="366-lsi-16" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>17 0.54270363 <a title="366-lsi-17" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>18 0.53808427 <a title="366-lsi-18" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>19 0.53316057 <a title="366-lsi-19" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>20 0.52987534 <a title="366-lsi-20" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.054), (42, 0.201), (45, 0.086), (48, 0.266), (50, 0.011), (61, 0.011), (68, 0.086), (69, 0.032), (74, 0.111), (82, 0.015), (95, 0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.92752117 <a title="366-lda-1" href="../hunch_net-2005/hunch_net-2005-04-27-DARPA_project%3A_LAGR.html">63 hunch net-2005-04-27-DARPA project: LAGR</a></p>
<p>Introduction: Larry Jackal has set up theLAGR("Learning Applied to Ground Robotics") project
(and competition) which seems to be quite well designed. Features include:Many
participants (8 going on 12?)Standardized hardware. In theDARPA grand
challengecontestants entering with motorcycles are at a severe disadvantage to
those entering with a Hummer. Similarly, contestants using more powerful
sensors can gain huge advantages.Monthly contests, with full feedback (but
since the hardware is standardized, only code is shipped). One of the premises
of the program is that robust systems are desired. Monthly evaluations at
different locations can help measure this and provide data.Attacks a known
hard problem. (cross country driving)</p><p>2 0.90400809 <a title="366-lda-2" href="../hunch_net-2005/hunch_net-2005-04-14-Families_of_Learning_Theory_Statements.html">56 hunch net-2005-04-14-Families of Learning Theory Statements</a></p>
<p>Introduction: The diagram above shows a very broad viewpoint of learning theory.arrowTypical
statementExamplesPast->PastSome prediction algorithmAdoes almost as well as
any of a set of algorithms.Weighted MajorityPast->FutureAssuming independent
samples, past performance predicts future performance.PAC analysis, ERM
analysisFuture->FutureFuture prediction performance on subproblems implies
future prediction performance using algorithmA.ECOC, ProbingA basic question
is: Are there other varieties of statements of this type?Avrimnoted that there
are also "arrows between arrows": generic methods for transforming between
Past->Past statements and Past->Future statements. Are there others?</p><p>3 0.89822525 <a title="366-lda-3" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>Introduction: Virtually every discipline of significant human endeavor has a way explaining
itself as fundamental and important. In all the cases I know of, they are both
right (they are vital) and wrong (they are not solely vital).Politics. This is
the one that everyone is familiar with at the moment. "What could be more
important than the process of making decisions?"Science and Technology. This
is the one that we-the-academics are familiar with. "The loss of modern
science and technology would be catastrophic."Military. "Without the military,
a nation will be invaded and destroyed."(insert your favorite here)Within
science and technology, the same thing happens again.Mathematics. "What could
be more important than a precise language for establishing truths?"Physics.
"Nothing is more fundamental than the laws which govern the universe.
Understanding them is the key to understanding everything else."Biology.
"Without life, we wouldn't be here, so clearly the study of life is
fundamental."Computer S</p><p>4 0.88577366 <a title="366-lda-4" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>Introduction: Machine learning is often computationally bounded which implies that the
ability to write fast code becomes important if you ever want to implement a
machine learning algorithm. Basic tactical optimizations are covered
wellelsewhere, but I haven't seen a reasonable guide to higher level
optimizations, which are the most important in my experience. Here are some of
the higher level optimizations I've often found useful.Algorithmic Improvement
First. This is Hard, but it is the most important consideration, and typically
yields the most benefits. Good optimizations here are publishable. In the
context of machine learning, you should be familiar with the arguments for
online vs. batch learning.Choice of Language. There are many arguments about
thechoice of language. Sometimes you don't have a choice when interfacing with
other people. Personally, I favor C/C++ when I want to write fast code. This
(admittedly) makes me a slower programmer than when using higher level
languages. (Sometimes</p><p>same-blog 5 0.86858934 <a title="366-lda-5" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>Introduction: Al Gore'sfilmand gradually more assertive and thorough science has managed to
mostly shift the debate on climate change from "Is it happening?" to "What
should be done?" In that context, it's worthwhile to think a bit about what
can be done within computer science research.There are two things we can think
about:Doing ResearchAt a cartoon level, computer science research consists of
some combination of commuting to&from; work, writing programs, running them on
computers, writing papers, and presenting them at conferences. A typical
computer has a power usage on the order of 100 Watts, which works out to 2.4
kiloWatt-hours/day. Looking upDavid MacKay'sreference on power usage per
person, it becomes clear that this is a relatively minor part of the
lifestyle, although it could become substantial if many more computers are
required. Much larger costs are associated with commuting (which is in common
with many people) and attending conferences. Since local commuting is common
across many pe</p><p>6 0.86206794 <a title="366-lda-6" href="../hunch_net-2005/hunch_net-2005-05-17-A_Short_Guide_to_PhD_Graduate_Study.html">73 hunch net-2005-05-17-A Short Guide to PhD Graduate Study</a></p>
<p>7 0.69604504 <a title="366-lda-7" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>8 0.69171005 <a title="366-lda-8" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>9 0.68582827 <a title="366-lda-9" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>10 0.68129176 <a title="366-lda-10" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>11 0.67941052 <a title="366-lda-11" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>12 0.67497027 <a title="366-lda-12" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>13 0.67343336 <a title="366-lda-13" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>14 0.67311841 <a title="366-lda-14" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>15 0.67214525 <a title="366-lda-15" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>16 0.67188996 <a title="366-lda-16" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>17 0.67111236 <a title="366-lda-17" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>18 0.67027164 <a title="366-lda-18" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>19 0.66875696 <a title="366-lda-19" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>20 0.66829741 <a title="366-lda-20" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
