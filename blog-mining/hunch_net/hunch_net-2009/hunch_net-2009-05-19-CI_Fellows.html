<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>355 hunch net-2009-05-19-CI Fellows</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-355" href="#">hunch_net-2009-355</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>355 hunch net-2009-05-19-CI Fellows</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-355-html" href="http://hunch.net/?p=748">html</a></p><p>Introduction: Lev Reyzinpoints out theCI Fellows Project. Essentially,NSFis funding 60
postdocs in computer science for graduates from a wide array of US places to a
wide array of US places. This is particularly welcome given a tough year for
new hires. I expect some fraction of these postdocs will be in ML. The time
frame is quite short, so those interested should look it over immediately.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('postdocs', 0.448), ('array', 0.352), ('wide', 0.319), ('reyzinpoints', 0.242), ('fellows', 0.224), ('lev', 0.224), ('theci', 0.224), ('tough', 0.211), ('graduates', 0.211), ('frame', 0.202), ('welcome', 0.181), ('us', 0.159), ('funding', 0.151), ('immediately', 0.148), ('places', 0.148), ('fraction', 0.139), ('short', 0.116), ('look', 0.109), ('computer', 0.108), ('science', 0.106)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="355-tfidf-1" href="../hunch_net-2009/hunch_net-2009-05-19-CI_Fellows.html">355 hunch net-2009-05-19-CI Fellows</a></p>
<p>Introduction: Lev Reyzinpoints out theCI Fellows Project. Essentially,NSFis funding 60
postdocs in computer science for graduates from a wide array of US places to a
wide array of US places. This is particularly welcome given a tough year for
new hires. I expect some fraction of these postdocs will be in ML. The time
frame is quite short, so those interested should look it over immediately.</p><p>2 0.46310371 <a title="355-tfidf-2" href="../hunch_net-2010/hunch_net-2010-04-28-CI_Fellows_program_renewed.html">396 hunch net-2010-04-28-CI Fellows program renewed</a></p>
<p>Introduction: Lev Reyzinpoints out theCI Fellows program is renewed. CI Fellows are
essentiallyNSFfunded computer science postdocs for universities and industry
research labs. I've been lucky and happy to have Lev visit me for a year
underlast year's program, so I strongly recommend participating if it suits
you.As with last year, the application timeline is very short, with everything
due by May 23.</p><p>3 0.25080279 <a title="355-tfidf-3" href="../hunch_net-2011/hunch_net-2011-05-09-CI_Fellows%2C_again.html">434 hunch net-2011-05-09-CI Fellows, again</a></p>
<p>Introduction: LevandHalpoint out theCI Fellowsprogram is on again for this year. Lev visited
me for a year under this program, and I quite enjoyed it. Due May 31.</p><p>4 0.14791439 <a title="355-tfidf-4" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>Introduction: Forhiswork on the subject of human computation includingESPGame,Peekaboom,
andPhetch. Thenew MacArthur fellows.</p><p>5 0.11160655 <a title="355-tfidf-5" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>Introduction: With a worldwide recession on, my impression is that the carnage in research
has not been as severe as might be feared, at least in the United States. I
know of two notable negative impacts:It's quite difficult to get a job this
year, as many companies and universities simply aren't hiring. This is
particularly tough on graduating students.Perhaps 10% ofIBM researchwas
fired.In contrast, around the time of the dot com bust,ATnT
ResearchandLucenthad one or several 50% size firings wiping out much of the
remainder ofBell Labs, triggering a notable diaspora for the respected machine
learning group there. As the recession progresses, we may easily see more
firings as companies in particular reach a point where they can no longer
support research.There are a couple positives to the recession as well.Both
the implosion of Wall Street (which siphoned off smart people) and the general
difficulty of getting a job coming out of an undergraduate education suggest
that the quality of admitted phd</p><p>6 0.11015731 <a title="355-tfidf-6" href="../hunch_net-2011/hunch_net-2011-08-20-The_Large_Scale_Learning_Survey_Tutorial.html">442 hunch net-2011-08-20-The Large Scale Learning Survey Tutorial</a></p>
<p>7 0.087768018 <a title="355-tfidf-7" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>8 0.087443404 <a title="355-tfidf-8" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>9 0.083674096 <a title="355-tfidf-9" href="../hunch_net-2008/hunch_net-2008-11-28-A_Bumper_Crop_of_Machine_Learning_Graduates.html">329 hunch net-2008-11-28-A Bumper Crop of Machine Learning Graduates</a></p>
<p>10 0.076346546 <a title="355-tfidf-10" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>11 0.070641398 <a title="355-tfidf-11" href="../hunch_net-2010/hunch_net-2010-10-28-NY_ML_Symposium_2010.html">415 hunch net-2010-10-28-NY ML Symposium 2010</a></p>
<p>12 0.06752526 <a title="355-tfidf-12" href="../hunch_net-2013/hunch_net-2013-11-09-Graduates_and_Postdocs.html">490 hunch net-2013-11-09-Graduates and Postdocs</a></p>
<p>13 0.067222603 <a title="355-tfidf-13" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>14 0.066257492 <a title="355-tfidf-14" href="../hunch_net-2010/hunch_net-2010-11-18-ICML_2011_%26%238211%3B_Call_for_Tutorials.html">417 hunch net-2010-11-18-ICML 2011 &#8211; Call for Tutorials</a></p>
<p>15 0.064768381 <a title="355-tfidf-15" href="../hunch_net-2006/hunch_net-2006-02-04-Research_Budget_Changes.html">154 hunch net-2006-02-04-Research Budget Changes</a></p>
<p>16 0.06444633 <a title="355-tfidf-16" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>17 0.056303732 <a title="355-tfidf-17" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>18 0.052359086 <a title="355-tfidf-18" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>19 0.052145436 <a title="355-tfidf-19" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>20 0.050815266 <a title="355-tfidf-20" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.072), (1, 0.054), (2, 0.101), (3, 0.015), (4, 0.041), (5, -0.013), (6, 0.027), (7, 0.046), (8, 0.038), (9, -0.134), (10, 0.15), (11, 0.081), (12, -0.061), (13, -0.205), (14, 0.271), (15, 0.072), (16, 0.214), (17, 0.017), (18, 0.084), (19, 0.152), (20, -0.075), (21, 0.151), (22, 0.135), (23, 0.096), (24, -0.119), (25, 0.011), (26, -0.145), (27, 0.074), (28, 0.054), (29, -0.129), (30, -0.031), (31, -0.012), (32, -0.088), (33, -0.011), (34, -0.069), (35, -0.057), (36, 0.046), (37, 0.067), (38, -0.019), (39, -0.002), (40, -0.089), (41, 0.046), (42, 0.004), (43, -0.034), (44, 0.007), (45, -0.002), (46, 0.013), (47, -0.012), (48, 0.071), (49, -0.008)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98842752 <a title="355-lsi-1" href="../hunch_net-2009/hunch_net-2009-05-19-CI_Fellows.html">355 hunch net-2009-05-19-CI Fellows</a></p>
<p>Introduction: Lev Reyzinpoints out theCI Fellows Project. Essentially,NSFis funding 60
postdocs in computer science for graduates from a wide array of US places to a
wide array of US places. This is particularly welcome given a tough year for
new hires. I expect some fraction of these postdocs will be in ML. The time
frame is quite short, so those interested should look it over immediately.</p><p>2 0.93902081 <a title="355-lsi-2" href="../hunch_net-2010/hunch_net-2010-04-28-CI_Fellows_program_renewed.html">396 hunch net-2010-04-28-CI Fellows program renewed</a></p>
<p>Introduction: Lev Reyzinpoints out theCI Fellows program is renewed. CI Fellows are
essentiallyNSFfunded computer science postdocs for universities and industry
research labs. I've been lucky and happy to have Lev visit me for a year
underlast year's program, so I strongly recommend participating if it suits
you.As with last year, the application timeline is very short, with everything
due by May 23.</p><p>3 0.87083268 <a title="355-lsi-3" href="../hunch_net-2011/hunch_net-2011-05-09-CI_Fellows%2C_again.html">434 hunch net-2011-05-09-CI Fellows, again</a></p>
<p>Introduction: LevandHalpoint out theCI Fellowsprogram is on again for this year. Lev visited
me for a year under this program, and I quite enjoyed it. Due May 31.</p><p>4 0.54725391 <a title="355-lsi-4" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>Introduction: Forhiswork on the subject of human computation includingESPGame,Peekaboom,
andPhetch. Thenew MacArthur fellows.</p><p>5 0.36577335 <a title="355-lsi-5" href="../hunch_net-2005/hunch_net-2005-02-10-Conferences%2C_Dates%2C_Locations.html">17 hunch net-2005-02-10-Conferences, Dates, Locations</a></p>
<p>Introduction: ConferenceLocateDateCOLTBertinoro, ItalyJune 27-30AAAIPittsburgh, PA, USAJuly
9-13UAIEdinburgh, ScotlandJuly 26-29IJCAIEdinburgh, ScotlandJuly 30 - August
5ICMLBonn, GermanyAugust 7-11KDDChicago, IL, USAAugust 21-24The big winner
this year is Europe. This is partly a coincidence, and partly due to the
general internationalization of science over the last few years. Withcuts to
basic sciencein the US and increased hassle for visitors, conferences outside
the US become more attractive. Europe and Australia/New Zealand are the
immediate winners because they have the science, infrastructure, and english
in place. China and India are possible future winners.</p><p>6 0.35307091 <a title="355-lsi-6" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>7 0.34542164 <a title="355-lsi-7" href="../hunch_net-2012/hunch_net-2012-07-17-MUCMD_and_BayLearn.html">470 hunch net-2012-07-17-MUCMD and BayLearn</a></p>
<p>8 0.32761049 <a title="355-lsi-8" href="../hunch_net-2005/hunch_net-2005-09-06-A_link.html">108 hunch net-2005-09-06-A link</a></p>
<p>9 0.30162975 <a title="355-lsi-9" href="../hunch_net-2010/hunch_net-2010-08-20-The_Workshop_on_Cores%2C_Clusters%2C_and_Clouds.html">404 hunch net-2010-08-20-The Workshop on Cores, Clusters, and Clouds</a></p>
<p>10 0.27428371 <a title="355-lsi-10" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>11 0.26763177 <a title="355-lsi-11" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>12 0.2605513 <a title="355-lsi-12" href="../hunch_net-2006/hunch_net-2006-01-08-Debugging_Your_Brain.html">147 hunch net-2006-01-08-Debugging Your Brain</a></p>
<p>13 0.25971648 <a title="355-lsi-13" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>14 0.25239247 <a title="355-lsi-14" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>15 0.25050271 <a title="355-lsi-15" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>16 0.25003746 <a title="355-lsi-16" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>17 0.24344113 <a title="355-lsi-17" href="../hunch_net-2005/hunch_net-2005-02-02-Kolmogorov_Complexity_and_Googling.html">10 hunch net-2005-02-02-Kolmogorov Complexity and Googling</a></p>
<p>18 0.23786788 <a title="355-lsi-18" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>19 0.22789414 <a title="355-lsi-19" href="../hunch_net-2010/hunch_net-2010-10-17-Partha_Niyogi_has_died.html">414 hunch net-2010-10-17-Partha Niyogi has died</a></p>
<p>20 0.22613655 <a title="355-lsi-20" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.061), (42, 0.149), (80, 0.616)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95172542 <a title="355-lda-1" href="../hunch_net-2009/hunch_net-2009-05-19-CI_Fellows.html">355 hunch net-2009-05-19-CI Fellows</a></p>
<p>Introduction: Lev Reyzinpoints out theCI Fellows Project. Essentially,NSFis funding 60
postdocs in computer science for graduates from a wide array of US places to a
wide array of US places. This is particularly welcome given a tough year for
new hires. I expect some fraction of these postdocs will be in ML. The time
frame is quite short, so those interested should look it over immediately.</p><p>2 0.86496753 <a title="355-lda-2" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>Introduction: Several people have had difficulty with comments which seem to have an allowed
language significantly poorer than posts. The set of allowed html tags has
been increased and themarkdown filterhas been put in place to try to make
commenting easier. I'll put some examples into the comments of this post.</p><p>3 0.42443821 <a title="355-lda-3" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>Introduction: Maybe it's too early to call, but with four separate Neural Network sessions
at this year'sICML, it looks like Neural Networks are making a comeback. Here
are my highlights of these sessions. In general, my feeling is that these
papers both demystify deep learning and show its broader applicability.The
first observation I made is that the once disreputable "Neural" nomenclature
is being used againin lieu of"deep learning". Maybe it's because Adam Coates
et al. showed that single layer networks can work surprisingly well.An
Analysis of Single-Layer Networks in Unsupervised Feature Learning,Adam
Coates,Honglak Lee,Andrew Y. Ng(AISTATS 2011)The Importance of Encoding Versus
Training with Sparse Coding and Vector Quantization,Adam Coates,Andrew Y.
Ng(ICML 2011)Another surprising result out of Andrew Ng's group comes from
Andrew Saxe et al. who show that certain convolutional pooling architectures
can obtain close to state-of-the-art performance with random weights (that is,
without actuall</p><p>4 0.41755509 <a title="355-lda-4" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>Introduction: Manifold based dimension-reduction algorithms share the following general
outline.Given: a metricd()and a set of pointsSConstruct a graph with a point
in every node and every edge connecting to the node of one of thek-nearest
neighbors. Associate with the edge a weight which is the distance between the
points in the connected nodes.Digest the graph. This might include computing
the shortest path between all points or figuring out how to linearly
interpolate the point from it's neighbors.Find a set of points in a low
dimensional space which preserve the digested properties.Examples include LLE,
Isomap (which I worked on), Hessian-LLE, SDE, and many others. The hope with
these algorithms is that they can recover the low dimensional structure of
point sets in high dimensional spaces. Many of them can be shown to work in
interesting ways producing various compelling pictures.Despite doing some
early work in this direction, I suffer from a motivational problem: Why do we
want to recover the</p><p>5 0.35761195 <a title="355-lda-5" href="../hunch_net-2011/hunch_net-2011-08-20-The_Large_Scale_Learning_Survey_Tutorial.html">442 hunch net-2011-08-20-The Large Scale Learning Survey Tutorial</a></p>
<p>Introduction: Ron Bekkermaninitiated an effort to create anedited book on parallel machine
learningthatMishaand I have been helping with. The breadth of efforts to
parallelize machine learning surprised me: I was only aware of a small
fraction initially.This put us in a unique position, with knowledge of a wide
array of different efforts, so it is natural to put together asurvey tutorial
on the subject of parallel learningforKDD, tomorrow. This tutorial
isnotlimited to the book itself however, as several interesting new algorithms
have come out since we started inviting chapters.This tutorial should interest
anyone trying to use machine learning on significant quantities of data,
anyone interested in developing algorithms for such, and of course who has
bragging rights to the fastest learning algorithm on planet earth(Also note
the Modeling with Hadoop tutorial just before ours which deals with one way of
trying to speed up learning algorithms. We have almost no overlap.)</p><p>6 0.35501483 <a title="355-lda-6" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>7 0.26641285 <a title="355-lda-7" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>8 0.24032025 <a title="355-lda-8" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>9 0.24022999 <a title="355-lda-9" href="../hunch_net-2013/hunch_net-2013-11-09-Graduates_and_Postdocs.html">490 hunch net-2013-11-09-Graduates and Postdocs</a></p>
<p>10 0.23995 <a title="355-lda-10" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>11 0.23901738 <a title="355-lda-11" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>12 0.23827587 <a title="355-lda-12" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>13 0.23793903 <a title="355-lda-13" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>14 0.23725674 <a title="355-lda-14" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>15 0.23709372 <a title="355-lda-15" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>16 0.23654531 <a title="355-lda-16" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>17 0.23595794 <a title="355-lda-17" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>18 0.23522951 <a title="355-lda-18" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>19 0.23476273 <a title="355-lda-19" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>20 0.23463793 <a title="355-lda-20" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
