<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>355 hunch net-2009-05-19-CI Fellows</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-355" href="#">hunch_net-2009-355</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>355 hunch net-2009-05-19-CI Fellows</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-355-html" href="http://hunch.net/?p=748">html</a></p><p>Introduction: Lev Reyzin  points out the  CI Fellows Project .  Essentially,  NSF  is funding 60 postdocs in computer science for graduates from a wide array of US places to a wide array of US places.  This is particularly welcome given a tough year for new hires.  I expect some fraction of these postdocs will be in ML.  The time frame is quite short, so those interested should look it over immediately.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Essentially,  NSF  is funding 60 postdocs in computer science for graduates from a wide array of US places to a wide array of US places. [sent-2, score-2.449]
</p><p>2 This is particularly welcome given a tough year for new hires. [sent-3, score-0.643]
</p><p>3 I expect some fraction of these postdocs will be in ML. [sent-4, score-0.65]
</p><p>4 The time frame is quite short, so those interested should look it over immediately. [sent-5, score-0.505]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('postdocs', 0.42), ('array', 0.349), ('wide', 0.31), ('reyzin', 0.222), ('ci', 0.222), ('lev', 0.21), ('tough', 0.21), ('fellows', 0.21), ('graduates', 0.21), ('frame', 0.2), ('nsf', 0.174), ('welcome', 0.174), ('us', 0.156), ('funding', 0.149), ('immediately', 0.147), ('places', 0.144), ('fraction', 0.138), ('project', 0.136), ('short', 0.114), ('look', 0.107), ('computer', 0.106), ('science', 0.102), ('points', 0.097), ('expect', 0.092), ('essentially', 0.091), ('interested', 0.084), ('particularly', 0.077), ('year', 0.072), ('given', 0.067), ('quite', 0.066), ('time', 0.048), ('new', 0.043)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="355-tfidf-1" href="../hunch_net-2009/hunch_net-2009-05-19-CI_Fellows.html">355 hunch net-2009-05-19-CI Fellows</a></p>
<p>Introduction: Lev Reyzin  points out the  CI Fellows Project .  Essentially,  NSF  is funding 60 postdocs in computer science for graduates from a wide array of US places to a wide array of US places.  This is particularly welcome given a tough year for new hires.  I expect some fraction of these postdocs will be in ML.  The time frame is quite short, so those interested should look it over immediately.</p><p>2 0.46142039 <a title="355-tfidf-2" href="../hunch_net-2010/hunch_net-2010-04-28-CI_Fellows_program_renewed.html">396 hunch net-2010-04-28-CI Fellows program renewed</a></p>
<p>Introduction: Lev Reyzin  points out  the  CI Fellows program is renewed .  CI Fellows are essentially  NSF  funded computer science postdocs for universities and industry research labs.  I’ve been lucky and happy to have Lev visit me for a year under  last year’s program , so I strongly recommend participating if it suits you.
 
As with last year, the application timeline is very short, with everything due by May 23.</p><p>3 0.30294946 <a title="355-tfidf-3" href="../hunch_net-2011/hunch_net-2011-05-09-CI_Fellows%2C_again.html">434 hunch net-2011-05-09-CI Fellows, again</a></p>
<p>Introduction: Lev  and  Hal  point out the  CI Fellows  program is on again for this year.  Lev visited me for a year under this program, and I quite enjoyed it.  Due May 31.</p><p>4 0.11939208 <a title="355-tfidf-4" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>Introduction: With a worldwide recession on, my impression is that the carnage in research has not been as severe as might be feared, at least in the United States.  I know of two notable negative impacts: 
  
 It’s quite difficult to get a job this year, as many companies and universities simply aren’t hiring.  This is particularly tough on graduating students. 
 Perhaps 10% of  IBM research  was fired. 
  
In contrast, around the time of the dot com bust,  ATnT Research  and  Lucent  had one or several 50% size firings wiping out much of the remainder of  Bell Labs , triggering a notable diaspora for the respected machine learning group there.  As the recession progresses, we may easily see more firings as companies in particular reach a point where they can no longer support research.
 
There are a couple positives to the recession as well.
  
 Both the implosion of Wall Street (which siphoned off smart people) and the general difficulty of getting a job coming out of an undergraduate education s</p><p>5 0.10754648 <a title="355-tfidf-5" href="../hunch_net-2011/hunch_net-2011-08-20-The_Large_Scale_Learning_Survey_Tutorial.html">442 hunch net-2011-08-20-The Large Scale Learning Survey Tutorial</a></p>
<p>Introduction: Ron Bekkerman  initiated an effort to create an  edited book on parallel machine learning  that  Misha  and I have been helping with.  The breadth of efforts to parallelize machine learning surprised me: I was only aware of a small fraction initially.
 
This put us in a unique position, with knowledge of a wide array of different efforts, so it is natural to put together a  survey tutorial on the subject of parallel learning  for  KDD , tomorrow.  This tutorial is  not  limited to the book itself however, as several interesting new algorithms have come out since we started inviting chapters.  
 
This tutorial should interest anyone trying to use machine learning on significant quantities of data, anyone interested in developing algorithms for such, and of course who has bragging rights to the fastest learning algorithm on planet earth   
 
(Also note the Modeling with Hadoop tutorial just before ours which deals with one way of trying to speed up learning algorithms.  We have almost no</p><p>6 0.10597496 <a title="355-tfidf-6" href="../hunch_net-2006/hunch_net-2006-02-04-Research_Budget_Changes.html">154 hunch net-2006-02-04-Research Budget Changes</a></p>
<p>7 0.10485117 <a title="355-tfidf-7" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>8 0.10425753 <a title="355-tfidf-8" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>9 0.10366797 <a title="355-tfidf-9" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>10 0.097763345 <a title="355-tfidf-10" href="../hunch_net-2013/hunch_net-2013-11-09-Graduates_and_Postdocs.html">490 hunch net-2013-11-09-Graduates and Postdocs</a></p>
<p>11 0.085413918 <a title="355-tfidf-11" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>12 0.080806591 <a title="355-tfidf-12" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>13 0.079584047 <a title="355-tfidf-13" href="../hunch_net-2008/hunch_net-2008-11-28-A_Bumper_Crop_of_Machine_Learning_Graduates.html">329 hunch net-2008-11-28-A Bumper Crop of Machine Learning Graduates</a></p>
<p>14 0.069085598 <a title="355-tfidf-14" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>15 0.067455716 <a title="355-tfidf-15" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>16 0.063552797 <a title="355-tfidf-16" href="../hunch_net-2010/hunch_net-2010-10-28-NY_ML_Symposium_2010.html">415 hunch net-2010-10-28-NY ML Symposium 2010</a></p>
<p>17 0.062696137 <a title="355-tfidf-17" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>18 0.0598391 <a title="355-tfidf-18" href="../hunch_net-2010/hunch_net-2010-11-18-ICML_2011_%26%238211%3B_Call_for_Tutorials.html">417 hunch net-2010-11-18-ICML 2011 &#8211; Call for Tutorials</a></p>
<p>19 0.056156229 <a title="355-tfidf-19" href="../hunch_net-2013/hunch_net-2013-01-01-Deep_Learning_2012.html">477 hunch net-2013-01-01-Deep Learning 2012</a></p>
<p>20 0.052873902 <a title="355-tfidf-20" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.08), (1, -0.051), (2, -0.107), (3, 0.037), (4, -0.052), (5, -0.018), (6, -0.012), (7, 0.06), (8, -0.107), (9, -0.06), (10, 0.105), (11, -0.058), (12, -0.235), (13, -0.298), (14, -0.164), (15, -0.292), (16, 0.122), (17, -0.181), (18, -0.033), (19, 0.051), (20, -0.011), (21, -0.057), (22, 0.016), (23, -0.044), (24, -0.059), (25, -0.06), (26, -0.047), (27, -0.07), (28, -0.014), (29, 0.1), (30, -0.12), (31, 0.012), (32, 0.006), (33, -0.043), (34, 0.046), (35, -0.099), (36, 0.069), (37, 0.033), (38, -0.006), (39, 0.054), (40, -0.02), (41, -0.057), (42, -0.041), (43, -0.008), (44, 0.037), (45, -0.033), (46, 0.02), (47, 0.029), (48, -0.05), (49, -0.097)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98860848 <a title="355-lsi-1" href="../hunch_net-2009/hunch_net-2009-05-19-CI_Fellows.html">355 hunch net-2009-05-19-CI Fellows</a></p>
<p>Introduction: Lev Reyzin  points out the  CI Fellows Project .  Essentially,  NSF  is funding 60 postdocs in computer science for graduates from a wide array of US places to a wide array of US places.  This is particularly welcome given a tough year for new hires.  I expect some fraction of these postdocs will be in ML.  The time frame is quite short, so those interested should look it over immediately.</p><p>2 0.95470881 <a title="355-lsi-2" href="../hunch_net-2010/hunch_net-2010-04-28-CI_Fellows_program_renewed.html">396 hunch net-2010-04-28-CI Fellows program renewed</a></p>
<p>Introduction: Lev Reyzin  points out  the  CI Fellows program is renewed .  CI Fellows are essentially  NSF  funded computer science postdocs for universities and industry research labs.  I’ve been lucky and happy to have Lev visit me for a year under  last year’s program , so I strongly recommend participating if it suits you.
 
As with last year, the application timeline is very short, with everything due by May 23.</p><p>3 0.87325311 <a title="355-lsi-3" href="../hunch_net-2011/hunch_net-2011-05-09-CI_Fellows%2C_again.html">434 hunch net-2011-05-09-CI Fellows, again</a></p>
<p>Introduction: Lev  and  Hal  point out the  CI Fellows  program is on again for this year.  Lev visited me for a year under this program, and I quite enjoyed it.  Due May 31.</p><p>4 0.40150571 <a title="355-lsi-4" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>Introduction: The New York Times has an interesting  article  about how DARPA has dropped funding for computer science to universities by about a factor of 2 over the last 5 years and become less directed towards basic research.  Partially in response, the number of grant submissions to NSF has grown by a factor of 3 (with the NSF budget staying approximately constant in the interim).
 
This is the sort of policy decision which may make sense for the defense department, but which means a large hit for basic research on information technology development in the US.  For example “darpa funded the invention of the internet” is reasonably correct.  This policy decision is particularly painful in the context of NSF budget cuts and the end of extensive phone monopoly funded research at Bell labs. 
 
The good news from a learning perspective is that (based on anecdotal evidence) much of the remaining funding is aimed at learning and learning-related fields.  Methods of making good automated predictions obv</p><p>5 0.38322887 <a title="355-lsi-5" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>Introduction: For  his  work on the subject of human computation including  ESPGame ,  Peekaboom , and  Phetch .  The  new MacArthur fellows .</p><p>6 0.36830387 <a title="355-lsi-6" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>7 0.31767926 <a title="355-lsi-7" href="../hunch_net-2006/hunch_net-2006-02-04-Research_Budget_Changes.html">154 hunch net-2006-02-04-Research Budget Changes</a></p>
<p>8 0.29772973 <a title="355-lsi-8" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>9 0.29045838 <a title="355-lsi-9" href="../hunch_net-2012/hunch_net-2012-07-17-MUCMD_and_BayLearn.html">470 hunch net-2012-07-17-MUCMD and BayLearn</a></p>
<p>10 0.24540189 <a title="355-lsi-10" href="../hunch_net-2013/hunch_net-2013-01-01-Deep_Learning_2012.html">477 hunch net-2013-01-01-Deep Learning 2012</a></p>
<p>11 0.24408293 <a title="355-lsi-11" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>12 0.24337789 <a title="355-lsi-12" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>13 0.23812136 <a title="355-lsi-13" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>14 0.23726533 <a title="355-lsi-14" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>15 0.23640727 <a title="355-lsi-15" href="../hunch_net-2006/hunch_net-2006-01-08-Debugging_Your_Brain.html">147 hunch net-2006-01-08-Debugging Your Brain</a></p>
<p>16 0.23560892 <a title="355-lsi-16" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>17 0.22765093 <a title="355-lsi-17" href="../hunch_net-2011/hunch_net-2011-01-03-Herman_Goldstine_2011.html">421 hunch net-2011-01-03-Herman Goldstine 2011</a></p>
<p>18 0.22560957 <a title="355-lsi-18" href="../hunch_net-2012/hunch_net-2012-03-13-The_Submodularity_workshop_and_Lucca_Professorship.html">459 hunch net-2012-03-13-The Submodularity workshop and Lucca Professorship</a></p>
<p>19 0.22340503 <a title="355-lsi-19" href="../hunch_net-2010/hunch_net-2010-10-17-Partha_Niyogi_has_died.html">414 hunch net-2010-10-17-Partha Niyogi has died</a></p>
<p>20 0.21787836 <a title="355-lsi-20" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(7, 0.541), (27, 0.067), (55, 0.092), (95, 0.138)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94815153 <a title="355-lda-1" href="../hunch_net-2009/hunch_net-2009-05-19-CI_Fellows.html">355 hunch net-2009-05-19-CI Fellows</a></p>
<p>Introduction: Lev Reyzin  points out the  CI Fellows Project .  Essentially,  NSF  is funding 60 postdocs in computer science for graduates from a wide array of US places to a wide array of US places.  This is particularly welcome given a tough year for new hires.  I expect some fraction of these postdocs will be in ML.  The time frame is quite short, so those interested should look it over immediately.</p><p>2 0.85393047 <a title="355-lda-2" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>Introduction: For  his  work on the subject of human computation including  ESPGame ,  Peekaboom , and  Phetch .  The  new MacArthur fellows .</p><p>3 0.73757041 <a title="355-lda-3" href="../hunch_net-2006/hunch_net-2006-06-15-IJCAI_is_out_of_season.html">184 hunch net-2006-06-15-IJCAI is out of season</a></p>
<p>Introduction: IJCAI  is running January 6-12 in Hyderabad India rather than a more traditional summer date. (Presumably, this is to avoid melting people in the Indian summer.)
 
The paper deadline(June 23 abstract / June 30 submission) are particularly inconvenient if you attend  COLT  or  ICML .  But on the other hand, itâ&euro;&trade;s a good excuse to visit India.</p><p>4 0.58109945 <a title="355-lda-4" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>Introduction: I thought this was a very good NIPS with many excellent papers. The following are a few NIPS papers which I liked and I hope to study more carefully when I get the chance. The list is not exhaustive and in no particular order…
  
 Preconditioner Approximations for Probabilistic Graphical Models. 
Pradeeep Ravikumar and John Lafferty. 
I thought the use of preconditioner methods from solving linear systems in the context of approximate inference was novel and interesting. The results look good and I’d like to understand the limitations.
 
 Rodeo: Sparse nonparametric regression in high dimensions. 
John Lafferty and Larry Wasserman. 
A very interesting approach to feature selection in nonparametric regression from a frequentist framework. The use of lengthscale variables in each dimension reminds me a lot of  ‘Automatic Relevance Determination’ in Gaussian process regression — it would be interesting to compare Rodeo to ARD in GPs.
 
 Interpolating between types and tokens by estimating</p><p>5 0.33886442 <a title="355-lda-5" href="../hunch_net-2010/hunch_net-2010-04-28-CI_Fellows_program_renewed.html">396 hunch net-2010-04-28-CI Fellows program renewed</a></p>
<p>Introduction: Lev Reyzin  points out  the  CI Fellows program is renewed .  CI Fellows are essentially  NSF  funded computer science postdocs for universities and industry research labs.  I’ve been lucky and happy to have Lev visit me for a year under  last year’s program , so I strongly recommend participating if it suits you.
 
As with last year, the application timeline is very short, with everything due by May 23.</p><p>6 0.30034608 <a title="355-lda-6" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>7 0.29760718 <a title="355-lda-7" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>8 0.29587954 <a title="355-lda-8" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>9 0.28440827 <a title="355-lda-9" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>10 0.28274521 <a title="355-lda-10" href="../hunch_net-2012/hunch_net-2012-02-24-ICML%2B50%25.html">456 hunch net-2012-02-24-ICML+50%</a></p>
<p>11 0.27723205 <a title="355-lda-11" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>12 0.27407169 <a title="355-lda-12" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>13 0.27277583 <a title="355-lda-13" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>14 0.27250099 <a title="355-lda-14" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>15 0.27059656 <a title="355-lda-15" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>16 0.26852971 <a title="355-lda-16" href="../hunch_net-2008/hunch_net-2008-10-01-NIPS_2008_workshop_on_%26%238216%3BLearning_over_Empirical_Hypothesis_Spaces%26%238217%3B.html">319 hunch net-2008-10-01-NIPS 2008 workshop on &#8216;Learning over Empirical Hypothesis Spaces&#8217;</a></p>
<p>17 0.26111367 <a title="355-lda-17" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>18 0.24047759 <a title="355-lda-18" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>19 0.23464662 <a title="355-lda-19" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>20 0.23129998 <a title="355-lda-20" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
