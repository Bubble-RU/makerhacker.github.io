<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>380 hunch net-2009-11-29-AI Safety</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2009" href="../home/hunch_net-2009_home.html">hunch_net-2009</a> <a title="hunch_net-2009-380" href="#">hunch_net-2009-380</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>380 hunch net-2009-11-29-AI Safety</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2009-380-html" href="http://hunch.net/?p=1053">html</a></p><p>Introduction: Dan Reevesintroduced me toMichael Vassarwho ran theSingularity Summitand
educated me a bit on the subject of AI safety which theSingularity
Institutehassmall grants for.I still believe thatinterstellar space travel is
necessary for long term civilization survival, and the AI is necessary for
interstellar space travel. On these grounds alone, we could judge that
developing AI is much more safe than not. Nevertheless, there is a basic
reasonable fear, as expressed by some commenters, that AI could go bad.A basic
scenario starts with someone inventing an AI and telling it to make as much
money as possible. The AI promptly starts trading in various markets to make
money. To improve, it crafts a virus that takes over most of the world's
computers using it as a surveillance network so that it can always make the
right decision. The AI also branches out into any form of distance work,
taking over the entire outsourcing process for all jobs that are entirely
digital. To further improve, the AI</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I still believe thatinterstellar space travel is necessary for long term civilization survival, and the AI is necessary for interstellar space travel. [sent-2, score-0.515]
</p><p>2 A basic scenario starts with someone inventing an AI and telling it to make as much money as possible. [sent-5, score-0.3]
</p><p>3 The AI promptly starts trading in various markets to make money. [sent-6, score-0.343]
</p><p>4 To improve, it crafts a virus that takes over most of the world's computers using it as a surveillance network so that it can always make the right decision. [sent-7, score-0.196]
</p><p>5 The AI also branches out into any form of distance work, taking over the entire outsourcing process for all jobs that are entirely digital. [sent-8, score-0.127]
</p><p>6 Robot cars and construction teams complete the process, so that any human with money can order anything cheaply and quickly, but no jobs remain for humans. [sent-10, score-0.246]
</p><p>7 At this point, the AI is stuck--it can eventually extract all the money from the economic system, and that's all there is. [sent-11, score-0.176]
</p><p>8 It simply funds appropriate political campaigns so that in some country a measure passes granting the AI the right to make money, which it promptly does, mushrooming it's wealth from trillions to the maximum number representable in all computers simultaneously. [sent-13, score-0.448]
</p><p>9 To remove this obstacle, the AI promptly starts making more computers on a worldwide scale until all available power sources are used up. [sent-14, score-0.48]
</p><p>10 To add more power, the AI starts a space program with beamed power. [sent-15, score-0.289]
</p><p>11 Unfortunately, it finds the pesky atmosphere an obstacle to space travel, so it chemically binds the atmosphere in the crust of the earth allowing manyGauss Gunsto efficiently project material into space wheresolar sailsare used for orbital positioning. [sent-16, score-0.903]
</p><p>12 This process continues, slowed perhaps by the need to cool the Earth's core, until the earth and other viable rocky bodies in the solar system are discorporated into aDyson sphere. [sent-17, score-0.348]
</p><p>13 Somewhere in this process, certainly by the time the atmosphere is chemically bound, all life on earth (except the AI if you count it) is extinct. [sent-19, score-0.437]
</p><p>14 One element of understanding AI safety seems to be understanding what an AI could do. [sent-21, score-0.15]
</p><p>15 The general problem is related to the wish problem: How do you specify a wish in a manner so that it can't be misinterpreted? [sent-25, score-0.255]
</p><p>16 Applied to AI, this approach also has limits because any limit imposed by a person can and eventually will be removed by a person given sufficient opportunity. [sent-27, score-0.222]
</p><p>17 Applied to AI, the idea would be that we make many AIs programmed to behave well either via laws or wish tricks, with an additional element of aggressively enforcing this behavior in other AIs. [sent-31, score-0.572]
</p><p>18 There must be multiple AIs, and (more importantly) the resources any one controls must be a small compared to all, an extreme form of antimonopoly. [sent-34, score-0.126]
</p><p>19 Furthermore, the default must be that AIs are programmed to not harm or cause harm to humans, enforcing that behavior in other AIs. [sent-35, score-0.44]
</p><p>20 Getting the programming right is the hard part, and I'm not clear on how viable this is, or how difficult it is compared to simply creating an AI, which of course I haven't managed. [sent-36, score-0.178]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ai', 0.671), ('ais', 0.211), ('earth', 0.174), ('atmosphere', 0.158), ('promptly', 0.158), ('starts', 0.133), ('money', 0.115), ('space', 0.107), ('chemically', 0.105), ('enforcing', 0.105), ('interstellar', 0.105), ('programmed', 0.105), ('wish', 0.099), ('obstacle', 0.094), ('thesingularity', 0.094), ('computers', 0.089), ('safety', 0.087), ('harm', 0.082), ('laws', 0.082), ('safe', 0.082), ('resources', 0.075), ('robotics', 0.072), ('jobs', 0.072), ('viable', 0.072), ('attack', 0.068), ('behavior', 0.066), ('travel', 0.066), ('necessary', 0.065), ('element', 0.063), ('imposed', 0.063), ('furthermore', 0.061), ('eventually', 0.061), ('anything', 0.059), ('manner', 0.057), ('right', 0.055), ('process', 0.055), ('constraints', 0.055), ('power', 0.053), ('make', 0.052), ('compared', 0.051), ('improve', 0.05), ('person', 0.049), ('add', 0.049), ('complementary', 0.047), ('corrupted', 0.047), ('funds', 0.047), ('granting', 0.047), ('solar', 0.047), ('tomichael', 0.047), ('worldwide', 0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="380-tfidf-1" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>Introduction: Dan Reevesintroduced me toMichael Vassarwho ran theSingularity Summitand
educated me a bit on the subject of AI safety which theSingularity
Institutehassmall grants for.I still believe thatinterstellar space travel is
necessary for long term civilization survival, and the AI is necessary for
interstellar space travel. On these grounds alone, we could judge that
developing AI is much more safe than not. Nevertheless, there is a basic
reasonable fear, as expressed by some commenters, that AI could go bad.A basic
scenario starts with someone inventing an AI and telling it to make as much
money as possible. The AI promptly starts trading in various markets to make
money. To improve, it crafts a virus that takes over most of the world's
computers using it as a surveillance network so that it can always make the
right decision. The AI also branches out into any form of distance work,
taking over the entire outsourcing process for all jobs that are entirely
digital. To further improve, the AI</p><p>2 0.35262829 <a title="380-tfidf-2" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>Introduction: Normally I do not blog, but John kindly invited me to do so. Since
computability issues play a major role in Artificial Intelligence and Machine
Learning, I would like to take the opportunity to comment on that and raise
some questions.The general attitude is that AI is about finding efficient
smart algorithms. For large parts of machine learning, the same attitude is
not too dangerous. If you want to concentrate on conceptual problems, simply
become a statistician. There is no analogous escape for modern research on AI
(as opposed toGOFAIrooted in logic).Let me show by analogy whylimiting
research to computational questions is bad for any field.Except in computer
science, computational aspects play little role in the development
offundamentaltheories: Consider e.g. set theory with axiom of choice,
foundations of logic, exact/full minimax for zero-sum games, quantum (field)
theory, string theory, â&euro;Ś Indeed, at least in physics, every new fundamental
theory seems to be less computable th</p><p>3 0.31556779 <a title="380-tfidf-3" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>Introduction: I recently had fun discussions with bothVikash MansinghkaandThomas Breuelabout
approaching AI with machine learning. The general interest in taking a crack
at AI with machine learning seems to be rising on many fronts
includingDARPA.As a matter of history, there was a great deal of interest in
AI which died down before I began research. There remain many projects and
conferences spawned in this earlier AI wave, as well as a good bit of
experience about what did not work, or at least did not work yet. Here are a
few examples of failure modes that people seem to run into:Supply/Product
confusion. Sometimes we think "Intelligences use X, so I'll create X and have
an Intelligence." An example of this is theCyc Projectwhich inspires some
people as "intelligences use ontologies, so I'll create an ontology and a
system using it to have an Intelligence." The flaw here is that
Intelligencescreateontologies, which they use, and without the ability to
create ontologies you don't have an Intellige</p><p>4 0.18111922 <a title="380-tfidf-4" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I've enjoyed theTerminatormovies and show. Neglecting the whacky aspects (time
travel and associated paradoxes), there is an enduring topic of discussion:
how do people deal with intelligent machines (and vice versa)?In Terminator-
land, the primary method for dealing with intelligent machines is to prevent
them from being made. This approach works pretty badly, because a new angle on
building an intelligent machine keeps coming up. This is partly a ploy for
writer's to avoid writing themselves out of a job, but there is a fundamental
truth to it as well: preventing progress in research is hard.The United
States, has been experimenting with trying to stop research onstem cells. It
hasn't worked very well--the net effect has been retarding research programs a
bit, and exporting some research to other countries. Another less recent
example was encryption technology, for which the United States generally did
not encourage early public research and evendiscouraged as a munition. This
slowe</p><p>5 0.13962027 <a title="380-tfidf-5" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>Introduction: Do we have computer hardware sufficient for AI? This question is difficult to
answer, but here's a try:One way to achieve AI is by simulating a human brain.
A human brain has about 1015synapses which operate at about 102per second
implying about 1017bit ops per second.A modern computer runs at
109cycles/second and operates on 102bits per cycle implying 1011bits processed
per second.The gap here is only 6 orders of magnitude, which can be plausibly
surpassed via cluster machines. For example, theBlueGene/Loperates 105nodes
(one order of magnitude short). It's peak recorded performance is about
0.5*1015FLOPS which translates to about 1016bit ops per second, which is
nearly 1017.There are many criticisms (both positive and negative) for this
argument.Simulation of a human brain might require substantially more detail.
Perhaps an additional 102is required per neuron.We may not need to simulate a
human brain to achieve AI. There are certainly many examples where we have
been able to design</p><p>6 0.12587522 <a title="380-tfidf-6" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>7 0.098486707 <a title="380-tfidf-7" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>8 0.093240298 <a title="380-tfidf-8" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>9 0.078910321 <a title="380-tfidf-9" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>10 0.074915856 <a title="380-tfidf-10" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>11 0.074348174 <a title="380-tfidf-11" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>12 0.074043356 <a title="380-tfidf-12" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>13 0.072921321 <a title="380-tfidf-13" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>14 0.071506217 <a title="380-tfidf-14" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>15 0.071293622 <a title="380-tfidf-15" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>16 0.070507169 <a title="380-tfidf-16" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>17 0.06875167 <a title="380-tfidf-17" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>18 0.059221763 <a title="380-tfidf-18" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>19 0.059159759 <a title="380-tfidf-19" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>20 0.059108004 <a title="380-tfidf-20" href="../hunch_net-2005/hunch_net-2005-09-20-Workshop_Proposal%3A_Atomic_Learning.html">114 hunch net-2005-09-20-Workshop Proposal: Atomic Learning</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.153), (1, -0.009), (2, 0.075), (3, -0.103), (4, 0.027), (5, 0.017), (6, -0.077), (7, 0.017), (8, 0.013), (9, 0.025), (10, -0.036), (11, 0.012), (12, 0.098), (13, -0.081), (14, 0.136), (15, 0.087), (16, -0.049), (17, 0.039), (18, -0.037), (19, -0.069), (20, -0.045), (21, 0.13), (22, -0.198), (23, 0.113), (24, 0.111), (25, -0.142), (26, 0.17), (27, -0.099), (28, 0.154), (29, 0.0), (30, 0.054), (31, 0.137), (32, 0.107), (33, 0.071), (34, -0.033), (35, 0.013), (36, 0.048), (37, -0.097), (38, 0.028), (39, 0.059), (40, -0.023), (41, 0.053), (42, -0.002), (43, -0.143), (44, 0.059), (45, -0.058), (46, 0.086), (47, -0.108), (48, 0.051), (49, -0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98686236 <a title="380-lsi-1" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>Introduction: Dan Reevesintroduced me toMichael Vassarwho ran theSingularity Summitand
educated me a bit on the subject of AI safety which theSingularity
Institutehassmall grants for.I still believe thatinterstellar space travel is
necessary for long term civilization survival, and the AI is necessary for
interstellar space travel. On these grounds alone, we could judge that
developing AI is much more safe than not. Nevertheless, there is a basic
reasonable fear, as expressed by some commenters, that AI could go bad.A basic
scenario starts with someone inventing an AI and telling it to make as much
money as possible. The AI promptly starts trading in various markets to make
money. To improve, it crafts a virus that takes over most of the world's
computers using it as a surveillance network so that it can always make the
right decision. The AI also branches out into any form of distance work,
taking over the entire outsourcing process for all jobs that are entirely
digital. To further improve, the AI</p><p>2 0.85220528 <a title="380-lsi-2" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>Introduction: Normally I do not blog, but John kindly invited me to do so. Since
computability issues play a major role in Artificial Intelligence and Machine
Learning, I would like to take the opportunity to comment on that and raise
some questions.The general attitude is that AI is about finding efficient
smart algorithms. For large parts of machine learning, the same attitude is
not too dangerous. If you want to concentrate on conceptual problems, simply
become a statistician. There is no analogous escape for modern research on AI
(as opposed toGOFAIrooted in logic).Let me show by analogy whylimiting
research to computational questions is bad for any field.Except in computer
science, computational aspects play little role in the development
offundamentaltheories: Consider e.g. set theory with axiom of choice,
foundations of logic, exact/full minimax for zero-sum games, quantum (field)
theory, string theory, â&euro;Ś Indeed, at least in physics, every new fundamental
theory seems to be less computable th</p><p>3 0.78137219 <a title="380-lsi-3" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>Introduction: Do we have computer hardware sufficient for AI? This question is difficult to
answer, but here's a try:One way to achieve AI is by simulating a human brain.
A human brain has about 1015synapses which operate at about 102per second
implying about 1017bit ops per second.A modern computer runs at
109cycles/second and operates on 102bits per cycle implying 1011bits processed
per second.The gap here is only 6 orders of magnitude, which can be plausibly
surpassed via cluster machines. For example, theBlueGene/Loperates 105nodes
(one order of magnitude short). It's peak recorded performance is about
0.5*1015FLOPS which translates to about 1016bit ops per second, which is
nearly 1017.There are many criticisms (both positive and negative) for this
argument.Simulation of a human brain might require substantially more detail.
Perhaps an additional 102is required per neuron.We may not need to simulate a
human brain to achieve AI. There are certainly many examples where we have
been able to design</p><p>4 0.75603408 <a title="380-lsi-4" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>Introduction: I recently had fun discussions with bothVikash MansinghkaandThomas Breuelabout
approaching AI with machine learning. The general interest in taking a crack
at AI with machine learning seems to be rising on many fronts
includingDARPA.As a matter of history, there was a great deal of interest in
AI which died down before I began research. There remain many projects and
conferences spawned in this earlier AI wave, as well as a good bit of
experience about what did not work, or at least did not work yet. Here are a
few examples of failure modes that people seem to run into:Supply/Product
confusion. Sometimes we think "Intelligences use X, so I'll create X and have
an Intelligence." An example of this is theCyc Projectwhich inspires some
people as "intelligences use ontologies, so I'll create an ontology and a
system using it to have an Intelligence." The flaw here is that
Intelligencescreateontologies, which they use, and without the ability to
create ontologies you don't have an Intellige</p><p>5 0.68230277 <a title="380-lsi-5" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I've enjoyed theTerminatormovies and show. Neglecting the whacky aspects (time
travel and associated paradoxes), there is an enduring topic of discussion:
how do people deal with intelligent machines (and vice versa)?In Terminator-
land, the primary method for dealing with intelligent machines is to prevent
them from being made. This approach works pretty badly, because a new angle on
building an intelligent machine keeps coming up. This is partly a ploy for
writer's to avoid writing themselves out of a job, but there is a fundamental
truth to it as well: preventing progress in research is hard.The United
States, has been experimenting with trying to stop research onstem cells. It
hasn't worked very well--the net effect has been retarding research programs a
bit, and exporting some research to other countries. Another less recent
example was encryption technology, for which the United States generally did
not encourage early public research and evendiscouraged as a munition. This
slowe</p><p>6 0.47008422 <a title="380-lsi-6" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>7 0.42836034 <a title="380-lsi-7" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>8 0.38293993 <a title="380-lsi-8" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>9 0.37053275 <a title="380-lsi-9" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>10 0.36445451 <a title="380-lsi-10" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>11 0.36265782 <a title="380-lsi-11" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>12 0.36264068 <a title="380-lsi-12" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>13 0.34825644 <a title="380-lsi-13" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>14 0.33870122 <a title="380-lsi-14" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>15 0.33235762 <a title="380-lsi-15" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>16 0.31311277 <a title="380-lsi-16" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>17 0.30804977 <a title="380-lsi-17" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>18 0.30497068 <a title="380-lsi-18" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>19 0.29719675 <a title="380-lsi-19" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>20 0.29395849 <a title="380-lsi-20" href="../hunch_net-2007/hunch_net-2007-06-23-Machine_Learning_Jobs_are_Growing_on_Trees.html">250 hunch net-2007-06-23-Machine Learning Jobs are Growing on Trees</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.018), (10, 0.015), (35, 0.042), (42, 0.179), (45, 0.042), (48, 0.036), (68, 0.071), (69, 0.018), (74, 0.097), (76, 0.011), (79, 0.022), (88, 0.034), (94, 0.286), (95, 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.8758586 <a title="380-lda-1" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>Introduction: Dan Reevesintroduced me toMichael Vassarwho ran theSingularity Summitand
educated me a bit on the subject of AI safety which theSingularity
Institutehassmall grants for.I still believe thatinterstellar space travel is
necessary for long term civilization survival, and the AI is necessary for
interstellar space travel. On these grounds alone, we could judge that
developing AI is much more safe than not. Nevertheless, there is a basic
reasonable fear, as expressed by some commenters, that AI could go bad.A basic
scenario starts with someone inventing an AI and telling it to make as much
money as possible. The AI promptly starts trading in various markets to make
money. To improve, it crafts a virus that takes over most of the world's
computers using it as a surveillance network so that it can always make the
right decision. The AI also branches out into any form of distance work,
taking over the entire outsourcing process for all jobs that are entirely
digital. To further improve, the AI</p><p>2 0.81318402 <a title="380-lda-2" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>Introduction: This is near the one month point, so it seems appropriate to consider meta-
issues for the moment.The number of posts is a bit over 20.The number of
people speaking up in discussions is about 10.The number of people viewing the
site is somewhat more than 100.I am (naturally) dissatisfied with many
things.Many of thepotential useshaven't been realized. This is partly a matter
of opportunity (no conferences in the last month), partly a matter of will (no
open problems because it's hard to give them up), and partly a matter of
tradition. In academia, there is a strong tradition of trying to get
everything perfectly right before presentation. This is somewhat contradictory
to the nature of making many posts, and it's definitely contradictory to the
idea of doing "public research". If that sort of idea is to pay off, it must
be significantly more succesful than previous methods. In an effort to
continue experimenting, I'm going to use the next week as "open problems
week".Spam is a problem.</p><p>3 0.77271593 <a title="380-lda-3" href="../hunch_net-2008/hunch_net-2008-01-18-Datasets.html">284 hunch net-2008-01-18-Datasets</a></p>
<p>Introduction: David Pennocknotes the impressiveset of datasetsatdatawrangling.</p><p>4 0.7483536 <a title="380-lda-4" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>5 0.61075294 <a title="380-lda-5" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>Introduction: Al Gore'sfilmand gradually more assertive and thorough science has managed to
mostly shift the debate on climate change from "Is it happening?" to "What
should be done?" In that context, it's worthwhile to think a bit about what
can be done within computer science research.There are two things we can think
about:Doing ResearchAt a cartoon level, computer science research consists of
some combination of commuting to&from; work, writing programs, running them on
computers, writing papers, and presenting them at conferences. A typical
computer has a power usage on the order of 100 Watts, which works out to 2.4
kiloWatt-hours/day. Looking upDavid MacKay'sreference on power usage per
person, it becomes clear that this is a relatively minor part of the
lifestyle, although it could become substantial if many more computers are
required. Much larger costs are associated with commuting (which is in common
with many people) and attending conferences. Since local commuting is common
across many pe</p><p>6 0.59781939 <a title="380-lda-6" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>7 0.59720349 <a title="380-lda-7" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>8 0.59562486 <a title="380-lda-8" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>9 0.5938772 <a title="380-lda-9" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>10 0.59329557 <a title="380-lda-10" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>11 0.59321207 <a title="380-lda-11" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>12 0.59317702 <a title="380-lda-12" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>13 0.59298211 <a title="380-lda-13" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>14 0.59085029 <a title="380-lda-14" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>15 0.58944476 <a title="380-lda-15" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>16 0.58863825 <a title="380-lda-16" href="../hunch_net-2010/hunch_net-2010-08-23-Boosted_Decision_Trees_for_Deep_Learning.html">407 hunch net-2010-08-23-Boosted Decision Trees for Deep Learning</a></p>
<p>17 0.58839583 <a title="380-lda-17" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>18 0.58775908 <a title="380-lda-18" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>19 0.58710039 <a title="380-lda-19" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>20 0.58629543 <a title="380-lda-20" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
