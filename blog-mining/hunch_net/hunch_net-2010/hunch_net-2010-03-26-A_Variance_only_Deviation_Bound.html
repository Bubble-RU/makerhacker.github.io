<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>392 hunch net-2010-03-26-A Variance only Deviation Bound</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-392" href="#">hunch_net-2010-392</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>392 hunch net-2010-03-26-A Variance only Deviation Bound</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-392-html" href="http://hunch.net/?p=1304">html</a></p><p>Introduction: At the  PAC-Bayes  workshop earlier this week,  Olivier Catoni  described a result that I hadn’t believed was possible:  a deviation bound depending  only  on the variance of a random variable .
 
For people not familiar with deviation bounds, this may be hard to appreciate.   Deviation bounds, are one of the core components for the foundations of machine learning theory, so developments here have a potential to alter our understanding of how to learn and what is learnable.  My understanding is that the basic proof techniques started with  Bernstein  and have evolved into several variants specialized for various applications.  All of the variants I knew had a dependence on the range, with some also having a dependence on the variance of an IID or martingale random variable.  This one is the first I know of with a dependence on only the variance.
 
The basic idea is to use a biased estimator of the mean which is not influenced much by outliers.  Then, a deviation bound can be proved by</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 At the  PAC-Bayes  workshop earlier this week,  Olivier Catoni  described a result that I hadn’t believed was possible:  a deviation bound depending  only  on the variance of a random variable . [sent-1, score-1.426]
</p><p>2 For people not familiar with deviation bounds, this may be hard to appreciate. [sent-2, score-0.65]
</p><p>3 Deviation bounds, are one of the core components for the foundations of machine learning theory, so developments here have a potential to alter our understanding of how to learn and what is learnable. [sent-3, score-0.502]
</p><p>4 My understanding is that the basic proof techniques started with  Bernstein  and have evolved into several variants specialized for various applications. [sent-4, score-0.611]
</p><p>5 All of the variants I knew had a dependence on the range, with some also having a dependence on the variance of an IID or martingale random variable. [sent-5, score-1.144]
</p><p>6 This one is the first I know of with a dependence on only the variance. [sent-6, score-0.239]
</p><p>7 The basic idea is to use a biased estimator of the mean which is not influenced much by outliers. [sent-7, score-0.55]
</p><p>8 Then, a deviation bound can be proved by using the exponential moment method, with the sum of the bias and the deviation bounded. [sent-8, score-1.664]
</p><p>9 The use of a biased estimator is clearly necessary, because an unbiased empirical average is inherently unstable—which was precisely the reason I didn’t think this was possible. [sent-9, score-0.871]
</p><p>10 Precisely how this is useful for machine learning isn’t clear yet, but it opens up possibilities. [sent-10, score-0.126]
</p><p>11 For example, it’s common to suffer from large ranges in exploration settings, such as contextual bandits or active learning. [sent-11, score-0.353]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('deviation', 0.582), ('dependence', 0.239), ('estimator', 0.233), ('biased', 0.183), ('variance', 0.169), ('variants', 0.169), ('precisely', 0.156), ('evolved', 0.126), ('developments', 0.126), ('martingale', 0.126), ('believed', 0.126), ('opens', 0.126), ('unstable', 0.116), ('bound', 0.115), ('bounds', 0.112), ('random', 0.111), ('olivier', 0.11), ('hadn', 0.11), ('unbiased', 0.101), ('bandits', 0.101), ('alter', 0.097), ('foundations', 0.097), ('specialized', 0.094), ('components', 0.094), ('suffer', 0.094), ('knew', 0.091), ('described', 0.091), ('week', 0.089), ('understanding', 0.088), ('proved', 0.087), ('range', 0.085), ('contextual', 0.085), ('didn', 0.08), ('earlier', 0.08), ('moment', 0.078), ('variable', 0.078), ('settings', 0.077), ('exponential', 0.077), ('sum', 0.075), ('depending', 0.074), ('exploration', 0.073), ('mean', 0.068), ('bias', 0.068), ('iid', 0.068), ('inherently', 0.068), ('proof', 0.068), ('familiar', 0.068), ('clearly', 0.067), ('basic', 0.066), ('average', 0.063)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="392-tfidf-1" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<p>Introduction: At the  PAC-Bayes  workshop earlier this week,  Olivier Catoni  described a result that I hadn’t believed was possible:  a deviation bound depending  only  on the variance of a random variable .
 
For people not familiar with deviation bounds, this may be hard to appreciate.   Deviation bounds, are one of the core components for the foundations of machine learning theory, so developments here have a potential to alter our understanding of how to learn and what is learnable.  My understanding is that the basic proof techniques started with  Bernstein  and have evolved into several variants specialized for various applications.  All of the variants I knew had a dependence on the range, with some also having a dependence on the variance of an IID or martingale random variable.  This one is the first I know of with a dependence on only the variance.
 
The basic idea is to use a biased estimator of the mean which is not influenced much by outliers.  Then, a deviation bound can be proved by</p><p>2 0.18183425 <a title="392-tfidf-2" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>Introduction: Sham Kakade  points out that we are missing a bound.
 
Suppose we have  m  samples  x  drawn IID from some distribution  D .  Through the magic of exponential moment method we know that:
  
 If the range of  x  is bounded by an interval of size  I , a  Chernoff/Hoeffding style bound  gives us a bound on the deviations like  O(I/m 0.5 )  (at least in crude form).  A proof is on page 9  here . 
 If the range of  x  is bounded, and the variance (or a bound on the variance) is known, then  Bennett’s bound  can give tighter results (*).  This can be a huge improvment when the true variance small. 
  
What’s missing here is a bound that depends on the observed variance rather than a bound on the variance.  This means that many people attempt to use Bennett’s bound (incorrectly) by plugging the observed variance in as the true variance, invalidating the bound application.  Most of the time, they get away with it, but this is a dangerous move when doing machine learning.  In machine learning,</p><p>3 0.17182174 <a title="392-tfidf-3" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>Introduction: This post is about contextual bandit problems where, repeatedly:
  
 The world chooses features  x  and rewards for each action  r 1 ,…,r k   then announces the features  x  (but not the rewards). 
 A policy chooses an action  a . 
 The world announces the reward  r a   
  
The goal in these situations is to learn a policy which maximizes  r a   in expectation efficiently.  I’m thinking about all situations which fit the above setting, whether they are drawn IID or adversarially from round to round and whether they involve past logged data or rapidly learning via interaction.
 
One common drawback of all algorithms for solving this setting, is that they have a poor dependence on the number of actions.  For example if  k  is the number of actions,  EXP4 (page 66)  has a dependence on  k 0.5  ,  epoch-greedy  (and the simpler epsilon greedy) have a dependence on  k 1/3  , and the  offset tree  has a dependence on  k-1 .  These results aren’t directly comparable because different things a</p><p>4 0.1129866 <a title="392-tfidf-4" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>Introduction: One of the fundamental underpinnings of the internet is advertising based content.  This has become much more effective due to targeted advertising where ads are specifically matched to interests.  Everyone is familiar with this, because everyone uses search engines and all search engines try to make money this way.
 
The problem of matching ads to interests is a natural machine learning problem in some ways since there is much information in who clicks on what.  A fundamental problem with this information is that it is not supervised—in particular a click-or-not on one ad doesn’t generally tell you if a different ad would have been clicked on.  This implies we have a fundamental exploration problem.
 
A standard mathematical setting for this situation is “ k -Armed Bandits”, often with various relevant embellishments.  The  k -Armed Bandit setting works on a round-by-round basis.  On each round:
  
 A policy chooses arm  a  from  1  of  k  arms (i.e. 1 of k ads). 
 The world reveals t</p><p>5 0.11131445 <a title="392-tfidf-5" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>Introduction: What?   Bounds are mathematical formulas relating observations to future error rates assuming that data is drawn independently.  In classical statistics, they are calld confidence intervals. 
 Why?  
  
  Good Judgement . In many applications of learning, it is desirable to know how well the learned predictor works in the future.  This helps you decide if the problem is solved or not. 
  Learning Essence .  The form of some of these bounds helps you understand what the essence of learning is. 
  Algorithm Design .  Some of these bounds suggest, motivate, or even directly imply learning algorithms. 
  
 What We Know Now 
 
There are several families of bounds, based on how information is used.
  
  Testing Bounds . These are methods which use labeled data not used in training to estimate the future error rate.  Examples include the  test set bound ,  progressive validation  also  here  and  here ,  train and test bounds , and cross-validation (but see the  big open problem ).  These tec</p><p>6 0.098124109 <a title="392-tfidf-6" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>7 0.094786935 <a title="392-tfidf-7" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>8 0.080843166 <a title="392-tfidf-8" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>9 0.07389345 <a title="392-tfidf-9" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>10 0.073149413 <a title="392-tfidf-10" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>11 0.073043078 <a title="392-tfidf-11" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>12 0.072686732 <a title="392-tfidf-12" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>13 0.071779765 <a title="392-tfidf-13" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>14 0.070713542 <a title="392-tfidf-14" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>15 0.070563152 <a title="392-tfidf-15" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>16 0.068724796 <a title="392-tfidf-16" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>17 0.067445114 <a title="392-tfidf-17" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>18 0.066856191 <a title="392-tfidf-18" href="../hunch_net-2005/hunch_net-2005-12-09-Machine_Learning_Thoughts.html">137 hunch net-2005-12-09-Machine Learning Thoughts</a></p>
<p>19 0.066759869 <a title="392-tfidf-19" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>20 0.065713242 <a title="392-tfidf-20" href="../hunch_net-2009/hunch_net-2009-08-26-Another_10-year_paper_in_Machine_Learning.html">368 hunch net-2009-08-26-Another 10-year paper in Machine Learning</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.136), (1, 0.054), (2, -0.004), (3, -0.004), (4, 0.056), (5, -0.033), (6, 0.057), (7, -0.025), (8, 0.022), (9, -0.002), (10, 0.105), (11, 0.054), (12, 0.052), (13, 0.041), (14, -0.055), (15, -0.0), (16, -0.036), (17, 0.027), (18, -0.065), (19, 0.074), (20, 0.012), (21, 0.033), (22, -0.112), (23, -0.001), (24, -0.081), (25, 0.036), (26, -0.061), (27, -0.015), (28, -0.027), (29, -0.014), (30, -0.071), (31, -0.076), (32, 0.035), (33, 0.035), (34, -0.054), (35, -0.029), (36, -0.068), (37, -0.023), (38, -0.044), (39, -0.004), (40, -0.086), (41, -0.063), (42, -0.108), (43, -0.005), (44, -0.067), (45, -0.036), (46, 0.088), (47, 0.032), (48, -0.059), (49, -0.011)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95374113 <a title="392-lsi-1" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<p>Introduction: At the  PAC-Bayes  workshop earlier this week,  Olivier Catoni  described a result that I hadn’t believed was possible:  a deviation bound depending  only  on the variance of a random variable .
 
For people not familiar with deviation bounds, this may be hard to appreciate.   Deviation bounds, are one of the core components for the foundations of machine learning theory, so developments here have a potential to alter our understanding of how to learn and what is learnable.  My understanding is that the basic proof techniques started with  Bernstein  and have evolved into several variants specialized for various applications.  All of the variants I knew had a dependence on the range, with some also having a dependence on the variance of an IID or martingale random variable.  This one is the first I know of with a dependence on only the variance.
 
The basic idea is to use a biased estimator of the mean which is not influenced much by outliers.  Then, a deviation bound can be proved by</p><p>2 0.76586145 <a title="392-lsi-2" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>Introduction: Sham Kakade  points out that we are missing a bound.
 
Suppose we have  m  samples  x  drawn IID from some distribution  D .  Through the magic of exponential moment method we know that:
  
 If the range of  x  is bounded by an interval of size  I , a  Chernoff/Hoeffding style bound  gives us a bound on the deviations like  O(I/m 0.5 )  (at least in crude form).  A proof is on page 9  here . 
 If the range of  x  is bounded, and the variance (or a bound on the variance) is known, then  Bennett’s bound  can give tighter results (*).  This can be a huge improvment when the true variance small. 
  
What’s missing here is a bound that depends on the observed variance rather than a bound on the variance.  This means that many people attempt to use Bennett’s bound (incorrectly) by plugging the observed variance in as the true variance, invalidating the bound application.  Most of the time, they get away with it, but this is a dangerous move when doing machine learning.  In machine learning,</p><p>3 0.66912264 <a title="392-lsi-3" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>Introduction: This post is about contextual bandit problems where, repeatedly:
  
 The world chooses features  x  and rewards for each action  r 1 ,…,r k   then announces the features  x  (but not the rewards). 
 A policy chooses an action  a . 
 The world announces the reward  r a   
  
The goal in these situations is to learn a policy which maximizes  r a   in expectation efficiently.  I’m thinking about all situations which fit the above setting, whether they are drawn IID or adversarially from round to round and whether they involve past logged data or rapidly learning via interaction.
 
One common drawback of all algorithms for solving this setting, is that they have a poor dependence on the number of actions.  For example if  k  is the number of actions,  EXP4 (page 66)  has a dependence on  k 0.5  ,  epoch-greedy  (and the simpler epsilon greedy) have a dependence on  k 1/3  , and the  offset tree  has a dependence on  k-1 .  These results aren’t directly comparable because different things a</p><p>4 0.59601015 <a title="392-lsi-4" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>Introduction: Steve Smale  and I have a debate about goals of learning theory.
 
Steve likes theorems with a dependence on unobservable quantities.  For example, if  D  is a distribution over a space  X x [0,1] , you can state a theorem about the error rate dependent on the variance,  E (x,y)~D  (y-E y’~D|x [y']) 2  .
 
I dislike this, because I want to use the theorems to produce code solving learning problems.  Since I don’t know (and can’t measure) the variance, a theorem depending on the variance does not help me—I would not know what variance to plug into the learning algorithm.
 
Recast more broadly, this is a debate between “declarative” and “operative” mathematics.  A strong example of “declarative” mathematics is  “a new kind of science” .  Roughly speaking, the goal of this kind of approach seems to be finding a way to explain the observations we make.  Examples include “some things are unpredictable”, “a phase transition exists”, etc…
 
“Operative” mathematics helps you make predictions a</p><p>5 0.57884365 <a title="392-lsi-5" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>Introduction: What?   Bounds are mathematical formulas relating observations to future error rates assuming that data is drawn independently.  In classical statistics, they are calld confidence intervals. 
 Why?  
  
  Good Judgement . In many applications of learning, it is desirable to know how well the learned predictor works in the future.  This helps you decide if the problem is solved or not. 
  Learning Essence .  The form of some of these bounds helps you understand what the essence of learning is. 
  Algorithm Design .  Some of these bounds suggest, motivate, or even directly imply learning algorithms. 
  
 What We Know Now 
 
There are several families of bounds, based on how information is used.
  
  Testing Bounds . These are methods which use labeled data not used in training to estimate the future error rate.  Examples include the  test set bound ,  progressive validation  also  here  and  here ,  train and test bounds , and cross-validation (but see the  big open problem ).  These tec</p><p>6 0.57351863 <a title="392-lsi-6" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>7 0.53772902 <a title="392-lsi-7" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>8 0.53502113 <a title="392-lsi-8" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>9 0.53460902 <a title="392-lsi-9" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>10 0.51123649 <a title="392-lsi-10" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>11 0.50891417 <a title="392-lsi-11" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>12 0.50435853 <a title="392-lsi-12" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>13 0.47381386 <a title="392-lsi-13" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>14 0.45706335 <a title="392-lsi-14" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>15 0.44374308 <a title="392-lsi-15" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>16 0.43460056 <a title="392-lsi-16" href="../hunch_net-2009/hunch_net-2009-08-26-Another_10-year_paper_in_Machine_Learning.html">368 hunch net-2009-08-26-Another 10-year paper in Machine Learning</a></p>
<p>17 0.42482251 <a title="392-lsi-17" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>18 0.40431157 <a title="392-lsi-18" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<p>19 0.40159011 <a title="392-lsi-19" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>20 0.39500132 <a title="392-lsi-20" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(10, 0.047), (27, 0.182), (35, 0.315), (53, 0.042), (55, 0.068), (77, 0.117), (94, 0.076), (95, 0.04)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.91035759 <a title="392-lda-1" href="../hunch_net-2005/hunch_net-2005-11-16-MLSS_2006.html">130 hunch net-2005-11-16-MLSS 2006</a></p>
<p>Introduction: There will be two  machine learning summer schools  in 2006.  
 
One is in  Canberra, Australia  from February 6 to February 17 (Aussie summer).  The webpage is fully ‘live’ so you should actively consider it now.
 
The other is in  Taipei, Taiwan  from July 24 to August 4.  This one is still in the planning phase, but that should be settled soon.  
 
Attending an MLSS is probably the quickest and easiest way to bootstrap yourself into a reasonable initial understanding of the field of machine learning.</p><p>same-blog 2 0.8704443 <a title="392-lda-2" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<p>Introduction: At the  PAC-Bayes  workshop earlier this week,  Olivier Catoni  described a result that I hadn’t believed was possible:  a deviation bound depending  only  on the variance of a random variable .
 
For people not familiar with deviation bounds, this may be hard to appreciate.   Deviation bounds, are one of the core components for the foundations of machine learning theory, so developments here have a potential to alter our understanding of how to learn and what is learnable.  My understanding is that the basic proof techniques started with  Bernstein  and have evolved into several variants specialized for various applications.  All of the variants I knew had a dependence on the range, with some also having a dependence on the variance of an IID or martingale random variable.  This one is the first I know of with a dependence on only the variance.
 
The basic idea is to use a biased estimator of the mean which is not influenced much by outliers.  Then, a deviation bound can be proved by</p><p>3 0.79868758 <a title="392-lda-3" href="../hunch_net-2005/hunch_net-2005-05-17-A_Short_Guide_to_PhD_Graduate_Study.html">73 hunch net-2005-05-17-A Short Guide to PhD Graduate Study</a></p>
<p>Introduction: Graduate study is a mysterious and uncertain process.  This easiest way to see this is by noting that a very old advisor/student mechanism is preferred. There is no known succesful mechanism for “mass producing” PhDs as is done (in some sense) for undergraduate and masters study.  Here are a few hints that might be useful to prospective or current students based on my own experience.
  
  Masters or PhD  (a) You want a PhD if you want to do research.  (b) You want a masters if you want to make money.  People wanting (b) will be manifestly unhappy with (a) because it typically means years of low pay.  People wanting (a) should try to avoid (b) because it prolongs an already long process. 
  Attitude .   Many  students struggle for awhile with the wrong attitude towards research.  Most students come into graduate school with 16-19 years of schooling where the principle means of success is proving that you know something via assignments, tests, etc…  Research does  not  work this way.  Re</p><p>4 0.59937918 <a title="392-lda-4" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>Introduction: One of the fundamental underpinnings of the internet is advertising based content.  This has become much more effective due to targeted advertising where ads are specifically matched to interests.  Everyone is familiar with this, because everyone uses search engines and all search engines try to make money this way.
 
The problem of matching ads to interests is a natural machine learning problem in some ways since there is much information in who clicks on what.  A fundamental problem with this information is that it is not supervised—in particular a click-or-not on one ad doesn’t generally tell you if a different ad would have been clicked on.  This implies we have a fundamental exploration problem.
 
A standard mathematical setting for this situation is “ k -Armed Bandits”, often with various relevant embellishments.  The  k -Armed Bandit setting works on a round-by-round basis.  On each round:
  
 A policy chooses arm  a  from  1  of  k  arms (i.e. 1 of k ads). 
 The world reveals t</p><p>5 0.59731913 <a title="392-lda-5" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>Introduction: An argument is sometimes made that the Bayesian way is the “right” way to do machine learning.  This is a serious argument which deserves a serious reply.  The approximation argument is a serious reply for which I have not yet seen a reply 2 .
 
The idea for the Bayesian approach is quite simple, elegant, and general.  Essentially, you first specify a prior  P(D)  over possible processes  D  producing the data, observe the data, then condition on the data according to Bayes law to construct a posterior:   P(D|x) = P(x|D)P(D)/P(x)   
After this, hard decisions are made (such as “turn left” or “turn right”) by choosing the one which minimizes the expected (with respect to the posterior) loss.
 
This basic idea is reused thousands of times with various choices of  P(D)  and loss functions which is unsurprising given the many nice properties:
  
 There is an extremely strong associated guarantee: If the actual distribution generating the data is drawn from  P(D)  there is no better method.</p><p>6 0.58842599 <a title="392-lda-6" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>7 0.58387589 <a title="392-lda-7" href="../hunch_net-2006/hunch_net-2006-09-09-How_to_solve_an_NP_hard_problem_in_quadratic_time.html">206 hunch net-2006-09-09-How to solve an NP hard problem in quadratic time</a></p>
<p>8 0.58269262 <a title="392-lda-8" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>9 0.56555897 <a title="392-lda-9" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>10 0.54871988 <a title="392-lda-10" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>11 0.54433864 <a title="392-lda-11" href="../hunch_net-2011/hunch_net-2011-06-22-Ultra_LDA.html">436 hunch net-2011-06-22-Ultra LDA</a></p>
<p>12 0.54257905 <a title="392-lda-12" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>13 0.54035592 <a title="392-lda-13" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>14 0.54029679 <a title="392-lda-14" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>15 0.5370869 <a title="392-lda-15" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>16 0.53492534 <a title="392-lda-16" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>17 0.53440869 <a title="392-lda-17" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>18 0.53329366 <a title="392-lda-18" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>19 0.53306824 <a title="392-lda-19" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>20 0.5327149 <a title="392-lda-20" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
