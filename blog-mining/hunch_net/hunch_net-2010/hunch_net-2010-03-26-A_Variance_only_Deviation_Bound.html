<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>392 hunch net-2010-03-26-A Variance only Deviation Bound</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-392" href="#">hunch_net-2010-392</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>392 hunch net-2010-03-26-A Variance only Deviation Bound</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-392-html" href="http://hunch.net/?p=1304">html</a></p><p>Introduction: At thePAC-Bayesworkshop earlier this week,Olivier Catonidescribed a result
that I hadn't believed was possible:a deviation bound dependingonlyon the
variance of a random variable.For people not familiar with deviation bounds,
this may be hard to appreciate. Deviation bounds, are one of the core
components for the foundations of machine learning theory, so developments
here have a potential to alter our understanding of how to learn and what is
learnable. My understanding is that the basic proof techniques started
withBernsteinand have evolved into several variants specialized for various
applications. All of the variants I knew had a dependence on the range, with
some also having a dependence on the variance of an IID or martingale random
variable. This one is the first I know of with a dependence on only the
variance.The basic idea is to use a biased estimator of the mean which is not
influenced much by outliers. Then, a deviation bound can be proved by using
the exponential moment me</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('deviation', 0.605), ('dependence', 0.254), ('estimator', 0.242), ('biased', 0.19), ('variance', 0.176), ('variants', 0.176), ('evolved', 0.131), ('developments', 0.131), ('martingale', 0.131), ('believed', 0.131), ('opens', 0.131), ('bound', 0.123), ('bounds', 0.118), ('random', 0.118), ('bandits', 0.114), ('foundations', 0.114), ('unbiased', 0.109), ('alter', 0.105), ('suffer', 0.101), ('specialized', 0.098)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="392-tfidf-1" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<p>Introduction: At thePAC-Bayesworkshop earlier this week,Olivier Catonidescribed a result
that I hadn't believed was possible:a deviation bound dependingonlyon the
variance of a random variable.For people not familiar with deviation bounds,
this may be hard to appreciate. Deviation bounds, are one of the core
components for the foundations of machine learning theory, so developments
here have a potential to alter our understanding of how to learn and what is
learnable. My understanding is that the basic proof techniques started
withBernsteinand have evolved into several variants specialized for various
applications. All of the variants I knew had a dependence on the range, with
some also having a dependence on the variance of an IID or martingale random
variable. This one is the first I know of with a dependence on only the
variance.The basic idea is to use a biased estimator of the mean which is not
influenced much by outliers. Then, a deviation bound can be proved by using
the exponential moment me</p><p>2 0.19790041 <a title="392-tfidf-2" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>Introduction: This post is about contextual bandit problems where, repeatedly:The world
chooses featuresxand rewards for each actionr1,â&euro;Ś,rkthen announces the
featuresx(but not the rewards).A policy chooses an actiona.The world announces
the rewardraThe goal in these situations is to learn a policy which
maximizesrain expectation efficiently. I'm thinking about all situations which
fit the above setting, whether they are drawn IID or adversarially from round
to round and whether they involve past logged data or rapidly learning via
interaction.One common drawback of all algorithms for solving this setting, is
that they have a poor dependence on the number of actions. For example ifkis
the number of actions,EXP4 (page 66)has a dependence onk0.5,epoch-greedy(and
the simpler epsilon greedy) have a dependence onk1/3, and theoffset treehas a
dependence onk-1. These results aren't directly comparable because different
things are being analyzed. The fact thatallanalyses have poor dependence onkis
troublesom</p><p>3 0.19087954 <a title="392-tfidf-3" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>Introduction: Sham Kakadepoints out that we are missing a bound.Suppose we
havemsamplesxdrawn IID from some distributionD. Through the magic of
exponential moment method we know that:If the range ofxis bounded by an
interval of sizeI, aChernoff/Hoeffding style boundgives us a bound on the
deviations likeO(I/m0.5)(at least in crude form). A proof is on page 9here.If
the range ofxis bounded, and the variance (or a bound on the variance) is
known, thenBennett's boundcan give tighter results (*). This can be a huge
improvment when the true variance small.What's missing here is a bound that
depends on the observed variance rather than a bound on the variance. This
means that many people attempt to use Bennett's bound (incorrectly) by
plugging the observed variance in as the true variance, invalidating the bound
application. Most of the time, they get away with it, but this is a dangerous
move when doing machine learning. In machine learning, we are typically trying
to find a predictor with 0 expected los</p><p>4 0.10828468 <a title="392-tfidf-4" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>Introduction: One of the fundamental underpinnings of the internet is advertising based
content. This has become much more effective due to targeted advertising where
ads are specifically matched to interests. Everyone is familiar with this,
because everyone uses search engines and all search engines try to make money
this way.The problem of matching ads to interests is a natural machine
learning problem in some ways since there is much information in who clicks on
what. A fundamental problem with this information is that it is not supervised
--in particular a click-or-not on one ad doesn't generally tell you if a
different ad would have been clicked on. This implies we have a fundamental
exploration problem.A standard mathematical setting for this situation is
"k-Armed Bandits", often with various relevant embellishments. Thek-Armed
Bandit setting works on a round-by-round basis. On each round:A policy chooses
armafrom1ofkarms (i.e. 1 of k ads).The world reveals the rewardraof the chosen
arm (i.e.</p><p>5 0.10601381 <a title="392-tfidf-5" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>Introduction: One thing which is clear on a little reflection is that there exists a single
master learning problem capable of encoding essentially all learning problems.
This problem is of course a very general sort of reinforcement learning where
the world interacts with an agent as:The world announces an observationx.The
agent makes a choicea.The world announces a rewardr.The goal here is to
maximize the sum of the rewards over the time of the agent. No particular
structure relatingxtoaoratoris implied by this setting so we do not know
effective general algorithms for the agent. It's very easy to prove lower
bounds showing that an agent cannot hope to succeed here--just consider the
case where actions are unrelated to rewards. Nevertheless, there is a real
sense in which essentially all forms of life are agents operating in this
setting, somehow succeeding. The gap between these observations drives
research--How can we find tractable specializations of the master problem
general enough to provide</p><p>6 0.10372515 <a title="392-tfidf-6" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>7 0.10048387 <a title="392-tfidf-7" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>8 0.091189593 <a title="392-tfidf-8" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>9 0.077883065 <a title="392-tfidf-9" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>10 0.076886825 <a title="392-tfidf-10" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>11 0.073805407 <a title="392-tfidf-11" href="../hunch_net-2009/hunch_net-2009-08-26-Another_10-year_paper_in_Machine_Learning.html">368 hunch net-2009-08-26-Another 10-year paper in Machine Learning</a></p>
<p>12 0.072050586 <a title="392-tfidf-12" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>13 0.069885582 <a title="392-tfidf-13" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>14 0.068196669 <a title="392-tfidf-14" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>15 0.067499958 <a title="392-tfidf-15" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>16 0.06660679 <a title="392-tfidf-16" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>17 0.065731123 <a title="392-tfidf-17" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>18 0.063770279 <a title="392-tfidf-18" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>19 0.062924802 <a title="392-tfidf-19" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>20 0.062650979 <a title="392-tfidf-20" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.136), (1, -0.064), (2, -0.016), (3, -0.023), (4, -0.066), (5, -0.097), (6, 0.05), (7, -0.04), (8, -0.042), (9, -0.095), (10, -0.062), (11, 0.021), (12, 0.013), (13, 0.006), (14, 0.008), (15, -0.013), (16, -0.058), (17, -0.002), (18, 0.073), (19, 0.025), (20, 0.037), (21, -0.022), (22, -0.07), (23, -0.006), (24, -0.08), (25, 0.072), (26, -0.105), (27, 0.024), (28, 0.092), (29, 0.036), (30, 0.123), (31, 0.014), (32, 0.026), (33, -0.035), (34, 0.066), (35, -0.019), (36, 0.003), (37, 0.062), (38, -0.09), (39, 0.069), (40, 0.035), (41, -0.043), (42, 0.065), (43, 0.052), (44, 0.07), (45, -0.033), (46, 0.076), (47, -0.026), (48, 0.039), (49, 0.147)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95014799 <a title="392-lsi-1" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<p>Introduction: At thePAC-Bayesworkshop earlier this week,Olivier Catonidescribed a result
that I hadn't believed was possible:a deviation bound dependingonlyon the
variance of a random variable.For people not familiar with deviation bounds,
this may be hard to appreciate. Deviation bounds, are one of the core
components for the foundations of machine learning theory, so developments
here have a potential to alter our understanding of how to learn and what is
learnable. My understanding is that the basic proof techniques started
withBernsteinand have evolved into several variants specialized for various
applications. All of the variants I knew had a dependence on the range, with
some also having a dependence on the variance of an IID or martingale random
variable. This one is the first I know of with a dependence on only the
variance.The basic idea is to use a biased estimator of the mean which is not
influenced much by outliers. Then, a deviation bound can be proved by using
the exponential moment me</p><p>2 0.73374432 <a title="392-lsi-2" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>Introduction: Sham Kakadepoints out that we are missing a bound.Suppose we
havemsamplesxdrawn IID from some distributionD. Through the magic of
exponential moment method we know that:If the range ofxis bounded by an
interval of sizeI, aChernoff/Hoeffding style boundgives us a bound on the
deviations likeO(I/m0.5)(at least in crude form). A proof is on page 9here.If
the range ofxis bounded, and the variance (or a bound on the variance) is
known, thenBennett's boundcan give tighter results (*). This can be a huge
improvment when the true variance small.What's missing here is a bound that
depends on the observed variance rather than a bound on the variance. This
means that many people attempt to use Bennett's bound (incorrectly) by
plugging the observed variance in as the true variance, invalidating the bound
application. Most of the time, they get away with it, but this is a dangerous
move when doing machine learning. In machine learning, we are typically trying
to find a predictor with 0 expected los</p><p>3 0.73229557 <a title="392-lsi-3" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>Introduction: This post is about contextual bandit problems where, repeatedly:The world
chooses featuresxand rewards for each actionr1,â&euro;Ś,rkthen announces the
featuresx(but not the rewards).A policy chooses an actiona.The world announces
the rewardraThe goal in these situations is to learn a policy which
maximizesrain expectation efficiently. I'm thinking about all situations which
fit the above setting, whether they are drawn IID or adversarially from round
to round and whether they involve past logged data or rapidly learning via
interaction.One common drawback of all algorithms for solving this setting, is
that they have a poor dependence on the number of actions. For example ifkis
the number of actions,EXP4 (page 66)has a dependence onk0.5,epoch-greedy(and
the simpler epsilon greedy) have a dependence onk1/3, and theoffset treehas a
dependence onk-1. These results aren't directly comparable because different
things are being analyzed. The fact thatallanalyses have poor dependence onkis
troublesom</p><p>4 0.60551476 <a title="392-lsi-4" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>Introduction: "Science" has many meanings, but one common meaning is "thescientific method"
which is a principled method for investigating the world using the following
steps:Form a hypothesis about the world.Use the hypothesis to make
predictions.Run experiments to confirm or disprove the predictions.The
ordering of these steps is very important to the scientific method. In
particular, predictionsmustbe made before experiments are run.Given that we
all believe in the scientific method of investigation, it may be surprising to
learn that cheating is very common. This happens for many reasons, some
innocent and some not.Drug studies. Pharmaceutical companies make predictions
about the effects of their drugs and then conduct blind clinical studies to
determine their effect. Unfortunately, they have also been caught using some
of the more advanced techniques for cheatinghere: including "reprobleming",
"data set selection", and probably "overfitting by review". It isn't too
surprising to observe this: w</p><p>5 0.54990679 <a title="392-lsi-5" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductionstransform a solver of one type of learning problem into a
solver of another type of learning problem. When we analyze these for
robustness we can make statement of the form "ReductionRhas the property that
regretr(or loss) on subproblems of typeAimplies regret at mostf ( r )on the
original problem of typeB".A lower bound for a learning reduction would have
the form "for all reductionsR, there exists a learning problem of typeBand
learning algorithm for problems of typeAwhere regretron induced problems
impliesat leastregretf ( r )forB".The pursuit of lower bounds is often
questionable because, unlike upper bounds, they do not yield practical
algorithms. Nevertheless, they may be helpful as a tool for thinking about
what is learnable and how learnable it is. This has already come
uphereandhere.At the moment, there is no coherent theory of lower bounds for
learning reductions, and we have little understanding of how feasible they are
or which techniques may be useful in</p><p>6 0.52518743 <a title="392-lsi-6" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>7 0.49942645 <a title="392-lsi-7" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>8 0.48124164 <a title="392-lsi-8" href="../hunch_net-2009/hunch_net-2009-08-26-Another_10-year_paper_in_Machine_Learning.html">368 hunch net-2009-08-26-Another 10-year paper in Machine Learning</a></p>
<p>9 0.4735949 <a title="392-lsi-9" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>10 0.46543372 <a title="392-lsi-10" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>11 0.46113399 <a title="392-lsi-11" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>12 0.45044011 <a title="392-lsi-12" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>13 0.44591847 <a title="392-lsi-13" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>14 0.44334978 <a title="392-lsi-14" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>15 0.43469465 <a title="392-lsi-15" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<p>16 0.42564672 <a title="392-lsi-16" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>17 0.4140341 <a title="392-lsi-17" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>18 0.41225484 <a title="392-lsi-18" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>19 0.40196702 <a title="392-lsi-19" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>20 0.38471943 <a title="392-lsi-20" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.031), (42, 0.28), (68, 0.06), (69, 0.068), (74, 0.021), (86, 0.362), (91, 0.057)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.84315264 <a title="392-lda-1" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<p>Introduction: At thePAC-Bayesworkshop earlier this week,Olivier Catonidescribed a result
that I hadn't believed was possible:a deviation bound dependingonlyon the
variance of a random variable.For people not familiar with deviation bounds,
this may be hard to appreciate. Deviation bounds, are one of the core
components for the foundations of machine learning theory, so developments
here have a potential to alter our understanding of how to learn and what is
learnable. My understanding is that the basic proof techniques started
withBernsteinand have evolved into several variants specialized for various
applications. All of the variants I knew had a dependence on the range, with
some also having a dependence on the variance of an IID or martingale random
variable. This one is the first I know of with a dependence on only the
variance.The basic idea is to use a biased estimator of the mean which is not
influenced much by outliers. Then, a deviation bound can be proved by using
the exponential moment me</p><p>2 0.78417748 <a title="392-lda-2" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>Introduction: For most people, a mathematical notation is like a language: you learn it and
stick with it. For people doing mathematical research, however, this is not
enough: they must design new notations for new problems. The design of good
notation is both hard and worthwhile since a bad initial notation can retard a
line of research greatly.Before we had mathematical notation, equations were
all written out in language. Since words have multiple meanings and variable
precedences, long equations written out in language can be extraordinarily
difficult and sometimes fundamentally ambiguous. A good representative example
of this is the legalese in the tax code. Since we want greater precision and
clarity, we adopt mathematical notation.One fundamental thing to understand
about mathematical notation, is that humans as logic verifiers, are barely
capable. This is the fundamental reason why one notation can be much better
than another. This observation is easier to miss than you might expect
because,</p><p>3 0.69601721 <a title="392-lda-3" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>Introduction: A good workshop is often far more interesting than the papers at a conference.
This happens because a workshop has a much tighter focus than a conference.
Since you choose the workshops fitting your interest, the increased relevance
can greatly enhance the level of your interest and attention. Roughly
speaking, a workshop program consists of elements related to a subject of your
interest. The main conference program consists of elements related to
someone's interest (which is rarely your own). Workshops are more about doing
research while conferences are more about presenting research.Several
conferences have associated workshop programs, some with deadlines due
shortly.ICML workshopsDue April 1IJCAI workshopsDeadlines VaryKDD workshopsNot
yet finalizedAnyone going to these conferences should examine the workshops
and see if any are of interest. (If none are, then maybe you should organize
one next year.)</p><p>4 0.68302774 <a title="392-lda-4" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>Introduction: Urs HoelzlefromGooglegave an invited presentation atNIPS. In the presentation,
he strongly advocates interacting with data in a particular scalable manner
which is something like the following:Make a cluster of machines.Build a
unified filesystem. (Google uses GFS, but NFS or other approaches work
reasonably well for smaller clusters.)Interact with data viaMapReduce.Creating
a cluster of machines is, by this point, relatively straightforward.Unified
filesystems are a little bit tricky--GFS is capable by design of essentially
unlimited speed throughput to disk. NFS can bottleneck because all of the data
has to move through one machine. Nevertheless, this may not be a limiting
factor for smaller clusters.MapReduce is a programming paradigm. Essentially,
it is a combination of a data element transform (map) and an
agreggator/selector (reduce). These operations are highly parallelizable and
the claim is that they support the forms of data interaction which are
necessary.Apparently, theNutc</p><p>5 0.61228079 <a title="392-lda-5" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>Introduction: At an intuitive level, the question here is "Can reinforcement learning be
solved with classification?"ProblemConstruct a reinforcement learning
algorithm with near-optimal expected sum of rewards in thedirect experience
modelgiven access to a classifier learning algorithm which has a small error
rate or regret on all posed classification problems. The definition of "posed"
here is slightly murky. I consider a problem "posed" if there is an algorithm
for constructing labeled classification examples.Past WorkThere exists
areduction of reinforcement learning to classification given a generative
model.A generative model is an inherently stronger assumption than the direct
experience model.Otherwork on learning reductionsmay be important.Several
algorithms for solving reinforcement learning in the direct experience model
exist. Most, such asE3,Factored-E3, andmetric-E3andRmaxrequire that the
observation be the state. Recent workextends this approach to POMDPs.This
problem is related topred</p><p>6 0.61212432 <a title="392-lda-6" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>7 0.6104669 <a title="392-lda-7" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>8 0.6089505 <a title="392-lda-8" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>9 0.60864156 <a title="392-lda-9" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>10 0.60733294 <a title="392-lda-10" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>11 0.60630631 <a title="392-lda-11" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>12 0.60459071 <a title="392-lda-12" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>13 0.60360152 <a title="392-lda-13" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>14 0.60144502 <a title="392-lda-14" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>15 0.6003235 <a title="392-lda-15" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>16 0.59896344 <a title="392-lda-16" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>17 0.59750348 <a title="392-lda-17" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>18 0.59729844 <a title="392-lda-18" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>19 0.59722239 <a title="392-lda-19" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>20 0.5972032 <a title="392-lda-20" href="../hunch_net-2005/hunch_net-2005-03-29-Academic_Mechanism_Design.html">48 hunch net-2005-03-29-Academic Mechanism Design</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
