<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>386 hunch net-2010-01-13-Sam Roweis died</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-386" href="#">hunch_net-2010-386</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>386 hunch net-2010-01-13-Sam Roweis died</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-386-html" href="http://hunch.net/?p=1172">html</a></p><p>Introduction: and I can’t help but remember him.
 
I first met  Sam  as an undergraduate at  Caltech  where he was TA for  Hopfield ‘s class, and again when I visited  Gatsby , when he invited me to visit  Toronto , and at too many conferences to recount.  His personality was a combination of enthusiastic and thoughtful, with a great ability to phrase a problem so it’s solution must be understood.  With respect to my own work, Sam was the one who advised me to make  my first tutorial , leading to others, and to other things, all of which I’m grateful to him for.  In fact, my every interaction with Sam was positive, and that was his way.
 
His death is  being called a suicide  which is so incompatible with my understanding of Sam that it strains my credibility.  But we know that his many responsibilities were great, and it is well understood that basically all sane researchers have legions of inner doubts.  Having been depressed now and then myself, it’s helpful to understand at least intellectually</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I first met  Sam  as an undergraduate at  Caltech  where he was TA for  Hopfield ‘s class, and again when I visited  Gatsby , when he invited me to visit  Toronto , and at too many conferences to recount. [sent-2, score-0.321]
</p><p>2 His personality was a combination of enthusiastic and thoughtful, with a great ability to phrase a problem so it’s solution must be understood. [sent-3, score-0.296]
</p><p>3 With respect to my own work, Sam was the one who advised me to make  my first tutorial , leading to others, and to other things, all of which I’m grateful to him for. [sent-4, score-0.076]
</p><p>4 In fact, my every interaction with Sam was positive, and that was his way. [sent-5, score-0.153]
</p><p>5 His death is  being called a suicide  which is so incompatible with my understanding of Sam that it strains my credibility. [sent-6, score-0.102]
</p><p>6 But we know that his many responsibilities were great, and it is well understood that basically all sane researchers have legions of inner doubts. [sent-7, score-0.275]
</p><p>7 Having been depressed now and then myself, it’s helpful to understand at least intellectually that the true darkness of the now is overestimated, and that you have more friends than you think. [sent-8, score-0.392]
</p><p>8 My last interaction with Sam, last week, was discussing a new research direction that interested him, optimizing the cost of acquiring feature information in the learning algorithm. [sent-10, score-0.468]
</p><p>9 This problem is endemic to real-world applications, and has been studied to some extent elsewhere, but I expect that in our unwritten future  history, we’ll discover that further study of this problem is more helpful than almost anyone realizes. [sent-11, score-0.329]
</p><p>10 The reply that I owed him feels heavy, and an incompleteness is hanging. [sent-12, score-0.199]
</p><p>11 For his wife and children it is surely so incomparably greater that I lack words. [sent-13, score-0.281]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sam', 0.645), ('memorial', 0.221), ('interaction', 0.153), ('fortnow', 0.11), ('inner', 0.11), ('overestimated', 0.11), ('depressed', 0.11), ('kevin', 0.11), ('intellectually', 0.11), ('toronto', 0.11), ('wife', 0.11), ('enthusiastic', 0.102), ('personality', 0.102), ('feels', 0.102), ('children', 0.102), ('incompatible', 0.102), ('reply', 0.097), ('heavy', 0.097), ('yisong', 0.097), ('yue', 0.097), ('thoughtful', 0.092), ('fund', 0.092), ('sane', 0.092), ('acquiring', 0.092), ('mine', 0.092), ('fernando', 0.092), ('phrase', 0.092), ('helpful', 0.092), ('lance', 0.088), ('endemic', 0.088), ('caltech', 0.088), ('ll', 0.087), ('undergraduate', 0.085), ('history', 0.083), ('others', 0.083), ('friends', 0.08), ('studied', 0.08), ('visit', 0.08), ('miss', 0.078), ('week', 0.078), ('met', 0.078), ('elsewhere', 0.078), ('visited', 0.078), ('leading', 0.076), ('discussing', 0.075), ('last', 0.074), ('basically', 0.073), ('discover', 0.069), ('remember', 0.069), ('surely', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="386-tfidf-1" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>Introduction: and I can’t help but remember him.
 
I first met  Sam  as an undergraduate at  Caltech  where he was TA for  Hopfield ‘s class, and again when I visited  Gatsby , when he invited me to visit  Toronto , and at too many conferences to recount.  His personality was a combination of enthusiastic and thoughtful, with a great ability to phrase a problem so it’s solution must be understood.  With respect to my own work, Sam was the one who advised me to make  my first tutorial , leading to others, and to other things, all of which I’m grateful to him for.  In fact, my every interaction with Sam was positive, and that was his way.
 
His death is  being called a suicide  which is so incompatible with my understanding of Sam that it strains my credibility.  But we know that his many responsibilities were great, and it is well understood that basically all sane researchers have legions of inner doubts.  Having been depressed now and then myself, it’s helpful to understand at least intellectually</p><p>2 0.20637819 <a title="386-tfidf-2" href="../hunch_net-2013/hunch_net-2013-11-21-Ben_Taskar_is_gone.html">491 hunch net-2013-11-21-Ben Taskar is gone</a></p>
<p>Introduction: I was not as personally close to  Ben  as  Sam , but the level of tragedy is similar and I canâ&euro;&trade;t help but be greatly saddened by the loss.
 
Various  news   stories  have coverage, but the synopsis is that he had a heart attack on Sunday and is survived by his wife Anat and daughter Aviv.  There is discussion of creating a memorial fund for them, which I hope comes to fruition, and plan to contribute to.  
 
I will remember Ben as someone who thought carefully and comprehensively about new ways to do things, then fought hard and successfully for what he believed in.  It is an ideal we strive for, that Ben accomplished.  
 
Edit: donations  go here , and more information is  here .</p><p>3 0.09511286 <a title="386-tfidf-3" href="../hunch_net-2009/hunch_net-2009-11-06-Yisong_Yue_on_Self-improving_Systems.html">376 hunch net-2009-11-06-Yisong Yue on Self-improving Systems</a></p>
<p>Introduction: I’d like to point out  Yisong Yue ‘s  post on Self-improving systems , which is a nicely readable description of the necessity and potential of interactive learning to deal with the information overload problem that is endemic to the modern internet.</p><p>4 0.089746594 <a title="386-tfidf-4" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>Introduction: A new direction of research seems to be arising in machine learning: Interactive Machine Learning.  This isn’t a familiar term, although it does include some familiar subjects.
 
 What is Interactive Machine Learning?   The fundamental requirement is (a) learning algorithms which interact with the world and (b) learn.  
 
For our purposes, let’s define learning as efficiently competing with a large set of possible predictors.  Examples include:
  
 Online learning against an adversary ( Avrim’s Notes ).  The interaction is almost trivial: the learning algorithm makes a prediction and then receives feedback. The learning is choosing based upon the advice of many experts. 
   Active Learning  .  In active learning, the interaction is choosing which examples to label, and the learning is choosing from amongst a large set of hypotheses. 
   Contextual Bandits  .  The interaction is choosing one of several actions and learning only the value of the chosen action (weaker than active learning</p><p>5 0.081756912 <a title="386-tfidf-5" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>Introduction: It was a fine time for learning in Pittsburgh. John and Sam mentioned some of my favorites. Here’s a few more worth checking out:
 
Online Multitask Learning 
Ofer Dekel, Phil Long, Yoram Singer 
This is on my reading list. Definitely an area I’m interested in.
 
Maximum Entropy Distribution Estimation with Generalized Regularization 
Miroslav DudÃƒÂ­k, Robert E. Schapire
 
Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path 
AndrÃƒÂ¡s Antos, Csaba SzepesvÃƒÂ¡ri, RÃƒÂ©mi Munos 
Again, on the list to read. I saw Csaba and Remi talk about this and related work at an ICML Workshop on Kernel Reinforcement Learning. The big question in my head is how this compares/contrasts with existing work in  reductions to reinforcement learning.  Are there advantages/disadvantages?
 
 Higher Order Learning On Graphs>  by Sameer Agarwal, Kristin Branson, and Serge Belongie, looks to be interesteding. They seem to poo-poo “tensorization</p><p>6 0.074343696 <a title="386-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>7 0.072633967 <a title="386-tfidf-7" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>8 0.066802733 <a title="386-tfidf-8" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>9 0.059729755 <a title="386-tfidf-9" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>10 0.058598325 <a title="386-tfidf-10" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>11 0.057717264 <a title="386-tfidf-11" href="../hunch_net-2009/hunch_net-2009-12-24-Top_graduates_this_season.html">384 hunch net-2009-12-24-Top graduates this season</a></p>
<p>12 0.051638987 <a title="386-tfidf-12" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>13 0.049472146 <a title="386-tfidf-13" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>14 0.048376989 <a title="386-tfidf-14" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>15 0.048181918 <a title="386-tfidf-15" href="../hunch_net-2006/hunch_net-2006-01-25-1_year.html">151 hunch net-2006-01-25-1 year</a></p>
<p>16 0.047209825 <a title="386-tfidf-16" href="../hunch_net-2010/hunch_net-2010-10-17-Partha_Niyogi_has_died.html">414 hunch net-2010-10-17-Partha Niyogi has died</a></p>
<p>17 0.046719942 <a title="386-tfidf-17" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>18 0.046594165 <a title="386-tfidf-18" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>19 0.04565876 <a title="386-tfidf-19" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>20 0.04544767 <a title="386-tfidf-20" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.113), (1, -0.017), (2, -0.057), (3, 0.039), (4, -0.029), (5, -0.003), (6, 0.019), (7, -0.001), (8, 0.001), (9, 0.011), (10, 0.007), (11, -0.041), (12, 0.004), (13, 0.033), (14, -0.024), (15, -0.018), (16, -0.018), (17, 0.01), (18, 0.054), (19, 0.068), (20, 0.031), (21, 0.008), (22, -0.03), (23, -0.034), (24, -0.012), (25, 0.009), (26, 0.03), (27, 0.056), (28, -0.039), (29, 0.07), (30, -0.0), (31, -0.06), (32, -0.024), (33, -0.049), (34, 0.018), (35, 0.025), (36, -0.028), (37, -0.014), (38, -0.031), (39, 0.186), (40, 0.073), (41, 0.006), (42, -0.012), (43, 0.078), (44, -0.05), (45, 0.005), (46, -0.08), (47, 0.007), (48, 0.019), (49, 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96131593 <a title="386-lsi-1" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>Introduction: and I can’t help but remember him.
 
I first met  Sam  as an undergraduate at  Caltech  where he was TA for  Hopfield ‘s class, and again when I visited  Gatsby , when he invited me to visit  Toronto , and at too many conferences to recount.  His personality was a combination of enthusiastic and thoughtful, with a great ability to phrase a problem so it’s solution must be understood.  With respect to my own work, Sam was the one who advised me to make  my first tutorial , leading to others, and to other things, all of which I’m grateful to him for.  In fact, my every interaction with Sam was positive, and that was his way.
 
His death is  being called a suicide  which is so incompatible with my understanding of Sam that it strains my credibility.  But we know that his many responsibilities were great, and it is well understood that basically all sane researchers have legions of inner doubts.  Having been depressed now and then myself, it’s helpful to understand at least intellectually</p><p>2 0.73174441 <a title="386-lsi-2" href="../hunch_net-2013/hunch_net-2013-11-21-Ben_Taskar_is_gone.html">491 hunch net-2013-11-21-Ben Taskar is gone</a></p>
<p>Introduction: I was not as personally close to  Ben  as  Sam , but the level of tragedy is similar and I canâ&euro;&trade;t help but be greatly saddened by the loss.
 
Various  news   stories  have coverage, but the synopsis is that he had a heart attack on Sunday and is survived by his wife Anat and daughter Aviv.  There is discussion of creating a memorial fund for them, which I hope comes to fruition, and plan to contribute to.  
 
I will remember Ben as someone who thought carefully and comprehensively about new ways to do things, then fought hard and successfully for what he believed in.  It is an ideal we strive for, that Ben accomplished.  
 
Edit: donations  go here , and more information is  here .</p><p>3 0.66431642 <a title="386-lsi-3" href="../hunch_net-2009/hunch_net-2009-11-06-Yisong_Yue_on_Self-improving_Systems.html">376 hunch net-2009-11-06-Yisong Yue on Self-improving Systems</a></p>
<p>Introduction: I’d like to point out  Yisong Yue ‘s  post on Self-improving systems , which is a nicely readable description of the necessity and potential of interactive learning to deal with the information overload problem that is endemic to the modern internet.</p><p>4 0.56374913 <a title="386-lsi-4" href="../hunch_net-2009/hunch_net-2009-12-24-Top_graduates_this_season.html">384 hunch net-2009-12-24-Top graduates this season</a></p>
<p>Introduction: I would like to point out 3 graduates this season as having my confidence they are capable of doing great things. 
  
  Daniel Hsu  has diverse papers with diverse coauthors on {active learning, mulitlabeling, temporal learning, …} each covering new algorithms and methods of analysis.  He is also a capable programmer, having helped me with some nitty-gritty details of cluster parallel  Vowpal Wabbit  this summer.  He has an excellent tendency to just get things done. 
  Nicolas Lambert  doesn’t nominally work in machine learning, but I’ve found his work in  elicitation  relevant nevertheless.  In essence, elicitable properties are closely related to learnable properties, and the elicitation complexity is related to a notion of learning complexity.  See the  Surrogate regret bounds paper  for some related discussion.  Few people successfully work at such a general level that it crosses fields, but he’s one of them. 
  Yisong Yue  is deeply focused on interactive learning, which he has a</p><p>5 0.50329089 <a title="386-lsi-5" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>Introduction: Researchers are typically confronted with big problems that they have no idea how to solve.  In trying to come up with a solution, a natural approach is to decompose the big problem into a set of subproblems whose solution yields a solution to the larger problem.  This approach can go wrong in several ways. 
  
  Decomposition failure .  The solution to the decomposition does not in fact yield a solution to the overall problem. 
  Artificial hardness .  The subproblems created are sufficient if solved to solve the overall problem, but they are harder than necessary. 
  
As you can see, computational complexity forms a relatively new (in research-history) razor by which to judge an approach sufficient but not necessary.
 
In my experience, the artificial hardness problem is very common.  Many researchers abdicate the responsibility of choosing a problem to work on to other people.  This process starts very naturally as a graduate student, when an incoming student might have relatively l</p><p>6 0.49817142 <a title="386-lsi-6" href="../hunch_net-2006/hunch_net-2006-12-05-Recruitment_Conferences.html">222 hunch net-2006-12-05-Recruitment Conferences</a></p>
<p>7 0.48450375 <a title="386-lsi-7" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>8 0.48309198 <a title="386-lsi-8" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>9 0.46251622 <a title="386-lsi-9" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>10 0.45920721 <a title="386-lsi-10" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>11 0.45865405 <a title="386-lsi-11" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>12 0.4557716 <a title="386-lsi-12" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>13 0.44854859 <a title="386-lsi-13" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>14 0.43896082 <a title="386-lsi-14" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<p>15 0.4363344 <a title="386-lsi-15" href="../hunch_net-2008/hunch_net-2008-07-04-More_Presentation_Preparation.html">307 hunch net-2008-07-04-More Presentation Preparation</a></p>
<p>16 0.43162736 <a title="386-lsi-16" href="../hunch_net-2005/hunch_net-2005-07-10-Thinking_the_Unthought.html">91 hunch net-2005-07-10-Thinking the Unthought</a></p>
<p>17 0.42901245 <a title="386-lsi-17" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>18 0.42668334 <a title="386-lsi-18" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>19 0.42554843 <a title="386-lsi-19" href="../hunch_net-2008/hunch_net-2008-11-28-A_Bumper_Crop_of_Machine_Learning_Graduates.html">329 hunch net-2008-11-28-A Bumper Crop of Machine Learning Graduates</a></p>
<p>20 0.42460731 <a title="386-lsi-20" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(10, 0.01), (13, 0.496), (27, 0.155), (38, 0.023), (53, 0.086), (54, 0.034), (55, 0.035), (94, 0.027), (95, 0.028)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97877848 <a title="386-lda-1" href="../hunch_net-2006/hunch_net-2006-10-13-David_Pennock_starts_Oddhead.html">214 hunch net-2006-10-13-David Pennock starts Oddhead</a></p>
<p>Introduction: his blog on information markets and other research topics .</p><p>2 0.91251785 <a title="386-lda-2" href="../hunch_net-2005/hunch_net-2005-12-09-Machine_Learning_Thoughts.html">137 hunch net-2005-12-09-Machine Learning Thoughts</a></p>
<p>Introduction: I added a link to Olivier Bousquetâ&euro;&trade;s  machine learning thoughts  blog.  Several of the posts may be of interest.</p><p>3 0.90393019 <a title="386-lda-3" href="../hunch_net-2005/hunch_net-2005-10-03-Not_ICML.html">117 hunch net-2005-10-03-Not ICML</a></p>
<p>Introduction: Alex Smola  showed me this  ICML 2006  webpage.  This is  NOT  the ICML we know, but rather some people at “Enformatika”.  Investigation shows that they registered with an anonymous yahoo email account from  dotregistrar.com  the “Home of the $6.79 wholesale domain!” and their nameservers are by  Turkticaret , a Turkish internet company.
 
It appears the website has since been altered to “ ICNL ” (the above link uses the google cache).
 
They say that imitation is the sincerest form of flattery, so the organizers of the real  ICML 2006  must feel quite flattered.</p><p>4 0.88347799 <a title="386-lda-4" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>Introduction: Aaron Hertzmann  points out the  health of conferences wiki , which has a great deal of information about how many different conferences function.</p><p>same-blog 5 0.85730731 <a title="386-lda-5" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>Introduction: and I can’t help but remember him.
 
I first met  Sam  as an undergraduate at  Caltech  where he was TA for  Hopfield ‘s class, and again when I visited  Gatsby , when he invited me to visit  Toronto , and at too many conferences to recount.  His personality was a combination of enthusiastic and thoughtful, with a great ability to phrase a problem so it’s solution must be understood.  With respect to my own work, Sam was the one who advised me to make  my first tutorial , leading to others, and to other things, all of which I’m grateful to him for.  In fact, my every interaction with Sam was positive, and that was his way.
 
His death is  being called a suicide  which is so incompatible with my understanding of Sam that it strains my credibility.  But we know that his many responsibilities were great, and it is well understood that basically all sane researchers have legions of inner doubts.  Having been depressed now and then myself, it’s helpful to understand at least intellectually</p><p>6 0.5493409 <a title="386-lda-6" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>7 0.51325709 <a title="386-lda-7" href="../hunch_net-2008/hunch_net-2008-08-04-Electoralmarkets.com.html">312 hunch net-2008-08-04-Electoralmarkets.com</a></p>
<p>8 0.50545555 <a title="386-lda-8" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>9 0.47230035 <a title="386-lda-9" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>10 0.34495384 <a title="386-lda-10" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>11 0.34323907 <a title="386-lda-11" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>12 0.34185782 <a title="386-lda-12" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>13 0.34021083 <a title="386-lda-13" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>14 0.33895099 <a title="386-lda-14" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>15 0.33877537 <a title="386-lda-15" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>16 0.33832437 <a title="386-lda-16" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>17 0.33728719 <a title="386-lda-17" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>18 0.33680186 <a title="386-lda-18" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>19 0.33641437 <a title="386-lda-19" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>20 0.33572999 <a title="386-lda-20" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
