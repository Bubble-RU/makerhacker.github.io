<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-413" href="#">hunch_net-2010-413</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-413-html" href="http://hunch.net/?p=1491">html</a></p><p>Introduction: Textbooks invariably seem to carry the proof that uses Markov's inequality,
moment-generating functions, and Taylor approximations. Here's an easier
way.For, letbe the KL divergence between a coin of biasand one of
bias:Theorem:Suppose you doindependent tosses of a coin of bias. The
probability of seeingheads or more, for, is at most. So is the probability of
seeingheads or less, for.Remark:By Pinsker's inequality,.ProofLet's do
thecase; the other is identical.Letbe the distribution overinduced by a coin
of bias, and likewisefor a coin of bias. Letbe the set of all sequences
oftosses which containheads or more. We'd like to show thatis unlikely
under.Pick any, with sayheads. Then:Sincefor every, we haveand we're done.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('coin', 0.623), ('letbe', 0.379), ('seeingheads', 0.379), ('bias', 0.19), ('carry', 0.168), ('invariably', 0.168), ('textbooks', 0.168), ('kl', 0.147), ('divergence', 0.147), ('probability', 0.146), ('sequences', 0.135), ('inequality', 0.135), ('unlikely', 0.126), ('suppose', 0.107), ('markov', 0.099), ('proof', 0.094), ('show', 0.091), ('functions', 0.084), ('theorem', 0.082), ('easier', 0.082)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="413-tfidf-1" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>Introduction: Textbooks invariably seem to carry the proof that uses Markov's inequality,
moment-generating functions, and Taylor approximations. Here's an easier
way.For, letbe the KL divergence between a coin of biasand one of
bias:Theorem:Suppose you doindependent tosses of a coin of bias. The
probability of seeingheads or more, for, is at most. So is the probability of
seeingheads or less, for.Remark:By Pinsker's inequality,.ProofLet's do
thecase; the other is identical.Letbe the distribution overinduced by a coin
of bias, and likewisefor a coin of bias. Letbe the set of all sequences
oftosses which containheads or more. We'd like to show thatis unlikely
under.Pick any, with sayheads. Then:Sincefor every, we haveand we're done.</p><p>2 0.084727868 <a title="413-tfidf-2" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provostgave a talk at the ICMLmetalearning workshopon "metalearning"
and the "no free lunch theorem" which seems worth summarizing.As a review: the
no free lunch theorem is the most complicated way we know of to say that
abiasis required in order to learn. The simplest way to see this is in a
nonprobabilistic setting. If you are given examples of the form(x,y)and you
wish to predictyfromxthen any prediction mechanism errs half the time in
expectation over all sequences of examples. The proof of this is very simple:
on every example a predictor must make some prediction and by symmetry over
the set of sequences it will be wrong half the time and right half the time.
The basic idea of this proof has been applied to many other settings.The
simplistic interpretation of this theorem which many people jump to is
"machine learning is dead" since there can be no single learning algorithm
which can solve all learning problems. This is the wrong way to think about
it. In the real world, w</p><p>3 0.07973101 <a title="413-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>Introduction: The essential problem here is the large gap between experimental observation
and theoretical understanding.MethodK-fold cross validation is a commonly used
technique which takes a set ofmexamples and partitions them intoKsets
("folds") of sizem/K. For each fold, a classifier is trained on the other
folds and then test on the fold.ProblemAssume only independent samples. Derive
a classifier from the K classifiers with a small bound on the true error
rate.Past Work(I'll add more as I remember/learn.)Devroye, Rogers, and Wagner
analyzed cross validation and found algorithm specific bounds. Not all of this
is online, but here is onepaper.Michael KearnsandDana Ronanalyzed cross
validationand found that under additional stability assumptions the bound for
the classifier which learns on all the data is not much worse than for a test
set of sizem/K.Avrim Blum,Adam Kalai, andmyselfanalyzed cross validationand
found that you can do at least as well as a test set of sizem/Kwith no
additional assum</p><p>4 0.072628476 <a title="413-tfidf-4" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>Introduction: Suppose we had an infinitely powerful mathematician sitting in a room and
proving theorems about learning. Could he solve machine learning?The answer is
"no". This answer is both obvious and sometimes underappreciated.There are
several ways to conclude that somebiasis necessary in order to succesfully
learn. For example, suppose we are trying to solve classification. At
prediction time, we observe some featuresXand want to make a prediction of
either0or1. Bias is what makes us prefer one answer over the other based on
past experience. In order to learn we must:Have a bias. Always predicting0is
as likely as1is useless.Have the "right" bias. Predicting1when the answer
is0is also not helpful.The implication of "have a bias" is that we can not
design effective learning algorithms with "a uniform prior over all
possibilities". The implication of "have the 'right' bias" is that our
mathematician fails since "right" is defined with respect to the solutions to
problems encountered in the real</p><p>5 0.071193844 <a title="413-tfidf-5" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these
suggest that some method of saying "I prefer this predictor to that predictor"
is useful and necessary. Examples include Bayesian reasoning, prediction
bounds, and online learning. One difficulty which arises is that the manner
and meaning of saying "I prefer this predictor to that predictor"
differs.Prior(Bayesian) A prior is a probability distribution over a set of
distributions which expresses a belief in the probability that some
distribution is the distribution generating the data."Prior"(Prediction bounds
& online learning) The "prior" is a measure over a set of classifiers which
expresses the degree to which you hope the classifier will predict
well.Bias(Regularization, Early termination of neural network training, etcâ&euro;Ś)
The bias is some (often implicitly specified by an algorithm) way of
preferring one predictor to another.This only scratches the surface--there are
yet more subtleties. For example the (as</p><p>6 0.066935211 <a title="413-tfidf-6" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>7 0.065975934 <a title="413-tfidf-7" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>8 0.06138926 <a title="413-tfidf-8" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>9 0.06125585 <a title="413-tfidf-9" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>10 0.047964238 <a title="413-tfidf-10" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<p>11 0.045123793 <a title="413-tfidf-11" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>12 0.043046106 <a title="413-tfidf-12" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>13 0.041540183 <a title="413-tfidf-13" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>14 0.040062901 <a title="413-tfidf-14" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>15 0.037658744 <a title="413-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>16 0.035094872 <a title="413-tfidf-16" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>17 0.034740403 <a title="413-tfidf-17" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>18 0.034712739 <a title="413-tfidf-18" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>19 0.034432001 <a title="413-tfidf-19" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>20 0.033766791 <a title="413-tfidf-20" href="../hunch_net-2006/hunch_net-2006-06-30-ICML_papers.html">188 hunch net-2006-06-30-ICML papers</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.05), (1, -0.038), (2, -0.034), (3, 0.0), (4, 0.009), (5, -0.02), (6, -0.044), (7, -0.016), (8, 0.007), (9, -0.039), (10, -0.003), (11, -0.01), (12, -0.043), (13, -0.065), (14, -0.063), (15, -0.011), (16, -0.005), (17, 0.01), (18, -0.077), (19, -0.013), (20, 0.004), (21, 0.018), (22, 0.003), (23, 0.026), (24, -0.003), (25, -0.041), (26, -0.017), (27, 0.006), (28, -0.023), (29, -0.017), (30, -0.044), (31, 0.036), (32, -0.05), (33, -0.051), (34, -0.026), (35, -0.008), (36, -0.014), (37, 0.013), (38, 0.055), (39, 0.075), (40, 0.007), (41, -0.031), (42, 0.034), (43, -0.004), (44, -0.002), (45, -0.015), (46, 0.012), (47, 0.008), (48, 0.02), (49, 0.012)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98159468 <a title="413-lsi-1" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>Introduction: Textbooks invariably seem to carry the proof that uses Markov's inequality,
moment-generating functions, and Taylor approximations. Here's an easier
way.For, letbe the KL divergence between a coin of biasand one of
bias:Theorem:Suppose you doindependent tosses of a coin of bias. The
probability of seeingheads or more, for, is at most. So is the probability of
seeingheads or less, for.Remark:By Pinsker's inequality,.ProofLet's do
thecase; the other is identical.Letbe the distribution overinduced by a coin
of bias, and likewisefor a coin of bias. Letbe the set of all sequences
oftosses which containheads or more. We'd like to show thatis unlikely
under.Pick any, with sayheads. Then:Sincefor every, we haveand we're done.</p><p>2 0.57584834 <a title="413-lsi-2" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>Introduction: Reviewers and students are sometimes greatly concerned by the distinction
between:Anopen setand aclosed set.ASupremumand aMaximum.An event which happens
with probability 1 and an event that always happens.I don't appreciate this
distinction in machine learning & learning theory. All machine learning takes
place (by definition) on a machine where every parameter has finite precision.
Consequently, every set is closed, a maximal element always exists, and
probability 1 events always happen.The fundamental issue here is that
substantial parts of mathematics don't appear well-matched to computation in
the physical world, because the mathematics has concerns which are unphysical.
This mismatched mathematics makes irrelevant distinctions. We can ask "what
mathematics is appropriate to computation?"Andrejhas convinced me that a
pretty good answer to this question isconstructive mathematics.So, here's a
basic challenge: Can anyone name a situation where any of the distinctions
above (or simila</p><p>3 0.56341332 <a title="413-lsi-3" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>Introduction: This is about methods for phrasing and think about the scope of some theorems
in learning theory. The basic claim is that there are several different ways
of quantifying the scope which sound different yet are essentially the
same.For all sequences of examples. This is the standard quantification in
online learning analysis. Standard theorems would say something like "for all
sequences of predictions by experts, the algorithm A will perform almost as
well as the best expert."For all training sets. This is the standard
quantification for boosting analysis such asadaboostormulticlass
boosting.Standard theorems have the form "for all training sets the error rate
inequalities … hold".For all distributions over examples. This is the one that
we have been using for reductions analysis. Standard theorem statements have
the form "For all distributions over examples, the error rate inequalities …
hold".It is not quite true that each of these is equivalent. For example, in
the online learning se</p><p>4 0.52536428 <a title="413-lsi-4" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.
There are at least 3 distinct ways the word is used.BayesianThe Bayesian
notion of probability is a 'degree of belief'. The degree of belief that some
event (i.e. "stock goes up" or "stock goes down") occurs can be measured by
asking a sequence of questions of the form "Would you bet the stock goes up or
down atYto 1 odds?" A consistent better will switch from 'for' to 'against' at
some single value ofY. The probability is thenY/(Y+1). Bayesian probabilities
express lack of knowledge rather than randomization. They are useful in
learning because we often lack knowledge and expressing that lack flexibly
makes the learning algorithms work better. Bayesian Learning uses
'probability' in this way exclusively.FrequentistThe Frequentist notion of
probability is a rate of occurence. A rate of occurrence can be measured by
doing an experiment many times. If an event occursktimes innexperiments then
it has probability ab</p><p>5 0.5087474 <a title="413-lsi-5" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these
suggest that some method of saying "I prefer this predictor to that predictor"
is useful and necessary. Examples include Bayesian reasoning, prediction
bounds, and online learning. One difficulty which arises is that the manner
and meaning of saying "I prefer this predictor to that predictor"
differs.Prior(Bayesian) A prior is a probability distribution over a set of
distributions which expresses a belief in the probability that some
distribution is the distribution generating the data."Prior"(Prediction bounds
& online learning) The "prior" is a measure over a set of classifiers which
expresses the degree to which you hope the classifier will predict
well.Bias(Regularization, Early termination of neural network training, etcâ&euro;Ś)
The bias is some (often implicitly specified by an algorithm) way of
preferring one predictor to another.This only scratches the surface--there are
yet more subtleties. For example the (as</p><p>6 0.49936306 <a title="413-lsi-6" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>7 0.48503092 <a title="413-lsi-7" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>8 0.43537429 <a title="413-lsi-8" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>9 0.42612311 <a title="413-lsi-9" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>10 0.42357844 <a title="413-lsi-10" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>11 0.41462445 <a title="413-lsi-11" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>12 0.40385744 <a title="413-lsi-12" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>13 0.40106627 <a title="413-lsi-13" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>14 0.39881119 <a title="413-lsi-14" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>15 0.3935765 <a title="413-lsi-15" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>16 0.38781941 <a title="413-lsi-16" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>17 0.38536802 <a title="413-lsi-17" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>18 0.38516086 <a title="413-lsi-18" href="../hunch_net-2005/hunch_net-2005-02-02-Kolmogorov_Complexity_and_Googling.html">10 hunch net-2005-02-02-Kolmogorov Complexity and Googling</a></p>
<p>19 0.38352284 <a title="413-lsi-19" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>20 0.38100013 <a title="413-lsi-20" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.143), (68, 0.063), (74, 0.077), (81, 0.526)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91567689 <a title="413-lda-1" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>Introduction: Textbooks invariably seem to carry the proof that uses Markov's inequality,
moment-generating functions, and Taylor approximations. Here's an easier
way.For, letbe the KL divergence between a coin of biasand one of
bias:Theorem:Suppose you doindependent tosses of a coin of bias. The
probability of seeingheads or more, for, is at most. So is the probability of
seeingheads or less, for.Remark:By Pinsker's inequality,.ProofLet's do
thecase; the other is identical.Letbe the distribution overinduced by a coin
of bias, and likewisefor a coin of bias. Letbe the set of all sequences
oftosses which containheads or more. We'd like to show thatis unlikely
under.Pick any, with sayheads. Then:Sincefor every, we haveand we're done.</p><p>2 0.88752258 <a title="413-lda-2" href="../hunch_net-2008/hunch_net-2008-08-18-Radford_Neal_starts_a_blog.html">313 hunch net-2008-08-18-Radford Neal starts a blog</a></p>
<p>Introduction: hereon statistics, ML, CS, and other things he knows well.</p><p>3 0.63565701 <a title="413-lda-3" href="../hunch_net-2007/hunch_net-2007-06-21-Presentation_Preparation.html">249 hunch net-2007-06-21-Presentation Preparation</a></p>
<p>Introduction: A big part of doing research is presenting it at a conference. Since many
people start out shy of public presentations, this can be a substantial
challenge. Here are a few notes which might be helpful when thinking about
preparing a presentation on research.Motivate. Talks which don't start by
describing the problem to solve cause many people to zone out.Prioritize. It
is typical that you have more things to say than time to say them, and many
presenters fall into the failure mode of trying to say too much. This is an
easy-to-understand failure mode as it's very natural to want to include
everything. A basic fact is: you can't. Example of this are:Your slides are so
densely full of equations and words that you can't cover them.Your talk runs
over and a moderator prioritizes for you by cutting you off.You motor-mouth
through the presentation, and the information absorption rate of the audience
prioritizes in some uncontrolled fashion.The rate of flow of concepts simply
exceeds the infor</p><p>4 0.57889199 <a title="413-lda-4" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>Introduction: After amajor financial crisis, there is much discussion about howfinance has
become a casinogambling with other's money, keeping the winnings, and walking
away when the money is lost.When thinking about financial reform, all the many
losers in the above scenario are apt to take the view that this activity
should be completely, or nearly completely curtailed. But, a more thoughtful
view is that sometimes there is a real sense in which there are right and
wrong decisions, and we as a society would really prefer that the people most
likely to make right decisions are making them. A crucial question then is:
"What is the difference between gambling and rewarding good
prediction?"Wediscussed this before the financial crisis. The cheat-sheet
sketch is that the online learning against an adversary problem, algorithm,
and theorems, provide a good mathematical model for thinking about this
question. What I would like to do here is map this onto various types of
financial transactions. The basic</p><p>5 0.51956934 <a title="413-lda-5" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<p>Introduction: There are a number of learning algorithms which explicitly incorporate
randomness into their execution. This includes at amongst others:Neural
Networks. Neural networks use randomization to assign initial
weights.Boltzmann Machines/Deep Belief Networks. Boltzmann machines are
something like a stochastic version of multinode logistic regression. The use
of randomness is more essential in Boltzmann machines, because the predicted
value at test time also uses randomness.Bagging. Bagging is a process where a
learning algorithm is run several different times on several different
datasets, creating a final predictor which makes a majority vote.Policy
descent. Several algorithms in reinforcement learning such asConservative
Policy Iterationuse random bits to create stochastic policies.Experts
algorithms. Randomized weighted majority use random bits as a part of the
prediction process to achieve better theoretical guarantees.A basic question
is: "Should there be explicit randomization in learn</p><p>6 0.45575631 <a title="413-lda-6" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<p>7 0.31369051 <a title="413-lda-7" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>8 0.30998158 <a title="413-lda-8" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>9 0.30552521 <a title="413-lda-9" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>10 0.30401593 <a title="413-lda-10" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>11 0.30158341 <a title="413-lda-11" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>12 0.30050692 <a title="413-lda-12" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>13 0.30011716 <a title="413-lda-13" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>14 0.30007353 <a title="413-lda-14" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>15 0.298558 <a title="413-lda-15" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>16 0.2976909 <a title="413-lda-16" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>17 0.29761142 <a title="413-lda-17" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>18 0.29720187 <a title="413-lda-18" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>19 0.29671448 <a title="413-lda-19" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>20 0.29663229 <a title="413-lda-20" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
