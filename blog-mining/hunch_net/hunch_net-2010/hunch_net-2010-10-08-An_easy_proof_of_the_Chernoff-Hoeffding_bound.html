<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-413" href="#">hunch_net-2010-413</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-413-html" href="http://hunch.net/?p=1491">html</a></p><p>Introduction: Textbooks invariably seem to carry the proof that uses Markov’s inequality, moment-generating functions, and Taylor approximations. Here’s an easier way.
 
For  , let   be the KL divergence between a coin of bias   and one of bias  :  
 
 Theorem:  Suppose you do   independent tosses of a coin of bias  . The probability of seeing   heads or more, for  , is at most  . So is the probability of seeing   heads or less, for  .
 
 Remark:  By Pinsker’s inequality,  .
 
 Proof  Let’s do the   case; the other is identical.
 
Let   be the distribution over   induced by a coin of bias  , and likewise   for a coin of bias  . Let   be the set of all sequences of   tosses which contain   heads or more. We’d like to show that   is unlikely under  .
 
Pick any  , with say   heads. Then: 
 
 
Since   for every  , we have   and we’re done.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Textbooks invariably seem to carry the proof that uses Markov’s inequality, moment-generating functions, and Taylor approximations. [sent-1, score-0.491]
</p><p>2 For  , let   be the KL divergence between a coin of bias   and one of bias  :      Theorem:  Suppose you do   independent tosses of a coin of bias  . [sent-3, score-2.75]
</p><p>3 The probability of seeing   heads or more, for  , is at most  . [sent-4, score-0.74]
</p><p>4 So is the probability of seeing   heads or less, for  . [sent-5, score-0.74]
</p><p>5 Let   be the distribution over   induced by a coin of bias  , and likewise   for a coin of bias  . [sent-8, score-1.94]
</p><p>6 Let   be the set of all sequences of   tosses which contain   heads or more. [sent-9, score-0.966]
</p><p>7 Then:      Since   for every  , we have   and we’re done. [sent-12, score-0.047]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('coin', 0.481), ('heads', 0.439), ('bias', 0.352), ('tosses', 0.292), ('let', 0.239), ('inequality', 0.208), ('seeing', 0.189), ('proof', 0.141), ('invariably', 0.13), ('textbooks', 0.13), ('carry', 0.12), ('likewise', 0.12), ('kl', 0.114), ('divergence', 0.114), ('probability', 0.112), ('sequences', 0.104), ('induced', 0.1), ('contain', 0.097), ('unlikely', 0.097), ('re', 0.086), ('markov', 0.077), ('pick', 0.077), ('suppose', 0.076), ('independent', 0.072), ('show', 0.069), ('functions', 0.064), ('easier', 0.063), ('theorem', 0.062), ('uses', 0.058), ('say', 0.058), ('distribution', 0.054), ('every', 0.047), ('case', 0.046), ('done', 0.044), ('less', 0.044), ('seem', 0.042), ('since', 0.037), ('set', 0.034), ('like', 0.026), ('one', 0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="413-tfidf-1" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>Introduction: Textbooks invariably seem to carry the proof that uses Markov’s inequality, moment-generating functions, and Taylor approximations. Here’s an easier way.
 
For  , let   be the KL divergence between a coin of bias   and one of bias  :  
 
 Theorem:  Suppose you do   independent tosses of a coin of bias  . The probability of seeing   heads or more, for  , is at most  . So is the probability of seeing   heads or less, for  .
 
 Remark:  By Pinsker’s inequality,  .
 
 Proof  Let’s do the   case; the other is identical.
 
Let   be the distribution over   induced by a coin of bias  , and likewise   for a coin of bias  . Let   be the set of all sequences of   tosses which contain   heads or more. We’d like to show that   is unlikely under  .
 
Pick any  , with say   heads. Then: 
 
 
Since   for every  , we have   and we’re done.</p><p>2 0.13040477 <a title="413-tfidf-2" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>Introduction: Suppose we had an infinitely powerful mathematician sitting in a room and proving theorems about learning.  Could he solve machine learning?
 
The answer is “no”.   This answer is both obvious and sometimes underappreciated.   
 
There are several ways to conclude that some  bias  is necessary in order to succesfully learn.  For example, suppose we are trying to solve classification.  At prediction time, we observe some features  X  and want to make a prediction of either  0  or  1 .   Bias is what makes us prefer one answer over the other based on past experience.  In order to learn we must:
  
 Have a bias.  Always predicting  0  is as likely as  1  is useless. 
 Have the “right” bias.  Predicting  1  when the answer is  0  is also not helpful. 
  
The implication of “have a bias” is that we can not design effective learning algorithms with “a uniform prior over all possibilities”.  The implication of “have the ‘right’ bias” is that our mathematician fails since “right” is defined wi</p><p>3 0.10313512 <a title="413-tfidf-3" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provost  gave a talk at the ICML  metalearning workshop  on “metalearning” and the “no free lunch theorem” which seems worth summarizing.
 
As a review: the no free lunch theorem is the most complicated way we know of to say that a  bias  is required in order to learn.  The simplest way to see this is in a nonprobabilistic setting.  If you are given examples of the form  (x,y)  and you wish to predict  y  from  x  then any prediction mechanism errs half the time in expectation over all sequences of examples.  The proof of this is very simple: on every example a predictor must make some prediction and by symmetry over the set of sequences it will be wrong half the time and right half the time.  The basic idea of this proof has been applied to many other settings.
 
The simplistic interpretation of this theorem which many people jump to is “machine learning is dead” since there can be no single learning algorithm which can solve all learning problems.  This is the wrong way to thi</p><p>4 0.099200279 <a title="413-tfidf-4" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these suggest that some method of saying “I prefer this predictor to that predictor” is useful and necessary.  Examples include Bayesian reasoning, prediction bounds, and online learning.   One difficulty which arises is that the manner and meaning of saying “I prefer this predictor to that predictor” differs.
  
  Prior  (Bayesian) A prior is a probability distribution over a set of distributions which expresses a belief in the probability that some distribution is the distribution generating the data. 
  “Prior”  (Prediction bounds & online learning) The “prior” is a measure over a set of classifiers which expresses the degree to which you hope the classifier will predict well. 
  Bias  (Regularization, Early termination of neural network training, etc…)  The bias is some (often implicitly specified by an algorithm) way of preferring one predictor to another. 
  
This only scratches the surface—there are yet more subt</p><p>5 0.06590756 <a title="413-tfidf-5" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>Introduction: This is about a design flaw in several learning algorithms such as the Naive Bayes classifier and Hidden Markov Models.  A number of people are aware of it, but it seems that not everyone is.
 
Several learning systems have the property that they estimate some conditional probabilities  P(event | other events)  either explicitly or implicitly.  Then, at prediction time, these learned probabilities are multiplied together according to some formula to produce a final prediction.  The Naive Bayes classifier for binary data is the simplest of these, so it seems like a good example.  
 
When Naive Bayes is used, a set of probabilities of the form  Pr’(feature i | label)  are estimated via counting statistics and some prior.  Predictions are made according to the label maximizing: 
  Pr’(label) * Product features i  Pr’(feature i | label)  
 
(The  Pr’  notation indicates these are estimated values.) 
 
There is nothing wrong with this method as long as (a) the prior for the sample counts is</p><p>6 0.065905735 <a title="413-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>7 0.065768585 <a title="413-tfidf-7" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>8 0.065442502 <a title="413-tfidf-8" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<p>9 0.056388721 <a title="413-tfidf-9" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>10 0.050944664 <a title="413-tfidf-10" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>11 0.05080907 <a title="413-tfidf-11" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>12 0.05025686 <a title="413-tfidf-12" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>13 0.049068186 <a title="413-tfidf-13" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>14 0.049044903 <a title="413-tfidf-14" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>15 0.046316426 <a title="413-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-09-Intuitions_from_applied_learning.html">16 hunch net-2005-02-09-Intuitions from applied learning</a></p>
<p>16 0.045940615 <a title="413-tfidf-16" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>17 0.044942077 <a title="413-tfidf-17" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>18 0.043656532 <a title="413-tfidf-18" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>19 0.042312156 <a title="413-tfidf-19" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>20 0.04163909 <a title="413-tfidf-20" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.064), (1, 0.04), (2, 0.037), (3, 0.002), (4, 0.004), (5, -0.017), (6, 0.021), (7, 0.014), (8, 0.048), (9, -0.044), (10, 0.008), (11, -0.006), (12, 0.067), (13, -0.03), (14, 0.056), (15, -0.008), (16, -0.047), (17, -0.006), (18, 0.015), (19, 0.021), (20, -0.031), (21, -0.008), (22, 0.067), (23, -0.036), (24, 0.009), (25, 0.0), (26, 0.05), (27, -0.017), (28, -0.056), (29, 0.012), (30, 0.024), (31, -0.01), (32, -0.043), (33, 0.029), (34, -0.054), (35, -0.045), (36, -0.051), (37, 0.086), (38, 0.018), (39, -0.037), (40, -0.059), (41, 0.0), (42, -0.095), (43, -0.034), (44, -0.013), (45, -0.046), (46, 0.023), (47, 0.121), (48, -0.065), (49, -0.008)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99048465 <a title="413-lsi-1" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>Introduction: Textbooks invariably seem to carry the proof that uses Markov’s inequality, moment-generating functions, and Taylor approximations. Here’s an easier way.
 
For  , let   be the KL divergence between a coin of bias   and one of bias  :  
 
 Theorem:  Suppose you do   independent tosses of a coin of bias  . The probability of seeing   heads or more, for  , is at most  . So is the probability of seeing   heads or less, for  .
 
 Remark:  By Pinsker’s inequality,  .
 
 Proof  Let’s do the   case; the other is identical.
 
Let   be the distribution over   induced by a coin of bias  , and likewise   for a coin of bias  . Let   be the set of all sequences of   tosses which contain   heads or more. We’d like to show that   is unlikely under  .
 
Pick any  , with say   heads. Then: 
 
 
Since   for every  , we have   and we’re done.</p><p>2 0.52211827 <a title="413-lsi-2" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these suggest that some method of saying “I prefer this predictor to that predictor” is useful and necessary.  Examples include Bayesian reasoning, prediction bounds, and online learning.   One difficulty which arises is that the manner and meaning of saying “I prefer this predictor to that predictor” differs.
  
  Prior  (Bayesian) A prior is a probability distribution over a set of distributions which expresses a belief in the probability that some distribution is the distribution generating the data. 
  “Prior”  (Prediction bounds & online learning) The “prior” is a measure over a set of classifiers which expresses the degree to which you hope the classifier will predict well. 
  Bias  (Regularization, Early termination of neural network training, etc…)  The bias is some (often implicitly specified by an algorithm) way of preferring one predictor to another. 
  
This only scratches the surface—there are yet more subt</p><p>3 0.50787073 <a title="413-lsi-3" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>Introduction: This is about a design flaw in several learning algorithms such as the Naive Bayes classifier and Hidden Markov Models.  A number of people are aware of it, but it seems that not everyone is.
 
Several learning systems have the property that they estimate some conditional probabilities  P(event | other events)  either explicitly or implicitly.  Then, at prediction time, these learned probabilities are multiplied together according to some formula to produce a final prediction.  The Naive Bayes classifier for binary data is the simplest of these, so it seems like a good example.  
 
When Naive Bayes is used, a set of probabilities of the form  Pr’(feature i | label)  are estimated via counting statistics and some prior.  Predictions are made according to the label maximizing: 
  Pr’(label) * Product features i  Pr’(feature i | label)  
 
(The  Pr’  notation indicates these are estimated values.) 
 
There is nothing wrong with this method as long as (a) the prior for the sample counts is</p><p>4 0.50594842 <a title="413-lsi-4" href="../hunch_net-2005/hunch_net-2005-04-26-To_calibrate_or_not%3F.html">62 hunch net-2005-04-26-To calibrate or not?</a></p>
<p>Introduction: A calibrated predictor is one which predicts the probability of a binary event with the property: For all predictions  p , the proportion of the time that  1  is observed is  p .
 
Since there are infinitely many  p , this definition must be “softened” to make sense for any finite number of samples.  The standard method for “softening” is to consider all predictions in a small neighborhood about each possible  p .
 
A great deal of effort has been devoted to strategies for achieving calibrated (such as  here ) prediction.  With statements like: (under minimal conditions) you can always make calibrated predictions.  
 
Given the strength of these statements, we might conclude we are done, but that would be a “confusion of ends”.  A confusion of ends arises in the following way:
  
 We want good probabilistic predictions. 
 Good probabilistic predictions are calibrated. 
 Therefore, we want calibrated predictions. 
  
The “Therefore” step misses the fact that calibration is a necessary b</p><p>5 0.49173436 <a title="413-lsi-5" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provost  gave a talk at the ICML  metalearning workshop  on “metalearning” and the “no free lunch theorem” which seems worth summarizing.
 
As a review: the no free lunch theorem is the most complicated way we know of to say that a  bias  is required in order to learn.  The simplest way to see this is in a nonprobabilistic setting.  If you are given examples of the form  (x,y)  and you wish to predict  y  from  x  then any prediction mechanism errs half the time in expectation over all sequences of examples.  The proof of this is very simple: on every example a predictor must make some prediction and by symmetry over the set of sequences it will be wrong half the time and right half the time.  The basic idea of this proof has been applied to many other settings.
 
The simplistic interpretation of this theorem which many people jump to is “machine learning is dead” since there can be no single learning algorithm which can solve all learning problems.  This is the wrong way to thi</p><p>6 0.48763195 <a title="413-lsi-6" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>7 0.46890059 <a title="413-lsi-7" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>8 0.46440774 <a title="413-lsi-8" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>9 0.45221737 <a title="413-lsi-9" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>10 0.43727225 <a title="413-lsi-10" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>11 0.43641642 <a title="413-lsi-11" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>12 0.42357495 <a title="413-lsi-12" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>13 0.41709659 <a title="413-lsi-13" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>14 0.41189522 <a title="413-lsi-14" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>15 0.3951036 <a title="413-lsi-15" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<p>16 0.38572964 <a title="413-lsi-16" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>17 0.38303635 <a title="413-lsi-17" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>18 0.37604076 <a title="413-lsi-18" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>19 0.37547934 <a title="413-lsi-19" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>20 0.37189224 <a title="413-lsi-20" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.02), (26, 0.581), (27, 0.104), (38, 0.071), (94, 0.059)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94584155 <a title="413-lda-1" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>Introduction: Textbooks invariably seem to carry the proof that uses Markov’s inequality, moment-generating functions, and Taylor approximations. Here’s an easier way.
 
For  , let   be the KL divergence between a coin of bias   and one of bias  :  
 
 Theorem:  Suppose you do   independent tosses of a coin of bias  . The probability of seeing   heads or more, for  , is at most  . So is the probability of seeing   heads or less, for  .
 
 Remark:  By Pinsker’s inequality,  .
 
 Proof  Let’s do the   case; the other is identical.
 
Let   be the distribution over   induced by a coin of bias  , and likewise   for a coin of bias  . Let   be the set of all sequences of   tosses which contain   heads or more. We’d like to show that   is unlikely under  .
 
Pick any  , with say   heads. Then: 
 
 
Since   for every  , we have   and we’re done.</p><p>2 0.92968917 <a title="413-lda-2" href="../hunch_net-2006/hunch_net-2006-04-09-Progress_in_Machine_Translation.html">171 hunch net-2006-04-09-Progress in Machine Translation</a></p>
<p>Introduction: I just visited  ISI  where  Daniel Marcu  and others are working on machine translation.  Apparently, machine translation is rapidly improving.   A particularly dramatic year was 2002->2003 when systems switched from word-based translation to phrase-based translation.  From a (now famous) slide by Charles Wayne at  DARPA  (which funds much of the work on machine translation) here is some anecdotal evidence:
  
 
 2002 
 2003 
 
 
 insistent Wednesday may recurred her trips to Libya tomorrow for flying.

 Cairo 6-4 ( AFP ) – An official announced today in the Egyptian lines company for flying  Tuesday is a company “insistent for flying” may resumed a consideration of a day Wednesday tomorrow her trips to Libya of Security Council decision trace international the imposed ban comment.


 And said the official “the institution sent a speech to Ministry of Foreign Affairs of lifting on Libya air, a situation her recieving replying are so a trip will pull to Libya a morning Wednesday.”

 
 E</p><p>3 0.74353492 <a title="413-lda-3" href="../hunch_net-2005/hunch_net-2005-02-10-Conferences%2C_Dates%2C_Locations.html">17 hunch net-2005-02-10-Conferences, Dates, Locations</a></p>
<p>Introduction: Conference 
 Locate 
 Date 
 
 
  COLT  
 Bertinoro, Italy 
 June 27-30 
 
 
  AAAI  
 Pittsburgh, PA, USA 
 July 9-13 
 
 
  UAI  
 Edinburgh, Scotland 
 July 26-29 
 
 
  IJCAI  
 Edinburgh, Scotland 
 July 30 â&euro;&ldquo; August 5 
 
 
  ICML  
 Bonn, Germany 
 August 7-11 
 
 
  KDD  
 Chicago, IL, USA 
 August 21-24 
 
  
The big winner this year is Europe.   This is partly a coincidence, and partly due to the general internationalization of science over the last few years.  With  cuts to basic science  in the US and increased hassle for visitors, conferences outside the US become more attractive.   Europe and Australia/New Zealand are the immediate winners because they have the science, infrastructure, and english in place.  China and India are possible future winners.</p><p>4 0.58357942 <a title="413-lda-4" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>Introduction: A  recent discussion  indicated that one goal of this blog might be to allow people to post comments about recent papers that they liked.  I think this could potentially be very useful, especially for those with diverse interests but only finite time to read through conference proceedings.   ACL 2005  recently completed, and here are four papers from that conference that I thought were either good or perhaps of interest to a machine learning audience.
 
David Chiang,   A Hierarchical Phrase-Based Model for Statistical Machine Translation  . (Best paper award.) This paper takes the standard phrase-based MT model that is popular in our field (basically, translate a sentence by individually translating phrases and reordering them according to a complicated statistical model) and extends it to take into account hierarchy in phrases, so that you can learn things like “X ‘s Y” -> “Y de X” in chinese, where X and Y are arbitrary phrases. This takes a step toward linguistic syntax for MT, whic</p><p>5 0.57871807 <a title="413-lda-5" href="../hunch_net-2008/hunch_net-2008-06-30-ICML_has_a_comment_system.html">305 hunch net-2008-06-30-ICML has a comment system</a></p>
<p>Introduction: Mark Reid  has stepped up and created a  comment system for ICML papers  which  Greger Linden  has tightly integrated.  
 
My understanding is that Mark spent quite  a bit of time on the details, and there are some cool features like working latex math mode.  This is an excellent chance for the ICML community to experiment with making ICML year-round, so I hope it works out.  Please do consider experimenting with it.</p><p>6 0.50242537 <a title="413-lda-6" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>7 0.4381952 <a title="413-lda-7" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>8 0.22470853 <a title="413-lda-8" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>9 0.220781 <a title="413-lda-9" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>10 0.21758455 <a title="413-lda-10" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>11 0.21569277 <a title="413-lda-11" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>12 0.21276566 <a title="413-lda-12" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>13 0.21157792 <a title="413-lda-13" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>14 0.21139011 <a title="413-lda-14" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>15 0.21131918 <a title="413-lda-15" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>16 0.20993428 <a title="413-lda-16" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>17 0.20864658 <a title="413-lda-17" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>18 0.2060539 <a title="413-lda-18" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>19 0.2039084 <a title="413-lda-19" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>20 0.20371997 <a title="413-lda-20" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
