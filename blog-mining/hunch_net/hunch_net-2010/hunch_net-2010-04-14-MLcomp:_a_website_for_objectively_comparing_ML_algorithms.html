<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-393" href="#">hunch_net-2010-393</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-393-html" href="http://hunch.net/?p=1309">html</a></p><p>Introduction: Much of the success and popularity of machine learning has been driven by its
practical impact. Of course, the evaluation of empirical work is an integral
part of the field. But are the existing mechanisms for evaluating algorithms
and comparing results good enough? We (PercyandJake) believe there are
currently a number of shortcomings:Incomplete Disclosure:You read a paper that
proposes Algorithm A which is shown to outperform SVMs on two datasets.
Great.  But what about on other datasets?  How sensitive is this result?
What about compute time - does the algorithm take two seconds on a laptop or
two weeks on a 100-node cluster?Lack of Standardization:Algorithm A beats
Algorithm B on one version of a dataset.  Algorithm B beats Algorithm A on
another version yet uses slightly different preprocessing.  Though doing a
head-on comparison would be ideal, it would be tedious since the programs
probably use different dataset formats and have a large array of options.  And
what if we wanted t</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Much of the success and popularity of machine learning has been driven by its practical impact. [sent-1, score-0.163]
</p><p>2 Of course, the evaluation of empirical work is an integral part of the field. [sent-2, score-0.08]
</p><p>3 But are the existing mechanisms for evaluating algorithms and comparing results good enough? [sent-3, score-0.306]
</p><p>4 We (PercyandJake) believe there are currently a number of shortcomings:Incomplete Disclosure:You read a paper that proposes Algorithm A which is shown to outperform SVMs on two datasets. [sent-4, score-0.364]
</p><p>5 What about compute time - does the algorithm take two seconds on a laptop or two weeks on a 100-node cluster? [sent-8, score-0.336]
</p><p>6 Lack of Standardization:Algorithm A beats Algorithm B on one version of a dataset. [sent-9, score-0.303]
</p><p>7 Algorithm B beats Algorithm A on another version yet uses slightly different preprocessing. [sent-10, score-0.303]
</p><p>8 Though doing a head-on comparison would be ideal, it would be tedious since the programs probably use different dataset formats and have a large array of options. [sent-11, score-0.712]
</p><p>9 And what if we wanted to compare on more than just one dataset and two algorithms? [sent-12, score-0.346]
</p><p>10 Incomplete View of State-of-the-Art:Basic question: What's the best algorithm for your favorite dataset? [sent-13, score-0.156]
</p><p>11 To find out, you could simply plow through fifty papers, get code from any author willing to reply, and reimplement the rest. [sent-14, score-0.235]
</p><p>12 In short, it's a collaborative website for objectively comparing machine learning programs across various datasets. [sent-20, score-0.824]
</p><p>13 On the website, a user can do any combination of the following:Upload a program to our online repository. [sent-21, score-0.425]
</p><p>14 )For any executed run, view the results (various error metrics and time/memory usage statistics). [sent-25, score-0.359]
</p><p>15 An important aspect of the site is that it'scollaborative: by uploading just one program or dataset, a user taps into the entire network of existing programs and datasets for comparison. [sent-27, score-1.092]
</p><p>16 org), MLcomp is unique in that data and code interact to produce analyzable results. [sent-31, score-0.22]
</p><p>17 Currently, seven machine learn task types (classification, regression, collaborative filtering, sequence tagging, etc. [sent-33, score-0.238]
</p><p>18 ) are supported, with hundreds of standard programs and datasets already online. [sent-34, score-0.453]
</p><p>19 We encourage you to browse the site and hopefully contribute more! [sent-35, score-0.189]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mlcomp', 0.324), ('user', 0.271), ('dataset', 0.256), ('programs', 0.223), ('beats', 0.216), ('collaborative', 0.168), ('algorithm', 0.156), ('program', 0.154), ('incomplete', 0.153), ('datasets', 0.15), ('comparing', 0.148), ('code', 0.146), ('site', 0.117), ('website', 0.117), ('currently', 0.108), ('view', 0.104), ('shortcomings', 0.096), ('objectively', 0.096), ('disclosure', 0.096), ('amazon', 0.096), ('uploading', 0.096), ('two', 0.09), ('usage', 0.089), ('tedious', 0.089), ('supported', 0.089), ('reimplement', 0.089), ('proposes', 0.089), ('executed', 0.089), ('popularity', 0.089), ('upload', 0.089), ('version', 0.087), ('reply', 0.084), ('run', 0.082), ('existing', 0.081), ('integral', 0.08), ('uci', 0.08), ('tagging', 0.08), ('hundreds', 0.08), ('metrics', 0.077), ('outperform', 0.077), ('evaluating', 0.077), ('today', 0.074), ('driven', 0.074), ('interact', 0.074), ('formats', 0.074), ('various', 0.072), ('contribute', 0.072), ('svms', 0.07), ('types', 0.07), ('array', 0.07)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999964 <a title="393-tfidf-1" href="../hunch_net-2010/hunch_net-2010-04-14-MLcomp%3A_a_website_for_objectively_comparing_ML_algorithms.html">393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</a></p>
<p>Introduction: Much of the success and popularity of machine learning has been driven by its
practical impact. Of course, the evaluation of empirical work is an integral
part of the field. But are the existing mechanisms for evaluating algorithms
and comparing results good enough? We (PercyandJake) believe there are
currently a number of shortcomings:Incomplete Disclosure:You read a paper that
proposes Algorithm A which is shown to outperform SVMs on two datasets.
Great.  But what about on other datasets?  How sensitive is this result?
What about compute time - does the algorithm take two seconds on a laptop or
two weeks on a 100-node cluster?Lack of Standardization:Algorithm A beats
Algorithm B on one version of a dataset.  Algorithm B beats Algorithm A on
another version yet uses slightly different preprocessing.  Though doing a
head-on comparison would be ideal, it would be tedious since the programs
probably use different dataset formats and have a large array of options.  And
what if we wanted t</p><p>2 0.15988468 <a title="393-tfidf-2" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>Introduction: Normally, I don't indulge in posters forICML, but this year is naturally an
exception for me. If you want one, there are a small numberleft here, if you
sign up before February.It also seems worthwhile to give some sense of the
scope and reviewing criteria for ICML for authors considering submitting
papers. At ICML, the (very large) program committee does the reviewing which
informs final decisions by area chairs on most papers. Program chairs setup
the process, deal with exceptions or disagreements, and provide advice for the
reviewing process. Providing advice is tricky (and easily misleading) because
a conference is a community, and in the end the aggregate interests of the
community determine the conference. Nevertheless, as a program chair this year
it seems worthwhile to state the overall philosophy I have and what I plan to
encourage (and occasionally discourage).At the highest level, I believe ICML
exists to further research into machine learning, which I generally think of
as</p><p>3 0.14732179 <a title="393-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>Introduction: "Overfitting" is traditionally defined as training some flexible
representation so that it memorizes the data but fails to predict well in the
future. For this post, I will define overfitting more generally as over-
representing the performance of systems. There are two styles of general
overfitting: overrepresenting performance on particular datasets and
(implicitly) overrepresenting performance of a method on future datasets.We
should all be aware of these methods, avoid them where possible, and take them
into account otherwise. I have used "reproblem" and "old datasets", and may
have participated in "overfitting by review"--some of these are very difficult
to avoid.NameMethodExplanationRemedyTraditional overfittingTrain a complex
predictor on too-few examples.Hold out pristine examples for testing.Use a
simpler predictor.Get more training examples.Integrate over many
predictors.Reject papers which do this.Parameter tweak overfittingUse a
learning algorithm with many parameters. Choo</p><p>4 0.14511052 <a title="393-tfidf-4" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>Introduction: Today brings a new release of theVowpal Wabbitfast online learning software.
This time, unlike the previous release, the project itself is going open
source, developing viagithub. For example, the lastest and greatest can be
downloaded via:git clone git://github.com/JohnLangford/vowpal_wabbit.gitIf you
aren't familiar withgit, it's a distributed version control system which
supports quick and easy branching, as well as reconciliation.This version of
the code is confirmed to compile without complaint on at least some flavors of
OSX as well as Linux boxes.As much of the point of this project is pushing the
limits of fast and effective machine learning, let me mention a few datapoints
from my experience.The program can effectively scale up to batch-style
training on sparse terafeature (i.e. 1012sparse feature) size datasets. The
limiting factor is typically i/o.I started using the the real datasets from
thelarge-scale learningworkshop as a convenient benchmark. The largest dataset
takes a</p><p>5 0.13875864 <a title="393-tfidf-5" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>Introduction: Thelarge scale learning challengefor ICML interests me a great deal, although
I have concerns about the way it is structured.From theinstructions page,
several issues come up:Large DefinitionMy personal definition of dataset size
is:smallA dataset is small if a human could look at the dataset and plausibly
find a good solution.mediumA dataset is mediumsize if it fits in the RAM of a
reasonably priced computer.largeA large dataset does not fit in the RAM of a
reasonably priced computer.By this definition, all of the datasets are medium
sized. This might sound like a pissing match over dataset size, but I believe
it is more than that.The fundamental reason for these definitions is that they
correspond to transitions in the sorts of approaches which are feasible. From
small to medium, the ability to use a human as the learning algorithm
degrades. From medium to large, it becomes essential to have learning
algorithms that don't require random access to examples.No Loading TimeThe
medium sc</p><p>6 0.13048254 <a title="393-tfidf-6" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>7 0.12047817 <a title="393-tfidf-7" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>8 0.11365553 <a title="393-tfidf-8" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>9 0.10609218 <a title="393-tfidf-9" href="../hunch_net-2009/hunch_net-2009-07-11-Interesting_papers_at_KDD.html">364 hunch net-2009-07-11-Interesting papers at KDD</a></p>
<p>10 0.099352479 <a title="393-tfidf-10" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>11 0.097922035 <a title="393-tfidf-11" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>12 0.097049698 <a title="393-tfidf-12" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>13 0.096779056 <a title="393-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>14 0.095070183 <a title="393-tfidf-14" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>15 0.093302295 <a title="393-tfidf-15" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>16 0.091997214 <a title="393-tfidf-16" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>17 0.090007976 <a title="393-tfidf-17" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>18 0.087112904 <a title="393-tfidf-18" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>19 0.087072909 <a title="393-tfidf-19" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>20 0.08441674 <a title="393-tfidf-20" href="../hunch_net-2007/hunch_net-2007-04-21-Videolectures.net.html">240 hunch net-2007-04-21-Videolectures.net</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.221), (1, -0.008), (2, 0.01), (3, 0.033), (4, -0.055), (5, 0.086), (6, 0.093), (7, 0.022), (8, 0.045), (9, 0.079), (10, -0.046), (11, -0.013), (12, -0.034), (13, -0.049), (14, 0.058), (15, -0.003), (16, 0.078), (17, -0.022), (18, 0.063), (19, -0.014), (20, 0.03), (21, -0.01), (22, 0.029), (23, -0.06), (24, 0.005), (25, 0.091), (26, -0.015), (27, 0.019), (28, -0.014), (29, -0.1), (30, -0.073), (31, 0.119), (32, 0.033), (33, -0.136), (34, -0.134), (35, 0.099), (36, -0.034), (37, 0.012), (38, 0.003), (39, -0.049), (40, -0.054), (41, -0.011), (42, -0.1), (43, -0.019), (44, -0.09), (45, -0.048), (46, -0.037), (47, -0.063), (48, -0.061), (49, 0.003)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95903546 <a title="393-lsi-1" href="../hunch_net-2010/hunch_net-2010-04-14-MLcomp%3A_a_website_for_objectively_comparing_ML_algorithms.html">393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</a></p>
<p>Introduction: Much of the success and popularity of machine learning has been driven by its
practical impact. Of course, the evaluation of empirical work is an integral
part of the field. But are the existing mechanisms for evaluating algorithms
and comparing results good enough? We (PercyandJake) believe there are
currently a number of shortcomings:Incomplete Disclosure:You read a paper that
proposes Algorithm A which is shown to outperform SVMs on two datasets.
Great.  But what about on other datasets?  How sensitive is this result?
What about compute time - does the algorithm take two seconds on a laptop or
two weeks on a 100-node cluster?Lack of Standardization:Algorithm A beats
Algorithm B on one version of a dataset.  Algorithm B beats Algorithm A on
another version yet uses slightly different preprocessing.  Though doing a
head-on comparison would be ideal, it would be tedious since the programs
probably use different dataset formats and have a large array of options.  And
what if we wanted t</p><p>2 0.6345796 <a title="393-lsi-2" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>Introduction: Today brings a new release of theVowpal Wabbitfast online learning software.
This time, unlike the previous release, the project itself is going open
source, developing viagithub. For example, the lastest and greatest can be
downloaded via:git clone git://github.com/JohnLangford/vowpal_wabbit.gitIf you
aren't familiar withgit, it's a distributed version control system which
supports quick and easy branching, as well as reconciliation.This version of
the code is confirmed to compile without complaint on at least some flavors of
OSX as well as Linux boxes.As much of the point of this project is pushing the
limits of fast and effective machine learning, let me mention a few datapoints
from my experience.The program can effectively scale up to batch-style
training on sparse terafeature (i.e. 1012sparse feature) size datasets. The
limiting factor is typically i/o.I started using the the real datasets from
thelarge-scale learningworkshop as a convenient benchmark. The largest dataset
takes a</p><p>3 0.62668288 <a title="393-lsi-3" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>Introduction: Thelarge scale learning challengefor ICML interests me a great deal, although
I have concerns about the way it is structured.From theinstructions page,
several issues come up:Large DefinitionMy personal definition of dataset size
is:smallA dataset is small if a human could look at the dataset and plausibly
find a good solution.mediumA dataset is mediumsize if it fits in the RAM of a
reasonably priced computer.largeA large dataset does not fit in the RAM of a
reasonably priced computer.By this definition, all of the datasets are medium
sized. This might sound like a pissing match over dataset size, but I believe
it is more than that.The fundamental reason for these definitions is that they
correspond to transitions in the sorts of approaches which are feasible. From
small to medium, the ability to use a human as the learning algorithm
degrades. From medium to large, it becomes essential to have learning
algorithms that don't require random access to examples.No Loading TimeThe
medium sc</p><p>4 0.60910898 <a title="393-lsi-4" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>Introduction: Machine learning is often computationally bounded which implies that the
ability to write fast code becomes important if you ever want to implement a
machine learning algorithm. Basic tactical optimizations are covered
wellelsewhere, but I haven't seen a reasonable guide to higher level
optimizations, which are the most important in my experience. Here are some of
the higher level optimizations I've often found useful.Algorithmic Improvement
First. This is Hard, but it is the most important consideration, and typically
yields the most benefits. Good optimizations here are publishable. In the
context of machine learning, you should be familiar with the arguments for
online vs. batch learning.Choice of Language. There are many arguments about
thechoice of language. Sometimes you don't have a choice when interfacing with
other people. Personally, I favor C/C++ when I want to write fast code. This
(admittedly) makes me a slower programmer than when using higher level
languages. (Sometimes</p><p>5 0.58447999 <a title="393-lsi-5" href="../hunch_net-2005/hunch_net-2005-11-05-The_design_of_a_computing_cluster.html">128 hunch net-2005-11-05-The design of a computing cluster</a></p>
<p>Introduction: This is about the design of a computing cluster from the viewpoint of applied
machine learning using current technology. We just built a small one at TTI so
this is some evidence of what is feasible and thoughts about the design
choices.ArchitectureThere are several architectural choices.AMD Athlon64 based
system. This seems to have the cheapest bang/buck. Maximum RAM is typically
2-3GB.AMD Opteron based system. Opterons provide the additional capability to
buy an SMP motherboard with two chips, and the motherboards often support 16GB
of RAM. The RAM is also the more expensive error correcting type.Intel PIV or
Xeon based system. The PIV and Xeon based systems are the intel analog of the
above 2. Due to architectural design reasons, these chips tend to run a bit
hotter and be a bit more expensive.Dual core chips. Both Intel and AMD have
chips that actually have 2 processors embedded in them.In the end, we decided
to go with option (2). Roughly speaking, the AMD system seemed like a bet</p><p>6 0.56247491 <a title="393-lsi-6" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>7 0.5515337 <a title="393-lsi-7" href="../hunch_net-2012/hunch_net-2012-12-29-Simons_Institute_Big_Data_Program.html">476 hunch net-2012-12-29-Simons Institute Big Data Program</a></p>
<p>8 0.52521569 <a title="393-lsi-8" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>9 0.49819177 <a title="393-lsi-9" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>10 0.49663389 <a title="393-lsi-10" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>11 0.49232173 <a title="393-lsi-11" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>12 0.48770529 <a title="393-lsi-12" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>13 0.48490998 <a title="393-lsi-13" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>14 0.48300287 <a title="393-lsi-14" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>15 0.48277017 <a title="393-lsi-15" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>16 0.4798013 <a title="393-lsi-16" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>17 0.4772051 <a title="393-lsi-17" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>18 0.4703131 <a title="393-lsi-18" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>19 0.47005799 <a title="393-lsi-19" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>20 0.46374387 <a title="393-lsi-20" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(31, 0.333), (35, 0.093), (42, 0.194), (45, 0.065), (68, 0.019), (69, 0.01), (74, 0.107), (82, 0.037), (88, 0.012), (95, 0.042)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94066864 <a title="393-lda-1" href="../hunch_net-2005/hunch_net-2005-11-16-MLSS_2006.html">130 hunch net-2005-11-16-MLSS 2006</a></p>
<p>Introduction: There will be twomachine learning summer schoolsin 2006.One is inCanberra,
Australiafrom February 6 to February 17 (Aussie summer). The webpage is fully
'live' so you should actively consider it now.The other is inTaipei,
Taiwanfrom July 24 to August 4. This one is still in the planning phase, but
that should be settled soon.Attending an MLSS is probably the quickest and
easiest way to bootstrap yourself into a reasonable initial understanding of
the field of machine learning.</p><p>same-blog 2 0.8196888 <a title="393-lda-2" href="../hunch_net-2010/hunch_net-2010-04-14-MLcomp%3A_a_website_for_objectively_comparing_ML_algorithms.html">393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</a></p>
<p>Introduction: Much of the success and popularity of machine learning has been driven by its
practical impact. Of course, the evaluation of empirical work is an integral
part of the field. But are the existing mechanisms for evaluating algorithms
and comparing results good enough? We (PercyandJake) believe there are
currently a number of shortcomings:Incomplete Disclosure:You read a paper that
proposes Algorithm A which is shown to outperform SVMs on two datasets.
Great.  But what about on other datasets?  How sensitive is this result?
What about compute time - does the algorithm take two seconds on a laptop or
two weeks on a 100-node cluster?Lack of Standardization:Algorithm A beats
Algorithm B on one version of a dataset.  Algorithm B beats Algorithm A on
another version yet uses slightly different preprocessing.  Though doing a
head-on comparison would be ideal, it would be tedious since the programs
probably use different dataset formats and have a large array of options.  And
what if we wanted t</p><p>3 0.79181057 <a title="393-lda-3" href="../hunch_net-2005/hunch_net-2005-02-08-Some_Links.html">15 hunch net-2005-02-08-Some Links</a></p>
<p>Introduction: Yaroslav Bulatov collects somelinksto other technical blogs.</p><p>4 0.58074927 <a title="393-lda-4" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>Introduction: Yahoo! laid off people. Unlike every previous time there have been layoffs,
this is serious forYahoo! Research.We had advanced warning
fromPrabhakarthrough thesimple act of leaving. Yahoo! Research was a world
class organization that Prabhakar recruited much of personally, so it is
deeply implausible that he would spontaneously decide to leave. My first
thought when I saw the news was "Uhoh,Robsaid that he knew it was serious when
the head of ATnT Research left." In this case it was even more significant,
because Prabhakar recruited me on the premise that Y!R was an experiment in
how research should be done: via a combination of high quality people and high
engagement with the company. Prabhakar's departure is a clear end to that
experiment.The result is ambiguous from a business perspective. Y!R clearly
was not capable of saving the company from its illnesses. I'm not privy to the
internal accounting of impact and this is the kind of subject where there can
easily be great disagreemen</p><p>5 0.57916266 <a title="393-lda-5" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>6 0.57676071 <a title="393-lda-6" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>7 0.57611936 <a title="393-lda-7" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>8 0.57522964 <a title="393-lda-8" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>9 0.57516646 <a title="393-lda-9" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>10 0.5739876 <a title="393-lda-10" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>11 0.57367897 <a title="393-lda-11" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>12 0.57317954 <a title="393-lda-12" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>13 0.57257974 <a title="393-lda-13" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>14 0.57080346 <a title="393-lda-14" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<p>15 0.56927878 <a title="393-lda-15" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>16 0.56863195 <a title="393-lda-16" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>17 0.56846899 <a title="393-lda-17" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>18 0.56807864 <a title="393-lda-18" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>19 0.56804919 <a title="393-lda-19" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>20 0.56800646 <a title="393-lda-20" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
