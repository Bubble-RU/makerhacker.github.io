<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>411 hunch net-2010-09-21-Regretting the dead</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-411" href="#">hunch_net-2010-411</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>411 hunch net-2010-09-21-Regretting the dead</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-411-html" href="http://hunch.net/?p=1483">html</a></p><p>Introduction: Nikos  pointed out this  new york times  article about  poor clinical design killing people .  For those of us who study learning from exploration information this is a reminder that low regret algorithms are particularly important, as regret in clinical trials is measured by patient deaths.
 
Two obvious improvements on the experimental design are:
  
 With reasonable record keeping of existing outcomes for the standard treatments, there is no need to explicitly assign people to a control group with the standard treatment, as that approach is effectively explored with great certainty.  Asserting otherwise would imply that the nature of effective treatments for cancer has changed between now and a year ago, which denies the value of any clinical trial. 
 An optimal experimental design will smoothly phase between exploration and exploitation as evidence for a new treatment shows that it can be effective.  This is old tech, for example in the  EXP3.P algorithm (page 12 aka 59)  although</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Nikos  pointed out this  new york times  article about  poor clinical design killing people . [sent-1, score-0.849]
</p><p>2 For those of us who study learning from exploration information this is a reminder that low regret algorithms are particularly important, as regret in clinical trials is measured by patient deaths. [sent-2, score-0.949]
</p><p>3 Asserting otherwise would imply that the nature of effective treatments for cancer has changed between now and a year ago, which denies the value of any clinical trial. [sent-4, score-1.02]
</p><p>4 An optimal experimental design will smoothly phase between exploration and exploitation as evidence for a new treatment shows that it can be effective. [sent-5, score-1.026]
</p><p>5 P algorithm (page 12 aka 59)  although I prefer the generalized and somewhat clearer analysis of  EXP4. [sent-7, score-0.143]
</p><p>6 Done the right way, the clinical trial for a successful treatment would start with some initial small pool (equivalent to “phase 1″ in the article) and then simply expanded the pool of participants over time as it proved superior to the existing treatment, until the pool is everyone. [sent-9, score-1.845]
</p><p>7 And as a bonus, you can even compete with policies on treatments rather than raw treatments (i. [sent-10, score-1.027]
</p><p>8 P was first published, and the progress in clinical trial design seems glacial to us outsiders. [sent-15, score-0.819]
</p><p>9 Partly, I think this is a communication and education failure, but partly, it’s also a failure of imagination within our own field. [sent-16, score-0.3]
</p><p>10 When we design algorithms, we often don’t think about all the applications, where a little massaging of the design in obvious-to-us ways so as to suit these applications would go a long ways. [sent-17, score-0.648]
</p><p>11 Getting this right here has a substantial moral aspect, potentially saving millions of lives over time through more precise and fast deployments of new treatments. [sent-18, score-0.327]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('clinical', 0.448), ('treatments', 0.415), ('treatment', 0.299), ('design', 0.214), ('pool', 0.195), ('trial', 0.157), ('phase', 0.143), ('article', 0.118), ('partly', 0.104), ('exploration', 0.104), ('experimental', 0.098), ('failure', 0.092), ('asserting', 0.09), ('moral', 0.09), ('expanded', 0.09), ('exploitation', 0.09), ('cancer', 0.09), ('saving', 0.09), ('regret', 0.088), ('getting', 0.086), ('bonus', 0.083), ('imagination', 0.083), ('explored', 0.083), ('patient', 0.083), ('tech', 0.083), ('massaging', 0.083), ('personalized', 0.083), ('aka', 0.078), ('outcomes', 0.078), ('millions', 0.078), ('reminder', 0.078), ('smoothly', 0.078), ('medicine', 0.078), ('existing', 0.074), ('raw', 0.072), ('nikos', 0.072), ('standard', 0.07), ('applications', 0.07), ('lives', 0.069), ('assign', 0.069), ('pointed', 0.069), ('would', 0.067), ('generalized', 0.065), ('education', 0.063), ('successful', 0.063), ('policies', 0.063), ('communication', 0.062), ('compete', 0.062), ('proved', 0.062), ('measured', 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="411-tfidf-1" href="../hunch_net-2010/hunch_net-2010-09-21-Regretting_the_dead.html">411 hunch net-2010-09-21-Regretting the dead</a></p>
<p>Introduction: Nikos  pointed out this  new york times  article about  poor clinical design killing people .  For those of us who study learning from exploration information this is a reminder that low regret algorithms are particularly important, as regret in clinical trials is measured by patient deaths.
 
Two obvious improvements on the experimental design are:
  
 With reasonable record keeping of existing outcomes for the standard treatments, there is no need to explicitly assign people to a control group with the standard treatment, as that approach is effectively explored with great certainty.  Asserting otherwise would imply that the nature of effective treatments for cancer has changed between now and a year ago, which denies the value of any clinical trial. 
 An optimal experimental design will smoothly phase between exploration and exploitation as evidence for a new treatment shows that it can be effective.  This is old tech, for example in the  EXP3.P algorithm (page 12 aka 59)  although</p><p>2 0.2090722 <a title="411-tfidf-2" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>Introduction: This post is about a technology which could develop in the future.
 
Right now, a new drug might be tested by finding patients with some diagnosis and giving or not giving them a drug according to a secret randomization.  The outcome is observed, and if the average outcome for those treated is measurably better than the average outcome for those not treated, the drug might become a standard treatment.
 
Generalizing this, a filter  F  sorts people into two groups: those for treatment  A  and those not for treatment  B  based upon observations  x .  To measure the outcome, you randomize between treatment and nontreatment of group  A  and measure the relative performance of the treatment.
 
A problem often arises: in many cases the treated group does not do better than the nontreated group.  A basic question is: does this mean the treatment is bad?  With respect to the filter  F  it may mean that, but with respect to another filter  F’ , the treatment might be very effective.  For exampl</p><p>3 0.087028295 <a title="411-tfidf-3" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>Introduction: One view of machine learning is that it’s about how to program computers to predict well.  This suggests a broader research program centered around the more pervasive goal of simply predicting well. 
There are many distinct strands of this broader research program which are only partially unified.  Here are the ones that I know of:
  
  Learning Theory .  Learning theory focuses on several topics related to the dynamics and process of prediction.  Convergence bounds like the  VC bound   give an intellectual foundation to many learning algorithms.  Online learning algorithms like  Weighted Majority  provide an alternate purely game theoretic foundation for learning.   Boosting algorithms  yield algorithms for purifying prediction abiliity.   Reduction algorithms  provide means for changing esoteric problems into well known ones. 
  Machine Learning .  A great deal of experience has accumulated in practical algorithm design from a mixture of paradigms, including bayesian, biological, opt</p><p>4 0.085947141 <a title="411-tfidf-4" href="../hunch_net-2007/hunch_net-2007-10-14-NIPS_workshp%3A_Learning_Problem_Design.html">265 hunch net-2007-10-14-NIPS workshp: Learning Problem Design</a></p>
<p>Introduction: Alina  and I are organizing a workshop on  Learning Problem Design  at  NIPS .  
 
 What is learning problem design?  Itâ&euro;&trade;s about being clever in creating learning problems from otherwise unlabeled data.  Read the webpage above for examples.
 
 I want to participate!  Email us before Nov. 1 with a description of what you want to talk about.</p><p>5 0.084387735 <a title="411-tfidf-5" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>Introduction: Data linkage is a problem which seems to come up in various applied machine learning problems.  I have heard it mentioned in various data mining contexts, but it seems relatively less studied for systemic reasons.
 
A very simple version of the data linkage problem is a cross hospital patient record merge.  Suppose a patient (John Doe) is admitted to a hospital (General Health), treated, and released.  Later, John Doe is admitted to a second hospital (Health General), treated, and released.  Given a large number of records of this sort, it becomes very tempting to try and predict the outcomes of treatments.  This is reasonably straightforward as a machine learning problem if there is a shared unique identifier for John Doe used by General Health and Health General along with time stamps.  We can merge the records and create examples of the form “Given symptoms and treatment, did the patient come back to a hospital within the next year?”  These examples could be fed into a learning algo</p><p>6 0.083599009 <a title="411-tfidf-6" href="../hunch_net-2006/hunch_net-2006-09-07-Objective_and_subjective_interpretations_of_probability.html">205 hunch net-2006-09-07-Objective and subjective interpretations of probability</a></p>
<p>7 0.079851985 <a title="411-tfidf-7" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>8 0.076154664 <a title="411-tfidf-8" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>9 0.071548454 <a title="411-tfidf-9" href="../hunch_net-2005/hunch_net-2005-03-29-Academic_Mechanism_Design.html">48 hunch net-2005-03-29-Academic Mechanism Design</a></p>
<p>10 0.071142338 <a title="411-tfidf-10" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>11 0.071141466 <a title="411-tfidf-11" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>12 0.069324598 <a title="411-tfidf-12" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>13 0.068171233 <a title="411-tfidf-13" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>14 0.067974344 <a title="411-tfidf-14" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>15 0.067109525 <a title="411-tfidf-15" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>16 0.066984087 <a title="411-tfidf-16" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>17 0.066311412 <a title="411-tfidf-17" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>18 0.061726641 <a title="411-tfidf-18" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>19 0.060597178 <a title="411-tfidf-19" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>20 0.059638362 <a title="411-tfidf-20" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, 0.011), (2, -0.039), (3, 0.026), (4, 0.01), (5, -0.001), (6, 0.032), (7, 0.037), (8, -0.023), (9, 0.01), (10, -0.004), (11, 0.006), (12, 0.011), (13, 0.017), (14, -0.053), (15, 0.013), (16, -0.019), (17, 0.027), (18, -0.008), (19, 0.011), (20, -0.038), (21, -0.012), (22, -0.029), (23, 0.028), (24, -0.11), (25, -0.013), (26, 0.053), (27, 0.018), (28, 0.089), (29, -0.072), (30, -0.096), (31, 0.002), (32, -0.008), (33, -0.032), (34, -0.037), (35, -0.069), (36, -0.038), (37, 0.002), (38, -0.087), (39, -0.023), (40, 0.048), (41, 0.056), (42, 0.01), (43, -0.009), (44, 0.009), (45, 0.001), (46, -0.008), (47, -0.022), (48, 0.04), (49, -0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96044272 <a title="411-lsi-1" href="../hunch_net-2010/hunch_net-2010-09-21-Regretting_the_dead.html">411 hunch net-2010-09-21-Regretting the dead</a></p>
<p>Introduction: Nikos  pointed out this  new york times  article about  poor clinical design killing people .  For those of us who study learning from exploration information this is a reminder that low regret algorithms are particularly important, as regret in clinical trials is measured by patient deaths.
 
Two obvious improvements on the experimental design are:
  
 With reasonable record keeping of existing outcomes for the standard treatments, there is no need to explicitly assign people to a control group with the standard treatment, as that approach is effectively explored with great certainty.  Asserting otherwise would imply that the nature of effective treatments for cancer has changed between now and a year ago, which denies the value of any clinical trial. 
 An optimal experimental design will smoothly phase between exploration and exploitation as evidence for a new treatment shows that it can be effective.  This is old tech, for example in the  EXP3.P algorithm (page 12 aka 59)  although</p><p>2 0.68442184 <a title="411-lsi-2" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>Introduction: This post is about a technology which could develop in the future.
 
Right now, a new drug might be tested by finding patients with some diagnosis and giving or not giving them a drug according to a secret randomization.  The outcome is observed, and if the average outcome for those treated is measurably better than the average outcome for those not treated, the drug might become a standard treatment.
 
Generalizing this, a filter  F  sorts people into two groups: those for treatment  A  and those not for treatment  B  based upon observations  x .  To measure the outcome, you randomize between treatment and nontreatment of group  A  and measure the relative performance of the treatment.
 
A problem often arises: in many cases the treated group does not do better than the nontreated group.  A basic question is: does this mean the treatment is bad?  With respect to the filter  F  it may mean that, but with respect to another filter  F’ , the treatment might be very effective.  For exampl</p><p>3 0.66411752 <a title="411-lsi-3" href="../hunch_net-2006/hunch_net-2006-09-07-Objective_and_subjective_interpretations_of_probability.html">205 hunch net-2006-09-07-Objective and subjective interpretations of probability</a></p>
<p>Introduction: An amusing tidbit (reproduced without permission) from Herman Chernoff’s delightful monograph, “Sequential analysis and optimal design”:
 
The use of randomization raises a philosophical question which is articulated by the following probably apocryphal anecdote.
 
The metallurgist told his friend the statistician how he planned to test the effect of heat on the strength of a metal bar by sawing the bar into six pieces. The first two would go into the hot oven, the next two into the medium oven, and the last two into the cool oven. The statistician, horrified, explained how he should randomize to avoid the effect of a possible gradient of strength in the metal bar. The method of randomization was applied, and it turned out that the randomized experiment called for putting the first two pieces into the hot oven, the next two into the medium oven, and the last two into the cool oven. “Obviously, we can’t do that,” said the metallurgist. “On the contrary, you have to do that,” said the st</p><p>4 0.60476702 <a title="411-lsi-4" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>Introduction: I found the article on “ Political Science ” at the  New York Times  interesting.  Essentially the article is about allegations that the US government has been systematically distorting scientific views.   With a  petition  by some  7000+ scientists  alleging such behavior this is clearly a significant concern.
 
One thing not mentioned explicitly in this discussion is that there are fundamental cultural differences between academic research and the rest of the world.  In academic research, careful, clear thought is valued.  This value is achieved by both formal and informal mechanisms.  One example of a formal mechanism is peer review.
 
In contrast, in the land of politics, the basic value is agreement.  It is only with some amount of agreement that a new law can be passed or other actions can be taken.  Since Science (with a capitol ‘S’) has accomplished many things, it can be a significant tool in persuading people.  This makes it compelling for a politician to use science as a mec</p><p>5 0.59204477 <a title="411-lsi-5" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>Introduction: Many people in computer science believe that patents are problematic.  The truth is even worse—the patent system in the US is fundamentally broken in ways that will require much more significant reform than  is being considered now .
 
The myth of the patent is the following: Patents are a mechanism for inventors to be compensated according to the value of their inventions while making the invention available to all.  This myth sounds pretty desirable, but the reality is a strange distortion slowly leading towards collapse.
 
There are many problems associated with patents, but I would like to focus on just two of them: 
  
  Patent Trolls   The way that patents have generally worked over the last several decades is that they were a tool of large companies.  Large companies would amass a large number of patents and then cross-license each other’s patents—in effect saying “we agree to owe each other nothing”.  Smaller companies would sometimes lose in this game, essentially because they</p><p>6 0.5658316 <a title="411-lsi-6" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>7 0.54604912 <a title="411-lsi-7" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>8 0.54434794 <a title="411-lsi-8" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>9 0.54171652 <a title="411-lsi-9" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>10 0.52645755 <a title="411-lsi-10" href="../hunch_net-2007/hunch_net-2007-10-14-NIPS_workshp%3A_Learning_Problem_Design.html">265 hunch net-2007-10-14-NIPS workshp: Learning Problem Design</a></p>
<p>11 0.51741844 <a title="411-lsi-11" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>12 0.5122233 <a title="411-lsi-12" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>13 0.51161945 <a title="411-lsi-13" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>14 0.48928872 <a title="411-lsi-14" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>15 0.48687539 <a title="411-lsi-15" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>16 0.48408568 <a title="411-lsi-16" href="../hunch_net-2006/hunch_net-2006-03-27-Gradients_everywhere.html">167 hunch net-2006-03-27-Gradients everywhere</a></p>
<p>17 0.48194593 <a title="411-lsi-17" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>18 0.47960037 <a title="411-lsi-18" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>19 0.47798514 <a title="411-lsi-19" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>20 0.47416395 <a title="411-lsi-20" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.022), (3, 0.021), (10, 0.021), (27, 0.182), (30, 0.011), (38, 0.034), (44, 0.011), (53, 0.012), (55, 0.09), (68, 0.036), (74, 0.018), (84, 0.284), (94, 0.099), (95, 0.052)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94170845 <a title="411-lda-1" href="../hunch_net-2009/hunch_net-2009-12-09-Inherent_Uncertainty.html">383 hunch net-2009-12-09-Inherent Uncertainty</a></p>
<p>Introduction: I’d like to point out  Inherent Uncertainty , which I’ve added to the ML blog post scanner on the right.   My understanding from  Jake  is that the intention is to have a multiauthor blog which is more specialized towards learning theory/game theory than this one.  Nevertheless, several of the posts seem to be of wider interest.</p><p>2 0.93094271 <a title="411-lda-2" href="../hunch_net-2005/hunch_net-2005-10-12-The_unrealized_potential_of_the_research_lab.html">121 hunch net-2005-10-12-The unrealized potential of the research lab</a></p>
<p>Introduction: I attended the  IBM research 60th anniversary .  IBM research is, by any reasonable account, the industrial research lab which has managed to bring the most value to it’s parent company over the long term.  This can be seen by simply counting the survivors: IBM research is the only older research lab which has not gone through a period of massive firing.  (Note that there are also  new research labs .)
 
Despite this impressive record, IBM research has failed, by far, to achieve it’s potential.  Examples which came up in this meeting include:
  
 It took about a decade to produce DRAM after it was invented in the lab.  (In fact, Intel produced it first.) 
 Relational databases and SQL were invented and then languished.  It was only under external competition that IBM released it’s own relational database.  Why didn’t IBM grow an  Oracle division ? 
 An early lead in IP networking hardware did not result in IBM growing a  Cisco division .  Why not? 
  
And remember … IBM research is a s</p><p>3 0.91744435 <a title="411-lda-3" href="../hunch_net-2012/hunch_net-2012-06-15-Normal_Deviate_and_the_UCSC_Machine_Learning_Summer_School.html">467 hunch net-2012-06-15-Normal Deviate and the UCSC Machine Learning Summer School</a></p>
<p>Introduction: Larry Wasserman  has started the  Normal Deviate  blog which I added to the blogroll on the right.
 
 Manfred Warmuth  points out the  UCSC machine learning summer school  running July 9-20 which may be of particular interest to those in silicon valley.</p><p>same-blog 4 0.91512597 <a title="411-lda-4" href="../hunch_net-2010/hunch_net-2010-09-21-Regretting_the_dead.html">411 hunch net-2010-09-21-Regretting the dead</a></p>
<p>Introduction: Nikos  pointed out this  new york times  article about  poor clinical design killing people .  For those of us who study learning from exploration information this is a reminder that low regret algorithms are particularly important, as regret in clinical trials is measured by patient deaths.
 
Two obvious improvements on the experimental design are:
  
 With reasonable record keeping of existing outcomes for the standard treatments, there is no need to explicitly assign people to a control group with the standard treatment, as that approach is effectively explored with great certainty.  Asserting otherwise would imply that the nature of effective treatments for cancer has changed between now and a year ago, which denies the value of any clinical trial. 
 An optimal experimental design will smoothly phase between exploration and exploitation as evidence for a new treatment shows that it can be effective.  This is old tech, for example in the  EXP3.P algorithm (page 12 aka 59)  although</p><p>5 0.90105498 <a title="411-lda-5" href="../hunch_net-2006/hunch_net-2006-08-03-AOL%26%238217%3Bs_data_drop.html">200 hunch net-2006-08-03-AOL&#8217;s data drop</a></p>
<p>Introduction: AOL has  released  several large search engine related datasets.  This looks like a pretty impressive data release, and it is a big opportunity for people everywhere to worry about search engine related learning problems, if they want.</p><p>6 0.83386159 <a title="411-lda-6" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>7 0.79189724 <a title="411-lda-7" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<p>8 0.71854937 <a title="411-lda-8" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>9 0.66386998 <a title="411-lda-9" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>10 0.6577242 <a title="411-lda-10" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>11 0.63389236 <a title="411-lda-11" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>12 0.62151575 <a title="411-lda-12" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>13 0.62077439 <a title="411-lda-13" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>14 0.61743909 <a title="411-lda-14" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>15 0.61366743 <a title="411-lda-15" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>16 0.61133862 <a title="411-lda-16" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>17 0.60721999 <a title="411-lda-17" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>18 0.60698676 <a title="411-lda-18" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>19 0.60642523 <a title="411-lda-19" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>20 0.60540533 <a title="411-lda-20" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
