<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>395 hunch net-2010-04-26-Compassionate Reviewing</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-395" href="#">hunch_net-2010-395</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>395 hunch net-2010-04-26-Compassionate Reviewing</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-395-html" href="http://hunch.net/?p=1336">html</a></p><p>Introduction: Most long conversations between academics seem to converge on the topic of
reviewing where almost no one is happy. A basic question is: Should most
people be happy?The case against is straightforward. Anyone who watches the
flow of papers realizes that most papers amount to little in the longer term.
By it's nature research is brutal, where the second-best method is worthless,
and the second person to discover things typically gets no credit. If you
think about this for a moment, it's very different from most other human
endeavors. The second best migrant laborer, construction worker, manager,
conductor, quarterback, etcâ&euro;Ś all can manage quite well. If a reviewer has even
a vaguely predictive sense of what's important in the longer term, then most
people submitting papers will be unhappy.But this argument unravels, in my
experience. Perhaps half of reviews are thoughtless or simply wrong with a
small part being simply malicious. And yet, I'm sure that most reviewers
genuinely believe th</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Most long conversations between academics seem to converge on the topic of reviewing where almost no one is happy. [sent-1, score-0.705]
</p><p>2 Anyone who watches the flow of papers realizes that most papers amount to little in the longer term. [sent-4, score-0.587]
</p><p>3 If a reviewer has even a vaguely predictive sense of what's important in the longer term, then most people submitting papers will be unhappy. [sent-8, score-0.349]
</p><p>4 And yet, I'm sure that most reviewers genuinely believe they can predict what will and will not be useful in the longer term. [sent-11, score-0.224]
</p><p>5 When academics have conversations about reviewing, the presumption of participants in each conversation is that they all share about the same beliefs about what will be useful, and what will take off. [sent-13, score-0.445]
</p><p>6 Such conversations rarely go into specifics, because the specifics are boring in particular, technical, and because their is a real chance of disagreement on the specifics themselves. [sent-14, score-0.605]
</p><p>7 When double blind reviewing was first being considered for ICML, I remember speaking about the experience in the Crypto community, where in my estimate the reviewing was both fairer and less happy. [sent-15, score-1.422]
</p><p>8 Without double blind reviewing, it is common to have an "in" crowd who everyone respects and whose papers are virtually always accepted. [sent-17, score-0.817]
</p><p>9 From a viewpoint external to the community, when the reviewing is poor and the viewpoint of people in the community highly contradictory, nothing good happens. [sent-21, score-0.948]
</p><p>10 most people) viewing the acrimony choose some other way to solve problems, proposals don't get funded, and the community itself tends to fracture. [sent-24, score-0.29]
</p><p>11 For example, in cryptography,TCC(not double blind) has started, presumably because the top theory people got tired of having their papers rejected atCrypto(double blind). [sent-25, score-0.5]
</p><p>12 What seems to be lost with double blind reviewing is some amount of compassion, unfairly allocated. [sent-27, score-1.05]
</p><p>13 In a double blind system, any given paper is plausibly from someone you don't know, and since most papers go nowhere, plausibly not going anywhere. [sent-28, score-0.843]
</p><p>14 Aaron Hertzmanstrongly disagreed on the grounds that this belief could dead end your career as an author. [sent-31, score-0.235]
</p><p>15 " In a healthy community, reviewers will actively understand why a piece of work is or is not important, filling in and extending the motivation as they consider the problem. [sent-35, score-0.31]
</p><p>16 ) It might help somewhat for reviewers to actively consider, as part of their review, the level and mechanism of impact that a paper may have. [sent-38, score-0.182]
</p><p>17 Reducing reviewing load is certainly helpful, but it is not sufficient alone, because many people naturally interpret a reduced reviewing load as time to work on other things. [sent-39, score-1.22]
</p><p>18 For example, the two-phase reviewing process thatICMLcurrently uses might save 0. [sent-41, score-0.433]
</p><p>19 5 reviews/paper, while guaranteeing that for half of the papers, the deciding review is done hastily with no author feedback, a recipe for mistakes. [sent-42, score-0.353]
</p><p>20 A natural conversation helps (the current method of single round response tends to be very stilted). [sent-45, score-0.277]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reviewing', 0.433), ('blind', 0.278), ('double', 0.278), ('specifics', 0.193), ('community', 0.192), ('conversations', 0.161), ('compassion', 0.156), ('papers', 0.133), ('longer', 0.127), ('viewpoint', 0.117), ('academics', 0.111), ('conversation', 0.104), ('happy', 0.104), ('responsibility', 0.104), ('load', 0.098), ('tends', 0.098), ('reviewers', 0.097), ('half', 0.096), ('people', 0.089), ('actively', 0.085), ('fair', 0.085), ('plausibly', 0.077), ('helps', 0.075), ('contradictory', 0.069), ('guaranteeing', 0.069), ('realizes', 0.069), ('interpret', 0.069), ('witness', 0.069), ('presumption', 0.069), ('disparity', 0.069), ('question', 0.068), ('everyone', 0.067), ('filling', 0.064), ('recipe', 0.064), ('extending', 0.064), ('nowhere', 0.064), ('manager', 0.064), ('flow', 0.064), ('author', 0.063), ('review', 0.061), ('amount', 0.061), ('crypto', 0.061), ('crowd', 0.061), ('suboptimal', 0.061), ('disagreed', 0.061), ('funded', 0.058), ('dead', 0.058), ('career', 0.058), ('grounds', 0.058), ('disagreement', 0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="395-tfidf-1" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>Introduction: Most long conversations between academics seem to converge on the topic of
reviewing where almost no one is happy. A basic question is: Should most
people be happy?The case against is straightforward. Anyone who watches the
flow of papers realizes that most papers amount to little in the longer term.
By it's nature research is brutal, where the second-best method is worthless,
and the second person to discover things typically gets no credit. If you
think about this for a moment, it's very different from most other human
endeavors. The second best migrant laborer, construction worker, manager,
conductor, quarterback, etcâ&euro;Ś all can manage quite well. If a reviewer has even
a vaguely predictive sense of what's important in the longer term, then most
people submitting papers will be unhappy.But this argument unravels, in my
experience. Perhaps half of reviews are thoughtless or simply wrong with a
small part being simply malicious. And yet, I'm sure that most reviewers
genuinely believe th</p><p>2 0.34752953 <a title="395-tfidf-2" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>3 0.31769201 <a title="395-tfidf-3" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>4 0.3024697 <a title="395-tfidf-4" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>5 0.28862029 <a title="395-tfidf-5" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>6 0.26153195 <a title="395-tfidf-6" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>7 0.25242978 <a title="395-tfidf-7" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>8 0.24086472 <a title="395-tfidf-8" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>9 0.23350936 <a title="395-tfidf-9" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>10 0.21228042 <a title="395-tfidf-10" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>11 0.20470655 <a title="395-tfidf-11" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>12 0.1868979 <a title="395-tfidf-12" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>13 0.1836843 <a title="395-tfidf-13" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>14 0.16571903 <a title="395-tfidf-14" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>15 0.1538914 <a title="395-tfidf-15" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>16 0.15364614 <a title="395-tfidf-16" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>17 0.15270104 <a title="395-tfidf-17" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>18 0.14951636 <a title="395-tfidf-18" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>19 0.14324862 <a title="395-tfidf-19" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>20 0.14168701 <a title="395-tfidf-20" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.291), (1, 0.288), (2, -0.22), (3, -0.116), (4, 0.022), (5, 0.023), (6, -0.037), (7, 0.043), (8, -0.003), (9, 0.033), (10, -0.033), (11, -0.081), (12, 0.051), (13, -0.072), (14, 0.023), (15, -0.105), (16, -0.067), (17, 0.026), (18, 0.016), (19, -0.029), (20, 0.017), (21, -0.011), (22, -0.022), (23, 0.023), (24, -0.025), (25, -0.062), (26, 0.079), (27, 0.035), (28, -0.046), (29, 0.006), (30, 0.146), (31, -0.092), (32, -0.062), (33, 0.012), (34, -0.093), (35, -0.068), (36, 0.028), (37, -0.014), (38, -0.117), (39, 0.031), (40, 0.019), (41, 0.062), (42, -0.039), (43, -0.002), (44, 0.017), (45, -0.035), (46, -0.017), (47, -0.037), (48, -0.025), (49, -0.029)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98023188 <a title="395-lsi-1" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>Introduction: Most long conversations between academics seem to converge on the topic of
reviewing where almost no one is happy. A basic question is: Should most
people be happy?The case against is straightforward. Anyone who watches the
flow of papers realizes that most papers amount to little in the longer term.
By it's nature research is brutal, where the second-best method is worthless,
and the second person to discover things typically gets no credit. If you
think about this for a moment, it's very different from most other human
endeavors. The second best migrant laborer, construction worker, manager,
conductor, quarterback, etcâ&euro;Ś all can manage quite well. If a reviewer has even
a vaguely predictive sense of what's important in the longer term, then most
people submitting papers will be unhappy.But this argument unravels, in my
experience. Perhaps half of reviews are thoughtless or simply wrong with a
small part being simply malicious. And yet, I'm sure that most reviewers
genuinely believe th</p><p>2 0.88945532 <a title="395-lsi-2" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>3 0.86307377 <a title="395-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>4 0.84524888 <a title="395-lsi-4" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>5 0.80105698 <a title="395-lsi-5" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>Introduction: Conferences exist as part of the process of doing research. They provide many
roles including "announcing research", "meeting people", and "point of
reference". Not all conferences are alike so a basic question is: "to what
extent do individual conferences attempt to aid research?" This question is
very difficult to answer in any satisfying way. What we can do is compare
details of the process across multiple conferences.CommentsThe average quality
of comments across conferences can vary dramatically. At one extreme, the
tradition in CS theory conferences is to provide essentially zero feedback. At
the other extreme, some conferences have a strong tradition of providing
detailed constructive feedback. Detailed feedback can give authors significant
guidance about how to improve research. This is the most subjective
entry.BlindVirtually all conferences offer single blind review where authors
do not know reviewers. Some also providedouble blindreview where reviewers do
not know authors. T</p><p>6 0.7862125 <a title="395-lsi-6" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>7 0.75155818 <a title="395-lsi-7" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>8 0.74557883 <a title="395-lsi-8" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>9 0.74001163 <a title="395-lsi-9" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>10 0.71253443 <a title="395-lsi-10" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>11 0.70035958 <a title="395-lsi-11" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>12 0.69390225 <a title="395-lsi-12" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>13 0.67884654 <a title="395-lsi-13" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>14 0.65737194 <a title="395-lsi-14" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>15 0.63426363 <a title="395-lsi-15" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>16 0.6281842 <a title="395-lsi-16" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>17 0.58718574 <a title="395-lsi-17" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>18 0.58583683 <a title="395-lsi-18" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>19 0.58443063 <a title="395-lsi-19" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>20 0.58426565 <a title="395-lsi-20" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.012), (6, 0.017), (13, 0.178), (35, 0.042), (42, 0.209), (45, 0.027), (68, 0.019), (69, 0.066), (74, 0.169), (82, 0.15), (95, 0.04)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.90461898 <a title="395-lda-1" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>Introduction: Most long conversations between academics seem to converge on the topic of
reviewing where almost no one is happy. A basic question is: Should most
people be happy?The case against is straightforward. Anyone who watches the
flow of papers realizes that most papers amount to little in the longer term.
By it's nature research is brutal, where the second-best method is worthless,
and the second person to discover things typically gets no credit. If you
think about this for a moment, it's very different from most other human
endeavors. The second best migrant laborer, construction worker, manager,
conductor, quarterback, etcâ&euro;Ś all can manage quite well. If a reviewer has even
a vaguely predictive sense of what's important in the longer term, then most
people submitting papers will be unhappy.But this argument unravels, in my
experience. Perhaps half of reviews are thoughtless or simply wrong with a
small part being simply malicious. And yet, I'm sure that most reviewers
genuinely believe th</p><p>2 0.87185997 <a title="395-lda-2" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>Introduction: Centmailis a scheme which makes charity donations have a secondary value, as a
stamp for email. When discussed onnewscientist,slashdot, and others, some of
the comments make the academic review process appear thoughtful. Some
prominent fallacies are:Costing money fallacy. Some commenters appear to
believe the system charges money per email. Instead, the basic idea is that
users get an extra benefit from donations to a charity and participation is
strictly voluntary. The solution to this fallacy is simply readingthe
details.Single solution fallacy. Some commenters seem to think this is
proposed as a complete solution to spam, and since not everyone will opt to
participate, it won't work. But a complete solution is not at all necessary or
even possible given theflag-day problem. Deployed machine learning systems for
fighting spam are great at taking advantage of a partial solution. The
solution to this fallacy is learning about machine learning. In the current
state of affairs, informed</p><p>3 0.84187657 <a title="395-lda-3" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>4 0.84006906 <a title="395-lda-4" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>Introduction: The New York Times had ashort interviewabout machine learning in datamining
being used pervasively by the IRS and large corporations to predict who to
audit and who to target for various marketing campaigns. This is a big
application area of machine learning. It can be harmful (learning + databases
= another way to invade privacy) or beneficial (as google demonstrates, better
targeting of marketing campaigns is far less annoying). This is yet more
evidence that we can not rely upon "I'm just another fish in the school" logic
for our expectations about treatment by government and large corporations.</p><p>5 0.83771354 <a title="395-lda-5" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>Introduction: Conferences exist as part of the process of doing research. They provide many
roles including "announcing research", "meeting people", and "point of
reference". Not all conferences are alike so a basic question is: "to what
extent do individual conferences attempt to aid research?" This question is
very difficult to answer in any satisfying way. What we can do is compare
details of the process across multiple conferences.CommentsThe average quality
of comments across conferences can vary dramatically. At one extreme, the
tradition in CS theory conferences is to provide essentially zero feedback. At
the other extreme, some conferences have a strong tradition of providing
detailed constructive feedback. Detailed feedback can give authors significant
guidance about how to improve research. This is the most subjective
entry.BlindVirtually all conferences offer single blind review where authors
do not know reviewers. Some also providedouble blindreview where reviewers do
not know authors. T</p><p>6 0.81905353 <a title="395-lda-6" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>7 0.81785941 <a title="395-lda-7" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>8 0.81634641 <a title="395-lda-8" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>9 0.80774695 <a title="395-lda-9" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>10 0.80639178 <a title="395-lda-10" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>11 0.80337244 <a title="395-lda-11" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>12 0.80297643 <a title="395-lda-12" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>13 0.80064595 <a title="395-lda-13" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>14 0.79683059 <a title="395-lda-14" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>15 0.78996027 <a title="395-lda-15" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>16 0.78700447 <a title="395-lda-16" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>17 0.78576428 <a title="395-lda-17" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>18 0.78537267 <a title="395-lda-18" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>19 0.78203726 <a title="395-lda-19" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>20 0.77963519 <a title="395-lda-20" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
