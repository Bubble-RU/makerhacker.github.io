<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-398" href="#">hunch_net-2010-398</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-398-html" href="http://hunch.net/?p=1358">html</a></p><p>Introduction: (I'm channeling forJean-Yves Audiberthere, with some minor tweaking for
clarity.)SinceNemirovski'sSaint Flour lecture notes, numerous researchers have
studied the following problem in least squares regression: predict as well
as(MS) the best of d given functions (like in prediction with expert advice;
model = finite set of d functions)(C) the best convex combination of these
functions (i.e., model = convex hull of the d functions)(L) the best linear
combination of these functions (i.e., model = linear span of the d
functions)It is now well known (see, e.g., Sacha Tsybakov's COLT'03 paper)
that these tasks can be achieved since there exist estimators having an excess
risk of order (log d)/n for (MS), min( sqrt((log d)/n), d/n ) for (C) and d/n
for (L), where n is the training set size. Here, "risk" is amount of extra
loss per example which may be suffered due to the choice of random sample.The
practical use of these results seems rather limited to trivial statements
like: do not use the</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('risk', 0.411), ('excess', 0.339), ('functions', 0.281), ('log', 0.245), ('estimators', 0.238), ('ms', 0.238), ('linear', 0.213), ('ols', 0.159), ('sqrt', 0.159), ('model', 0.139), ('estimator', 0.131), ('combination', 0.112), ('procedure', 0.103), ('favorite', 0.097), ('convex', 0.091), ('order', 0.084), ('prefer', 0.082), ('best', 0.08), ('choose', 0.077), ('set', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="398-tfidf-1" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>Introduction: (I'm channeling forJean-Yves Audiberthere, with some minor tweaking for
clarity.)SinceNemirovski'sSaint Flour lecture notes, numerous researchers have
studied the following problem in least squares regression: predict as well
as(MS) the best of d given functions (like in prediction with expert advice;
model = finite set of d functions)(C) the best convex combination of these
functions (i.e., model = convex hull of the d functions)(L) the best linear
combination of these functions (i.e., model = linear span of the d
functions)It is now well known (see, e.g., Sacha Tsybakov's COLT'03 paper)
that these tasks can be achieved since there exist estimators having an excess
risk of order (log d)/n for (MS), min( sqrt((log d)/n), d/n ) for (C) and d/n
for (L), where n is the training set size. Here, "risk" is amount of extra
loss per example which may be suffered due to the choice of random sample.The
practical use of these results seems rather limited to trivial statements
like: do not use the</p><p>2 0.15509002 <a title="398-tfidf-2" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>Introduction: One conventional wisdom is that learning algorithms with linear
representations are sufficient to solve natural learning problems. This
conventional wisdom appears unsupported by empirical evidence as far as I can
tell. In nearly all vision, language, robotics, and speech applications I know
where machine learning is effectively applied, the approach involves either a
linear representation on hand crafted features capturing substantial
nonlinearities or learning directly on nonlinear representations.There are a
few exceptions to this--for example, if the problem of interest to you is
predicting the next word given previous words, n-gram methods have been shown
effective. Viewed the right way, n-gram methods are essentially linear
predictors on an enormous sparse feature space, learned from an enormous
number of examples. Hal's postheredescribes some of this in more detail.In
contrast, if you go to a machine learning conference, a large number of the
new algorithms are variations of lea</p><p>3 0.1065575 <a title="398-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>4 0.10321294 <a title="398-tfidf-4" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>Introduction: One of the remarkable things about machine learning is how diverse it is. The
viewpoints of Bayesian learning, reinforcement learning, graphical models,
supervised learning, unsupervised learning, genetic programming, etc… share
little enough overlap that many people can and do make their careers within
one without touching, or even necessarily understanding the others.There are
two fundamental reasons why this is possible.For many problems, many
approaches work in the sense that they do something useful. This is true
empirically, where for many problems we can observe that many different
approaches yield better performance than any constant predictor. It's also
true in theory, where we know that for any set of predictors representable in
a finite amount of RAM, minimizing training error over the set of predictors
does something nontrivial when there are a sufficient number of examples.There
is nothing like a unifying problem defining the field. In many other areas
there are unifying p</p><p>5 0.10098988 <a title="398-tfidf-5" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>Introduction: AtICML 2003,Marty Zinkevichproposedthe online convex optimization setting and
showed that a particular gradient descent algorithm has regret O(T0.5) with
respect to the best predictor where T is the number of rounds. This seems to
be a nice model for online learning, and there has been some significant
follow-up work.AtCOLT 2006Elad Hazan,Adam Kalai,Satyen Kale, andAmit
Agarwalpresenteda modification which takes a Newton stepguaranteeing O(log T)
regret when the first and second derivatives are bounded.Then they applied
these algorithms to portfolio managementatICML 2006(withRobert Schapire)
yielding some very fun graphs.</p><p>6 0.10010472 <a title="398-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>7 0.099634059 <a title="398-tfidf-7" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>8 0.091501974 <a title="398-tfidf-8" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>9 0.08874812 <a title="398-tfidf-9" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>10 0.086371414 <a title="398-tfidf-10" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>11 0.085436523 <a title="398-tfidf-11" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>12 0.085345298 <a title="398-tfidf-12" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>13 0.083935156 <a title="398-tfidf-13" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>14 0.082672723 <a title="398-tfidf-14" href="../hunch_net-2005/hunch_net-2005-05-11-Visa_Casualties.html">69 hunch net-2005-05-11-Visa Casualties</a></p>
<p>15 0.082647942 <a title="398-tfidf-15" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>16 0.082618162 <a title="398-tfidf-16" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>17 0.080966629 <a title="398-tfidf-17" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>18 0.080574088 <a title="398-tfidf-18" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>19 0.080280982 <a title="398-tfidf-19" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>20 0.079411909 <a title="398-tfidf-20" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.182), (1, -0.115), (2, -0.057), (3, 0.038), (4, 0.007), (5, 0.034), (6, -0.018), (7, -0.04), (8, -0.046), (9, -0.04), (10, 0.012), (11, -0.019), (12, -0.03), (13, 0.008), (14, -0.03), (15, 0.057), (16, 0.036), (17, -0.032), (18, -0.019), (19, -0.033), (20, -0.034), (21, -0.019), (22, 0.013), (23, 0.01), (24, -0.091), (25, -0.03), (26, -0.014), (27, -0.021), (28, -0.009), (29, 0.033), (30, 0.066), (31, 0.059), (32, -0.002), (33, -0.075), (34, -0.005), (35, 0.041), (36, -0.068), (37, -0.009), (38, 0.076), (39, -0.017), (40, 0.071), (41, -0.02), (42, 0.012), (43, -0.04), (44, 0.002), (45, 0.054), (46, 0.063), (47, -0.024), (48, -0.024), (49, 0.098)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97401184 <a title="398-lsi-1" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>Introduction: (I'm channeling forJean-Yves Audiberthere, with some minor tweaking for
clarity.)SinceNemirovski'sSaint Flour lecture notes, numerous researchers have
studied the following problem in least squares regression: predict as well
as(MS) the best of d given functions (like in prediction with expert advice;
model = finite set of d functions)(C) the best convex combination of these
functions (i.e., model = convex hull of the d functions)(L) the best linear
combination of these functions (i.e., model = linear span of the d
functions)It is now well known (see, e.g., Sacha Tsybakov's COLT'03 paper)
that these tasks can be achieved since there exist estimators having an excess
risk of order (log d)/n for (MS), min( sqrt((log d)/n), d/n ) for (C) and d/n
for (L), where n is the training set size. Here, "risk" is amount of extra
loss per example which may be suffered due to the choice of random sample.The
practical use of these results seems rather limited to trivial statements
like: do not use the</p><p>2 0.6604045 <a title="398-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>Introduction: One nice use for this blog is to consider and discuss papers that that have
appeared at recent conferences. I really enjoyed Andrew Ng and Sham Kakade's
paperOnline Bounds for Bayesian Algorithms. From the paper:The philosophy
taken in the Bayesian methodology is often at odds withthat in the online
learning community…. the online learning settingmakes rather minimal
assumptions on the conditions under which thedata are being presented to the
learner â€”usually, Nature could provideexamples in an adversarial manner. We
study the performance ofBayesian algorithms in a more adversarial setting… We
providecompetitive bounds when the cost function is the log loss, and
wecompare our performance to the best model in our model class (as inthe
experts setting).It's a very nice analysis of some of my favorite algorithms
that all hinges around a beautiful theorem:Let Q be any distribution over
parameters theta. Then for all sequences S:L_{Bayes}(S) leq L_Q(S) +
KL(Q|P)where P is our prior and th</p><p>3 0.56806928 <a title="398-lsi-3" href="../hunch_net-2006/hunch_net-2006-07-05-more_icml_papers.html">189 hunch net-2006-07-05-more icml papers</a></p>
<p>Introduction: Here are a few other papers I enjoyed from ICML06.Topic Models:Dynamic Topic
ModelsDavid Blei, John LaffertyA nice model for how topics in LDA type models
can evolve over time,using a linear dynamical system on the natural parameters
and a veryclever structured variational approximation (in which the mean
fieldparameters are pseudo-observations of a virtual LDS). Like all
Bleipapers, he makes it look easy, but it is extremely impressive.Pachinko
AllocationWei Li, Andrew McCallumA very elegant (but computationally
challenging) model which inducescorrelation amongst topics using a multi-level
DAG whose interior nodesare "super-topics" and "sub-topics" and whose leaves
are thevocabulary words. Makes the slumbering monster of structure learning
stir.Sequence Analysis (I missed these talks since I was chairing another
session)Online Decoding of Markov Models with Latency ConstraintsMukund
Narasimhan, Paul Viola, Michael ShilmanAn "ah-ha!" paper showing how to trade
off latency and decodinga</p><p>4 0.55084693 <a title="398-lsi-4" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>Introduction: How do we judge success in Machine Learning? AsAaronnotes, the best way is to
use the loss imposed on you by the world. This turns out to be infeasible
sometimes for various reasons. The ones I've seen are:The learned prediction
is used in some complicated process that does not give the feedback necessary
to understand the prediction's impact on the loss.The prediction is used by
some other system which expects some semantics to the predicted value. This is
similar to the previous example, except that the issue is design modularity
rather than engineering modularity.The correct loss function is simply unknown
(and perhaps unknowable, except by experimentation).In these situations, it's
unclear what metric for evaluation should be chosen. This post has some design
advice for this murkier case. I'm using the word "metric" here to distinguish
the fact that we are considering methods forevaluatingpredictive systems
rather than a loss imposed by the real world or a loss which is optimized b</p><p>5 0.5437386 <a title="398-lsi-5" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>Introduction: There weretwopapersat ICML presenting learning algorithms for acontextual
bandit-style setting, where the loss for all labels is not known, but the loss
for one label is known. (The first might require aexploration
scavengingviewpoint to understand if the experimental assignment was
nonrandom.) I strongly approve of these papers and further work in this
setting and its variants, because I expect it to become more important than
supervised learning. As a quick review, we are thinking about situations where
repeatedly:The world reveals feature values (aka context information).A policy
chooses an action.The world provides a reward.Sometimes this is done in an
online fashion where the policy can change based on immediate feedback and
sometimes it's done in a batch setting where many samples are collected before
the policy can change. If you haven't spent time thinking about the setting,
you might want to because there are many natural applications.I'm going to
pick on the Banditron paper (</p><p>6 0.54020298 <a title="398-lsi-6" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>7 0.53909862 <a title="398-lsi-7" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>8 0.52989191 <a title="398-lsi-8" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>9 0.52606446 <a title="398-lsi-9" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>10 0.52043957 <a title="398-lsi-10" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>11 0.51216727 <a title="398-lsi-11" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>12 0.51083404 <a title="398-lsi-12" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>13 0.50618666 <a title="398-lsi-13" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>14 0.50423491 <a title="398-lsi-14" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>15 0.5008378 <a title="398-lsi-15" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>16 0.49239931 <a title="398-lsi-16" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>17 0.48778063 <a title="398-lsi-17" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>18 0.48287481 <a title="398-lsi-18" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>19 0.48236677 <a title="398-lsi-19" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>20 0.48102078 <a title="398-lsi-20" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(5, 0.27), (16, 0.014), (35, 0.065), (42, 0.253), (45, 0.048), (50, 0.017), (55, 0.013), (68, 0.076), (74, 0.073), (82, 0.018), (88, 0.021), (92, 0.022), (95, 0.021)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.92915761 <a title="398-lda-1" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>Introduction: As usualICML 2007will be hosting aworkshop programto be held this year on June
24th. The success of the program depends on having researchers like you
propose interesting workshop topics and then organize the workshops. I'd like
to encourage all of you to consider sending a workshop proposal. The proposal
deadline has been extended to March 5. See the workshop web-site for
details.Organizing a workshop is a unique way to gather an international group
of researchers together to focus for an entire day on a topic of your
choosing. I've always found that the cost of organizing a workshop is not so
large, and very low compared to the benefits. The topic and format of a
workshop are limited only by your imagination (and the attractiveness to
potential participants) and need not follow the usual model of a mini-
conference on a particular ML sub-area. Hope to see some interesting proposals
rolling in.</p><p>same-blog 2 0.89019293 <a title="398-lda-2" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>Introduction: (I'm channeling forJean-Yves Audiberthere, with some minor tweaking for
clarity.)SinceNemirovski'sSaint Flour lecture notes, numerous researchers have
studied the following problem in least squares regression: predict as well
as(MS) the best of d given functions (like in prediction with expert advice;
model = finite set of d functions)(C) the best convex combination of these
functions (i.e., model = convex hull of the d functions)(L) the best linear
combination of these functions (i.e., model = linear span of the d
functions)It is now well known (see, e.g., Sacha Tsybakov's COLT'03 paper)
that these tasks can be achieved since there exist estimators having an excess
risk of order (log d)/n for (MS), min( sqrt((log d)/n), d/n ) for (C) and d/n
for (L), where n is the training set size. Here, "risk" is amount of extra
loss per example which may be suffered due to the choice of random sample.The
practical use of these results seems rather limited to trivial statements
like: do not use the</p><p>3 0.83874303 <a title="398-lda-3" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>Introduction: Yesterday, there was a discussion aboutfuture publication models at
NIPS.YannandZoubinhave specific detailed proposals which I'll add links to
when I get them (Yann's proposalandZoubin's proposal).What struck me about the
discussion is that there are many simultaneous concerns as well as many
simultaneous proposals, which makes it difficult to keep all the distinctions
straight in a verbal conversation. It also seemed like people were serious
enough about this that we may see some real movement. Certainly, my personal
experience motivates that as I'veposted many timesabout the substantial flaws
in our review process, including some very poor personal experiences.Concerns
include the following:(Several) Reviewers are overloaded, boosting the noise
in decision making.(Yann) A new system should run with as little built-in
delay and friction to the process of research as possible.(Hanna
Wallach(updated)) Double-blind review is particularly important for people who
are unknown or from an un</p><p>4 0.79237181 <a title="398-lda-4" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?Reductions are machines which turn solvers for one problem into solvers
for another problem.Why?Reductions are useful for several reasons.Laziness.
Reducing a problem to classification make at least 10 learning algorithms
available to solve a problem. Inventing 10 learning algorithms is quite a bit
of work. Similarly, programming a reduction is often trivial, while
programming a learning algorithm is a great deal of work.Crystallization. The
problems we often want to solve in learning are worst-case-impossible, but
average case feasible. By reducing all problems onto one or a few primitives,
we can fine tune these primitives to perform well on real-world problems with
greater precision due to the greater number of problems to validate
on.Theoretical Organization. By studying what reductions are easy vs. hard vs.
impossible, we can learn which problems are roughly equivalent in difficulty
and which are much harder.What we know now.Typesafe reductions. In the
beginning, there was th</p><p>5 0.72250599 <a title="398-lda-5" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>Introduction: At NIPS,Andrew Ngasked me what should be in a large scale learning class.
After some discussion with him andNandoand mulling it over a bit, these are
the topics that I think should be covered.There are many different kinds of
scaling.Scaling in examplesThis is the most basic kind of scaling.Online
Gradient DescentThis is an old algorithm--I'm not sure if anyone can be
credited with it in particular. Perhaps thePerceptronis a good precursor, but
substantial improvements come from the notion of a loss function of
whichsquared loss,logistic loss, Hinge Loss, andQuantile Lossare all worth
covering. It's important to cover thesemanticsof these loss functions as
well.Vowpal Wabbitis a reasonably fast codebase implementing these.Second
Order Gradient Descent methodsFor some problems, methods taking into account
second derivative information can be more effective. I've seen preconditioned
conjugate gradient work well, for whichJonathan Shewchuck'swriteupis
reasonable. Nando likesL-BFGSwhich I</p><p>6 0.71474671 <a title="398-lda-6" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>7 0.71368992 <a title="398-lda-7" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>8 0.71150631 <a title="398-lda-8" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>9 0.70982224 <a title="398-lda-9" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>10 0.70905679 <a title="398-lda-10" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>11 0.70830643 <a title="398-lda-11" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>12 0.70798147 <a title="398-lda-12" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>13 0.70763725 <a title="398-lda-13" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>14 0.70626378 <a title="398-lda-14" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>15 0.70523876 <a title="398-lda-15" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>16 0.70521134 <a title="398-lda-16" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>17 0.70414692 <a title="398-lda-17" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>18 0.70384711 <a title="398-lda-18" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>19 0.70359278 <a title="398-lda-19" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>20 0.7035898 <a title="398-lda-20" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
