<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>401 hunch net-2010-06-20-2010 ICML discussion site</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-401" href="#">hunch_net-2010-401</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>401 hunch net-2010-06-20-2010 ICML discussion site</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-401-html" href="http://hunch.net/?p=1419">html</a></p><p>Introduction: A substantial difficulty with the 2009 and 2008  ICML discussion system  was a communication vacuum, where authors were not informed of comments, and commenters were not informed of responses to their comments without explicit monitoring.   Mark Reid  has setup a  new discussion system for 2010  with the goal of addressing this.
 
Mark didn’t want to make it to intrusive, so you must opt-in.  As an author,  find your paper  and “Subscribe by email” to the comments.  As a commenter, you have the option of providing an email for follow-up notification.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A substantial difficulty with the 2009 and 2008  ICML discussion system  was a communication vacuum, where authors were not informed of comments, and commenters were not informed of responses to their comments without explicit monitoring. [sent-1, score-2.638]
</p><p>2 Mark Reid  has setup a  new discussion system for 2010  with the goal of addressing this. [sent-2, score-0.842]
</p><p>3 Mark didn’t want to make it to intrusive, so you must opt-in. [sent-3, score-0.209]
</p><p>4 As an author,  find your paper  and “Subscribe by email” to the comments. [sent-4, score-0.152]
</p><p>5 As a commenter, you have the option of providing an email for follow-up notification. [sent-5, score-0.637]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('informed', 0.394), ('mark', 0.352), ('email', 0.302), ('comments', 0.266), ('commenters', 0.236), ('subscribe', 0.223), ('responses', 0.223), ('discussion', 0.203), ('reid', 0.197), ('option', 0.191), ('addressing', 0.181), ('communication', 0.176), ('system', 0.165), ('didn', 0.162), ('explicit', 0.148), ('providing', 0.144), ('setup', 0.142), ('authors', 0.127), ('difficulty', 0.116), ('author', 0.114), ('goal', 0.106), ('without', 0.1), ('find', 0.091), ('substantial', 0.09), ('must', 0.079), ('icml', 0.079), ('want', 0.074), ('paper', 0.061), ('make', 0.056), ('new', 0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="401-tfidf-1" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>Introduction: A substantial difficulty with the 2009 and 2008  ICML discussion system  was a communication vacuum, where authors were not informed of comments, and commenters were not informed of responses to their comments without explicit monitoring.   Mark Reid  has setup a  new discussion system for 2010  with the goal of addressing this.
 
Mark didn’t want to make it to intrusive, so you must opt-in.  As an author,  find your paper  and “Subscribe by email” to the comments.  As a commenter, you have the option of providing an email for follow-up notification.</p><p>2 0.28168201 <a title="401-tfidf-2" href="../hunch_net-2007/hunch_net-2007-07-12-ICML_Trends.html">254 hunch net-2007-07-12-ICML Trends</a></p>
<p>Introduction: Mark Reid  did a post on  ICML trends  that I found interesting.</p><p>3 0.23840877 <a title="401-tfidf-3" href="../hunch_net-2008/hunch_net-2008-06-30-ICML_has_a_comment_system.html">305 hunch net-2008-06-30-ICML has a comment system</a></p>
<p>Introduction: Mark Reid  has stepped up and created a  comment system for ICML papers  which  Greger Linden  has tightly integrated.  
 
My understanding is that Mark spent quite  a bit of time on the details, and there are some cool features like working latex math mode.  This is an excellent chance for the ICML community to experiment with making ICML year-round, so I hope it works out.  Please do consider experimenting with it.</p><p>4 0.18833491 <a title="401-tfidf-4" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>Introduction: Mark Reid  has setup a  discussion site for ICML papers  again this year and  Monica Dinculescu  has linked it in from the ICML site.  Last year’s attempt appears to have been an acceptable but not wild success as a little bit of fruitful discussion occurred.  I’m hoping this year will be a bit more of a success—please don’t be shy   
 
I’d like to also point out that  ICML ‘s early  registration  deadline has a few hours left, while  UAI ‘s and  COLT ‘s are in a week.</p><p>5 0.18121721 <a title="401-tfidf-5" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>Introduction: Just about nothing could keep me from attending  ICML , except for  Dora  who arrived on Monday.  Consequently, I have only secondhand reports that the conference is going well.
 
For those who are remote (like me) or after the conference (like everyone),  Mark Reid  has setup the  ICML discussion  site where you can comment on any paper or subscribe to papers.  Authors are automatically subscribed to their own papers, so it should be possible to have a discussion significantly after the fact, as people desire.
 
We also conducted a survey before the conference and have the  survey results  now.  This can be compared with the  ICML 2010 survey results .  Looking at the comparable questions, we can sometimes order the answers to have scores ranging from 0 to 3 or 0 to 4 with 3 or 4 being best and 0 worst, then compute the average difference between 2012 and 2010.
 
Glancing through them, I see:
  
 Most people found the papers they reviewed a good fit for their expertise (-.037 w.r.t 20</p><p>6 0.15044774 <a title="401-tfidf-6" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>7 0.12103103 <a title="401-tfidf-7" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>8 0.11789598 <a title="401-tfidf-8" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>9 0.10496303 <a title="401-tfidf-9" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>10 0.10272529 <a title="401-tfidf-10" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>11 0.097279526 <a title="401-tfidf-11" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>12 0.096715234 <a title="401-tfidf-12" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>13 0.091322109 <a title="401-tfidf-13" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>14 0.09007898 <a title="401-tfidf-14" href="../hunch_net-2007/hunch_net-2007-10-14-NIPS_workshp%3A_Learning_Problem_Design.html">265 hunch net-2007-10-14-NIPS workshp: Learning Problem Design</a></p>
<p>15 0.08496958 <a title="401-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>16 0.084388286 <a title="401-tfidf-16" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>17 0.080435961 <a title="401-tfidf-17" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>18 0.080189392 <a title="401-tfidf-18" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>19 0.080011442 <a title="401-tfidf-19" href="../hunch_net-2005/hunch_net-2005-10-03-Not_ICML.html">117 hunch net-2005-10-03-Not ICML</a></p>
<p>20 0.073941208 <a title="401-tfidf-20" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.11), (1, -0.113), (2, 0.085), (3, 0.039), (4, 0.021), (5, -0.002), (6, -0.018), (7, -0.072), (8, -0.044), (9, -0.002), (10, -0.054), (11, -0.037), (12, -0.199), (13, 0.121), (14, 0.173), (15, 0.002), (16, -0.273), (17, -0.179), (18, -0.023), (19, 0.128), (20, -0.005), (21, -0.096), (22, -0.102), (23, 0.036), (24, -0.042), (25, -0.082), (26, 0.071), (27, -0.101), (28, 0.085), (29, 0.023), (30, -0.058), (31, -0.007), (32, 0.02), (33, 0.066), (34, -0.005), (35, 0.051), (36, -0.004), (37, -0.097), (38, 0.022), (39, -0.015), (40, 0.072), (41, -0.043), (42, -0.037), (43, 0.001), (44, 0.099), (45, -0.014), (46, -0.004), (47, 0.068), (48, 0.074), (49, -0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99211001 <a title="401-lsi-1" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>Introduction: A substantial difficulty with the 2009 and 2008  ICML discussion system  was a communication vacuum, where authors were not informed of comments, and commenters were not informed of responses to their comments without explicit monitoring.   Mark Reid  has setup a  new discussion system for 2010  with the goal of addressing this.
 
Mark didn’t want to make it to intrusive, so you must opt-in.  As an author,  find your paper  and “Subscribe by email” to the comments.  As a commenter, you have the option of providing an email for follow-up notification.</p><p>2 0.87026197 <a title="401-lsi-2" href="../hunch_net-2007/hunch_net-2007-07-12-ICML_Trends.html">254 hunch net-2007-07-12-ICML Trends</a></p>
<p>Introduction: Mark Reid  did a post on  ICML trends  that I found interesting.</p><p>3 0.83848649 <a title="401-lsi-3" href="../hunch_net-2008/hunch_net-2008-06-30-ICML_has_a_comment_system.html">305 hunch net-2008-06-30-ICML has a comment system</a></p>
<p>Introduction: Mark Reid  has stepped up and created a  comment system for ICML papers  which  Greger Linden  has tightly integrated.  
 
My understanding is that Mark spent quite  a bit of time on the details, and there are some cool features like working latex math mode.  This is an excellent chance for the ICML community to experiment with making ICML year-round, so I hope it works out.  Please do consider experimenting with it.</p><p>4 0.71965218 <a title="401-lsi-4" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>Introduction: Mark Reid  has setup a  discussion site for ICML papers  again this year and  Monica Dinculescu  has linked it in from the ICML site.  Last year’s attempt appears to have been an acceptable but not wild success as a little bit of fruitful discussion occurred.  I’m hoping this year will be a bit more of a success—please don’t be shy   
 
I’d like to also point out that  ICML ‘s early  registration  deadline has a few hours left, while  UAI ‘s and  COLT ‘s are in a week.</p><p>5 0.68645245 <a title="401-lsi-5" href="../hunch_net-2005/hunch_net-2005-10-03-Not_ICML.html">117 hunch net-2005-10-03-Not ICML</a></p>
<p>Introduction: Alex Smola  showed me this  ICML 2006  webpage.  This is  NOT  the ICML we know, but rather some people at “Enformatika”.  Investigation shows that they registered with an anonymous yahoo email account from  dotregistrar.com  the “Home of the $6.79 wholesale domain!” and their nameservers are by  Turkticaret , a Turkish internet company.
 
It appears the website has since been altered to “ ICNL ” (the above link uses the google cache).
 
They say that imitation is the sincerest form of flattery, so the organizers of the real  ICML 2006  must feel quite flattered.</p><p>6 0.5829252 <a title="401-lsi-6" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>7 0.45860365 <a title="401-lsi-7" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>8 0.45732489 <a title="401-lsi-8" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>9 0.44074258 <a title="401-lsi-9" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>10 0.39594448 <a title="401-lsi-10" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>11 0.3863188 <a title="401-lsi-11" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>12 0.36119244 <a title="401-lsi-12" href="../hunch_net-2006/hunch_net-2006-12-06-The_Spam_Problem.html">223 hunch net-2006-12-06-The Spam Problem</a></p>
<p>13 0.36055171 <a title="401-lsi-13" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>14 0.35605898 <a title="401-lsi-14" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>15 0.35413468 <a title="401-lsi-15" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>16 0.33906785 <a title="401-lsi-16" href="../hunch_net-2009/hunch_net-2009-07-11-Interesting_papers_at_KDD.html">364 hunch net-2009-07-11-Interesting papers at KDD</a></p>
<p>17 0.33610108 <a title="401-lsi-17" href="../hunch_net-2007/hunch_net-2007-12-17-New_Machine_Learning_mailing_list.html">278 hunch net-2007-12-17-New Machine Learning mailing list</a></p>
<p>18 0.33029938 <a title="401-lsi-18" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>19 0.32324412 <a title="401-lsi-19" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>20 0.32239637 <a title="401-lsi-20" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.601), (27, 0.104), (55, 0.129)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94273984 <a title="401-lda-1" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>Introduction: A substantial difficulty with the 2009 and 2008  ICML discussion system  was a communication vacuum, where authors were not informed of comments, and commenters were not informed of responses to their comments without explicit monitoring.   Mark Reid  has setup a  new discussion system for 2010  with the goal of addressing this.
 
Mark didn’t want to make it to intrusive, so you must opt-in.  As an author,  find your paper  and “Subscribe by email” to the comments.  As a commenter, you have the option of providing an email for follow-up notification.</p><p>2 0.86094207 <a title="401-lda-2" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>Introduction: This  problem  has been cracked (but not quite completely solved) by  Alina ,  Pradeep , and  I .  The problem is essentially finding a better way to reduce multiclass classification to binary classification.  The solution is to use a carefully crafted tournament,  the simplest version of which is a  single elimination tournament  where the “players” are the different classes.  An example of the structure is here: 
    
For the single elimination tournament, we can prove that: 
 For all multiclass problems  D , for all learned binary classifiers  c , the regret of an induced multiclass classifier is bounded by the regret of the binary classifier times  log 2  k .  Restated:  
  reg multiclass (D,Filter_tree_test(c)) <= reg binary  (Filter_tree_train(D),c)    
Here:
  
   Filter_tree_train(D)  is the induced binary classification problem 
   Filter_tree_test(c)  is the induced multiclass classifier. 
   reg multiclass   is the multiclass regret (= difference between error rate and minim</p><p>3 0.76234168 <a title="401-lda-3" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>Introduction: I want to expand on  this post  which describes one of the core tricks for making  Vowpal Wabbit  fast and easy to use when learning from text.  
 
The central trick is converting a word (or any other parseable quantity) into a number via a hash function.   Kishore  tells me this is a relatively old trick in NLP land, but it has some added advantages when doing online learning, because you can learn directly from the existing data without preprocessing the data to create features (destroying the online property) or using an expensive hashtable lookup (slowing things down).
 
A central concern for this approach is collisions, which create a loss of information.  If you use  m  features in an index space of size  n  the birthday paradox suggests a collision if  m > n 0.5  , essentially because there are  m 2   pairs.   This is pretty bad, because it says that with a vocabulary of  10 5   features, you might need to have  10 10   entries in your table.
 
It turns out that redundancy is gr</p><p>4 0.66473085 <a title="401-lda-4" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data sources  D , 
  Pr S ~ D (f(D) > g(S)) > 1-d   
where  f  is some function of the distribution (such as the mean) and  g  is some function of the observed sample  S .   The constraints on  D  can vary between “Independent and identically distributed (IID) samples from a gaussian with an unknown mean” to “IID samples from an arbitrary distribution  D “.  There are even some confidence intervals which do not require IID samples.
 
Classical confidence intervals often confuse people.  They do  not  say “with high probability, for my observed sample, the bounds holds”.   Instead, they tell you that if you reason according to the confidence interval in the future (and the constraints on  D  are satisfied), then you are not often wrong.  Restated, they tell you something about what a safe procedure is in a stochastic world where  d  is the safety parameter.
 
There are a number of results in theoretical machine learn</p><p>5 0.66075087 <a title="401-lda-5" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>Introduction: This, again, is something of a research direction rather than a single problem.
 
There are several metrics people care about which depend upon the relative ranking of examples and there are sometimes good reasons to care about such metrics.  Examples include  AROC , “F1″, the proportion of the time that the top ranked element is in some class, the proportion of the top 10 examples in some class ( google ‘s problem),  the lowest ranked example of some class, and the “sort distance” from a predicted ranking to a correct ranking.  See  here  for an example of some of these.  
 
 Problem  What does the ability to classify well imply about performance under these metrics?
 
 Past Work 
  
  Probabilistic classification under squared error  can be solved with a classifier.  A counterexample shows this does not imply a good AROC. 
 Sample complexity bounds for  AROC  (and  here ). 
 A paper on “ Learning to Order Things “. 
  
 Difficulty  Several of these may be easy.  Some of them may be h</p><p>6 0.60975826 <a title="401-lda-6" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>7 0.52941233 <a title="401-lda-7" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>8 0.49298245 <a title="401-lda-8" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>9 0.44570956 <a title="401-lda-9" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>10 0.39144817 <a title="401-lda-10" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>11 0.3901968 <a title="401-lda-11" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>12 0.37474334 <a title="401-lda-12" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>13 0.35434186 <a title="401-lda-13" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>14 0.33345187 <a title="401-lda-14" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>15 0.32957193 <a title="401-lda-15" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>16 0.32890087 <a title="401-lda-16" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>17 0.32780525 <a title="401-lda-17" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>18 0.31997728 <a title="401-lda-18" href="../hunch_net-2006/hunch_net-2006-12-06-The_Spam_Problem.html">223 hunch net-2006-12-06-The Spam Problem</a></p>
<p>19 0.31818748 <a title="401-lda-19" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>20 0.31509787 <a title="401-lda-20" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
