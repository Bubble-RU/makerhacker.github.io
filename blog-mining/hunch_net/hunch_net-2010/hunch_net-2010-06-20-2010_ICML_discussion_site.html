<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>401 hunch net-2010-06-20-2010 ICML discussion site</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-401" href="#">hunch_net-2010-401</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>401 hunch net-2010-06-20-2010 ICML discussion site</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-401-html" href="http://hunch.net/?p=1419">html</a></p><p>Introduction: A substantial difficulty with the 2009 and 2008ICML discussion systemwas a
communication vacuum, where authors were not informed of comments, and
commenters were not informed of responses to their comments without explicit
monitoring.Mark Reidhas setup anew discussion system for 2010with the goal of
addressing this.Mark didn't want to make it to intrusive, so you must opt-in.
As an author,find your paperand "Subscribe by email" to the comments. As a
commenter, you have the option of providing an email for follow-up
notification.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A substantial difficulty with the 2009 and 2008ICML discussion systemwas a communication vacuum, where authors were not informed of comments, and commenters were not informed of responses to their comments without explicit monitoring. [sent-1, score-2.674]
</p><p>2 Mark Reidhas setup anew discussion system for 2010with the goal of addressing this. [sent-2, score-1.023]
</p><p>3 Mark didn't want to make it to intrusive, so you must opt-in. [sent-3, score-0.226]
</p><p>4 As a commenter, you have the option of providing an email for follow-up notification. [sent-5, score-0.691]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('informed', 0.42), ('email', 0.332), ('comments', 0.294), ('commenters', 0.252), ('anew', 0.237), ('reidhas', 0.237), ('subscribe', 0.237), ('responses', 0.237), ('discussion', 0.228), ('option', 0.203), ('addressing', 0.197), ('communication', 0.192), ('explicit', 0.161), ('setup', 0.158), ('providing', 0.156), ('authors', 0.135), ('difficulty', 0.13), ('goal', 0.113), ('without', 0.109), ('substantial', 0.096), ('system', 0.09), ('must', 0.086), ('want', 0.079), ('make', 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="401-tfidf-1" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>Introduction: A substantial difficulty with the 2009 and 2008ICML discussion systemwas a
communication vacuum, where authors were not informed of comments, and
commenters were not informed of responses to their comments without explicit
monitoring.Mark Reidhas setup anew discussion system for 2010with the goal of
addressing this.Mark didn't want to make it to intrusive, so you must opt-in.
As an author,find your paperand "Subscribe by email" to the comments. As a
commenter, you have the option of providing an email for follow-up
notification.</p><p>2 0.170771 <a title="401-tfidf-2" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>Introduction: Centmailis a scheme which makes charity donations have a secondary value, as a
stamp for email. When discussed onnewscientist,slashdot, and others, some of
the comments make the academic review process appear thoughtful. Some
prominent fallacies are:Costing money fallacy. Some commenters appear to
believe the system charges money per email. Instead, the basic idea is that
users get an extra benefit from donations to a charity and participation is
strictly voluntary. The solution to this fallacy is simply readingthe
details.Single solution fallacy. Some commenters seem to think this is
proposed as a complete solution to spam, and since not everyone will opt to
participate, it won't work. But a complete solution is not at all necessary or
even possible given theflag-day problem. Deployed machine learning systems for
fighting spam are great at taking advantage of a partial solution. The
solution to this fallacy is learning about machine learning. In the current
state of affairs, informed</p><p>3 0.13901018 <a title="401-tfidf-3" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>Introduction: Several people have had difficulty with comments which seem to have an allowed
language significantly poorer than posts. The set of allowed html tags has
been increased and themarkdown filterhas been put in place to try to make
commenting easier. I'll put some examples into the comments of this post.</p><p>4 0.1183881 <a title="401-tfidf-4" href="../hunch_net-2013/hunch_net-2013-03-22-I%26%238217%3Bm_a_bandit.html">480 hunch net-2013-03-22-I&#8217;m a bandit</a></p>
<p>Introduction: Sebastien Bubeck has anew ML blogfocused on optimization and partial feedback
which may interest people.</p><p>5 0.11680508 <a title="401-tfidf-5" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>Introduction: Mark Reidhas setup adiscussion site for ICML papersagain this year andMonica
Dinculescuhas linked it in from the ICML site. Last year's attempt appears to
have been an acceptable but not wild success as a little bit of fruitful
discussion occurred. I'm hoping this year will be a bit more of a success--
please don't be shyI'd like to also point out thatICML's
earlyregistrationdeadline has a few hours left, whileUAI's andCOLT's are in a
week.</p><p>6 0.11159126 <a title="401-tfidf-6" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>7 0.10409539 <a title="401-tfidf-7" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>8 0.10050442 <a title="401-tfidf-8" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>9 0.099290259 <a title="401-tfidf-9" href="../hunch_net-2007/hunch_net-2007-10-14-NIPS_workshp%3A_Learning_Problem_Design.html">265 hunch net-2007-10-14-NIPS workshp: Learning Problem Design</a></p>
<p>10 0.092248678 <a title="401-tfidf-10" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>11 0.081128836 <a title="401-tfidf-11" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>12 0.080516592 <a title="401-tfidf-12" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>13 0.076737911 <a title="401-tfidf-13" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>14 0.075219654 <a title="401-tfidf-14" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>15 0.073419541 <a title="401-tfidf-15" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>16 0.072911881 <a title="401-tfidf-16" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>17 0.069853291 <a title="401-tfidf-17" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>18 0.069109984 <a title="401-tfidf-18" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>19 0.068864264 <a title="401-tfidf-19" href="../hunch_net-2006/hunch_net-2006-12-06-The_Spam_Problem.html">223 hunch net-2006-12-06-The Spam Problem</a></p>
<p>20 0.067109495 <a title="401-tfidf-20" href="../hunch_net-2008/hunch_net-2008-06-30-ICML_has_a_comment_system.html">305 hunch net-2008-06-30-ICML has a comment system</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.079), (1, 0.073), (2, -0.018), (3, -0.055), (4, 0.011), (5, 0.023), (6, 0.017), (7, -0.042), (8, 0.075), (9, 0.063), (10, -0.008), (11, -0.005), (12, 0.046), (13, 0.074), (14, -0.016), (15, -0.083), (16, 0.092), (17, 0.007), (18, -0.08), (19, 0.174), (20, 0.088), (21, 0.032), (22, -0.03), (23, 0.043), (24, -0.096), (25, -0.001), (26, 0.06), (27, -0.042), (28, 0.026), (29, 0.009), (30, 0.001), (31, 0.069), (32, 0.035), (33, 0.011), (34, 0.045), (35, 0.166), (36, -0.092), (37, 0.024), (38, -0.013), (39, -0.081), (40, -0.064), (41, 0.093), (42, 0.062), (43, 0.065), (44, -0.088), (45, 0.121), (46, -0.025), (47, -0.093), (48, 0.038), (49, 0.028)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99534714 <a title="401-lsi-1" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>Introduction: A substantial difficulty with the 2009 and 2008ICML discussion systemwas a
communication vacuum, where authors were not informed of comments, and
commenters were not informed of responses to their comments without explicit
monitoring.Mark Reidhas setup anew discussion system for 2010with the goal of
addressing this.Mark didn't want to make it to intrusive, so you must opt-in.
As an author,find your paperand "Subscribe by email" to the comments. As a
commenter, you have the option of providing an email for follow-up
notification.</p><p>2 0.69287586 <a title="401-lsi-2" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>Introduction: Centmailis a scheme which makes charity donations have a secondary value, as a
stamp for email. When discussed onnewscientist,slashdot, and others, some of
the comments make the academic review process appear thoughtful. Some
prominent fallacies are:Costing money fallacy. Some commenters appear to
believe the system charges money per email. Instead, the basic idea is that
users get an extra benefit from donations to a charity and participation is
strictly voluntary. The solution to this fallacy is simply readingthe
details.Single solution fallacy. Some commenters seem to think this is
proposed as a complete solution to spam, and since not everyone will opt to
participate, it won't work. But a complete solution is not at all necessary or
even possible given theflag-day problem. Deployed machine learning systems for
fighting spam are great at taking advantage of a partial solution. The
solution to this fallacy is learning about machine learning. In the current
state of affairs, informed</p><p>3 0.56221598 <a title="401-lsi-3" href="../hunch_net-2006/hunch_net-2006-12-06-The_Spam_Problem.html">223 hunch net-2006-12-06-The Spam Problem</a></p>
<p>Introduction: TheNew York Timeshas an article on thegrowth of spam. Interesting facts
include: 9/10 of all email is spam, spam source identification is nearly
useless due to botnet spam senders, and image based spam (emails which consist
of an image only) are on the growth.Estimates of the cost of spam are almost
certainly far to low, because they do not account for the cost in time lost by
people.The image based spam which is currently penetrating many filters should
be catchable with a more sophisticated application of machine learning
technology. For the spam I see, the rendered images come in only a few
formats, which would be easy to recognize via a support vector machine (with
RBF kernel), neural network, or even nearest-neighbor architecture. The
mechanics of setting this up to run efficiently is the only real challenge.
This is the next step in the spam war.The response to this system is to make
the image based spam even more random. We should (essentially) expect to
seeCaptchaspam, and our</p><p>4 0.54197526 <a title="401-lsi-4" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>Introduction: Several people have had difficulty with comments which seem to have an allowed
language significantly poorer than posts. The set of allowed html tags has
been increased and themarkdown filterhas been put in place to try to make
commenting easier. I'll put some examples into the comments of this post.</p><p>5 0.48011452 <a title="401-lsi-5" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>Introduction: The hunch.net server has been updated. I've taken the opportunity to upgrade
the version of wordpress which caused cascading changes.Old threaded comments
are now flattened. The system we used to use (Brian's threaded comments)
appears incompatible with the new threading system built into wordpress. I
haven't yet figured out a workaround.I setup afeedburner account.I added an
RSS aggregator for both Machine Learning and other research blogs that I like
to follow. This is something that I've wanted to do for awhile.Many other
minor changes in font and format, with some help fromAlina.If you have any
suggestions for site tweaks, please speak up.</p><p>6 0.45305601 <a title="401-lsi-6" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>7 0.44463062 <a title="401-lsi-7" href="../hunch_net-2005/hunch_net-2005-10-03-Not_ICML.html">117 hunch net-2005-10-03-Not ICML</a></p>
<p>8 0.41683799 <a title="401-lsi-8" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>9 0.41127774 <a title="401-lsi-9" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>10 0.3974272 <a title="401-lsi-10" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>11 0.35729718 <a title="401-lsi-11" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>12 0.33837172 <a title="401-lsi-12" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>13 0.33484861 <a title="401-lsi-13" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>14 0.33179969 <a title="401-lsi-14" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>15 0.33037043 <a title="401-lsi-15" href="../hunch_net-2007/hunch_net-2007-10-14-NIPS_workshp%3A_Learning_Problem_Design.html">265 hunch net-2007-10-14-NIPS workshp: Learning Problem Design</a></p>
<p>16 0.32818109 <a title="401-lsi-16" href="../hunch_net-2007/hunch_net-2007-12-17-New_Machine_Learning_mailing_list.html">278 hunch net-2007-12-17-New Machine Learning mailing list</a></p>
<p>17 0.32273737 <a title="401-lsi-17" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>18 0.32264972 <a title="401-lsi-18" href="../hunch_net-2005/hunch_net-2005-09-20-Workshop_Proposal%3A_Atomic_Learning.html">114 hunch net-2005-09-20-Workshop Proposal: Atomic Learning</a></p>
<p>19 0.32191753 <a title="401-lsi-19" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>20 0.31525511 <a title="401-lsi-20" href="../hunch_net-2008/hunch_net-2008-06-30-ICML_has_a_comment_system.html">305 hunch net-2008-06-30-ICML has a comment system</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(33, 0.513), (42, 0.121), (74, 0.188)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96702445 <a title="401-lda-1" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>Introduction: A substantial difficulty with the 2009 and 2008ICML discussion systemwas a
communication vacuum, where authors were not informed of comments, and
commenters were not informed of responses to their comments without explicit
monitoring.Mark Reidhas setup anew discussion system for 2010with the goal of
addressing this.Mark didn't want to make it to intrusive, so you must opt-in.
As an author,find your paperand "Subscribe by email" to the comments. As a
commenter, you have the option of providing an email for follow-up
notification.</p><p>2 0.40722269 <a title="401-lda-2" href="../hunch_net-2006/hunch_net-2006-03-27-Gradients_everywhere.html">167 hunch net-2006-03-27-Gradients everywhere</a></p>
<p>Introduction: One of the basic observations from theatomic learning workshopis that
gradient-based optimization is pervasive. For example, at least 7 (of 12)
speakers used the word 'gradient' in their talk and several others may be
approximating a gradient. The essential useful quality of a gradient is that
it decouples local updates from global optimization. Restated: Given a
gradient, we can determine how to change individual parameters of the system
so as to improve overall performance.It's easy to feel depressed about this
and think "nothing has happened", but that appears untrue. Many of the talks
were about clever techniques for computing gradients where your calculus
textbook breaks down.Sometimes there are clever approximations of the
gradient. (Simon Osindero)Sometimes we can compute constrained gradients via
iterated gradient/project steps. (Ben Taskar)Sometimes we can compute
gradients anyways over mildly nondifferentiable functions. (Drew Bagnell)Even
given a gradient, the choice of upda</p><p>3 0.3980619 <a title="401-lda-3" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>Introduction: The internet has recently made the research process much smoother: papers are
easy to obtain, citations are easy to follow, and unpublished "tutorials" are
often available. Yet, new research fields can look very complicated to
outsiders or newcomers. Every paper is like a small piece of an unfinished
jigsaw puzzle: to understand just one publication, a researcher without
experience in the field will typically have to follow several layers of
citations, and many of the papers he encounters have a great deal of repeated
information. Furthermore, from one publication to the next, notation and
terminology may not be consistent which can further confuse the reader.But the
internet is now proving to be an extremely useful medium for collaboration and
knowledge aggregation. Online forums allow users to ask and answer questions
and to share ideas. The recent phenomenon of Wikipedia provides a proof-of-
concept for the "anyone can edit" system. Can such models be used to
facilitate research and</p><p>4 0.39653778 <a title="401-lda-4" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>5 0.39621133 <a title="401-lda-5" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>Introduction: Parallel machine learning is a subject rarely addressed at machine learning
conferences. Nevertheless, it seems likely to increase in importance
because:Data set sizes appear to be growing substantially faster than
computation. Essentially, this happens because more and more sensors of
various sorts are being hooked up to the internet.Serial speedups of
processors seem are relatively stalled. The new trend is to make processors
more powerful by making themmulticore.BothAMDandIntelare making dual core
designs standard, with plans for more parallelism in the future.IBM'sCell
processorhas (essentially) 9 cores.Modern graphics chips can have an order of
magnitude more separate execution units.The meaning of 'core' varies a bit
from processor to processor, but the overall trend seems quite clear.So, how
do we parallelize machine learning algorithms?The simplest and most common
technique is to simply run the same learning algorithm with different
parameters on different processors. Cluster m</p><p>6 0.39614484 <a title="401-lda-6" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>7 0.39564049 <a title="401-lda-7" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>8 0.39263114 <a title="401-lda-8" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>9 0.38920626 <a title="401-lda-9" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>10 0.38680059 <a title="401-lda-10" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>11 0.37873617 <a title="401-lda-11" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>12 0.37114835 <a title="401-lda-12" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>13 0.37088415 <a title="401-lda-13" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>14 0.36779106 <a title="401-lda-14" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>15 0.36518073 <a title="401-lda-15" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>16 0.36379871 <a title="401-lda-16" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>17 0.3635025 <a title="401-lda-17" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>18 0.36240593 <a title="401-lda-18" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>19 0.36111468 <a title="401-lda-19" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>20 0.36013997 <a title="401-lda-20" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
