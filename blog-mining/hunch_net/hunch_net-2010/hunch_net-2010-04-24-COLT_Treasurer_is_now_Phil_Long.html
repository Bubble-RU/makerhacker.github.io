<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>394 hunch net-2010-04-24-COLT Treasurer is now Phil Long</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-394" href="#">hunch_net-2010-394</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>394 hunch net-2010-04-24-COLT Treasurer is now Phil Long</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-394-html" href="http://hunch.net/?p=1314">html</a></p><p>Introduction: For about 5 years, I've been the treasurer of the Association for
Computational Learning, otherwise known as COLT, taking over fromJohn
Casebefore me. A transfer of duties toPhil Longis now about complete. This
probably matters to almost no one, but I wanted to describe things a bit for
those interested.The immediate impetus for this decision was unhappiness over
reviewing decisions atCOLT 2009, one as an author and several as a member of
the program committee. I seem to have disagreements fairly often about what is
important work, partly because I'm focused on learning theory with practical
implications, partly because I define learning theory more broadly than is
typical amongst COLT members, and partly because COLT suffers a bit from
insider-clique issues. The degree to which these issues come up varies
substantially each year so last year is not predictive of this one. And, it's
important to understand that COLT remains healthy with these issues not nearly
so bad asthey were. Never</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 For about 5 years, I've been the treasurer of the Association for Computational Learning, otherwise known as COLT, taking over fromJohn Casebefore me. [sent-1, score-0.315]
</p><p>2 A transfer of duties toPhil Longis now about complete. [sent-2, score-0.245]
</p><p>3 The immediate impetus for this decision was unhappiness over reviewing decisions atCOLT 2009, one as an author and several as a member of the program committee. [sent-4, score-0.205]
</p><p>4 The degree to which these issues come up varies substantially each year so last year is not predictive of this one. [sent-6, score-0.247]
</p><p>5 Nevertheless, I would like to see them taken more actively into account than I've been able to persuade people so far. [sent-8, score-0.154]
</p><p>6 After thinking about it for a few days before acting, I decided to go ahead with the transfer for another reason: I've been suffering from multitask poisoning. [sent-9, score-0.24]
</p><p>7 Partly this isAda, but partly it's many other things, each of which takes a small bit of my time, in aggregate leaving me disappointing people, myself in particular. [sent-10, score-0.663]
</p><p>8 Despite the above, I found being treasurer not particularly difficult. [sent-14, score-0.315]
</p><p>9 The functions of the treasury part of ACL have beenSelf-insurance for the conference each year. [sent-15, score-0.213]
</p><p>10 Prior to the formation of ACL-the-nonprofit (whichBobwas instrumental in), COLT used to buy insurance against the possibility that some disaster would strike canceling the conference while leaving the local organizer on the hook for substantial expenses. [sent-16, score-0.817]
</p><p>11 When I came in, the treasury was a little bit low for this function, and when I left, somewhat too high. [sent-17, score-0.316]
</p><p>12 Local organizers typically have a local account from which they spend for expenses and collect registration fees. [sent-19, score-0.748]
</p><p>13 Without the ACL, dealing with net positive or negative local accounts from year to year was awkward. [sent-20, score-0.495]
</p><p>14 COLT is partly sponsored by several big CS-related companies including IBM, Microsoft, and Google. [sent-23, score-0.319]
</p><p>15 Providing a stable point of contact definitely helps ease this process. [sent-24, score-0.31]
</p><p>16 This also helps on the publishing side, whereOmnipressis the current publisher of proceedings. [sent-25, score-0.146]
</p><p>17 Somewhat to my surprise, the proper role of the treasurer was typically asking the local organizer to reduce registration fees rather than increase. [sent-27, score-0.91]
</p><p>18 The essential observation is that local organizers, because they operate out of a local account, tend to be a bit conservative in budget estimates. [sent-28, score-0.748]
</p><p>19 On the other hand, because ACL has an adequate interest bearing account, we should expect and desire to spend the interest in each typical year. [sent-29, score-0.296]
</p><p>20 After having been treasurer for a little while, I'm convinced that having a nonprofit to back a conference is a good idea easing many difficulties with relatively small effort. [sent-31, score-0.661]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('acl', 0.394), ('local', 0.321), ('treasurer', 0.315), ('colt', 0.259), ('partly', 0.249), ('account', 0.154), ('treasury', 0.14), ('duties', 0.14), ('stable', 0.122), ('organizer', 0.122), ('contact', 0.112), ('bit', 0.106), ('transfer', 0.105), ('leaving', 0.105), ('spend', 0.095), ('registration', 0.091), ('organizers', 0.087), ('year', 0.087), ('helps', 0.076), ('conference', 0.073), ('issues', 0.073), ('small', 0.072), ('impetus', 0.07), ('publisher', 0.07), ('sponsor', 0.07), ('suffering', 0.07), ('phil', 0.07), ('easing', 0.07), ('unhappiness', 0.07), ('disaster', 0.07), ('nonprofit', 0.07), ('disappointing', 0.07), ('bearing', 0.07), ('sponsored', 0.07), ('somewhat', 0.07), ('typical', 0.07), ('effect', 0.068), ('association', 0.065), ('ahead', 0.065), ('formation', 0.065), ('member', 0.065), ('acting', 0.065), ('desire', 0.061), ('convinced', 0.061), ('ready', 0.061), ('strike', 0.061), ('disagreements', 0.061), ('posting', 0.061), ('fees', 0.061), ('aggregate', 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="394-tfidf-1" href="../hunch_net-2010/hunch_net-2010-04-24-COLT_Treasurer_is_now_Phil_Long.html">394 hunch net-2010-04-24-COLT Treasurer is now Phil Long</a></p>
<p>Introduction: For about 5 years, I've been the treasurer of the Association for
Computational Learning, otherwise known as COLT, taking over fromJohn
Casebefore me. A transfer of duties toPhil Longis now about complete. This
probably matters to almost no one, but I wanted to describe things a bit for
those interested.The immediate impetus for this decision was unhappiness over
reviewing decisions atCOLT 2009, one as an author and several as a member of
the program committee. I seem to have disagreements fairly often about what is
important work, partly because I'm focused on learning theory with practical
implications, partly because I define learning theory more broadly than is
typical amongst COLT members, and partly because COLT suffers a bit from
insider-clique issues. The degree to which these issues come up varies
substantially each year so last year is not predictive of this one. And, it's
important to understand that COLT remains healthy with these issues not nearly
so bad asthey were. Never</p><p>2 0.22288123 <a title="394-tfidf-2" href="../hunch_net-2013/hunch_net-2013-05-04-COLT_and_ICML_registration.html">482 hunch net-2013-05-04-COLT and ICML registration</a></p>
<p>Introduction: Sebastien Bubeckpoints outCOLTregistrationwith a May 13 early registration
deadline. The local organizers have done an admirable job of containing costs
with a $300 registration fee.ICMLregistrationis also available, at about an x3
higher cost. My understanding is that this is partly due to the costs of a
larger conference being harder to contain, partly due to ICML lasting twice as
long with tutorials and workshops, and partly because the conference
organizers were a bit over-conservative in various ways.</p><p>3 0.17369626 <a title="394-tfidf-3" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>Introduction: ByShieandNatiFollowing John's advertisement for submitting to ICML, we thought
it appropriate to highlight the advantages of COLT, and the reasons it is
often the best place for theory papers. We would like to emphasize that we
both respect ICML, and are active in ICML, both as authors and as area chairs,
and certainly are not arguing that ICML is a bad place for your papers. For
many papers, ICML is the best venue. But for many theory papers, COLT is a
better and more appropriate place.Why should you submit to COLT?By-and-large,
theory papers go to COLT. This is the tradition of the field and most theory
papers are sent to COLT. This is the place to present your ground-breaking
theorems and new models that will shape the theory of machine learning. COLT
is more focused then ICML with a single track session. Unlike ICML, the norm
in COLT is for people to sit through most sessions, and hear most of the talks
presented. There is also often a lively discussion following paper
presentation</p><p>4 0.17263666 <a title="394-tfidf-4" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>Introduction: The health ofCOLT(Conference on Learning Theory or Computational Learning
Theory depending on who you ask) has been questioned over the last few years.
Low points for the conference occurred whenEuroCOLTmerged with COLT in 2001,
and the attendance at the 2002 Sydney COLT fell to a new low. This occurred in
the general context of machine learning conferences rising in both number and
size over the last decade.Any discussion ofwhyCOLT has had difficulties is
inherently controversial as is any story about well-intentioned people making
the wrong decisions. Nevertheless, this may be worth discussing in the hope of
avoiding problems in the future and general understanding. In any such
discussion there is a strong tendency to identify with a conference/community
in a patriotic manner that is detrimental to thinking. Keep in mind that
conferences exist to further research.My understanding (I wasn't around) is
that COLT started as a subcommunity of the computer science theory community.
This i</p><p>5 0.13006207 <a title="394-tfidf-5" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>Introduction: Unfortunately, I ended up sick for much of this ICML. I did manage to catch
one interesting paper:Richard Socher,Cliff Lin,Andrew Y. Ng, andChristopher D.
ManningParsing Natural Scenes and Natural Language with Recursive Neural
Networks.I invited Richard to share his list of interesting papers, so
hopefully we'll hear from him soon. In the meantime,PaulandHalhave posted some
lists.the futureJoelleand I are program chairs for ICML 2012 inEdinburgh,
which I previously enjoyed visiting in2005. This is a huge responsibility,
that we hope to accomplish well. A part of this (perhaps the most fun part),
is imagining how we can make ICML better. A key and critical constraint is
choosing things that can be accomplished. So far we have:Colocation. The first
thing we looked into was potential colocations. We quickly discovered that
many other conferences precomitted their location. For the future, getting a
colocation withACLorSIGIR, seems to require more advanced planning. If that
can be done, I</p><p>6 0.11209431 <a title="394-tfidf-6" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>7 0.11007483 <a title="394-tfidf-7" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>8 0.1097464 <a title="394-tfidf-8" href="../hunch_net-2005/hunch_net-2005-06-29-Not_EM_for_clustering_at_COLT.html">87 hunch net-2005-06-29-Not EM for clustering at COLT</a></p>
<p>9 0.1049979 <a title="394-tfidf-9" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>10 0.097248174 <a title="394-tfidf-10" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>11 0.09494172 <a title="394-tfidf-11" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>12 0.090023145 <a title="394-tfidf-12" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>13 0.089145757 <a title="394-tfidf-13" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>14 0.085906312 <a title="394-tfidf-14" href="../hunch_net-2009/hunch_net-2009-10-10-ALT_2009.html">374 hunch net-2009-10-10-ALT 2009</a></p>
<p>15 0.085788541 <a title="394-tfidf-15" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>16 0.0814486 <a title="394-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>17 0.081169382 <a title="394-tfidf-17" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>18 0.080434024 <a title="394-tfidf-18" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>19 0.077359609 <a title="394-tfidf-19" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>20 0.076332949 <a title="394-tfidf-20" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.183), (1, 0.116), (2, 0.016), (3, 0.047), (4, 0.047), (5, -0.01), (6, -0.022), (7, 0.023), (8, 0.005), (9, 0.018), (10, -0.09), (11, -0.111), (12, 0.027), (13, 0.045), (14, 0.029), (15, 0.093), (16, 0.138), (17, 0.107), (18, 0.004), (19, 0.078), (20, -0.066), (21, -0.037), (22, 0.053), (23, -0.076), (24, 0.128), (25, 0.135), (26, 0.011), (27, -0.044), (28, 0.076), (29, 0.049), (30, -0.109), (31, 0.025), (32, 0.023), (33, -0.001), (34, 0.121), (35, 0.029), (36, 0.017), (37, -0.029), (38, -0.053), (39, 0.038), (40, 0.036), (41, 0.022), (42, 0.055), (43, 0.02), (44, 0.07), (45, 0.063), (46, 0.085), (47, 0.026), (48, 0.044), (49, 0.021)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97678262 <a title="394-lsi-1" href="../hunch_net-2010/hunch_net-2010-04-24-COLT_Treasurer_is_now_Phil_Long.html">394 hunch net-2010-04-24-COLT Treasurer is now Phil Long</a></p>
<p>Introduction: For about 5 years, I've been the treasurer of the Association for
Computational Learning, otherwise known as COLT, taking over fromJohn
Casebefore me. A transfer of duties toPhil Longis now about complete. This
probably matters to almost no one, but I wanted to describe things a bit for
those interested.The immediate impetus for this decision was unhappiness over
reviewing decisions atCOLT 2009, one as an author and several as a member of
the program committee. I seem to have disagreements fairly often about what is
important work, partly because I'm focused on learning theory with practical
implications, partly because I define learning theory more broadly than is
typical amongst COLT members, and partly because COLT suffers a bit from
insider-clique issues. The degree to which these issues come up varies
substantially each year so last year is not predictive of this one. And, it's
important to understand that COLT remains healthy with these issues not nearly
so bad asthey were. Never</p><p>2 0.79135215 <a title="394-lsi-2" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>Introduction: Registration for COLT 2007 is now open.The conference will take place on 13-15
June, 2007, in San Diego, California, as part of the 2007 Federated Computing
Research Conference (FCRC), which includes STOC, Complexity, and EC.The
website for COLT: http://www.learningtheory.org/colt2007/index.htmlThe early
registration deadline is May 11, and the cutoff date for discounted hotel
rates is May 9.Before registering, take note that the fees are substantially
lower for members of ACM and/or SIGACT than for nonmembers. If you've been
contemplating joining either of these two societies (annual dues: $99 for ACM,
$18 for SIGACT), now would be a good time!</p><p>3 0.69474 <a title="394-lsi-3" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>Introduction: The health ofCOLT(Conference on Learning Theory or Computational Learning
Theory depending on who you ask) has been questioned over the last few years.
Low points for the conference occurred whenEuroCOLTmerged with COLT in 2001,
and the attendance at the 2002 Sydney COLT fell to a new low. This occurred in
the general context of machine learning conferences rising in both number and
size over the last decade.Any discussion ofwhyCOLT has had difficulties is
inherently controversial as is any story about well-intentioned people making
the wrong decisions. Nevertheless, this may be worth discussing in the hope of
avoiding problems in the future and general understanding. In any such
discussion there is a strong tendency to identify with a conference/community
in a patriotic manner that is detrimental to thinking. Keep in mind that
conferences exist to further research.My understanding (I wasn't around) is
that COLT started as a subcommunity of the computer science theory community.
This i</p><p>4 0.67430615 <a title="394-lsi-4" href="../hunch_net-2013/hunch_net-2013-05-04-COLT_and_ICML_registration.html">482 hunch net-2013-05-04-COLT and ICML registration</a></p>
<p>Introduction: Sebastien Bubeckpoints outCOLTregistrationwith a May 13 early registration
deadline. The local organizers have done an admirable job of containing costs
with a $300 registration fee.ICMLregistrationis also available, at about an x3
higher cost. My understanding is that this is partly due to the costs of a
larger conference being harder to contain, partly due to ICML lasting twice as
long with tutorials and workshops, and partly because the conference
organizers were a bit over-conservative in various ways.</p><p>5 0.6397329 <a title="394-lsi-5" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">324 hunch net-2008-11-09-A Healthy  COLT</a></p>
<p>Introduction: Awhile ago, we discussed the health ofCOLT.COLT 2008substantially addressed my
concerns. The papers were diverse and several were interesting. Attendance was
up, which is particularly notable in Europe. In my opinion, the colocation
with UAI and ICML was the best colocation since 1998.And, perhaps best of all,
registration ended up being free for all students due to various grants from
theAcademy of Finland,Google,IBM, andYahoo.A basic question is: what went
right? There seem to be several answers.Cost-wise, COLT had sufficient grants
to alleviate the high cost of the Euro and location at a university
substantially reduces the cost compared to a hotel.Organization-wise, the
Finns were great with hordes of volunteers helping set everything up. Having
too many volunteers is a good failure mode.Organization-wise, it was clear
that all 3 program chairs were cooperating in designing the program
.Facilities-wise, proximity in time and space made the colocation much more
real than many others</p><p>6 0.60781115 <a title="394-lsi-6" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>7 0.52532315 <a title="394-lsi-7" href="../hunch_net-2010/hunch_net-2010-10-29-To_Vidoelecture_or_not.html">416 hunch net-2010-10-29-To Vidoelecture or not</a></p>
<p>8 0.50805032 <a title="394-lsi-8" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>9 0.49382761 <a title="394-lsi-9" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>10 0.49313501 <a title="394-lsi-10" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>11 0.47331315 <a title="394-lsi-11" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>12 0.45280886 <a title="394-lsi-12" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>13 0.43199712 <a title="394-lsi-13" href="../hunch_net-2005/hunch_net-2005-06-29-Not_EM_for_clustering_at_COLT.html">87 hunch net-2005-06-29-Not EM for clustering at COLT</a></p>
<p>14 0.43135473 <a title="394-lsi-14" href="../hunch_net-2005/hunch_net-2005-07-01-The_Role_of_Impromptu_Talks.html">88 hunch net-2005-07-01-The Role of Impromptu Talks</a></p>
<p>15 0.42599338 <a title="394-lsi-15" href="../hunch_net-2006/hunch_net-2006-01-06-MLTV.html">146 hunch net-2006-01-06-MLTV</a></p>
<p>16 0.42551649 <a title="394-lsi-16" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>17 0.42457023 <a title="394-lsi-17" href="../hunch_net-2005/hunch_net-2005-02-10-Conferences%2C_Dates%2C_Locations.html">17 hunch net-2005-02-10-Conferences, Dates, Locations</a></p>
<p>18 0.41025621 <a title="394-lsi-18" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>19 0.40492171 <a title="394-lsi-19" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>20 0.40004906 <a title="394-lsi-20" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.018), (6, 0.015), (35, 0.034), (39, 0.034), (42, 0.212), (45, 0.024), (49, 0.263), (68, 0.044), (69, 0.032), (74, 0.181), (95, 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.8835994 <a title="394-lda-1" href="../hunch_net-2010/hunch_net-2010-04-24-COLT_Treasurer_is_now_Phil_Long.html">394 hunch net-2010-04-24-COLT Treasurer is now Phil Long</a></p>
<p>Introduction: For about 5 years, I've been the treasurer of the Association for
Computational Learning, otherwise known as COLT, taking over fromJohn
Casebefore me. A transfer of duties toPhil Longis now about complete. This
probably matters to almost no one, but I wanted to describe things a bit for
those interested.The immediate impetus for this decision was unhappiness over
reviewing decisions atCOLT 2009, one as an author and several as a member of
the program committee. I seem to have disagreements fairly often about what is
important work, partly because I'm focused on learning theory with practical
implications, partly because I define learning theory more broadly than is
typical amongst COLT members, and partly because COLT suffers a bit from
insider-clique issues. The degree to which these issues come up varies
substantially each year so last year is not predictive of this one. And, it's
important to understand that COLT remains healthy with these issues not nearly
so bad asthey were. Never</p><p>2 0.72964299 <a title="394-lda-2" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>Introduction: Unfortunately, I ended up sick for much of this ICML. I did manage to catch
one interesting paper:Richard Socher,Cliff Lin,Andrew Y. Ng, andChristopher D.
ManningParsing Natural Scenes and Natural Language with Recursive Neural
Networks.I invited Richard to share his list of interesting papers, so
hopefully we'll hear from him soon. In the meantime,PaulandHalhave posted some
lists.the futureJoelleand I are program chairs for ICML 2012 inEdinburgh,
which I previously enjoyed visiting in2005. This is a huge responsibility,
that we hope to accomplish well. A part of this (perhaps the most fun part),
is imagining how we can make ICML better. A key and critical constraint is
choosing things that can be accomplished. So far we have:Colocation. The first
thing we looked into was potential colocations. We quickly discovered that
many other conferences precomitted their location. For the future, getting a
colocation withACLorSIGIR, seems to require more advanced planning. If that
can be done, I</p><p>3 0.72427458 <a title="394-lda-3" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>Introduction: One of the confusing things about research is that progress is very hard to
measure. One of the consequences of being in a hard-to-measure environment is
that the wrong things are often measured.Lines of CodeThe classical example of
this phenomenon is the old lines-of-code-produced metric for programming. It
is easy to imagine systems for producing many lines of code with very little
work that accomplish very little.Paper countIn academia, a "paper count" is an
analog of "lines of code", and it suffers from the same failure modes. The
obvious failure mode here is that we end up with a large number of
uninteresting papers since people end up spending a lot of time optimizing
this metric.ComplexityAnother metric, is "complexity" (in the eye of a
reviewer) of a paper. There is a common temptation to make a method appear
more complex than it is in order for reviewers to judge it worthy of
publication. The failure mode here is unclean thinking. Simple effective
methods are often overlooked</p><p>4 0.72025073 <a title="394-lda-4" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>Introduction: In the quest to understand what good reviewing is, perhaps it's worthwhile to
think about what good research is. One way to think about good research is in
terms of a producer/consumer model.In the producer/consumer model of research,
for any element of research there are producers (authors and coauthors of
papers, for example) and consumers (people who use the papers to make new
papers or code solving problems). An produced bit of research is judged as
"good" if it is used by many consumers. There are two basic questions which
immediately arise:Is this a good model of research?Are there alternatives?The
producer/consumer model has some difficulties which can be (partially)
addressed.Disconnect.A group of people doing research on some subject may
become disconnected from the rest of the world. Each person uses the research
of other people in the group so it appears good research is being done, but
the group has no impact on the rest of the world. One way to detect this is by
looking at</p><p>5 0.71809632 <a title="394-lda-5" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>Introduction: Essentially everyone who writes research papers suffers rejections. They
always sting immediately, but upon further reflection many of these rejections
come to seem reasonable. Maybe the equations had too many typos or maybe the
topic just isn't as important as was originally thought. A few rejections do
not come to seem acceptable, and these form the basis of reviewing horror
stories, a great material for conversations. I've decided to share three of
mine, now all safely a bit distant in the past.Prediction Theory for
Classification Tutorial. This is a tutorial about tight sample complexity
bounds for classification that I submitted toJMLR. The first decision I heard
was a reject which appeared quite unjust to me--for example one of the
reviewers appeared to claim that all the content was in standard statistics
books. Upon further inquiry, several citations were given, none of which
actually covered the content. Later, I was shocked to hear the paper was
accepted. Apparently, the pape</p><p>6 0.71722889 <a title="394-lda-6" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>7 0.71674293 <a title="394-lda-7" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>8 0.71640235 <a title="394-lda-8" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>9 0.71628278 <a title="394-lda-9" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>10 0.71190661 <a title="394-lda-10" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>11 0.71182013 <a title="394-lda-11" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>12 0.71026295 <a title="394-lda-12" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>13 0.70911676 <a title="394-lda-13" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>14 0.70715249 <a title="394-lda-14" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>15 0.70714808 <a title="394-lda-15" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>16 0.70520622 <a title="394-lda-16" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<p>17 0.70291924 <a title="394-lda-17" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>18 0.70265925 <a title="394-lda-18" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>19 0.70239139 <a title="394-lda-19" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>20 0.69986957 <a title="394-lda-20" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
