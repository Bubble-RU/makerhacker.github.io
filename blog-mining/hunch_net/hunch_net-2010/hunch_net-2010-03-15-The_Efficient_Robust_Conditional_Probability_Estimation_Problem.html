<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-391" href="#">hunch_net-2010-391</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-391-html" href="http://hunch.net/?p=1253">html</a></p><p>Introduction: I’m offering a reward of $1000 for a solution to this problem.  This joins the  cross validation problem  which I’m offering a  $500 reward  for.  I believe both of these problems are hard but plausibly solvable, and plausibly with a solution of substantial practical value.  While it’s unlikely these rewards are worth your time on an hourly wage basis, the recognition for solving them definitely should be   
  The Problem  
The problem is finding a general, robust, and efficient mechanism for estimating a conditional probability  P(y|x)  where robustness and efficiency are measured using techniques from learning reductions. 
 
In particular, suppose we have access to a binary regression oracle  B  which has two interfaces—one for specifying training information and one for testing. Training information is specified as  B(x’,y’)  where  x’  is a feature vector and  y’  is a scalar in  [0,1]  with no value returned.  Testing is done according to  B(x’)  with a value in  [0,1]  returned.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In particular, suppose we have access to a binary regression oracle  B  which has two interfaces—one for specifying training information and one for testing. [sent-5, score-0.803]
</p><p>2 A learning reduction consists of two algorithms  R  and  R -1   which transform examples from the original input problem into examples for the oracle and then transform the oracle’s predictions into a prediction for the original problem. [sent-8, score-1.377]
</p><p>3 R  then specifies a training example  (x’,y’)  for the oracle  B . [sent-10, score-0.646]
</p><p>4 A basic observation is that for any oracle algorithm, a distribution  D(x,y)  over multiclass examples and a reduction  R  induces a distribution over a sequence  (x’,y’) *   of oracle examples. [sent-13, score-1.664]
</p><p>5 We collapse this into a distribution  D’(x’,y’)  over oracle examples by drawing uniformly from the sequence. [sent-14, score-0.834]
</p><p>6 We measure the power of an oracle and a reduction according to squared-loss regret. [sent-16, score-0.719]
</p><p>7 Alternatively, this open problem is satisfied by proving there exists no deterministic algorithms  R,R -1   satisfying the above theorem statement. [sent-19, score-0.452]
</p><p>8 Typically conditional probability estimation is done in situations where the conditional probability of only one bit is required, however there are a growing number of applications where a well-estimated conditional probability over a more complex object is required. [sent-22, score-0.796]
</p><p>9 The motivation for using the learning reduction framework to specify this problem is a combination of generality and the empirical effectiveness in application of learning reductions. [sent-27, score-0.494]
</p><p>10 Any solution to this will be general because any oracle  B  can be plugged in, even ones which use many strange kinds of prior information, features, and active multitask hierachical (insert your favorite adjective here) structure. [sent-28, score-0.626]
</p><p>11 For multiclass classification in a partial label setting,  no learning reduction can provide a constant regret guarantee . [sent-34, score-0.464]
</p><p>12 On the other hand, because  R  calls the oracle at least once, there is a defined induced distribution  D’ . [sent-39, score-0.64]
</p><p>13 Since the theorem must hold for all  D  and  B , it must hold for a  D  your specified learning algorithm fails on and for a  B  for which reg (D’,B)=0  implying the theorem is not satisfied. [sent-40, score-0.879]
</p><p>14 Feed random examples into  B  and vacuously satisfy the theorem by making sure that the right hand side is larger than a constant. [sent-41, score-0.619]
</p><p>15 In particular, if the oracle is given examples of the form  (x’,y’)  where  y’  is uniformly at random either  0  or  1 , any oracle specifying  B(x’)=0. [sent-43, score-1.44]
</p><p>16 Feed pseudorandom examples into  B  and vacuously satisfy the theorem by making sure that the right hand side is larger than a constant. [sent-45, score-0.663]
</p><p>17 This doesn’t work, because the quantification is “for all binary oracles  B ”, and there exists one which, knowing the pseudorandom seed, can achieve zero loss (and hence zero regret). [sent-46, score-0.72]
</p><p>18 The oracle here is not limited in this fashion since it could completely err for a small fraction of invocations. [sent-49, score-0.561]
</p><p>19 Employing this approach is not straightforward, because the average in  D’  is over an increased number of oracle examples. [sent-51, score-0.658]
</p><p>20 Hence, at a fixed expected (over oracle examples) regret, the number of examples allowed to have a large regret is increased. [sent-52, score-0.821]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('oracle', 0.561), ('reg', 0.234), ('theorem', 0.18), ('reduction', 0.158), ('regret', 0.138), ('conditional', 0.132), ('examples', 0.122), ('zero', 0.121), ('hence', 0.113), ('pseudorandom', 0.106), ('vacuously', 0.106), ('multiclass', 0.104), ('probability', 0.101), ('specified', 0.1), ('satisfying', 0.1), ('increased', 0.097), ('estimation', 0.097), ('binary', 0.095), ('problem', 0.093), ('motivation', 0.091), ('feed', 0.087), ('offering', 0.087), ('log', 0.086), ('training', 0.085), ('specify', 0.083), ('quantification', 0.082), ('oracles', 0.082), ('open', 0.079), ('distribution', 0.079), ('satisfy', 0.075), ('hand', 0.074), ('input', 0.073), ('uniformly', 0.072), ('tricks', 0.072), ('using', 0.069), ('transform', 0.068), ('correcting', 0.066), ('structure', 0.065), ('favorite', 0.065), ('robustness', 0.065), ('provide', 0.064), ('algorithm', 0.063), ('random', 0.062), ('specifying', 0.062), ('hold', 0.061), ('reward', 0.058), ('testing', 0.058), ('original', 0.056), ('doesn', 0.056), ('boosting', 0.055)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999958 <a title="391-tfidf-1" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>Introduction: I’m offering a reward of $1000 for a solution to this problem.  This joins the  cross validation problem  which I’m offering a  $500 reward  for.  I believe both of these problems are hard but plausibly solvable, and plausibly with a solution of substantial practical value.  While it’s unlikely these rewards are worth your time on an hourly wage basis, the recognition for solving them definitely should be   
  The Problem  
The problem is finding a general, robust, and efficient mechanism for estimating a conditional probability  P(y|x)  where robustness and efficiency are measured using techniques from learning reductions. 
 
In particular, suppose we have access to a binary regression oracle  B  which has two interfaces—one for specifying training information and one for testing. Training information is specified as  B(x’,y’)  where  x’  is a feature vector and  y’  is a scalar in  [0,1]  with no value returned.  Testing is done according to  B(x’)  with a value in  [0,1]  returned.</p><p>2 0.26508594 <a title="391-tfidf-2" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>Introduction: One thing which is clear on a little reflection is that there exists a single master learning problem capable of encoding essentially all learning problems.  This problem is of course a very general sort of reinforcement learning where the world interacts with an agent as:
  
 The world announces an observation  x . 
 The agent makes a choice  a . 
 The world announces a reward  r . 
  
The goal here is to maximize the sum of the rewards over the time of the agent.  No particular structure relating  x  to  a  or  a  to  r  is implied by this setting so we do not know effective general algorithms for the agent.  It’s very easy to prove lower bounds showing that an agent cannot hope to succeed here—just consider the case where actions are unrelated to rewards.  Nevertheless, there is a real sense in which essentially all forms of life are agents operating in this setting, somehow succeeding.  The gap between these observations drives research—How can we find tractable specializations of</p><p>3 0.25128528 <a title="391-tfidf-3" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>Introduction: This  problem  has been cracked (but not quite completely solved) by  Alina ,  Pradeep , and  I .  The problem is essentially finding a better way to reduce multiclass classification to binary classification.  The solution is to use a carefully crafted tournament,  the simplest version of which is a  single elimination tournament  where the “players” are the different classes.  An example of the structure is here: 
    
For the single elimination tournament, we can prove that: 
 For all multiclass problems  D , for all learned binary classifiers  c , the regret of an induced multiclass classifier is bounded by the regret of the binary classifier times  log 2  k .  Restated:  
  reg multiclass (D,Filter_tree_test(c)) <= reg binary  (Filter_tree_train(D),c)    
Here:
  
   Filter_tree_train(D)  is the induced binary classification problem 
   Filter_tree_test(c)  is the induced multiclass classifier. 
   reg multiclass   is the multiclass regret (= difference between error rate and minim</p><p>4 0.24037376 <a title="391-tfidf-4" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>Introduction: This post is about an open problem in learning reductions.
 
 Background  A reduction might transform a a multiclass prediction problem where there are  k  possible labels into a binary learning problem where there are only 2 possible labels.   On this induced binary problem we might learn a binary classifier with some error rate  e .  After subtracting the minimum possible (Bayes) error rate  b , we get a regret  r = e – b .  The  PECOC (Probabilistic Error Correcting Output Code) reduction has the property that binary regret  r  implies multiclass regret at most  4r 0.5  .
 
 The problem  This is not the “rightest” answer.  Consider the  k=2  case, where we reduce binary to binary.  There exists a reduction (the identity) with the property that regret  r  implies regret  r .  This is substantially superior to the transform given by the PECOC reduction, which suggests that a better reduction may exist for general  k .  For example, we can not rule out the possibility that a reduction</p><p>5 0.20180236 <a title="391-tfidf-5" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a data source (Example:  X x {0,1} ,  X x [0,1] ,  X x {1,2,3,4,5} , etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…).  For simplicity, we’ll assume that all losses have a minimum of zero.
 
For this post, we can think of a learning reduction as
  
 A mapping  R  from samples of one type  T  (like multiclass classification) to another type  T’  (like binary classification). 
 A mapping  Q  from predictors for type  T’  to predictors for type  T . 
  
The simplest sort of learning reduction is a “loss reduction”.  The idea in a loss reduction is to prove a statement of the form: 
 Theorem  For all base predictors  b , for all distributions  D  over examples of type  T : 
  E (x,y) ~ D  L T (y,Q(b,x)) <= f(E (x’,y’)~R(D)  L T’ (y’,b(x’)))   
Here  L T   is the loss for the type  T  problem and  L T’   is the loss for the type  T’  problem.  Also,  R(D)  is the distribution ov</p><p>6 0.17966212 <a title="391-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>7 0.17659192 <a title="391-tfidf-7" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>8 0.17237541 <a title="391-tfidf-8" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>9 0.14277193 <a title="391-tfidf-9" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>10 0.13955849 <a title="391-tfidf-10" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>11 0.13653855 <a title="391-tfidf-11" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>12 0.13466936 <a title="391-tfidf-12" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>13 0.12904753 <a title="391-tfidf-13" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>14 0.12585507 <a title="391-tfidf-14" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>15 0.12445451 <a title="391-tfidf-15" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>16 0.12198175 <a title="391-tfidf-16" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>17 0.12189317 <a title="391-tfidf-17" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>18 0.11733039 <a title="391-tfidf-18" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>19 0.1164578 <a title="391-tfidf-19" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>20 0.11614706 <a title="391-tfidf-20" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.265), (1, 0.217), (2, 0.096), (3, -0.102), (4, -0.028), (5, -0.053), (6, 0.175), (7, -0.043), (8, -0.101), (9, 0.026), (10, -0.035), (11, -0.053), (12, -0.002), (13, 0.021), (14, -0.051), (15, 0.045), (16, -0.006), (17, -0.034), (18, 0.066), (19, 0.025), (20, -0.106), (21, -0.026), (22, 0.148), (23, -0.029), (24, -0.014), (25, 0.011), (26, -0.048), (27, -0.017), (28, 0.029), (29, -0.031), (30, -0.013), (31, -0.013), (32, -0.003), (33, 0.028), (34, 0.037), (35, -0.071), (36, -0.07), (37, 0.057), (38, -0.009), (39, 0.026), (40, 0.013), (41, 0.015), (42, 0.007), (43, 0.012), (44, -0.032), (45, -0.074), (46, 0.005), (47, 0.048), (48, -0.009), (49, -0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95849723 <a title="391-lsi-1" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>Introduction: I’m offering a reward of $1000 for a solution to this problem.  This joins the  cross validation problem  which I’m offering a  $500 reward  for.  I believe both of these problems are hard but plausibly solvable, and plausibly with a solution of substantial practical value.  While it’s unlikely these rewards are worth your time on an hourly wage basis, the recognition for solving them definitely should be   
  The Problem  
The problem is finding a general, robust, and efficient mechanism for estimating a conditional probability  P(y|x)  where robustness and efficiency are measured using techniques from learning reductions. 
 
In particular, suppose we have access to a binary regression oracle  B  which has two interfaces—one for specifying training information and one for testing. Training information is specified as  B(x’,y’)  where  x’  is a feature vector and  y’  is a scalar in  [0,1]  with no value returned.  Testing is done according to  B(x’)  with a value in  [0,1]  returned.</p><p>2 0.77325988 <a title="391-lsi-2" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>Introduction: This post is about an open problem in learning reductions.
 
 Background  A reduction might transform a a multiclass prediction problem where there are  k  possible labels into a binary learning problem where there are only 2 possible labels.   On this induced binary problem we might learn a binary classifier with some error rate  e .  After subtracting the minimum possible (Bayes) error rate  b , we get a regret  r = e – b .  The  PECOC (Probabilistic Error Correcting Output Code) reduction has the property that binary regret  r  implies multiclass regret at most  4r 0.5  .
 
 The problem  This is not the “rightest” answer.  Consider the  k=2  case, where we reduce binary to binary.  There exists a reduction (the identity) with the property that regret  r  implies regret  r .  This is substantially superior to the transform given by the PECOC reduction, which suggests that a better reduction may exist for general  k .  For example, we can not rule out the possibility that a reduction</p><p>3 0.76189107 <a title="391-lsi-3" href="../hunch_net-2006/hunch_net-2006-09-09-How_to_solve_an_NP_hard_problem_in_quadratic_time.html">206 hunch net-2006-09-09-How to solve an NP hard problem in quadratic time</a></p>
<p>Introduction: This title is a lie, but it is a special lie which has a bit of truth.
 
If  n  players each play each other, you have a tournament.   How do you order the players from weakest to strongest?
 
The standard first attempt is “find the ordering which agrees with the tournament on as many player pairs as possible”.  This is called the “minimum feedback arcset” problem in the CS theory literature and it is a well known NP-hard problem.  A basic guarantee holds for the solution to this problem: if there is some “true” intrinsic ordering, and the outcome of the tournament disagrees  k  times (due to noise for instance), then the output ordering will disagree with the original ordering on at most  2k  edges (and no solution can be better).
 
One standard approach to tractably solving an NP-hard problem is to find another algorithm with an approximation guarantee.  For example,  Don Coppersmith ,  Lisa Fleischer  and  Atri Rudra  proved that  ordering players according to the number of wins is</p><p>4 0.76080525 <a title="391-lsi-4" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>Introduction: This  problem  has been cracked (but not quite completely solved) by  Alina ,  Pradeep , and  I .  The problem is essentially finding a better way to reduce multiclass classification to binary classification.  The solution is to use a carefully crafted tournament,  the simplest version of which is a  single elimination tournament  where the “players” are the different classes.  An example of the structure is here: 
    
For the single elimination tournament, we can prove that: 
 For all multiclass problems  D , for all learned binary classifiers  c , the regret of an induced multiclass classifier is bounded by the regret of the binary classifier times  log 2  k .  Restated:  
  reg multiclass (D,Filter_tree_test(c)) <= reg binary  (Filter_tree_train(D),c)    
Here:
  
   Filter_tree_train(D)  is the induced binary classification problem 
   Filter_tree_test(c)  is the induced multiclass classifier. 
   reg multiclass   is the multiclass regret (= difference between error rate and minim</p><p>5 0.73938894 <a title="391-lsi-5" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?  Reductions are machines which turn solvers for one problem into solvers for another problem. 
 Why?  Reductions are useful for several reasons.
  
  Laziness .  Reducing a problem to classification make at least 10 learning algorithms available to solve a problem.  Inventing 10 learning algorithms is quite a bit of work.  Similarly, programming a reduction is often trivial, while programming a learning algorithm is a great deal of work. 
  Crystallization .  The problems we often want to solve in learning are worst-case-impossible, but average case feasible.  By reducing all problems onto one or a few primitives, we can fine tune these primitives to perform well on real-world problems with greater precision due to the greater number of problems to validate on. 
  Theoretical Organization .  By studying what reductions are easy vs. hard vs. impossible, we can learn which problems are roughly equivalent in difficulty and which are much harder. 
  
 What we know now .
 
 Typesafe r</p><p>6 0.68872803 <a title="391-lsi-6" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>7 0.6591984 <a title="391-lsi-7" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>8 0.63971061 <a title="391-lsi-8" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>9 0.63135165 <a title="391-lsi-9" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>10 0.62738854 <a title="391-lsi-10" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>11 0.60401434 <a title="391-lsi-11" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>12 0.58691144 <a title="391-lsi-12" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>13 0.58510762 <a title="391-lsi-13" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>14 0.58506137 <a title="391-lsi-14" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>15 0.56112379 <a title="391-lsi-15" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>16 0.56004602 <a title="391-lsi-16" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>17 0.5512616 <a title="391-lsi-17" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>18 0.54016912 <a title="391-lsi-18" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>19 0.53440398 <a title="391-lsi-19" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>20 0.52999794 <a title="391-lsi-20" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.016), (3, 0.282), (10, 0.018), (27, 0.209), (38, 0.12), (48, 0.019), (53, 0.046), (55, 0.045), (64, 0.023), (77, 0.037), (94, 0.066), (95, 0.02)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96273232 <a title="391-lda-1" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>Introduction: This  problem  has been cracked (but not quite completely solved) by  Alina ,  Pradeep , and  I .  The problem is essentially finding a better way to reduce multiclass classification to binary classification.  The solution is to use a carefully crafted tournament,  the simplest version of which is a  single elimination tournament  where the “players” are the different classes.  An example of the structure is here: 
    
For the single elimination tournament, we can prove that: 
 For all multiclass problems  D , for all learned binary classifiers  c , the regret of an induced multiclass classifier is bounded by the regret of the binary classifier times  log 2  k .  Restated:  
  reg multiclass (D,Filter_tree_test(c)) <= reg binary  (Filter_tree_train(D),c)    
Here:
  
   Filter_tree_train(D)  is the induced binary classification problem 
   Filter_tree_test(c)  is the induced multiclass classifier. 
   reg multiclass   is the multiclass regret (= difference between error rate and minim</p><p>2 0.95188648 <a title="391-lda-2" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>Introduction: I want to expand on  this post  which describes one of the core tricks for making  Vowpal Wabbit  fast and easy to use when learning from text.  
 
The central trick is converting a word (or any other parseable quantity) into a number via a hash function.   Kishore  tells me this is a relatively old trick in NLP land, but it has some added advantages when doing online learning, because you can learn directly from the existing data without preprocessing the data to create features (destroying the online property) or using an expensive hashtable lookup (slowing things down).
 
A central concern for this approach is collisions, which create a loss of information.  If you use  m  features in an index space of size  n  the birthday paradox suggests a collision if  m > n 0.5  , essentially because there are  m 2   pairs.   This is pretty bad, because it says that with a vocabulary of  10 5   features, you might need to have  10 10   entries in your table.
 
It turns out that redundancy is gr</p><p>same-blog 3 0.93729359 <a title="391-lda-3" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>Introduction: I’m offering a reward of $1000 for a solution to this problem.  This joins the  cross validation problem  which I’m offering a  $500 reward  for.  I believe both of these problems are hard but plausibly solvable, and plausibly with a solution of substantial practical value.  While it’s unlikely these rewards are worth your time on an hourly wage basis, the recognition for solving them definitely should be   
  The Problem  
The problem is finding a general, robust, and efficient mechanism for estimating a conditional probability  P(y|x)  where robustness and efficiency are measured using techniques from learning reductions. 
 
In particular, suppose we have access to a binary regression oracle  B  which has two interfaces—one for specifying training information and one for testing. Training information is specified as  B(x’,y’)  where  x’  is a feature vector and  y’  is a scalar in  [0,1]  with no value returned.  Testing is done according to  B(x’)  with a value in  [0,1]  returned.</p><p>4 0.91401762 <a title="391-lda-4" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data sources  D , 
  Pr S ~ D (f(D) > g(S)) > 1-d   
where  f  is some function of the distribution (such as the mean) and  g  is some function of the observed sample  S .   The constraints on  D  can vary between “Independent and identically distributed (IID) samples from a gaussian with an unknown mean” to “IID samples from an arbitrary distribution  D “.  There are even some confidence intervals which do not require IID samples.
 
Classical confidence intervals often confuse people.  They do  not  say “with high probability, for my observed sample, the bounds holds”.   Instead, they tell you that if you reason according to the confidence interval in the future (and the constraints on  D  are satisfied), then you are not often wrong.  Restated, they tell you something about what a safe procedure is in a stochastic world where  d  is the safety parameter.
 
There are a number of results in theoretical machine learn</p><p>5 0.87783766 <a title="391-lda-5" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>Introduction: This, again, is something of a research direction rather than a single problem.
 
There are several metrics people care about which depend upon the relative ranking of examples and there are sometimes good reasons to care about such metrics.  Examples include  AROC , “F1″, the proportion of the time that the top ranked element is in some class, the proportion of the top 10 examples in some class ( google ‘s problem),  the lowest ranked example of some class, and the “sort distance” from a predicted ranking to a correct ranking.  See  here  for an example of some of these.  
 
 Problem  What does the ability to classify well imply about performance under these metrics?
 
 Past Work 
  
  Probabilistic classification under squared error  can be solved with a classifier.  A counterexample shows this does not imply a good AROC. 
 Sample complexity bounds for  AROC  (and  here ). 
 A paper on “ Learning to Order Things “. 
  
 Difficulty  Several of these may be easy.  Some of them may be h</p><p>6 0.85330433 <a title="391-lda-6" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>7 0.85301685 <a title="391-lda-7" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>8 0.79340386 <a title="391-lda-8" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>9 0.73700315 <a title="391-lda-9" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>10 0.73528314 <a title="391-lda-10" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>11 0.73320335 <a title="391-lda-11" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>12 0.73023987 <a title="391-lda-12" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>13 0.72457409 <a title="391-lda-13" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>14 0.72329783 <a title="391-lda-14" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>15 0.71627593 <a title="391-lda-15" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>16 0.69428247 <a title="391-lda-16" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>17 0.69372159 <a title="391-lda-17" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>18 0.69275367 <a title="391-lda-18" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>19 0.69214427 <a title="391-lda-19" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>20 0.68790948 <a title="391-lda-20" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
