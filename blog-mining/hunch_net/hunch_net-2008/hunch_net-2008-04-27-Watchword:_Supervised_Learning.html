<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>299 hunch net-2008-04-27-Watchword: Supervised Learning</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-299" href="#">hunch_net-2008-299</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>299 hunch net-2008-04-27-Watchword: Supervised Learning</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-299-html" href="http://hunch.net/?p=329">html</a></p><p>Introduction: I recently discovered that supervised learning is a controversial term. The
two definitions are:Known LossSupervised learning corresponds to the situation
where you have unlabeled examples plus knowledge of the loss of each possible
predicted choice. This is the definition I'm familiar and comfortable with.
One reason to prefer this definition is that the analysis of sample complexity
for this class of learning problems are all pretty similar.Any kind of
signalSupervised learning corresponds to the situation where you have
unlabeled examples plus any source of side information about what the right
choice is. This notion of supervised learning seems to subsume reinforcement
learning, which makes me uncomfortable, because it means there are two words
for the same class. This also means there isn't a convenient word to describe
the first definition.Reviews suggest there are people who are dedicated to the
second definition out there, so it can be important to discriminate which you
mean.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('corresponds', 0.326), ('plus', 0.313), ('definition', 0.301), ('unlabeled', 0.239), ('situation', 0.224), ('supervised', 0.199), ('discriminate', 0.195), ('dedicated', 0.195), ('convenient', 0.181), ('comfortable', 0.171), ('uncomfortable', 0.156), ('controversial', 0.156), ('discovered', 0.151), ('definitions', 0.142), ('means', 0.142), ('predicted', 0.132), ('examples', 0.12), ('describe', 0.119), ('recently', 0.119), ('word', 0.117)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="299-tfidf-1" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>Introduction: I recently discovered that supervised learning is a controversial term. The
two definitions are:Known LossSupervised learning corresponds to the situation
where you have unlabeled examples plus knowledge of the loss of each possible
predicted choice. This is the definition I'm familiar and comfortable with.
One reason to prefer this definition is that the analysis of sample complexity
for this class of learning problems are all pretty similar.Any kind of
signalSupervised learning corresponds to the situation where you have
unlabeled examples plus any source of side information about what the right
choice is. This notion of supervised learning seems to subsume reinforcement
learning, which makes me uncomfortable, because it means there are two words
for the same class. This also means there isn't a convenient word to describe
the first definition.Reviews suggest there are people who are dedicated to the
second definition out there, so it can be important to discriminate which you
mean.</p><p>2 0.13098703 <a title="299-tfidf-2" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>Introduction: One of the common trends in machine learning has been an emphasis on the use
of unlabeled data. The argument goes something like "there aren't many labeled
web pages out there, but there are ahugenumber of web pages, so we must find a
way to take advantage of them." There are several standard approaches for
doing this:Unsupervised Learning. You use only unlabeled data. In a typical
application, you cluster the data and hope that the clusters somehow
correspond to what you care about.Semisupervised Learning. You use both
unlabeled and labeled data to build a predictor. The unlabeled data influences
the learned predictor in some way.Active Learning. You have unlabeled data and
access to a labeling oracle. You interactively choose which examples to label
so as to optimize prediction accuracy.It seems there is a fourth approach
worth serious investigation--automated labeling. The approach goes as
follows:Identify some subset of observed values to predict from the
others.Build a predictor.U</p><p>3 0.10853694 <a title="299-tfidf-3" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.In selective sampling style
active learning, a learning algorithm chooses which examples to label. We now
have an active learning algorithm that is:Efficientin label complexity,
unlabeled complexity, and computational complexity.Competitivewith supervised
learning anywhere that supervised learning works.Compatiblewith online
learning, with any optimization-based learning algorithm, with any loss
function, with offline testing, and even with changing learning
algorithms.Empiricallyeffective.The basic idea is to combinedisagreement
region-based samplingwithimportance weighting: an example is selected to be
labeled with probability proportional to how useful it is for distinguishing
among near-optimal classifiers, and labeled examples are importance-weighted
by the inverse of these probabilities. The combination of these simple ideas
removes thesampling biasproblem that has plagued many previous heuristics for
active learning, and yet leads to</p><p>4 0.10379129 <a title="299-tfidf-4" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,Sanjoymade a postsaying roughly "we should study
active learning theoretically, because not much is understood".At the time, we
did not understand basic things such as whether or not it was possible to PAC-
learn with an active algorithm without making strong assumptions about the
noise rate. In other words, the fundamental question was "can we do it?"The
nature of the question has fundamentally changed in my mind. The answer is to
the previous question is "yes", both information theoretically and
computationally, most places where supervised learning could be applied.In
many situation, the question has now changed to: "is it worth it?" Is the
programming and computational overhead low enough to make the label cost
savings of active learning worthwhile? Currently, there are situations where
this question could go either way. Much of the challenge for the future is in
figuring out how to make active learning easier or more worthwhile.At
theactive learning tutor</p><p>5 0.10270891 <a title="299-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>6 0.098887652 <a title="299-tfidf-6" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>7 0.097008429 <a title="299-tfidf-7" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>8 0.096358649 <a title="299-tfidf-8" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>9 0.091644049 <a title="299-tfidf-9" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>10 0.088012077 <a title="299-tfidf-10" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>11 0.08724834 <a title="299-tfidf-11" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>12 0.081901856 <a title="299-tfidf-12" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>13 0.080864191 <a title="299-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>14 0.080793999 <a title="299-tfidf-14" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>15 0.0793726 <a title="299-tfidf-15" href="../hunch_net-2007/hunch_net-2007-12-19-Cool_and_interesting_things_seen_at_NIPS.html">279 hunch net-2007-12-19-Cool and interesting things seen at NIPS</a></p>
<p>16 0.076207899 <a title="299-tfidf-16" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>17 0.074934103 <a title="299-tfidf-17" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>18 0.074844576 <a title="299-tfidf-18" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>19 0.073916905 <a title="299-tfidf-19" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>20 0.073166266 <a title="299-tfidf-20" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.156), (1, -0.098), (2, -0.029), (3, 0.02), (4, -0.004), (5, 0.007), (6, -0.02), (7, -0.015), (8, -0.095), (9, -0.069), (10, -0.027), (11, 0.05), (12, 0.091), (13, 0.084), (14, 0.022), (15, -0.092), (16, 0.011), (17, 0.055), (18, -0.019), (19, -0.027), (20, -0.006), (21, 0.027), (22, 0.019), (23, -0.025), (24, 0.057), (25, -0.03), (26, -0.051), (27, -0.012), (28, -0.118), (29, 0.011), (30, -0.056), (31, -0.036), (32, -0.1), (33, -0.071), (34, -0.039), (35, -0.043), (36, -0.033), (37, -0.037), (38, -0.02), (39, 0.057), (40, 0.071), (41, -0.064), (42, 0.028), (43, -0.002), (44, 0.115), (45, 0.015), (46, -0.048), (47, -0.037), (48, -0.05), (49, 0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93051249 <a title="299-lsi-1" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>Introduction: I recently discovered that supervised learning is a controversial term. The
two definitions are:Known LossSupervised learning corresponds to the situation
where you have unlabeled examples plus knowledge of the loss of each possible
predicted choice. This is the definition I'm familiar and comfortable with.
One reason to prefer this definition is that the analysis of sample complexity
for this class of learning problems are all pretty similar.Any kind of
signalSupervised learning corresponds to the situation where you have
unlabeled examples plus any source of side information about what the right
choice is. This notion of supervised learning seems to subsume reinforcement
learning, which makes me uncomfortable, because it means there are two words
for the same class. This also means there isn't a convenient word to describe
the first definition.Reviews suggest there are people who are dedicated to the
second definition out there, so it can be important to discriminate which you
mean.</p><p>2 0.62317324 <a title="299-lsi-2" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>Introduction: One of the common trends in machine learning has been an emphasis on the use
of unlabeled data. The argument goes something like "there aren't many labeled
web pages out there, but there are ahugenumber of web pages, so we must find a
way to take advantage of them." There are several standard approaches for
doing this:Unsupervised Learning. You use only unlabeled data. In a typical
application, you cluster the data and hope that the clusters somehow
correspond to what you care about.Semisupervised Learning. You use both
unlabeled and labeled data to build a predictor. The unlabeled data influences
the learned predictor in some way.Active Learning. You have unlabeled data and
access to a labeling oracle. You interactively choose which examples to label
so as to optimize prediction accuracy.It seems there is a fourth approach
worth serious investigation--automated labeling. The approach goes as
follows:Identify some subset of observed values to predict from the
others.Build a predictor.U</p><p>3 0.599177 <a title="299-lsi-3" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,Sanjoymade a postsaying roughly "we should study
active learning theoretically, because not much is understood".At the time, we
did not understand basic things such as whether or not it was possible to PAC-
learn with an active algorithm without making strong assumptions about the
noise rate. In other words, the fundamental question was "can we do it?"The
nature of the question has fundamentally changed in my mind. The answer is to
the previous question is "yes", both information theoretically and
computationally, most places where supervised learning could be applied.In
many situation, the question has now changed to: "is it worth it?" Is the
programming and computational overhead low enough to make the label cost
savings of active learning worthwhile? Currently, there are situations where
this question could go either way. Much of the challenge for the future is in
figuring out how to make active learning easier or more worthwhile.At
theactive learning tutor</p><p>4 0.59166968 <a title="299-lsi-4" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>Introduction: This post is by Daniel Hsu and John Langford.In selective sampling style
active learning, a learning algorithm chooses which examples to label. We now
have an active learning algorithm that is:Efficientin label complexity,
unlabeled complexity, and computational complexity.Competitivewith supervised
learning anywhere that supervised learning works.Compatiblewith online
learning, with any optimization-based learning algorithm, with any loss
function, with offline testing, and even with changing learning
algorithms.Empiricallyeffective.The basic idea is to combinedisagreement
region-based samplingwithimportance weighting: an example is selected to be
labeled with probability proportional to how useful it is for distinguishing
among near-optimal classifiers, and labeled examples are importance-weighted
by the inverse of these probabilities. The combination of these simple ideas
removes thesampling biasproblem that has plagued many previous heuristics for
active learning, and yet leads to</p><p>5 0.58849746 <a title="299-lsi-5" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>Introduction: Often, unlabeled data is easy to come by but labels are expensive. For
instance, if you're building a speech recognizer, it's easy enough to get raw
speech samples -- just walk around with a microphone -- but labeling even one
of these samples is a tedious process in which a human must examine the speech
signal and carefully segment it into phonemes. In the field of active
learning, the goal is as usual to construct an accurate classifier, but the
labels of the data points are initially hidden and there is a charge for each
label you want revealed. The hope is that by intelligent adaptive querying,
you can get away with significantly fewer labels than you would need in a
regular supervised learning framework.Here's an example. Suppose the data lie
on the real line, and the classifiers are simple thresholding functions, H =
{hw}:hw(x) = 1 if x > w, and 0 otherwise.VC theory tells us that if the
underlying distribution P can be classified perfectly by some hypothesis in H
(called thereal</p><p>6 0.57189965 <a title="299-lsi-6" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>7 0.56474322 <a title="299-lsi-7" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>8 0.55992913 <a title="299-lsi-8" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>9 0.50870389 <a title="299-lsi-9" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>10 0.50627434 <a title="299-lsi-10" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>11 0.48604736 <a title="299-lsi-11" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>12 0.48371467 <a title="299-lsi-12" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>13 0.47094503 <a title="299-lsi-13" href="../hunch_net-2006/hunch_net-2006-12-12-Interesting_Papers_at_NIPS_2006.html">224 hunch net-2006-12-12-Interesting Papers at NIPS 2006</a></p>
<p>14 0.45595846 <a title="299-lsi-14" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>15 0.45129347 <a title="299-lsi-15" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>16 0.44635797 <a title="299-lsi-16" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>17 0.44623849 <a title="299-lsi-17" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>18 0.44004661 <a title="299-lsi-18" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>19 0.43664798 <a title="299-lsi-19" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>20 0.42730603 <a title="299-lsi-20" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.866)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99991876 <a title="299-lda-1" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>Introduction: I recently discovered that supervised learning is a controversial term. The
two definitions are:Known LossSupervised learning corresponds to the situation
where you have unlabeled examples plus knowledge of the loss of each possible
predicted choice. This is the definition I'm familiar and comfortable with.
One reason to prefer this definition is that the analysis of sample complexity
for this class of learning problems are all pretty similar.Any kind of
signalSupervised learning corresponds to the situation where you have
unlabeled examples plus any source of side information about what the right
choice is. This notion of supervised learning seems to subsume reinforcement
learning, which makes me uncomfortable, because it means there are two words
for the same class. This also means there isn't a convenient word to describe
the first definition.Reviews suggest there are people who are dedicated to the
second definition out there, so it can be important to discriminate which you
mean.</p><p>2 0.99919683 <a title="299-lda-2" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>Introduction: Say we have two random variablesX,Ywith mutual informationI(X,Y). Let's say we
want to represent them with a bayes net of the formX< -M->Y, such that the
entropy ofMequals the mutual information, i.e.H(M)=I(X,Y). Intuitively, we
would like our hidden state to be as simple as possible (entropy wise). The
data processing inequality means thatH(M)>=I(X,Y), so the mutual information
is a lower bound on how simple theMcould be. Furthermore, if such a
construction existed it would have a nice coding interpretation -- one could
jointly codeXandYby first coding the mutual information, then codingXwith this
mutual info (withoutY) and codingYwith this mutual info (withoutX).It turns
out that such a construction does not exist in general (ThxAlina
Beygelzimerfor a counterexample! see below for the sketch).What are the
implications of this? Well, it's hard for me to say, but it does suggest to me
that the 'generative' model philosophy might be burdened with a harder
modeling task. If all we care a</p><p>3 0.99913281 <a title="299-lda-3" href="../hunch_net-2012/hunch_net-2012-10-26-ML_Symposium_and_Strata-Hadoop_World.html">475 hunch net-2012-10-26-ML Symposium and Strata-Hadoop World</a></p>
<p>Introduction: TheNew York ML symposiumwas last Friday. There were 303 registrations, up a
bit fromlast year. I particularly enjoyed talks byBill Freemanon vision and
ML,Jon Lenchneron strategy in Jeopardy, andTara N. Sainathand Brian Kingsbury
ondeep learning for speech recognition. If anyone has suggestions or thoughts
for next year, please speak up.I also attendedStrata + Hadoop Worldfor the
first time. This is primarily a trade conference rather than an academic
conference, but I found it pretty interesting as a first time attendee. This
is ground zero for theBig databuzzword, and I see now why. It's about data,
and the word "big" is so ambiguous that everyone can lay claim to it. There
were essentially zero academic talks. Instead, the focus was on war stories,
product announcements, and education. The general level of education is much
lower--explaining Machine Learning to the SQL educated is the primary
operating point. Nevertheless that's happening, and the fact that machine
learning is consi</p><p>4 0.9988516 <a title="299-lda-4" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>Introduction: A common defect of many pieces of research is defining the problem in terms of
the solution. Here are some examples in learning:"The learning problem is
finding a good seperating hyperplane.""The goal of learning is to
minimize(y-p)2+ C w2wherey= the observation,p= the prediction andw= a
parameter vector."Defining thelossfunction to be the one that your algorithm
optimizes rather than the one imposed by the world.The fundamental reason why
this is a defect is that it creates artificial boundaries to problem solution.
Artificial boundaries lead to the possibility of being blind-sided. For
example, someone committing (1) or (2) above might find themselves themselves
surprised to find a decision tree working well on a problem. Example (3) might
result in someone else solving a learning problem better for real world
purposes, even if it's worse with respect to the algorithm optimization. This
defect should be avoided so as to not artificially limit your learning
kungfu.The way to avoid thi</p><p>5 0.99814397 <a title="299-lda-5" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>Introduction: Here is a set of papers that I found interesting (and why).A PAC-Bayes
approach to the Set Covering Machineimproves the set covering machine. The set
covering machine approach is a new way to do classification characterized by a
very close connection between theory and algorithm. At this point, the
approach seems to be competing well with SVMs in about all dimensions: similar
computational speed, similar accuracy, stronger learning theory guarantees,
more general information source (a kernel has strictly more structure than a
metric), and more sparsity. Developing a classification algorithm is not very
easy, but the results so far are encouraging.Off-Road Obstacle Avoidance
through End-to-End LearningandLearning Depth from Single Monocular Imagesboth
effectively showed that depth information can be predicted from camera images
(using notably different techniques). This ability is strongly enabling
because cameras are cheap, tiny, light, and potentially provider longer range
distance in</p><p>6 0.99804348 <a title="299-lda-6" href="../hunch_net-2006/hunch_net-2006-06-15-IJCAI_is_out_of_season.html">184 hunch net-2006-06-15-IJCAI is out of season</a></p>
<p>7 0.99746865 <a title="299-lda-7" href="../hunch_net-2005/hunch_net-2005-03-29-Academic_Mechanism_Design.html">48 hunch net-2005-03-29-Academic Mechanism Design</a></p>
<p>8 0.99571192 <a title="299-lda-8" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>9 0.9955017 <a title="299-lda-9" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>10 0.98740375 <a title="299-lda-10" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>11 0.98612624 <a title="299-lda-11" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>12 0.97738785 <a title="299-lda-12" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>13 0.97117656 <a title="299-lda-13" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>14 0.96720743 <a title="299-lda-14" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>15 0.96312094 <a title="299-lda-15" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>16 0.95813882 <a title="299-lda-16" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>17 0.95636135 <a title="299-lda-17" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>18 0.9491021 <a title="299-lda-18" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>19 0.94900185 <a title="299-lda-19" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>20 0.94723374 <a title="299-lda-20" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
