<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>290 hunch net-2008-02-27-The Stats Handicap</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-290" href="#">hunch_net-2008-290</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>290 hunch net-2008-02-27-The Stats Handicap</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-290-html" href="http://hunch.net/?p=318">html</a></p><p>Introduction: Graduating students in Statistics appear to be at a substantial handicap
compared to graduating students in Machine Learning, despite being in
substantially overlapping subjects.The problem seems to be cultural.
Statistics comes from a mathematics background which emphasizes large
publications slowly published under review at journals. Machine Learning comes
from a Computer Science background which emphasizes quick publishing at
reviewed conferences. This has a number of implications:Graduating statistics
PhDs often have 0-2 publications while graduating machine learning PhDs might
have 5-15.Graduating ML students have had a chance for others to build on
their work. Stats students have had no such chance.Graduating ML students have
attended a number of conferences and presented their work, giving them a
chance to meet people. Stats students have had fewer chances of this sort.In
short, Stats students have had relatively few chances to distinguish
themselves and are heavily reliant on t</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Graduating students in Statistics appear to be at a substantial handicap compared to graduating students in Machine Learning, despite being in substantially overlapping subjects. [sent-1, score-1.383]
</p><p>2 Statistics comes from a mathematics background which emphasizes large publications slowly published under review at journals. [sent-3, score-0.677]
</p><p>3 Machine Learning comes from a Computer Science background which emphasizes quick publishing at reviewed conferences. [sent-4, score-0.522]
</p><p>4 This has a number of implications:Graduating statistics PhDs often have 0-2 publications while graduating machine learning PhDs might have 5-15. [sent-5, score-0.702]
</p><p>5 Graduating ML students have had a chance for others to build on their work. [sent-6, score-0.534]
</p><p>6 Graduating ML students have attended a number of conferences and presented their work, giving them a chance to meet people. [sent-8, score-0.671]
</p><p>7 Stats students have had fewer chances of this sort. [sent-9, score-0.635]
</p><p>8 In short, Stats students have had relatively few chances to distinguish themselves and are heavily reliant on their advisors for jobs afterwards. [sent-10, score-0.927]
</p><p>9 This is a poor situation, because advisors have a strong incentive to place students well, implying that recommendation letters must always be considered with a grain of salt. [sent-11, score-0.963]
</p><p>10 This problem is more or less prevalent depending on which Stats department students go to. [sent-12, score-0.596]
</p><p>11 In some places the difference is substantial, and in other places not. [sent-13, score-0.214]
</p><p>12 One practical implication of this, is that when considering graduating stats PhDs for hire, some amount of affirmative action is in order. [sent-14, score-1.063]
</p><p>13 At a minimum, this implies spending extra time getting to know the candidate and what the candidate can do is in order. [sent-15, score-0.402]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('stats', 0.492), ('graduating', 0.405), ('students', 0.405), ('phds', 0.262), ('chances', 0.175), ('emphasizes', 0.153), ('advisors', 0.153), ('publications', 0.153), ('statistics', 0.144), ('candidate', 0.14), ('background', 0.118), ('places', 0.107), ('hire', 0.087), ('grain', 0.087), ('letters', 0.087), ('chance', 0.081), ('ml', 0.081), ('comes', 0.076), ('spending', 0.073), ('prevalent', 0.07), ('meet', 0.068), ('department', 0.068), ('jobs', 0.068), ('implication', 0.065), ('incentive', 0.065), ('slowly', 0.064), ('heavily', 0.064), ('distinguish', 0.062), ('reviewed', 0.062), ('recommendation', 0.062), ('substantial', 0.062), ('mathematics', 0.059), ('quick', 0.059), ('attended', 0.059), ('presented', 0.058), ('despite', 0.058), ('implications', 0.058), ('fewer', 0.055), ('publishing', 0.054), ('published', 0.054), ('action', 0.053), ('poor', 0.053), ('minimum', 0.053), ('depending', 0.053), ('considered', 0.051), ('situation', 0.05), ('extra', 0.049), ('compared', 0.048), ('build', 0.048), ('considering', 0.048)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="290-tfidf-1" href="../hunch_net-2008/hunch_net-2008-02-27-The_Stats_Handicap.html">290 hunch net-2008-02-27-The Stats Handicap</a></p>
<p>Introduction: Graduating students in Statistics appear to be at a substantial handicap
compared to graduating students in Machine Learning, despite being in
substantially overlapping subjects.The problem seems to be cultural.
Statistics comes from a mathematics background which emphasizes large
publications slowly published under review at journals. Machine Learning comes
from a Computer Science background which emphasizes quick publishing at
reviewed conferences. This has a number of implications:Graduating statistics
PhDs often have 0-2 publications while graduating machine learning PhDs might
have 5-15.Graduating ML students have had a chance for others to build on
their work. Stats students have had no such chance.Graduating ML students have
attended a number of conferences and presented their work, giving them a
chance to meet people. Stats students have had fewer chances of this sort.In
short, Stats students have had relatively few chances to distinguish
themselves and are heavily reliant on t</p><p>2 0.15239617 <a title="290-tfidf-2" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>Introduction: Carnegie MellonSchool of Computer Sciencehas the first academicMachine
Learning department. This department already existed as theCenter for
Automated Learning and Discovery, but recently changed it's name.The reason
for changing the name is obvious: very few people think of themselves as
"Automated Learner and Discoverers", but there are number of people who think
of themselves as "Machine Learners". Machine learning is both more succinct
and recognizable--good properties for a name.A more interesting question is
"Should there be a Machine Learning Department?".Tom Mitchellhas a
relevantwhitepaperclaiming that machine learning is answering a different
question than other fields or departments. The fundamental debate here is "Is
machine learning different from statistics?"At a cultural level, there is no
real debate: they are different. Machine learning is characterized by several
very active large peer reviewed conferences, operating in a computer science
mode. Statistics tends to fun</p><p>3 0.12387577 <a title="290-tfidf-3" href="../hunch_net-2005/hunch_net-2005-05-17-A_Short_Guide_to_PhD_Graduate_Study.html">73 hunch net-2005-05-17-A Short Guide to PhD Graduate Study</a></p>
<p>Introduction: Graduate study is a mysterious and uncertain process. This easiest way to see
this is by noting that a very old advisor/student mechanism is preferred.
There is no known succesful mechanism for "mass producing" PhDs as is done (in
some sense) for undergraduate and masters study. Here are a few hints that
might be useful to prospective or current students based on my own
experience.Masters or PhD(a) You want a PhD if you want to do research. (b)
You want a masters if you want to make money. People wanting (b) will be
manifestly unhappy with (a) because it typically means years of low pay.
People wanting (a) should try to avoid (b) because it prolongs an already long
process.Attitude.Manystudents struggle for awhile with the wrong attitude
towards research. Most students come into graduate school with 16-19 years of
schooling where the principle means of success is proving that you know
something via assignments, tests, etcâ&euro;Ś Research doesnotwork this way. Research
is what a PhD is about.</p><p>4 0.12176523 <a title="290-tfidf-4" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>Introduction: This is about the hard choices that graduate students must make.The cultural
definition of success in academic research is to:Produce good research which
many other people appreciate.Produce many students who go on to do the
same.There are fundamental reasons why this is success in the local culture.
Good research appreciated by others means access to jobs. Many students
succesful in the same way implies that there are a number of people who think
in a similar way and appreciate your work.In order to graduate, a phd student
must live in an academic culture for a period of several years. It is common
to adopt the culture's definition of success during this time. It's also
common for many phd students discover they are not suited to an academic
research lifestyle. This collision of values and abilities naturally results
in depression.The most fundamental advice when this happens is: change
something. Pick a new advisor. Pick a new research topic. Or leave the program
(and do something el</p><p>5 0.092876926 <a title="290-tfidf-5" href="../hunch_net-2008/hunch_net-2008-08-18-Radford_Neal_starts_a_blog.html">313 hunch net-2008-08-18-Radford Neal starts a blog</a></p>
<p>Introduction: hereon statistics, ML, CS, and other things he knows well.</p><p>6 0.091607548 <a title="290-tfidf-6" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>7 0.086864494 <a title="290-tfidf-7" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>8 0.086639352 <a title="290-tfidf-8" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>9 0.081028871 <a title="290-tfidf-9" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>10 0.077212624 <a title="290-tfidf-10" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>11 0.076524049 <a title="290-tfidf-11" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>12 0.074244216 <a title="290-tfidf-12" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>13 0.07284119 <a title="290-tfidf-13" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>14 0.066665471 <a title="290-tfidf-14" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>15 0.062761694 <a title="290-tfidf-15" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>16 0.061959743 <a title="290-tfidf-16" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>17 0.060208339 <a title="290-tfidf-17" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>18 0.057981078 <a title="290-tfidf-18" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>19 0.057471316 <a title="290-tfidf-19" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>20 0.055620246 <a title="290-tfidf-20" href="../hunch_net-2005/hunch_net-2005-05-11-Visa_Casualties.html">69 hunch net-2005-05-11-Visa Casualties</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.102), (1, 0.045), (2, 0.08), (3, -0.033), (4, 0.051), (5, -0.001), (6, 0.004), (7, 0.054), (8, 0.024), (9, -0.054), (10, 0.024), (11, 0.029), (12, 0.012), (13, -0.004), (14, -0.046), (15, 0.071), (16, -0.05), (17, 0.097), (18, -0.009), (19, 0.014), (20, 0.024), (21, 0.054), (22, 0.067), (23, 0.045), (24, 0.089), (25, -0.035), (26, 0.024), (27, 0.03), (28, -0.019), (29, -0.036), (30, 0.052), (31, -0.003), (32, -0.03), (33, -0.028), (34, -0.046), (35, 0.105), (36, -0.036), (37, 0.013), (38, 0.093), (39, 0.02), (40, 0.088), (41, -0.061), (42, -0.019), (43, 0.168), (44, -0.1), (45, 0.043), (46, -0.083), (47, -0.021), (48, -0.056), (49, -0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96737927 <a title="290-lsi-1" href="../hunch_net-2008/hunch_net-2008-02-27-The_Stats_Handicap.html">290 hunch net-2008-02-27-The Stats Handicap</a></p>
<p>Introduction: Graduating students in Statistics appear to be at a substantial handicap
compared to graduating students in Machine Learning, despite being in
substantially overlapping subjects.The problem seems to be cultural.
Statistics comes from a mathematics background which emphasizes large
publications slowly published under review at journals. Machine Learning comes
from a Computer Science background which emphasizes quick publishing at
reviewed conferences. This has a number of implications:Graduating statistics
PhDs often have 0-2 publications while graduating machine learning PhDs might
have 5-15.Graduating ML students have had a chance for others to build on
their work. Stats students have had no such chance.Graduating ML students have
attended a number of conferences and presented their work, giving them a
chance to meet people. Stats students have had fewer chances of this sort.In
short, Stats students have had relatively few chances to distinguish
themselves and are heavily reliant on t</p><p>2 0.60538924 <a title="290-lsi-2" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>Introduction: Yahoo released theKey Scientific Challengesprogram. There is aMachine
Learninglist I worked on and aStatisticslist whichDeepakworked on.I'm hoping
this is taken quite seriously by graduate students. The primary value, is that
it gave us a chance to sit down and publicly specify directions of research
which would be valuable to make progress on. A good strategy for a beginning
graduate student is to pick one of these directions, pursue it, and make
substantial advances for a PhD. The directions are sufficiently general that
I'm sure any serious advance has applications well beyond Yahoo.A secondary
point, (which I'm sure is primary for many) is that there is money for
graduate students here. It's unrestricted, so you can use it for any
reasonable travel, supplies, etcâ&euro;Ś</p><p>3 0.57360899 <a title="290-lsi-3" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>Introduction: Since we last discussedthe other online learning,Stanfordhas very visibly
started pushing mass teaching inAI,Machine Learning, andDatabases. In
retrospect, it's not too surprising that the next step up in serious online
teaching experiments are occurring at the computer science department of a
university embedded in the land of startups. Numbers on the order of100000are
quite significant--similar in scale to the number ofcomputer science
undergraduate students/yearin the US. Although these populations surely
differ, the fact that theycouldoverlap is worth considering for the
future.It's too soon to say how successful these classes will be and there are
many easy criticisms to make:Registration != Learning… but if only 1/10th
complete these classes, the scale of teaching still surpasses the scale of any
traditional process.1st year excitement != nth year routine… but if only
1/10th take future classes, the scale of teaching still surpasses the scale of
any traditional process.Hello, che</p><p>4 0.57012618 <a title="290-lsi-4" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>Introduction: This is about the hard choices that graduate students must make.The cultural
definition of success in academic research is to:Produce good research which
many other people appreciate.Produce many students who go on to do the
same.There are fundamental reasons why this is success in the local culture.
Good research appreciated by others means access to jobs. Many students
succesful in the same way implies that there are a number of people who think
in a similar way and appreciate your work.In order to graduate, a phd student
must live in an academic culture for a period of several years. It is common
to adopt the culture's definition of success during this time. It's also
common for many phd students discover they are not suited to an academic
research lifestyle. This collision of values and abilities naturally results
in depression.The most fundamental advice when this happens is: change
something. Pick a new advisor. Pick a new research topic. Or leave the program
(and do something el</p><p>5 0.54054338 <a title="290-lsi-5" href="../hunch_net-2005/hunch_net-2005-05-17-A_Short_Guide_to_PhD_Graduate_Study.html">73 hunch net-2005-05-17-A Short Guide to PhD Graduate Study</a></p>
<p>Introduction: Graduate study is a mysterious and uncertain process. This easiest way to see
this is by noting that a very old advisor/student mechanism is preferred.
There is no known succesful mechanism for "mass producing" PhDs as is done (in
some sense) for undergraduate and masters study. Here are a few hints that
might be useful to prospective or current students based on my own
experience.Masters or PhD(a) You want a PhD if you want to do research. (b)
You want a masters if you want to make money. People wanting (b) will be
manifestly unhappy with (a) because it typically means years of low pay.
People wanting (a) should try to avoid (b) because it prolongs an already long
process.Attitude.Manystudents struggle for awhile with the wrong attitude
towards research. Most students come into graduate school with 16-19 years of
schooling where the principle means of success is proving that you know
something via assignments, tests, etcâ&euro;Ś Research doesnotwork this way. Research
is what a PhD is about.</p><p>6 0.48038515 <a title="290-lsi-6" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>7 0.47349676 <a title="290-lsi-7" href="../hunch_net-2005/hunch_net-2005-05-11-Visa_Casualties.html">69 hunch net-2005-05-11-Visa Casualties</a></p>
<p>8 0.46629232 <a title="290-lsi-8" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>9 0.45942137 <a title="290-lsi-9" href="../hunch_net-2008/hunch_net-2008-08-18-Radford_Neal_starts_a_blog.html">313 hunch net-2008-08-18-Radford Neal starts a blog</a></p>
<p>10 0.44996223 <a title="290-lsi-10" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>11 0.42638251 <a title="290-lsi-11" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>12 0.42609912 <a title="290-lsi-12" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>13 0.40474296 <a title="290-lsi-13" href="../hunch_net-2010/hunch_net-2010-10-17-Partha_Niyogi_has_died.html">414 hunch net-2010-10-17-Partha Niyogi has died</a></p>
<p>14 0.39839956 <a title="290-lsi-14" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>15 0.36560935 <a title="290-lsi-15" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>16 0.36455238 <a title="290-lsi-16" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>17 0.36285761 <a title="290-lsi-17" href="../hunch_net-2010/hunch_net-2010-08-21-Rob_Schapire_at_NYC_ML_Meetup.html">405 hunch net-2010-08-21-Rob Schapire at NYC ML Meetup</a></p>
<p>18 0.35564768 <a title="290-lsi-18" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>19 0.35100031 <a title="290-lsi-19" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>20 0.34162778 <a title="290-lsi-20" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.018), (35, 0.103), (38, 0.363), (42, 0.184), (45, 0.045), (61, 0.015), (68, 0.043), (74, 0.079), (95, 0.024)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96071601 <a title="290-lda-1" href="../hunch_net-2008/hunch_net-2008-09-04-Fall_ML_Conferences.html">316 hunch net-2008-09-04-Fall ML Conferences</a></p>
<p>Introduction: If you are in the New York area and interested in machine learning, consider
submitting a 2 page abstract to theML symposiumby tomorrow (Sept 5th)
midnight. It's a fun one day affair on October 10 in an awesome location
overlooking the world trade center site.A bit further off (but a real
conference) is theAI and Statsdeadline on November 5, to be held in Florida
April 16-19.</p><p>2 0.92488241 <a title="290-lda-2" href="../hunch_net-2005/hunch_net-2005-02-27-Antilearning%3A_When_proximity_goes_bad.html">32 hunch net-2005-02-27-Antilearning: When proximity goes bad</a></p>
<p>Introduction: Joel Preddmentioned"Antilearning" byAdam Kowalczyk, which is interesting from
a foundational intuitions viewpoint.There is a pervasive intuition that
"nearby things tend to have the same label". This intuition is instantiated in
SVMs, nearest neighbor classifiers, decision trees, and neural networks. It
turns out there are natural problems where this intuition is opposite of the
truth.One natural situation where this occurs is in competition. For example,
whenIntelfails to meet its earnings estimate, is this evidence thatAMDis doing
badly also? Or evidence that AMD is doing well?This violation of the proximity
intuition means that when the number of examples is few,negatinga classifier
which attempts to exploit proximity can provide predictive power (thus, the
term "antilearning").</p><p>3 0.91116309 <a title="290-lda-3" href="../hunch_net-2008/hunch_net-2008-06-30-ICML_has_a_comment_system.html">305 hunch net-2008-06-30-ICML has a comment system</a></p>
<p>Introduction: Mark Reidhas stepped up and created acomment system for ICML paperswhichGreger
Lindenhas tightly integrated.My understanding is that Mark spent quite a bit
of time on the details, and there are some cool features like working latex
math mode. This is an excellent chance for the ICML community to experiment
with making ICML year-round, so I hope it works out. Please do consider
experimenting with it.</p><p>same-blog 4 0.90770346 <a title="290-lda-4" href="../hunch_net-2008/hunch_net-2008-02-27-The_Stats_Handicap.html">290 hunch net-2008-02-27-The Stats Handicap</a></p>
<p>Introduction: Graduating students in Statistics appear to be at a substantial handicap
compared to graduating students in Machine Learning, despite being in
substantially overlapping subjects.The problem seems to be cultural.
Statistics comes from a mathematics background which emphasizes large
publications slowly published under review at journals. Machine Learning comes
from a Computer Science background which emphasizes quick publishing at
reviewed conferences. This has a number of implications:Graduating statistics
PhDs often have 0-2 publications while graduating machine learning PhDs might
have 5-15.Graduating ML students have had a chance for others to build on
their work. Stats students have had no such chance.Graduating ML students have
attended a number of conferences and presented their work, giving them a
chance to meet people. Stats students have had fewer chances of this sort.In
short, Stats students have had relatively few chances to distinguish
themselves and are heavily reliant on t</p><p>5 0.82111621 <a title="290-lda-5" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<p>Introduction: Here are two papers that seem particularly interesting at this year's
COLT.Gilles BlanchardandFranÃƒÂ§ois Fleuret,Occam's Hammer. When we are
interested in very tight bounds on the true error rate of a classifier, it is
tempting to use a PAC-Bayes bound which can (empirically) bequite tight. A
disadvantage of the PAC-Bayes bound is that it applies to a classifier which
is randomized over a set of base classifiers rather than a single classifier.
This paper shows that a similar bound can be proved which holds for a single
classifier drawn from the set. The ability to safely use a single classifier
is very nice. This technique applies generically to any base bound, so it has
other applications covered in the paper.Adam Tauman Kalai.Learning Nested
Halfspaces and Uphill Decision Trees. Classification PAC-learning, where you
prove that any problem amongst some set is polytime learnable with respect to
any distribution over the inputXis extraordinarily challenging as judged by
lack of progr</p><p>6 0.75319022 <a title="290-lda-6" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>7 0.75285882 <a title="290-lda-7" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>8 0.68805122 <a title="290-lda-8" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>9 0.6053409 <a title="290-lda-9" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>10 0.56778026 <a title="290-lda-10" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>11 0.52938765 <a title="290-lda-11" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>12 0.52891451 <a title="290-lda-12" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>13 0.52509975 <a title="290-lda-13" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>14 0.5217576 <a title="290-lda-14" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>15 0.52131808 <a title="290-lda-15" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>16 0.52031541 <a title="290-lda-16" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>17 0.51995891 <a title="290-lda-17" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>18 0.51790786 <a title="290-lda-18" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>19 0.51702374 <a title="290-lda-19" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>20 0.51625699 <a title="290-lda-20" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
