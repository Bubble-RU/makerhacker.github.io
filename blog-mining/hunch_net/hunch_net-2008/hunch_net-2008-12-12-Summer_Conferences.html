<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>331 hunch net-2008-12-12-Summer Conferences</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-331" href="#">hunch_net-2008-331</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>331 hunch net-2008-12-12-Summer Conferences</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-331-html" href="http://hunch.net/?p=485">html</a></p><p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ConferenceDeadlineReviewer TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January 26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune 19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis, FranceJune 28-July 1Reviewer targeting is new this year. [sent-2, score-0.239]
</p><p>2 The idea is that many poor decisions happen because the papers go to reviewers who are unqualified, and the hope is that allowing authors to point out who is qualified results in better decisions. [sent-3, score-1.657]
</p><p>3 In my experience, this is a reasonable idea to test. [sent-4, score-0.244]
</p><p>4 Both UAI and COLT are experimenting this year as well with double blind and author feedback, respectively. [sent-5, score-1.062]
</p><p>5 Of the two, I believe author feedback is more important, as I've seen it make a difference. [sent-6, score-0.687]
</p><p>6 However, I still consider double blind reviewing a net win, as it's a substantial public commitment to fairness. [sent-7, score-1.451]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('blind', 0.276), ('double', 0.276), ('fairness', 0.241), ('qualified', 0.241), ('feedback', 0.22), ('author', 0.22), ('table', 0.201), ('commitment', 0.201), ('targeting', 0.193), ('net', 0.186), ('january', 0.18), ('win', 0.175), ('handy', 0.171), ('uai', 0.167), ('experimenting', 0.167), ('idea', 0.164), ('poor', 0.147), ('allowing', 0.132), ('summer', 0.131), ('colt', 0.127), ('public', 0.126), ('happen', 0.124), ('authors', 0.12), ('decisions', 0.12), ('reviewing', 0.116), ('reviewers', 0.112), ('wrong', 0.108), ('seen', 0.104), ('still', 0.1), ('icml', 0.099), ('experience', 0.095), ('go', 0.095), ('however', 0.092), ('believe', 0.089), ('hope', 0.087), ('consider', 0.085), ('substantial', 0.085), ('results', 0.084), ('reasonable', 0.08), ('year', 0.075), ('point', 0.073), ('important', 0.071), ('papers', 0.066), ('better', 0.061), ('two', 0.057), ('make', 0.054), ('well', 0.048), ('new', 0.046), ('many', 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="331-tfidf-1" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>2 0.35041702 <a title="331-tfidf-2" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>3 0.28862029 <a title="331-tfidf-3" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>Introduction: Most long conversations between academics seem to converge on the topic of
reviewing where almost no one is happy. A basic question is: Should most
people be happy?The case against is straightforward. Anyone who watches the
flow of papers realizes that most papers amount to little in the longer term.
By it's nature research is brutal, where the second-best method is worthless,
and the second person to discover things typically gets no credit. If you
think about this for a moment, it's very different from most other human
endeavors. The second best migrant laborer, construction worker, manager,
conductor, quarterback, etcâ&euro;Ś all can manage quite well. If a reviewer has even
a vaguely predictive sense of what's important in the longer term, then most
people submitting papers will be unhappy.But this argument unravels, in my
experience. Perhaps half of reviews are thoughtless or simply wrong with a
small part being simply malicious. And yet, I'm sure that most reviewers
genuinely believe th</p><p>4 0.22431868 <a title="331-tfidf-4" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>Introduction: Here's a quick reference for summer ML-related conferences sorted by due
date:ConferenceDue dateLocationReviewingKDDFeb 10August 12-16, Beijing,
ChinaSingle BlindCOLTFeb 14June 25-June 27, Edinburgh, ScotlandSingle Blind?
(historically)ICMLFeb 24June 26-July 1, Edinburgh, ScotlandDouble Blind,
author response, zeroSPOFUAIMarch 30August 15-17, Catalina Islands,
CaliforniaDouble Blind, author responseGeographically, this is greatly
dispersed and the UAI/KDD conflict is unfortunate.Machine Learning conferences
are triannual now, betweenNIPS,AIStat, andICML. This has not always been the
case: the academic default is annual summer conferences, then NIPS started
with a December conference, and now AIStat has grown into an April
conference.However, the first claim is not quite correct. NIPS and AIStat have
few competing venues while ICML implicitly competes with many other
conferences accepting machine learning related papers. SinceJoelleand I are
taking a turn as program chairs this year, I</p><p>5 0.22253866 <a title="331-tfidf-5" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>Introduction: Unfortunately, I ended up sick for much of this ICML. I did manage to catch
one interesting paper:Richard Socher,Cliff Lin,Andrew Y. Ng, andChristopher D.
ManningParsing Natural Scenes and Natural Language with Recursive Neural
Networks.I invited Richard to share his list of interesting papers, so
hopefully we'll hear from him soon. In the meantime,PaulandHalhave posted some
lists.the futureJoelleand I are program chairs for ICML 2012 inEdinburgh,
which I previously enjoyed visiting in2005. This is a huge responsibility,
that we hope to accomplish well. A part of this (perhaps the most fun part),
is imagining how we can make ICML better. A key and critical constraint is
choosing things that can be accomplished. So far we have:Colocation. The first
thing we looked into was potential colocations. We quickly discovered that
many other conferences precomitted their location. For the future, getting a
colocation withACLorSIGIR, seems to require more advanced planning. If that
can be done, I</p><p>6 0.2101399 <a title="331-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>7 0.20075098 <a title="331-tfidf-7" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>8 0.18042283 <a title="331-tfidf-8" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>9 0.16690883 <a title="331-tfidf-9" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>10 0.15086801 <a title="331-tfidf-10" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>11 0.14891472 <a title="331-tfidf-11" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>12 0.1480899 <a title="331-tfidf-12" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>13 0.14263278 <a title="331-tfidf-13" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>14 0.13753453 <a title="331-tfidf-14" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>15 0.13645689 <a title="331-tfidf-15" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>16 0.13219 <a title="331-tfidf-16" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>17 0.12962508 <a title="331-tfidf-17" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>18 0.12349407 <a title="331-tfidf-18" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>19 0.11813066 <a title="331-tfidf-19" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>20 0.11809114 <a title="331-tfidf-20" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.18), (1, 0.27), (2, -0.199), (3, -0.008), (4, -0.013), (5, 0.019), (6, -0.014), (7, 0.072), (8, 0.069), (9, -0.038), (10, -0.03), (11, -0.227), (12, 0.103), (13, -0.031), (14, 0.09), (15, -0.141), (16, 0.014), (17, 0.11), (18, 0.044), (19, -0.029), (20, 0.006), (21, -0.017), (22, 0.005), (23, 0.024), (24, -0.023), (25, -0.084), (26, 0.087), (27, -0.013), (28, 0.02), (29, 0.127), (30, 0.087), (31, -0.116), (32, -0.025), (33, -0.042), (34, -0.076), (35, -0.054), (36, 0.038), (37, 0.013), (38, -0.081), (39, 0.048), (40, 0.027), (41, 0.084), (42, -0.035), (43, -0.066), (44, -0.002), (45, -0.004), (46, -0.048), (47, -0.062), (48, -0.031), (49, -0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99234509 <a title="331-lsi-1" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>2 0.91352832 <a title="331-lsi-2" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>3 0.76552713 <a title="331-lsi-3" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>Introduction: Most long conversations between academics seem to converge on the topic of
reviewing where almost no one is happy. A basic question is: Should most
people be happy?The case against is straightforward. Anyone who watches the
flow of papers realizes that most papers amount to little in the longer term.
By it's nature research is brutal, where the second-best method is worthless,
and the second person to discover things typically gets no credit. If you
think about this for a moment, it's very different from most other human
endeavors. The second best migrant laborer, construction worker, manager,
conductor, quarterback, etcâ&euro;Ś all can manage quite well. If a reviewer has even
a vaguely predictive sense of what's important in the longer term, then most
people submitting papers will be unhappy.But this argument unravels, in my
experience. Perhaps half of reviews are thoughtless or simply wrong with a
small part being simply malicious. And yet, I'm sure that most reviewers
genuinely believe th</p><p>4 0.64001423 <a title="331-lsi-4" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>5 0.6317926 <a title="331-lsi-5" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>Introduction: It's conference season once again.ConferenceDue?When?Where?double blind?author
feedback?Workshops?AAAIFebruary 1/6 (and 27)July 22-26Vancouver, British
ColumbiaYesYesDoneUAIFebruary 28/March 2July 19-22Vancouver, British
ColumbiaNoNoNoCOLTJanuary 16June 13-15San Diego, California
(withFCRC)NoNoNoICMLFebruary 7/9June 20-24Corvallis, OregonYesYesFebruary
16KDDFebruary 23/28August 12-15San Jose, CaliforniaYesNo?February 28The
geowinner this year is the west coast of North America.Last year's geowinner
was the Northeastern US, and theyear beforeit was mostly Europe. It's notable
how tightly the conferences cluster, even when they don't colocate.</p><p>6 0.61429369 <a title="331-lsi-6" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>7 0.59467894 <a title="331-lsi-7" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>8 0.57588011 <a title="331-lsi-8" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>9 0.57155651 <a title="331-lsi-9" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>10 0.55044216 <a title="331-lsi-10" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>11 0.54499322 <a title="331-lsi-11" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>12 0.54392105 <a title="331-lsi-12" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>13 0.52149922 <a title="331-lsi-13" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>14 0.51719463 <a title="331-lsi-14" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>15 0.50640935 <a title="331-lsi-15" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>16 0.50606489 <a title="331-lsi-16" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>17 0.50313014 <a title="331-lsi-17" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>18 0.49744493 <a title="331-lsi-18" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>19 0.47837463 <a title="331-lsi-19" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>20 0.44032007 <a title="331-lsi-20" href="../hunch_net-2006/hunch_net-2006-04-17-Rexa_is_live.html">173 hunch net-2006-04-17-Rexa is live</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(14, 0.292), (42, 0.143), (45, 0.04), (74, 0.24), (82, 0.155)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91538692 <a title="331-lda-1" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>2 0.74715 <a title="331-lda-2" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>Introduction: â&euro;Ś but only the little prize. TheBellKor teamfocused on integrating predictions
from many different methods. The base methods consist of:Nearest Neighbor
MethodsMatrix Factorization Methods (asymmetric and symmetric)Linear
Regression on various feature spacesRestricted Boltzman MachinesThe final
predictor was an ensemble (as was reasonable to expect), although it's a
little bit more complicated than just a weighted average--it's essentially a
customized learning algorithm. Base approaches (1)-(3) seem like relatively
well-known approaches (although I haven't seen the asymmetric factorization
variant before). RBMs are the new approach.Thewriteupis pretty clear for more
details.The contestants are close to reaching the big prize, but the last 1.5%
is probably at least as hard as what's been done. A few new structurally
different methods for making predictions may need to be discovered and added
into the mixture. In other words, research may be required.</p><p>3 0.71080041 <a title="331-lda-3" href="../hunch_net-2005/hunch_net-2005-09-20-Workshop_Proposal%3A_Atomic_Learning.html">114 hunch net-2005-09-20-Workshop Proposal: Atomic Learning</a></p>
<p>Introduction: This is a proposal for a workshop. It may or may not happen depending on the
level of interest. If you are interested, feel free to indicate so (by email
or comments).Description:Assume(*) that any system for solving large difficult
learning problems must decompose into repeated use of basic elements (i.e.
atoms). There are many basic questions which remain:What are the viable basic
elements?What makes a basic element viable?What are the viable principles for
the composition of these basic elements?What are the viable principles for
learning in such systems?What problems can this approach handle?Hal Daume
adds:Can composition of atoms be (semi-) automatically constructed[?]When
atoms are constructed through reductions, is there some notion of the
"naturalness" of the created leaning problems?Other than Markov
fields/graphical models/Bayes nets, is there a good language for representing
atoms and their compositions?The answer to these and related questions remain
unclear to me. A worksh</p><p>4 0.68604022 <a title="331-lda-4" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>Introduction: Here. I'm particularly interested in theWeb Search,Efficient ML, and (of
course)Learning Problem Designworkshops but there are many others to check out
as well. Workshops are a great chance to make progress on or learn about a
topic. Relevance and interaction amongst diverse people can sometimes be
magical.</p><p>5 0.67804337 <a title="331-lda-5" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>Introduction: Conferences exist as part of the process of doing research. They provide many
roles including "announcing research", "meeting people", and "point of
reference". Not all conferences are alike so a basic question is: "to what
extent do individual conferences attempt to aid research?" This question is
very difficult to answer in any satisfying way. What we can do is compare
details of the process across multiple conferences.CommentsThe average quality
of comments across conferences can vary dramatically. At one extreme, the
tradition in CS theory conferences is to provide essentially zero feedback. At
the other extreme, some conferences have a strong tradition of providing
detailed constructive feedback. Detailed feedback can give authors significant
guidance about how to improve research. This is the most subjective
entry.BlindVirtually all conferences offer single blind review where authors
do not know reviewers. Some also providedouble blindreview where reviewers do
not know authors. T</p><p>6 0.67353201 <a title="331-lda-6" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>7 0.66728157 <a title="331-lda-7" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>8 0.66674763 <a title="331-lda-8" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>9 0.66480744 <a title="331-lda-9" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>10 0.65464526 <a title="331-lda-10" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>11 0.64950097 <a title="331-lda-11" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>12 0.64603829 <a title="331-lda-12" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>13 0.64337033 <a title="331-lda-13" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>14 0.64282739 <a title="331-lda-14" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>15 0.64144242 <a title="331-lda-15" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>16 0.63964945 <a title="331-lda-16" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>17 0.63916051 <a title="331-lda-17" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>18 0.63902503 <a title="331-lda-18" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>19 0.63806534 <a title="331-lda-19" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>20 0.63693607 <a title="331-lda-20" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
