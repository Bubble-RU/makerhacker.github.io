<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-303" href="#">hunch_net-2008-303</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-303-html" href="http://hunch.net/?p=333">html</a></p><p>Introduction: This post is about a trick that I learned fromDale Schuurmanswhich has been
repeatedly useful for me over time.The basic trick has to do with importance
weighting for monte carlo integration. Consider the problem of finding:N = Ex
~ Df(x)given samples fromDand knowledge off.Often, we don't have samples
fromDavailable. Instead, we must make do with samples from some other
distributionQ. In that case, we can still often solve the problem, as long as
Q(x) isn't 0 when D(x) is nonzero, using the importance weighting formula:Ex ~
Qf(x) D(x)/Q(x)A basic question is: How many samples fromQare required in
order to estimateNto some precision? In general the convergence rate is not
bounded, becausef(x) D(x)/Q(x)is not bounded given the
assumptions.Nevertheless, there is one special valueQ(x) = f(x) D(x) / Nwhere
the sample complexity turns out to be1, which is typically substantially
better than the sample complexity of the original problem.This observation
underlies the motivation for voluntary</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('weighting', 0.365), ('samples', 0.331), ('ex', 0.325), ('importance', 0.275), ('trick', 0.225), ('bounded', 0.21), ('voluntary', 0.163), ('fromd', 0.163), ('fromdand', 0.163), ('sample', 0.155), ('nonzero', 0.151), ('carlo', 0.142), ('monte', 0.142), ('formula', 0.13), ('approximations', 0.13), ('complexity', 0.126), ('terrible', 0.126), ('precision', 0.122), ('logic', 0.11), ('repeatedly', 0.107)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="303-tfidf-1" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>Introduction: This post is about a trick that I learned fromDale Schuurmanswhich has been
repeatedly useful for me over time.The basic trick has to do with importance
weighting for monte carlo integration. Consider the problem of finding:N = Ex
~ Df(x)given samples fromDand knowledge off.Often, we don't have samples
fromDavailable. Instead, we must make do with samples from some other
distributionQ. In that case, we can still often solve the problem, as long as
Q(x) isn't 0 when D(x) is nonzero, using the importance weighting formula:Ex ~
Qf(x) D(x)/Q(x)A basic question is: How many samples fromQare required in
order to estimateNto some precision? In general the convergence rate is not
bounded, becausef(x) D(x)/Q(x)is not bounded given the
assumptions.Nevertheless, there is one special valueQ(x) = f(x) D(x) / Nwhere
the sample complexity turns out to be1, which is typically substantially
better than the sample complexity of the original problem.This observation
underlies the motivation for voluntary</p><p>2 0.11381869 <a title="303-tfidf-2" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>Introduction: Here are a few of the papers I enjoyed at ICML.Steffen Bickel, Michael
BrÃƒÂ¼eckner,Tobias Scheffer,Discriminative Learning for Differing Training
and Test DistributionsThere is a nice trick in this paper: they predict the
probability that an unlabeled sample is in the training set vs. the test set,
and then use this prediction to importance weight labeled samples in the
training set. This paper uses a specific parametric model, but the approach is
easily generalized.Steve HannekeA Bound on the Label Complexity of Agnostic
Active LearningThis paper bounds the number of labels required by the
A2algorithm for active learning in the agnostic case. Last year we figured out
agnostic active learning was possible. This year, it's quantified. Hopefull
soon, it will be practical.Sylvian Gelly,David SilverCombining Online and
Offline Knowledge in UCT. This paper is about techniques for improvingMoGowith
various sorts of learning. MoGo has a fair claim at being the world's best Go
algorithm.There</p><p>3 0.093860365 <a title="303-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>Introduction: Suppose we have a set of classifierscmaking binary predictions from an
inputxand we see examples in an online fashion. In particular, we repeatedly
see an unlabeled examplex, make a predictiony'(possibly based on the
classifiersc), and then see the correct labely.When one of these classifiers
is perfect, there is a great algorithm available: predict according to the
majority vote over every classifier consistent with every previous example.
This is called the Halving algorithm. It makes at mostlog2|c|mistakes since on
any mistake, at least half of the classifiers are eliminated.Obviously, we
can't generally hope that the there exists a classifier which never errs.
TheBinomial Weighting algorithmis an elegant technique allowing a variant
Halving algorithm to cope with errors by creating a set of virtual classifiers
for every classifier which occasionally disagree with the original classifier.
The Halving algorithm on this set of virtual classifiers satisfies a theorem
of the form:errors</p><p>4 0.090257578 <a title="303-tfidf-4" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>Introduction: Exploration is one of the big unsolved problems in machine learning. This
isn't for lack of trying--there are many models of exploration which have been
analyzed in many different ways by many different groups of people. At some
point, it is worthwhile to sit back and see what has been done across these
many models.Reinforcement Learning(1). Reinforcement learning has
traditionally focused on Markov Decision Processes where the next states'is
given by a conditional distributionP(s'|s,a)given the current statesand
actiona. The typical result here is that certain specific algorithms
controlling an agent can behave withineof optimal for horizonTexcept
forpoly(1/e,T,S,A)"wasted" experiences (with high probability). This started
withE3bySatinder SinghandMichael Kearns.Sham Kakade's thesishas significant
discussion. Extensions have typically been of the form "under extra
assumptions, we can prove more", for exampleFactored-E3andMetric-E3. (It turns
out that the number of wasted samples can b</p><p>5 0.088123277 <a title="303-tfidf-5" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>6 0.087744907 <a title="303-tfidf-6" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>7 0.087557405 <a title="303-tfidf-7" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>8 0.082577311 <a title="303-tfidf-8" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>9 0.076905683 <a title="303-tfidf-9" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>10 0.076552302 <a title="303-tfidf-10" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>11 0.075554155 <a title="303-tfidf-11" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>12 0.075530589 <a title="303-tfidf-12" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>13 0.074873775 <a title="303-tfidf-13" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>14 0.073545858 <a title="303-tfidf-14" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>15 0.071691759 <a title="303-tfidf-15" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>16 0.071620435 <a title="303-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>17 0.068948537 <a title="303-tfidf-17" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>18 0.064383179 <a title="303-tfidf-18" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>19 0.062792875 <a title="303-tfidf-19" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>20 0.060916025 <a title="303-tfidf-20" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.135), (1, -0.076), (2, -0.028), (3, -0.021), (4, -0.036), (5, -0.063), (6, 0.009), (7, -0.001), (8, 0.014), (9, 0.012), (10, -0.022), (11, 0.026), (12, -0.011), (13, 0.003), (14, -0.002), (15, -0.049), (16, 0.03), (17, 0.032), (18, -0.003), (19, -0.045), (20, -0.017), (21, 0.041), (22, -0.025), (23, -0.029), (24, 0.05), (25, 0.046), (26, -0.081), (27, -0.056), (28, -0.02), (29, 0.047), (30, -0.019), (31, 0.023), (32, 0.015), (33, -0.021), (34, 0.002), (35, -0.03), (36, 0.021), (37, -0.012), (38, -0.005), (39, -0.091), (40, 0.05), (41, 0.012), (42, 0.082), (43, -0.009), (44, -0.005), (45, -0.051), (46, 0.009), (47, -0.049), (48, 0.043), (49, -0.048)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96757561 <a title="303-lsi-1" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>Introduction: This post is about a trick that I learned fromDale Schuurmanswhich has been
repeatedly useful for me over time.The basic trick has to do with importance
weighting for monte carlo integration. Consider the problem of finding:N = Ex
~ Df(x)given samples fromDand knowledge off.Often, we don't have samples
fromDavailable. Instead, we must make do with samples from some other
distributionQ. In that case, we can still often solve the problem, as long as
Q(x) isn't 0 when D(x) is nonzero, using the importance weighting formula:Ex ~
Qf(x) D(x)/Q(x)A basic question is: How many samples fromQare required in
order to estimateNto some precision? In general the convergence rate is not
bounded, becausef(x) D(x)/Q(x)is not bounded given the
assumptions.Nevertheless, there is one special valueQ(x) = f(x) D(x) / Nwhere
the sample complexity turns out to be1, which is typically substantially
better than the sample complexity of the original problem.This observation
underlies the motivation for voluntary</p><p>2 0.66016716 <a title="303-lsi-2" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>Introduction: Suppose we have a set of observations over timex1,x2,…,xtand want to predict
some future eventyt+1. An inevitable problem arises, because learning a
predictorh(x1,…,xt)ofyt+1is generically intractable due to the size of the
input. To make this problem tractable, what's necessary is a method for
summarizing the relevant information in past observations for the purpose of
prediction in the future. In other words, state is required.Existing
approaches for deriving state have some limitations.Hidden Markov
modelslearned with EM suffer from local minima, use tabular learning
approaches which provide dubious generalization ability, and often require
substantial a.priori specification of the observations.Kalman
FiltersandParticle Filtersare very parametric in the sense that substantial
information must be specified up front.Dynamic Bayesian Networks (graphical
modelsthrough time) require substantial a.priori specification and often
require the solution of difficult computational problems to u</p><p>3 0.65125233 <a title="303-lsi-3" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>Introduction: One of the central concerns of learning is to understand and toprevent
overfitting. Various notion of "function complexity" oftenarise: VC dimension,
Rademacher complexity, comparison classes ofexperts, and program length are
just a few.The term "complexity" to me seems somehow misleading; the terms
nevercapture something that meets my intuitive notion of complexity.
TheBayesian notion clearly captures what's going on. Functions
aren't"complex"- they're just "surprising": we assign to them lowprobability.
Most (all?) complexity notions I know boil downto some (generally loose) bound
on the prior probability of the function.In a sense, "complexity"
fundementally arises because probabilitydistributions must sum to one. You
can't believe in all possibilitiesat the same time, or at least not equally.
Rather you have tocarefully spread the probability mass over the options you'd
like toconsider. Large complexity classes means that beliefs are spreadthinly.
In it's simplest form, this phenom</p><p>4 0.624421 <a title="303-lsi-4" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>5 0.57688594 <a title="303-lsi-5" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for thereductions
tutorialAlina,Bianca, and I are planning to do atICML. Please come, if you are
interested.Many research programs can be thought of as finding and building
new useful abstractions. The running example I'll use islearning
reductionswhere I have experience. The basic abstraction here is that we can
build a learning algorithm capable of solving classification problems up to a
small expected regret. This is used repeatedly to solve more complex
problems.In working on a new abstraction, I think you typically run into many
substantial problems of understanding, which make publishing particularly
difficult.It is difficult to seriously discuss the reason behind or mechanism
for abstraction in a conference paper with small page limits. People rarely
see such discussions and hence have little basis on which to think about new
abstractions. Another difficulty is that when building an abstraction, you
often don't know the right way to</p><p>6 0.51758963 <a title="303-lsi-6" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>7 0.51124603 <a title="303-lsi-7" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>8 0.51028997 <a title="303-lsi-8" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>9 0.50745791 <a title="303-lsi-9" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>10 0.50742584 <a title="303-lsi-10" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>11 0.5038172 <a title="303-lsi-11" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>12 0.49028814 <a title="303-lsi-12" href="../hunch_net-2005/hunch_net-2005-07-10-Thinking_the_Unthought.html">91 hunch net-2005-07-10-Thinking the Unthought</a></p>
<p>13 0.47958839 <a title="303-lsi-13" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>14 0.46146563 <a title="303-lsi-14" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>15 0.46014485 <a title="303-lsi-15" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>16 0.4524478 <a title="303-lsi-16" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>17 0.45038134 <a title="303-lsi-17" href="../hunch_net-2006/hunch_net-2006-09-09-How_to_solve_an_NP_hard_problem_in_quadratic_time.html">206 hunch net-2006-09-09-How to solve an NP hard problem in quadratic time</a></p>
<p>18 0.44718757 <a title="303-lsi-18" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>19 0.44718295 <a title="303-lsi-19" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>20 0.44308105 <a title="303-lsi-20" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.255), (45, 0.043), (74, 0.044), (98, 0.53)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93853807 <a title="303-lda-1" href="../hunch_net-2013/hunch_net-2013-11-21-Ben_Taskar_is_gone.html">491 hunch net-2013-11-21-Ben Taskar is gone</a></p>
<p>Introduction: I was not as personally close toBenasSam, but the level of tragedy is similar
and I can't help but be greatly saddened by the loss.Variousnewsstorieshave
coverage, but the synopsis is that he had a heart attack on Sunday and is
survived by his wife Anat and daughter Aviv. There is discussion of creating a
memorial fund for them, which I hope comes to fruition, and plan to contribute
to.I will remember Ben as someone who thought carefully and comprehensively
about new ways to do things, then fought hard and successfully for what he
believed in. It is an ideal we strive for, that Ben accomplished.Edit:
donationsgo here, and more information ishere.</p><p>same-blog 2 0.90635729 <a title="303-lda-2" href="../hunch_net-2008/hunch_net-2008-06-09-The_Minimum_Sample_Complexity_of_Importance_Weighting.html">303 hunch net-2008-06-09-The Minimum Sample Complexity of Importance Weighting</a></p>
<p>Introduction: This post is about a trick that I learned fromDale Schuurmanswhich has been
repeatedly useful for me over time.The basic trick has to do with importance
weighting for monte carlo integration. Consider the problem of finding:N = Ex
~ Df(x)given samples fromDand knowledge off.Often, we don't have samples
fromDavailable. Instead, we must make do with samples from some other
distributionQ. In that case, we can still often solve the problem, as long as
Q(x) isn't 0 when D(x) is nonzero, using the importance weighting formula:Ex ~
Qf(x) D(x)/Q(x)A basic question is: How many samples fromQare required in
order to estimateNto some precision? In general the convergence rate is not
bounded, becausef(x) D(x)/Q(x)is not bounded given the
assumptions.Nevertheless, there is one special valueQ(x) = f(x) D(x) / Nwhere
the sample complexity turns out to be1, which is typically substantially
better than the sample complexity of the original problem.This observation
underlies the motivation for voluntary</p><p>3 0.80179644 <a title="303-lda-3" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>Introduction: Every year about now hundreds of applicants apply for a research/teaching job
with the timing governed by the university recruitment schedule. This time,
it's my turn--the hat's in the ring, I am a contender, etcâ&euro;Ś What I have heard
is that this year is good in both directions--both an increased supply and an
increased demand for machine learning expertise.I consider this post a bit of
an abuse as it is neither about general research nor machine learning. Please
forgive me this once.My hope is that I will learn about new places interested
in funding basic research--it's easy to imagine that I have overlooked
possibilities.I am not dogmatic about where I end up in any particular way.
Several earlier posts detail what I think of as a good research environment,
so I will avoid a repeat. A few more details seem important:Application. There
is often a tension between basic research and immediate application. This
tension is not as strong as might be expected in my case. As evidence, many of</p><p>4 0.67706925 <a title="303-lda-4" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>Introduction: This is about methods for phrasing and think about the scope of some theorems
in learning theory. The basic claim is that there are several different ways
of quantifying the scope which sound different yet are essentially the
same.For all sequences of examples. This is the standard quantification in
online learning analysis. Standard theorems would say something like "for all
sequences of predictions by experts, the algorithm A will perform almost as
well as the best expert."For all training sets. This is the standard
quantification for boosting analysis such asadaboostormulticlass
boosting.Standard theorems have the form "for all training sets the error rate
inequalities … hold".For all distributions over examples. This is the one that
we have been using for reductions analysis. Standard theorem statements have
the form "For all distributions over examples, the error rate inequalities …
hold".It is not quite true that each of these is equivalent. For example, in
the online learning se</p><p>5 0.66018414 <a title="303-lda-5" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>Introduction: Let me kick things off by posing this question to ML researchers:What do you
think are some important holy grails of machine learning?For example:- "A
classifier with SVM-level performance but much more scalable"- "Practical
confidence bounds (or learning bounds) for classification"- "A reinforcement
learning algorithm that can handle the ___ problem"- "Understanding
theoretically why ___ works so well in practice"etc.I pose this question
because I believe that when goals are stated explicitly and well (thus
providing clarity as well as opening up the problems to more people), rather
than left implicit, they are likely to be achieved much more quickly. I would
also like to know more about the internal goals of the various machine
learning sub-areas (theory, kernel methods, graphical models, reinforcement
learning, etc) as stated by people in these respective areas. This could help
people cross sub-areas.</p><p>6 0.61728466 <a title="303-lda-6" href="../hunch_net-2008/hunch_net-2008-03-23-Interactive_Machine_Learning.html">293 hunch net-2008-03-23-Interactive Machine Learning</a></p>
<p>7 0.50659895 <a title="303-lda-7" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>8 0.47820652 <a title="303-lda-8" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>9 0.47531122 <a title="303-lda-9" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>10 0.47312757 <a title="303-lda-10" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>11 0.46727699 <a title="303-lda-11" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>12 0.46356681 <a title="303-lda-12" href="../hunch_net-2009/hunch_net-2009-12-24-Top_graduates_this_season.html">384 hunch net-2009-12-24-Top graduates this season</a></p>
<p>13 0.4632746 <a title="303-lda-13" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>14 0.46026781 <a title="303-lda-14" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>15 0.45542485 <a title="303-lda-15" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>16 0.45511061 <a title="303-lda-16" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>17 0.45498461 <a title="303-lda-17" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>18 0.45493126 <a title="303-lda-18" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<p>19 0.4506447 <a title="303-lda-19" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>20 0.45019487 <a title="303-lda-20" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
