<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>287 hunch net-2008-01-28-Sufficient Computation</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-287" href="#">hunch_net-2008-287</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>287 hunch net-2008-01-28-Sufficient Computation</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-287-html" href="http://hunch.net/?p=315">html</a></p><p>Introduction: Do we have computer hardware sufficient for AI? This question is difficult to
answer, but here's a try:One way to achieve AI is by simulating a human brain.
A human brain has about 1015synapses which operate at about 102per second
implying about 1017bit ops per second.A modern computer runs at
109cycles/second and operates on 102bits per cycle implying 1011bits processed
per second.The gap here is only 6 orders of magnitude, which can be plausibly
surpassed via cluster machines. For example, theBlueGene/Loperates 105nodes
(one order of magnitude short). It's peak recorded performance is about
0.5*1015FLOPS which translates to about 1016bit ops per second, which is
nearly 1017.There are many criticisms (both positive and negative) for this
argument.Simulation of a human brain might require substantially more detail.
Perhaps an additional 102is required per neuron.We may not need to simulate a
human brain to achieve AI. There are certainly many examples where we have
been able to design</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This question is difficult to answer, but here's a try:One way to achieve AI is by simulating a human brain. [sent-2, score-0.39]
</p><p>2 A human brain has about 1015synapses which operate at about 102per second implying about 1017bit ops per second. [sent-3, score-1.521]
</p><p>3 A modern computer runs at 109cycles/second and operates on 102bits per cycle implying 1011bits processed per second. [sent-4, score-1.497]
</p><p>4 The gap here is only 6 orders of magnitude, which can be plausibly surpassed via cluster machines. [sent-5, score-0.373]
</p><p>5 For example, theBlueGene/Loperates 105nodes (one order of magnitude short). [sent-6, score-0.179]
</p><p>6 5*1015FLOPS which translates to about 1016bit ops per second, which is nearly 1017. [sent-8, score-0.837]
</p><p>7 There are many criticisms (both positive and negative) for this argument. [sent-9, score-0.199]
</p><p>8 Simulation of a human brain might require substantially more detail. [sent-10, score-0.533]
</p><p>9 We may not need to simulate a human brain to achieve AI. [sent-12, score-0.785]
</p><p>10 There are certainly many examples where we have been able to design systems that work much better than evolved systems. [sent-13, score-0.226]
</p><p>11 The internet can be viewed as a supercluster with 109or so CPUs, easily satisfying the computational requirements. [sent-14, score-0.357]
</p><p>12 Satisfying the computational requirement is not enough--bandwidth and latency requirements must also be satisfied. [sent-15, score-0.434]
</p><p>13 These sorts of order-of-magnitude calculations appear sloppy, but they work out a remarkable number of timeswhen tested elsewhere. [sent-16, score-0.517]
</p><p>14 Even with sufficient harrdware, we are missing a vital ingredient: knowing how to do things. [sent-18, score-0.414]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('per', 0.326), ('ops', 0.306), ('brain', 0.269), ('human', 0.264), ('magnitude', 0.179), ('ai', 0.169), ('implying', 0.145), ('cpus', 0.136), ('cycle', 0.136), ('calculations', 0.136), ('evolved', 0.136), ('processed', 0.136), ('sufficient', 0.135), ('achieve', 0.126), ('ingredient', 0.126), ('simulate', 0.126), ('peak', 0.126), ('translates', 0.126), ('computer', 0.121), ('operates', 0.119), ('hardware', 0.119), ('requirement', 0.119), ('criticisms', 0.119), ('orders', 0.113), ('recorded', 0.113), ('second', 0.112), ('remarkable', 0.109), ('vital', 0.109), ('latency', 0.105), ('requirements', 0.105), ('computational', 0.105), ('runs', 0.102), ('operate', 0.099), ('gap', 0.096), ('tested', 0.096), ('satisfying', 0.096), ('knowing', 0.092), ('work', 0.09), ('surprised', 0.09), ('cluster', 0.088), ('sorts', 0.086), ('modern', 0.086), ('viewed', 0.083), ('positive', 0.08), ('nearly', 0.079), ('negative', 0.078), ('missing', 0.078), ('plausibly', 0.076), ('internet', 0.073), ('additional', 0.072)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="287-tfidf-1" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>Introduction: Do we have computer hardware sufficient for AI? This question is difficult to
answer, but here's a try:One way to achieve AI is by simulating a human brain.
A human brain has about 1015synapses which operate at about 102per second
implying about 1017bit ops per second.A modern computer runs at
109cycles/second and operates on 102bits per cycle implying 1011bits processed
per second.The gap here is only 6 orders of magnitude, which can be plausibly
surpassed via cluster machines. For example, theBlueGene/Loperates 105nodes
(one order of magnitude short). It's peak recorded performance is about
0.5*1015FLOPS which translates to about 1016bit ops per second, which is
nearly 1017.There are many criticisms (both positive and negative) for this
argument.Simulation of a human brain might require substantially more detail.
Perhaps an additional 102is required per neuron.We may not need to simulate a
human brain to achieve AI. There are certainly many examples where we have
been able to design</p><p>2 0.14939937 <a title="287-tfidf-2" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>Introduction: Normally I do not blog, but John kindly invited me to do so. Since
computability issues play a major role in Artificial Intelligence and Machine
Learning, I would like to take the opportunity to comment on that and raise
some questions.The general attitude is that AI is about finding efficient
smart algorithms. For large parts of machine learning, the same attitude is
not too dangerous. If you want to concentrate on conceptual problems, simply
become a statistician. There is no analogous escape for modern research on AI
(as opposed toGOFAIrooted in logic).Let me show by analogy whylimiting
research to computational questions is bad for any field.Except in computer
science, computational aspects play little role in the development
offundamentaltheories: Consider e.g. set theory with axiom of choice,
foundations of logic, exact/full minimax for zero-sum games, quantum (field)
theory, string theory, â&euro;Ś Indeed, at least in physics, every new fundamental
theory seems to be less computable th</p><p>3 0.13962027 <a title="287-tfidf-3" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>Introduction: Dan Reevesintroduced me toMichael Vassarwho ran theSingularity Summitand
educated me a bit on the subject of AI safety which theSingularity
Institutehassmall grants for.I still believe thatinterstellar space travel is
necessary for long term civilization survival, and the AI is necessary for
interstellar space travel. On these grounds alone, we could judge that
developing AI is much more safe than not. Nevertheless, there is a basic
reasonable fear, as expressed by some commenters, that AI could go bad.A basic
scenario starts with someone inventing an AI and telling it to make as much
money as possible. The AI promptly starts trading in various markets to make
money. To improve, it crafts a virus that takes over most of the world's
computers using it as a surveillance network so that it can always make the
right decision. The AI also branches out into any form of distance work,
taking over the entire outsourcing process for all jobs that are entirely
digital. To further improve, the AI</p><p>4 0.1233696 <a title="287-tfidf-4" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>Introduction: I recently had fun discussions with bothVikash MansinghkaandThomas Breuelabout
approaching AI with machine learning. The general interest in taking a crack
at AI with machine learning seems to be rising on many fronts
includingDARPA.As a matter of history, there was a great deal of interest in
AI which died down before I began research. There remain many projects and
conferences spawned in this earlier AI wave, as well as a good bit of
experience about what did not work, or at least did not work yet. Here are a
few examples of failure modes that people seem to run into:Supply/Product
confusion. Sometimes we think "Intelligences use X, so I'll create X and have
an Intelligence." An example of this is theCyc Projectwhich inspires some
people as "intelligences use ontologies, so I'll create an ontology and a
system using it to have an Intelligence." The flaw here is that
Intelligencescreateontologies, which they use, and without the ability to
create ontologies you don't have an Intellige</p><p>5 0.10781479 <a title="287-tfidf-5" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>Introduction: Watsonconvincingly beat the best championJeopardy!players. The apparent
significance of this varies hugely, depending on your background knowledge
about the related machine learning, NLP, and search technology. For a random
person, this might seem evidence of serious machine intelligence, while for
people working on the system itself, it probably seems like a reasonably good
assemblage of existing technologies with several twists to make the entire
system work.Above all, I think we should congratulate the people who managed
to put together and execute this project--many years of effort by a diverse
set of highly skilled people were needed to make this happen. In academia,
it's pretty difficult for one professor to assemble that quantity of talent,
and in industry it's rarely the case that such a capable group has both a
worthwhile project and the support needed to pursue something like this for
several years before success.Alinainvited me to the Jeopardy watching party
atIBM, which was</p><p>6 0.10061344 <a title="287-tfidf-6" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>7 0.095992699 <a title="287-tfidf-7" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>8 0.091968991 <a title="287-tfidf-8" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>9 0.091557994 <a title="287-tfidf-9" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>10 0.091300078 <a title="287-tfidf-10" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>11 0.089469895 <a title="287-tfidf-11" href="../hunch_net-2006/hunch_net-2006-02-27-The_Peekaboom_Dataset.html">159 hunch net-2006-02-27-The Peekaboom Dataset</a></p>
<p>12 0.087902389 <a title="287-tfidf-12" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>13 0.087645106 <a title="287-tfidf-13" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>14 0.086716413 <a title="287-tfidf-14" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>15 0.085441567 <a title="287-tfidf-15" href="../hunch_net-2011/hunch_net-2011-12-13-Vowpal_Wabbit_version_6.1_%26%23038%3B_the_NIPS_tutorial.html">451 hunch net-2011-12-13-Vowpal Wabbit version 6.1 &#038; the NIPS tutorial</a></p>
<p>16 0.084753156 <a title="287-tfidf-16" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>17 0.082503892 <a title="287-tfidf-17" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>18 0.08185032 <a title="287-tfidf-18" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>19 0.081846505 <a title="287-tfidf-19" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>20 0.080728702 <a title="287-tfidf-20" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.148), (1, -0.027), (2, 0.067), (3, -0.077), (4, -0.01), (5, 0.077), (6, -0.023), (7, 0.026), (8, 0.027), (9, 0.071), (10, -0.002), (11, 0.018), (12, 0.055), (13, -0.104), (14, 0.127), (15, 0.052), (16, -0.018), (17, -0.013), (18, -0.059), (19, -0.042), (20, -0.063), (21, 0.138), (22, -0.095), (23, 0.077), (24, 0.047), (25, -0.059), (26, 0.078), (27, -0.055), (28, 0.048), (29, 0.007), (30, 0.038), (31, 0.096), (32, 0.022), (33, 0.019), (34, -0.087), (35, 0.057), (36, 0.013), (37, -0.038), (38, -0.029), (39, -0.056), (40, 0.007), (41, -0.037), (42, -0.005), (43, -0.095), (44, 0.123), (45, -0.022), (46, 0.043), (47, 0.007), (48, 0.036), (49, 0.013)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98173898 <a title="287-lsi-1" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>Introduction: Do we have computer hardware sufficient for AI? This question is difficult to
answer, but here's a try:One way to achieve AI is by simulating a human brain.
A human brain has about 1015synapses which operate at about 102per second
implying about 1017bit ops per second.A modern computer runs at
109cycles/second and operates on 102bits per cycle implying 1011bits processed
per second.The gap here is only 6 orders of magnitude, which can be plausibly
surpassed via cluster machines. For example, theBlueGene/Loperates 105nodes
(one order of magnitude short). It's peak recorded performance is about
0.5*1015FLOPS which translates to about 1016bit ops per second, which is
nearly 1017.There are many criticisms (both positive and negative) for this
argument.Simulation of a human brain might require substantially more detail.
Perhaps an additional 102is required per neuron.We may not need to simulate a
human brain to achieve AI. There are certainly many examples where we have
been able to design</p><p>2 0.81500369 <a title="287-lsi-2" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>Introduction: Dan Reevesintroduced me toMichael Vassarwho ran theSingularity Summitand
educated me a bit on the subject of AI safety which theSingularity
Institutehassmall grants for.I still believe thatinterstellar space travel is
necessary for long term civilization survival, and the AI is necessary for
interstellar space travel. On these grounds alone, we could judge that
developing AI is much more safe than not. Nevertheless, there is a basic
reasonable fear, as expressed by some commenters, that AI could go bad.A basic
scenario starts with someone inventing an AI and telling it to make as much
money as possible. The AI promptly starts trading in various markets to make
money. To improve, it crafts a virus that takes over most of the world's
computers using it as a surveillance network so that it can always make the
right decision. The AI also branches out into any form of distance work,
taking over the entire outsourcing process for all jobs that are entirely
digital. To further improve, the AI</p><p>3 0.73804784 <a title="287-lsi-3" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>Introduction: Normally I do not blog, but John kindly invited me to do so. Since
computability issues play a major role in Artificial Intelligence and Machine
Learning, I would like to take the opportunity to comment on that and raise
some questions.The general attitude is that AI is about finding efficient
smart algorithms. For large parts of machine learning, the same attitude is
not too dangerous. If you want to concentrate on conceptual problems, simply
become a statistician. There is no analogous escape for modern research on AI
(as opposed toGOFAIrooted in logic).Let me show by analogy whylimiting
research to computational questions is bad for any field.Except in computer
science, computational aspects play little role in the development
offundamentaltheories: Consider e.g. set theory with axiom of choice,
foundations of logic, exact/full minimax for zero-sum games, quantum (field)
theory, string theory, â&euro;Ś Indeed, at least in physics, every new fundamental
theory seems to be less computable th</p><p>4 0.70151341 <a title="287-lsi-4" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>Introduction: I recently had fun discussions with bothVikash MansinghkaandThomas Breuelabout
approaching AI with machine learning. The general interest in taking a crack
at AI with machine learning seems to be rising on many fronts
includingDARPA.As a matter of history, there was a great deal of interest in
AI which died down before I began research. There remain many projects and
conferences spawned in this earlier AI wave, as well as a good bit of
experience about what did not work, or at least did not work yet. Here are a
few examples of failure modes that people seem to run into:Supply/Product
confusion. Sometimes we think "Intelligences use X, so I'll create X and have
an Intelligence." An example of this is theCyc Projectwhich inspires some
people as "intelligences use ontologies, so I'll create an ontology and a
system using it to have an Intelligence." The flaw here is that
Intelligencescreateontologies, which they use, and without the ability to
create ontologies you don't have an Intellige</p><p>5 0.65781993 <a title="287-lsi-5" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>Introduction: In the AI-related parts of machine learning, it is often tempting to examine
howyoudo things in order to imagine how a machine should do things. This is
introspection, and it can easily go awry. I will call introspection gone awry
introspectionism.Introspectionism is almost unique to AI (and the AI-related
parts of machine learning) and it can lead to huge wasted effort in research.
It's easiest to show how introspectionism arises by an example.Suppose we want
to solve the problem of navigating a robot from point A to point B given a
camera. Then, the following research action plan might seem natural when you
examine your own capabilities:Build an edge detector for still images.Build an
object recognition system given the edge detector.Build a system to predict
distance and orientation to objects given the object recognition system.Build
a system to plan a path through the scene you construct from {object
identification, distance, orientation} predictions.As you execute the above,
cons</p><p>6 0.61386782 <a title="287-lsi-6" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>7 0.54104805 <a title="287-lsi-7" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>8 0.5082438 <a title="287-lsi-8" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>9 0.49453503 <a title="287-lsi-9" href="../hunch_net-2005/hunch_net-2005-11-05-The_design_of_a_computing_cluster.html">128 hunch net-2005-11-05-The design of a computing cluster</a></p>
<p>10 0.49094036 <a title="287-lsi-10" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>11 0.42593449 <a title="287-lsi-11" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>12 0.41677809 <a title="287-lsi-12" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>13 0.41409448 <a title="287-lsi-13" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>14 0.41105855 <a title="287-lsi-14" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>15 0.39801595 <a title="287-lsi-15" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>16 0.39718723 <a title="287-lsi-16" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>17 0.37346765 <a title="287-lsi-17" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>18 0.37227884 <a title="287-lsi-18" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>19 0.37090892 <a title="287-lsi-19" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>20 0.35542551 <a title="287-lsi-20" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.019), (42, 0.199), (68, 0.099), (74, 0.069), (87, 0.424), (95, 0.084)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.799891 <a title="287-lda-1" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>Introduction: Do we have computer hardware sufficient for AI? This question is difficult to
answer, but here's a try:One way to achieve AI is by simulating a human brain.
A human brain has about 1015synapses which operate at about 102per second
implying about 1017bit ops per second.A modern computer runs at
109cycles/second and operates on 102bits per cycle implying 1011bits processed
per second.The gap here is only 6 orders of magnitude, which can be plausibly
surpassed via cluster machines. For example, theBlueGene/Loperates 105nodes
(one order of magnitude short). It's peak recorded performance is about
0.5*1015FLOPS which translates to about 1016bit ops per second, which is
nearly 1017.There are many criticisms (both positive and negative) for this
argument.Simulation of a human brain might require substantially more detail.
Perhaps an additional 102is required per neuron.We may not need to simulate a
human brain to achieve AI. There are certainly many examples where we have
been able to design</p><p>2 0.72320324 <a title="287-lda-2" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>Introduction: YoramandShai'sonline learning tutorialatICMLbrings up a question for me, "Why
use thedual?"The basic setting is learning a weight vectorwiso that the
functionf(x)= sumiwixioptimizes some convex loss function.The functional view
of the dual is that instead of (or in addition to) keeping track ofwiover the
feature space, you keep track of a vectorajover the examples and definewi=
sumjajxji.The above view of duality makes operating in the dual appear
unnecessary, because in the end a weight vector is always used. The tutorial
suggests that thinking about the dual gives a unified algorithmic font for
deriving online learning algorithms. I haven't worked with the dual
representation much myself, but I have seen a few examples where it appears
helpful.NoiseWhen doing online optimization (i.e. online learning where you
are allowed to look at individual examples multiple times), the dual
representation may be helpful in dealing with noisy labels.RatesOne annoyance
of working in the primal spac</p><p>3 0.71745563 <a title="287-lda-3" href="../hunch_net-2005/hunch_net-2005-02-12-ROC_vs._Accuracy_vs._AROC.html">18 hunch net-2005-02-12-ROC vs. Accuracy vs. AROC</a></p>
<p>Introduction: Foster Provostand I discussed the merits of ROC curves vs. accuracy
estimation. Here is a quick summary of our discussion.The "Receiver Operating
Characteristic" (ROC) curve is an alternative to accuracy for the evaluation
of learning algorithms on natural datasets. The ROC curve is acurveand not a
single number statistic. In particular, this means that the comparison of two
algorithms on a dataset does not always produce an obvious order.Accuracy (= 1
- error rate) is a standard method used to evaluate learning algorithms. It is
a single-number summary of performance.AROC is the area under the ROC curve.
It is a single number summary of performance.The comparison of these metrics
is a subtle affair, because in machine learning, they are compared on
different natural datasets. This makes some sense if we accept the hypothesis
"Performance on past learning problems (roughly) predicts performance on
future learning problems."The ROC vs. accuracy discussion is often conflated
with "is the</p><p>4 0.49199426 <a title="287-lda-4" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>Introduction: A loss function is some function which, for any example, takes a prediction
and the correct prediction, and determines how much loss is incurred. (People
sometimes attempt to optimize functions of more than one example such as "area
under the ROC curve" or "harmonic mean of precision and recall".) Typically we
try to find predictors that minimize loss.There seems to be a strong dichotomy
between two views of what "loss" means in learning.Loss is determined by the
problem.Loss is a part of the specification of the learning problem. Examples
of problems specified by the loss function include "binary classification",
"multiclass classification", "importance weighted classification",
"l2regression", etcâ&euro;Ś This is the decision theory view of what loss means, and
the view that I prefer.Loss is determined by the solution.To solve a problem,
you optimize some particular loss functionnotgiven by the problem. Examples of
these loss functions are "hinge loss" (for SVMs), "log loss" (common in
Baye</p><p>5 0.48313144 <a title="287-lda-5" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>Introduction: This is about the hard choices that graduate students must make.The cultural
definition of success in academic research is to:Produce good research which
many other people appreciate.Produce many students who go on to do the
same.There are fundamental reasons why this is success in the local culture.
Good research appreciated by others means access to jobs. Many students
succesful in the same way implies that there are a number of people who think
in a similar way and appreciate your work.In order to graduate, a phd student
must live in an academic culture for a period of several years. It is common
to adopt the culture's definition of success during this time. It's also
common for many phd students discover they are not suited to an academic
research lifestyle. This collision of values and abilities naturally results
in depression.The most fundamental advice when this happens is: change
something. Pick a new advisor. Pick a new research topic. Or leave the program
(and do something el</p><p>6 0.4772023 <a title="287-lda-6" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>7 0.47424024 <a title="287-lda-7" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>8 0.4709219 <a title="287-lda-8" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>9 0.46981072 <a title="287-lda-9" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>10 0.4697786 <a title="287-lda-10" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>11 0.46954542 <a title="287-lda-11" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>12 0.46817535 <a title="287-lda-12" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>13 0.46787545 <a title="287-lda-13" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>14 0.46748698 <a title="287-lda-14" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>15 0.4661063 <a title="287-lda-15" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>16 0.46608561 <a title="287-lda-16" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>17 0.46558797 <a title="287-lda-17" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>18 0.46504149 <a title="287-lda-18" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>19 0.46499634 <a title="287-lda-19" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>20 0.46422982 <a title="287-lda-20" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
