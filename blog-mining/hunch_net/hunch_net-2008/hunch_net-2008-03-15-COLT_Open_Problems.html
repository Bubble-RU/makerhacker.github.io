<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>292 hunch net-2008-03-15-COLT Open Problems</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-292" href="#">hunch_net-2008-292</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>292 hunch net-2008-03-15-COLT Open Problems</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-292-html" href="http://hunch.net/?p=320">html</a></p><p>Introduction: COLT has a  call for open problems  due March 21.  I encourage anyone with a specifiable open problem to write it down and send it in.  Just the effort of specifying an open problem precisely and concisely has been very helpful for my own solutions, and there is a substantial chance others will solve it.  To increase the chance someone will take it up, you can even put a bounty on the solution.  (Perhaps I should raise the  $500 bounty  on the  K-fold cross-validation problem  as it hasnâ&euro;&trade;t yet been solved).</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 COLT has a  call for open problems  due March 21. [sent-1, score-0.586]
</p><p>2 I encourage anyone with a specifiable open problem to write it down and send it in. [sent-2, score-1.228]
</p><p>3 Just the effort of specifying an open problem precisely and concisely has been very helpful for my own solutions, and there is a substantial chance others will solve it. [sent-3, score-1.688]
</p><p>4 To increase the chance someone will take it up, you can even put a bounty on the solution. [sent-4, score-1.322]
</p><p>5 (Perhaps I should raise the  $500 bounty  on the  K-fold cross-validation problem  as it hasnâ&euro;&trade;t yet been solved). [sent-5, score-0.979]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bounty', 0.545), ('open', 0.307), ('specifiable', 0.242), ('concisely', 0.242), ('chance', 0.225), ('raise', 0.224), ('hasn', 0.181), ('increase', 0.163), ('specifying', 0.16), ('send', 0.157), ('precisely', 0.151), ('encourage', 0.151), ('march', 0.148), ('call', 0.146), ('write', 0.139), ('put', 0.137), ('problem', 0.132), ('solutions', 0.125), ('solved', 0.115), ('someone', 0.112), ('effort', 0.11), ('helpful', 0.101), ('anyone', 0.1), ('colt', 0.1), ('others', 0.09), ('substantial', 0.085), ('solve', 0.085), ('due', 0.08), ('take', 0.08), ('yet', 0.078), ('perhaps', 0.075), ('even', 0.06), ('problems', 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="292-tfidf-1" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>Introduction: COLT has a  call for open problems  due March 21.  I encourage anyone with a specifiable open problem to write it down and send it in.  Just the effort of specifying an open problem precisely and concisely has been very helpful for my own solutions, and there is a substantial chance others will solve it.  To increase the chance someone will take it up, you can even put a bounty on the solution.  (Perhaps I should raise the  $500 bounty  on the  K-fold cross-validation problem  as it hasnâ&euro;&trade;t yet been solved).</p><p>2 0.16943486 <a title="292-tfidf-2" href="../hunch_net-2007/hunch_net-2007-11-16-MLSS_2008.html">273 hunch net-2007-11-16-MLSS 2008</a></p>
<p>Introduction: … is in Kioloa, Australia from March 3 to March 14.  It’s a great chance to learn something about Machine Learning and I’ve enjoyed several  previous Machine Learning Summer Schools .
 
The  website has many more details , but registration is open now for the first 80 to sign up.</p><p>3 0.15673554 <a title="292-tfidf-3" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>Introduction: Alina  and  Jake  point out the COLT  Call for Open Questions  due May 11.  In general, this is cool, and worth doing if you can come up with a crisp question.  In my case, I particularly enjoyed  crafting an open question  with precisely a form such that a  critic targeting my papers  would be forced to confront their fallacy or make a case for the reward.  But less esoterically, this is a way to get the attention of some very smart people focused on a problem that really matters, which is the real value.</p><p>4 0.14378303 <a title="292-tfidf-4" href="../hunch_net-2012/hunch_net-2012-03-06-COLT-ICML_Open_Questions_and_ICML_Instructions.html">458 hunch net-2012-03-06-COLT-ICML Open Questions and ICML Instructions</a></p>
<p>Introduction: Sasha  is the  open problems  chair for both  COLT   and   ICML .  Open problems will be presented in a joint session in the evening of the COLT/ICML overlap day.   COLT has a history of open sessions, but this is new for ICML.  If you have a difficult theoretically definable problem in machine learning, consider submitting it for review,  due March 16 .  You’ll benefit three ways: 
  
 The effort of writing down a precise formulation of what you want often helps you understand the nature of the problem. 
 Your problem will be officially published and citable. 
 You might have it solved by some very intelligent bored people. 
  
The general idea could easily be applied to any problem which can be crisply stated with an easily verifiable solution, and we may consider expanding this in later years, but for this year all problems need to be of a theoretical variety.
 
 Joelle  and I (and  Mahdi , and  Laurent ) finished an initial assignment of  Program Committee  and  Area Chairs  to pap</p><p>5 0.13299237 <a title="292-tfidf-5" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pool  and I recently discussed the similarities and differences between academia and open source programming.   
 
Similarities:
  
  Cost profile   Research and programming share approximately the same cost profile: A large upfront effort is required to produce something useful, and then “anyone” can use it.  (The “anyone” is not quite right for either group because only sufficiently technical people could use it.) 
  Wealth profile  A “wealthy” academic or open source programmer is someone who has contributed a lot to other people in research or programs.  Much of academia is a “gift culture”: whoever gives the most is most respected. 
  Problems   Both academia and open source programming suffer from similar problems.
 
 Whether or not (and which) open source program is used are perhaps too-often personality driven rather than driven by capability or usefulness.  Similar phenomena can happen in academia with respect to directions of research. 
 Funding is often a problem for</p><p>6 0.1252861 <a title="292-tfidf-6" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>7 0.10339832 <a title="292-tfidf-7" href="../hunch_net-2005/hunch_net-2005-03-28-Open_Problems_for_Colt.html">47 hunch net-2005-03-28-Open Problems for Colt</a></p>
<p>8 0.10216361 <a title="292-tfidf-8" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>9 0.091029473 <a title="292-tfidf-9" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>10 0.072648786 <a title="292-tfidf-10" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>11 0.072102107 <a title="292-tfidf-11" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>12 0.072047696 <a title="292-tfidf-12" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>13 0.071407482 <a title="292-tfidf-13" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>14 0.070638873 <a title="292-tfidf-14" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>15 0.069676541 <a title="292-tfidf-15" href="../hunch_net-2006/hunch_net-2006-01-25-1_year.html">151 hunch net-2006-01-25-1 year</a></p>
<p>16 0.066744886 <a title="292-tfidf-16" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>17 0.066281877 <a title="292-tfidf-17" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>18 0.06606061 <a title="292-tfidf-18" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>19 0.064840242 <a title="292-tfidf-19" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>20 0.064431772 <a title="292-tfidf-20" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.109), (1, -0.058), (2, -0.049), (3, -0.018), (4, -0.06), (5, -0.045), (6, 0.035), (7, -0.003), (8, -0.041), (9, -0.029), (10, -0.053), (11, -0.005), (12, -0.038), (13, 0.099), (14, 0.075), (15, 0.011), (16, 0.044), (17, -0.066), (18, -0.084), (19, 0.031), (20, -0.111), (21, 0.263), (22, 0.045), (23, -0.123), (24, 0.045), (25, 0.056), (26, -0.015), (27, 0.129), (28, 0.085), (29, 0.082), (30, 0.069), (31, 0.066), (32, 0.048), (33, 0.025), (34, 0.022), (35, -0.076), (36, -0.057), (37, -0.028), (38, 0.074), (39, 0.024), (40, 0.045), (41, 0.007), (42, 0.017), (43, 0.07), (44, -0.019), (45, -0.014), (46, -0.016), (47, 0.044), (48, -0.061), (49, -0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98151547 <a title="292-lsi-1" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>Introduction: COLT has a  call for open problems  due March 21.  I encourage anyone with a specifiable open problem to write it down and send it in.  Just the effort of specifying an open problem precisely and concisely has been very helpful for my own solutions, and there is a substantial chance others will solve it.  To increase the chance someone will take it up, you can even put a bounty on the solution.  (Perhaps I should raise the  $500 bounty  on the  K-fold cross-validation problem  as it hasnâ&euro;&trade;t yet been solved).</p><p>2 0.82385713 <a title="292-lsi-2" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>Introduction: Alina  and  Jake  point out the COLT  Call for Open Questions  due May 11.  In general, this is cool, and worth doing if you can come up with a crisp question.  In my case, I particularly enjoyed  crafting an open question  with precisely a form such that a  critic targeting my papers  would be forced to confront their fallacy or make a case for the reward.  But less esoterically, this is a way to get the attention of some very smart people focused on a problem that really matters, which is the real value.</p><p>3 0.72564262 <a title="292-lsi-3" href="../hunch_net-2012/hunch_net-2012-03-06-COLT-ICML_Open_Questions_and_ICML_Instructions.html">458 hunch net-2012-03-06-COLT-ICML Open Questions and ICML Instructions</a></p>
<p>Introduction: Sasha  is the  open problems  chair for both  COLT   and   ICML .  Open problems will be presented in a joint session in the evening of the COLT/ICML overlap day.   COLT has a history of open sessions, but this is new for ICML.  If you have a difficult theoretically definable problem in machine learning, consider submitting it for review,  due March 16 .  You’ll benefit three ways: 
  
 The effort of writing down a precise formulation of what you want often helps you understand the nature of the problem. 
 Your problem will be officially published and citable. 
 You might have it solved by some very intelligent bored people. 
  
The general idea could easily be applied to any problem which can be crisply stated with an easily verifiable solution, and we may consider expanding this in later years, but for this year all problems need to be of a theoretical variety.
 
 Joelle  and I (and  Mahdi , and  Laurent ) finished an initial assignment of  Program Committee  and  Area Chairs  to pap</p><p>4 0.6839124 <a title="292-lsi-4" href="../hunch_net-2005/hunch_net-2005-03-28-Open_Problems_for_Colt.html">47 hunch net-2005-03-28-Open Problems for Colt</a></p>
<p>Introduction: Adam Klivans  and  Rocco Servedio  are looking for  open (learning theory) problems  for  COLT .  This is a good idea in the same way that the KDDcup challenge is a good idea: crisp problem definitions that anyone can attack yield solutions that advance science.</p><p>5 0.60964137 <a title="292-lsi-5" href="../hunch_net-2007/hunch_net-2007-11-16-MLSS_2008.html">273 hunch net-2007-11-16-MLSS 2008</a></p>
<p>Introduction: … is in Kioloa, Australia from March 3 to March 14.  It’s a great chance to learn something about Machine Learning and I’ve enjoyed several  previous Machine Learning Summer Schools .
 
The  website has many more details , but registration is open now for the first 80 to sign up.</p><p>6 0.60623091 <a title="292-lsi-6" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>7 0.59140009 <a title="292-lsi-7" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>8 0.50228113 <a title="292-lsi-8" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>9 0.48262033 <a title="292-lsi-9" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>10 0.4427861 <a title="292-lsi-10" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>11 0.42258149 <a title="292-lsi-11" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>12 0.42211586 <a title="292-lsi-12" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>13 0.3847439 <a title="292-lsi-13" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>14 0.37481371 <a title="292-lsi-14" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<p>15 0.36184108 <a title="292-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>16 0.36109161 <a title="292-lsi-16" href="../hunch_net-2011/hunch_net-2011-03-27-Vowpal_Wabbit%2C_v5.1.html">428 hunch net-2011-03-27-Vowpal Wabbit, v5.1</a></p>
<p>17 0.35212255 <a title="292-lsi-17" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>18 0.34281534 <a title="292-lsi-18" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">324 hunch net-2008-11-09-A Healthy  COLT</a></p>
<p>19 0.34225333 <a title="292-lsi-19" href="../hunch_net-2011/hunch_net-2011-01-03-Herman_Goldstine_2011.html">421 hunch net-2011-01-03-Herman Goldstine 2011</a></p>
<p>20 0.33337018 <a title="292-lsi-20" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.074), (30, 0.357), (38, 0.028), (49, 0.051), (53, 0.128), (55, 0.197)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.86434466 <a title="292-lda-1" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>Introduction: COLT has a  call for open problems  due March 21.  I encourage anyone with a specifiable open problem to write it down and send it in.  Just the effort of specifying an open problem precisely and concisely has been very helpful for my own solutions, and there is a substantial chance others will solve it.  To increase the chance someone will take it up, you can even put a bounty on the solution.  (Perhaps I should raise the  $500 bounty  on the  K-fold cross-validation problem  as it hasnâ&euro;&trade;t yet been solved).</p><p>2 0.80973756 <a title="292-lda-2" href="../hunch_net-2009/hunch_net-2009-07-11-Interesting_papers_at_KDD.html">364 hunch net-2009-07-11-Interesting papers at KDD</a></p>
<p>Introduction: I attended  KDD  this year.  The conference has always had a strong grounding in what works based on the  KDDcup , but it has developed a halo of workshops on various subjects.  It seems that KDD has become a place where the economy meets machine learning in a stronger sense than many other conferences.
 
There were several papers that other people might like to take a look at.
  
  Yehuda Koren   Collaborative Filtering with Temporal Dynamics .  This paper describes how to incorporate temporal dynamics into a couple of collaborative filtering approaches.  This was also a best paper award. 
  D. Sculley , Robert Malkin,  Sugato Basu ,  Roberto J. Bayardo ,  Predicting Bounce Rates in Sponsored Search Advertisements .  The basic claim of this paper is that the probability people immediately leave (“bounce”) after clicking on an advertisement is predictable. 
  Frank McSherry  and  Ilya Mironov   Differentially Private Recommender Systems: Building Privacy into the Netflix Prize Contende</p><p>3 0.78921348 <a title="292-lda-3" href="../hunch_net-2006/hunch_net-2006-07-05-more_icml_papers.html">189 hunch net-2006-07-05-more icml papers</a></p>
<p>Introduction: Here are a few other papers I enjoyed from ICML06.
 
Topic Models:
  
   
Dynamic Topic Models  
David Blei, John Lafferty 
A nice model for how topics in LDA type models can evolve over time, 
using a linear dynamical system on the natural parameters and a very 
clever structured variational approximation (in which the mean field 
parameters are pseudo-observations of a virtual LDS). Like all Blei 
papers, he makes it look easy, but it is extremely impressive. 
   
Pachinko Allocation  
Wei Li, Andrew McCallum 
A very elegant (but computationally challenging) model which induces 
correlation amongst topics using a multi-level DAG whose interior nodes 
are “super-topics” and “sub-topics” and whose leaves are the 
vocabulary words. Makes the slumbering monster of structure learning stir. 
  
Sequence Analysis (I missed these talks since I was chairing another session)
  
   
Online Decoding of Markov Models with Latency Constraints  
Mukund Narasimhan, Paul Viola, Michael Shilman 
An “a</p><p>4 0.75270969 <a title="292-lda-4" href="../hunch_net-2006/hunch_net-2006-02-04-Research_Budget_Changes.html">154 hunch net-2006-02-04-Research Budget Changes</a></p>
<p>Introduction: The announcement of an increase in funding for basic research in the US is encouraging.   There is some discussion of this at the  Computing Research Policy  blog.  
 
One part of this discussion has a graph of NSF funding over time, presumably in dollar budgets.  I donâ&euro;&trade;t believe that dollar budgets are the right way to judge the impact of funding changes on researchers.  A better way to judge seems to be in terms of dollar budget divided by GDP which provides a measure of the relative emphasis on research.
 
  
 
This graph was assembled by dividing the  NSF budget  by the  US GDP .  For 2005 GDP, I used the  current estimate  and for 2006 and 2007 assumed an increase by a factor of 1.04 per year.  The 2007 number also uses the requested 2007 budget which is certain to change.
 
This graph makes it clear why researchers were upset: research funding emphasis has fallen for 3 years in a row.  The reality has been significantly more severe due to  DARPA decreasing funding  and industrial</p><p>5 0.73046887 <a title="292-lda-5" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>Introduction: At  KDD  I enjoyed  Stephen Boyd ‘s invited talk about optimization quite a bit.  However, the most interesting talk for me was  David Haussler ‘s.  His talk started out with a formidable load of biological complexity.  About half-way through you start wondering, “can this be used to help with cancer?”  And at the end he connects it directly to use with a call to arms for the audience: cure cancer.  The core thesis here is that cancer is a complex set of diseases which can be distentangled via genetic assays, allowing attacking the specific signature of individual cancers.  However, the data quantity and complex dependencies within the data require systematic and relatively automatic prediction and analysis algorithms of the kind that we are best familiar with.
 
Some of the papers which interested me are:
  
  Kai-Wei Chang  and  Dan Roth ,  Selective Block Minimization for Faster Convergence of Limited Memory Large-Scale Linear Models , which is about effectively using a hard-example</p><p>6 0.68155688 <a title="292-lda-6" href="../hunch_net-2012/hunch_net-2012-02-20-Berkeley_Streaming_Data_Workshop.html">455 hunch net-2012-02-20-Berkeley Streaming Data Workshop</a></p>
<p>7 0.54696649 <a title="292-lda-7" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>8 0.53676701 <a title="292-lda-8" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>9 0.51490223 <a title="292-lda-9" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>10 0.50631654 <a title="292-lda-10" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>11 0.49835438 <a title="292-lda-11" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>12 0.49692681 <a title="292-lda-12" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>13 0.49602085 <a title="292-lda-13" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>14 0.49521217 <a title="292-lda-14" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>15 0.48919255 <a title="292-lda-15" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>16 0.48741797 <a title="292-lda-16" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>17 0.48693532 <a title="292-lda-17" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>18 0.47968596 <a title="292-lda-18" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>19 0.47908461 <a title="292-lda-19" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>20 0.47609136 <a title="292-lda-20" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
