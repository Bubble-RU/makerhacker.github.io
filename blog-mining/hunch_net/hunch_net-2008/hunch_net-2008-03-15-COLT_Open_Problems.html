<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>292 hunch net-2008-03-15-COLT Open Problems</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-292" href="#">hunch_net-2008-292</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>292 hunch net-2008-03-15-COLT Open Problems</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-292-html" href="http://hunch.net/?p=320">html</a></p><p>Introduction: COLT has acall for open problemsdue March 21. I encourage anyone with a
specifiable open problem to write it down and send it in. Just the effort of
specifying an open problem precisely and concisely has been very helpful for
my own solutions, and there is a substantial chance others will solve it. To
increase the chance someone will take it up, you can even put a bounty on the
solution. (Perhaps I should raise the$500 bountyon theK-fold cross-validation
problemas it hasn't yet been solved).</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I encourage anyone with a specifiable open problem to write it down and send it in. [sent-2, score-1.485]
</p><p>2 Just the effort of specifying an open problem precisely and concisely has been very helpful for my own solutions, and there is a substantial chance others will solve it. [sent-3, score-2.058]
</p><p>3 To increase the chance someone will take it up, you can even put a bounty on the solution. [sent-4, score-0.97]
</p><p>4 (Perhaps I should raise the$500 bountyon theK-fold cross-validation problemas it hasn't yet been solved). [sent-5, score-0.373]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('open', 0.39), ('specifiable', 0.299), ('concisely', 0.299), ('chance', 0.279), ('raise', 0.277), ('march', 0.207), ('specifying', 0.202), ('increase', 0.202), ('send', 0.193), ('precisely', 0.186), ('encourage', 0.186), ('write', 0.177), ('put', 0.171), ('colt', 0.158), ('solutions', 0.156), ('solved', 0.142), ('someone', 0.142), ('effort', 0.136), ('anyone', 0.127), ('helpful', 0.127), ('others', 0.116), ('problem', 0.113), ('substantial', 0.105), ('solve', 0.105), ('take', 0.1), ('perhaps', 0.096), ('yet', 0.096), ('even', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="292-tfidf-1" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>Introduction: COLT has acall for open problemsdue March 21. I encourage anyone with a
specifiable open problem to write it down and send it in. Just the effort of
specifying an open problem precisely and concisely has been very helpful for
my own solutions, and there is a substantial chance others will solve it. To
increase the chance someone will take it up, you can even put a bounty on the
solution. (Perhaps I should raise the$500 bountyon theK-fold cross-validation
problemas it hasn't yet been solved).</p><p>2 0.25108525 <a title="292-tfidf-2" href="../hunch_net-2007/hunch_net-2007-11-16-MLSS_2008.html">273 hunch net-2007-11-16-MLSS 2008</a></p>
<p>Introduction: â&euro;Ś is in Kioloa, Australia from March 3 to March 14. It's a great chance to
learn something about Machine Learning and I've enjoyed severalprevious
Machine Learning Summer Schools.Thewebsite has many more details, but
registration is open now for the first 80 to sign up.</p><p>3 0.16246583 <a title="292-tfidf-3" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pooland I recently discussed the similarities and differences between
academia and open source programming.Similarities:Cost profileResearch and
programming share approximately the same cost profile: A large upfront effort
is required to produce something useful, and then "anyone" can use it. (The
"anyone" is not quite right for either group because only sufficiently
technical people could use it.)Wealth profileA "wealthy" academic or open
source programmer is someone who has contributed a lot to other people in
research or programs. Much of academia is a "gift culture": whoever gives the
most is most respected.ProblemsBoth academia and open source programming
suffer from similar problems.Whether or not (and which) open source program is
used are perhaps too-often personality driven rather than driven by capability
or usefulness. Similar phenomena can happen in academia with respect to
directions of research.Funding is often a problem for both groups. Academics
often invest many</p><p>4 0.15879694 <a title="292-tfidf-4" href="../hunch_net-2012/hunch_net-2012-03-06-COLT-ICML_Open_Questions_and_ICML_Instructions.html">458 hunch net-2012-03-06-COLT-ICML Open Questions and ICML Instructions</a></p>
<p>Introduction: Sashais theopen problemschair for bothCOLTandICML. Open problems will be
presented in a joint session in the evening of the COLT/ICML overlap day. COLT
has a history of open sessions, but this is new for ICML. If you have a
difficult theoretically definable problem in machine learning, consider
submitting it for review,due March 16. You'll benefit three ways:The effort of
writing down a precise formulation of what you want often helps you understand
the nature of the problem.Your problem will be officially published and
citable.You might have it solved by some very intelligent bored people.The
general idea could easily be applied to any problem which can be crisply
stated with an easily verifiable solution, and we may consider expanding this
in later years, but for this year all problems need to be of a theoretical
variety.Joelleand I (andMahdi, andLaurent) finished an initial assignment
ofProgram CommitteeandArea Chairsto papers. We'll be updatinginstructions for
the PCand ACsas we fi</p><p>5 0.1561113 <a title="292-tfidf-5" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>Introduction: AlinaandJakepoint out the COLTCall for Open Questionsdue May 11. In general,
this is cool, and worth doing if you can come up with a crisp question. In my
case, I particularly enjoyedcrafting an open questionwith precisely a form
such that acritic targeting my paperswould be forced to confront their fallacy
or make a case for the reward. But less esoterically, this is a way to get the
attention of some very smart people focused on a problem that really matters,
which is the real value.</p><p>6 0.14277324 <a title="292-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>7 0.12171558 <a title="292-tfidf-7" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>8 0.10170105 <a title="292-tfidf-8" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>9 0.099031962 <a title="292-tfidf-9" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>10 0.098473944 <a title="292-tfidf-10" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>11 0.08893916 <a title="292-tfidf-11" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>12 0.08798863 <a title="292-tfidf-12" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>13 0.08701399 <a title="292-tfidf-13" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>14 0.086574093 <a title="292-tfidf-14" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>15 0.086019136 <a title="292-tfidf-15" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>16 0.081662878 <a title="292-tfidf-16" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>17 0.081485003 <a title="292-tfidf-17" href="../hunch_net-2008/hunch_net-2008-11-26-Efficient_Reinforcement_Learning_in_MDPs.html">328 hunch net-2008-11-26-Efficient Reinforcement Learning in MDPs</a></p>
<p>18 0.081285 <a title="292-tfidf-18" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<p>19 0.080243461 <a title="292-tfidf-19" href="../hunch_net-2006/hunch_net-2006-01-25-1_year.html">151 hunch net-2006-01-25-1 year</a></p>
<p>20 0.078719132 <a title="292-tfidf-20" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.118), (1, 0.059), (2, 0.091), (3, 0.023), (4, 0.068), (5, -0.054), (6, 0.021), (7, 0.017), (8, 0.102), (9, 0.009), (10, -0.026), (11, -0.165), (12, 0.123), (13, 0.179), (14, -0.108), (15, -0.063), (16, 0.036), (17, -0.141), (18, 0.097), (19, 0.102), (20, -0.18), (21, 0.184), (22, -0.111), (23, 0.001), (24, 0.048), (25, 0.028), (26, -0.01), (27, -0.026), (28, -0.127), (29, -0.039), (30, -0.005), (31, -0.16), (32, 0.1), (33, -0.026), (34, 0.045), (35, -0.025), (36, 0.03), (37, 0.066), (38, 0.005), (39, 0.04), (40, -0.067), (41, -0.002), (42, -0.074), (43, -0.006), (44, -0.005), (45, 0.097), (46, 0.057), (47, 0.007), (48, -0.031), (49, 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98772478 <a title="292-lsi-1" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>Introduction: COLT has acall for open problemsdue March 21. I encourage anyone with a
specifiable open problem to write it down and send it in. Just the effort of
specifying an open problem precisely and concisely has been very helpful for
my own solutions, and there is a substantial chance others will solve it. To
increase the chance someone will take it up, you can even put a bounty on the
solution. (Perhaps I should raise the$500 bountyon theK-fold cross-validation
problemas it hasn't yet been solved).</p><p>2 0.73567289 <a title="292-lsi-2" href="../hunch_net-2012/hunch_net-2012-03-06-COLT-ICML_Open_Questions_and_ICML_Instructions.html">458 hunch net-2012-03-06-COLT-ICML Open Questions and ICML Instructions</a></p>
<p>Introduction: Sashais theopen problemschair for bothCOLTandICML. Open problems will be
presented in a joint session in the evening of the COLT/ICML overlap day. COLT
has a history of open sessions, but this is new for ICML. If you have a
difficult theoretically definable problem in machine learning, consider
submitting it for review,due March 16. You'll benefit three ways:The effort of
writing down a precise formulation of what you want often helps you understand
the nature of the problem.Your problem will be officially published and
citable.You might have it solved by some very intelligent bored people.The
general idea could easily be applied to any problem which can be crisply
stated with an easily verifiable solution, and we may consider expanding this
in later years, but for this year all problems need to be of a theoretical
variety.Joelleand I (andMahdi, andLaurent) finished an initial assignment
ofProgram CommitteeandArea Chairsto papers. We'll be updatinginstructions for
the PCand ACsas we fi</p><p>3 0.64181942 <a title="292-lsi-3" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>Introduction: AlinaandJakepoint out the COLTCall for Open Questionsdue May 11. In general,
this is cool, and worth doing if you can come up with a crisp question. In my
case, I particularly enjoyedcrafting an open questionwith precisely a form
such that acritic targeting my paperswould be forced to confront their fallacy
or make a case for the reward. But less esoterically, this is a way to get the
attention of some very smart people focused on a problem that really matters,
which is the real value.</p><p>4 0.61563045 <a title="292-lsi-4" href="../hunch_net-2007/hunch_net-2007-11-16-MLSS_2008.html">273 hunch net-2007-11-16-MLSS 2008</a></p>
<p>Introduction: â&euro;Ś is in Kioloa, Australia from March 3 to March 14. It's a great chance to
learn something about Machine Learning and I've enjoyed severalprevious
Machine Learning Summer Schools.Thewebsite has many more details, but
registration is open now for the first 80 to sign up.</p><p>5 0.61390764 <a title="292-lsi-5" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pooland I recently discussed the similarities and differences between
academia and open source programming.Similarities:Cost profileResearch and
programming share approximately the same cost profile: A large upfront effort
is required to produce something useful, and then "anyone" can use it. (The
"anyone" is not quite right for either group because only sufficiently
technical people could use it.)Wealth profileA "wealthy" academic or open
source programmer is someone who has contributed a lot to other people in
research or programs. Much of academia is a "gift culture": whoever gives the
most is most respected.ProblemsBoth academia and open source programming
suffer from similar problems.Whether or not (and which) open source program is
used are perhaps too-often personality driven rather than driven by capability
or usefulness. Similar phenomena can happen in academia with respect to
directions of research.Funding is often a problem for both groups. Academics
often invest many</p><p>6 0.47706082 <a title="292-lsi-6" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>7 0.45131746 <a title="292-lsi-7" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>8 0.4467954 <a title="292-lsi-8" href="../hunch_net-2011/hunch_net-2011-03-27-Vowpal_Wabbit%2C_v5.1.html">428 hunch net-2011-03-27-Vowpal Wabbit, v5.1</a></p>
<p>9 0.44616905 <a title="292-lsi-9" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>10 0.42683196 <a title="292-lsi-10" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>11 0.39995813 <a title="292-lsi-11" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>12 0.39602417 <a title="292-lsi-12" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>13 0.37239352 <a title="292-lsi-13" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<p>14 0.37022078 <a title="292-lsi-14" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>15 0.36896104 <a title="292-lsi-15" href="../hunch_net-2008/hunch_net-2008-11-26-Efficient_Reinforcement_Learning_in_MDPs.html">328 hunch net-2008-11-26-Efficient Reinforcement Learning in MDPs</a></p>
<p>16 0.36771527 <a title="292-lsi-16" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>17 0.35284323 <a title="292-lsi-17" href="../hunch_net-2005/hunch_net-2005-03-28-Open_Problems_for_Colt.html">47 hunch net-2005-03-28-Open Problems for Colt</a></p>
<p>18 0.34382391 <a title="292-lsi-18" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>19 0.34239733 <a title="292-lsi-19" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>20 0.34229255 <a title="292-lsi-20" href="../hunch_net-2011/hunch_net-2011-02-25-Yahoo%21_Machine_Learning_grant_due_March_11.html">425 hunch net-2011-02-25-Yahoo! Machine Learning grant due March 11</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.242), (74, 0.158), (95, 0.055), (97, 0.38)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.87999523 <a title="292-lda-1" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>Introduction: The competitors for theNetflix Prizeare tantalizingly close winning the
million dollar prize. This year,BellKorandCommendo Researchsent a combined
solution that won theprogress prize. Reading thewriteups2is instructive.
Several aspects of solutions are taken for granted including stochastic
gradient descent, ensemble prediction, and targeting residuals (a form of
boosting). Relatively to last year, it appears that many approaches have added
parameterizations, especially for the purpose of modeling through time.The big
question is: will they make the big prize? At this point, the level of
complexity in entering the competition is prohibitive, so perhaps only the
existing competitors will continue to try. (This equation might change
drastically if the teams open source their existing solutions, including
parameter settings.) One fear is that the progress is asymptoting on the wrong
side of the 10% threshold. In the first year, the teams progressed through
84.3% of the 10% gap, and in the</p><p>2 0.83829892 <a title="292-lda-2" href="../hunch_net-2012/hunch_net-2012-02-24-ICML%2B50%25.html">456 hunch net-2012-02-24-ICML+50%</a></p>
<p>Introduction: TheICMLpaper deadline has passed.Joelleand I were surprised to see the number
of submissions jump from last year by about 50% to around 900 submissions. A
tiny portion of these are immediate rejects(*), so this is a much larger set
of papers than expected. The number of workshop submissions also doubled
compared to last year, so ICML may grow significantly this year, if we can
manage to handle the load well. The prospect of making 900 good decisions is
fundamentally daunting, and success will rely heavily on theprogram
committeeandarea chairsat this point.For those who want to rubberneck a bit
more, here's a breakdown of submissions by primary topic of submitted
papers:66 Reinforcement Learning 52 Supervised Learning 51 Clustering 46
Kernel Methods 40 Optimization Algorithms 39 Feature Selection and
Dimensionality Reduction 33 Learning Theory 33 Graphical Models 33
Applications 29 Probabilistic Models 29 NN & Deep Learning 26 Transfer and
Multi-Task Learning 25 Online Learning 25 Activ</p><p>same-blog 3 0.835576 <a title="292-lda-3" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>Introduction: COLT has acall for open problemsdue March 21. I encourage anyone with a
specifiable open problem to write it down and send it in. Just the effort of
specifying an open problem precisely and concisely has been very helpful for
my own solutions, and there is a substantial chance others will solve it. To
increase the chance someone will take it up, you can even put a bounty on the
solution. (Perhaps I should raise the$500 bountyon theK-fold cross-validation
problemas it hasn't yet been solved).</p><p>4 0.82866383 <a title="292-lda-4" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>Introduction: Many people in computer science believe that patents are problematic. The
truth is even worse--the patent system in the US is fundamentally broken in
ways that will require much more significant reform thanis being considered
now.The myth of the patent is the following: Patents are a mechanism for
inventors to be compensated according to the value of their inventions while
making the invention available to all. This myth sounds pretty desirable, but
the reality is a strange distortion slowly leading towards collapse.There are
many problems associated with patents, but I would like to focus on just two
of them:Patent TrollsThe way that patents have generally worked over the last
several decades is that they were a tool of large companies. Large companies
would amass a large number of patents and then cross-license each other's
patents--in effect saying "we agree to owe each other nothing". Smaller
companies would sometimes lose in this game, essentially because they didn't
have enough p</p><p>5 0.81778646 <a title="292-lda-5" href="../hunch_net-2006/hunch_net-2006-09-09-How_to_solve_an_NP_hard_problem_in_quadratic_time.html">206 hunch net-2006-09-09-How to solve an NP hard problem in quadratic time</a></p>
<p>Introduction: This title is a lie, but it is a special lie which has a bit of
truth.Ifnplayers each play each other, you have a tournament. How do you order
the players from weakest to strongest?The standard first attempt is "find the
ordering which agrees with the tournament on as many player pairs as
possible". This is called the "minimum feedback arcset" problem in the CS
theory literature and it is a well known NP-hard problem. A basic guarantee
holds for the solution to this problem: if there is some "true" intrinsic
ordering, and the outcome of the tournament disagreesktimes (due to noise for
instance), then the output ordering will disagree with the original ordering
on at most2kedges (and no solution can be better).One standard approach to
tractably solving an NP-hard problem is to find another algorithm with an
approximation guarantee. For example,Don Coppersmith,Lisa FleischerandAtri
Rudraproved thatordering players according to the number of wins is a
5-approximation to the NP-hard proble</p><p>6 0.76054919 <a title="292-lda-6" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>7 0.61091959 <a title="292-lda-7" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>8 0.60259712 <a title="292-lda-8" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>9 0.59771097 <a title="292-lda-9" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>10 0.59760433 <a title="292-lda-10" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>11 0.59661484 <a title="292-lda-11" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>12 0.59468377 <a title="292-lda-12" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>13 0.59369379 <a title="292-lda-13" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>14 0.59292829 <a title="292-lda-14" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>15 0.58978057 <a title="292-lda-15" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>16 0.58964431 <a title="292-lda-16" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>17 0.58961254 <a title="292-lda-17" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>18 0.5889101 <a title="292-lda-18" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>19 0.58820134 <a title="292-lda-19" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>20 0.5873841 <a title="292-lda-20" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
