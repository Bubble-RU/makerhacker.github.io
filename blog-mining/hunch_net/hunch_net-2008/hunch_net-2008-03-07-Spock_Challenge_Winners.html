<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>291 hunch net-2008-03-07-Spock Challenge Winners</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-291" href="#">hunch_net-2008-291</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>291 hunch net-2008-03-07-Spock Challenge Winners</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-291-html" href="http://hunch.net/?p=319">html</a></p><p>Introduction: Thespock challengefor named entity recognition waswonbyBerno Stein, Sven
Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, andMartin Potthast.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('entity', 0.559), ('challengefor', 0.559), ('named', 0.489), ('recognition', 0.369)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="291-tfidf-1" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>Introduction: Thespock challengefor named entity recognition waswonbyBerno Stein, Sven
Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, andMartin Potthast.</p><p>2 0.18136796 <a title="291-tfidf-2" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the companySpockis setting up a$50k entity resolution challenge.
$50k is much less than the Netflix challenge, but it's effectively the same as
Netflix untilsomeone reaches 10%. It's also nice that the Spock challenge has
a short duration. The (visible) test set is of size 25k and the training set
has size 75k.</p><p>3 0.052009616 <a title="291-tfidf-3" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>Introduction: The 201314 isNew York Machine Learning Symposiumis finally happening on March
28th at theNew York Academy of Science. Every invited speaker interests me
personally. They are:Rayid Ghani(Chief Scientist at Obama 2012)Brian
Kingsbury(Speech Recognition @ IBM)Jorge Nocedal(who did LBFGS)We've been
somewhat disorganized in advertising this. As a consequence, anyone who has
not submitted an abstract but would like to do so may send one directly to me
(jl@hunch.net title NYASMLS) by Friday March 14. I will forward them to the
rest of the committee for consideration.</p><p>4 0.05087772 <a title="291-tfidf-4" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>Introduction: Watsonconvincingly beat the best championJeopardy!players. The apparent
significance of this varies hugely, depending on your background knowledge
about the related machine learning, NLP, and search technology. For a random
person, this might seem evidence of serious machine intelligence, while for
people working on the system itself, it probably seems like a reasonably good
assemblage of existing technologies with several twists to make the entire
system work.Above all, I think we should congratulate the people who managed
to put together and execute this project--many years of effort by a diverse
set of highly skilled people were needed to make this happen. In academia,
it's pretty difficult for one professor to assemble that quantity of talent,
and in industry it's rarely the case that such a capable group has both a
worthwhile project and the support needed to pursue something like this for
several years before success.Alinainvited me to the Jeopardy watching party
atIBM, which was</p><p>5 0.047146562 <a title="291-tfidf-5" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>6 0.038607903 <a title="291-tfidf-6" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>7 0.036498945 <a title="291-tfidf-7" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>8 0.036323436 <a title="291-tfidf-8" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>9 0.035507198 <a title="291-tfidf-9" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>10 0.026990985 <a title="291-tfidf-10" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>11 0.026170643 <a title="291-tfidf-11" href="../hunch_net-2010/hunch_net-2010-10-28-NY_ML_Symposium_2010.html">415 hunch net-2010-10-28-NY ML Symposium 2010</a></p>
<p>12 0.024282377 <a title="291-tfidf-12" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>13 0.024051238 <a title="291-tfidf-13" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>14 0.023905898 <a title="291-tfidf-14" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>15 0.020689221 <a title="291-tfidf-15" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>16 0.017008105 <a title="291-tfidf-16" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>17 0.012879465 <a title="291-tfidf-17" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>18 0.010528861 <a title="291-tfidf-18" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>19 0.0 <a title="291-tfidf-19" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<p>20 0.0 <a title="291-tfidf-20" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.007), (1, -0.005), (2, 0.006), (3, -0.002), (4, -0.009), (5, -0.002), (6, -0.003), (7, 0.005), (8, 0.007), (9, -0.023), (10, -0.004), (11, 0.009), (12, -0.009), (13, -0.006), (14, -0.004), (15, 0.029), (16, -0.007), (17, -0.025), (18, -0.03), (19, -0.013), (20, -0.034), (21, 0.055), (22, 0.016), (23, -0.015), (24, -0.03), (25, 0.002), (26, -0.008), (27, 0.015), (28, -0.033), (29, -0.001), (30, 0.009), (31, -0.014), (32, -0.005), (33, -0.008), (34, -0.042), (35, 0.029), (36, -0.017), (37, 0.001), (38, 0.006), (39, 0.024), (40, 0.031), (41, 0.016), (42, -0.018), (43, 0.0), (44, -0.02), (45, 0.107), (46, 0.026), (47, -0.004), (48, 0.007), (49, 0.006)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99707836 <a title="291-lsi-1" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>Introduction: Thespock challengefor named entity recognition waswonbyBerno Stein, Sven
Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, andMartin Potthast.</p><p>2 0.54210645 <a title="291-lsi-2" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the companySpockis setting up a$50k entity resolution challenge.
$50k is much less than the Netflix challenge, but it's effectively the same as
Netflix untilsomeone reaches 10%. It's also nice that the Spock challenge has
a short duration. The (visible) test set is of size 25k and the training set
has size 75k.</p><p>3 0.38404721 <a title="291-lsi-3" href="../hunch_net-2008/hunch_net-2008-11-26-Efficient_Reinforcement_Learning_in_MDPs.html">328 hunch net-2008-11-26-Efficient Reinforcement Learning in MDPs</a></p>
<p>Introduction: Claude Sammutis attempting to put together anEncyclopedia of Machine Learning.
I volunteered to write one article onEfficient RL in MDPs, which I would like
to invite comment on. Is something critical missing?</p><p>4 0.38260874 <a title="291-lsi-4" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<p>Introduction: Rajat Rainapresented a paper on the technique they used for
thePASCALRecognizing Textual Entailmentchallenge."Text entailment" is the
problem of deciding if one sentence implies another. For example the previous
sentence entails:Text entailment is a decision problem.One sentence can imply
another.The challenge was of the form: given an original sentence and another
sentence predict whether there was an entailment. All current techniques for
predicting correctness of an entailment are at the "flail" stage--accuracies
of around 58% where humans could achieve near 100% accuracy, so there is much
room to improve. Apparently, there may be another PASCAL challenge on this
problem in the near future.</p><p>5 0.32498351 <a title="291-lsi-5" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>Introduction: The 201314 isNew York Machine Learning Symposiumis finally happening on March
28th at theNew York Academy of Science. Every invited speaker interests me
personally. They are:Rayid Ghani(Chief Scientist at Obama 2012)Brian
Kingsbury(Speech Recognition @ IBM)Jorge Nocedal(who did LBFGS)We've been
somewhat disorganized in advertising this. As a consequence, anyone who has
not submitted an abstract but would like to do so may send one directly to me
(jl@hunch.net title NYASMLS) by Friday March 14. I will forward them to the
rest of the committee for consideration.</p><p>6 0.32440692 <a title="291-lsi-6" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>7 0.31356287 <a title="291-lsi-7" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>8 0.30114678 <a title="291-lsi-8" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>9 0.29804066 <a title="291-lsi-9" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>10 0.2972258 <a title="291-lsi-10" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>11 0.27228385 <a title="291-lsi-11" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>12 0.2667416 <a title="291-lsi-12" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>13 0.2525177 <a title="291-lsi-13" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>14 0.2494854 <a title="291-lsi-14" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>15 0.239529 <a title="291-lsi-15" href="../hunch_net-2008/hunch_net-2008-02-27-The_Stats_Handicap.html">290 hunch net-2008-02-27-The Stats Handicap</a></p>
<p>16 0.23625728 <a title="291-lsi-16" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>17 0.23073959 <a title="291-lsi-17" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>18 0.22301531 <a title="291-lsi-18" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>19 0.21974555 <a title="291-lsi-19" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>20 0.21314023 <a title="291-lsi-20" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(91, 0.667)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="291-lda-1" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>Introduction: Thespock challengefor named entity recognition waswonbyBerno Stein, Sven
Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, andMartin Potthast.</p><p>2 0.83820611 <a title="291-lda-2" href="../hunch_net-2010/hunch_net-2010-08-21-Rob_Schapire_at_NYC_ML_Meetup.html">405 hunch net-2010-08-21-Rob Schapire at NYC ML Meetup</a></p>
<p>Introduction: I've been wanting to attend theNYC ML Meetupfor some time and hope to make
itnext week on the 25th.Rob Schapireis talking about "Playing Repeated Games",
which in my experience is far more relevant to machine learning than the title
might indicate.</p><p>3 0.59842724 <a title="291-lda-3" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>Introduction: Theresults have been posted, withCMU first,Stanford second, andVirginia Tech
Third.Considering that this was an open event (at least for people in the US),
this was a very strong showing for research at universities (instead of
defense contractors, for example). Some details should become public at
theNIPS workshops.Slashdothas apostwith many comments.</p><p>4 0.43938369 <a title="291-lda-4" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>Introduction: Sham Kakadepoints out that we are missing a bound.Suppose we
havemsamplesxdrawn IID from some distributionD. Through the magic of
exponential moment method we know that:If the range ofxis bounded by an
interval of sizeI, aChernoff/Hoeffding style boundgives us a bound on the
deviations likeO(I/m0.5)(at least in crude form). A proof is on page 9here.If
the range ofxis bounded, and the variance (or a bound on the variance) is
known, thenBennett's boundcan give tighter results (*). This can be a huge
improvment when the true variance small.What's missing here is a bound that
depends on the observed variance rather than a bound on the variance. This
means that many people attempt to use Bennett's bound (incorrectly) by
plugging the observed variance in as the true variance, invalidating the bound
application. Most of the time, they get away with it, but this is a dangerous
move when doing machine learning. In machine learning, we are typically trying
to find a predictor with 0 expected los</p><p>5 0.37298712 <a title="291-lda-5" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>Introduction: This post is about a general technique for problem solving which I've never
seen taught (in full generality), but which I've found very useful.Many
problems in computer science turn out to be discretely difficult. The best
known version of such problems are NP-hard problems, but I mean 'discretely
difficult' in a much more general way, which I only know how to capture by
examples.ERMIn empirical risk minimization, you choose a minimum error rate
classifier from a set of classifiers. This is NP hard for common sets, but it
can be much harder, depending on the set.ExpertsIn the online learning with
experts setting, you try to predict well so as to compete with a set of
(adversarial) experts. Here the alternating quantifiers of you and an
adversary playing out a game can yield a dynamic programming problem that
grows exponentially.Policy IterationThe problem with policy iteration is that
you learn a new policy with respect to an old policy, which implies that
simply adopting the new polic</p><p>6 0.35885048 <a title="291-lda-6" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>7 0.2434409 <a title="291-lda-7" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>8 0.23611395 <a title="291-lda-8" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>9 0.16681895 <a title="291-lda-9" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>10 0.11464453 <a title="291-lda-10" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>11 0.091421619 <a title="291-lda-11" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>12 0.074349232 <a title="291-lda-12" href="../hunch_net-2010/hunch_net-2010-03-26-A_Variance_only_Deviation_Bound.html">392 hunch net-2010-03-26-A Variance only Deviation Bound</a></p>
<p>13 0.07094501 <a title="291-lda-13" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>14 0.054068368 <a title="291-lda-14" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>15 0.052241914 <a title="291-lda-15" href="../hunch_net-2005/hunch_net-2005-05-11-Visa_Casualties.html">69 hunch net-2005-05-11-Visa Casualties</a></p>
<p>16 0.051243361 <a title="291-lda-16" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>17 0.051078212 <a title="291-lda-17" href="../hunch_net-2005/hunch_net-2005-09-20-Workshop_Proposal%3A_Atomic_Learning.html">114 hunch net-2005-09-20-Workshop Proposal: Atomic Learning</a></p>
<p>18 0.049519178 <a title="291-lda-18" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>19 0.045778658 <a title="291-lda-19" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>20 0.041883659 <a title="291-lda-20" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
