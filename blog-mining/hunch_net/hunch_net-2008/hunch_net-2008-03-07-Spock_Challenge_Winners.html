<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>291 hunch net-2008-03-07-Spock Challenge Winners</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-291" href="#">hunch_net-2008-291</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>291 hunch net-2008-03-07-Spock Challenge Winners</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-291-html" href="http://hunch.net/?p=319">html</a></p><p>Introduction: The  spock challenge  for named entity recognition was  won  by  Berno Stein , Sven Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, and  Martin Potthast .</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The  spock challenge  for named entity recognition was  won  by  Berno Stein , Sven Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, and  Martin Potthast . [sent-1, score-2.178]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('entity', 0.474), ('spock', 0.474), ('named', 0.414), ('martin', 0.395), ('recognition', 0.301), ('won', 0.268), ('challenge', 0.247)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="291-tfidf-1" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>Introduction: The  spock challenge  for named entity recognition was  won  by  Berno Stein , Sven Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, and  Martin Potthast .</p><p>2 0.47053963 <a title="291-tfidf-2" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the company  Spock  is setting up a  $50k entity resolution challenge .  $50k is much less than the Netflix challenge, but it’s effectively the same as Netflix until  someone reaches 10% .  It’s also nice that the Spock challenge has a short duration.  The (visible) test set is of size 25k and the training set has size 75k.</p><p>3 0.087646164 <a title="291-tfidf-3" href="../hunch_net-2013/hunch_net-2013-01-01-Deep_Learning_2012.html">477 hunch net-2013-01-01-Deep Learning 2012</a></p>
<p>Introduction: 2012 was a tumultuous year for me, but it was undeniably a great year for deep learning efforts.  Signs of this include:
  
 Winning a  Kaggle competition . 
 Wide adoption of  deep learning for speech recognition . 
 Significant  industry support . 
 Gains in  image   recognition . 
  
This is a rare event in research: a significant capability breakout.  Congratulations are definitely in order for those who managed to achieve it.  At this point, deep learning algorithms seem like a choice undeniably worth investigating for real applications with significant data.</p><p>4 0.06119936 <a title="291-tfidf-4" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>Introduction: Slashdot  points out the  Traffic Prediction Challenge  which looks pretty fun.  The temporal aspect seems to be very common in many real-world problems and somewhat understudied.</p><p>5 0.046146136 <a title="291-tfidf-5" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>Introduction: Watson  convincingly beat the best champion  Jeopardy!  players.  The apparent significance of this varies hugely, depending on your background knowledge about the related machine learning, NLP, and search technology.  For a random person, this might seem evidence of serious machine intelligence, while for people working on the system itself, it probably seems like a reasonably good assemblage of existing technologies with several twists to make the entire system work.
 
Above all, I think we should congratulate the people who managed to put together and execute this project—many years of effort by a diverse set of highly skilled people were needed to make this happen.  In academia, it’s pretty difficult for one professor to assemble that quantity of talent, and in industry it’s rarely the case that such a capable group has both a worthwhile project and the support needed to pursue something like this for several years before success.
 
 Alina  invited me to the Jeopardy watching party</p><p>6 0.04265834 <a title="291-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-28-Open_Problems_for_Colt.html">47 hunch net-2005-03-28-Open Problems for Colt</a></p>
<p>7 0.04250408 <a title="291-tfidf-7" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>8 0.041312821 <a title="291-tfidf-8" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>9 0.040127631 <a title="291-tfidf-9" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>10 0.038912132 <a title="291-tfidf-10" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>11 0.037902612 <a title="291-tfidf-11" href="../hunch_net-2006/hunch_net-2006-07-17-A_Winner.html">197 hunch net-2006-07-17-A Winner</a></p>
<p>12 0.036644999 <a title="291-tfidf-12" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>13 0.035330769 <a title="291-tfidf-13" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<p>14 0.034576032 <a title="291-tfidf-14" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>15 0.032790959 <a title="291-tfidf-15" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>16 0.031887725 <a title="291-tfidf-16" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>17 0.030083297 <a title="291-tfidf-17" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>18 0.029082494 <a title="291-tfidf-18" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>19 0.028804559 <a title="291-tfidf-19" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>20 0.028282743 <a title="291-tfidf-20" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.017), (1, 0.006), (2, -0.02), (3, -0.001), (4, 0.001), (5, 0.004), (6, -0.036), (7, 0.003), (8, -0.013), (9, -0.042), (10, -0.019), (11, 0.108), (12, -0.047), (13, -0.021), (14, -0.005), (15, 0.027), (16, 0.005), (17, 0.006), (18, 0.011), (19, 0.008), (20, -0.12), (21, 0.014), (22, -0.06), (23, -0.08), (24, 0.064), (25, -0.07), (26, -0.004), (27, 0.009), (28, 0.017), (29, 0.013), (30, 0.116), (31, 0.15), (32, 0.052), (33, 0.083), (34, -0.098), (35, -0.075), (36, 0.007), (37, 0.089), (38, -0.027), (39, 0.037), (40, 0.238), (41, -0.079), (42, -0.031), (43, -0.184), (44, -0.136), (45, 0.058), (46, 0.164), (47, -0.102), (48, 0.021), (49, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99915761 <a title="291-lsi-1" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>Introduction: The  spock challenge  for named entity recognition was  won  by  Berno Stein , Sven Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, and  Martin Potthast .</p><p>2 0.89900273 <a title="291-lsi-2" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>Introduction: Apparently, the company  Spock  is setting up a  $50k entity resolution challenge .  $50k is much less than the Netflix challenge, but it’s effectively the same as Netflix until  someone reaches 10% .  It’s also nice that the Spock challenge has a short duration.  The (visible) test set is of size 25k and the training set has size 75k.</p><p>3 0.52040219 <a title="291-lsi-3" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<p>Introduction: Rajat Raina  presented a paper on the technique they used for the  PASCAL   Recognizing Textual Entailment  challenge.  
 
“Text entailment” is the problem of deciding if one sentence implies another.  For example the previous sentence entails: 
  
 Text entailment is a decision problem. 
 One sentence can imply another. 
  
The challenge was of the form: given an original sentence and another sentence predict whether there was an entailment.  All current techniques for predicting correctness of an entailment are at the “flail” stage—accuracies of around 58% where humans could achieve near 100% accuracy, so there is much room to improve.   Apparently, there may be another PASCAL challenge on this problem in the near future.</p><p>4 0.40455478 <a title="291-lsi-4" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>Introduction: A couple security researchers  claim to have cracked the netflix dataset .  The claims of success appear somewhat overstated to me, but the method of attack is valid and could plausibly be substantially improved so as to reveal the movie preferences of a small fraction of Netflix users.
 
The basic idea is to use a heuristic similarity function between ratings in a public database (from IMDB) and an anonymized database (Netflix) to link ratings in the private database to public identities (in IMDB).  They claim to have linked two of a few dozen IMDB users to anonymized netflix users.
 
The claims seem a bit inflated to me, because (a) knowing the IMDB identity isn’t equivalent to knowing the person and (b) the claims of statistical significance are with respect to a model of the world they created (rather than one they created).
 
Overall, this is another example showing that complete  privacy is hard .  It may be worth remembering that there are some substantial benefits from the Netf</p><p>5 0.37404165 <a title="291-lsi-5" href="../hunch_net-2006/hunch_net-2006-04-09-Progress_in_Machine_Translation.html">171 hunch net-2006-04-09-Progress in Machine Translation</a></p>
<p>Introduction: I just visited  ISI  where  Daniel Marcu  and others are working on machine translation.  Apparently, machine translation is rapidly improving.   A particularly dramatic year was 2002->2003 when systems switched from word-based translation to phrase-based translation.  From a (now famous) slide by Charles Wayne at  DARPA  (which funds much of the work on machine translation) here is some anecdotal evidence:
  
 
 2002 
 2003 
 
 
 insistent Wednesday may recurred her trips to Libya tomorrow for flying.

 Cairo 6-4 ( AFP ) – An official announced today in the Egyptian lines company for flying  Tuesday is a company “insistent for flying” may resumed a consideration of a day Wednesday tomorrow her trips to Libya of Security Council decision trace international the imposed ban comment.


 And said the official “the institution sent a speech to Ministry of Foreign Affairs of lifting on Libya air, a situation her recieving replying are so a trip will pull to Libya a morning Wednesday.”

 
 E</p><p>6 0.29739654 <a title="291-lsi-6" href="../hunch_net-2005/hunch_net-2005-03-28-Open_Problems_for_Colt.html">47 hunch net-2005-03-28-Open Problems for Colt</a></p>
<p>7 0.28421101 <a title="291-lsi-7" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>8 0.27991584 <a title="291-lsi-8" href="../hunch_net-2005/hunch_net-2005-04-27-DARPA_project%3A_LAGR.html">63 hunch net-2005-04-27-DARPA project: LAGR</a></p>
<p>9 0.2662369 <a title="291-lsi-9" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>10 0.2634019 <a title="291-lsi-10" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>11 0.25817224 <a title="291-lsi-11" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>12 0.23659782 <a title="291-lsi-12" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>13 0.230399 <a title="291-lsi-13" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>14 0.22090946 <a title="291-lsi-14" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>15 0.21548219 <a title="291-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-27-Antilearning%3A_When_proximity_goes_bad.html">32 hunch net-2005-02-27-Antilearning: When proximity goes bad</a></p>
<p>16 0.20770405 <a title="291-lsi-16" href="../hunch_net-2005/hunch_net-2005-06-22-Languages__of_Learning.html">84 hunch net-2005-06-22-Languages  of Learning</a></p>
<p>17 0.20569669 <a title="291-lsi-17" href="../hunch_net-2010/hunch_net-2010-10-17-Partha_Niyogi_has_died.html">414 hunch net-2010-10-17-Partha Niyogi has died</a></p>
<p>18 0.20170736 <a title="291-lsi-18" href="../hunch_net-2008/hunch_net-2008-01-18-Datasets.html">284 hunch net-2008-01-18-Datasets</a></p>
<p>19 0.20115705 <a title="291-lsi-19" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>20 0.1953903 <a title="291-lsi-20" href="../hunch_net-2006/hunch_net-2006-02-07-Pittsburgh_Mind_Reading_Competition.html">155 hunch net-2006-02-07-Pittsburgh Mind Reading Competition</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(64, 0.723)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="291-lda-1" href="../hunch_net-2008/hunch_net-2008-03-07-Spock_Challenge_Winners.html">291 hunch net-2008-03-07-Spock Challenge Winners</a></p>
<p>Introduction: The  spock challenge  for named entity recognition was  won  by  Berno Stein , Sven Eissen, Tino Rub, Hagen Tonnies, Christof Braeutigam, and  Martin Potthast .</p><p>2 0.6532104 <a title="291-lda-2" href="../hunch_net-2006/hunch_net-2006-02-07-Pittsburgh_Mind_Reading_Competition.html">155 hunch net-2006-02-07-Pittsburgh Mind Reading Competition</a></p>
<p>Introduction: Francisco Pereira  points out a fun  Prediction Competition .   Francisco says:
 
DARPA is sponsoring a competition to analyze data from an unusual functional Magnetic Resonance Imaging experiment. Subjects watch videos inside the scanner while fMRI data are acquired. Unbeknownst to these subjects, the videos have been seen by a panel of other subjects that labeled each instant with labels in categories such as representation (are there tools, body parts, motion, sound), location, presence of actors, emotional content, etc.
 
The challenge is to predict all of these different labels on an instant-by-instant basis from the fMRI data. A few reasons why this is particularly interesting:
  
  This is beyond the current state of the art, but not inconceivably hard. 
  This is a new type of experiment design current analysis methods cannot deal with. 
  This is an opportunity to work with a heavily examined and preprocessed neuroimaging dataset. 
  DARPA is offering prizes!</p><p>3 0.62953472 <a title="291-lda-3" href="../hunch_net-2011/hunch_net-2011-08-20-The_Large_Scale_Learning_Survey_Tutorial.html">442 hunch net-2011-08-20-The Large Scale Learning Survey Tutorial</a></p>
<p>Introduction: Ron Bekkerman  initiated an effort to create an  edited book on parallel machine learning  that  Misha  and I have been helping with.  The breadth of efforts to parallelize machine learning surprised me: I was only aware of a small fraction initially.
 
This put us in a unique position, with knowledge of a wide array of different efforts, so it is natural to put together a  survey tutorial on the subject of parallel learning  for  KDD , tomorrow.  This tutorial is  not  limited to the book itself however, as several interesting new algorithms have come out since we started inviting chapters.  
 
This tutorial should interest anyone trying to use machine learning on significant quantities of data, anyone interested in developing algorithms for such, and of course who has bragging rights to the fastest learning algorithm on planet earth   
 
(Also note the Modeling with Hadoop tutorial just before ours which deals with one way of trying to speed up learning algorithms.  We have almost no</p><p>4 0.45312884 <a title="291-lda-4" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>Introduction: Machine learning algorithms have a much better chance of being widely adopted if they are implemented in some easy-to-use code.  There are several important concerns associated with machine learning which stress programming languages on the ease-of-use vs. speed frontier.
  
  Speed   The rate at which data sources are growing seems to be outstripping the rate at which computational power is growing, so it is important that we be able to eak out every bit of computational power.  Garbage collected languages ( java ,  ocaml ,  perl  and  python ) often have several issues here.
 
 Garbage collection often implies that floating point numbers are “boxed”: every float is represented by a pointer to a float.  Boxing can cause an order of magnitude slowdown because an extra nonlocalized memory reference is made, and accesses to main memory can are many CPU cycles long. 
 Garbage collection often implies that considerably more memory is used than is necessary.   This has a variable effect.  I</p><p>5 0.42378923 <a title="291-lda-5" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>Introduction: I enjoyed attending  NIPS  this year, with several things interesting me.  For the conference itself:
  
  Peter Welinder ,  Steve  Branson ,  Serge Belongie , and  Pietro Perona ,  The Multidimensional Wisdom of Crowds .  This paper is about using  mechanical turk  to get label information, with results superior to a majority vote approach. 
  David McAllester ,  Tamir Hazan , and  Joseph Keshet   Direct Loss Minimization for Structured Prediction .  This is about another technique for directly optimizing the loss in structured prediction, with an application to speech recognition.  
  Mohammad Saberian  and  Nuno Vasconcelos   Boosting Classifier Cascades .  This is about an algorithm for simultaneously optimizing loss and computation in a classifier cascade construction.  There were several other papers on cascades which are worth looking at if interested. 
  Alan Fern  and  Prasad Tadepalli ,  A Computational Decision Theory for Interactive Assistants .  This paper carves out some</p><p>6 0.40979466 <a title="291-lda-6" href="../hunch_net-2005/hunch_net-2005-02-12-ROC_vs._Accuracy_vs._AROC.html">18 hunch net-2005-02-12-ROC vs. Accuracy vs. AROC</a></p>
<p>7 0.40663645 <a title="291-lda-7" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>8 0.098036706 <a title="291-lda-8" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>9 0.08029817 <a title="291-lda-9" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>10 0.079963535 <a title="291-lda-10" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>11 0.072477952 <a title="291-lda-11" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>12 0.06818331 <a title="291-lda-12" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>13 0.067398958 <a title="291-lda-13" href="../hunch_net-2005/hunch_net-2005-11-05-The_design_of_a_computing_cluster.html">128 hunch net-2005-11-05-The design of a computing cluster</a></p>
<p>14 0.066472791 <a title="291-lda-14" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>15 0.058933146 <a title="291-lda-15" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>16 0.056949012 <a title="291-lda-16" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>17 0.055587467 <a title="291-lda-17" href="../hunch_net-2006/hunch_net-2006-09-07-Objective_and_subjective_interpretations_of_probability.html">205 hunch net-2006-09-07-Objective and subjective interpretations of probability</a></p>
<p>18 0.054360077 <a title="291-lda-18" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>19 0.051696323 <a title="291-lda-19" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>20 0.051009808 <a title="291-lda-20" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
