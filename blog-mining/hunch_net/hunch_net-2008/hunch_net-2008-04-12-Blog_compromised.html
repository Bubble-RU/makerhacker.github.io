<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>294 hunch net-2008-04-12-Blog compromised</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-294" href="#">hunch_net-2008-294</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>294 hunch net-2008-04-12-Blog compromised</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-294-html" href="http://hunch.net/?p=325">html</a></p><p>Introduction: Iainnoticed that hunch.net had zero width divs hiding spammy URLs. Some
investigation reveals that the wordpress version being used (2.0.3) had
security flaws. I've upgraded to the latest, rotated passwords, and removed
the spammy URLs. I don't believe any content was lost. You can check your own
and other sites for a similar problem by greping for "width:0″ or "width: 0″
in the delivered html source.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Some investigation reveals that the wordpress version being used (2. [sent-3, score-0.614]
</p><p>2 I've upgraded to the latest, rotated passwords, and removed the spammy URLs. [sent-6, score-0.781]
</p><p>3 You can check your own and other sites for a similar problem by greping for "width:0″ or "width: 0″ in the delivered html source. [sent-8, score-0.743]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('width', 0.652), ('spammy', 0.434), ('upgraded', 0.193), ('html', 0.179), ('hiding', 0.179), ('wordpress', 0.169), ('sites', 0.169), ('security', 0.169), ('latest', 0.169), ('delivered', 0.169), ('reveals', 0.161), ('removed', 0.154), ('investigation', 0.144), ('zero', 0.133), ('check', 0.116), ('content', 0.111), ('version', 0.087), ('source', 0.085), ('similar', 0.074), ('believe', 0.071), ('used', 0.053), ('problem', 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="294-tfidf-1" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>Introduction: Iainnoticed that hunch.net had zero width divs hiding spammy URLs. Some
investigation reveals that the wordpress version being used (2.0.3) had
security flaws. I've upgraded to the latest, rotated passwords, and removed
the spammy URLs. I don't believe any content was lost. You can check your own
and other sites for a similar problem by greping for "width:0″ or "width: 0″
in the delivered html source.</p><p>2 0.10830324 <a title="294-tfidf-2" href="../hunch_net-2006/hunch_net-2006-06-05-Server_Shift%2C_Site_Tweaks%2C_Suggestions%3F.html">182 hunch net-2006-06-05-Server Shift, Site Tweaks, Suggestions?</a></p>
<p>Introduction: Hunch.net has shifted to a new server, and wordpress has been updated to the
latest version. If anyone notices difficulties associated with this, please
comment. (Note that DNS updates can take awhile so the shift may not yet be
complete.)More generally, this is a good time to ask for suggestions. What
would make this blog more useful?</p><p>3 0.05829059 <a title="294-tfidf-3" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>Introduction: Several people have had difficulty with comments which seem to have an allowed
language significantly poorer than posts. The set of allowed html tags has
been increased and themarkdown filterhas been put in place to try to make
commenting easier. I'll put some examples into the comments of this post.</p><p>4 0.044640917 <a title="294-tfidf-4" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>Introduction: The hunch.net server has been updated. I've taken the opportunity to upgrade
the version of wordpress which caused cascading changes.Old threaded comments
are now flattened. The system we used to use (Brian's threaded comments)
appears incompatible with the new threading system built into wordpress. I
haven't yet figured out a workaround.I setup afeedburner account.I added an
RSS aggregator for both Machine Learning and other research blogs that I like
to follow. This is something that I've wanted to do for awhile.Many other
minor changes in font and format, with some help fromAlina.If you have any
suggestions for site tweaks, please speak up.</p><p>5 0.040604871 <a title="294-tfidf-5" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>Introduction: At thelast ICML,Tom Dietterichasked me to look into systems for commenting on
papers. I've been slow getting to this, but it's relevant now.The essential
observation is that we now have many tools for online collaboration, but they
are not yet much used in academic research. If we can find the right way to
use them, then perhaps great things might happen, with extra kudos to the
first conference that manages to really create an online community. Various
conferences have been poking at this. For example,UAI has setup a wiki, COLT
hasstarted usingJoomla, with some dynamic content, and AAAI has been setting
up a "student blog". Similarly,Dinoj Surendransetup a twiki for theChicago
Machine Learning Summer School, which was quite useful for coordinating events
and other things.I believe the most important thing is a willingness to
experiment. A good place to start seems to be enhancing existing conference
websites. For example, theICML 2007 papers pageis basically only useful via
grep. A mu</p><p>6 0.039812613 <a title="294-tfidf-6" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>7 0.034662262 <a title="294-tfidf-7" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>8 0.033799838 <a title="294-tfidf-8" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>9 0.031885549 <a title="294-tfidf-9" href="../hunch_net-2005/hunch_net-2005-10-03-Not_ICML.html">117 hunch net-2005-10-03-Not ICML</a></p>
<p>10 0.030530564 <a title="294-tfidf-10" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>11 0.029716825 <a title="294-tfidf-11" href="../hunch_net-2008/hunch_net-2008-07-04-More_Presentation_Preparation.html">307 hunch net-2008-07-04-More Presentation Preparation</a></p>
<p>12 0.028140657 <a title="294-tfidf-12" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>13 0.026838223 <a title="294-tfidf-13" href="../hunch_net-2006/hunch_net-2006-01-25-1_year.html">151 hunch net-2006-01-25-1 year</a></p>
<p>14 0.025815755 <a title="294-tfidf-14" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>15 0.025375426 <a title="294-tfidf-15" href="../hunch_net-2012/hunch_net-2012-10-26-ML_Symposium_and_Strata-Hadoop_World.html">475 hunch net-2012-10-26-ML Symposium and Strata-Hadoop World</a></p>
<p>16 0.023498457 <a title="294-tfidf-16" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>17 0.022370867 <a title="294-tfidf-17" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>18 0.022054283 <a title="294-tfidf-18" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>19 0.021065123 <a title="294-tfidf-19" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>20 0.020835251 <a title="294-tfidf-20" href="../hunch_net-2006/hunch_net-2006-04-09-Progress_in_Machine_Translation.html">171 hunch net-2006-04-09-Progress in Machine Translation</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.027), (1, 0.002), (2, 0.007), (3, -0.013), (4, 0.009), (5, -0.002), (6, 0.029), (7, -0.034), (8, 0.012), (9, 0.02), (10, -0.016), (11, 0.007), (12, 0.023), (13, 0.003), (14, -0.018), (15, -0.008), (16, 0.02), (17, 0.0), (18, -0.026), (19, 0.032), (20, -0.009), (21, -0.017), (22, -0.009), (23, -0.009), (24, -0.062), (25, 0.039), (26, -0.018), (27, 0.041), (28, -0.028), (29, 0.008), (30, -0.016), (31, -0.028), (32, 0.029), (33, 0.029), (34, 0.01), (35, 0.007), (36, 0.007), (37, -0.041), (38, 0.032), (39, -0.032), (40, -0.021), (41, 0.011), (42, 0.02), (43, -0.007), (44, 0.002), (45, 0.003), (46, -0.017), (47, -0.002), (48, 0.011), (49, -0.018)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95391214 <a title="294-lsi-1" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>Introduction: Iainnoticed that hunch.net had zero width divs hiding spammy URLs. Some
investigation reveals that the wordpress version being used (2.0.3) had
security flaws. I've upgraded to the latest, rotated passwords, and removed
the spammy URLs. I don't believe any content was lost. You can check your own
and other sites for a similar problem by greping for "width:0″ or "width: 0″
in the delivered html source.</p><p>2 0.56113112 <a title="294-lsi-2" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>Introduction: The hunch.net server has been updated. I've taken the opportunity to upgrade
the version of wordpress which caused cascading changes.Old threaded comments
are now flattened. The system we used to use (Brian's threaded comments)
appears incompatible with the new threading system built into wordpress. I
haven't yet figured out a workaround.I setup afeedburner account.I added an
RSS aggregator for both Machine Learning and other research blogs that I like
to follow. This is something that I've wanted to do for awhile.Many other
minor changes in font and format, with some help fromAlina.If you have any
suggestions for site tweaks, please speak up.</p><p>3 0.46978012 <a title="294-lsi-3" href="../hunch_net-2006/hunch_net-2006-06-05-Server_Shift%2C_Site_Tweaks%2C_Suggestions%3F.html">182 hunch net-2006-06-05-Server Shift, Site Tweaks, Suggestions?</a></p>
<p>Introduction: Hunch.net has shifted to a new server, and wordpress has been updated to the
latest version. If anyone notices difficulties associated with this, please
comment. (Note that DNS updates can take awhile so the shift may not yet be
complete.)More generally, this is a good time to ask for suggestions. What
would make this blog more useful?</p><p>4 0.40844372 <a title="294-lsi-4" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>Introduction: Several people have had difficulty with comments which seem to have an allowed
language significantly poorer than posts. The set of allowed html tags has
been increased and themarkdown filterhas been put in place to try to make
commenting easier. I'll put some examples into the comments of this post.</p><p>5 0.38980818 <a title="294-lsi-5" href="../hunch_net-2006/hunch_net-2006-11-27-Continuizing_Solutions.html">220 hunch net-2006-11-27-Continuizing Solutions</a></p>
<p>Introduction: This post is about a general technique for problem solving which I've never
seen taught (in full generality), but which I've found very useful.Many
problems in computer science turn out to be discretely difficult. The best
known version of such problems are NP-hard problems, but I mean 'discretely
difficult' in a much more general way, which I only know how to capture by
examples.ERMIn empirical risk minimization, you choose a minimum error rate
classifier from a set of classifiers. This is NP hard for common sets, but it
can be much harder, depending on the set.ExpertsIn the online learning with
experts setting, you try to predict well so as to compete with a set of
(adversarial) experts. Here the alternating quantifiers of you and an
adversary playing out a game can yield a dynamic programming problem that
grows exponentially.Policy IterationThe problem with policy iteration is that
you learn a new policy with respect to an old policy, which implies that
simply adopting the new polic</p><p>6 0.37727988 <a title="294-lsi-6" href="../hunch_net-2012/hunch_net-2012-09-29-Vowpal_Wabbit%2C_version_7.0.html">473 hunch net-2012-09-29-Vowpal Wabbit, version 7.0</a></p>
<p>7 0.37082475 <a title="294-lsi-7" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>8 0.36856577 <a title="294-lsi-8" href="../hunch_net-2005/hunch_net-2005-02-20-At_One_Month.html">25 hunch net-2005-02-20-At One Month</a></p>
<p>9 0.36620697 <a title="294-lsi-9" href="../hunch_net-2011/hunch_net-2011-03-27-Vowpal_Wabbit%2C_v5.1.html">428 hunch net-2011-03-27-Vowpal Wabbit, v5.1</a></p>
<p>10 0.36551723 <a title="294-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-08-Some_Links.html">15 hunch net-2005-02-08-Some Links</a></p>
<p>11 0.36283609 <a title="294-lsi-11" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>12 0.34669209 <a title="294-lsi-12" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>13 0.33901903 <a title="294-lsi-13" href="../hunch_net-2010/hunch_net-2010-06-20-2010_ICML_discussion_site.html">401 hunch net-2010-06-20-2010 ICML discussion site</a></p>
<p>14 0.33598718 <a title="294-lsi-14" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>15 0.33431315 <a title="294-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-19-Machine_learning_reading_groups.html">24 hunch net-2005-02-19-Machine learning reading groups</a></p>
<p>16 0.33021405 <a title="294-lsi-16" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<p>17 0.33017889 <a title="294-lsi-17" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>18 0.32586515 <a title="294-lsi-18" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>19 0.32355836 <a title="294-lsi-19" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>20 0.32168275 <a title="294-lsi-20" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(34, 0.62), (42, 0.142), (74, 0.032)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99828684 <a title="294-lda-1" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>Introduction: I justpresentedthecross validationproblem atCOLT.The problem now has a cash
prize (up to $500) associated with it--see thepresentationfor details
.Thewrite-up for colt.</p><p>same-blog 2 0.96611696 <a title="294-lda-2" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>Introduction: Iainnoticed that hunch.net had zero width divs hiding spammy URLs. Some
investigation reveals that the wordpress version being used (2.0.3) had
security flaws. I've upgraded to the latest, rotated passwords, and removed
the spammy URLs. I don't believe any content was lost. You can check your own
and other sites for a similar problem by greping for "width:0″ or "width: 0″
in the delivered html source.</p><p>3 0.57279116 <a title="294-lda-3" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>4 0.50247419 <a title="294-lda-4" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>Introduction: Multitask learning is the problem of jointly predicting multiple labels
simultaneously with one system. A basic question iswhether or not multitask
learning can be decomposed into one (or more) single prediction problems. It
seems the answer to this is "yes", in a fairly straightforward manner.The
basic idea is that a controlled input feature is equivalent to an extra
output. Suppose we have some process generating examples:(x,y1,y2) in
Swherey1andy2are labels for two different tasks. Then, we could reprocess the
data to the formSb(S) = {((x,i),yi): (x,y1,y2) in S, i in {1,2}}and then learn
a classifierc:X x {1,2} -> Y. Note that(x,i)is the (composite) input. At
testing time, given an inputx, we can querycfor the predicted values of y1and
y2using(x,1)and(x,2).A strong form of equivalence can be stated between these
tasks. In particular, suppose we have a multitask learning algorithmMLwhich
learns a multitask predictorm:X -> Y x Y. Then the following theorem can be
proved:For allMLfor a</p><p>5 0.23869014 <a title="294-lda-5" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>Introduction: The essential problem here is the large gap between experimental observation
and theoretical understanding.MethodK-fold cross validation is a commonly used
technique which takes a set ofmexamples and partitions them intoKsets
("folds") of sizem/K. For each fold, a classifier is trained on the other
folds and then test on the fold.ProblemAssume only independent samples. Derive
a classifier from the K classifiers with a small bound on the true error
rate.Past Work(I'll add more as I remember/learn.)Devroye, Rogers, and Wagner
analyzed cross validation and found algorithm specific bounds. Not all of this
is online, but here is onepaper.Michael KearnsandDana Ronanalyzed cross
validationand found that under additional stability assumptions the bound for
the classifier which learns on all the data is not much worse than for a test
set of sizem/K.Avrim Blum,Adam Kalai, andmyselfanalyzed cross validationand
found that you can do at least as well as a test set of sizem/Kwith no
additional assum</p><p>6 0.22695422 <a title="294-lda-6" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>7 0.22691247 <a title="294-lda-7" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>8 0.22677454 <a title="294-lda-8" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>9 0.22613747 <a title="294-lda-9" href="../hunch_net-2005/hunch_net-2005-03-29-Academic_Mechanism_Design.html">48 hunch net-2005-03-29-Academic Mechanism Design</a></p>
<p>10 0.2259938 <a title="294-lda-10" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>11 0.22595908 <a title="294-lda-11" href="../hunch_net-2006/hunch_net-2006-06-15-IJCAI_is_out_of_season.html">184 hunch net-2006-06-15-IJCAI is out of season</a></p>
<p>12 0.22589745 <a title="294-lda-12" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>13 0.22532344 <a title="294-lda-13" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>14 0.22508325 <a title="294-lda-14" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>15 0.22507165 <a title="294-lda-15" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>16 0.22466271 <a title="294-lda-16" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>17 0.22457023 <a title="294-lda-17" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>18 0.22410686 <a title="294-lda-18" href="../hunch_net-2012/hunch_net-2012-10-26-ML_Symposium_and_Strata-Hadoop_World.html">475 hunch net-2012-10-26-ML Symposium and Strata-Hadoop World</a></p>
<p>19 0.2237386 <a title="294-lda-19" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>20 0.22340155 <a title="294-lda-20" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
