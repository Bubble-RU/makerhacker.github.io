<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-301" href="#">hunch_net-2008-301</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-301-html" href="http://hunch.net/?p=331">html</a></p><p>Introduction: In October 2006, the online movie renter, Netflix, announced theNetflix
Prizecontest. They published a comprehensive dataset including more than 100
million movie ratings, which were performed by about 480,000 real customers on
17,770 movies.Ã‚ÂCompetitors in the challenge are required to estimate a few
million ratings.Ã‚ÂTo win the "grand prize," they need to deliver a 10%
improvement in the prediction error compared with the results of Cinematch,
Netflix's proprietary recommender system. Best current results deliver
9.12%improvement, which is quite close to the 10% goal, yet painfully
distant.Ã‚ÂThe Netflix Prize breathed new life and excitement into recommender
systems research. The competition allowed the wide research community to
access a large scale, real life dataset. Beyond this, the competition changed
the rules of the game. Claiming that your nice idea could outperform some
mediocre algorithms on some toy dataset is no longer acceptable. Now
researchers should face a new gol</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('model', 0.271), ('level', 0.268), ('movies', 0.228), ('neighborhood', 0.211), ('netflix', 0.194), ('svd', 0.183), ('models', 0.177), ('latent', 0.169), ('three', 0.162), ('ratings', 0.16), ('maybe', 0.129), ('movie', 0.127), ('users', 0.126), ('recommender', 0.11), ('levels', 0.106), ('metadata', 0.103), ('numerical', 0.103), ('squeezing', 0.103), ('factor', 0.1), ('prize', 0.092)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="301-tfidf-1" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced theNetflix
Prizecontest. They published a comprehensive dataset including more than 100
million movie ratings, which were performed by about 480,000 real customers on
17,770 movies.Ã‚ÂCompetitors in the challenge are required to estimate a few
million ratings.Ã‚ÂTo win the "grand prize," they need to deliver a 10%
improvement in the prediction error compared with the results of Cinematch,
Netflix's proprietary recommender system. Best current results deliver
9.12%improvement, which is quite close to the 10% goal, yet painfully
distant.Ã‚ÂThe Netflix Prize breathed new life and excitement into recommender
systems research. The competition allowed the wide research community to
access a large scale, real life dataset. Beyond this, the competition changed
the rules of the game. Claiming that your nice idea could outperform some
mediocre algorithms on some toy dataset is no longer acceptable. Now
researchers should face a new gol</p><p>2 0.18365154 <a title="301-tfidf-2" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>3 0.1696451 <a title="301-tfidf-3" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>Introduction: In everyday use a model is a system which explains the behavior of some
system, hopefully at the level where some alteration of the model predicts
some alteration of the real-world system. In machine learning "model" has
several variant definitions.Everyday. The common definition is sometimes
used.Parameterized. Sometimes model is a short-hand for "parameterized model".
Here, it refers to a model with unspecified free parameters. In the Bayesian
learning approach, you typically have a prior over (everyday)
models.Predictive. Even further from everyday use is the predictive model.
Examples of this are "my model is a decision tree" or "my model is a support
vector machine". Here, there is no real sense in which an SVM explains the
underlying process. For example, an SVM tells us nothing in particular about
how alterations to the real-world system would create a change.Which
definition is being used at any particular time is important information. For
example, if it's a parameterized or p</p><p>4 0.16112146 <a title="301-tfidf-4" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>Introduction: A couple security researchersclaim to have cracked the netflix dataset. The
claims of success appear somewhat overstated to me, but the method of attack
is valid and could plausibly be substantially improved so as to reveal the
movie preferences of a small fraction of Netflix users.The basic idea is to
use a heuristic similarity function between ratings in a public database (from
IMDB) and an anonymized database (Netflix) to link ratings in the private
database to public identities (in IMDB). They claim to have linked two of a
few dozen IMDB users to anonymized netflix users.The claims seem a bit
inflated to me, because (a) knowing the IMDB identity isn't equivalent to
knowing the person and (b) the claims of statistical significance are with
respect to a model of the world they created (rather than one they
created).Overall, this is another example showing that completeprivacy is
hard. It may be worth remembering that there are some substantial benefits
from the Netflix challenge as w</p><p>5 0.16040972 <a title="301-tfidf-5" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended theNetflix prizeceremony this morning. The press conference part
iscovered fine elsewhere, with the basic outcome being thatBellKor's Pragmatic
Chaoswon overThe Ensembleby 15-20minutes, because they were tied in
performance on the ultimate holdout set. I'm sure the individual participants
will have many chances to speak about the solution. One of these is Bell at
theNYAS ML symposium on Nov. 6.Several additional details may interest ML
people.The degree of overfitting exhibited by the difference in performance on
theleaderboard test setand the ultimate hold out set was small, but
determining at .02 to .03%.A tie was possible, because the rules cut off
measurements below the fourth digit based on significance concerns. In
actuality, of course, the scores do differ before rounding, but everyone I
spoke to claimed not to know how. The complete dataset has beenreleased on
UCI, so each team could compute their own score to whatever accuracy desired.I
was impressed by the slick sy</p><p>6 0.1423451 <a title="301-tfidf-6" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>7 0.13647555 <a title="301-tfidf-7" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>8 0.120339 <a title="301-tfidf-8" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>9 0.11833545 <a title="301-tfidf-9" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>10 0.11565365 <a title="301-tfidf-10" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>11 0.10905254 <a title="301-tfidf-11" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>12 0.10850404 <a title="301-tfidf-12" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>13 0.10114654 <a title="301-tfidf-13" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>14 0.09982457 <a title="301-tfidf-14" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>15 0.099447757 <a title="301-tfidf-15" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>16 0.099376887 <a title="301-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>17 0.098982617 <a title="301-tfidf-17" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>18 0.097415797 <a title="301-tfidf-18" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>19 0.095940165 <a title="301-tfidf-19" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>20 0.095338054 <a title="301-tfidf-20" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.243), (1, -0.017), (2, 0.025), (3, -0.014), (4, -0.018), (5, 0.087), (6, -0.053), (7, -0.007), (8, 0.093), (9, -0.033), (10, -0.075), (11, 0.032), (12, -0.144), (13, 0.125), (14, 0.038), (15, 0.169), (16, 0.094), (17, -0.117), (18, -0.101), (19, -0.062), (20, -0.075), (21, 0.005), (22, 0.03), (23, 0.043), (24, -0.114), (25, 0.007), (26, 0.072), (27, 0.057), (28, -0.046), (29, 0.133), (30, 0.083), (31, -0.038), (32, -0.031), (33, -0.06), (34, -0.041), (35, 0.049), (36, -0.126), (37, -0.0), (38, -0.126), (39, 0.094), (40, 0.017), (41, 0.028), (42, -0.079), (43, -0.005), (44, 0.015), (45, -0.027), (46, -0.007), (47, 0.024), (48, -0.038), (49, 0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98077655 <a title="301-lsi-1" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced theNetflix
Prizecontest. They published a comprehensive dataset including more than 100
million movie ratings, which were performed by about 480,000 real customers on
17,770 movies.Ã‚ÂCompetitors in the challenge are required to estimate a few
million ratings.Ã‚ÂTo win the "grand prize," they need to deliver a 10%
improvement in the prediction error compared with the results of Cinematch,
Netflix's proprietary recommender system. Best current results deliver
9.12%improvement, which is quite close to the 10% goal, yet painfully
distant.Ã‚ÂThe Netflix Prize breathed new life and excitement into recommender
systems research. The competition allowed the wide research community to
access a large scale, real life dataset. Beyond this, the competition changed
the rules of the game. Claiming that your nice idea could outperform some
mediocre algorithms on some toy dataset is no longer acceptable. Now
researchers should face a new gol</p><p>2 0.74143511 <a title="301-lsi-2" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>Introduction: A couple security researchersclaim to have cracked the netflix dataset. The
claims of success appear somewhat overstated to me, but the method of attack
is valid and could plausibly be substantially improved so as to reveal the
movie preferences of a small fraction of Netflix users.The basic idea is to
use a heuristic similarity function between ratings in a public database (from
IMDB) and an anonymized database (Netflix) to link ratings in the private
database to public identities (in IMDB). They claim to have linked two of a
few dozen IMDB users to anonymized netflix users.The claims seem a bit
inflated to me, because (a) knowing the IMDB identity isn't equivalent to
knowing the person and (b) the claims of statistical significance are with
respect to a model of the world they created (rather than one they
created).Overall, this is another example showing that completeprivacy is
hard. It may be worth remembering that there are some substantial benefits
from the Netflix challenge as w</p><p>3 0.73622787 <a title="301-lsi-3" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>Introduction: In everyday use a model is a system which explains the behavior of some
system, hopefully at the level where some alteration of the model predicts
some alteration of the real-world system. In machine learning "model" has
several variant definitions.Everyday. The common definition is sometimes
used.Parameterized. Sometimes model is a short-hand for "parameterized model".
Here, it refers to a model with unspecified free parameters. In the Bayesian
learning approach, you typically have a prior over (everyday)
models.Predictive. Even further from everyday use is the predictive model.
Examples of this are "my model is a decision tree" or "my model is a support
vector machine". Here, there is no real sense in which an SVM explains the
underlying process. For example, an SVM tells us nothing in particular about
how alterations to the real-world system would create a change.Which
definition is being used at any particular time is important information. For
example, if it's a parameterized or p</p><p>4 0.65749061 <a title="301-lsi-4" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>Introduction: Arecent discussionindicated that one goal of this blog might be to allow
people to post comments about recent papers that they liked. I think this
could potentially be very useful, especially for those with diverse interests
but only finite time to read through conference proceedings.ACL 2005recently
completed, and here are four papers from that conference that I thought were
either good or perhaps of interest to a machine learning audience.David
Chiang,A Hierarchical Phrase-Based Model for Statistical Machine Translation.
(Best paper award.) This paper takes the standard phrase-based MT model that
is popular in our field (basically, translate a sentence by individually
translating phrases and reordering them according to a complicated statistical
model) and extends it to take into account hierarchy in phrases, so that you
can learn things like "X 's Y" -> "Y de X" in chinese, where X and Y are
arbitrary phrases. This takes a step toward linguistic syntax for MT, which
our group is wor</p><p>5 0.63540113 <a title="301-lsi-5" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>6 0.59505552 <a title="301-lsi-6" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>7 0.57033396 <a title="301-lsi-7" href="../hunch_net-2006/hunch_net-2006-07-05-more_icml_papers.html">189 hunch net-2006-07-05-more icml papers</a></p>
<p>8 0.54803705 <a title="301-lsi-8" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>9 0.52163279 <a title="301-lsi-9" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>10 0.50957698 <a title="301-lsi-10" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>11 0.50889146 <a title="301-lsi-11" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>12 0.50346208 <a title="301-lsi-12" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>13 0.49567631 <a title="301-lsi-13" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>14 0.49427089 <a title="301-lsi-14" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>15 0.48547289 <a title="301-lsi-15" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>16 0.46377674 <a title="301-lsi-16" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>17 0.45426989 <a title="301-lsi-17" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<p>18 0.45079026 <a title="301-lsi-18" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>19 0.4450992 <a title="301-lsi-19" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>20 0.43733215 <a title="301-lsi-20" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.205), (6, 0.026), (29, 0.019), (35, 0.07), (42, 0.201), (45, 0.031), (47, 0.011), (50, 0.054), (68, 0.052), (69, 0.033), (74, 0.09), (76, 0.052), (82, 0.015), (95, 0.049)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93678743 <a title="301-lda-1" href="../hunch_net-2013/hunch_net-2013-01-01-Deep_Learning_2012.html">477 hunch net-2013-01-01-Deep Learning 2012</a></p>
<p>Introduction: 2012 was a tumultuous year for me, but it was undeniably a great year for deep
learning efforts. Signs of this include:Winning aKaggle competition.Wide
adoption ofdeep learning for speech recognition.Significantindustry
support.Gains inimagerecognition.This is a rare event in research: a
significant capability breakout. Congratulations are definitely in order for
those who managed to achieve it. At this point, deep learning algorithms seem
like a choice undeniably worth investigating for real applications with
significant data.</p><p>2 0.93508893 <a title="301-lda-2" href="../hunch_net-2010/hunch_net-2010-09-17-New_York_Area_Machine_Learning_Events.html">410 hunch net-2010-09-17-New York Area Machine Learning Events</a></p>
<p>Introduction: On Sept 21, there is anothermachine learning meetupwhere I'll be speaking.
Although the topic is contextual bandits, I think of it as "the future of
machine learning". In particular, it's all about how to learn in an
interactive environment, such as for ad display, trading, news recommendation,
etcâ&euro;ŚOn Sept 24, abstracts for theNew York Machine Learning Symposiumare due.
This is the largest Machine Learning event in the area, so it's a great way to
have a conversation with other people.On Oct 22, the NY ML Symposium actually
happens. This year, we are expanding the spotlights, and trying to have more
time for posters. In addition, we have a strong set of invited speakers:David
Blei,Sanjoy Dasgupta,Tommi Jaakkola, andYann LeCun. After the meeting, a
latehackNYrelated event is planned where students and startups can meet.I'd
also like to point out the relatedCS/Econ symposiumas I have interests there
as well.</p><p>3 0.92808098 <a title="301-lda-3" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>Introduction: Many different paper deadlines are coming up soon so I made a little reference
table. Out of curiosity, I also computed the interval between submission
deadline and
conference.ConferenceLocationDateDeadlineintervalCOLTPittsburghJune
22-25January 21152ICMLPittsburghJune 26-28January 30/February 6140UAIMITJuly
13-16March 9/March 16119AAAIBostonJuly 16-20February
16/21145KDDPhiladelphiaAugust 23-26March 3/March 10166It looks like the
northeastern US is the big winner as far as location this year.</p><p>4 0.88805532 <a title="301-lda-4" href="../hunch_net-2006/hunch_net-2006-07-26-Two_more_UAI_papers_of_interest.html">199 hunch net-2006-07-26-Two more UAI papers of interest</a></p>
<p>Introduction: In addition to Ed Snelson's paper, there were (at least) two other papers that
caught my eye at UAI.One wasthis paperby Sanjoy Dasgupta, Daniel Hsu and Nakul
Verma at UCSD which shows in a surprisingly general and strong way that almost
all linear projections of any jointly distributed vector random variable with
finite first and second moments look sphereical and unimodal (in fact look
like a scale mixture of Gaussians). Great result, as you'd expect from
Sanjoy.The other paper which I found intriguing but which I just haven't
groked yet isthis beastby Manfred and Dima Kuzmin.You can check out the
(beautiful)slidesif that helps. I feel like there is something deep here, but
my brain is too small to understand it. The COLT and last NIPS papers/slides
are also on Manfred's page. Hopefully someone here can illuminate.</p><p>same-blog 5 0.88523942 <a title="301-lda-5" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced theNetflix
Prizecontest. They published a comprehensive dataset including more than 100
million movie ratings, which were performed by about 480,000 real customers on
17,770 movies.Ã‚ÂCompetitors in the challenge are required to estimate a few
million ratings.Ã‚ÂTo win the "grand prize," they need to deliver a 10%
improvement in the prediction error compared with the results of Cinematch,
Netflix's proprietary recommender system. Best current results deliver
9.12%improvement, which is quite close to the 10% goal, yet painfully
distant.Ã‚ÂThe Netflix Prize breathed new life and excitement into recommender
systems research. The competition allowed the wide research community to
access a large scale, real life dataset. Beyond this, the competition changed
the rules of the game. Claiming that your nice idea could outperform some
mediocre algorithms on some toy dataset is no longer acceptable. Now
researchers should face a new gol</p><p>6 0.79332078 <a title="301-lda-6" href="../hunch_net-2011/hunch_net-2011-02-25-Yahoo%21_Machine_Learning_grant_due_March_11.html">425 hunch net-2011-02-25-Yahoo! Machine Learning grant due March 11</a></p>
<p>7 0.78381485 <a title="301-lda-7" href="../hunch_net-2005/hunch_net-2005-04-01-Basic_computer_science_research_takes_a_hit.html">50 hunch net-2005-04-01-Basic computer science research takes a hit</a></p>
<p>8 0.74900633 <a title="301-lda-8" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>9 0.73939657 <a title="301-lda-9" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>10 0.73728758 <a title="301-lda-10" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>11 0.73321831 <a title="301-lda-11" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>12 0.73212248 <a title="301-lda-12" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>13 0.73002332 <a title="301-lda-13" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>14 0.72345042 <a title="301-lda-14" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>15 0.72297424 <a title="301-lda-15" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>16 0.72176558 <a title="301-lda-16" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>17 0.72059399 <a title="301-lda-17" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>18 0.71993917 <a title="301-lda-18" href="../hunch_net-2008/hunch_net-2008-11-28-A_Bumper_Crop_of_Machine_Learning_Graduates.html">329 hunch net-2008-11-28-A Bumper Crop of Machine Learning Graduates</a></p>
<p>19 0.71853197 <a title="301-lda-19" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>20 0.71847349 <a title="301-lda-20" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
