<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>288 hunch net-2008-02-10-Complexity Illness</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-288" href="#">hunch_net-2008-288</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>288 hunch net-2008-02-10-Complexity Illness</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-288-html" href="http://hunch.net/?p=316">html</a></p><p>Introduction: One of the enduring stereotypes of academia is that people spend a great deal
of intelligence, time, and effort finding complexity rather than simplicity.
This is at least anecdotally true in my experience.Math++Several people have
found that adding useless math makes their paper more publishable as evidenced
by a reject-add-accept sequence.8 page minimumWho submitted a paper
toICMLviolating the 8 page minimum? Every author fears that the reviewers
won't take their work seriously unless the allowed length is fully used. The
best minimum violation I know isAdam's paper at SODA ongenerating random
factored numbers, but this is deeply exceptional. It's a fair bet that 90% of
papers submitted are exactly at the page limit. We could imagine that this is
because papers naturally take more space, but few people seem to be clamoring
for more space.JournalongHas anyone been asked to review a 100 page journal
paper? I have. Journal papers can be nice, because they give an author the
opportunity</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('page', 0.317), ('illness', 0.249), ('spend', 0.224), ('encourages', 0.184), ('journal', 0.171), ('submitted', 0.146), ('teaching', 0.143), ('exactly', 0.143), ('minimum', 0.133), ('complexity', 0.129), ('solution', 0.125), ('papers', 0.121), ('paper', 0.116), ('solutions', 0.115), ('misplaced', 0.11), ('burden', 0.11), ('crippling', 0.11), ('enduring', 0.11), ('slowing', 0.11), ('stereotypes', 0.11)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9999997 <a title="288-tfidf-1" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>Introduction: One of the enduring stereotypes of academia is that people spend a great deal
of intelligence, time, and effort finding complexity rather than simplicity.
This is at least anecdotally true in my experience.Math++Several people have
found that adding useless math makes their paper more publishable as evidenced
by a reject-add-accept sequence.8 page minimumWho submitted a paper
toICMLviolating the 8 page minimum? Every author fears that the reviewers
won't take their work seriously unless the allowed length is fully used. The
best minimum violation I know isAdam's paper at SODA ongenerating random
factored numbers, but this is deeply exceptional. It's a fair bet that 90% of
papers submitted are exactly at the page limit. We could imagine that this is
because papers naturally take more space, but few people seem to be clamoring
for more space.JournalongHas anyone been asked to review a 100 page journal
paper? I have. Journal papers can be nice, because they give an author the
opportunity</p><p>2 0.17466408 <a title="288-tfidf-2" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>3 0.1505978 <a title="288-tfidf-3" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>Introduction: Essentially everyone who writes research papers suffers rejections. They
always sting immediately, but upon further reflection many of these rejections
come to seem reasonable. Maybe the equations had too many typos or maybe the
topic just isn't as important as was originally thought. A few rejections do
not come to seem acceptable, and these form the basis of reviewing horror
stories, a great material for conversations. I've decided to share three of
mine, now all safely a bit distant in the past.Prediction Theory for
Classification Tutorial. This is a tutorial about tight sample complexity
bounds for classification that I submitted toJMLR. The first decision I heard
was a reject which appeared quite unjust to me--for example one of the
reviewers appeared to claim that all the content was in standard statistics
books. Upon further inquiry, several citations were given, none of which
actually covered the content. Later, I was shocked to hear the paper was
accepted. Apparently, the pape</p><p>4 0.14967689 <a title="288-tfidf-4" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>Introduction: The internet has significantly effected the way we do research but it's
capabilities have not yet been fully realized.First, let's acknowledge some
known effects.Self-publishingBy default, all researchers in machine learning
(and more generally computer science and physics) place their papers online
for anyone to download. The exact mechanism differs--physicists tend to use a
central repository (Arxiv) while computer scientists tend to place the papers
on their webpage. Arxiv has been slowly growing in subject breadth so it now
sometimes used by computer scientists.CollaborationEmail has enabled working
remotely with coauthors. This has allowed collaborationis which would not
otherwise have been possible and generally speeds research.Now, let's look at
attempts to go further.Blogs(like this one) allow public discussion about
topics which are not easily categorized as "a new idea in machine learning"
(like this topic).Organizationof some subfield of research. This
includesSatinder Singh</p><p>5 0.14355756 <a title="288-tfidf-5" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>Introduction: Claireasked me to be on the SODA program committee this year, which was quite
a bit of work.I had a relatively light load--merely 49 theory papers. Many of
these papers were not on subjects that I was expert about, so (as is common
for theory conferences) I found various reviewers that I trusted to help
review the papers. I ended up reviewing about 1/3 personally. There were a
couple instances where I ended up overruling a subreviewer whose logic seemed
off, but otherwise I generally let their reviews stand.There are some
differences in standards for paper reviews between the machine learning and
theory communities. In machine learning it is expected that a review be
detailed, while in the theory community this is often not the case. Every
paper given to me ended up with a review varying between somewhat and very
detailed.I'm sure not every author was happy with the outcome. While we did
our best to make good decisions, they were difficult decisions to make. For
example, if there is a</p><p>6 0.14324862 <a title="288-tfidf-6" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>7 0.14036009 <a title="288-tfidf-7" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>8 0.13524936 <a title="288-tfidf-8" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>9 0.12807992 <a title="288-tfidf-9" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>10 0.12682562 <a title="288-tfidf-10" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>11 0.12632827 <a title="288-tfidf-11" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>12 0.12614135 <a title="288-tfidf-12" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>13 0.12459824 <a title="288-tfidf-13" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>14 0.1245553 <a title="288-tfidf-14" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>15 0.11983927 <a title="288-tfidf-15" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>16 0.11680749 <a title="288-tfidf-16" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>17 0.11581147 <a title="288-tfidf-17" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>18 0.1156809 <a title="288-tfidf-18" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>19 0.11397922 <a title="288-tfidf-19" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>20 0.11249871 <a title="288-tfidf-20" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.233), (1, 0.155), (2, -0.111), (3, -0.085), (4, 0.026), (5, -0.01), (6, 0.046), (7, -0.018), (8, -0.019), (9, -0.015), (10, 0.021), (11, 0.019), (12, 0.019), (13, -0.004), (14, -0.001), (15, 0.007), (16, 0.013), (17, -0.006), (18, -0.017), (19, -0.087), (20, 0.025), (21, 0.054), (22, -0.102), (23, -0.025), (24, 0.017), (25, -0.029), (26, 0.041), (27, -0.106), (28, -0.072), (29, -0.019), (30, 0.037), (31, -0.008), (32, 0.069), (33, -0.013), (34, 0.02), (35, -0.031), (36, 0.016), (37, 0.035), (38, 0.001), (39, -0.06), (40, -0.007), (41, -0.032), (42, 0.071), (43, 0.071), (44, -0.114), (45, 0.051), (46, 0.029), (47, -0.149), (48, 0.089), (49, -0.019)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97534913 <a title="288-lsi-1" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>Introduction: One of the enduring stereotypes of academia is that people spend a great deal
of intelligence, time, and effort finding complexity rather than simplicity.
This is at least anecdotally true in my experience.Math++Several people have
found that adding useless math makes their paper more publishable as evidenced
by a reject-add-accept sequence.8 page minimumWho submitted a paper
toICMLviolating the 8 page minimum? Every author fears that the reviewers
won't take their work seriously unless the allowed length is fully used. The
best minimum violation I know isAdam's paper at SODA ongenerating random
factored numbers, but this is deeply exceptional. It's a fair bet that 90% of
papers submitted are exactly at the page limit. We could imagine that this is
because papers naturally take more space, but few people seem to be clamoring
for more space.JournalongHas anyone been asked to review a 100 page journal
paper? I have. Journal papers can be nice, because they give an author the
opportunity</p><p>2 0.71641219 <a title="288-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>Introduction: Makc asked a goodquestionin comments--"Why bother to make a paper, at all?"
There are several reasons for writing papers which may not be immediately
obvious to people not in academia.The basic idea is that papers have
considerably more utility than the obvious "present an idea".Papers are a
formalized units of work. Academics (especially young ones) are often judged
on the number of papers they produce.Papers have a formalized method of citing
and crediting other--the bibliography. Academics (especially older ones) are
often judged on the number of citations they receive.Papers enable a "more
fair" anonymous review. Conferences receivemanypapers, from which a subset are
selected. Discussion forums are inherently not anonymous for anyone who wants
to build a reputation for good work.Papers are an excuse to meet your friends.
Papers are the content of conferences, but much of what you do is talk to
friends about interesting problems while there. Sometimes you even solve
them.Papers are</p><p>3 0.7046448 <a title="288-lsi-3" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>Introduction: How many papers do you remember from 2006? 2005? 2002? 1997? 1987? 1967? One
way to judge this would be to look at the citations of the papers you write--
how many came from which year? For myself, the answers on recent papers
are:year200620052002199719871967count4105100This spectrum is fairly typical of
papers in general. There are many reasons that citations are focused on recent
papers.The number of papers being published continues to grow. This is not a
very significant effect, because the rate of publication has not grown nearly
as fast.Dead men don't reject your papers for not citing them. This reason
seems lame, because it's a distortion from the ideal of science. Nevertheless,
it must be stated because the effect can be significant.In 1997, I started as
a PhD student. Naturally, papers after 1997 are better remembered because they
were absorbed in real time. A large fraction of people writing papers and
attending conferences haven't been doing it for 10 years.Old papers aren't</p><p>4 0.6954785 <a title="288-lsi-4" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>Introduction: The internet has significantly effected the way we do research but it's
capabilities have not yet been fully realized.First, let's acknowledge some
known effects.Self-publishingBy default, all researchers in machine learning
(and more generally computer science and physics) place their papers online
for anyone to download. The exact mechanism differs--physicists tend to use a
central repository (Arxiv) while computer scientists tend to place the papers
on their webpage. Arxiv has been slowly growing in subject breadth so it now
sometimes used by computer scientists.CollaborationEmail has enabled working
remotely with coauthors. This has allowed collaborationis which would not
otherwise have been possible and generally speeds research.Now, let's look at
attempts to go further.Blogs(like this one) allow public discussion about
topics which are not easily categorized as "a new idea in machine learning"
(like this topic).Organizationof some subfield of research. This
includesSatinder Singh</p><p>5 0.66967338 <a title="288-lsi-5" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>Introduction: One of the confusing things about research is that progress is very hard to
measure. One of the consequences of being in a hard-to-measure environment is
that the wrong things are often measured.Lines of CodeThe classical example of
this phenomenon is the old lines-of-code-produced metric for programming. It
is easy to imagine systems for producing many lines of code with very little
work that accomplish very little.Paper countIn academia, a "paper count" is an
analog of "lines of code", and it suffers from the same failure modes. The
obvious failure mode here is that we end up with a large number of
uninteresting papers since people end up spending a lot of time optimizing
this metric.ComplexityAnother metric, is "complexity" (in the eye of a
reviewer) of a paper. There is a common temptation to make a method appear
more complex than it is in order for reviewers to judge it worthy of
publication. The failure mode here is unclean thinking. Simple effective
methods are often overlooked</p><p>6 0.6557188 <a title="288-lsi-6" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>7 0.63472486 <a title="288-lsi-7" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>8 0.63318217 <a title="288-lsi-8" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>9 0.60593283 <a title="288-lsi-9" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>10 0.5939427 <a title="288-lsi-10" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>11 0.59080267 <a title="288-lsi-11" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>12 0.58808881 <a title="288-lsi-12" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>13 0.58405042 <a title="288-lsi-13" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>14 0.58103007 <a title="288-lsi-14" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>15 0.58053178 <a title="288-lsi-15" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>16 0.57908165 <a title="288-lsi-16" href="../hunch_net-2005/hunch_net-2005-04-04-Grounds_for_Rejection.html">52 hunch net-2005-04-04-Grounds for Rejection</a></p>
<p>17 0.57706559 <a title="288-lsi-17" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>18 0.57683057 <a title="288-lsi-18" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>19 0.57595247 <a title="288-lsi-19" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>20 0.56404322 <a title="288-lsi-20" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.451), (35, 0.021), (42, 0.272), (74, 0.101), (82, 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94487476 <a title="288-lda-1" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>Introduction: In research, it's often the case that solving a problem helps you realize that
it wasn't the right problem to solve. This is the case for the "reduce RL to
classification" problem with the solution hinted athereand turned into a
paperhere.The essential difficulty is that the method of stating and analyzing
reductions ends up being nonalgorithmic (unlike previous reductions) unless
you work with learning from teleoperated robots asGreg Grudicdoes. The
difficulty here is due to the reduction being dependent on the optimal policy
(which a human teleoperator might simulate, but which is otherwise
unavailable).So, thisproblemis "open" again with the caveat that this time we
want a more algorithmic solution.Whether or not this is feasible at all is
still unclear and evidence in either direction would greatly interest me. A
positive answer might have many practical implications in the long run.</p><p>2 0.94188601 <a title="288-lda-2" href="../hunch_net-2008/hunch_net-2008-10-01-NIPS_2008_workshop_on_%26%238216%3BLearning_over_Empirical_Hypothesis_Spaces%26%238217%3B.html">319 hunch net-2008-10-01-NIPS 2008 workshop on &#8216;Learning over Empirical Hypothesis Spaces&#8217;</a></p>
<p>Introduction: This workshop asks for insights how far we may/can push the theoretical
boundary of using data in the design of learning machines. Can we express our
classification rule in terms of the sample, or do we have to stick to a core
assumption of classical statistical learning theory, namely that the
hypothesis space is to be defined independent from the sample? This workshop
is particularly interested in - but not restricted to - the 'luckiness
framework' and the recently introduced notion of 'compatibility functions' in
a semi-supervised learning context (more information can be found
athttp://www.kuleuven.be/wehys).</p><p>3 0.92498714 <a title="288-lda-3" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>Introduction: Many decision problems can be represented in the formFORn=1,2,â&euro;Ś:-- Reality
chooses a datumxn.-- Decision Maker chooses his decisiondn.-- Reality chooses
an observationyn.-- Decision Maker suffers lossL(yn,dn).END FOR.The
observationyncan be, for example, tomorrow's stock price and the decisiondnthe
number of shares Decision Maker chooses to buy. The datumxnideally contains
all information that might be relevant in making this decision. We do not want
to assume anything about the way Reality generates the observations and
data.Suppose there is a good and not too complex decision ruleDmapping each
datumxto a decisionD(x). Can we perform as well, or almost as well, asD,
without knowing it? This is essentially a special case of the problem ofon-
line learning.This is a simple result of this kind. Suppose the dataxnare
taken from [0,1] andL(y,d)=|y-d|. A norm ||h|| of a functionhon [0,1] is
defined by||h||2= (Integral01h(t)dt)2+ Integral01(h'(t))2dt.Decision Maker has
a strategy that guaran</p><p>4 0.92011976 <a title="288-lda-4" href="../hunch_net-2005/hunch_net-2005-06-22-Languages__of_Learning.html">84 hunch net-2005-06-22-Languages  of Learning</a></p>
<p>Introduction: A language is a set of primitives which can be combined to succesfully create
complex objects. Languages arise in all sorts of situations: mechanical
construction, martial arts, communication, etcâ&euro;Ś Languages appear to be the key
to succesfully creating complex objects--it is difficult to come up with any
convincing example of a complex object which is not built using some language.
Since languages are so crucial to success, it is interesting to organize
various machine learning research programs by language.The most common
language in machine learning are languages for representing the solution to
machine learning. This includes:Bayes Nets and Graphical ModelsA language for
representing probability distributions. The key concept supporting modularity
is conditional independence.Michael Kearnshas been working on extending this
to game theory.Kernelized Linear ClassifiersA language for representing linear
separators, possibly in a large space. The key form of modularity here is
kerneliza</p><p>5 0.91784602 <a title="288-lda-5" href="../hunch_net-2006/hunch_net-2006-12-06-The_Spam_Problem.html">223 hunch net-2006-12-06-The Spam Problem</a></p>
<p>Introduction: TheNew York Timeshas an article on thegrowth of spam. Interesting facts
include: 9/10 of all email is spam, spam source identification is nearly
useless due to botnet spam senders, and image based spam (emails which consist
of an image only) are on the growth.Estimates of the cost of spam are almost
certainly far to low, because they do not account for the cost in time lost by
people.The image based spam which is currently penetrating many filters should
be catchable with a more sophisticated application of machine learning
technology. For the spam I see, the rendered images come in only a few
formats, which would be easy to recognize via a support vector machine (with
RBF kernel), neural network, or even nearest-neighbor architecture. The
mechanics of setting this up to run efficiently is the only real challenge.
This is the next step in the spam war.The response to this system is to make
the image based spam even more random. We should (essentially) expect to
seeCaptchaspam, and our</p><p>6 0.91614962 <a title="288-lda-6" href="../hunch_net-2009/hunch_net-2009-02-16-KDNuggets.html">342 hunch net-2009-02-16-KDNuggets</a></p>
<p>same-blog 7 0.90579647 <a title="288-lda-7" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>8 0.84164679 <a title="288-lda-8" href="../hunch_net-2005/hunch_net-2005-08-08-Apprenticeship_Reinforcement_Learning_for_Control.html">101 hunch net-2005-08-08-Apprenticeship Reinforcement Learning for Control</a></p>
<p>9 0.69795245 <a title="288-lda-9" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>10 0.61815143 <a title="288-lda-10" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>11 0.60361397 <a title="288-lda-11" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>12 0.59539127 <a title="288-lda-12" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>13 0.58929014 <a title="288-lda-13" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>14 0.5850358 <a title="288-lda-14" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>15 0.58048087 <a title="288-lda-15" href="../hunch_net-2006/hunch_net-2006-06-30-ICML_papers.html">188 hunch net-2006-06-30-ICML papers</a></p>
<p>16 0.57961893 <a title="288-lda-16" href="../hunch_net-2007/hunch_net-2007-10-24-Contextual_Bandits.html">269 hunch net-2007-10-24-Contextual Bandits</a></p>
<p>17 0.57765001 <a title="288-lda-17" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>18 0.57764208 <a title="288-lda-18" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>19 0.57758784 <a title="288-lda-19" href="../hunch_net-2005/hunch_net-2005-07-21-Six_Months.html">96 hunch net-2005-07-21-Six Months</a></p>
<p>20 0.57698089 <a title="288-lda-20" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
