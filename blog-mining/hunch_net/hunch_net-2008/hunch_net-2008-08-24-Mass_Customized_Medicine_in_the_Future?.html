<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-314" href="#">hunch_net-2008-314</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-314-html" href="http://hunch.net/?p=400">html</a></p><p>Introduction: This post is about a technology which could develop in the future.
 
Right now, a new drug might be tested by finding patients with some diagnosis and giving or not giving them a drug according to a secret randomization.  The outcome is observed, and if the average outcome for those treated is measurably better than the average outcome for those not treated, the drug might become a standard treatment.
 
Generalizing this, a filter  F  sorts people into two groups: those for treatment  A  and those not for treatment  B  based upon observations  x .  To measure the outcome, you randomize between treatment and nontreatment of group  A  and measure the relative performance of the treatment.
 
A problem often arises: in many cases the treated group does not do better than the nontreated group.  A basic question is: does this mean the treatment is bad?  With respect to the filter  F  it may mean that, but with respect to another filter  F’ , the treatment might be very effective.  For exampl</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Right now, a new drug might be tested by finding patients with some diagnosis and giving or not giving them a drug according to a secret randomization. [sent-2, score-1.367]
</p><p>2 The outcome is observed, and if the average outcome for those treated is measurably better than the average outcome for those not treated, the drug might become a standard treatment. [sent-3, score-1.395]
</p><p>3 Generalizing this, a filter  F  sorts people into two groups: those for treatment  A  and those not for treatment  B  based upon observations  x . [sent-4, score-1.201]
</p><p>4 To measure the outcome, you randomize between treatment and nontreatment of group  A  and measure the relative performance of the treatment. [sent-5, score-0.843]
</p><p>5 A problem often arises: in many cases the treated group does not do better than the nontreated group. [sent-6, score-0.297]
</p><p>6 A basic question is: does this mean the treatment is bad? [sent-7, score-0.531]
</p><p>7 With respect to the filter  F  it may mean that, but with respect to another filter  F’ , the treatment might be very effective. [sent-8, score-1.067]
</p><p>8 For example, a drug might work great for people which have one blood type, but not so well for others. [sent-9, score-0.407]
</p><p>9 The basic import is that we can learn a rule  F’  for filters which are more strict than the original  F . [sent-12, score-0.178]
</p><p>10 This can be done on  past recorded data , and if done properly we can even statistically prove that  F’  works,  without  another randomized trial. [sent-13, score-0.261]
</p><p>11 Right now, the filters  F  are typically a diagnosis of one sort or another. [sent-16, score-0.427]
</p><p>12 Instead, a doctor might record many observations, and have many learned filters  F’  applied to suggest treatments. [sent-18, score-0.489]
</p><p>13 The “not understanding the details” problem is sometimes severe, so we can expect a renewed push for understandable machine learning rules. [sent-19, score-0.28]
</p><p>14 Some tradeoff between understandability and predictive power seems to exist creating a tension: do you want a good treatment or do you want an understandable treatment? [sent-20, score-0.698]
</p><p>15 If we manage to reach a pointer in the future where  Gattaca style  near instantaneous genomic sequencing is available, feeding this into a learning algorithm is potentially very effective. [sent-22, score-0.141]
</p><p>16 In general a constant pressure to measure more should be expected. [sent-23, score-0.293]
</p><p>17 Given that we can learn from  past  data, going back and measuring additional characteristics of past patients may even be desirable. [sent-24, score-0.56]
</p><p>18 Since many treatments are commercial in the US, there will be a great deal of pressure to find a filter  F’  which appears good, and a company investing millions into the question is quite capable of overfitting so that  F’  is better than it appears. [sent-25, score-0.825]
</p><p>19 Safe and sane ways to deal with this exist, as showcased by various machine learning challenges, such as the  Netflix challenge . [sent-26, score-0.126]
</p><p>20 To gain trust in such approaches, a trustable and trusted third party capable of this sort of testing must exist. [sent-27, score-0.358]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('treatment', 0.448), ('drug', 0.307), ('filter', 0.218), ('treated', 0.213), ('outcome', 0.207), ('filters', 0.178), ('diagnosis', 0.173), ('patients', 0.173), ('pressure', 0.173), ('understandable', 0.142), ('past', 0.123), ('measure', 0.12), ('exist', 0.108), ('might', 0.1), ('observations', 0.087), ('technology', 0.086), ('capable', 0.086), ('group', 0.084), ('mean', 0.083), ('giving', 0.083), ('average', 0.077), ('measuring', 0.077), ('feeding', 0.077), ('statistically', 0.077), ('commercial', 0.077), ('doctor', 0.077), ('generalizing', 0.077), ('renewed', 0.077), ('sort', 0.076), ('secret', 0.071), ('trusted', 0.071), ('randomize', 0.071), ('treatments', 0.071), ('investing', 0.071), ('finding', 0.07), ('learned', 0.069), ('trial', 0.067), ('tension', 0.067), ('fed', 0.067), ('millions', 0.067), ('safe', 0.067), ('applied', 0.065), ('pointer', 0.064), ('sane', 0.064), ('characteristics', 0.064), ('party', 0.064), ('deal', 0.062), ('push', 0.061), ('trust', 0.061), ('recorded', 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="314-tfidf-1" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>Introduction: This post is about a technology which could develop in the future.
 
Right now, a new drug might be tested by finding patients with some diagnosis and giving or not giving them a drug according to a secret randomization.  The outcome is observed, and if the average outcome for those treated is measurably better than the average outcome for those not treated, the drug might become a standard treatment.
 
Generalizing this, a filter  F  sorts people into two groups: those for treatment  A  and those not for treatment  B  based upon observations  x .  To measure the outcome, you randomize between treatment and nontreatment of group  A  and measure the relative performance of the treatment.
 
A problem often arises: in many cases the treated group does not do better than the nontreated group.  A basic question is: does this mean the treatment is bad?  With respect to the filter  F  it may mean that, but with respect to another filter  F’ , the treatment might be very effective.  For exampl</p><p>2 0.2090722 <a title="314-tfidf-2" href="../hunch_net-2010/hunch_net-2010-09-21-Regretting_the_dead.html">411 hunch net-2010-09-21-Regretting the dead</a></p>
<p>Introduction: Nikos  pointed out this  new york times  article about  poor clinical design killing people .  For those of us who study learning from exploration information this is a reminder that low regret algorithms are particularly important, as regret in clinical trials is measured by patient deaths.
 
Two obvious improvements on the experimental design are:
  
 With reasonable record keeping of existing outcomes for the standard treatments, there is no need to explicitly assign people to a control group with the standard treatment, as that approach is effectively explored with great certainty.  Asserting otherwise would imply that the nature of effective treatments for cancer has changed between now and a year ago, which denies the value of any clinical trial. 
 An optimal experimental design will smoothly phase between exploration and exploitation as evidence for a new treatment shows that it can be effective.  This is old tech, for example in the  EXP3.P algorithm (page 12 aka 59)  although</p><p>3 0.1263624 <a title="314-tfidf-3" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>Introduction: “Science” has many meanings, but one common meaning is “the  scientific method ” which is a principled method for investigating the world using the following steps:
  
 Form a hypothesis about the world. 
 Use the hypothesis to make predictions. 
 Run experiments to confirm or disprove the predictions. 
  
The ordering of these steps is very important to the scientific method.  In particular, predictions  must  be made before experiments are run.  
 
Given that we all believe in the scientific method of investigation, it may be surprising to learn that cheating is very common.  This happens for many reasons, some innocent and some not.    
  
 Drug studies.  Pharmaceutical companies make predictions about the effects of their drugs and then conduct blind clinical studies to determine their effect.  Unfortunately, they have also been caught using some of the more advanced techniques for cheating  here : including “reprobleming”, “data set selection”, and probably “overfitting by review”</p><p>4 0.11222901 <a title="314-tfidf-4" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>Introduction: Data linkage is a problem which seems to come up in various applied machine learning problems.  I have heard it mentioned in various data mining contexts, but it seems relatively less studied for systemic reasons.
 
A very simple version of the data linkage problem is a cross hospital patient record merge.  Suppose a patient (John Doe) is admitted to a hospital (General Health), treated, and released.  Later, John Doe is admitted to a second hospital (Health General), treated, and released.  Given a large number of records of this sort, it becomes very tempting to try and predict the outcomes of treatments.  This is reasonably straightforward as a machine learning problem if there is a shared unique identifier for John Doe used by General Health and Health General along with time stamps.  We can merge the records and create examples of the form “Given symptoms and treatment, did the patient come back to a hospital within the next year?”  These examples could be fed into a learning algo</p><p>5 0.099050313 <a title="314-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>Introduction: “Overfitting” is traditionally defined as training some flexible representation so that it memorizes the data but fails to predict well in the future. For this post, I will define overfitting more generally as over-representing the performance of systems.  There are two styles of general overfitting: overrepresenting performance on particular datasets and (implicitly) overrepresenting performance of a method on future datasets.  
 
We should all be aware of these methods, avoid them where possible, and take them into account otherwise.   I have used “reproblem” and “old datasets”, and may have participated in “overfitting by review”—some of these are very difficult to avoid.
  
 
 Name 
 Method 
 Explanation 
 Remedy 
 
 
 Traditional overfitting 
 Train a complex predictor on too-few examples. 
  
 
 
 Hold out pristine examples for testing. 
 Use a simpler predictor. 
 Get more training examples. 
 Integrate over many predictors. 
 Reject papers which do this. 
 
 
 
 
 Parameter twe</p><p>6 0.096390948 <a title="314-tfidf-6" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>7 0.089048773 <a title="314-tfidf-7" href="../hunch_net-2005/hunch_net-2005-04-14-Families_of_Learning_Theory_Statements.html">56 hunch net-2005-04-14-Families of Learning Theory Statements</a></p>
<p>8 0.085286126 <a title="314-tfidf-8" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>9 0.084789805 <a title="314-tfidf-9" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>10 0.083724096 <a title="314-tfidf-10" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>11 0.080214255 <a title="314-tfidf-11" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>12 0.078334637 <a title="314-tfidf-12" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>13 0.077438802 <a title="314-tfidf-13" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>14 0.075915836 <a title="314-tfidf-14" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>15 0.075135827 <a title="314-tfidf-15" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>16 0.073216848 <a title="314-tfidf-16" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>17 0.072593488 <a title="314-tfidf-17" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>18 0.071121693 <a title="314-tfidf-18" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>19 0.070906058 <a title="314-tfidf-19" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>20 0.06944827 <a title="314-tfidf-20" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.186), (1, 0.044), (2, -0.039), (3, 0.049), (4, -0.01), (5, -0.03), (6, 0.021), (7, 0.058), (8, 0.008), (9, -0.027), (10, -0.051), (11, 0.069), (12, 0.066), (13, -0.011), (14, -0.032), (15, -0.016), (16, 0.011), (17, -0.018), (18, -0.013), (19, 0.023), (20, -0.023), (21, -0.019), (22, -0.047), (23, 0.019), (24, -0.082), (25, -0.02), (26, 0.023), (27, 0.005), (28, 0.019), (29, -0.003), (30, -0.084), (31, 0.011), (32, 0.013), (33, -0.021), (34, -0.048), (35, -0.001), (36, -0.046), (37, 0.02), (38, -0.079), (39, -0.023), (40, 0.097), (41, 0.018), (42, 0.016), (43, 0.008), (44, -0.074), (45, -0.016), (46, 0.015), (47, -0.075), (48, 0.025), (49, -0.085)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92555517 <a title="314-lsi-1" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>Introduction: This post is about a technology which could develop in the future.
 
Right now, a new drug might be tested by finding patients with some diagnosis and giving or not giving them a drug according to a secret randomization.  The outcome is observed, and if the average outcome for those treated is measurably better than the average outcome for those not treated, the drug might become a standard treatment.
 
Generalizing this, a filter  F  sorts people into two groups: those for treatment  A  and those not for treatment  B  based upon observations  x .  To measure the outcome, you randomize between treatment and nontreatment of group  A  and measure the relative performance of the treatment.
 
A problem often arises: in many cases the treated group does not do better than the nontreated group.  A basic question is: does this mean the treatment is bad?  With respect to the filter  F  it may mean that, but with respect to another filter  F’ , the treatment might be very effective.  For exampl</p><p>2 0.73370832 <a title="314-lsi-2" href="../hunch_net-2010/hunch_net-2010-09-21-Regretting_the_dead.html">411 hunch net-2010-09-21-Regretting the dead</a></p>
<p>Introduction: Nikos  pointed out this  new york times  article about  poor clinical design killing people .  For those of us who study learning from exploration information this is a reminder that low regret algorithms are particularly important, as regret in clinical trials is measured by patient deaths.
 
Two obvious improvements on the experimental design are:
  
 With reasonable record keeping of existing outcomes for the standard treatments, there is no need to explicitly assign people to a control group with the standard treatment, as that approach is effectively explored with great certainty.  Asserting otherwise would imply that the nature of effective treatments for cancer has changed between now and a year ago, which denies the value of any clinical trial. 
 An optimal experimental design will smoothly phase between exploration and exploitation as evidence for a new treatment shows that it can be effective.  This is old tech, for example in the  EXP3.P algorithm (page 12 aka 59)  although</p><p>3 0.69429177 <a title="314-lsi-3" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>Introduction: Data linkage is a problem which seems to come up in various applied machine learning problems.  I have heard it mentioned in various data mining contexts, but it seems relatively less studied for systemic reasons.
 
A very simple version of the data linkage problem is a cross hospital patient record merge.  Suppose a patient (John Doe) is admitted to a hospital (General Health), treated, and released.  Later, John Doe is admitted to a second hospital (Health General), treated, and released.  Given a large number of records of this sort, it becomes very tempting to try and predict the outcomes of treatments.  This is reasonably straightforward as a machine learning problem if there is a shared unique identifier for John Doe used by General Health and Health General along with time stamps.  We can merge the records and create examples of the form “Given symptoms and treatment, did the patient come back to a hospital within the next year?”  These examples could be fed into a learning algo</p><p>4 0.61792409 <a title="314-lsi-4" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>Introduction: One striking feature of many machine learning algorithms is the gymnastics that designers go through to avoid symmetry breaking.  In the most basic form of machine learning, there are labeled examples composed of features.  Each of these can be treated symmetrically or asymmetrically by algorithms.
  
  feature symmetry   Every feature is treated the same.   In gradient update rules, the same update is applied whether the feature is first or last.  In metric-based predictions, every feature is just as important in computing the distance.   
  example symmetry   Every example is treated the same.  Batch learning algorithms are great exemplars of this approach. 
  label symmetry   Every label is treated the same.  This is particularly noticeable in multiclass classification systems which predict according to  arg max l  w l  x  but it occurs in many other places as well. 
  
Empirically, breaking symmetry well seems to yield great algorithms.
  
  feature asymmetry   For those who like t</p><p>5 0.61387914 <a title="314-lsi-5" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>Introduction: “Science” has many meanings, but one common meaning is “the  scientific method ” which is a principled method for investigating the world using the following steps:
  
 Form a hypothesis about the world. 
 Use the hypothesis to make predictions. 
 Run experiments to confirm or disprove the predictions. 
  
The ordering of these steps is very important to the scientific method.  In particular, predictions  must  be made before experiments are run.  
 
Given that we all believe in the scientific method of investigation, it may be surprising to learn that cheating is very common.  This happens for many reasons, some innocent and some not.    
  
 Drug studies.  Pharmaceutical companies make predictions about the effects of their drugs and then conduct blind clinical studies to determine their effect.  Unfortunately, they have also been caught using some of the more advanced techniques for cheating  here : including “reprobleming”, “data set selection”, and probably “overfitting by review”</p><p>6 0.60403013 <a title="314-lsi-6" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>7 0.5976665 <a title="314-lsi-7" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>8 0.58660793 <a title="314-lsi-8" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>9 0.58467299 <a title="314-lsi-9" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>10 0.57686251 <a title="314-lsi-10" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>11 0.57479429 <a title="314-lsi-11" href="../hunch_net-2006/hunch_net-2006-04-09-Progress_in_Machine_Translation.html">171 hunch net-2006-04-09-Progress in Machine Translation</a></p>
<p>12 0.57115108 <a title="314-lsi-12" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>13 0.57003057 <a title="314-lsi-13" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>14 0.56782204 <a title="314-lsi-14" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>15 0.56031555 <a title="314-lsi-15" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>16 0.5512929 <a title="314-lsi-16" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>17 0.54892069 <a title="314-lsi-17" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>18 0.54192036 <a title="314-lsi-18" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>19 0.53924501 <a title="314-lsi-19" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>20 0.53720784 <a title="314-lsi-20" href="../hunch_net-2006/hunch_net-2006-09-07-Objective_and_subjective_interpretations_of_probability.html">205 hunch net-2006-09-07-Objective and subjective interpretations of probability</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.356), (16, 0.016), (27, 0.195), (53, 0.069), (55, 0.081), (84, 0.039), (94, 0.111), (95, 0.04)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93865573 <a title="314-lda-1" href="../hunch_net-2006/hunch_net-2006-09-07-Objective_and_subjective_interpretations_of_probability.html">205 hunch net-2006-09-07-Objective and subjective interpretations of probability</a></p>
<p>Introduction: An amusing tidbit (reproduced without permission) from Herman Chernoff’s delightful monograph, “Sequential analysis and optimal design”:
 
The use of randomization raises a philosophical question which is articulated by the following probably apocryphal anecdote.
 
The metallurgist told his friend the statistician how he planned to test the effect of heat on the strength of a metal bar by sawing the bar into six pieces. The first two would go into the hot oven, the next two into the medium oven, and the last two into the cool oven. The statistician, horrified, explained how he should randomize to avoid the effect of a possible gradient of strength in the metal bar. The method of randomization was applied, and it turned out that the randomized experiment called for putting the first two pieces into the hot oven, the next two into the medium oven, and the last two into the cool oven. “Obviously, we can’t do that,” said the metallurgist. “On the contrary, you have to do that,” said the st</p><p>2 0.86197728 <a title="314-lda-2" href="../hunch_net-2005/hunch_net-2005-03-10-Breaking_Abstractions.html">39 hunch net-2005-03-10-Breaking Abstractions</a></p>
<p>Introduction: Sam Roweis ‘s comment reminds me of a more general issue that comes up in doing research: abstractions always break.  
  
 Real number’s aren’t.  Most real numbers can not be represented with any machine.  One implication of this is that many real-number based algorithms have difficulties when implemented with floating point numbers. 
 The box on your desk is not a turing machine. A turing machine can compute anything computable, given sufficient time.  A typical computer fails terribly when the state required for the computation exceeds some limit. 
 Nash equilibria aren’t equilibria.  This comes up when trying to predict human behavior based on the result of the equilibria computation.  Often, it doesn’t work. 
 The  probability  isn’t.  Probability is an abstraction expressing either our lack of knowledge (the Bayesian viewpoint) or fundamental randomization (the frequentist viewpoint).  From the frequentist viewpoint the lack of knowledge typically precludes actually knowing the fu</p><p>3 0.84569371 <a title="314-lda-3" href="../hunch_net-2005/hunch_net-2005-05-29-Bad_ideas.html">76 hunch net-2005-05-29-Bad ideas</a></p>
<p>Introduction: I found these two essays on bad ideas interesting.  Neither of these is written from the viewpoint of research, but they are both highly relevant.
  
  Why smart people have bad ideas  by Paul Graham 
  Why smart people defend bad ideas  by Scott Berkun (which appeared on  slashdot ) 
  
In my experience, bad ideas are common  and  over confidence in ideas is common.  This overconfidence can take either the form of excessive condemnation or excessive praise.  Some of this is necessary to the process of research.  For example, some overconfidence in the value of your own research is expected and probably necessary to motivate your own investigation.  Since research is a rather risky business, much of it does not pan out.  Learning to accept when something does not pan out is a critical skill which is sometimes never acquired.
 
Excessive condemnation can be a real ill when it’s encountered.  This has two effects:
  
 When the penalty for being wrong is too large, it means people have a</p><p>same-blog 4 0.82611489 <a title="314-lda-4" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>Introduction: This post is about a technology which could develop in the future.
 
Right now, a new drug might be tested by finding patients with some diagnosis and giving or not giving them a drug according to a secret randomization.  The outcome is observed, and if the average outcome for those treated is measurably better than the average outcome for those not treated, the drug might become a standard treatment.
 
Generalizing this, a filter  F  sorts people into two groups: those for treatment  A  and those not for treatment  B  based upon observations  x .  To measure the outcome, you randomize between treatment and nontreatment of group  A  and measure the relative performance of the treatment.
 
A problem often arises: in many cases the treated group does not do better than the nontreated group.  A basic question is: does this mean the treatment is bad?  With respect to the filter  F  it may mean that, but with respect to another filter  F’ , the treatment might be very effective.  For exampl</p><p>5 0.81278729 <a title="314-lda-5" href="../hunch_net-2013/hunch_net-2013-07-10-Thoughts_on_Artificial_Intelligence.html">486 hunch net-2013-07-10-Thoughts on Artificial Intelligence</a></p>
<p>Introduction: David McAllester   starts a blog .</p><p>6 0.66345423 <a title="314-lda-6" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>7 0.59474182 <a title="314-lda-7" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>8 0.58228225 <a title="314-lda-8" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>9 0.56706303 <a title="314-lda-9" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>10 0.56247962 <a title="314-lda-10" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>11 0.56181151 <a title="314-lda-11" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>12 0.56003636 <a title="314-lda-12" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>13 0.55938631 <a title="314-lda-13" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>14 0.55895364 <a title="314-lda-14" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>15 0.55528593 <a title="314-lda-15" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>16 0.5540725 <a title="314-lda-16" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>17 0.55173683 <a title="314-lda-17" href="../hunch_net-2005/hunch_net-2005-07-21-Six_Months.html">96 hunch net-2005-07-21-Six Months</a></p>
<p>18 0.55145186 <a title="314-lda-18" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>19 0.55127722 <a title="314-lda-19" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>20 0.55063093 <a title="314-lda-20" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
