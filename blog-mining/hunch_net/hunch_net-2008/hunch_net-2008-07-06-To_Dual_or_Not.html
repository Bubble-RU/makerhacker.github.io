<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>308 hunch net-2008-07-06-To Dual or Not</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-308" href="#">hunch_net-2008-308</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>308 hunch net-2008-07-06-To Dual or Not</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-308-html" href="http://hunch.net/?p=339">html</a></p><p>Introduction: YoramandShai'sonline learning tutorialatICMLbrings up a question for me, "Why
use thedual?"The basic setting is learning a weight vectorwiso that the
functionf(x)= sumiwixioptimizes some convex loss function.The functional view
of the dual is that instead of (or in addition to) keeping track ofwiover the
feature space, you keep track of a vectorajover the examples and definewi=
sumjajxji.The above view of duality makes operating in the dual appear
unnecessary, because in the end a weight vector is always used. The tutorial
suggests that thinking about the dual gives a unified algorithmic font for
deriving online learning algorithms. I haven't worked with the dual
representation much myself, but I have seen a few examples where it appears
helpful.NoiseWhen doing online optimization (i.e. online learning where you
are allowed to look at individual examples multiple times), the dual
representation may be helpful in dealing with noisy labels.RatesOne annoyance
of working in the primal spac</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dual', 0.604), ('weight', 0.306), ('nonconvex', 0.241), ('vector', 0.199), ('representation', 0.189), ('track', 0.14), ('view', 0.131), ('duality', 0.121), ('annoyance', 0.121), ('online', 0.119), ('font', 0.112), ('functionf', 0.112), ('primal', 0.112), ('examples', 0.111), ('space', 0.11), ('deriving', 0.105), ('unified', 0.105), ('unavoidable', 0.105), ('unnecessary', 0.101), ('functional', 0.088)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="308-tfidf-1" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>Introduction: YoramandShai'sonline learning tutorialatICMLbrings up a question for me, "Why
use thedual?"The basic setting is learning a weight vectorwiso that the
functionf(x)= sumiwixioptimizes some convex loss function.The functional view
of the dual is that instead of (or in addition to) keeping track ofwiover the
feature space, you keep track of a vectorajover the examples and definewi=
sumjajxji.The above view of duality makes operating in the dual appear
unnecessary, because in the end a weight vector is always used. The tutorial
suggests that thinking about the dual gives a unified algorithmic font for
deriving online learning algorithms. I haven't worked with the dual
representation much myself, but I have seen a few examples where it appears
helpful.NoiseWhen doing online optimization (i.e. online learning where you
are allowed to look at individual examples multiple times), the dual
representation may be helpful in dealing with noisy labels.RatesOne annoyance
of working in the primal spac</p><p>2 0.14884979 <a title="308-tfidf-2" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>Introduction: The Gibbs-Jaynes theorem is a classical result that tells us that the highest
entropy distribution (most uncertain, least committed, etc.) subject to
expectation constraints on a set of features is an exponential family
distribution with the features as sufficient statistics. In math,argmax_p
H(p)s.t. E_p[f_i] = c_iis given by e^{\sum \lambda_i f_i}/Z. (Z here is the
necessary normalization constraint, and the lambdas are free parameters we set
to meet the expectation constraints).A great deal of statistical mechanics
flows from this result, and it has proven very fruitful in learning as well.
(Motivating work in models in text learning and Conditional Random Fields, for
instance. ) The result has been demonstrated a number of ways. One of the most
elegant is the Ã¢â‚¬Å“geometricÃ¢â‚¬Â versionhere.In the case when the
expectation constraints come from data, this tells us that the maximum entropy
distribution is exactly the maximum likelihood distribution in the exponential
family. ItÃ</p><p>3 0.10506035 <a title="308-tfidf-3" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>Introduction: Several papers at NIPS caught my attention.Elad HazanandSatyen Kale,Online
Submodular OptimizationThey define an algorithm for online optimization of
submodular functions with regret guarantees. This places submodular
optimization roughly on par with online convex optimization as tractable
settings for online learning.Elad HazanandSatyen KaleOn Stochastic and Worst-
Case Models of Investing. At it's core, this is yet another example of
modifying worst-case online learning to deal with variance, but the
application to financial models is particularly cool and it seems plausibly
superior other common approaches for financial modeling.Mark Palatucci,Dean
Pomerlau,Tom Mitchell, andGeoff HintonZero Shot Learning with Semantic Output
CodesThe goal here is predicting a label in a multiclass supervised setting
where the label never occurs in the training data. They have some basic
analysis and also a nice application to FMRI brain reading.Shobha
Venkataraman,Avrim Blum,Dawn Song,Subhabrata Sen</p><p>4 0.10332488 <a title="308-tfidf-4" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>Introduction: TheExponentiated Gradientalgorithm byManfred WarmuthandJyrki Kivinencame out
just as I was starting graduate school, so I missed it both at a conference
and in class. It's a fine algorithm which has a remarkable theoretical
statement accompanying it.The essential statement holds in the "online
learning with an adversary" setting. Initially, there are of set ofnweights,
which might have values(1/n,â&euro;Ś,1/n), (or any other values from a probability
distribution). Everything happens in a round-by-round fashion. On each round,
the following happens:The world reveals a set of featuresx in {0,1}n. In the
online learning with an adversary literature, the features are called
"experts" and thought of as subpredictors, but this interpretation isn't
necessary--you can just use feature values as experts (or maybe the feature
value and the negation of the feature value as two experts).EG makes a
prediction according toy' = w . x(dot product).The world reveals the truthy in
[0,1].EG updates the weights</p><p>5 0.09287779 <a title="308-tfidf-5" href="../hunch_net-2006/hunch_net-2006-05-16-The_value_of_the_orthodox_view_of_Boosting.html">179 hunch net-2006-05-16-The value of the orthodox view of Boosting</a></p>
<p>Introduction: The term "boosting" comes from the idea of using a meta-algorithm which takes
"weak" learners (that may be able to only barely predict slightly better than
random) and turn them into strongly capable learners (which predict very
well).Adaboostin 1995 was the first widely used (and useful) boosting
algorithm, although there were theoretical boosting algorithms floating around
since 1990 (see the bottom ofthis page).Since then, many different
interpretations of why boosting works have arisen. There is significant
discussion about these different views in theannals of statistics, including
aresponsebyYoav FreundandRobert Schapire.I believe there is a great deal of
value to be found in the original view of boosting (meta-algorithm for
creating a strong learner from a weak learner). This is not a claim that one
particular viewpoint obviates the value of all others, but rather that no
other viewpoint seems to really capture important properties.Comparing with
all other views of boosting is t</p><p>6 0.087684073 <a title="308-tfidf-6" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>7 0.086944543 <a title="308-tfidf-7" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>8 0.086386926 <a title="308-tfidf-8" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>9 0.083965987 <a title="308-tfidf-9" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>10 0.077970684 <a title="308-tfidf-10" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>11 0.076877892 <a title="308-tfidf-11" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>12 0.076518185 <a title="308-tfidf-12" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>13 0.075150058 <a title="308-tfidf-13" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>14 0.075081915 <a title="308-tfidf-14" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>15 0.073948145 <a title="308-tfidf-15" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>16 0.071749344 <a title="308-tfidf-16" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>17 0.070735253 <a title="308-tfidf-17" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>18 0.067980103 <a title="308-tfidf-18" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>19 0.066812493 <a title="308-tfidf-19" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>20 0.063783243 <a title="308-tfidf-20" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, -0.091), (2, -0.021), (3, 0.037), (4, -0.026), (5, 0.085), (6, 0.044), (7, 0.014), (8, -0.014), (9, 0.026), (10, 0.067), (11, -0.072), (12, -0.018), (13, -0.008), (14, 0.007), (15, -0.018), (16, 0.01), (17, 0.01), (18, 0.006), (19, 0.01), (20, -0.003), (21, -0.015), (22, -0.027), (23, -0.035), (24, 0.033), (25, -0.052), (26, -0.009), (27, -0.072), (28, 0.01), (29, -0.039), (30, -0.011), (31, -0.055), (32, -0.03), (33, -0.07), (34, 0.076), (35, -0.023), (36, -0.005), (37, 0.022), (38, -0.002), (39, -0.014), (40, 0.005), (41, -0.066), (42, 0.017), (43, 0.005), (44, -0.042), (45, 0.094), (46, 0.043), (47, 0.076), (48, 0.074), (49, -0.022)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93729407 <a title="308-lsi-1" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>Introduction: YoramandShai'sonline learning tutorialatICMLbrings up a question for me, "Why
use thedual?"The basic setting is learning a weight vectorwiso that the
functionf(x)= sumiwixioptimizes some convex loss function.The functional view
of the dual is that instead of (or in addition to) keeping track ofwiover the
feature space, you keep track of a vectorajover the examples and definewi=
sumjajxji.The above view of duality makes operating in the dual appear
unnecessary, because in the end a weight vector is always used. The tutorial
suggests that thinking about the dual gives a unified algorithmic font for
deriving online learning algorithms. I haven't worked with the dual
representation much myself, but I have seen a few examples where it appears
helpful.NoiseWhen doing online optimization (i.e. online learning where you
are allowed to look at individual examples multiple times), the dual
representation may be helpful in dealing with noisy labels.RatesOne annoyance
of working in the primal spac</p><p>2 0.65311944 <a title="308-lsi-2" href="../hunch_net-2009/hunch_net-2009-12-27-Interesting_things_at_NIPS_2009.html">385 hunch net-2009-12-27-Interesting things at NIPS 2009</a></p>
<p>Introduction: Several papers at NIPS caught my attention.Elad HazanandSatyen Kale,Online
Submodular OptimizationThey define an algorithm for online optimization of
submodular functions with regret guarantees. This places submodular
optimization roughly on par with online convex optimization as tractable
settings for online learning.Elad HazanandSatyen KaleOn Stochastic and Worst-
Case Models of Investing. At it's core, this is yet another example of
modifying worst-case online learning to deal with variance, but the
application to financial models is particularly cool and it seems plausibly
superior other common approaches for financial modeling.Mark Palatucci,Dean
Pomerlau,Tom Mitchell, andGeoff HintonZero Shot Learning with Semantic Output
CodesThe goal here is predicting a label in a multiclass supervised setting
where the label never occurs in the training data. They have some basic
analysis and also a nice application to FMRI brain reading.Shobha
Venkataraman,Avrim Blum,Dawn Song,Subhabrata Sen</p><p>3 0.60767722 <a title="308-lsi-3" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>Introduction: TheExponentiated Gradientalgorithm byManfred WarmuthandJyrki Kivinencame out
just as I was starting graduate school, so I missed it both at a conference
and in class. It's a fine algorithm which has a remarkable theoretical
statement accompanying it.The essential statement holds in the "online
learning with an adversary" setting. Initially, there are of set ofnweights,
which might have values(1/n,â&euro;Ś,1/n), (or any other values from a probability
distribution). Everything happens in a round-by-round fashion. On each round,
the following happens:The world reveals a set of featuresx in {0,1}n. In the
online learning with an adversary literature, the features are called
"experts" and thought of as subpredictors, but this interpretation isn't
necessary--you can just use feature values as experts (or maybe the feature
value and the negation of the feature value as two experts).EG makes a
prediction according toy' = w . x(dot product).The world reveals the truthy in
[0,1].EG updates the weights</p><p>4 0.60273463 <a title="308-lsi-4" href="../hunch_net-2007/hunch_net-2007-10-17-Online_as_the_new_adjective.html">267 hunch net-2007-10-17-Online as the new adjective</a></p>
<p>Introduction: Online learning is in vogue, which means we should expect to see in the near
future:Online boosting.Online decision trees.Online SVMs. (actually, we've
already seen)Online deep learning.Online parallel learning.etc…There are three
fundamental drivers of this trend.Increasing size of datasets makes online
algorithms attractive.Online learning can simply be more efficient than batch
learning. Here is a picture from a class on online learning:The point of this
picture is that even in 3 dimensions and even with linear constraints, finding
the minima of a set in an online fashion can be typically faster than finding
the minima in a batch fashion. To see this, note that there is a minimal
number of gradient updates (i.e. 2) required in order to reach the minima in
the typical case. Given this, it's best to do these updates as quickly as
possible, which implies doing the first update online (i.e. before seeing all
the examples) is preferred. Note that this is the simplest possible setting--
m</p><p>5 0.5946964 <a title="308-lsi-5" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem. When someone screws up, do you fire them?
Or do you accept the error and let them continue? This is a very difficult
problem and we all know of stories where the wrong decision was made.Online
learning(as meant here), is a subfield of learning theory which analyzes the
online learning model.In the online learning model, there are a set of
hypotheses or "experts". On any instantancex, each expert makes a predictiony.
A master algorithmAuses these predictions to form it's own predictionyAand
then learns the correct predictiony*. This process repeats.The goal of online
learning is to find a master algorithmAwhich uses the advice of the experts to
make good predictions. In particular, we typically want to guarantee that the
master algorithm performs almost as well as the best expert. IfL(e)is the loss
of experteandL(A)is the loss of the master algorithm, it is often possible to
prove:L(A) less than mineL(e) + log(number of experts)over all sequences.In
p</p><p>6 0.59133261 <a title="308-lsi-6" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>7 0.57436627 <a title="308-lsi-7" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>8 0.57373536 <a title="308-lsi-8" href="../hunch_net-2009/hunch_net-2009-01-07-Interesting_Papers_at_SODA_2009.html">334 hunch net-2009-01-07-Interesting Papers at SODA 2009</a></p>
<p>9 0.5652262 <a title="308-lsi-9" href="../hunch_net-2006/hunch_net-2006-11-22-Explicit_Randomization_in_Learning_algorithms.html">219 hunch net-2006-11-22-Explicit Randomization in Learning algorithms</a></p>
<p>10 0.55912793 <a title="308-lsi-10" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>11 0.53851163 <a title="308-lsi-11" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>12 0.53194141 <a title="308-lsi-12" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>13 0.52693367 <a title="308-lsi-13" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>14 0.52293348 <a title="308-lsi-14" href="../hunch_net-2006/hunch_net-2006-05-16-The_value_of_the_orthodox_view_of_Boosting.html">179 hunch net-2006-05-16-The value of the orthodox view of Boosting</a></p>
<p>15 0.51700824 <a title="308-lsi-15" href="../hunch_net-2010/hunch_net-2010-12-04-Vowpal_Wabbit%2C_version_5.0%2C_and_the_second_heresy.html">419 hunch net-2010-12-04-Vowpal Wabbit, version 5.0, and the second heresy</a></p>
<p>16 0.51422709 <a title="308-lsi-16" href="../hunch_net-2005/hunch_net-2005-04-06-Structured_Regret_Minimization.html">53 hunch net-2005-04-06-Structured Regret Minimization</a></p>
<p>17 0.50786668 <a title="308-lsi-17" href="../hunch_net-2006/hunch_net-2006-06-24-Online_convex_optimization_at_COLT.html">186 hunch net-2006-06-24-Online convex optimization at COLT</a></p>
<p>18 0.50695425 <a title="308-lsi-18" href="../hunch_net-2007/hunch_net-2007-07-01-Watchword%3A_Online_Learning.html">252 hunch net-2007-07-01-Watchword: Online Learning</a></p>
<p>19 0.49734938 <a title="308-lsi-19" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>20 0.49556035 <a title="308-lsi-20" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.081), (42, 0.231), (45, 0.064), (68, 0.046), (74, 0.111), (82, 0.027), (87, 0.303), (95, 0.019)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.89152408 <a title="308-lda-1" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>Introduction: Do we have computer hardware sufficient for AI? This question is difficult to
answer, but here's a try:One way to achieve AI is by simulating a human brain.
A human brain has about 1015synapses which operate at about 102per second
implying about 1017bit ops per second.A modern computer runs at
109cycles/second and operates on 102bits per cycle implying 1011bits processed
per second.The gap here is only 6 orders of magnitude, which can be plausibly
surpassed via cluster machines. For example, theBlueGene/Loperates 105nodes
(one order of magnitude short). It's peak recorded performance is about
0.5*1015FLOPS which translates to about 1016bit ops per second, which is
nearly 1017.There are many criticisms (both positive and negative) for this
argument.Simulation of a human brain might require substantially more detail.
Perhaps an additional 102is required per neuron.We may not need to simulate a
human brain to achieve AI. There are certainly many examples where we have
been able to design</p><p>same-blog 2 0.88406634 <a title="308-lda-2" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>Introduction: YoramandShai'sonline learning tutorialatICMLbrings up a question for me, "Why
use thedual?"The basic setting is learning a weight vectorwiso that the
functionf(x)= sumiwixioptimizes some convex loss function.The functional view
of the dual is that instead of (or in addition to) keeping track ofwiover the
feature space, you keep track of a vectorajover the examples and definewi=
sumjajxji.The above view of duality makes operating in the dual appear
unnecessary, because in the end a weight vector is always used. The tutorial
suggests that thinking about the dual gives a unified algorithmic font for
deriving online learning algorithms. I haven't worked with the dual
representation much myself, but I have seen a few examples where it appears
helpful.NoiseWhen doing online optimization (i.e. online learning where you
are allowed to look at individual examples multiple times), the dual
representation may be helpful in dealing with noisy labels.RatesOne annoyance
of working in the primal spac</p><p>3 0.85706729 <a title="308-lda-3" href="../hunch_net-2005/hunch_net-2005-02-12-ROC_vs._Accuracy_vs._AROC.html">18 hunch net-2005-02-12-ROC vs. Accuracy vs. AROC</a></p>
<p>Introduction: Foster Provostand I discussed the merits of ROC curves vs. accuracy
estimation. Here is a quick summary of our discussion.The "Receiver Operating
Characteristic" (ROC) curve is an alternative to accuracy for the evaluation
of learning algorithms on natural datasets. The ROC curve is acurveand not a
single number statistic. In particular, this means that the comparison of two
algorithms on a dataset does not always produce an obvious order.Accuracy (= 1
- error rate) is a standard method used to evaluate learning algorithms. It is
a single-number summary of performance.AROC is the area under the ROC curve.
It is a single number summary of performance.The comparison of these metrics
is a subtle affair, because in machine learning, they are compared on
different natural datasets. This makes some sense if we accept the hypothesis
"Performance on past learning problems (roughly) predicts performance on
future learning problems."The ROC vs. accuracy discussion is often conflated
with "is the</p><p>4 0.66193503 <a title="308-lda-4" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>5 0.66048801 <a title="308-lda-5" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pooland I recently discussed the similarities and differences between
academia and open source programming.Similarities:Cost profileResearch and
programming share approximately the same cost profile: A large upfront effort
is required to produce something useful, and then "anyone" can use it. (The
"anyone" is not quite right for either group because only sufficiently
technical people could use it.)Wealth profileA "wealthy" academic or open
source programmer is someone who has contributed a lot to other people in
research or programs. Much of academia is a "gift culture": whoever gives the
most is most respected.ProblemsBoth academia and open source programming
suffer from similar problems.Whether or not (and which) open source program is
used are perhaps too-often personality driven rather than driven by capability
or usefulness. Similar phenomena can happen in academia with respect to
directions of research.Funding is often a problem for both groups. Academics
often invest many</p><p>6 0.65925586 <a title="308-lda-6" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>7 0.65905517 <a title="308-lda-7" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>8 0.65731204 <a title="308-lda-8" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>9 0.65683711 <a title="308-lda-9" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>10 0.65571815 <a title="308-lda-10" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>11 0.65398639 <a title="308-lda-11" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>12 0.6527431 <a title="308-lda-12" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>13 0.65268284 <a title="308-lda-13" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>14 0.65252978 <a title="308-lda-14" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>15 0.65200913 <a title="308-lda-15" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>16 0.65199637 <a title="308-lda-16" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>17 0.65195036 <a title="308-lda-17" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>18 0.65095776 <a title="308-lda-18" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>19 0.65072215 <a title="308-lda-19" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>20 0.65039688 <a title="308-lda-20" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
