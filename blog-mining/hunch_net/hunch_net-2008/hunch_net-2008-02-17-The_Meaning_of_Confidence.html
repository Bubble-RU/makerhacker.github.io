<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>289 hunch net-2008-02-17-The Meaning of Confidence</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2008" href="../home/hunch_net-2008_home.html">hunch_net-2008</a> <a title="hunch_net-2008-289" href="#">hunch_net-2008-289</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>289 hunch net-2008-02-17-The Meaning of Confidence</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2008-289-html" href="http://hunch.net/?p=317">html</a></p><p>Introduction: In many machine learning papers experiments are done and little confidence
bars are reported for the results. This often seems quite clear, until you
actually try to figure out what it means. There are several different kinds of
'confidence' being used, and it's easy to become confused.Confidence =
Probability. For those who haven't worried about confidence for a long time,
confidence is simply the probability of some event. You are confident about
events which have a large probability. This meaning of confidence is
inadequate in many applications because we want to reason about how much more
information we have, how much more is needed, and where to get it. As an
example, a learning algorithm might predict that the probability of an event
is0.5, but it's unclear if the probability is0.5because no examples have been
provided or0.5because many examples have been provided and the event is simply
fundamentally uncertain.Classical Confidence Intervals. These are common in
learning theory.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In many machine learning papers experiments are done and little confidence bars are reported for the results. [sent-1, score-0.588]
</p><p>2 For those who haven't worried about confidence for a long time, confidence is simply the probability of some event. [sent-5, score-1.265]
</p><p>3 This meaning of confidence is inadequate in many applications because we want to reason about how much more information we have, how much more is needed, and where to get it. [sent-7, score-0.638]
</p><p>4 Given observations from the world (such as err-or-not on examples), an interval is constructed around the hidden value. [sent-15, score-0.793]
</p><p>5 The semantics of the classical confidence interval is: the (random) interval contains the (determistic but unknown) value, with high probability. [sent-16, score-1.908]
</p><p>6 Classical confidence intervals (as applied in machine learning) typically require that observations are independent. [sent-17, score-1.08]
</p><p>7 One drawback of concern is that classical confidence intervals breakdown rapidly when conditioning on information. [sent-19, score-1.242]
</p><p>8 If you have a prior distribution over the way the world creates observations, then you can use Bayes law to construct a posterior distribution over the way the world creates observations. [sent-22, score-0.85]
</p><p>9 With respect to this posterior distribution, you construct an interval containing the truth with high probability. [sent-23, score-0.792]
</p><p>10 The semantics of a Bayesian confidence interval is "If the world is drawn from the prior the interval contains the truth with high probability". [sent-24, score-2.093]
</p><p>11 Unlike classical confidence intervals, it's easy to have a statement conditioned on features. [sent-26, score-0.832]
</p><p>12 My principal source of uneasiness with respect to Bayesian confidence intervals is the "If the world is drawn from the prior" clause--I believe it is difficult to know and specify a correct prior distribution. [sent-29, score-1.25]
</p><p>13 Many Bayesians aren't bothered by this, but the meaning of a Bayesian confidence interval becomes unclear if you work with an incorrect (or subjective) prior. [sent-30, score-1.142]
</p><p>14 The basic line of reasoning seems to be: "Someone once told me that if observations are IID, then their average converges to a normal distribution, so let's use an unbiased estimate of the mean and variance, assume convergence, and then construct a confidence interval for the mean of a gaussian". [sent-33, score-1.353]
</p><p>15 Asymptotic intervals are asymptotically equivalent to classical confidence intervals, but they can differ spectacularly with finite sample sizes. [sent-34, score-1.158]
</p><p>16 A classical confidence interval for the error rate is[0,log(1/d)/n]wherenis the size of the test set anddis the probability that the interval contains the truth. [sent-36, score-2.025]
</p><p>17 The essential idea, is that we cease to make intervals about the world, and instead make intervals around our predictions of the world. [sent-40, score-0.985]
</p><p>18 A basic question is: can this notion of internal confidence guide other forms of exploration? [sent-44, score-0.609]
</p><p>19 In this setting, a confidence interval is (roughly) a set of predictions output by an adaptive rule with the property that it contains the true observation a large fraction of the time. [sent-47, score-1.168]
</p><p>20 This approach has yet to catch on, but it is interesting because it provides a feature dependent confidence interval without making strong assumptions about the world. [sent-48, score-0.994]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('confidence', 0.543), ('interval', 0.451), ('intervals', 0.406), ('classical', 0.209), ('world', 0.17), ('probability', 0.137), ('observations', 0.131), ('contains', 0.128), ('truth', 0.093), ('construct', 0.091), ('asymptotic', 0.084), ('prior', 0.083), ('distribution', 0.079), ('semantics', 0.072), ('guide', 0.066), ('posterior', 0.064), ('provided', 0.064), ('bayesian', 0.059), ('creates', 0.057), ('high', 0.054), ('error', 0.054), ('event', 0.053), ('meaning', 0.053), ('unclear', 0.053), ('rate', 0.052), ('mean', 0.049), ('drawn', 0.048), ('predictions', 0.046), ('reported', 0.045), ('conditioning', 0.045), ('cease', 0.045), ('incorrect', 0.042), ('inadequate', 0.042), ('confident', 0.042), ('wherenis', 0.042), ('bayesians', 0.042), ('featuresx', 0.042), ('worried', 0.042), ('examples', 0.042), ('around', 0.041), ('essential', 0.041), ('easy', 0.041), ('common', 0.04), ('actually', 0.04), ('bogus', 0.039), ('containing', 0.039), ('normal', 0.039), ('conditioned', 0.039), ('foundations', 0.039), ('breakdown', 0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="289-tfidf-1" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>Introduction: In many machine learning papers experiments are done and little confidence
bars are reported for the results. This often seems quite clear, until you
actually try to figure out what it means. There are several different kinds of
'confidence' being used, and it's easy to become confused.Confidence =
Probability. For those who haven't worried about confidence for a long time,
confidence is simply the probability of some event. You are confident about
events which have a large probability. This meaning of confidence is
inadequate in many applications because we want to reason about how much more
information we have, how much more is needed, and where to get it. As an
example, a learning algorithm might predict that the probability of an event
is0.5, but it's unclear if the probability is0.5because no examples have been
provided or0.5because many examples have been provided and the event is simply
fundamentally uncertain.Classical Confidence Intervals. These are common in
learning theory.</p><p>2 0.71576196 <a title="289-tfidf-2" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data
sourcesD,PrS ~ D(f(D) > g(S)) > 1-dwherefis some function of the distribution
(such as the mean) andgis some function of the observed sampleS. The
constraints onDcan vary between "Independent and identically distributed (IID)
samples from a gaussian with an unknown mean" to "IID samples from an
arbitrary distributionD". There are even some confidence intervals which do
not require IID samples.Classical confidence intervals often confuse people.
They donotsay "with high probability, for my observed sample, the bounds
holds". Instead, they tell you that if you reason according to the confidence
interval in the future (and the constraints onDare satisfied), then you are
not often wrong. Restated, they tell you something about what a safe procedure
is in a stochastic world wheredis the safety parameter.There are a number of
results in theoretical machine learning which use confidence intervals. For
example,TheE3alg</p><p>3 0.14248063 <a title="289-tfidf-3" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.
There are at least 3 distinct ways the word is used.BayesianThe Bayesian
notion of probability is a 'degree of belief'. The degree of belief that some
event (i.e. "stock goes up" or "stock goes down") occurs can be measured by
asking a sequence of questions of the form "Would you bet the stock goes up or
down atYto 1 odds?" A consistent better will switch from 'for' to 'against' at
some single value ofY. The probability is thenY/(Y+1). Bayesian probabilities
express lack of knowledge rather than randomization. They are useful in
learning because we often lack knowledge and expressing that lack flexibly
makes the learning algorithms work better. Bayesian Learning uses
'probability' in this way exclusively.FrequentistThe Frequentist notion of
probability is a rate of occurence. A rate of occurrence can be measured by
doing an experiment many times. If an event occursktimes innexperiments then
it has probability ab</p><p>4 0.1352527 <a title="289-tfidf-4" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>Introduction: Many different paper deadlines are coming up soon so I made a little reference
table. Out of curiosity, I also computed the interval between submission
deadline and
conference.ConferenceLocationDateDeadlineintervalCOLTPittsburghJune
22-25January 21152ICMLPittsburghJune 26-28January 30/February 6140UAIMITJuly
13-16March 9/March 16119AAAIBostonJuly 16-20February
16/21145KDDPhiladelphiaAugust 23-26March 3/March 10166It looks like the
northeastern US is the big winner as far as location this year.</p><p>5 0.11947624 <a title="289-tfidf-5" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>Introduction: I don't consider myself a "Bayesian", but I do try hard to understand why
Bayesian learning works. For the purposes of this post, Bayesian learning is a
simple process of:Specify a prior over world models.Integrate using Bayes law
with respect to all observed information to compute a posterior over world
models.Predict according to the posterior.Bayesian learning has many
advantages over other learning programs:InterpolationBayesian learning methods
interpolate all the way to pure engineering. When faced with any learning
problem, there is a choice of how much time and effort a human vs. a computer
puts in. (For example, the mars rover pathfinding algorithms are almost
entirely engineered.) When creating an engineered system, you build a model of
the world and then find a good controller in that model. Bayesian methods
interpolate to this extreme because the Bayesian prior can be a delta function
on one model of the world. What this means is that a recipe of "think harder"
(about speci</p><p>6 0.11830445 <a title="289-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>7 0.10690965 <a title="289-tfidf-7" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>8 0.10651219 <a title="289-tfidf-8" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>9 0.10483295 <a title="289-tfidf-9" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>10 0.10441969 <a title="289-tfidf-10" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>11 0.10309404 <a title="289-tfidf-11" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>12 0.10046986 <a title="289-tfidf-12" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>13 0.095937461 <a title="289-tfidf-13" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>14 0.091775812 <a title="289-tfidf-14" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>15 0.084316716 <a title="289-tfidf-15" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>16 0.084235519 <a title="289-tfidf-16" href="../hunch_net-2007/hunch_net-2007-08-28-Live_ML_Class.html">261 hunch net-2007-08-28-Live ML Class</a></p>
<p>17 0.081976891 <a title="289-tfidf-17" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>18 0.081457749 <a title="289-tfidf-18" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>19 0.077062353 <a title="289-tfidf-19" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>20 0.072508141 <a title="289-tfidf-20" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, -0.119), (2, -0.048), (3, -0.019), (4, 0.008), (5, -0.131), (6, -0.103), (7, -0.029), (8, -0.025), (9, -0.167), (10, -0.11), (11, -0.007), (12, -0.126), (13, -0.159), (14, -0.168), (15, -0.165), (16, 0.027), (17, 0.063), (18, -0.003), (19, 0.074), (20, -0.014), (21, -0.062), (22, -0.31), (23, 0.265), (24, 0.06), (25, 0.302), (26, -0.057), (27, 0.108), (28, -0.033), (29, 0.027), (30, -0.105), (31, 0.017), (32, -0.075), (33, -0.068), (34, -0.113), (35, 0.122), (36, 0.167), (37, 0.001), (38, 0.032), (39, 0.076), (40, 0.031), (41, 0.135), (42, -0.055), (43, -0.034), (44, -0.041), (45, 0.116), (46, 0.105), (47, 0.026), (48, -0.014), (49, -0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97689116 <a title="289-lsi-1" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>Introduction: In many machine learning papers experiments are done and little confidence
bars are reported for the results. This often seems quite clear, until you
actually try to figure out what it means. There are several different kinds of
'confidence' being used, and it's easy to become confused.Confidence =
Probability. For those who haven't worried about confidence for a long time,
confidence is simply the probability of some event. You are confident about
events which have a large probability. This meaning of confidence is
inadequate in many applications because we want to reason about how much more
information we have, how much more is needed, and where to get it. As an
example, a learning algorithm might predict that the probability of an event
is0.5, but it's unclear if the probability is0.5because no examples have been
provided or0.5because many examples have been provided and the event is simply
fundamentally uncertain.Classical Confidence Intervals. These are common in
learning theory.</p><p>2 0.96636766 <a title="289-lsi-2" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data
sourcesD,PrS ~ D(f(D) > g(S)) > 1-dwherefis some function of the distribution
(such as the mean) andgis some function of the observed sampleS. The
constraints onDcan vary between "Independent and identically distributed (IID)
samples from a gaussian with an unknown mean" to "IID samples from an
arbitrary distributionD". There are even some confidence intervals which do
not require IID samples.Classical confidence intervals often confuse people.
They donotsay "with high probability, for my observed sample, the bounds
holds". Instead, they tell you that if you reason according to the confidence
interval in the future (and the constraints onDare satisfied), then you are
not often wrong. Restated, they tell you something about what a safe procedure
is in a stochastic world wheredis the safety parameter.There are a number of
results in theoretical machine learning which use confidence intervals. For
example,TheE3alg</p><p>3 0.48280984 <a title="289-lsi-3" href="../hunch_net-2007/hunch_net-2007-08-28-Live_ML_Class.html">261 hunch net-2007-08-28-Live ML Class</a></p>
<p>Introduction: Davor andChunnanpoint out thatMLSS 2007 in Tuebingenhaslive videofor the
majority of the world that is not there (heh).</p><p>4 0.47580469 <a title="289-lsi-4" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.
There are at least 3 distinct ways the word is used.BayesianThe Bayesian
notion of probability is a 'degree of belief'. The degree of belief that some
event (i.e. "stock goes up" or "stock goes down") occurs can be measured by
asking a sequence of questions of the form "Would you bet the stock goes up or
down atYto 1 odds?" A consistent better will switch from 'for' to 'against' at
some single value ofY. The probability is thenY/(Y+1). Bayesian probabilities
express lack of knowledge rather than randomization. They are useful in
learning because we often lack knowledge and expressing that lack flexibly
makes the learning algorithms work better. Bayesian Learning uses
'probability' in this way exclusively.FrequentistThe Frequentist notion of
probability is a rate of occurence. A rate of occurrence can be measured by
doing an experiment many times. If an event occursktimes innexperiments then
it has probability ab</p><p>5 0.41343307 <a title="289-lsi-5" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>Introduction: Textbooks invariably seem to carry the proof that uses Markov's inequality,
moment-generating functions, and Taylor approximations. Here's an easier
way.For, letbe the KL divergence between a coin of biasand one of
bias:Theorem:Suppose you doindependent tosses of a coin of bias. The
probability of seeingheads or more, for, is at most. So is the probability of
seeingheads or less, for.Remark:By Pinsker's inequality,.ProofLet's do
thecase; the other is identical.Letbe the distribution overinduced by a coin
of bias, and likewisefor a coin of bias. Letbe the set of all sequences
oftosses which containheads or more. We'd like to show thatis unlikely
under.Pick any, with sayheads. Then:Sincefor every, we haveand we're done.</p><p>6 0.38313481 <a title="289-lsi-6" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>7 0.37749344 <a title="289-lsi-7" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>8 0.34527054 <a title="289-lsi-8" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>9 0.32941258 <a title="289-lsi-9" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>10 0.32672447 <a title="289-lsi-10" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>11 0.31684196 <a title="289-lsi-11" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>12 0.31597409 <a title="289-lsi-12" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>13 0.30393049 <a title="289-lsi-13" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>14 0.30111885 <a title="289-lsi-14" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>15 0.30075318 <a title="289-lsi-15" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>16 0.29259679 <a title="289-lsi-16" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>17 0.28707772 <a title="289-lsi-17" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>18 0.28632993 <a title="289-lsi-18" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>19 0.27725714 <a title="289-lsi-19" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>20 0.27640876 <a title="289-lsi-20" href="../hunch_net-2009/hunch_net-2009-12-24-Top_graduates_this_season.html">384 hunch net-2009-12-24-Top graduates this season</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.015), (16, 0.307), (35, 0.028), (42, 0.265), (45, 0.024), (50, 0.014), (68, 0.052), (69, 0.037), (74, 0.085), (76, 0.049), (95, 0.012)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94101423 <a title="289-lda-1" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>Introduction: Suppose we have a set of classifierscmaking binary predictions from an
inputxand we see examples in an online fashion. In particular, we repeatedly
see an unlabeled examplex, make a predictiony'(possibly based on the
classifiersc), and then see the correct labely.When one of these classifiers
is perfect, there is a great algorithm available: predict according to the
majority vote over every classifier consistent with every previous example.
This is called the Halving algorithm. It makes at mostlog2|c|mistakes since on
any mistake, at least half of the classifiers are eliminated.Obviously, we
can't generally hope that the there exists a classifier which never errs.
TheBinomial Weighting algorithmis an elegant technique allowing a variant
Halving algorithm to cope with errors by creating a set of virtual classifiers
for every classifier which occasionally disagree with the original classifier.
The Halving algorithm on this set of virtual classifiers satisfies a theorem
of the form:errors</p><p>2 0.91448683 <a title="289-lda-2" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<p>Introduction: According to theNew York Times,Yahoo is releasing Project Panama shortly.
Project Panama is about better predicting which advertisements are relevant to
a search, implying a higher click through rate, implying larger income
forYahoo. There are two things that seem interesting here:A significant
portion of that improved accuracy is almost certainly machine learning at
work.The quantitative effect is huge--the estimate in the article is
$600*106.Googlealready has such improvements andMicrosoft Searchis surely
working on them, which suggest this is (perhaps) a $109per year machine
learning problem.The exact methodology under use is unlikely to be publicly
discussed in the near future because of the competitive enivironment.
Hopefully we'll have some public "war stories" at some point in the future
when this information becomes less sensitive. For now, it's reassuring to
simply note that machine learning is having a big impact.</p><p>same-blog 3 0.90969867 <a title="289-lda-3" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>Introduction: In many machine learning papers experiments are done and little confidence
bars are reported for the results. This often seems quite clear, until you
actually try to figure out what it means. There are several different kinds of
'confidence' being used, and it's easy to become confused.Confidence =
Probability. For those who haven't worried about confidence for a long time,
confidence is simply the probability of some event. You are confident about
events which have a large probability. This meaning of confidence is
inadequate in many applications because we want to reason about how much more
information we have, how much more is needed, and where to get it. As an
example, a learning algorithm might predict that the probability of an event
is0.5, but it's unclear if the probability is0.5because no examples have been
provided or0.5because many examples have been provided and the event is simply
fundamentally uncertain.Classical Confidence Intervals. These are common in
learning theory.</p><p>4 0.89235389 <a title="289-lda-4" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data
sourcesD,PrS ~ D(f(D) > g(S)) > 1-dwherefis some function of the distribution
(such as the mean) andgis some function of the observed sampleS. The
constraints onDcan vary between "Independent and identically distributed (IID)
samples from a gaussian with an unknown mean" to "IID samples from an
arbitrary distributionD". There are even some confidence intervals which do
not require IID samples.Classical confidence intervals often confuse people.
They donotsay "with high probability, for my observed sample, the bounds
holds". Instead, they tell you that if you reason according to the confidence
interval in the future (and the constraints onDare satisfied), then you are
not often wrong. Restated, they tell you something about what a safe procedure
is in a stochastic world wheredis the safety parameter.There are a number of
results in theoretical machine learning which use confidence intervals. For
example,TheE3alg</p><p>5 0.88634264 <a title="289-lda-5" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>Introduction: This, again, is something of a research direction rather than a single
problem.There are several metrics people care about which depend upon the
relative ranking of examples and there are sometimes good reasons to care
about such metrics. Examples includeAROC, "F1â&euro;ł, the proportion of the time
that the top ranked element is in some class, the proportion of the top 10
examples in some class (google's problem), the lowest ranked example of some
class, and the "sort distance" from a predicted ranking to a correct ranking.
Seeherefor an example of some of these.ProblemWhat does the ability to
classify well imply about performance under these metrics?Past
WorkProbabilistic classification under squared errorcan be solved with a
classifier. A counterexample shows this does not imply a good AROC.Sample
complexity bounds forAROC(andhere).A paper on "Learning to Order
Things".DifficultySeveral of these may be easy. Some of them may be
hard.ImpactPositive or negative results will broaden our under</p><p>6 0.81121373 <a title="289-lda-6" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>7 0.75819665 <a title="289-lda-7" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>8 0.73009825 <a title="289-lda-8" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>9 0.71559322 <a title="289-lda-9" href="../hunch_net-2008/hunch_net-2008-01-07-2008_Summer_Machine_Learning_Conference_Schedule.html">283 hunch net-2008-01-07-2008 Summer Machine Learning Conference Schedule</a></p>
<p>10 0.70933932 <a title="289-lda-10" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>11 0.70321566 <a title="289-lda-11" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>12 0.70245862 <a title="289-lda-12" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>13 0.70080173 <a title="289-lda-13" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>14 0.70064604 <a title="289-lda-14" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>15 0.69762397 <a title="289-lda-15" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>16 0.69176465 <a title="289-lda-16" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>17 0.68795508 <a title="289-lda-17" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>18 0.68376404 <a title="289-lda-18" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>19 0.6824441 <a title="289-lda-19" href="../hunch_net-2005/hunch_net-2005-11-02-Progress_in_Active_Learning.html">127 hunch net-2005-11-02-Progress in Active Learning</a></p>
<p>20 0.68012774 <a title="289-lda-20" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
