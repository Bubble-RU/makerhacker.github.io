<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>185 hunch net-2006-06-16-Regularization = Robustness</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-185" href="#">hunch_net-2006-185</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>185 hunch net-2006-06-16-Regularization = Robustness</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-185-html" href="http://hunch.net/?p=197">html</a></p><p>Introduction: The Gibbs-Jaynes theorem is a classical result that tells us that the highest
entropy distribution (most uncertain, least committed, etc.) subject to
expectation constraints on a set of features is an exponential family
distribution with the features as sufficient statistics. In math,argmax_p
H(p)s.t. E_p[f_i] = c_iis given by e^{\sum \lambda_i f_i}/Z. (Z here is the
necessary normalization constraint, and the lambdas are free parameters we set
to meet the expectation constraints).A great deal of statistical mechanics
flows from this result, and it has proven very fruitful in learning as well.
(Motivating work in models in text learning and Conditional Random Fields, for
instance. ) The result has been demonstrated a number of ways. One of the most
elegant is the Ã¢â‚¬Å“geometricÃ¢â‚¬Â versionhere.In the case when the
expectation constraints come from data, this tells us that the maximum entropy
distribution is exactly the maximum likelihood distribution in the exponential
family. ItÃ</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The Gibbs-Jaynes theorem is a classical result that tells us that the highest entropy distribution (most uncertain, least committed, etc. [sent-1, score-0.825]
</p><p>2 ) subject to expectation constraints on a set of features is an exponential family distribution with the features as sufficient statistics. [sent-2, score-0.792]
</p><p>3 (Z here is the necessary normalization constraint, and the lambdas are free parameters we set to meet the expectation constraints). [sent-6, score-0.128]
</p><p>4 A great deal of statistical mechanics flows from this result, and it has proven very fruitful in learning as well. [sent-7, score-0.408]
</p><p>5 ) The result has been demonstrated a number of ways. [sent-9, score-0.14]
</p><p>6 In the case when the expectation constraints come from data, this tells us that the maximum entropy distribution is exactly the maximum likelihood distribution in the exponential family. [sent-11, score-1.827]
</p><p>7 ItÃ¢â‚¬â„¢s a surprising connection and the duality it flows from appears in a wide variety of work. [sent-12, score-0.397]
</p><p>8 (For instance, Martin WainwrightÃ¢â‚¬â„¢sapproximate inference techniquesrely (in essence) on this result. [sent-13, score-0.136]
</p><p>9 The traditional trick is to pull a sleight of hand in the derivation. [sent-15, score-0.284]
</p><p>10 We start with the primal entropy problem, move to the dual, and in the dual add a Ã¢â‚¬Å“priorÃ¢â‚¬Â that penalizes the lambdas. [sent-16, score-0.688]
</p><p>11 ) This game is played in a variety of papers, and itÃ¢â‚¬â„¢s a sleight of hand because the penalties donÃ¢â‚¬â„¢t come from the motivating problem (the primal) but rather get tacked on at the end. [sent-18, score-0.451]
</p><p>12 So I realized a few months back, that the primal (entropy) problem that regularization relates to is remarkably natural. [sent-20, score-0.572]
</p><p>13 Basically, it tells us that regularization in the dual corresponds directly to uncertainty (mini-max) about the constraints in the primal. [sent-21, score-0.936]
</p><p>14 What we end up with is a distribution p that is robust in the sense that it maximizes the entropy subject to a large set of potential constraints. [sent-22, score-0.622]
</p><p>15 Schapire, have a paper that derives this relation and then goes a step further to show what performance guarantees the method provides. [sent-26, score-0.278]
</p><p>16 ItÃ¢â‚¬â„¢s a great paper and I hope you get a chance to check it out:Performance guarantees for regularized maximum entropy density estimation. [sent-27, score-0.938]
</p><p>17 Arkin show a related result where regularization directly follows from a robustness or uncertainty guarantee. [sent-36, score-0.675]
</p><p>18 Yasemin Altun and Alex Smola have a paper (that I havenÃ¢â‚¬â„¢t yet finished, but at least begins very well) that generalizes the regularized maximum entropy duality to a whole class of statistical inference procedures. [sent-38, score-1.43]
</p><p>19 Unifying Divergence Minimization and Statistical Inference via Convex DualityThe deep, unifying result seems to be what the title of the post says: robustness = regularization. [sent-40, score-0.302]
</p><p>20 This viewpoint makes regularization seem like much less of a hack, and goes further in suggesting just what range of constants might be reasonable. [sent-41, score-0.341]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('entropy', 0.333), ('maximum', 0.232), ('regularization', 0.215), ('re', 0.202), ('constraints', 0.196), ('primal', 0.187), ('dual', 0.168), ('flows', 0.151), ('regularized', 0.151), ('sleight', 0.151), ('distribution', 0.147), ('result', 0.14), ('tells', 0.139), ('inference', 0.136), ('generalizes', 0.134), ('duality', 0.134), ('expectation', 0.128), ('goes', 0.126), ('likelihood', 0.125), ('whole', 0.125), ('statistical', 0.123), ('motivating', 0.117), ('schapire', 0.117), ('variety', 0.112), ('realized', 0.108), ('robustness', 0.095), ('uncertainty', 0.091), ('features', 0.088), ('exponential', 0.082), ('check', 0.081), ('robust', 0.079), ('guarantees', 0.079), ('show', 0.073), ('hand', 0.071), ('dud', 0.067), ('fruitful', 0.067), ('proven', 0.067), ('smola', 0.067), ('unifying', 0.067), ('us', 0.066), ('subject', 0.063), ('penalty', 0.062), ('relates', 0.062), ('jordan', 0.062), ('wainwright', 0.062), ('begins', 0.062), ('pull', 0.062), ('density', 0.062), ('geometric', 0.062), ('directly', 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999976 <a title="185-tfidf-1" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>Introduction: The Gibbs-Jaynes theorem is a classical result that tells us that the highest
entropy distribution (most uncertain, least committed, etc.) subject to
expectation constraints on a set of features is an exponential family
distribution with the features as sufficient statistics. In math,argmax_p
H(p)s.t. E_p[f_i] = c_iis given by e^{\sum \lambda_i f_i}/Z. (Z here is the
necessary normalization constraint, and the lambdas are free parameters we set
to meet the expectation constraints).A great deal of statistical mechanics
flows from this result, and it has proven very fruitful in learning as well.
(Motivating work in models in text learning and Conditional Random Fields, for
instance. ) The result has been demonstrated a number of ways. One of the most
elegant is the Ã¢â‚¬Å“geometricÃ¢â‚¬Â versionhere.In the case when the
expectation constraints come from data, this tells us that the maximum entropy
distribution is exactly the maximum likelihood distribution in the exponential
family. ItÃ</p><p>2 0.14884979 <a title="185-tfidf-2" href="../hunch_net-2008/hunch_net-2008-07-06-To_Dual_or_Not.html">308 hunch net-2008-07-06-To Dual or Not</a></p>
<p>Introduction: YoramandShai'sonline learning tutorialatICMLbrings up a question for me, "Why
use thedual?"The basic setting is learning a weight vectorwiso that the
functionf(x)= sumiwixioptimizes some convex loss function.The functional view
of the dual is that instead of (or in addition to) keeping track ofwiover the
feature space, you keep track of a vectorajover the examples and definewi=
sumjajxji.The above view of duality makes operating in the dual appear
unnecessary, because in the end a weight vector is always used. The tutorial
suggests that thinking about the dual gives a unified algorithmic font for
deriving online learning algorithms. I haven't worked with the dual
representation much myself, but I have seen a few examples where it appears
helpful.NoiseWhen doing online optimization (i.e. online learning where you
are allowed to look at individual examples multiple times), the dual
representation may be helpful in dealing with noisy labels.RatesOne annoyance
of working in the primal spac</p><p>3 0.12186326 <a title="185-tfidf-3" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>Introduction: In recent years, there’s been an explosion of free educational resources that
make high-level knowledge and skills accessible to an ever-wider group of
people. In your own field, you probably have a good idea of where to look for
the answer to any particular question. But outside your areas of expertise,
sifting through textbooks, Wikipedia articles, research papers, and online
lectures can be bewildering (unless you’re fortunate enough to have a
knowledgeable colleague to consult). What are the key concepts in the field,
how do they relate to each other, which ones should you learn, and where
should you learn them?Courses are a major vehicle for packaging educational
materials for a broad audience. The trouble is that they’re typically meant to
be consumed linearly, regardless of your specific background or goals. Also,
unless thousands of other people have had the same background and learning
goals, there may not even be a course that fits your needs. Recently, we
(Roger GrosseandCol</p><p>4 0.11828399 <a title="185-tfidf-4" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>Introduction: A few weeks ago I readthis. David Blei and I spent some time thinking hard
about this a few years back (thanks to Kary Myers for pointing us to it):In
short I was thinking that Ã¢â‚¬Å“bayesian belief updatingÃ¢â‚¬Â and
Ã¢â‚¬Å“maximum entropyÃ¢â‚¬Â were two othogonal principles. But it appear
that they are not, and that they can even be in conflict !Example (from Kass
1996); consider a Die (6 sides), consider prior knowledge E[X]=3.5.Maximum
entropy leads to P(X)= (1/6, 1/6, 1/6, 1/6, 1/6, 1/6).Now consider a new piece
of evidence A=Ã¢â‚¬ÂX is an odd numberÃ¢â‚¬ÂBayesian posterior P(X|A)=
P(A|X) P(X) = (1/3, 0, 1/3, 0, 1/3, 0).But MaxEnt with the constraints
E[X]=3.5 and E[Indicator function of A]=1 leads to (.22, 0, .32, 0, .47, 0) !!
(note that E[Indicator function of A]=P(A))Indeed, for MaxEnt, because there
is no more Ã¢â‚¬Ëœ6Ã¢â‚¬Â², big numbers must be more probable to ensure an
average of 3.5. For bayesian updating, P(X|A) doesnÃ¢â‚¬â„¢t have to have a
3.5 expectation. P(X) a</p><p>5 0.09754952 <a title="185-tfidf-5" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>Introduction: Yaroslav Bulatovsays that we should think about regularization a bit. It's a
complex topic which I only partially understand, so I'll try to explain from a
couple viewpoints.Functionally. Regularization is optimizing some
representation to fit the dataandminimize some notion of predictor complexity.
This notion of complexity is often the l1or l2norm on a set of parameters, but
the term can be used much more generally. Empirically, this often works much
better than simply fitting the data.Statistical Learning
ViewpointRegularization is about the failiure of statistical learning to
adequately predict generalization error. Lete(c,D)be the expected error rate
with respect toDof classifiercande(c,S)the observed error rate on a sampleS.
There are numerous bounds of the form: assuming i.i.d. samples, with high
probability over the drawn samplesS,e(c,D) less than e(c,S) +
f(complexity)wherecomplexityis some measure of the size of a set of functions.
Unfortunately, we have never convincingly na</p><p>6 0.095852122 <a title="185-tfidf-6" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>7 0.089048073 <a title="185-tfidf-7" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>8 0.084466673 <a title="185-tfidf-8" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>9 0.082079701 <a title="185-tfidf-9" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>10 0.081804588 <a title="185-tfidf-10" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>11 0.081761464 <a title="185-tfidf-11" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>12 0.081309512 <a title="185-tfidf-12" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>13 0.080802746 <a title="185-tfidf-13" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>14 0.078504868 <a title="185-tfidf-14" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>15 0.076311611 <a title="185-tfidf-15" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>16 0.072418772 <a title="185-tfidf-16" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>17 0.072339259 <a title="185-tfidf-17" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>18 0.07229238 <a title="185-tfidf-18" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>19 0.069565959 <a title="185-tfidf-19" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>20 0.067528069 <a title="185-tfidf-20" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.173), (1, -0.046), (2, -0.022), (3, 0.013), (4, -0.055), (5, 0.018), (6, -0.049), (7, -0.062), (8, 0.026), (9, -0.051), (10, 0.002), (11, -0.015), (12, -0.054), (13, 0.047), (14, -0.01), (15, 0.03), (16, 0.058), (17, -0.007), (18, 0.017), (19, 0.021), (20, -0.017), (21, 0.061), (22, -0.028), (23, 0.001), (24, 0.021), (25, -0.088), (26, -0.002), (27, -0.034), (28, 0.026), (29, -0.042), (30, 0.035), (31, -0.06), (32, 0.019), (33, 0.026), (34, 0.017), (35, -0.018), (36, 0.061), (37, -0.021), (38, 0.107), (39, -0.017), (40, 0.04), (41, 0.012), (42, -0.001), (43, -0.039), (44, -0.092), (45, -0.03), (46, 0.08), (47, 0.008), (48, 0.031), (49, 0.026)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96408415 <a title="185-lsi-1" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>Introduction: The Gibbs-Jaynes theorem is a classical result that tells us that the highest
entropy distribution (most uncertain, least committed, etc.) subject to
expectation constraints on a set of features is an exponential family
distribution with the features as sufficient statistics. In math,argmax_p
H(p)s.t. E_p[f_i] = c_iis given by e^{\sum \lambda_i f_i}/Z. (Z here is the
necessary normalization constraint, and the lambdas are free parameters we set
to meet the expectation constraints).A great deal of statistical mechanics
flows from this result, and it has proven very fruitful in learning as well.
(Motivating work in models in text learning and Conditional Random Fields, for
instance. ) The result has been demonstrated a number of ways. One of the most
elegant is the Ã¢â‚¬Å“geometricÃ¢â‚¬Â versionhere.In the case when the
expectation constraints come from data, this tells us that the maximum entropy
distribution is exactly the maximum likelihood distribution in the exponential
family. ItÃ</p><p>2 0.66575605 <a title="185-lsi-2" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>Introduction: Following up on Hal Daume's post and John's post on cool and interesting
things seen at NIPS I'll post my own little list of neat papers here as well.
Of course it's going to be biased towards what I think is interesting. Also, I
have to say that I hadn't been able to see many papers this year at nips due
to myself being too busy, so please feel free to contribute the papers that
you liked1. P. Mudigonda, V. Kolmogorov, P. Torr. An Analysis of Convex
Relaxations for MAP Estimation. A surprising paper which shows that many of
the more sophisticated convex relaxations that had been proposed recently
turns out to be subsumed by the simplest LP relaxation. Be careful next time
you try a cool new convex relaxation!2. D. Sontag, T. Jaakkola. New Outer
Bounds on the Marginal Polytope. The title says it all. The marginal polytope
is the set of local marginal distributions over subsets of variables that are
globally consistent in the sense that there is at least one distribution over
all the va</p><p>3 0.64501035 <a title="185-lsi-3" href="../hunch_net-2005/hunch_net-2005-12-11-More_NIPS_Papers.html">139 hunch net-2005-12-11-More NIPS Papers</a></p>
<p>Introduction: Let me add to John's post with a few of my own favouritesfrom this year's
conference. First, let me say thatSanjoy's talk,Coarse Sample Complexity
Bounds for ActiveLearningwas also one of my favourites, as was theForgettron
paper.I also really enjoyed the last third ofChristos'talkon the complexity of
finding Nash equilibria.And, speaking of tagging, I thinkthe U.Mass Citeseer
replacement systemRexafrom the demo track is very cool.Finally, let me add my
recommendations for specific papers:Z. Ghahramani, K. Heller:Bayesian Sets[no
preprint](A very elegant probabilistic information retrieval style modelof
which objects are "most like" a given subset of objects.)T. Griffiths, Z.
Ghahramani:Infinite Latent Feature Models andthe Indian Buffet
Process[preprint](A Dirichlet style prior over infinite binary matrices
withbeautiful exchangeability properties.)K. Weinberger, J. Blitzer, L.
Saul:Distance Metric Learning forLarge Margin Nearest Neighbor
Classification[preprint](A nice idea about ho</p><p>4 0.60219657 <a title="185-lsi-4" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>Introduction: I thought this was a very good NIPS with many excellent papers. The following
are a few NIPS papers which I liked and I hope to study more carefully when I
get the chance. The list is not exhaustive and in no particular
order…Preconditioner Approximations for Probabilistic Graphical
Models.Pradeeep Ravikumar and John Lafferty.I thought the use of
preconditioner methods from solving linear systems in the context of
approximate inference was novel and interesting. The results look good and I'd
like to understand the limitations.Rodeo: Sparse nonparametric regression in
high dimensions.John Lafferty and Larry Wasserman.A very interesting approach
to feature selection in nonparametric regression from a frequentist framework.
The use of lengthscale variables in each dimension reminds me a lot of
'Automatic Relevance Determination' in Gaussian process regression -- it would
be interesting to compare Rodeo to ARD in GPs.Interpolating between types and
tokens by estimating power law generators</p><p>5 0.60040545 <a title="185-lsi-5" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>Introduction: John makes a fascinating point about structured classification (and slightly
scooped my post!). Maximum Margin Markov Networks (M3N) are an interesting
example of the second class of structured classifiers (where the
classification of one label depends on the others), and one of my favorite
papers. I'm not alone: the paper won the best student paper award at NIPS in
2003.There are some things I find odd about the paper. For instance, it says
of probabilistic models"cannot handle high dimensional feature spaces and lack
strong theoretical guarrantees."I'm aware of no such limitations.
Also:"Unfortunately, even probabilistic graphical models that are trained
discriminatively do not achieve the same level of performance as SVMs,
especially when kernel features are used."This is quite interesting and
contradicts my own experience as well as that of a number of
peopleIgreatlyrespect. I wonder what the root cause is: perhaps there is
something different about the data Ben+Carlos were working</p><p>6 0.59678209 <a title="185-lsi-6" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>7 0.57880694 <a title="185-lsi-7" href="../hunch_net-2006/hunch_net-2006-07-05-more_icml_papers.html">189 hunch net-2006-07-05-more icml papers</a></p>
<p>8 0.5543015 <a title="185-lsi-8" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>9 0.54759139 <a title="185-lsi-9" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>10 0.53307056 <a title="185-lsi-10" href="../hunch_net-2006/hunch_net-2006-07-26-Two_more_UAI_papers_of_interest.html">199 hunch net-2006-07-26-Two more UAI papers of interest</a></p>
<p>11 0.52400869 <a title="185-lsi-11" href="../hunch_net-2011/hunch_net-2011-08-01-Interesting_papers_at_COLT_2011.html">439 hunch net-2011-08-01-Interesting papers at COLT 2011</a></p>
<p>12 0.51745737 <a title="185-lsi-12" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>13 0.50671417 <a title="185-lsi-13" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>14 0.49884558 <a title="185-lsi-14" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>15 0.49592996 <a title="185-lsi-15" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>16 0.48291937 <a title="185-lsi-16" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>17 0.47599438 <a title="185-lsi-17" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>18 0.47322387 <a title="185-lsi-18" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>19 0.46058655 <a title="185-lsi-19" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>20 0.45548531 <a title="185-lsi-20" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.011), (26, 0.014), (35, 0.07), (42, 0.225), (45, 0.02), (55, 0.366), (68, 0.046), (69, 0.016), (74, 0.103), (88, 0.01), (95, 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.88987082 <a title="185-lda-1" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>Introduction: TheNYAS ML symposiumgrew again this year to 170 participants, despite the need
to outsmart or otherwise tunnel througha crowd.Perhaps the most distinct talk
was by Bob Bell on various aspects of theNetflix prizecompetition. I also
enjoyed several student posters includingMatt Hoffman's cool examples of blind
source separation for music.I'm somewhat surprised how much the workshop has
grown, as it is now comparable in size to a small conference, although in
style more similar to a workshop. At some point as an event grows, it becomes
owned by the community rather than the organizers, so if anyone has
suggestions on improving it, speak up and be heard.</p><p>same-blog 2 0.85870481 <a title="185-lda-2" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>Introduction: The Gibbs-Jaynes theorem is a classical result that tells us that the highest
entropy distribution (most uncertain, least committed, etc.) subject to
expectation constraints on a set of features is an exponential family
distribution with the features as sufficient statistics. In math,argmax_p
H(p)s.t. E_p[f_i] = c_iis given by e^{\sum \lambda_i f_i}/Z. (Z here is the
necessary normalization constraint, and the lambdas are free parameters we set
to meet the expectation constraints).A great deal of statistical mechanics
flows from this result, and it has proven very fruitful in learning as well.
(Motivating work in models in text learning and Conditional Random Fields, for
instance. ) The result has been demonstrated a number of ways. One of the most
elegant is the Ã¢â‚¬Å“geometricÃ¢â‚¬Â versionhere.In the case when the
expectation constraints come from data, this tells us that the maximum entropy
distribution is exactly the maximum likelihood distribution in the exponential
family. ItÃ</p><p>3 0.84812826 <a title="185-lda-3" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>Introduction: One prescription for solving a problem well is:State the problem, in the
simplest way possible. In particular, this statement should involve no
contamination with or anticipation of the solution.Think about solutions to
the stated problem.Stating a problem in a succinct and crisp manner tends to
invite a simple elegant solution. When a problem can not be stated succinctly,
we wonder if the problem is even understood. (And when a problem is not
understood, we wonder if a solution can be meaningful.)Reinforcement learning
does step (1) well. It provides a clean simple language to state general AI
problems. In reinforcement learning there is a set of actionsA, a set of
observationsO, and a rewardr. The reinforcement learning problem, in general,
is defined by a conditional measureD( o, r | (o,r,a)*)which produces an
observationoand a rewardrgiven a history(o,r,a)*. The goal in reinforcement
learning is to find a policypi:(o,r,a)*-> amapping histories to actions so as
to maximize (or appro</p><p>4 0.84477288 <a title="185-lda-4" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<p>Introduction: I found Tong Zhang's paper onData Dependent Concentration Bounds for
Sequential Prediction Algorithmsinteresting. Roughly speaking, it states a
tight bound on the future error rate for online learning algorithms assuming
that samples are drawn independently. This bound is easily computed and will
make the progressive validation approaches usedheresignificantly more
practical.</p><p>5 0.73059756 <a title="185-lda-5" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>Introduction: One way that many conferences in machine learning assign reviewers to papers
is via bidding, which has steps something like:Invite people to reviewAccept
papersReviewers look at title and abstract and state the papers they are
interested in reviewing.Some massaging happens, but reviewers often get
approximately the papers they bid for.At the ICML business meeting,Andrew
McCallumsuggested getting rid of bidding for papers. A couple reasons were
given:PrivacyThe title and abstract of the entire set of papers is visible to
every participating reviewer. Some authors might be uncomfortable about this
for submitted papers. I'm not sympathetic to this reason: the point of
submitting a paper to review is to publish it, so the value (if any) of not
publishing a part of it a little bit earlier seems limited.CliquesA bidding
system is gameable. If you have 3 buddies and you inform each other of your
submissions, you can each bid for your friend's papers and express a
disinterest in others. There</p><p>6 0.57458574 <a title="185-lda-6" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>7 0.57399184 <a title="185-lda-7" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>8 0.57322377 <a title="185-lda-8" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>9 0.57182276 <a title="185-lda-9" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>10 0.57139844 <a title="185-lda-10" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>11 0.57110101 <a title="185-lda-11" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>12 0.57078928 <a title="185-lda-12" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>13 0.57053578 <a title="185-lda-13" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>14 0.56991291 <a title="185-lda-14" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>15 0.56967676 <a title="185-lda-15" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>16 0.56792611 <a title="185-lda-16" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>17 0.56760579 <a title="185-lda-17" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>18 0.56746376 <a title="185-lda-18" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>19 0.56739342 <a title="185-lda-19" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>20 0.56627721 <a title="185-lda-20" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
