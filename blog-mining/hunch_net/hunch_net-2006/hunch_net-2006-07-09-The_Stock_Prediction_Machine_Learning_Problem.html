<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-193" href="#">hunch_net-2006-193</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-193-html" href="http://hunch.net/?p=210">html</a></p><p>Introduction: …is discussed inthis nytimes article. I generally expect such approaches to
become more common since computers are getting faster, machine learning is
getting better, and data is becoming more plentiful. This is another example
where machine learning technology may have a huge economic impact. Some side
notes:We-in-research know almost nothing about how these things are done
(because it is typically a corporate secret).… but the limited discussion in
the article seem naive from a machine learning viewpoint.The learning process
used apparently often fails to take into account transaction costs.What little
of the approaches is discussed appears modeling based. It seems plausible that
more direct prediction methods can yield an edge.One difficulty with stock
picking as a research topic is that it is inherently a zero sum game (for
every winner, there is a loser). Much of the rest of research is positive sum
(basically, everyone wins).</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sum', 0.279), ('discussed', 0.221), ('transaction', 0.207), ('getting', 0.199), ('secret', 0.192), ('corporate', 0.181), ('wins', 0.181), ('approaches', 0.165), ('notes', 0.16), ('naive', 0.16), ('apparently', 0.155), ('economic', 0.155), ('stock', 0.15), ('picking', 0.15), ('winner', 0.143), ('modeling', 0.143), ('zero', 0.143), ('article', 0.139), ('basically', 0.136), ('fails', 0.134)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999976 <a title="193-tfidf-1" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>Introduction: …is discussed inthis nytimes article. I generally expect such approaches to
become more common since computers are getting faster, machine learning is
getting better, and data is becoming more plentiful. This is another example
where machine learning technology may have a huge economic impact. Some side
notes:We-in-research know almost nothing about how these things are done
(because it is typically a corporate secret).… but the limited discussion in
the article seem naive from a machine learning viewpoint.The learning process
used apparently often fails to take into account transaction costs.What little
of the approaches is discussed appears modeling based. It seems plausible that
more direct prediction methods can yield an edge.One difficulty with stock
picking as a research topic is that it is inherently a zero sum game (for
every winner, there is a loser). Much of the rest of research is positive sum
(basically, everyone wins).</p><p>2 0.14464435 <a title="193-tfidf-2" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>Introduction: Virtually every discipline of significant human endeavor has a way explaining
itself as fundamental and important. In all the cases I know of, they are both
right (they are vital) and wrong (they are not solely vital).Politics. This is
the one that everyone is familiar with at the moment. "What could be more
important than the process of making decisions?"Science and Technology. This
is the one that we-the-academics are familiar with. "The loss of modern
science and technology would be catastrophic."Military. "Without the military,
a nation will be invaded and destroyed."(insert your favorite here)Within
science and technology, the same thing happens again.Mathematics. "What could
be more important than a precise language for establishing truths?"Physics.
"Nothing is more fundamental than the laws which govern the universe.
Understanding them is the key to understanding everything else."Biology.
"Without life, we wouldn't be here, so clearly the study of life is
fundamental."Computer S</p><p>3 0.11779339 <a title="193-tfidf-3" href="../hunch_net-2005/hunch_net-2005-07-21-Six_Months.html">96 hunch net-2005-07-21-Six Months</a></p>
<p>Introduction: This is the6 month pointin the "run a research blog" experiment, so it seems
like a good point to take stock and assess.One fundamental question is: "Is it
worth it?" The idea of running a research blog will never become widely
popular and useful unless it actually aids research. On the negative side,
composing ideas for a post and maintaining a blog takes a significant amount
of time. On the positive side, the process might yield better research because
there is an opportunity for better, faster feedback implying better, faster
thinking.My answer at the moment is a provisional "yes". Running the blog has
been incidentally helpful in several ways:It is sometimes
educational.exampleMore often, the process of composing thoughts well enough
to post simply aids thinking. This has resulted in a couple solutions to
problems ofinterest(and perhaps more over time). If you really want to solve a
problem, letting the world know is helpful. This isn't necessarily because the
world will help you s</p><p>4 0.10183636 <a title="193-tfidf-4" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>Introduction: Suppose you have a dataset with 2 terafeatures (we only count nonzero entries
in a datamatrix), and want to learn a good linear predictor in a reasonable
amount of time. How do you do it? As a learning theorist, the first thing you
do is pray that this is too much data for the number of parameters--but that's
not the case, there are around 16 billion examples, 16 million parameters, and
people really care about a high quality predictor, so subsampling is not a
good strategy.Alekhvisited us last summer, and we had a breakthrough
(seeherefor details), coming up with the first learning algorithm I've seen
that is provably faster thanany futuresingle machine learning algorithm. The
proof of this is simple: We can output a optimal-up-to-precision linear
predictor faster than the data can be streamed through the network interface
of any single machine involved in the computation.It is necessary but not
sufficient to have an effective communication infrastructure. It is necessary
but not suff</p><p>5 0.10040623 <a title="193-tfidf-5" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>Introduction: This is about a design flaw in several learning algorithms such as the Naive
Bayes classifier and Hidden Markov Models. A number of people are aware of it,
but it seems that not everyone is.Several learning systems have the property
that they estimate some conditional probabilitiesP(event | other events)either
explicitly or implicitly. Then, at prediction time, these learned
probabilities are multiplied together according to some formula to produce a
final prediction. The Naive Bayes classifier for binary data is the simplest
of these, so it seems like a good example.When Naive Bayes is used, a set of
probabilities of the formPr'(feature i | label)are estimated via counting
statistics and some prior. Predictions are made according to the label
maximizing:Pr'(label) * Productfeatures iPr'(feature i | label)(ThePr'notation
indicates these are estimated values.)There is nothing wrong with this method
as long as (a) the prior for the sample counts is very strong and (b) the
prior (on the c</p><p>6 0.095835321 <a title="193-tfidf-6" href="../hunch_net-2005/hunch_net-2005-08-01-Peekaboom.html">99 hunch net-2005-08-01-Peekaboom</a></p>
<p>7 0.095552683 <a title="193-tfidf-7" href="../hunch_net-2012/hunch_net-2012-07-09-Videolectures.html">469 hunch net-2012-07-09-Videolectures</a></p>
<p>8 0.094323985 <a title="193-tfidf-8" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>9 0.093707606 <a title="193-tfidf-9" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>10 0.092353314 <a title="193-tfidf-10" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>11 0.089897491 <a title="193-tfidf-11" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>12 0.086486697 <a title="193-tfidf-12" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>13 0.08440946 <a title="193-tfidf-13" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>14 0.083338976 <a title="193-tfidf-14" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>15 0.082221247 <a title="193-tfidf-15" href="../hunch_net-2012/hunch_net-2012-10-26-ML_Symposium_and_Strata-Hadoop_World.html">475 hunch net-2012-10-26-ML Symposium and Strata-Hadoop World</a></p>
<p>16 0.08171346 <a title="193-tfidf-16" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>17 0.081181929 <a title="193-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>18 0.077645667 <a title="193-tfidf-18" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>19 0.077581078 <a title="193-tfidf-19" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>20 0.077126667 <a title="193-tfidf-20" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.187), (1, 0.0), (2, 0.091), (3, -0.064), (4, 0.053), (5, 0.008), (6, -0.048), (7, 0.018), (8, 0.026), (9, 0.006), (10, -0.019), (11, 0.045), (12, -0.006), (13, -0.04), (14, 0.067), (15, -0.045), (16, -0.009), (17, 0.009), (18, -0.036), (19, -0.019), (20, -0.011), (21, -0.086), (22, -0.009), (23, -0.014), (24, -0.05), (25, -0.04), (26, 0.025), (27, 0.034), (28, -0.026), (29, 0.009), (30, -0.009), (31, 0.022), (32, 0.032), (33, 0.07), (34, 0.126), (35, -0.101), (36, -0.001), (37, 0.051), (38, -0.007), (39, -0.018), (40, 0.01), (41, 0.044), (42, -0.028), (43, 0.035), (44, 0.009), (45, 0.135), (46, 0.157), (47, 0.093), (48, 0.065), (49, -0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93043989 <a title="193-lsi-1" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>Introduction: …is discussed inthis nytimes article. I generally expect such approaches to
become more common since computers are getting faster, machine learning is
getting better, and data is becoming more plentiful. This is another example
where machine learning technology may have a huge economic impact. Some side
notes:We-in-research know almost nothing about how these things are done
(because it is typically a corporate secret).… but the limited discussion in
the article seem naive from a machine learning viewpoint.The learning process
used apparently often fails to take into account transaction costs.What little
of the approaches is discussed appears modeling based. It seems plausible that
more direct prediction methods can yield an edge.One difficulty with stock
picking as a research topic is that it is inherently a zero sum game (for
every winner, there is a loser). Much of the rest of research is positive sum
(basically, everyone wins).</p><p>2 0.60613185 <a title="193-lsi-2" href="../hunch_net-2005/hunch_net-2005-09-14-The_Predictionist_Viewpoint.html">112 hunch net-2005-09-14-The Predictionist Viewpoint</a></p>
<p>Introduction: Virtually every discipline of significant human endeavor has a way explaining
itself as fundamental and important. In all the cases I know of, they are both
right (they are vital) and wrong (they are not solely vital).Politics. This is
the one that everyone is familiar with at the moment. "What could be more
important than the process of making decisions?"Science and Technology. This
is the one that we-the-academics are familiar with. "The loss of modern
science and technology would be catastrophic."Military. "Without the military,
a nation will be invaded and destroyed."(insert your favorite here)Within
science and technology, the same thing happens again.Mathematics. "What could
be more important than a precise language for establishing truths?"Physics.
"Nothing is more fundamental than the laws which govern the universe.
Understanding them is the key to understanding everything else."Biology.
"Without life, we wouldn't be here, so clearly the study of life is
fundamental."Computer S</p><p>3 0.60521793 <a title="193-lsi-3" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>Introduction: I found the article on "Political Science" at theNew York Timesinteresting.
Essentially the article is about allegations that the US government has been
systematically distorting scientific views. With apetitionby some7000+
scientistsalleging such behavior this is clearly a significant concern.One
thing not mentioned explicitly in this discussion is that there are
fundamental cultural differences between academic research and the rest of the
world. In academic research, careful, clear thought is valued. This value is
achieved by both formal and informal mechanisms. One example of a formal
mechanism is peer review.In contrast, in the land of politics, the basic value
is agreement. It is only with some amount of agreement that a new law can be
passed or other actions can be taken. Since Science (with a capitol 'S') has
accomplished many things, it can be a significant tool in persuading people.
This makes it compelling for a politician to use science as a mechanism for
pushing agreement</p><p>4 0.60218894 <a title="193-lsi-4" href="../hunch_net-2012/hunch_net-2012-07-09-Videolectures.html">469 hunch net-2012-07-09-Videolectures</a></p>
<p>Introduction: Yaserpoints out some nicelyvideotaped machine learning lecturesatCaltech.
Yaser taught me machine learning, and I always found the lectures clear and
interesting, so I expect many people can benefit from watching. Relative
toAndrew Ng'sML classthere are somewhat different areas of emphasis but the
topic is the same, so picking and choosing the union may be helpful.</p><p>5 0.56715053 <a title="193-lsi-5" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>Introduction: I've avoided discussing politics here, although not for lack of interest. The
problem with discussing politics is that it's customary for people to say much
based upon little information. Nevertheless, politics can have a substantial
impact on science (and we might hope for the vice-versa). It's primary
election time in the United States, so the topic is timely, although the
issues are not.There are several policy decisions which substantially effect
development of science and technology in the US.EducationThe US has great
contrasts in education. The top universities are very good places, yet the
grade school education system produces mediocre results. For me, the contrast
between apublic educationandCaltechwas bracing. For many others attending
Caltech, it clearly was not. Upgrading the k-12 education system in the US is
a long-standing chronic problem which I know relatively little about. My own
experience is that a basic attitude of "no child unrealized" is better than
"no child lef</p><p>6 0.56537676 <a title="193-lsi-6" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>7 0.56110525 <a title="193-lsi-7" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>8 0.56008893 <a title="193-lsi-8" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>9 0.54720813 <a title="193-lsi-9" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>10 0.53310013 <a title="193-lsi-10" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>11 0.52641863 <a title="193-lsi-11" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>12 0.51505631 <a title="193-lsi-12" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>13 0.49801278 <a title="193-lsi-13" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>14 0.49777725 <a title="193-lsi-14" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>15 0.49594164 <a title="193-lsi-15" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>16 0.48734182 <a title="193-lsi-16" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>17 0.48523498 <a title="193-lsi-17" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>18 0.48491654 <a title="193-lsi-18" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>19 0.47962698 <a title="193-lsi-19" href="../hunch_net-2006/hunch_net-2006-04-09-Progress_in_Machine_Translation.html">171 hunch net-2006-04-09-Progress in Machine Translation</a></p>
<p>20 0.47889176 <a title="193-lsi-20" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.224), (74, 0.146), (82, 0.518)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98043954 <a title="193-lda-1" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>2 0.96771812 <a title="193-lda-2" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>Introduction: Geoff Gordonpoints outAIStats 2011in Ft. Lauderdale, Florida. Thecall for
papersis now out, due Nov. 1. The plan is toexperiment with the review
processto encourage quality in several ways. I expect to submit a paper and
would encourage others with good research to do likewise.</p><p>same-blog 3 0.93381047 <a title="193-lda-3" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>Introduction: …is discussed inthis nytimes article. I generally expect such approaches to
become more common since computers are getting faster, machine learning is
getting better, and data is becoming more plentiful. This is another example
where machine learning technology may have a huge economic impact. Some side
notes:We-in-research know almost nothing about how these things are done
(because it is typically a corporate secret).… but the limited discussion in
the article seem naive from a machine learning viewpoint.The learning process
used apparently often fails to take into account transaction costs.What little
of the approaches is discussed appears modeling based. It seems plausible that
more direct prediction methods can yield an edge.One difficulty with stock
picking as a research topic is that it is inherently a zero sum game (for
every winner, there is a loser). Much of the rest of research is positive sum
(basically, everyone wins).</p><p>4 0.9069894 <a title="193-lda-4" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>Introduction: If we accept that bad reviewing often occurs and want to fix it, the question
is "how"?Reviewing is done by paper writers just like yourself, so a good
proxy for this question is asking "How can I be a better reviewer?" Here are a
few things I've learned by trial (and error), as a paper writer, and as a
reviewer.The secret ingredient is careful thought. There is no good
substitution for a deep and careful understanding.Avoid reviewing papers that
you feel competitive about. You almost certainly will be asked to review
papers that feel competitive if you work on subjects of common interest. But,
the feeling of competition can easily lead to bad judgement.If you feel biased
for some other reason, then you should avoid reviewing. For exampleâ&euro;ŚFeeling
angry or threatened by a paper is a form of bias. See above.Double blind
yourself (avoid looking at the name even in a single-blind situation). The
significant effect of a name you recognize is making you pay close attention
to a paper. Since</p><p>5 0.80397272 <a title="193-lda-5" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>Introduction: This post is about a technology which could develop in the future.Right now, a
new drug might be tested by finding patients with some diagnosis and giving or
not giving them a drug according to a secret randomization. The outcome is
observed, and if the average outcome for those treated is measurably better
than the average outcome for those not treated, the drug might become a
standard treatment.Generalizing this, a filterFsorts people into two groups:
those for treatmentAand those not for treatmentBbased upon observationsx. To
measure the outcome, you randomize between treatment and nontreatment of
groupAand measure the relative performance of the treatment.A problem often
arises: in many cases the treated group does not do better than the nontreated
group. A basic question is: does this mean the treatment is bad? With respect
to the filterFit may mean that, but with respect to another filterF', the
treatment might be very effective. For example, a drug might work great for
people wh</p><p>6 0.71280766 <a title="193-lda-6" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>7 0.67644882 <a title="193-lda-7" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>8 0.67069364 <a title="193-lda-8" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>9 0.65157622 <a title="193-lda-9" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>10 0.62778807 <a title="193-lda-10" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>11 0.61430961 <a title="193-lda-11" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>12 0.59896392 <a title="193-lda-12" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>13 0.59717625 <a title="193-lda-13" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>14 0.59296644 <a title="193-lda-14" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>15 0.59269899 <a title="193-lda-15" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>16 0.58925593 <a title="193-lda-16" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>17 0.58078527 <a title="193-lda-17" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>18 0.57843637 <a title="193-lda-18" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>19 0.57439137 <a title="193-lda-19" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>20 0.55483556 <a title="193-lda-20" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
