<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>160 hunch net-2006-03-02-Why do people count for learning?</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-160" href="#">hunch_net-2006-160</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>160 hunch net-2006-03-02-Why do people count for learning?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-160-html" href="http://hunch.net/?p=171">html</a></p><p>Introduction: This post is about a confusion of mine with respect to many commonly used
machine learning algorithms.A simple example where this comes up is Bayes net
prediction. A Bayes net where a directed acyclic graph over a set of nodes
where each node is associated with a variable and the edges indicate
dependence. The joint probability distribution over the variables is given by
a set of conditional probabilities. For example, a very simple Bayes net might
express:P(A,B,C) = P(A | B,C)P(B)P(C)What I don't understand is the mechanism
commonly used to estimateP(A | B, C). If we letN(A,B,C)be the number of
instances ofA,B,Cthen people sometimes form an estimate according to:P'(A |
B,C) = N(A,B,C) / N /[N(B)/N * N(C)/N] = N(A,B,C) N /[N(B) N(C)]â&euro;Ś in other
words, people just estimateP'(A | B,C)according to observed relative
frequencies. This is a reasonable technique when you have a large number of
samples compared to the size spaceA x B x C, but it (naturally) falls apart
when this is not the case</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('purpose', 0.236), ('net', 0.231), ('estimatep', 0.224), ('count', 0.217), ('prior', 0.184), ('bayes', 0.166), ('reasonable', 0.166), ('prediction', 0.162), ('translation', 0.16), ('dirichlet', 0.16), ('according', 0.147), ('joint', 0.141), ('default', 0.126), ('estimate', 0.124), ('vision', 0.122), ('situations', 0.12), ('algorithm', 0.116), ('commonly', 0.111), ('probabilistic', 0.109), ('general', 0.109)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="160-tfidf-1" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>Introduction: This post is about a confusion of mine with respect to many commonly used
machine learning algorithms.A simple example where this comes up is Bayes net
prediction. A Bayes net where a directed acyclic graph over a set of nodes
where each node is associated with a variable and the edges indicate
dependence. The joint probability distribution over the variables is given by
a set of conditional probabilities. For example, a very simple Bayes net might
express:P(A,B,C) = P(A | B,C)P(B)P(C)What I don't understand is the mechanism
commonly used to estimateP(A | B, C). If we letN(A,B,C)be the number of
instances ofA,B,Cthen people sometimes form an estimate according to:P'(A |
B,C) = N(A,B,C) / N /[N(B)/N * N(C)/N] = N(A,B,C) N /[N(B) N(C)]â&euro;Ś in other
words, people just estimateP'(A | B,C)according to observed relative
frequencies. This is a reasonable technique when you have a large number of
samples compared to the size spaceA x B x C, but it (naturally) falls apart
when this is not the case</p><p>2 0.22264385 <a title="160-tfidf-2" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>Introduction: This is about a design flaw in several learning algorithms such as the Naive
Bayes classifier and Hidden Markov Models. A number of people are aware of it,
but it seems that not everyone is.Several learning systems have the property
that they estimate some conditional probabilitiesP(event | other events)either
explicitly or implicitly. Then, at prediction time, these learned
probabilities are multiplied together according to some formula to produce a
final prediction. The Naive Bayes classifier for binary data is the simplest
of these, so it seems like a good example.When Naive Bayes is used, a set of
probabilities of the formPr'(feature i | label)are estimated via counting
statistics and some prior. Predictions are made according to the label
maximizing:Pr'(label) * Productfeatures iPr'(feature i | label)(ThePr'notation
indicates these are estimated values.)There is nothing wrong with this method
as long as (a) the prior for the sample counts is very strong and (b) the
prior (on the c</p><p>3 0.13835056 <a title="160-tfidf-3" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>Introduction: Machine learning has a new kind of "scaling to larger problems" to worry
about: scaling with the amount of contextual information. The standard
development path for a machine learning application in practice seems to be
the following:Marginal. In the beginning, there was "majority vote". At this
stage, it isn't necessary to understand that you have a prediction problem.
People just realize that one answer is right sometimes and another answer
other times. In machine learning terms, this corresponds to making a
prediction without side information.First context. A clever person realizes
that some bit of informationx1could be helpful. Ifx1is discrete, they
condition on it and make a predictorh(x1), typically by counting. If they are
clever, then they also do some smoothing. Ifx1is some real valued parameter,
it's very common to make a threshold cutoff. Often, these tasks are simply
done by hand.Second. Another clever person (or perhaps the same one) realizes
that some other bit of informa</p><p>4 0.13809375 <a title="160-tfidf-4" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>5 0.12325175 <a title="160-tfidf-5" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>Introduction: An argument is sometimes made that the Bayesian way is the "right" way to do
machine learning. This is a serious argument which deserves a serious reply.
The approximation argument is a serious reply for which I have not yet seen a
reply2.The idea for the Bayesian approach is quite simple, elegant, and
general. Essentially, you first specify a priorP(D)over possible
processesDproducing the data, observe the data, then condition on the data
according to Bayes law to construct a posterior:P(D|x) = P(x|D)P(D)/P(x)After
this, hard decisions are made (such as "turn left" or "turn right") by
choosing the one which minimizes the expected (with respect to the posterior)
loss.This basic idea is reused thousands of times with various choices
ofP(D)and loss functions which is unsurprising given the many nice
properties:There is an extremely strong associated guarantee: If the actual
distribution generating the data is drawn fromP(D)there is no better method.
One way to think about this is that in</p><p>6 0.12222045 <a title="160-tfidf-6" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>7 0.11974372 <a title="160-tfidf-7" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>8 0.11814261 <a title="160-tfidf-8" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>9 0.11714928 <a title="160-tfidf-9" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>10 0.1117471 <a title="160-tfidf-10" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>11 0.10835478 <a title="160-tfidf-11" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>12 0.10438042 <a title="160-tfidf-12" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>13 0.10365885 <a title="160-tfidf-13" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>14 0.10228768 <a title="160-tfidf-14" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>15 0.10087278 <a title="160-tfidf-15" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>16 0.10029972 <a title="160-tfidf-16" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>17 0.099475481 <a title="160-tfidf-17" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>18 0.09887179 <a title="160-tfidf-18" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>19 0.097672679 <a title="160-tfidf-19" href="../hunch_net-2007/hunch_net-2007-06-24-Interesting_Papers_at_ICML_2007.html">251 hunch net-2007-06-24-Interesting Papers at ICML 2007</a></p>
<p>20 0.095799074 <a title="160-tfidf-20" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.245), (1, -0.121), (2, -0.011), (3, -0.047), (4, -0.02), (5, 0.005), (6, -0.133), (7, 0.012), (8, 0.036), (9, 0.003), (10, -0.068), (11, -0.052), (12, -0.083), (13, -0.094), (14, -0.056), (15, -0.072), (16, 0.071), (17, -0.026), (18, -0.106), (19, 0.027), (20, -0.052), (21, 0.027), (22, 0.069), (23, -0.055), (24, 0.05), (25, -0.019), (26, 0.026), (27, -0.036), (28, -0.006), (29, 0.038), (30, 0.007), (31, -0.07), (32, 0.006), (33, 0.065), (34, 0.072), (35, 0.012), (36, 0.005), (37, -0.02), (38, 0.013), (39, -0.03), (40, 0.048), (41, 0.034), (42, 0.024), (43, -0.005), (44, 0.043), (45, -0.027), (46, 0.048), (47, 0.076), (48, 0.07), (49, 0.042)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95118386 <a title="160-lsi-1" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>Introduction: This post is about a confusion of mine with respect to many commonly used
machine learning algorithms.A simple example where this comes up is Bayes net
prediction. A Bayes net where a directed acyclic graph over a set of nodes
where each node is associated with a variable and the edges indicate
dependence. The joint probability distribution over the variables is given by
a set of conditional probabilities. For example, a very simple Bayes net might
express:P(A,B,C) = P(A | B,C)P(B)P(C)What I don't understand is the mechanism
commonly used to estimateP(A | B, C). If we letN(A,B,C)be the number of
instances ofA,B,Cthen people sometimes form an estimate according to:P'(A |
B,C) = N(A,B,C) / N /[N(B)/N * N(C)/N] = N(A,B,C) N /[N(B) N(C)]â&euro;Ś in other
words, people just estimateP'(A | B,C)according to observed relative
frequencies. This is a reasonable technique when you have a large number of
samples compared to the size spaceA x B x C, but it (naturally) falls apart
when this is not the case</p><p>2 0.84613842 <a title="160-lsi-2" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>Introduction: This is about a design flaw in several learning algorithms such as the Naive
Bayes classifier and Hidden Markov Models. A number of people are aware of it,
but it seems that not everyone is.Several learning systems have the property
that they estimate some conditional probabilitiesP(event | other events)either
explicitly or implicitly. Then, at prediction time, these learned
probabilities are multiplied together according to some formula to produce a
final prediction. The Naive Bayes classifier for binary data is the simplest
of these, so it seems like a good example.When Naive Bayes is used, a set of
probabilities of the formPr'(feature i | label)are estimated via counting
statistics and some prior. Predictions are made according to the label
maximizing:Pr'(label) * Productfeatures iPr'(feature i | label)(ThePr'notation
indicates these are estimated values.)There is nothing wrong with this method
as long as (a) the prior for the sample counts is very strong and (b) the
prior (on the c</p><p>3 0.73397976 <a title="160-lsi-3" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>Introduction: Machine learning has a new kind of "scaling to larger problems" to worry
about: scaling with the amount of contextual information. The standard
development path for a machine learning application in practice seems to be
the following:Marginal. In the beginning, there was "majority vote". At this
stage, it isn't necessary to understand that you have a prediction problem.
People just realize that one answer is right sometimes and another answer
other times. In machine learning terms, this corresponds to making a
prediction without side information.First context. A clever person realizes
that some bit of informationx1could be helpful. Ifx1is discrete, they
condition on it and make a predictorh(x1), typically by counting. If they are
clever, then they also do some smoothing. Ifx1is some real valued parameter,
it's very common to make a threshold cutoff. Often, these tasks are simply
done by hand.Second. Another clever person (or perhaps the same one) realizes
that some other bit of informa</p><p>4 0.71916103 <a title="160-lsi-4" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>Introduction: Many different ways of reasoning about learning exist, and many of these
suggest that some method of saying "I prefer this predictor to that predictor"
is useful and necessary. Examples include Bayesian reasoning, prediction
bounds, and online learning. One difficulty which arises is that the manner
and meaning of saying "I prefer this predictor to that predictor"
differs.Prior(Bayesian) A prior is a probability distribution over a set of
distributions which expresses a belief in the probability that some
distribution is the distribution generating the data."Prior"(Prediction bounds
& online learning) The "prior" is a measure over a set of classifiers which
expresses the degree to which you hope the classifier will predict
well.Bias(Regularization, Early termination of neural network training, etcâ&euro;Ś)
The bias is some (often implicitly specified by an algorithm) way of
preferring one predictor to another.This only scratches the surface--there are
yet more subtleties. For example the (as</p><p>5 0.68350035 <a title="160-lsi-5" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>Introduction: I don't consider myself a "Bayesian", but I do try hard to understand why
Bayesian learning works. For the purposes of this post, Bayesian learning is a
simple process of:Specify a prior over world models.Integrate using Bayes law
with respect to all observed information to compute a posterior over world
models.Predict according to the posterior.Bayesian learning has many
advantages over other learning programs:InterpolationBayesian learning methods
interpolate all the way to pure engineering. When faced with any learning
problem, there is a choice of how much time and effort a human vs. a computer
puts in. (For example, the mars rover pathfinding algorithms are almost
entirely engineered.) When creating an engineered system, you build a model of
the world and then find a good controller in that model. Bayesian methods
interpolate to this extreme because the Bayesian prior can be a delta function
on one model of the world. What this means is that a recipe of "think harder"
(about speci</p><p>6 0.68216175 <a title="160-lsi-6" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>7 0.66595823 <a title="160-lsi-7" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>8 0.6511789 <a title="160-lsi-8" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>9 0.63581759 <a title="160-lsi-9" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>10 0.62341142 <a title="160-lsi-10" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>11 0.61494511 <a title="160-lsi-11" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>12 0.58986777 <a title="160-lsi-12" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>13 0.57365215 <a title="160-lsi-13" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>14 0.56229794 <a title="160-lsi-14" href="../hunch_net-2005/hunch_net-2005-02-28-Regularization.html">33 hunch net-2005-02-28-Regularization</a></p>
<p>15 0.55518603 <a title="160-lsi-15" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>16 0.55102891 <a title="160-lsi-16" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>17 0.54956263 <a title="160-lsi-17" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>18 0.54951662 <a title="160-lsi-18" href="../hunch_net-2006/hunch_net-2006-06-16-Regularization_%3D_Robustness.html">185 hunch net-2006-06-16-Regularization = Robustness</a></p>
<p>19 0.54009569 <a title="160-lsi-19" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>20 0.5392226 <a title="160-lsi-20" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.025), (35, 0.073), (42, 0.281), (45, 0.084), (68, 0.053), (69, 0.026), (74, 0.1), (76, 0.06), (93, 0.201)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.92726362 <a title="160-lda-1" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>Introduction: Forlearning reductionswe have been concentrating on reducing various complex
learning problems to binary classification. This choice needs to be actively
questioned, because it was not carefully considered.Binary clasification is
learning a classifierc:X -> {0,1}so as to minimize the probability of being
wrong,Prx,y~D(c(x)y).The primary alternative candidate seems to be squared
error regression. In squared error regression, you learn a regressors:X ->
[0,1]so as to minimize squared error,Ex,y~D(s(x)-y)2.It is difficult to judge
one primitive against another. The judgement must at least partially be made
on nontheoretical grounds because (essentially) we are evaluating a choice
between two axioms/assumptions.These two primitives are significantly related.
Classification can be reduced to regression in the obvious way: you use the
regressor to predictD(y=1|x), then threshold at0.5. For this simple reduction
a squared error regret ofrimplies a classification regret of at mostr0.5.
Regress</p><p>2 0.91961312 <a title="160-lda-2" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>Introduction: Nati SrebroandShai Ben-Davidhave apaperatCOLTwhich, in the appendix, proves
something very striking: several previous error bounds arealwaysgreater than
1.BackgroundOne branch of learning theory focuses on theorems whichAssume
samples are drawn IID from an unknown distributionD.Fix a set of
classifiersFind a high probability bound on the maximum true error rate (with
respect toD) as a function of the empirical error rate on the training
set.Many of these bounds become extremely complex and hairy.CurrentEveryone
working on this subject wants "tighter bounds", however there are different
definitions of "tighter". Some groups focus on "functional tightness" (getting
the right functional dependency between the size of the training set and a
parameterization of the hypothesis space) whileothersfocus on "practical
tightness" (finding bounds which work well on practical problems). (I am
definitely in the second camp.)One of the dangers of striving for "functional
tightness" is that the bound</p><p>3 0.91713601 <a title="160-lda-3" href="../hunch_net-2006/hunch_net-2006-04-09-Progress_in_Machine_Translation.html">171 hunch net-2006-04-09-Progress in Machine Translation</a></p>
<p>Introduction: I just visitedISIwhereDaniel Marcuand others are working on machine
translation. Apparently, machine translation is rapidly improving. A
particularly dramatic year was 2002->2003 when systems switched from word-
based translation to phrase-based translation. From a (now famous) slide by
Charles Wayne atDARPA(which funds much of the work on machine translation)
here is some anecdotal evidence:20022003insistent Wednesday may recurred her
trips to Libya tomorrow for flying.Cairo 6-4 ( AFP ) - An official announced
today in the Egyptian lines company for flying Tuesday is a company "insistent
for flying" may resumed a consideration of a day Wednesday tomorrow her trips
to Libya of Security Council decision trace international the imposed ban
comment.And said the official "the institution sent a speech to Ministry of
Foreign Affairs of lifting on Libya air, a situation her recieving replying
are so a trip will pull to Libya a morning Wednesday."Egyptair has tomorrow to
Resume Its flight to</p><p>same-blog 4 0.91523898 <a title="160-lda-4" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>Introduction: This post is about a confusion of mine with respect to many commonly used
machine learning algorithms.A simple example where this comes up is Bayes net
prediction. A Bayes net where a directed acyclic graph over a set of nodes
where each node is associated with a variable and the edges indicate
dependence. The joint probability distribution over the variables is given by
a set of conditional probabilities. For example, a very simple Bayes net might
express:P(A,B,C) = P(A | B,C)P(B)P(C)What I don't understand is the mechanism
commonly used to estimateP(A | B, C). If we letN(A,B,C)be the number of
instances ofA,B,Cthen people sometimes form an estimate according to:P'(A |
B,C) = N(A,B,C) / N /[N(B)/N * N(C)/N] = N(A,B,C) N /[N(B) N(C)]â&euro;Ś in other
words, people just estimateP'(A | B,C)according to observed relative
frequencies. This is a reasonable technique when you have a large number of
samples compared to the size spaceA x B x C, but it (naturally) falls apart
when this is not the case</p><p>5 0.91410673 <a title="160-lda-5" href="../hunch_net-2005/hunch_net-2005-04-28-Science_Fiction_and_Research.html">64 hunch net-2005-04-28-Science Fiction and Research</a></p>
<p>Introduction: A big part of doing research is imagining how things could be different, and
then trying to figure out how to get there.A big part of science fiction is
imagining how things could be different, and then working through the
implications.Because of the similarity here, reading science fiction can
sometimes be helpful in understanding and doing research. (And, hey, it's
fun.) Here's some list of science fiction books I enjoyed which seem
particularly relevant to computer science and (sometimes) learning
systems:Vernor Vinge, "True Names", "A Fire Upon the Deep"Marc Stiegler,
"David's Sling", "Earthweb"Charles Stross, "Singularity Sky"Greg Egan,
"Diaspora"Joe Haldeman, "Forever Peace"(There are surely many
others.)Incidentally, the nature of science fiction itself has changed.
Decades ago, science fiction projected great increases in the power humans
control (example: E.E. Smith Lensman series). That didn't really happen in the
last 50 years. Instead, we gradually refined the degree to whi</p><p>6 0.82398641 <a title="160-lda-6" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>7 0.82206112 <a title="160-lda-7" href="../hunch_net-2006/hunch_net-2006-03-12-Online_learning_or_online_preservation_of_learning%3F.html">163 hunch net-2006-03-12-Online learning or online preservation of learning?</a></p>
<p>8 0.82062161 <a title="160-lda-8" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>9 0.81809223 <a title="160-lda-9" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>10 0.81677443 <a title="160-lda-10" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>11 0.81598377 <a title="160-lda-11" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>12 0.81512535 <a title="160-lda-12" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>13 0.81440216 <a title="160-lda-13" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>14 0.81377876 <a title="160-lda-14" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>15 0.81356066 <a title="160-lda-15" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>16 0.81333464 <a title="160-lda-16" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>17 0.81157398 <a title="160-lda-17" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>18 0.81123483 <a title="160-lda-18" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>19 0.81062496 <a title="160-lda-19" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>20 0.8086434 <a title="160-lda-20" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
