<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>211 hunch net-2006-10-02-$1M Netflix prediction contest</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-211" href="#">hunch_net-2006-211</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>211 hunch net-2006-10-02-$1M Netflix prediction contest</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-211-html" href="http://hunch.net/?p=231">html</a></p><p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('contest', 0.372), ('yields', 0.324), ('smaller', 0.298), ('improvement', 0.281), ('failing', 0.223), ('orders', 0.213), ('achievable', 0.213), ('recommender', 0.205), ('apparently', 0.191), ('recommendation', 0.181), ('netflix', 0.181), ('prize', 0.172), ('system', 0.169), ('magnitude', 0.169), ('money', 0.156), ('looks', 0.154), ('improve', 0.137), ('dataset', 0.137), ('public', 0.133), ('datasets', 0.133)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="211-tfidf-1" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><p>2 0.25191587 <a title="211-tfidf-2" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended theNetflix prizeceremony this morning. The press conference part
iscovered fine elsewhere, with the basic outcome being thatBellKor's Pragmatic
Chaoswon overThe Ensembleby 15-20minutes, because they were tied in
performance on the ultimate holdout set. I'm sure the individual participants
will have many chances to speak about the solution. One of these is Bell at
theNYAS ML symposium on Nov. 6.Several additional details may interest ML
people.The degree of overfitting exhibited by the difference in performance on
theleaderboard test setand the ultimate hold out set was small, but
determining at .02 to .03%.A tie was possible, because the rules cut off
measurements below the fourth digit based on significance concerns. In
actuality, of course, the scores do differ before rounding, but everyone I
spoke to claimed not to know how. The complete dataset has beenreleased on
UCI, so each team could compute their own score to whatever accuracy desired.I
was impressed by the slick sy</p><p>3 0.205551 <a title="211-tfidf-3" href="../hunch_net-2011/hunch_net-2011-03-20-KDD_Cup_2011.html">427 hunch net-2011-03-20-KDD Cup 2011</a></p>
<p>Introduction: Yehudapoints outKDD-Cup 2011whichMarkusandGideonhelped setup. This is a
prediction and recommendation contest for music. In addition to being a fun
chance to show your expertise, there are cash prizes of $5K/$2K/$1K.</p><p>4 0.17665206 <a title="211-tfidf-4" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>Introduction: There are two prediction competitions currently in the air.ThePerformance
Prediction ChallengebyIsabelle Guyon. Good entries minimize a weighted 0/1
loss + the difference between a prediction of this loss and the observed truth
on 5 datasets. Isabelle tells me all of the problems are "real world" and the
test datasets are large enough (17K minimum) that the winner should be well
determined by ability rather than luck. This is due March 1.ThePredictive
Uncertainty ChallengebyGavin Cawley. Good entries minimize log loss on real
valued output variables for one synthetic and 3 "real" datasets related to
atmospheric prediction. The use of log loss (which can be infinite and hence
is never convergent) and smaller test sets of size 1K to 7K examples makes the
winner of this contest more luck dependent. Nevertheless, the contest may be
of some interest particularly to the branch of learning (typically Bayes
learning) which prefers to optimize log loss.May the best predictor win.</p><p>5 0.16057271 <a title="211-tfidf-5" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: TheHeritage Health Prizeis potentially the largest prediction prize yet at
$3M, which is sure to get many people interested. Several elements of the
competition may be worth discussing.The most straightforward way for HPN to
deploy this predictor is in determining who to cover with insurance. This
might easily cover the costs of running the contest itself, but the value to
the health system of a whole is minimal, as people not covered still exist.
While HPN itself is a provider network, they have active relationships with a
number of insurance companies, and the right to resell any entrant. It's worth
keeping in mind that the research and development may nevertheless end up
being useful in the longer term, especially as entrants also keep the right to
their code.Thejudging metricis something I haven't seen previously. If a
patient has probability 0.5 of being in the hospital 0 days and probability
0.5 of being in the hospital ~53.6 days, the optimal prediction in expectation
is ~6.4 da</p><p>6 0.1384722 <a title="211-tfidf-6" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>7 0.13247314 <a title="211-tfidf-7" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>8 0.120339 <a title="211-tfidf-8" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>9 0.099086836 <a title="211-tfidf-9" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>10 0.096328512 <a title="211-tfidf-10" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>11 0.091388069 <a title="211-tfidf-11" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>12 0.087631352 <a title="211-tfidf-12" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>13 0.082931481 <a title="211-tfidf-13" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>14 0.078284502 <a title="211-tfidf-14" href="../hunch_net-2005/hunch_net-2005-07-11-AAAI_blog.html">92 hunch net-2005-07-11-AAAI blog</a></p>
<p>15 0.075820744 <a title="211-tfidf-15" href="../hunch_net-2011/hunch_net-2011-08-15-Vowpal_Wabbit_6.0.html">441 hunch net-2011-08-15-Vowpal Wabbit 6.0</a></p>
<p>16 0.074635983 <a title="211-tfidf-16" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>17 0.07194557 <a title="211-tfidf-17" href="../hunch_net-2005/hunch_net-2005-07-10-Thinking_the_Unthought.html">91 hunch net-2005-07-10-Thinking the Unthought</a></p>
<p>18 0.071456194 <a title="211-tfidf-18" href="../hunch_net-2011/hunch_net-2011-12-13-Vowpal_Wabbit_version_6.1_%26%23038%3B_the_NIPS_tutorial.html">451 hunch net-2011-12-13-Vowpal Wabbit version 6.1 &#038; the NIPS tutorial</a></p>
<p>19 0.071307234 <a title="211-tfidf-19" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>20 0.070491329 <a title="211-tfidf-20" href="../hunch_net-2005/hunch_net-2005-04-04-Grounds_for_Rejection.html">52 hunch net-2005-04-04-Grounds for Rejection</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.1), (1, -0.006), (2, 0.026), (3, 0.038), (4, 0.068), (5, 0.177), (6, 0.042), (7, 0.061), (8, 0.181), (9, -0.038), (10, -0.262), (11, 0.009), (12, -0.171), (13, 0.065), (14, 0.118), (15, 0.052), (16, -0.123), (17, -0.101), (18, -0.128), (19, -0.02), (20, -0.045), (21, 0.055), (22, 0.081), (23, 0.138), (24, 0.013), (25, 0.052), (26, -0.012), (27, -0.029), (28, -0.073), (29, -0.014), (30, 0.115), (31, 0.071), (32, 0.053), (33, -0.029), (34, 0.005), (35, -0.05), (36, -0.046), (37, 0.056), (38, -0.038), (39, -0.03), (40, -0.014), (41, 0.082), (42, -0.01), (43, 0.048), (44, 0.018), (45, -0.011), (46, 0.012), (47, -0.013), (48, 0.043), (49, -0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99467766 <a title="211-lsi-1" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><p>2 0.72360909 <a title="211-lsi-2" href="../hunch_net-2011/hunch_net-2011-03-20-KDD_Cup_2011.html">427 hunch net-2011-03-20-KDD Cup 2011</a></p>
<p>Introduction: Yehudapoints outKDD-Cup 2011whichMarkusandGideonhelped setup. This is a
prediction and recommendation contest for music. In addition to being a fun
chance to show your expertise, there are cash prizes of $5K/$2K/$1K.</p><p>3 0.63025486 <a title="211-lsi-3" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: TheHeritage Health Prizeis potentially the largest prediction prize yet at
$3M, which is sure to get many people interested. Several elements of the
competition may be worth discussing.The most straightforward way for HPN to
deploy this predictor is in determining who to cover with insurance. This
might easily cover the costs of running the contest itself, but the value to
the health system of a whole is minimal, as people not covered still exist.
While HPN itself is a provider network, they have active relationships with a
number of insurance companies, and the right to resell any entrant. It's worth
keeping in mind that the research and development may nevertheless end up
being useful in the longer term, especially as entrants also keep the right to
their code.Thejudging metricis something I haven't seen previously. If a
patient has probability 0.5 of being in the hospital 0 days and probability
0.5 of being in the hospital ~53.6 days, the optimal prediction in expectation
is ~6.4 da</p><p>4 0.62726903 <a title="211-lsi-4" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>Introduction: A $1M qualifying result was achieved on thepublic Netflix test setby a3-way
ensemble team. This is just in time forYehuda's presentation atKDD, which I'm
sure will be one of the best attended ever.This isn't quite over--there are a
few days for another super-conglomerate team to come together and there is
some small chance that the performance is nonrepresentative of the final test
set, but I expect not.Regardless of the final outcome, the biggest lesson for
ML from the Netflix contest has been the formidable performance edge of
ensemble methods.</p><p>5 0.61763054 <a title="211-lsi-5" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended theNetflix prizeceremony this morning. The press conference part
iscovered fine elsewhere, with the basic outcome being thatBellKor's Pragmatic
Chaoswon overThe Ensembleby 15-20minutes, because they were tied in
performance on the ultimate holdout set. I'm sure the individual participants
will have many chances to speak about the solution. One of these is Bell at
theNYAS ML symposium on Nov. 6.Several additional details may interest ML
people.The degree of overfitting exhibited by the difference in performance on
theleaderboard test setand the ultimate hold out set was small, but
determining at .02 to .03%.A tie was possible, because the rules cut off
measurements below the fourth digit based on significance concerns. In
actuality, of course, the scores do differ before rounding, but everyone I
spoke to claimed not to know how. The complete dataset has beenreleased on
UCI, so each team could compute their own score to whatever accuracy desired.I
was impressed by the slick sy</p><p>6 0.5878638 <a title="211-lsi-6" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>7 0.54793561 <a title="211-lsi-7" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>8 0.47548977 <a title="211-lsi-8" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>9 0.45762971 <a title="211-lsi-9" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>10 0.41495264 <a title="211-lsi-10" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>11 0.37909958 <a title="211-lsi-11" href="../hunch_net-2010/hunch_net-2010-12-02-Traffic_Prediction_Problem.html">418 hunch net-2010-12-02-Traffic Prediction Problem</a></p>
<p>12 0.36864275 <a title="211-lsi-12" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>13 0.36575344 <a title="211-lsi-13" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>14 0.3642363 <a title="211-lsi-14" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>15 0.32314417 <a title="211-lsi-15" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>16 0.31177351 <a title="211-lsi-16" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>17 0.31088534 <a title="211-lsi-17" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>18 0.30694517 <a title="211-lsi-18" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>19 0.3024492 <a title="211-lsi-19" href="../hunch_net-2005/hunch_net-2005-07-11-AAAI_blog.html">92 hunch net-2005-07-11-AAAI blog</a></p>
<p>20 0.28969425 <a title="211-lsi-20" href="../hunch_net-2011/hunch_net-2011-08-15-Vowpal_Wabbit_6.0.html">441 hunch net-2011-08-15-Vowpal Wabbit 6.0</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(29, 0.558), (42, 0.157), (45, 0.123)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91561925 <a title="211-lda-1" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><p>2 0.88366824 <a title="211-lda-2" href="../hunch_net-2006/hunch_net-2006-07-17-A_Winner.html">197 hunch net-2006-07-17-A Winner</a></p>
<p>Introduction: Ed Snelsonwon thePredictive Uncertainty in Environmental Modelling
Competitionin the temp(erature) category usingthis algorithm. Some
characteristics of the algorithm are:Gradient descent… on about 600
parameters… with local minima… to solve regression.This bears a strong
resemblance to a neural network. The two main differences seem to be:The
system has a probabilistic interpretation (which may aid design).There are
(perhaps) fewer parameters than a typical neural network might have for the
same problem (aiding speed).</p><p>3 0.83463806 <a title="211-lda-3" href="../hunch_net-2009/hunch_net-2009-04-21-Interesting_Presentations_at_Snowbird.html">349 hunch net-2009-04-21-Interesting Presentations at Snowbird</a></p>
<p>Introduction: Here are a few of presentations interesting me at thesnowbird learningworkshop
(which, amusingly, was in Florida withAIStat).Thomas Breueldescribed machine
learning problems within OCR and an open sourceOCR software/researchplatform
with modular learning components as well has a 60Million size dataset derived
fromGoogle's scanned books.Kristen GraumanandFei-Fei Lidiscussed using active
learning with different cost labels and large datasets forimage ontology. Both
of them usedMechanical Turkas alabeling system, which looks to become routine,
at least for vision problems.Russ Tedrakediscussed using machine learning for
control, with a basic claim that it was the way to go for problems involving a
mediumReynold's numbersuch as in bird flight, where simulation is extremely
intense.Yann LeCunpresented a poster on anFPGA for convolutional neural
networksyielding a factor of 100 speedup in processing. In addition to the
graphics processor approachRajathas worked on, this seems like an effecti</p><p>4 0.63533825 <a title="211-lda-4" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>Introduction: Last year about this time, we received a conditional accept for thesearn
paper, which asked us to reference a paper that was not reasonable to cite
because there was strictly more relevant work by the same authors that we
already cited. We wrote a response explaining this, and didn't cite it in the
final draft, giving the SPC an excuse toreject the paper, leading to
unhappiness for all.Later,Sanjoy Dasguptasuggested that an alternative was to
talk to the PC chair instead, as soon as you see that a conditional accept is
unreasonable.William Cohenand I spoke about this by email, the relevant bit of
which is:If an SPC asks for a revision that is inappropriate, the
correctaction is to contact the chairs as soon as the decision is made,clearly
explaining what the problem is, so we can decide whether ornot to over-rule
the SPC. As you say, this is extra work for uschairs, but that's part of the
job, and we're willing to do that sortof work to improve the overall quality
of the reviewing proc</p><p>5 0.58205616 <a title="211-lda-5" href="../hunch_net-2008/hunch_net-2008-12-07-A_NIPS_paper.html">330 hunch net-2008-12-07-A NIPS paper</a></p>
<p>Introduction: I'm skipping NIPS this year in favor ofAda, but I wanted to point outthis
paperbyAndriy MnihandGeoff Hinton. The basic claim of the paper is that by
carefully but automatically constructing a binary tree over words, it's
possible to predict words well with huge computational resource savings over
unstructured approaches.I'm interested in this beyond the application to word
prediction because it is relevant to the general normalization problem: If you
want to predict the probability of one of a large number of events, often you
must compute a predicted score for all the events and then normalize, a
computationally inefficient operation. The problem comes up in many places
using probabilistic models, but I've run into it with high-dimensional
regression.There are a couple workarounds for this computational
bug:Approximate. There are many ways. Often the approximations are
uncontrolled (i.e. can be arbitrarily bad), and hence finicky in
application.Avoid. You don't really want a probabili</p><p>6 0.3363952 <a title="211-lda-6" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>7 0.33286411 <a title="211-lda-7" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>8 0.33138108 <a title="211-lda-8" href="../hunch_net-2009/hunch_net-2009-03-18-Parallel_ML_primitives.html">346 hunch net-2009-03-18-Parallel ML primitives</a></p>
<p>9 0.3284497 <a title="211-lda-9" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>10 0.32659259 <a title="211-lda-10" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>11 0.32350948 <a title="211-lda-11" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>12 0.31048432 <a title="211-lda-12" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>13 0.3091909 <a title="211-lda-13" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>14 0.30758926 <a title="211-lda-14" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>15 0.30282643 <a title="211-lda-15" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>16 0.29989192 <a title="211-lda-16" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>17 0.29634333 <a title="211-lda-17" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>18 0.29531628 <a title="211-lda-18" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>19 0.29363075 <a title="211-lda-19" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>20 0.29119644 <a title="211-lda-20" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
