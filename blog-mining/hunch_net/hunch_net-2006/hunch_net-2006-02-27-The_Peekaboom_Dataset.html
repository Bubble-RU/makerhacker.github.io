<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>159 hunch net-2006-02-27-The Peekaboom Dataset</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-159" href="#">hunch_net-2006-159</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>159 hunch net-2006-02-27-The Peekaboom Dataset</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-159-html" href="http://hunch.net/?p=170">html</a></p><p>Introduction: Luis von Ahn â&euro;&tilde;s  Peekaboom project  has yielded  data  (830MB).
 
Peekaboom is the second attempt (after  Espgame ) to produce a dataset which is useful for learning to solve vision problems based on voluntary game play.  As a second attempt, it is meant to address all of the shortcomings of the first attempt.  In particular:
  
 The locations of specific objects are provided by the data. 
 The data collection is far more complete and extensive. 
  
The data consists of:
  
 The source images. (1 file per image, just short of 60K images.) 
 The in-game events. (1 file per image, in a lispy syntax.) 
 A description of the event language. 
  
There is a great deal of very specific and relevant data here so the hope that this will help solve vision problems seems quite reasonable.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Luis von Ahn â&euro;&tilde;s  Peekaboom project  has yielded  data  (830MB). [sent-1, score-0.636]
</p><p>2 Peekaboom is the second attempt (after  Espgame ) to produce a dataset which is useful for learning to solve vision problems based on voluntary game play. [sent-2, score-1.413]
</p><p>3 As a second attempt, it is meant to address all of the shortcomings of the first attempt. [sent-3, score-0.607]
</p><p>4 In particular:     The locations of specific objects are provided by the data. [sent-4, score-0.622]
</p><p>5 The data collection is far more complete and extensive. [sent-5, score-0.507]
</p><p>6 There is a great deal of very specific and relevant data here so the hope that this will help solve vision problems seems quite reasonable. [sent-11, score-1.272]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('peekaboom', 0.344), ('file', 0.31), ('image', 0.245), ('vision', 0.223), ('specific', 0.204), ('attempt', 0.201), ('data', 0.19), ('shortcomings', 0.186), ('voluntary', 0.186), ('yielded', 0.186), ('per', 0.173), ('ahn', 0.172), ('espgame', 0.162), ('locations', 0.162), ('luis', 0.155), ('von', 0.155), ('consists', 0.155), ('second', 0.146), ('collection', 0.139), ('solve', 0.13), ('objects', 0.128), ('provided', 0.128), ('meant', 0.12), ('game', 0.116), ('description', 0.114), ('address', 0.11), ('event', 0.107), ('complete', 0.105), ('project', 0.105), ('produce', 0.103), ('dataset', 0.095), ('short', 0.088), ('problems', 0.081), ('source', 0.081), ('relevant', 0.081), ('help', 0.075), ('deal', 0.075), ('far', 0.073), ('hope', 0.067), ('reasonable', 0.061), ('based', 0.061), ('useful', 0.06), ('particular', 0.059), ('great', 0.057), ('quite', 0.051), ('first', 0.045), ('seems', 0.038), ('learning', 0.011)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="159-tfidf-1" href="../hunch_net-2006/hunch_net-2006-02-27-The_Peekaboom_Dataset.html">159 hunch net-2006-02-27-The Peekaboom Dataset</a></p>
<p>Introduction: Luis von Ahn â&euro;&tilde;s  Peekaboom project  has yielded  data  (830MB).
 
Peekaboom is the second attempt (after  Espgame ) to produce a dataset which is useful for learning to solve vision problems based on voluntary game play.  As a second attempt, it is meant to address all of the shortcomings of the first attempt.  In particular:
  
 The locations of specific objects are provided by the data. 
 The data collection is far more complete and extensive. 
  
The data consists of:
  
 The source images. (1 file per image, just short of 60K images.) 
 The in-game events. (1 file per image, in a lispy syntax.) 
 A description of the event language. 
  
There is a great deal of very specific and relevant data here so the hope that this will help solve vision problems seems quite reasonable.</p><p>2 0.33896834 <a title="159-tfidf-2" href="../hunch_net-2005/hunch_net-2005-08-01-Peekaboom.html">99 hunch net-2005-08-01-Peekaboom</a></p>
<p>Introduction: Luis  has released  Peekaboom  a successor to  ESPgame  ( game site ).  The purpose of the game is similar—using the actions of people playing a game to gather data helpful in solving AI.  
 
Peekaboom gathers more detailed, and perhaps more useful, data about vision.  For ESPgame, the byproduct of the game was mutually agreed upon labels for common images.  For Peekaboom, the location of the subimage generating the label is revealed by the game as well.  Given knowledge about what portion of the image is related to a label it may be more feasible learn to recognize the appropriate parts. 
 
There isn’t a dataset yet available for this game as there is for ESPgame, but hopefully a significant number of people will play and we’ll have one to work wtih soon.</p><p>3 0.25318003 <a title="159-tfidf-3" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>Introduction: For  his  work on the subject of human computation including  ESPGame ,  Peekaboom , and  Phetch .  The  new MacArthur fellows .</p><p>4 0.21841133 <a title="159-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>Introduction: Luis von Ahn  has been running the  espgame  for awhile now.  The espgame provides a picture to two randomly paired people across the web, and asks them to agree on a label.  It hasn’t managed to label the web yet, but it has produced a  large dataset  of (image, label) pairs.  I organized the dataset so you could  explore the implied bipartite graph  (requires much bandwidth).
 
Relative to other image datasets, this one is quite large—67000 images, 358,000 labels (average of 5/image with variation from 1 to 19), and 22,000 unique labels (one every 3 images).  The dataset is also very ‘natural’, consisting of images spidered from the internet.  The multiple label characteristic is intriguing because ‘learning to learn’ and metalearning techniques may be applicable.  The ‘natural’ quality means that this dataset varies greatly in difficulty from easy (predicting “red”) to hard (predicting “funny”) and potentially more rewarding to tackle.
 
The open problem here is, of course, to make</p><p>5 0.079695165 <a title="159-tfidf-5" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>Introduction: Machine Learning is rising in importance because data is being collected for all sorts of tasks where it either wasn’t previously collected, or for tasks that did not previously exist.  While this is great for Machine Learning, it has a downside—the massive data collection which is so useful can also lead to substantial privacy problems.  
 
It’s important to understand that this is a much harder problem than many people appreciate.  The  AOL   data   release  is a good example.  To those doing machine learning, the following strategies might be obvious:
  
 Just delete any names or other obviously personally identifiable information.  The logic here seems to be “if I can’t easily find the person then no one can”.  That doesn’t work as demonstrated by the people who were found circumstantially from the AOL data. 
 … then just hash all the search terms!  The logic here is “if I can’t read it, then no one can”.  It’s also trivially broken by a dictionary attack—just hash all the strings</p><p>6 0.078907199 <a title="159-tfidf-6" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>7 0.076687433 <a title="159-tfidf-7" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>8 0.075616181 <a title="159-tfidf-8" href="../hunch_net-2009/hunch_net-2009-04-21-Interesting_Presentations_at_Snowbird.html">349 hunch net-2009-04-21-Interesting Presentations at Snowbird</a></p>
<p>9 0.074571773 <a title="159-tfidf-9" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>10 0.07032714 <a title="159-tfidf-10" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>11 0.069833413 <a title="159-tfidf-11" href="../hunch_net-2006/hunch_net-2006-12-06-The_Spam_Problem.html">223 hunch net-2006-12-06-The Spam Problem</a></p>
<p>12 0.067419283 <a title="159-tfidf-12" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>13 0.066849001 <a title="159-tfidf-13" href="../hunch_net-2013/hunch_net-2013-01-01-Deep_Learning_2012.html">477 hunch net-2013-01-01-Deep Learning 2012</a></p>
<p>14 0.065262578 <a title="159-tfidf-14" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>15 0.064321622 <a title="159-tfidf-15" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>16 0.063507073 <a title="159-tfidf-16" href="../hunch_net-2007/hunch_net-2007-12-10-Learning_Track_of_International_Planning_Competition.html">276 hunch net-2007-12-10-Learning Track of International Planning Competition</a></p>
<p>17 0.062309697 <a title="159-tfidf-17" href="../hunch_net-2007/hunch_net-2007-12-21-Vowpal_Wabbit_Code_Release.html">281 hunch net-2007-12-21-Vowpal Wabbit Code Release</a></p>
<p>18 0.061973207 <a title="159-tfidf-18" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>19 0.06191003 <a title="159-tfidf-19" href="../hunch_net-2010/hunch_net-2010-04-14-MLcomp%3A_a_website_for_objectively_comparing_ML_algorithms.html">393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</a></p>
<p>20 0.061607391 <a title="159-tfidf-20" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.114), (1, 0.027), (2, -0.066), (3, 0.027), (4, 0.044), (5, -0.004), (6, -0.046), (7, 0.032), (8, 0.028), (9, -0.075), (10, -0.137), (11, -0.038), (12, -0.095), (13, -0.002), (14, -0.18), (15, -0.14), (16, -0.04), (17, -0.107), (18, -0.077), (19, 0.126), (20, 0.13), (21, -0.038), (22, 0.051), (23, -0.068), (24, 0.241), (25, 0.135), (26, -0.155), (27, 0.037), (28, 0.043), (29, -0.163), (30, 0.064), (31, 0.039), (32, -0.127), (33, 0.174), (34, -0.08), (35, 0.03), (36, -0.065), (37, -0.069), (38, 0.045), (39, -0.035), (40, -0.028), (41, 0.105), (42, -0.066), (43, 0.078), (44, -0.119), (45, -0.033), (46, -0.067), (47, 0.02), (48, 0.009), (49, 0.081)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97374582 <a title="159-lsi-1" href="../hunch_net-2006/hunch_net-2006-02-27-The_Peekaboom_Dataset.html">159 hunch net-2006-02-27-The Peekaboom Dataset</a></p>
<p>Introduction: Luis von Ahn â&euro;&tilde;s  Peekaboom project  has yielded  data  (830MB).
 
Peekaboom is the second attempt (after  Espgame ) to produce a dataset which is useful for learning to solve vision problems based on voluntary game play.  As a second attempt, it is meant to address all of the shortcomings of the first attempt.  In particular:
  
 The locations of specific objects are provided by the data. 
 The data collection is far more complete and extensive. 
  
The data consists of:
  
 The source images. (1 file per image, just short of 60K images.) 
 The in-game events. (1 file per image, in a lispy syntax.) 
 A description of the event language. 
  
There is a great deal of very specific and relevant data here so the hope that this will help solve vision problems seems quite reasonable.</p><p>2 0.95887411 <a title="159-lsi-2" href="../hunch_net-2005/hunch_net-2005-08-01-Peekaboom.html">99 hunch net-2005-08-01-Peekaboom</a></p>
<p>Introduction: Luis  has released  Peekaboom  a successor to  ESPgame  ( game site ).  The purpose of the game is similar—using the actions of people playing a game to gather data helpful in solving AI.  
 
Peekaboom gathers more detailed, and perhaps more useful, data about vision.  For ESPgame, the byproduct of the game was mutually agreed upon labels for common images.  For Peekaboom, the location of the subimage generating the label is revealed by the game as well.  Given knowledge about what portion of the image is related to a label it may be more feasible learn to recognize the appropriate parts. 
 
There isn’t a dataset yet available for this game as there is for ESPgame, but hopefully a significant number of people will play and we’ll have one to work wtih soon.</p><p>3 0.83643842 <a title="159-lsi-3" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<p>Introduction: For  his  work on the subject of human computation including  ESPGame ,  Peekaboom , and  Phetch .  The  new MacArthur fellows .</p><p>4 0.82825679 <a title="159-lsi-4" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>Introduction: Luis von Ahn  has been running the  espgame  for awhile now.  The espgame provides a picture to two randomly paired people across the web, and asks them to agree on a label.  It hasn’t managed to label the web yet, but it has produced a  large dataset  of (image, label) pairs.  I organized the dataset so you could  explore the implied bipartite graph  (requires much bandwidth).
 
Relative to other image datasets, this one is quite large—67000 images, 358,000 labels (average of 5/image with variation from 1 to 19), and 22,000 unique labels (one every 3 images).  The dataset is also very ‘natural’, consisting of images spidered from the internet.  The multiple label characteristic is intriguing because ‘learning to learn’ and metalearning techniques may be applicable.  The ‘natural’ quality means that this dataset varies greatly in difficulty from easy (predicting “red”) to hard (predicting “funny”) and potentially more rewarding to tackle.
 
The open problem here is, of course, to make</p><p>5 0.44967982 <a title="159-lsi-5" href="../hunch_net-2006/hunch_net-2006-12-06-The_Spam_Problem.html">223 hunch net-2006-12-06-The Spam Problem</a></p>
<p>Introduction: The  New York Times  has an article on the  growth of spam .  Interesting facts include: 9/10 of all email is spam, spam source identification is nearly useless due to botnet spam senders, and image based spam (emails which consist of an image only) are on the growth.
 
Estimates of the cost of spam are almost certainly far to low, because they do not account for the cost in time lost by people.
 
The image based spam which is currently penetrating many filters should be catchable with a more sophisticated application of machine learning technology.  For the spam I see, the rendered images come in only a few formats, which would be easy to recognize via a support vector machine (with RBF kernel), neural network, or even nearest-neighbor architecture.  The mechanics of setting this up to run efficiently is the only real challenge.  This is the next step in the spam war.
 
The response to this system is to make the image based spam even more random.  We should (essentially) expect to see</p><p>6 0.40344912 <a title="159-lsi-6" href="../hunch_net-2010/hunch_net-2010-08-24-Alex_Smola_starts_a_blog.html">408 hunch net-2010-08-24-Alex Smola starts a blog</a></p>
<p>7 0.33961949 <a title="159-lsi-7" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>8 0.33100209 <a title="159-lsi-8" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>9 0.3265385 <a title="159-lsi-9" href="../hunch_net-2009/hunch_net-2009-04-21-Interesting_Presentations_at_Snowbird.html">349 hunch net-2009-04-21-Interesting Presentations at Snowbird</a></p>
<p>10 0.31716594 <a title="159-lsi-10" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>11 0.30866161 <a title="159-lsi-11" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>12 0.29862031 <a title="159-lsi-12" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<p>13 0.27505541 <a title="159-lsi-13" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>14 0.27283946 <a title="159-lsi-14" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>15 0.26759017 <a title="159-lsi-15" href="../hunch_net-2006/hunch_net-2006-02-07-Pittsburgh_Mind_Reading_Competition.html">155 hunch net-2006-02-07-Pittsburgh Mind Reading Competition</a></p>
<p>16 0.26753205 <a title="159-lsi-16" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>17 0.26645949 <a title="159-lsi-17" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>18 0.25993678 <a title="159-lsi-18" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>19 0.2584914 <a title="159-lsi-19" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<p>20 0.25656423 <a title="159-lsi-20" href="../hunch_net-2012/hunch_net-2012-02-20-Berkeley_Streaming_Data_Workshop.html">455 hunch net-2012-02-20-Berkeley Streaming Data Workshop</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.047), (53, 0.108), (55, 0.305), (60, 0.325), (95, 0.082)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95453686 <a title="159-lda-1" href="../hunch_net-2006/hunch_net-2006-02-27-The_Peekaboom_Dataset.html">159 hunch net-2006-02-27-The Peekaboom Dataset</a></p>
<p>Introduction: Luis von Ahn â&euro;&tilde;s  Peekaboom project  has yielded  data  (830MB).
 
Peekaboom is the second attempt (after  Espgame ) to produce a dataset which is useful for learning to solve vision problems based on voluntary game play.  As a second attempt, it is meant to address all of the shortcomings of the first attempt.  In particular:
  
 The locations of specific objects are provided by the data. 
 The data collection is far more complete and extensive. 
  
The data consists of:
  
 The source images. (1 file per image, just short of 60K images.) 
 The in-game events. (1 file per image, in a lispy syntax.) 
 A description of the event language. 
  
There is a great deal of very specific and relevant data here so the hope that this will help solve vision problems seems quite reasonable.</p><p>2 0.81543106 <a title="159-lda-2" href="../hunch_net-2006/hunch_net-2006-07-25-Upcoming_conference.html">198 hunch net-2006-07-25-Upcoming conference</a></p>
<p>Introduction: The Workshop for Women in Machine Learning will be held in San Diego on October 4, 2006.
 
For details see the workshop website:
 
http://www.seas.upenn.edu/~wiml/</p><p>3 0.68662667 <a title="159-lda-3" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here’s a handy table for the summer conferences.
  
 
 Conference 
 Deadline 
 Reviewer Targeting 
 Double Blind 
 Author Feedback 
 Location 
 Date 
 
 
  ICML  ( wrong ICML ) 
 January 26 
 Yes 
 Yes 
 Yes 
 Montreal, Canada 
 June 14-17 
 
 
  COLT  
 February 13 
 No 
 No 
 Yes 
 Montreal 
 June 19-21 
 
 
  UAI  
 March 13 
 No 
 Yes 
 No 
 Montreal 
 June 19-21 
 
 
  KDD  
 February 2/6 
 No 
 No 
 No 
 Paris, France 
 June 28-July 1 
 
  
Reviewer targeting is new this year.  The idea is that many poor decisions happen because the papers go to reviewers who are unqualified, and the hope is that allowing authors to point out who is qualified results in better decisions.  In my experience, this is a reasonable idea to test.
 
Both UAI and COLT are experimenting this year as well with double blind and author feedback, respectively.  Of the two, I believe author feedback is more important, as I’ve seen it make a difference.  However, I still consider double blind reviewing a net wi</p><p>4 0.67254299 <a title="159-lda-4" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>Introduction: By  Shie  and  Nati 
 
Following John’s advertisement for submitting to ICML, we thought it appropriate to highlight the advantages of COLT, and the reasons it is often the best place for theory papers.  We would like to emphasize that we both respect ICML, and are active in ICML, both as authors and as area chairs, and certainly are not arguing that ICML is a bad place for your papers.  For many papers, ICML is the best venue.  But for many theory papers, COLT is a better and more appropriate place.
 
Why should you submit to COLT?
 
By-and-large, theory papers go to COLT. This is the tradition of the field and most theory papers are sent to COLT. This is the place to present your ground-breaking theorems and new models that will shape the theory of machine learning. COLT is more focused then ICML with a single track session.  Unlike ICML, the norm in COLT is for people to sit through most sessions, and hear most of the talks presented.  There is also often a lively discussion followi</p><p>5 0.66869271 <a title="159-lda-5" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>Introduction: The  New York Machine Learning Symposium  is October 19 with a 2 page abstract deadline due September 13 via email with subject “Machine Learning Poster Submission” sent to physicalscience@nyas.org.  Everyone is welcome to submit.  Last year’s attendance was 246 and I expect more this year.
 
The primary experiment for  ICML 2013  is multiple paper submission deadlines with rolling review cycles.  The key dates are October 1, December 15, and February 15.  This is an attempt to shift ICML further towards a journal style review process and reduce peak load.   The “not for proceedings” experiment from this year’s ICML is not continuing.
 
Edit: Fixed second ICML deadline.</p><p>6 0.66196561 <a title="159-lda-6" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>7 0.66107959 <a title="159-lda-7" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>8 0.6590628 <a title="159-lda-8" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>9 0.6573779 <a title="159-lda-9" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>10 0.65311003 <a title="159-lda-10" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>11 0.65284073 <a title="159-lda-11" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>12 0.6513021 <a title="159-lda-12" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>13 0.6513021 <a title="159-lda-13" href="../hunch_net-2012/hunch_net-2012-05-12-ICML_accepted_papers_and_early_registration.html">465 hunch net-2012-05-12-ICML accepted papers and early registration</a></p>
<p>14 0.64904571 <a title="159-lda-14" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>15 0.62582111 <a title="159-lda-15" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>16 0.62261248 <a title="159-lda-16" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>17 0.61761093 <a title="159-lda-17" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>18 0.61487532 <a title="159-lda-18" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>19 0.60852158 <a title="159-lda-19" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>20 0.60381609 <a title="159-lda-20" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
