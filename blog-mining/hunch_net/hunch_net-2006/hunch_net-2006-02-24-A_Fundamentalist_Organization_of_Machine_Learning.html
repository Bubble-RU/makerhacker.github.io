<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-158" href="#">hunch_net-2006-158</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-158-html" href="http://hunch.net/?p=169">html</a></p><p>Introduction: There are several different flavors of Machine Learning classes. Many classes
are of the 'zoo' sort: many different learning algorithms are presented.
Others avoid the zoo by not covering the full scope of machine learning.This
is my view of what makes a good machine learning class, along with why. I'd
like to specifically invite comment on whether things are missing,
misemphasized, or misplaced.PhaseSubjectWhy?IntroductionWhat is a machine
learning problem?A good understanding of the characteristics of machine
learning problems seems essential. Characteristics include: a data source,
some hope the data is predictive, and a need for generalization. This is
probably best taught in a case study manner: lay out the specifics of some
problem and then ask "Is this a machine learning problem?"IntroductionMachine
Learning Problem IdentificationIdentification and recognition of the type of
learning problems is (obviously) a very important step in solving such
problems. People need to be famili</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Many classes are of the 'zoo' sort: many different learning algorithms are presented. [sent-2, score-0.348]
</p><p>2 Others avoid the zoo by not covering the full scope of machine learning. [sent-3, score-0.348]
</p><p>3 This is my view of what makes a good machine learning class, along with why. [sent-4, score-0.331]
</p><p>4 A good understanding of the characteristics of machine learning problems seems essential. [sent-8, score-0.687]
</p><p>5 This is probably best taught in a case study manner: lay out the specifics of some problem and then ask "Is this a machine learning problem? [sent-10, score-0.692]
</p><p>6 People need to be familiar witth the concept of 'regression', 'classification', 'cost sensitive classification', 'reinforcement learning', etc… A good organization of these things is possible, but not yet well done. [sent-12, score-0.293]
</p><p>7 IntroductionExample algorithm 1To really understand machine learning, a couple learning algorithms must be understood in detail. [sent-13, score-0.659]
</p><p>8 The reason why the number is "2″ and not "1″ or "3″ is that 2 is the minimum number required to make people naturally aware of the degrees of freedom available in learning algorithm design. [sent-15, score-0.462]
</p><p>9 AnalysisBias for LearningThe need for a good bias is one of the defining characteristics of learning. [sent-16, score-0.617]
</p><p>10 This statement is generic so it will always apply to one degree or another. [sent-18, score-0.323]
</p><p>11 This is the boosting observation: that it is possible to bootstrap predictive ability to create a better overall system. [sent-20, score-0.378]
</p><p>12 AnalysisLearning can be transformedThis is the reductions observation: that the ability to solve one kind of learning problems implies the ability to solve other kinds of leanring problems. [sent-22, score-0.776]
</p><p>13 AnalysisLearning can be preservedThis is the online learning with experts observation: that we can have a master algorithm which preserves the best learning performance of subalgorithms. [sent-24, score-0.532]
</p><p>14 AnalysisHardness of LearningIt turns out that there are several different ways in which machine learning can be hard including computational and information theoretic hardness. [sent-28, score-0.514]
</p><p>15 An understanding of how and why learning algorithms can fail seems important to understand the process. [sent-30, score-0.439]
</p><p>16 ApplicationsVisionOne example of how learning is applied to solve vision problems. [sent-31, score-0.275]
</p><p>17 ApplicationsRoboticsDitto for roboticsApplicationsSpeechDitto for speechApplicationsBusinessesDitto for businessesWhere is machine learning going? [sent-33, score-0.331]
</p><p>18 It should be understood that the field of machine learning is changing rapidly. [sent-35, score-0.453]
</p><p>19 The emphasis here is on fundamentals: generally applicable mathematical statements and understandings of the learning problem. [sent-36, score-0.51]
</p><p>20 Given that emphasis, the 'applications' section could be cut without harming the integrity of the purpose. [sent-37, score-0.297]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('characteristics', 0.277), ('statement', 0.237), ('machine', 0.172), ('learning', 0.159), ('observation', 0.158), ('emphasis', 0.157), ('predictive', 0.138), ('ability', 0.137), ('bias', 0.125), ('need', 0.123), ('similarly', 0.122), ('understood', 0.122), ('solve', 0.116), ('preserves', 0.111), ('integrity', 0.111), ('understandings', 0.111), ('degrees', 0.111), ('leanring', 0.111), ('algorithm', 0.103), ('algorithms', 0.103), ('learningthe', 0.103), ('learningit', 0.103), ('bootstrap', 0.103), ('flavors', 0.103), ('specifics', 0.103), ('avoid', 0.1), ('important', 0.098), ('lay', 0.097), ('cut', 0.097), ('overfit', 0.097), ('theoretic', 0.097), ('priors', 0.092), ('defining', 0.092), ('etc', 0.092), ('freedom', 0.089), ('concept', 0.089), ('pac', 0.089), ('section', 0.089), ('different', 0.086), ('generic', 0.086), ('insert', 0.086), ('problem', 0.083), ('applicable', 0.083), ('specifically', 0.083), ('discussing', 0.081), ('invite', 0.081), ('organization', 0.081), ('understanding', 0.079), ('taught', 0.078), ('scope', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="158-tfidf-1" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>Introduction: There are several different flavors of Machine Learning classes. Many classes
are of the 'zoo' sort: many different learning algorithms are presented.
Others avoid the zoo by not covering the full scope of machine learning.This
is my view of what makes a good machine learning class, along with why. I'd
like to specifically invite comment on whether things are missing,
misemphasized, or misplaced.PhaseSubjectWhy?IntroductionWhat is a machine
learning problem?A good understanding of the characteristics of machine
learning problems seems essential. Characteristics include: a data source,
some hope the data is predictive, and a need for generalization. This is
probably best taught in a case study manner: lay out the specifics of some
problem and then ask "Is this a machine learning problem?"IntroductionMachine
Learning Problem IdentificationIdentification and recognition of the type of
learning problems is (obviously) a very important step in solving such
problems. People need to be famili</p><p>2 0.18513939 <a title="158-tfidf-2" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>Introduction: One of the remarkable things about machine learning is how diverse it is. The
viewpoints of Bayesian learning, reinforcement learning, graphical models,
supervised learning, unsupervised learning, genetic programming, etc… share
little enough overlap that many people can and do make their careers within
one without touching, or even necessarily understanding the others.There are
two fundamental reasons why this is possible.For many problems, many
approaches work in the sense that they do something useful. This is true
empirically, where for many problems we can observe that many different
approaches yield better performance than any constant predictor. It's also
true in theory, where we know that for any set of predictors representable in
a finite amount of RAM, minimizing training error over the set of predictors
does something nontrivial when there are a sufficient number of examples.There
is nothing like a unifying problem defining the field. In many other areas
there are unifying p</p><p>3 0.17515704 <a title="158-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>Introduction: What?Reductions are machines which turn solvers for one problem into solvers
for another problem.Why?Reductions are useful for several reasons.Laziness.
Reducing a problem to classification make at least 10 learning algorithms
available to solve a problem. Inventing 10 learning algorithms is quite a bit
of work. Similarly, programming a reduction is often trivial, while
programming a learning algorithm is a great deal of work.Crystallization. The
problems we often want to solve in learning are worst-case-impossible, but
average case feasible. By reducing all problems onto one or a few primitives,
we can fine tune these primitives to perform well on real-world problems with
greater precision due to the greater number of problems to validate
on.Theoretical Organization. By studying what reductions are easy vs. hard vs.
impossible, we can learn which problems are roughly equivalent in difficulty
and which are much harder.What we know now.Typesafe reductions. In the
beginning, there was th</p><p>4 0.1686794 <a title="158-tfidf-4" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>5 0.15576132 <a title="158-tfidf-5" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>Introduction: I've had serious conversations with several people who believe that the theory
in machine learning is "only useful for getting papers published". That's a
compelling statement, as I've seen many papers where the algorithm clearly
came first, and the theoretical justification for it came second, purely as a
perceived means to improve the chance of publication.Naturally, I disagree and
believe that learning theory has much more substantial applications.Even in
core learning algorithm design, I've found learning theory to be useful,
although it's application is more subtle than many realize. The most
straightforward applications can fail, because (as expectation suggests) worst
case bounds tend to be loose in practice (*). In my experience, considering
learning theory when designing an algorithm has two important effects in
practice:It can help make your algorithm behave right at a crude level of
analysis, leaving finer details to tuning or common sense. The best example I
have of this is</p><p>6 0.15201436 <a title="158-tfidf-6" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>7 0.14578289 <a title="158-tfidf-7" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>8 0.14014839 <a title="158-tfidf-8" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>9 0.13814518 <a title="158-tfidf-9" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>10 0.13764587 <a title="158-tfidf-10" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>11 0.13086137 <a title="158-tfidf-11" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>12 0.12813011 <a title="158-tfidf-12" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>13 0.12812687 <a title="158-tfidf-13" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>14 0.12747473 <a title="158-tfidf-14" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>15 0.12719025 <a title="158-tfidf-15" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>16 0.12555893 <a title="158-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>17 0.12539425 <a title="158-tfidf-17" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>18 0.12413231 <a title="158-tfidf-18" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>19 0.12198215 <a title="158-tfidf-19" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>20 0.12016348 <a title="158-tfidf-20" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.315), (1, -0.131), (2, 0.065), (3, -0.052), (4, -0.044), (5, -0.021), (6, -0.089), (7, 0.053), (8, -0.021), (9, 0.043), (10, 0.024), (11, -0.081), (12, 0.125), (13, -0.063), (14, -0.059), (15, 0.051), (16, -0.031), (17, -0.057), (18, 0.026), (19, 0.018), (20, 0.097), (21, -0.078), (22, 0.048), (23, -0.021), (24, -0.084), (25, -0.011), (26, 0.026), (27, 0.061), (28, -0.067), (29, -0.055), (30, -0.047), (31, -0.045), (32, -0.013), (33, -0.015), (34, -0.012), (35, -0.026), (36, -0.026), (37, 0.041), (38, 0.037), (39, 0.052), (40, -0.017), (41, 0.007), (42, -0.044), (43, -0.018), (44, -0.004), (45, -0.039), (46, 0.022), (47, 0.024), (48, 0.057), (49, 0.011)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9608928 <a title="158-lsi-1" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>Introduction: There are several different flavors of Machine Learning classes. Many classes
are of the 'zoo' sort: many different learning algorithms are presented.
Others avoid the zoo by not covering the full scope of machine learning.This
is my view of what makes a good machine learning class, along with why. I'd
like to specifically invite comment on whether things are missing,
misemphasized, or misplaced.PhaseSubjectWhy?IntroductionWhat is a machine
learning problem?A good understanding of the characteristics of machine
learning problems seems essential. Characteristics include: a data source,
some hope the data is predictive, and a need for generalization. This is
probably best taught in a case study manner: lay out the specifics of some
problem and then ask "Is this a machine learning problem?"IntroductionMachine
Learning Problem IdentificationIdentification and recognition of the type of
learning problems is (obviously) a very important step in solving such
problems. People need to be famili</p><p>2 0.85678452 <a title="158-lsi-2" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>Introduction: Let's define a learning problem as making predictions given past data. There
are several ways to attack the learning problem which seem to be equivalent to
solving the learning problem.Find the InvariantThis viewpoint says that
learning is all about learning (or incorporating) transformations of objects
that do not change the correct prediction. The best possible invariant is the
one which says "all things of the same class are the same". Finding this is
equivalent to learning. This viewpoint is particularly common when working
with image features.Feature SelectionThis viewpoint says that the way to learn
is by finding the right features to input to a learning algorithm. The best
feature is the one which is the class to predict. Finding this is equivalent
to learning for all reasonable learning algorithms. This viewpoint is common
in several applications of machine learning. SeeGilad's and Bianca's
comments.Find the RepresentationThis is almost the same as feature selection,
except int</p><p>3 0.84336972 <a title="158-lsi-3" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>Introduction: One of the remarkable things about machine learning is how diverse it is. The
viewpoints of Bayesian learning, reinforcement learning, graphical models,
supervised learning, unsupervised learning, genetic programming, etc… share
little enough overlap that many people can and do make their careers within
one without touching, or even necessarily understanding the others.There are
two fundamental reasons why this is possible.For many problems, many
approaches work in the sense that they do something useful. This is true
empirically, where for many problems we can observe that many different
approaches yield better performance than any constant predictor. It's also
true in theory, where we know that for any set of predictors representable in
a finite amount of RAM, minimizing training error over the set of predictors
does something nontrivial when there are a sufficient number of examples.There
is nothing like a unifying problem defining the field. In many other areas
there are unifying p</p><p>4 0.84103829 <a title="158-lsi-4" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>Introduction: A couple years ago, Drew Bagnell and I started theRLBench projectto setup a
suite of reinforcement learning benchmark problems. We haven't been able to
touch it (due to lack of time) for a year so the project is on hold. Luckily,
there are several other projects such asCLSquareandRL-Gluewith a similar goal,
and we strongly endorse their continued development.I would like to explain
why, especially in the context of criticism of other learning benchmarks. For
example, sometimes theUCI Machine Learning Repositoryis criticized. There are
two criticisms I know of:Learning algorithms have overfit to the problems in
the repository. It is easy to imagine a mechanism for this happening
unintentionally. Strong evidence of this would be provided by learning
algorithms which perform great on the UCI machine learning repository but very
badly (relative to other learning algorithms) on non-UCI learning problems. I
have seen little evidence of this but it remains a point of concern. There is
a natur</p><p>5 0.8349691 <a title="158-lsi-5" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provostgave a talk at the ICMLmetalearning workshopon "metalearning"
and the "no free lunch theorem" which seems worth summarizing.As a review: the
no free lunch theorem is the most complicated way we know of to say that
abiasis required in order to learn. The simplest way to see this is in a
nonprobabilistic setting. If you are given examples of the form(x,y)and you
wish to predictyfromxthen any prediction mechanism errs half the time in
expectation over all sequences of examples. The proof of this is very simple:
on every example a predictor must make some prediction and by symmetry over
the set of sequences it will be wrong half the time and right half the time.
The basic idea of this proof has been applied to many other settings.The
simplistic interpretation of this theorem which many people jump to is
"machine learning is dead" since there can be no single learning algorithm
which can solve all learning problems. This is the wrong way to think about
it. In the real world, w</p><p>6 0.79311597 <a title="158-lsi-6" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>7 0.78701758 <a title="158-lsi-7" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>8 0.78119791 <a title="158-lsi-8" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>9 0.7811535 <a title="158-lsi-9" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>10 0.78050417 <a title="158-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>11 0.77818632 <a title="158-lsi-11" href="../hunch_net-2005/hunch_net-2005-11-28-A_question_of_quantification.html">133 hunch net-2005-11-28-A question of quantification</a></p>
<p>12 0.75410366 <a title="158-lsi-12" href="../hunch_net-2005/hunch_net-2005-02-04-JMLG.html">13 hunch net-2005-02-04-JMLG</a></p>
<p>13 0.75319749 <a title="158-lsi-13" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>14 0.75006503 <a title="158-lsi-14" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>15 0.74750286 <a title="158-lsi-15" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>16 0.74563432 <a title="158-lsi-16" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>17 0.74288189 <a title="158-lsi-17" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>18 0.74261379 <a title="158-lsi-18" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>19 0.73416042 <a title="158-lsi-19" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>20 0.7312423 <a title="158-lsi-20" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(19, 0.131), (35, 0.059), (42, 0.386), (45, 0.049), (50, 0.04), (74, 0.113), (76, 0.032), (83, 0.03), (95, 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96132982 <a title="158-lda-1" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>Introduction: There are several different flavors of Machine Learning classes. Many classes
are of the 'zoo' sort: many different learning algorithms are presented.
Others avoid the zoo by not covering the full scope of machine learning.This
is my view of what makes a good machine learning class, along with why. I'd
like to specifically invite comment on whether things are missing,
misemphasized, or misplaced.PhaseSubjectWhy?IntroductionWhat is a machine
learning problem?A good understanding of the characteristics of machine
learning problems seems essential. Characteristics include: a data source,
some hope the data is predictive, and a need for generalization. This is
probably best taught in a case study manner: lay out the specifics of some
problem and then ask "Is this a machine learning problem?"IntroductionMachine
Learning Problem IdentificationIdentification and recognition of the type of
learning problems is (obviously) a very important step in solving such
problems. People need to be famili</p><p>2 0.95305651 <a title="158-lda-2" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>Introduction: There were several papers that seemed fairly interesting atKDD this year. The
ones that caught my attention are:Xin Jin, Mingyang Zhang,Nan Zhang, andGautam
Das,Versatile Publishing For Privacy Preservation. This paper provides a
conservative method for safely determining which data is publishable from any
complete source of information (for example, a hospital) such that it does not
violate privacy rules in a natural language. It is not differentially private,
so no external sources of join information can exist. However, it is a
mechanism forpublishingdata rather than (say) the output of a learning
algorithm.Arik FriedmanAssaf Schuster,Data Mining with Differential Privacy.
This paper shows how to create effective differentially private decision
trees. Progress in differentially private datamining is pretty impressive, as
it wasdefined in 2006.David Chan, Rong Ge, Ori Gershony,Tim Hesterberg,Diane
Lambert,Evaluating Online Ad Campaigns in a Pipeline: Causal Models At
ScaleThis paper</p><p>3 0.93270278 <a title="158-lda-3" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>Introduction: A little over 4 years ago,Sanjoymade a postsaying roughly "we should study
active learning theoretically, because not much is understood".At the time, we
did not understand basic things such as whether or not it was possible to PAC-
learn with an active algorithm without making strong assumptions about the
noise rate. In other words, the fundamental question was "can we do it?"The
nature of the question has fundamentally changed in my mind. The answer is to
the previous question is "yes", both information theoretically and
computationally, most places where supervised learning could be applied.In
many situation, the question has now changed to: "is it worth it?" Is the
programming and computational overhead low enough to make the label cost
savings of active learning worthwhile? Currently, there are situations where
this question could go either way. Much of the challenge for the future is in
figuring out how to make active learning easier or more worthwhile.At
theactive learning tutor</p><p>4 0.93147725 <a title="158-lda-4" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>Introduction: I've had serious conversations with several people who believe that the theory
in machine learning is "only useful for getting papers published". That's a
compelling statement, as I've seen many papers where the algorithm clearly
came first, and the theoretical justification for it came second, purely as a
perceived means to improve the chance of publication.Naturally, I disagree and
believe that learning theory has much more substantial applications.Even in
core learning algorithm design, I've found learning theory to be useful,
although it's application is more subtle than many realize. The most
straightforward applications can fail, because (as expectation suggests) worst
case bounds tend to be loose in practice (*). In my experience, considering
learning theory when designing an algorithm has two important effects in
practice:It can help make your algorithm behave right at a crude level of
analysis, leaving finer details to tuning or common sense. The best example I
have of this is</p><p>5 0.928684 <a title="158-lda-5" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>Introduction: Muthuinvited me to the workshop onalgorithms in the field, with the goal of
providing a sense of where near-term research should go. When the time came
though, I bargained for a post instead, which provides a chance for many other
people to comment.There are several things I didn't fully understand when I
went to Yahoo! about 5 years ago. I'd like to repeat them as people in
academia may not yet understand them intuitively.Almost all the big impact
algorithms operate in pseudo-linear or better time. Think about caching,
hashing, sorting, filtering, etcâ&euro;Ś and you have a sense of what some of the
most heavily used algorithms are. This matters quite a bit to Machine Learning
research, because people often work with superlinear time algorithms and
languages. Two very common examples of this are graphical models, where
inference is often a superlinear operation--think about then2dependence on the
number of states in aHidden Markov Modeland KernelizedSupport Vector
Machineswhere optimization</p><p>6 0.92711645 <a title="158-lda-6" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>7 0.92654878 <a title="158-lda-7" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>8 0.92577249 <a title="158-lda-8" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>9 0.92484683 <a title="158-lda-9" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>10 0.92428994 <a title="158-lda-10" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>11 0.92362982 <a title="158-lda-11" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>12 0.92275941 <a title="158-lda-12" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>13 0.92245537 <a title="158-lda-13" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>14 0.92239159 <a title="158-lda-14" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>15 0.92228538 <a title="158-lda-15" href="../hunch_net-2013/hunch_net-2013-12-01-NIPS_tutorials_and_Vowpal_Wabbit_7.4.html">492 hunch net-2013-12-01-NIPS tutorials and Vowpal Wabbit 7.4</a></p>
<p>16 0.92218107 <a title="158-lda-16" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>17 0.92162824 <a title="158-lda-17" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>18 0.92158389 <a title="158-lda-18" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>19 0.9194234 <a title="158-lda-19" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>20 0.91927904 <a title="158-lda-20" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
