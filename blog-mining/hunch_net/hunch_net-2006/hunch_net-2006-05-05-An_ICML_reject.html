<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>177 hunch net-2006-05-05-An ICML reject</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-177" href="#">hunch_net-2006-177</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>177 hunch net-2006-05-05-An ICML reject</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-177-html" href="http://hunch.net/?p=188">html</a></p><p>Introduction: Hal ,  Daniel , and I have been working on the algorithm  Searn  for structured prediction.  This was just conditionally accepted and then rejected from ICML, and we were quite surprised.  By any reasonable criteria, it seems this is an interesting algorithm.
  
 Prediction Performance: Searn performed better than any other algorithm on all the problems we tested against using the same feature set.  This is true even using the numbers reported by authors in their papers. 
 Theoretical underpinning.  Searn is a reduction which comes with a reduction guarantee: the good performance on a base classifiers implies good performance for the overall system.  No other theorem of this type has been made for other structured prediction algorithms, as far as we know. 
 Speed. Searn has no problem handling much larger datasets than other algorithms we tested against. 
 Simplicity.  Given code for a binary classifier and a problem-specific search algorithm, only a few tens of lines are necessary to</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Prediction Performance: Searn performed better than any other algorithm on all the problems we tested against using the same feature set. [sent-4, score-0.21]
</p><p>2 Searn is a reduction which comes with a reduction guarantee: the good performance on a base classifiers implies good performance for the overall system. [sent-7, score-0.584]
</p><p>3 It can use (and cope with) arbitrary loss functions over the data. [sent-15, score-0.191]
</p><p>4 A very typical (although often unstated) tradeoff is expending extra computation to gain better predictive performance in practice. [sent-18, score-0.294]
</p><p>5 One endorsement of this comes from a reviewer who said   In the end, I do think there is something there, but I think its introduction should have been like that for CRF. [sent-26, score-0.175]
</p><p>6 The SPC stated:    The results, though, which essentially show that good local classifiers imply good global performance, are not that significant, and hold for other approaches that use local classifiers as building blocks. [sent-30, score-1.119]
</p><p>7 After all, perfect local classifiers provide perfect local accuracy, and therefore provide perfect global accuracy, and again provide perfect global loss of any kind. [sent-31, score-2.511]
</p><p>8 Both sentences are simply false in the setting we consider. [sent-32, score-0.199]
</p><p>9 In particular, no other algorithms appear to have a good local performance to global performance guarantee for general global loss functions. [sent-33, score-1.537]
</p><p>10 Furthermore, it is  not  the case that perfect local performance implies perfect global performance except (perhaps) in a noise free world. [sent-34, score-1.566]
</p><p>11 Most of us believe that the problems we address typically contain fundamental ambiguities and noise (that was certainly our mathematical model). [sent-35, score-0.196]
</p><p>12 It’s easy to setup a (noisy) distribution over inputs+loss such that best-possible-up-to-the-noise-limit local predictors are globally suboptimal. [sent-36, score-0.25]
</p><p>13 The SPC wanted us to contrast with  Michael Collins, Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms, EMNLP02 . [sent-37, score-0.196]
</p><p>14 I believe any reasonable reading of these and the Searn paper will find the ACL04 paper superceeds the EMNLP02 paper in relevance. [sent-39, score-0.195]
</p><p>15 IBT is a modification of the earlier algorithm which integrates global information (in the form of problem specific  constraints ) into the local training process yielding performance gains. [sent-50, score-1.01]
</p><p>16 Searn is made to cope with global loss functions rather than global constraints. [sent-52, score-0.871]
</p><p>17 For whatever reason, it is psychologically difficult to build on rejected work. [sent-57, score-0.192]
</p><p>18 If you think something is true but aren’t sure, it is appropriate to say “I think …” rather than simply asserting it as a fact. [sent-65, score-0.387]
</p><p>19 If there are no comments or simply comments about Searn, that’s fine. [sent-68, score-0.203]
</p><p>20 This post violates a standard: avoiding talking about specific papers the poster has been working on. [sent-73, score-0.177]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('searn', 0.386), ('global', 0.311), ('local', 0.25), ('perfect', 0.226), ('performance', 0.215), ('spc', 0.202), ('classifiers', 0.154), ('ibt', 0.123), ('punyakanok', 0.123), ('false', 0.11), ('collins', 0.109), ('asserting', 0.109), ('roth', 0.109), ('loss', 0.109), ('rejected', 0.104), ('modification', 0.101), ('structured', 0.092), ('simply', 0.089), ('build', 0.088), ('cope', 0.082), ('tradeoff', 0.079), ('perceptron', 0.079), ('tested', 0.077), ('aren', 0.075), ('provide', 0.074), ('algorithm', 0.073), ('us', 0.071), ('accuracy', 0.07), ('hal', 0.07), ('true', 0.069), ('noise', 0.065), ('paper', 0.065), ('stated', 0.064), ('guarantee', 0.064), ('wanted', 0.063), ('michael', 0.062), ('algorithms', 0.062), ('contrast', 0.062), ('post', 0.061), ('specific', 0.06), ('think', 0.06), ('problems', 0.06), ('experiments', 0.059), ('weak', 0.059), ('case', 0.058), ('made', 0.058), ('comments', 0.057), ('papers', 0.056), ('looking', 0.056), ('reviewer', 0.055)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="177-tfidf-1" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>Introduction: Hal ,  Daniel , and I have been working on the algorithm  Searn  for structured prediction.  This was just conditionally accepted and then rejected from ICML, and we were quite surprised.  By any reasonable criteria, it seems this is an interesting algorithm.
  
 Prediction Performance: Searn performed better than any other algorithm on all the problems we tested against using the same feature set.  This is true even using the numbers reported by authors in their papers. 
 Theoretical underpinning.  Searn is a reduction which comes with a reduction guarantee: the good performance on a base classifiers implies good performance for the overall system.  No other theorem of this type has been made for other structured prediction algorithms, as far as we know. 
 Speed. Searn has no problem handling much larger datasets than other algorithms we tested against. 
 Simplicity.  Given code for a binary classifier and a problem-specific search algorithm, only a few tens of lines are necessary to</p><p>2 0.15670927 <a title="177-tfidf-2" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>Introduction: This post is partly meant as an advertisement for the  reductions tutorial   Alina ,  Bianca , and I are planning to do at  ICML .  Please come, if you are interested.
 
Many research programs can be thought of as finding and building new useful abstractions.  The running example I’ll use is  learning reductions  where I have experience.  The basic abstraction here is that we can build a learning algorithm capable of solving classification problems up to a small expected regret.   This is used repeatedly to solve more complex problems.
 
In working on a new abstraction, I think you typically run into many substantial problems of understanding, which make publishing particularly difficult.
  
 It is difficult to seriously discuss the reason behind or mechanism for abstraction in a conference paper with small page limits.  People rarely see such discussions and hence have little basis on which to think about new abstractions.    Another difficulty is that when building an abstraction, yo</p><p>3 0.15580584 <a title="177-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>Introduction: “Overfitting” is traditionally defined as training some flexible representation so that it memorizes the data but fails to predict well in the future. For this post, I will define overfitting more generally as over-representing the performance of systems.  There are two styles of general overfitting: overrepresenting performance on particular datasets and (implicitly) overrepresenting performance of a method on future datasets.  
 
We should all be aware of these methods, avoid them where possible, and take them into account otherwise.   I have used “reproblem” and “old datasets”, and may have participated in “overfitting by review”—some of these are very difficult to avoid.
  
 
 Name 
 Method 
 Explanation 
 Remedy 
 
 
 Traditional overfitting 
 Train a complex predictor on too-few examples. 
  
 
 
 Hold out pristine examples for testing. 
 Use a simpler predictor. 
 Get more training examples. 
 Integrate over many predictors. 
 Reject papers which do this. 
 
 
 
 
 Parameter twe</p><p>4 0.15242817 <a title="177-tfidf-4" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but sometimes the unfairness seems particularly striking.  This is most easily seen by comparison:
  
 
 Paper 
  Banditron  
  Offset Tree  
 Notes 
 
 
 Problem Scope 
 Multiclass problems where only the loss of one choice can be probed. 
 Strictly greater: Cost sensitive multiclass problems where only the loss of one choice can be probed. 
 Often generalizations don’t matter.  That’s not the case here, since every plausible application I’ve thought of involves loss functions substantially different from 0/1. 
 
 
 What’s new 
 Analysis and Experiments 
 Algorithm, Analysis, and Experiments 
  As far as I know, the essence of the more general problem was first stated and analyzed with the  EXP4 algorithm (page 16)  (1998).  It’s also the time horizon 1 simplification of the Reinforcement Learning setting for the  random trajectory method (page 15)  (2002).  The Banditron algorithm itself is functionally identi</p><p>5 0.14564919 <a title="177-tfidf-5" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>Introduction: Last year about this time, we received a conditional accept for the  searn paper , which asked us to reference a paper that was not reasonable to cite because there was strictly more relevant work by the same authors that we already cited.  We wrote a response explaining this, and didn’t cite it in the final draft, giving the SPC an excuse to  reject the paper , leading to unhappiness for all.
 
Later,  Sanjoy Dasgupta  suggested that an alternative was to talk to the PC chair instead, as soon as you see that a conditional accept is unreasonable.   William Cohen  and I spoke about this by email, the relevant bit of which is:
  

If an SPC asks for a revision that is inappropriate, the correct 
action is to contact the chairs as soon as the decision is made, 
clearly explaining what the problem is, so we can decide whether or 
not to over-rule the SPC.  As you say, this is extra work for us 
chairs, but that’s part of the job, and we’re willing to do that sort 
of work to improve the ov</p><p>6 0.13605313 <a title="177-tfidf-6" href="../hunch_net-2005/hunch_net-2005-06-29-Not_EM_for_clustering_at_COLT.html">87 hunch net-2005-06-29-Not EM for clustering at COLT</a></p>
<p>7 0.13427861 <a title="177-tfidf-7" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>8 0.13168116 <a title="177-tfidf-8" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>9 0.12655589 <a title="177-tfidf-9" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>10 0.12288994 <a title="177-tfidf-10" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>11 0.11857257 <a title="177-tfidf-11" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>12 0.11856646 <a title="177-tfidf-12" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>13 0.11798044 <a title="177-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>14 0.11758158 <a title="177-tfidf-14" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>15 0.11547669 <a title="177-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>16 0.11519089 <a title="177-tfidf-16" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>17 0.11250316 <a title="177-tfidf-17" href="../hunch_net-2010/hunch_net-2010-04-24-COLT_Treasurer_is_now_Phil_Long.html">394 hunch net-2010-04-24-COLT Treasurer is now Phil Long</a></p>
<p>18 0.11172078 <a title="177-tfidf-18" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>19 0.11096048 <a title="177-tfidf-19" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>20 0.11038096 <a title="177-tfidf-20" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.301), (1, 0.053), (2, 0.098), (3, -0.012), (4, -0.047), (5, 0.028), (6, -0.008), (7, -0.032), (8, -0.005), (9, 0.048), (10, -0.004), (11, 0.003), (12, -0.015), (13, -0.03), (14, 0.046), (15, 0.013), (16, 0.045), (17, 0.014), (18, -0.015), (19, -0.037), (20, 0.028), (21, -0.068), (22, -0.045), (23, -0.115), (24, -0.069), (25, -0.007), (26, -0.028), (27, -0.039), (28, 0.043), (29, -0.121), (30, -0.076), (31, 0.015), (32, -0.015), (33, -0.032), (34, 0.067), (35, 0.102), (36, -0.024), (37, 0.026), (38, 0.036), (39, 0.049), (40, 0.051), (41, -0.005), (42, -0.034), (43, -0.066), (44, 0.154), (45, -0.026), (46, -0.034), (47, 0.056), (48, -0.022), (49, 0.065)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97610837 <a title="177-lsi-1" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>Introduction: Hal ,  Daniel , and I have been working on the algorithm  Searn  for structured prediction.  This was just conditionally accepted and then rejected from ICML, and we were quite surprised.  By any reasonable criteria, it seems this is an interesting algorithm.
  
 Prediction Performance: Searn performed better than any other algorithm on all the problems we tested against using the same feature set.  This is true even using the numbers reported by authors in their papers. 
 Theoretical underpinning.  Searn is a reduction which comes with a reduction guarantee: the good performance on a base classifiers implies good performance for the overall system.  No other theorem of this type has been made for other structured prediction algorithms, as far as we know. 
 Speed. Searn has no problem handling much larger datasets than other algorithms we tested against. 
 Simplicity.  Given code for a binary classifier and a problem-specific search algorithm, only a few tens of lines are necessary to</p><p>2 0.70126903 <a title="177-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-12-ROC_vs._Accuracy_vs._AROC.html">18 hunch net-2005-02-12-ROC vs. Accuracy vs. AROC</a></p>
<p>Introduction: Foster Provost  and I discussed the merits of ROC curves vs. accuracy estimation.  Here is a quick summary of our discussion.
 
The “Receiver Operating Characteristic” (ROC) curve is an alternative to accuracy for the evaluation of learning algorithms on natural datasets.  The ROC curve is a  curve  and not a single number statistic.  In particular, this means that the comparison of two algorithms on a dataset does not always produce an obvious order.
 
Accuracy (= 1 – error rate) is a standard method used to evaluate learning algorithms.  It is a single-number summary of performance.
 
AROC is the area under the ROC curve.  It is a single number summary of performance.
 
The comparison of these metrics is a subtle affair, because in machine learning, they are compared on different natural datasets.  This makes some sense if we accept the hypothesis “Performance on past learning problems (roughly) predicts performance on future learning problems.”
 
The ROC vs. accuracy discussion is o</p><p>3 0.65224534 <a title="177-lsi-3" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>Introduction: “Overfitting” is traditionally defined as training some flexible representation so that it memorizes the data but fails to predict well in the future. For this post, I will define overfitting more generally as over-representing the performance of systems.  There are two styles of general overfitting: overrepresenting performance on particular datasets and (implicitly) overrepresenting performance of a method on future datasets.  
 
We should all be aware of these methods, avoid them where possible, and take them into account otherwise.   I have used “reproblem” and “old datasets”, and may have participated in “overfitting by review”—some of these are very difficult to avoid.
  
 
 Name 
 Method 
 Explanation 
 Remedy 
 
 
 Traditional overfitting 
 Train a complex predictor on too-few examples. 
  
 
 
 Hold out pristine examples for testing. 
 Use a simpler predictor. 
 Get more training examples. 
 Integrate over many predictors. 
 Reject papers which do this. 
 
 
 
 
 Parameter twe</p><p>4 0.63035321 <a title="177-lsi-4" href="../hunch_net-2005/hunch_net-2005-04-04-Grounds_for_Rejection.html">52 hunch net-2005-04-04-Grounds for Rejection</a></p>
<p>Introduction: It’s reviewing season right now, so I thought I would list (at a high level) the sorts of problems which I see in papers.  Hopefully, this will help us all write better papers.
 
The following flaws are fatal to any paper:
  
  Incorrect theorem or lemma statements  A typo might be “ok”, if it can be understood.  Any theorem or lemma which indicates an incorrect understanding of reality must be rejected.  Not doing so would severely harm the integrity of the conference.  A paper rejected for this reason must be fixed. 
  Lack of Understanding  If a paper is understood by none of the (typically 3) reviewers then it must be rejected for the same reason.  This is more controversial than it sounds because there are some people who maximize paper complexity in the hope of impressing the reviewer.  The tactic sometimes succeeds with some reviewers (but not with me).

As a reviewer, I sometimes get lost for stupid reasons.  This is why an anonymized  communication channel  with the author can</p><p>5 0.62841636 <a title="177-lsi-5" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but sometimes the unfairness seems particularly striking.  This is most easily seen by comparison:
  
 
 Paper 
  Banditron  
  Offset Tree  
 Notes 
 
 
 Problem Scope 
 Multiclass problems where only the loss of one choice can be probed. 
 Strictly greater: Cost sensitive multiclass problems where only the loss of one choice can be probed. 
 Often generalizations don’t matter.  That’s not the case here, since every plausible application I’ve thought of involves loss functions substantially different from 0/1. 
 
 
 What’s new 
 Analysis and Experiments 
 Algorithm, Analysis, and Experiments 
  As far as I know, the essence of the more general problem was first stated and analyzed with the  EXP4 algorithm (page 16)  (1998).  It’s also the time horizon 1 simplification of the Reinforcement Learning setting for the  random trajectory method (page 15)  (2002).  The Banditron algorithm itself is functionally identi</p><p>6 0.62140781 <a title="177-lsi-6" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>7 0.61567134 <a title="177-lsi-7" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>8 0.61275876 <a title="177-lsi-8" href="../hunch_net-2005/hunch_net-2005-06-29-Not_EM_for_clustering_at_COLT.html">87 hunch net-2005-06-29-Not EM for clustering at COLT</a></p>
<p>9 0.6105516 <a title="177-lsi-9" href="../hunch_net-2008/hunch_net-2008-07-26-Compositional_Machine_Learning_Algorithm_Design.html">311 hunch net-2008-07-26-Compositional Machine Learning Algorithm Design</a></p>
<p>10 0.60737795 <a title="177-lsi-10" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>11 0.60604155 <a title="177-lsi-11" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>12 0.58552951 <a title="177-lsi-12" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>13 0.58397746 <a title="177-lsi-13" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>14 0.57958972 <a title="177-lsi-14" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>15 0.57868207 <a title="177-lsi-15" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>16 0.56721264 <a title="177-lsi-16" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>17 0.56691808 <a title="177-lsi-17" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>18 0.56007892 <a title="177-lsi-18" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>19 0.55805969 <a title="177-lsi-19" href="../hunch_net-2010/hunch_net-2010-04-14-MLcomp%3A_a_website_for_objectively_comparing_ML_algorithms.html">393 hunch net-2010-04-14-MLcomp: a website for objectively comparing ML algorithms</a></p>
<p>20 0.55254692 <a title="177-lsi-20" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.013), (3, 0.019), (9, 0.019), (10, 0.041), (27, 0.25), (38, 0.063), (46, 0.223), (53, 0.082), (55, 0.056), (92, 0.011), (94, 0.094), (95, 0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95492315 <a title="177-lda-1" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>Introduction: After a  major financial crisis , there is much discussion about how  finance has become a casino  gambling with other’s money, keeping the winnings, and walking away when the money is lost.  
 
When thinking about financial reform, all the many losers in the above scenario are apt to take the view that this activity should be completely, or nearly completely curtailed.  But, a more thoughtful view is that sometimes there is a real sense in which there are right and wrong decisions, and we as a society would really prefer that the people most likely to make right decisions are making them.  A crucial question then is: “What is the  difference between gambling and rewarding good prediction?”
 
We  discussed this before the financial crisis . The cheat-sheet sketch is that the online learning against an adversary problem, algorithm, and theorems, provide a good mathematical model for thinking about this question.  What I would like to do here is map this onto various types of financial t</p><p>2 0.91551429 <a title="177-lda-2" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>Introduction: The essential problem here is the large gap between experimental observation and theoretical understanding.
 
 Method   K-fold cross validation is a commonly used technique which takes a set of  m  examples and partitions them into  K  sets (“folds”) of size  m/K .  For each fold, a classifier is trained on the other folds and then test on the fold.
 
 Problem   Assume only independent samples.  Derive a classifier from the K classifiers with a small bound on the true error rate.
 
 Past Work  (I’ll add more as I remember/learn.)
  
  Devroye , Rogers, and Wagner analyzed cross validation and found algorithm specific bounds.  Not all of this is online, but here is one  paper .  
  Michael Kearns  and  Dana Ron   analyzed cross validation  and found that under additional stability assumptions the bound for the classifier which learns on all the data is not much worse than for a test set of size  m/K  .  
  Avrim Blum,   Adam Kalai , and  myself   analyzed cross validation  and found tha</p><p>same-blog 3 0.91280627 <a title="177-lda-3" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>Introduction: Hal ,  Daniel , and I have been working on the algorithm  Searn  for structured prediction.  This was just conditionally accepted and then rejected from ICML, and we were quite surprised.  By any reasonable criteria, it seems this is an interesting algorithm.
  
 Prediction Performance: Searn performed better than any other algorithm on all the problems we tested against using the same feature set.  This is true even using the numbers reported by authors in their papers. 
 Theoretical underpinning.  Searn is a reduction which comes with a reduction guarantee: the good performance on a base classifiers implies good performance for the overall system.  No other theorem of this type has been made for other structured prediction algorithms, as far as we know. 
 Speed. Searn has no problem handling much larger datasets than other algorithms we tested against. 
 Simplicity.  Given code for a binary classifier and a problem-specific search algorithm, only a few tens of lines are necessary to</p><p>4 0.90213162 <a title="177-lda-4" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>Introduction: Accountability is a social problem.  When someone screws up, do you fire them?  Or do you accept the error and let them continue?  This is a very difficult problem and we all know of stories where the wrong decision was made.
 
 Online learning  (as meant here), is a subfield of learning theory which analyzes the online learning model.  
 
In the online learning model, there are a set of hypotheses or “experts”.  On any instantance  x , each expert makes a prediction  y .  A master algorithm  A  uses these predictions to form it’s own prediction  y A   and then  learns the correct prediction  y *  .  This process repeats.
 
The goal of online learning is to find a master algorithm  A  which uses the advice of the experts to make good predictions.  In particular, we typically want to guarantee that the master algorithm performs almost as well as the best expert.  If  L(e)  is the loss of expert  e  and  L(A)  is the loss of the master algorithm, it is often possible to prove:   L(A) les</p><p>5 0.79245877 <a title="177-lda-5" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>Introduction: Rich Caruana ,  Alexandru Niculescu , Geoff Crew, and Alex Ksikes have done  a lot of empirical testing  which shows that  using all methods to make a prediction  is more powerful than using any single method.  This is in rough agreement with the Bayesian way of solving problems, but based upon a different (essentially empirical) motivation.  A rough summary is:
  
 Take all of {decision trees, boosted decision trees, bagged decision trees, boosted decision stumps, K nearest neighbors, neural networks, SVM} with all reasonable parameter settings. 
 Run the methods on each problem of 8 problems with a large test set, calibrating margins using either  sigmoid fitting  or  isotonic regression . 
 For each loss of {accuracy, area under the ROC curve, cross entropy, squared error, etc…} evaluate the average performance of the method. 
  
A series of conclusions can be drawn from the observations.
  
 ( Calibrated ) boosted decision trees appear to perform best, in general although support v</p><p>6 0.78366011 <a title="177-lda-6" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>7 0.78296816 <a title="177-lda-7" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>8 0.78232658 <a title="177-lda-8" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>9 0.78156781 <a title="177-lda-9" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>10 0.78117847 <a title="177-lda-10" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>11 0.77971631 <a title="177-lda-11" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>12 0.77924812 <a title="177-lda-12" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>13 0.77903759 <a title="177-lda-13" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>14 0.77881944 <a title="177-lda-14" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>15 0.77792025 <a title="177-lda-15" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>16 0.77692795 <a title="177-lda-16" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>17 0.77639467 <a title="177-lda-17" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>18 0.77502644 <a title="177-lda-18" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>19 0.77498525 <a title="177-lda-19" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>20 0.77487785 <a title="177-lda-20" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
