<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>212 hunch net-2006-10-04-Health of Conferences Wiki</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-212" href="#">hunch_net-2006-212</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>212 hunch net-2006-10-04-Health of Conferences Wiki</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-212-html" href="http://hunch.net/?p=232">html</a></p><p>Introduction: Aaron Hertzmannpoints out thehealth of conferences wiki, which has a great
deal of information about how many different conferences function.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('aaron', 0.582), ('wiki', 0.509), ('conferences', 0.449), ('deal', 0.238), ('function', 0.23), ('great', 0.179), ('information', 0.174), ('different', 0.15), ('many', 0.075)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="212-tfidf-1" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>Introduction: Aaron Hertzmannpoints out thehealth of conferences wiki, which has a great
deal of information about how many different conferences function.</p><p>2 0.14334257 <a title="212-tfidf-2" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>Introduction: At thelast ICML,Tom Dietterichasked me to look into systems for commenting on
papers. I've been slow getting to this, but it's relevant now.The essential
observation is that we now have many tools for online collaboration, but they
are not yet much used in academic research. If we can find the right way to
use them, then perhaps great things might happen, with extra kudos to the
first conference that manages to really create an online community. Various
conferences have been poking at this. For example,UAI has setup a wiki, COLT
hasstarted usingJoomla, with some dynamic content, and AAAI has been setting
up a "student blog". Similarly,Dinoj Surendransetup a twiki for theChicago
Machine Learning Summer School, which was quite useful for coordinating events
and other things.I believe the most important thing is a willingness to
experiment. A good place to start seems to be enhancing existing conference
websites. For example, theICML 2007 papers pageis basically only useful via
grep. A mu</p><p>3 0.14084029 <a title="212-tfidf-3" href="../hunch_net-2005/hunch_net-2005-06-13-Wikis_for_Summer_Schools_and_Workshops.html">81 hunch net-2005-06-13-Wikis for Summer Schools and Workshops</a></p>
<p>Introduction: Chicago '05ended a couple of weeks ago. This was the sixthMachine Learning
Summer School, and the second one that used awiki. (The first was Berder '04,
thanks to Gunnar Raetsch.) Wikis are relatively easy to set up, greatly aid
social interaction, and should be used a lot more at summer schools and
workshops. They can even be used as the meeting's webpage, as a permanent
record of its participants' collaborations -- see for example the wiki/website
for last year'sNVO Summer School.A basic wiki is a collection of editable
webpages, maintained by software called awiki engine. The engine used at both
Berder and Chicago wasTikiWiki-- it is well documented and gets you something
running fast. It uses PHP and MySQL, but doesn't require you to know either.
Tikiwiki has far more features than most wikis, as it is really a fullContent
Management System. (My thanks to Sebastian Stark for pointing this out.) Here
are the features we found most useful:Bulletin boards, or forums. The most-
used on</p><p>4 0.13371225 <a title="212-tfidf-4" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<p>Introduction: This is an attempt to organize the broad research programs related to machine
learning currently underway. This isn't easy--this map is partial, the
categories often overlap, and there are many details left out. Nevertheless,
it is (perhaps) helpful to have some map of what is happening where. The word
'typical' should not be construed narrowly here.Learning TheoryFocuses on
analyzing mathematical models of learning, essentially no experiments. Typical
conference: COLT.Bayesian LearningBayes law is always used. Focus on methods
of speeding up or approximating integration, new probabilistic models, and
practical applications. Typical conferences: NIPS,UAIStructured
learningPredicting complex structured outputs, some applications. Typiical
conferences: NIPS, UAI, othersReinforcement LearningFocused on 'agent-in-the-
world' learning problems where the goal is optimizing reward. Typical
conferences: ICMLUnsupervised Learning/Clustering/Dimensionality
ReductionFocused on simpiflying data. T</p><p>5 0.12577121 <a title="212-tfidf-5" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>Introduction: Conferences exist as part of the process of doing research. They provide many
roles including "announcing research", "meeting people", and "point of
reference". Not all conferences are alike so a basic question is: "to what
extent do individual conferences attempt to aid research?" This question is
very difficult to answer in any satisfying way. What we can do is compare
details of the process across multiple conferences.CommentsThe average quality
of comments across conferences can vary dramatically. At one extreme, the
tradition in CS theory conferences is to provide essentially zero feedback. At
the other extreme, some conferences have a strong tradition of providing
detailed constructive feedback. Detailed feedback can give authors significant
guidance about how to improve research. This is the most subjective
entry.BlindVirtually all conferences offer single blind review where authors
do not know reviewers. Some also providedouble blindreview where reviewers do
not know authors. T</p><p>6 0.10422163 <a title="212-tfidf-6" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>7 0.10270453 <a title="212-tfidf-7" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>8 0.089339525 <a title="212-tfidf-8" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>9 0.081829876 <a title="212-tfidf-9" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>10 0.070714816 <a title="212-tfidf-10" href="../hunch_net-2011/hunch_net-2011-03-27-Vowpal_Wabbit%2C_v5.1.html">428 hunch net-2011-03-27-Vowpal Wabbit, v5.1</a></p>
<p>11 0.063745409 <a title="212-tfidf-11" href="../hunch_net-2008/hunch_net-2008-11-04-Rise_of_the_Machines.html">323 hunch net-2008-11-04-Rise of the Machines</a></p>
<p>12 0.063482247 <a title="212-tfidf-12" href="../hunch_net-2007/hunch_net-2007-07-13-The_View_From_China.html">255 hunch net-2007-07-13-The View From China</a></p>
<p>13 0.060755678 <a title="212-tfidf-13" href="../hunch_net-2006/hunch_net-2006-12-05-Recruitment_Conferences.html">222 hunch net-2006-12-05-Recruitment Conferences</a></p>
<p>14 0.060524482 <a title="212-tfidf-14" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>15 0.060304116 <a title="212-tfidf-15" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>16 0.060065255 <a title="212-tfidf-16" href="../hunch_net-2009/hunch_net-2009-11-06-Yisong_Yue_on_Self-improving_Systems.html">376 hunch net-2009-11-06-Yisong Yue on Self-improving Systems</a></p>
<p>17 0.054846976 <a title="212-tfidf-17" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>18 0.053614281 <a title="212-tfidf-18" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>19 0.053279404 <a title="212-tfidf-19" href="../hunch_net-2006/hunch_net-2006-07-12-Who_is_having_visa_problems_reaching_US_conferences%3F.html">195 hunch net-2006-07-12-Who is having visa problems reaching US conferences?</a></p>
<p>20 0.052149024 <a title="212-tfidf-20" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.078), (1, 0.043), (2, 0.014), (3, 0.021), (4, 0.03), (5, 0.008), (6, -0.044), (7, -0.004), (8, -0.038), (9, 0.063), (10, -0.051), (11, -0.058), (12, 0.016), (13, -0.018), (14, -0.013), (15, 0.014), (16, -0.012), (17, 0.129), (18, 0.004), (19, -0.079), (20, -0.003), (21, -0.061), (22, -0.077), (23, -0.073), (24, -0.028), (25, 0.097), (26, 0.071), (27, 0.033), (28, -0.059), (29, -0.214), (30, 0.125), (31, -0.048), (32, 0.069), (33, 0.068), (34, 0.03), (35, 0.035), (36, 0.044), (37, -0.037), (38, 0.069), (39, 0.03), (40, -0.006), (41, -0.029), (42, 0.081), (43, 0.041), (44, -0.024), (45, -0.117), (46, 0.004), (47, -0.007), (48, -0.103), (49, 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99100494 <a title="212-lsi-1" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>Introduction: Aaron Hertzmannpoints out thehealth of conferences wiki, which has a great
deal of information about how many different conferences function.</p><p>2 0.57597059 <a title="212-lsi-2" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<p>Introduction: This is an attempt to organize the broad research programs related to machine
learning currently underway. This isn't easy--this map is partial, the
categories often overlap, and there are many details left out. Nevertheless,
it is (perhaps) helpful to have some map of what is happening where. The word
'typical' should not be construed narrowly here.Learning TheoryFocuses on
analyzing mathematical models of learning, essentially no experiments. Typical
conference: COLT.Bayesian LearningBayes law is always used. Focus on methods
of speeding up or approximating integration, new probabilistic models, and
practical applications. Typical conferences: NIPS,UAIStructured
learningPredicting complex structured outputs, some applications. Typiical
conferences: NIPS, UAI, othersReinforcement LearningFocused on 'agent-in-the-
world' learning problems where the goal is optimizing reward. Typical
conferences: ICMLUnsupervised Learning/Clustering/Dimensionality
ReductionFocused on simpiflying data. T</p><p>3 0.53542042 <a title="212-lsi-3" href="../hunch_net-2008/hunch_net-2008-11-04-Rise_of_the_Machines.html">323 hunch net-2008-11-04-Rise of the Machines</a></p>
<p>Introduction: On theenduring topic of how people deal with intelligent machines, we have
this importantelection bulletin.</p><p>4 0.51719344 <a title="212-lsi-4" href="../hunch_net-2005/hunch_net-2005-07-13-%26%238220%3BSister_Conference%26%238221%3B_presentations.html">93 hunch net-2005-07-13-&#8220;Sister Conference&#8221; presentations</a></p>
<p>Introduction: Some of the "sister conference" presentations atAAAIhave been great. Roughly
speaking, the conference organizers asked other conference organizers to come
give a summary of their conference. Many different AI-related conferences
accepted. The presenters typically discuss some of the background and goals of
the conference then mention the results from a few papers they liked. This is
great because it provides a mechanism to get a digested overview of the work
of several thousand researchers--something which is simply available nowhere
else.Based on these presentations, it looks like there is a significant
component of (and opportunity for) applied machine learning inAIIDE,IUI,
andACL.There was also some discussion of having a super-colocation event
similar toFCRC, but centered on AI & Learning. This seems like a fine idea.
The field is fractured across so many different conferences that the mixing of
a supercolocation seems likely helpful for research.</p><p>5 0.47393841 <a title="212-lsi-5" href="../hunch_net-2007/hunch_net-2007-11-02-The_Machine_Learning_Award_goes_to_%26%238230%3B.html">270 hunch net-2007-11-02-The Machine Learning Award goes to &#8230;</a></p>
<p>Introduction: Perhaps the biggest CS prize for research is theTuring Award, which has a
$0.25M cash prize associated with it. It appears none of the prizes so far
have been for anything like machine learning (the closest are perhaps database
awards).In CS theory, there is theGÃƒÂ¶del Prizewhich is smaller and newer,
offering a $5K prize along and perhaps (more importantly) recognition. One
such award has been given for Machine Learning, toRobert SchapireandYoav
Freundfor Adaboost.In Machine Learning, there seems to be no equivalent of
these sorts of prizes. There are several plausible reasons for this:There is
no coherent community.People drift in and out of the central conferences all
the time. Most of the author names from 10 years ago do not occur in the
conferences of today. In addition, the entire subject area is fairly new.There
are at least a core group of people who have stayed around.Machine Learning
work doesn't lastAlmost every paper is forgotten, because {the goals change,
there isn't an</p><p>6 0.45477921 <a title="212-lsi-6" href="../hunch_net-2009/hunch_net-2009-11-06-Yisong_Yue_on_Self-improving_Systems.html">376 hunch net-2009-11-06-Yisong Yue on Self-improving Systems</a></p>
<p>7 0.43958837 <a title="212-lsi-7" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>8 0.40633643 <a title="212-lsi-8" href="../hunch_net-2007/hunch_net-2007-07-13-The_View_From_China.html">255 hunch net-2007-07-13-The View From China</a></p>
<p>9 0.39216587 <a title="212-lsi-9" href="../hunch_net-2006/hunch_net-2006-12-05-Recruitment_Conferences.html">222 hunch net-2006-12-05-Recruitment Conferences</a></p>
<p>10 0.39014062 <a title="212-lsi-10" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>11 0.37857345 <a title="212-lsi-11" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>12 0.37759298 <a title="212-lsi-12" href="../hunch_net-2007/hunch_net-2007-02-11-24.html">232 hunch net-2007-02-11-24</a></p>
<p>13 0.36996025 <a title="212-lsi-13" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<p>14 0.35685879 <a title="212-lsi-14" href="../hunch_net-2006/hunch_net-2006-01-06-MLTV.html">146 hunch net-2006-01-06-MLTV</a></p>
<p>15 0.34803504 <a title="212-lsi-15" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>16 0.34224954 <a title="212-lsi-16" href="../hunch_net-2006/hunch_net-2006-04-14-JMLR_is_a_success.html">172 hunch net-2006-04-14-JMLR is a success</a></p>
<p>17 0.33608812 <a title="212-lsi-17" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>18 0.32936081 <a title="212-lsi-18" href="../hunch_net-2009/hunch_net-2009-03-08-Prediction_Science.html">345 hunch net-2009-03-08-Prediction Science</a></p>
<p>19 0.31612921 <a title="212-lsi-19" href="../hunch_net-2005/hunch_net-2005-06-13-Wikis_for_Summer_Schools_and_Workshops.html">81 hunch net-2005-06-13-Wikis for Summer Schools and Workshops</a></p>
<p>20 0.31316337 <a title="212-lsi-20" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.295), (54, 0.432)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97529697 <a title="212-lda-1" href="../hunch_net-2007/hunch_net-2007-07-12-ICML_Trends.html">254 hunch net-2007-07-12-ICML Trends</a></p>
<p>Introduction: Mark Reiddid a post onICML trendsthat I found interesting.</p><p>2 0.93119484 <a title="212-lda-2" href="../hunch_net-2005/hunch_net-2005-01-26-Summer_Schools.html">4 hunch net-2005-01-26-Summer Schools</a></p>
<p>Introduction: There are several summer schools related to machine learning.We are running a
two weekmachine learning summer schoolin Chicago, USA May 16-27.IPAM is
running a more focused three week summer school onIntelligent Extraction of
Information from Graphs and High Dimensional Datain Los Angeles, USA July
11-29.A broad one-week school onanalysis of patternswill be held in Erice,
Italy, Oct. 28-Nov 6.</p><p>same-blog 3 0.85626686 <a title="212-lda-3" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>Introduction: Aaron Hertzmannpoints out thehealth of conferences wiki, which has a great
deal of information about how many different conferences function.</p><p>4 0.81619877 <a title="212-lda-4" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>Introduction: Here are a few papers fromCOLT 2008that I found interesting.Maria-Florina
Balcan,Steve Hanneke, andJenn Wortman,The True Sample Complexity of Active
Learning. This paper shows that in an asymptotic setting, active learning
isalwaysbetter than supervised learning (although the gap may be small). This
is evidence that the only thing in the way of universal active learning is us
knowing how to do it properly.Nir AilonandMehryar Mohri,An Efficient Reduction
of Ranking to Classification. This paper shows how to robustly ranknobjects
withn log(n)classifications using a quicksort based algorithm. The result is
applicable to many ranking loss functions and has implications for
others.Michael KearnsandJennifer Wortman.Learning from Collective Behavior.
This is about learning in a new model, where the goal is to predict how a
collection of interacting agents behave. One claim is that learning in this
setting can be reduced to IID learning.Due to the relation withMetric-E3, I
was particularly int</p><p>5 0.59999543 <a title="212-lda-5" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>Introduction: I want to try to describe what doing research means, especially from the point
of view of an undergraduate. The shift from a class-taking mentality to a
research mentality is very significant and not easy.Problem PosingPosing the
right problem is often as important as solving them. Many people can get by in
research by solving problems others have posed, but that's not sufficient for
really inspiring research. For learning in particular, there is a strong
feeling that we just haven't figured out which questions are the right ones to
ask. You can see this, because the answers we have do not seem
convincing.Gambling your lifeWhen you do research, you think very hard about
new ways of solving problems, new problems, and new solutions. Many
conversations are of the form "I wonder what would happen if…" These processes
can be short (days or weeks) or years-long endeavours. The worst part is that
you'll only know if you were succesful at the end of the process (and
sometimes not even then be</p><p>6 0.56321418 <a title="212-lda-6" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>7 0.56280756 <a title="212-lda-7" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>8 0.5627715 <a title="212-lda-8" href="../hunch_net-2012/hunch_net-2012-10-26-ML_Symposium_and_Strata-Hadoop_World.html">475 hunch net-2012-10-26-ML Symposium and Strata-Hadoop World</a></p>
<p>9 0.56261313 <a title="212-lda-9" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>10 0.56221455 <a title="212-lda-10" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>11 0.56215793 <a title="212-lda-11" href="../hunch_net-2006/hunch_net-2006-06-15-IJCAI_is_out_of_season.html">184 hunch net-2006-06-15-IJCAI is out of season</a></p>
<p>12 0.56183416 <a title="212-lda-12" href="../hunch_net-2005/hunch_net-2005-03-29-Academic_Mechanism_Design.html">48 hunch net-2005-03-29-Academic Mechanism Design</a></p>
<p>13 0.56084466 <a title="212-lda-13" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>14 0.56072623 <a title="212-lda-14" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>15 0.55616498 <a title="212-lda-15" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>16 0.55544543 <a title="212-lda-16" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>17 0.55052346 <a title="212-lda-17" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>18 0.54702485 <a title="212-lda-18" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>19 0.5447892 <a title="212-lda-19" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>20 0.54248744 <a title="212-lda-20" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
