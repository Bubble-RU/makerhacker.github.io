<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>216 hunch net-2006-11-02-2006 NIPS workshops</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-216" href="#">hunch_net-2006-216</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>216 hunch net-2006-11-02-2006 NIPS workshops</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-216-html" href="http://hunch.net/?p=236">html</a></p><p>Introduction: I expect the  NIPS 2006 workshops  to be quite interesting, and recommend going for anyone interested in machine learning research.  (Most or all of the workshops webpages can be found two links deep.)</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I expect the  NIPS 2006 workshops  to be quite interesting, and recommend going for anyone interested in machine learning research. [sent-1, score-1.851]
</p><p>2 (Most or all of the workshops webpages can be found two links deep. [sent-2, score-1.628]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('workshops', 0.492), ('webpages', 0.459), ('links', 0.382), ('recommend', 0.342), ('going', 0.213), ('anyone', 0.204), ('nips', 0.201), ('expect', 0.189), ('found', 0.182), ('interested', 0.173), ('interesting', 0.145), ('quite', 0.137), ('two', 0.113), ('machine', 0.072), ('learning', 0.029)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="216-tfidf-1" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect the  NIPS 2006 workshops  to be quite interesting, and recommend going for anyone interested in machine learning research.  (Most or all of the workshops webpages can be found two links deep.)</p><p>2 0.31949428 <a title="216-tfidf-2" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>Introduction: NIPS  is the big winter conference of learning.  
  
 Paper due date: June 3rd. (Tweaked thanks to  Fei Sha .) 
 Location: Vancouver (main program) Dec. 5-8 and Whistler (workshops) Dec 9-10, BC, Canada 
  
NIPS is larger than all of the other learning conferences, partly because itâ&euro;&trade;s the only one at that time of year.  I recommend the workshops which are often quite interesting and energetic.</p><p>3 0.30453128 <a title="216-tfidf-3" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>Introduction: Attendance at the  NIPS workshops  is highly recommended for both research and learning.   Unfortunately, there does not yet appear to be a public list of workshops. However, I found the following workshop webpages of interest:
  
  Machine Learning in Finance  
  Learning to Rank  
  Foundations of Active Learning  
  Machine Learning Based Robotics in Unstructured Environments  
  
There are  many  more workshops.  In fact, there are so many that it is not plausible anyone can attend every workshop they are interested in.  Maybe in future years the organizers can spread them out over more days to reduce overlap. 
 
Many of these workshops are accepting presentation proposals (due mid-October).</p><p>4 0.3034659 <a title="216-tfidf-4" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>Introduction: I’m the  workshops chair  for  ICML  this year.  As such, I would like to personally encourage people to consider running a workshop.
 
My general view of workshops is that they are excellent as opportunities to discuss and develop research directions—some of my best work has come from collaborations at workshops and several workshops have substantially altered my thinking about various problems.  My experience running workshops is that setting them up and making them fly often appears much harder than it actually is, and the workshops often come off much better than expected in the end.  Submissions are due January 18, two weeks before papers.
 
Similarly,  Ben Taskar  is looking for good  tutorials , which is complementary.  Workshops are about exploring a subject, while a tutorial is about distilling it down into an easily taught essence, a vital part of the research process.  Tutorials are due February 13, two weeks after papers.</p><p>5 0.29099491 <a title="216-tfidf-5" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">285 hunch net-2008-01-23-Why Workshop?</a></p>
<p>Introduction: I second the  call for workshops at ICML/COLT/UAI .
 
 Several   times   before , details of why and how to run a  workshop have been mentioned.  
 
There is a simple reason to prefer workshops here: attendance.  The Helsinki colocation has placed workshops  directly between ICML and COLT/UAI , which is optimal for getting attendees from any conference.  In addition,  last year ICML had relatively few workshops  and NIPS workshops were overloaded.  In addition to  those that happened  a similar number were rejected.  The overload has strange consequences—for example,  the best attended workshop  wasn’t an official NIPS workshop.  Aside from intrinsic interest, the Deep Learning workshop benefited greatly from being off schedule.</p><p>6 0.2887539 <a title="216-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>7 0.21028064 <a title="216-tfidf-7" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>8 0.19552737 <a title="216-tfidf-8" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>9 0.19402702 <a title="216-tfidf-9" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>10 0.17442963 <a title="216-tfidf-10" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>11 0.15604115 <a title="216-tfidf-11" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>12 0.145375 <a title="216-tfidf-12" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>13 0.1430911 <a title="216-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-08-Some_Links.html">15 hunch net-2005-02-08-Some Links</a></p>
<p>14 0.1419742 <a title="216-tfidf-14" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>15 0.11268234 <a title="216-tfidf-15" href="../hunch_net-2007/hunch_net-2007-04-21-Videolectures.net.html">240 hunch net-2007-04-21-Videolectures.net</a></p>
<p>16 0.10891369 <a title="216-tfidf-16" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>17 0.10051668 <a title="216-tfidf-17" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>18 0.099438258 <a title="216-tfidf-18" href="../hunch_net-2005/hunch_net-2005-09-06-A_link.html">108 hunch net-2005-09-06-A link</a></p>
<p>19 0.092547625 <a title="216-tfidf-19" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>20 0.090379246 <a title="216-tfidf-20" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.106), (1, -0.159), (2, -0.168), (3, -0.206), (4, 0.038), (5, 0.298), (6, 0.244), (7, 0.079), (8, 0.15), (9, 0.144), (10, -0.045), (11, 0.097), (12, -0.04), (13, -0.099), (14, -0.028), (15, 0.016), (16, -0.05), (17, -0.079), (18, 0.181), (19, -0.003), (20, 0.088), (21, 0.095), (22, -0.038), (23, -0.081), (24, -0.018), (25, -0.108), (26, -0.064), (27, 0.058), (28, 0.064), (29, 0.047), (30, -0.042), (31, -0.01), (32, -0.019), (33, 0.066), (34, -0.012), (35, 0.089), (36, -0.025), (37, 0.057), (38, -0.008), (39, -0.069), (40, 0.005), (41, 0.015), (42, -0.038), (43, 0.052), (44, 0.036), (45, -0.002), (46, 0.004), (47, -0.067), (48, 0.054), (49, 0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98624438 <a title="216-lsi-1" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect the  NIPS 2006 workshops  to be quite interesting, and recommend going for anyone interested in machine learning research.  (Most or all of the workshops webpages can be found two links deep.)</p><p>2 0.84519553 <a title="216-lsi-2" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>Introduction: NIPS  is the big winter conference of learning.  
  
 Paper due date: June 3rd. (Tweaked thanks to  Fei Sha .) 
 Location: Vancouver (main program) Dec. 5-8 and Whistler (workshops) Dec 9-10, BC, Canada 
  
NIPS is larger than all of the other learning conferences, partly because itâ&euro;&trade;s the only one at that time of year.  I recommend the workshops which are often quite interesting and energetic.</p><p>3 0.82599193 <a title="216-lsi-3" href="../hunch_net-2008/hunch_net-2008-01-23-Why_Workshop%3F.html">285 hunch net-2008-01-23-Why Workshop?</a></p>
<p>Introduction: I second the  call for workshops at ICML/COLT/UAI .
 
 Several   times   before , details of why and how to run a  workshop have been mentioned.  
 
There is a simple reason to prefer workshops here: attendance.  The Helsinki colocation has placed workshops  directly between ICML and COLT/UAI , which is optimal for getting attendees from any conference.  In addition,  last year ICML had relatively few workshops  and NIPS workshops were overloaded.  In addition to  those that happened  a similar number were rejected.  The overload has strange consequences—for example,  the best attended workshop  wasn’t an official NIPS workshop.  Aside from intrinsic interest, the Deep Learning workshop benefited greatly from being off schedule.</p><p>4 0.82044756 <a title="216-lsi-4" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>Introduction: I’m the  workshops chair  for  ICML  this year.  As such, I would like to personally encourage people to consider running a workshop.
 
My general view of workshops is that they are excellent as opportunities to discuss and develop research directions—some of my best work has come from collaborations at workshops and several workshops have substantially altered my thinking about various problems.  My experience running workshops is that setting them up and making them fly often appears much harder than it actually is, and the workshops often come off much better than expected in the end.  Submissions are due January 18, two weeks before papers.
 
Similarly,  Ben Taskar  is looking for good  tutorials , which is complementary.  Workshops are about exploring a subject, while a tutorial is about distilling it down into an easily taught essence, a vital part of the research process.  Tutorials are due February 13, two weeks after papers.</p><p>5 0.77700627 <a title="216-lsi-5" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>Introduction: A good workshop is often far more interesting than the papers at a conference.  This happens because a workshop has a much tighter focus than a conference.  Since you choose the workshops fitting your interest, the increased relevance can greatly enhance the level of your interest and attention.  Roughly speaking, a workshop program consists of elements related to a subject of your interest.  The main conference program consists of elements related to someoneâ&euro;&trade;s interest (which is rarely your own).  Workshops are more about doing research while conferences are more about presenting research.  
 
Several conferences have associated workshop programs, some with deadlines due shortly.
  
 
  ICML workshops  
 Due April 1 
 
 
  IJCAI workshops  
 Deadlines Vary 
 
 
 KDD workshops 
 Not yet finalized 
 
  
Anyone going to these conferences should examine the workshops and see if any are of interest.  (If none are, then maybe you should organize one next year.)</p><p>6 0.74665123 <a title="216-lsi-6" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>7 0.71652085 <a title="216-lsi-7" href="../hunch_net-2007/hunch_net-2007-09-30-NIPS_workshops_are_out..html">264 hunch net-2007-09-30-NIPS workshops are out.</a></p>
<p>8 0.69892454 <a title="216-lsi-8" href="../hunch_net-2005/hunch_net-2005-09-19-NIPS_Workshops.html">113 hunch net-2005-09-19-NIPS Workshops</a></p>
<p>9 0.58157104 <a title="216-lsi-9" href="../hunch_net-2013/hunch_net-2013-08-31-Extreme_Classification_workshop_at_NIPS.html">488 hunch net-2013-08-31-Extreme Classification workshop at NIPS</a></p>
<p>10 0.49124599 <a title="216-lsi-10" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>11 0.48651755 <a title="216-lsi-11" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>12 0.47435912 <a title="216-lsi-12" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>13 0.44440606 <a title="216-lsi-13" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>14 0.41335288 <a title="216-lsi-14" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>15 0.40612012 <a title="216-lsi-15" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>16 0.37946934 <a title="216-lsi-16" href="../hunch_net-2005/hunch_net-2005-02-08-Some_Links.html">15 hunch net-2005-02-08-Some Links</a></p>
<p>17 0.3420732 <a title="216-lsi-17" href="../hunch_net-2006/hunch_net-2006-12-05-Recruitment_Conferences.html">222 hunch net-2006-12-05-Recruitment Conferences</a></p>
<p>18 0.33484137 <a title="216-lsi-18" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<p>19 0.33400863 <a title="216-lsi-19" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>20 0.31589165 <a title="216-lsi-20" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.325), (55, 0.298), (95, 0.154)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92537344 <a title="216-lda-1" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>Introduction: I expect the  NIPS 2006 workshops  to be quite interesting, and recommend going for anyone interested in machine learning research.  (Most or all of the workshops webpages can be found two links deep.)</p><p>2 0.8284539 <a title="216-lda-2" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>Introduction: Registration for COLT 2007 is now open.
 
The conference will take place on 13-15 June, 2007, in San Diego, California, as part of the 2007 Federated Computing Research Conference (FCRC), which includes STOC, Complexity, and EC.
 
The website for COLT: http://www.learningtheory.org/colt2007/index.html
 
The early registration deadline is May 11, and the cutoff date for discounted hotel rates is May 9.
 
Before registering, take note that the fees are substantially lower for members of ACM and/or SIGACT than for nonmembers. If youâ&euro;&trade;ve been contemplating joining either of these two societies (annual dues: $99 for ACM, $18 for SIGACT), now would be a good time!</p><p>3 0.66691285 <a title="216-lda-3" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>Introduction: This post is a (near) transcript of a talk that I gave at the  ICML 2013 Workshop on Peer Review and Publishing Models . Although there’s a  PDF available on my website , I’ve chosen to post a slightly modified version here as well in order to better facilitate discussion.
 
 Disclaimers and Context 
 
I want to start with a couple of disclaimers and some context.
 
First, I want to point out that although I’ve read a lot about double-blind review, this isn’t my research area and the research discussed in this post is not my own. As a result, I probably can’t answer super detailed questions about these studies.
 
I also want to note that I’m not opposed to open peer review — I was a free and open source software developer for over ten years and I care a great deal about openness and transparency. Rather, my motivation in writing this post is simply to create awareness of and to initiate discussion about the benefits of double-blind review.
 
Lastly, and most importantly, I think it’s e</p><p>4 0.65181822 <a title="216-lda-4" href="../hunch_net-2007/hunch_net-2007-07-13-The_View_From_China.html">255 hunch net-2007-07-13-The View From China</a></p>
<p>Introduction: I’m visiting Beijing for the  Pao-Lu Hsu Statistics Conference  on Machine Learning.
 
I had several discussions about the state of Chinese research.  Given the large population and economy, you might expect substantial research—more than has been observed at international conferences.  The fundamental problem seems to be the  Cultural Revolution  which  lobotimized higher education, and the research associated with it.  There has been a process of slow recovery since then, which has begun to be felt in the research world via increased participation in international conferences and (now) conferences in China.
 
The amount of effort going into construction in Beijing is very impressive—people are literally building a skyscraper at night outside the window of the hotel I’m staying at (and this is not unusual).  If a small fraction of this effort is later focused onto supporting research, the effect could be very substantial.  General growth in China’s research portfolio should be expecte</p><p>5 0.65016097 <a title="216-lda-5" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>Introduction: The  New York Machine Learning Symposium  is October 19 with a 2 page abstract deadline due September 13 via email with subject “Machine Learning Poster Submission” sent to physicalscience@nyas.org.  Everyone is welcome to submit.  Last year’s attendance was 246 and I expect more this year.
 
The primary experiment for  ICML 2013  is multiple paper submission deadlines with rolling review cycles.  The key dates are October 1, December 15, and February 15.  This is an attempt to shift ICML further towards a journal style review process and reduce peak load.   The “not for proceedings” experiment from this year’s ICML is not continuing.
 
Edit: Fixed second ICML deadline.</p><p>6 0.64349055 <a title="216-lda-6" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>7 0.63799816 <a title="216-lda-7" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>8 0.63799816 <a title="216-lda-8" href="../hunch_net-2012/hunch_net-2012-05-12-ICML_accepted_papers_and_early_registration.html">465 hunch net-2012-05-12-ICML accepted papers and early registration</a></p>
<p>9 0.61284471 <a title="216-lda-9" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>10 0.61217928 <a title="216-lda-10" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>11 0.6117996 <a title="216-lda-11" href="../hunch_net-2011/hunch_net-2011-10-03-Monday_announcements.html">446 hunch net-2011-10-03-Monday announcements</a></p>
<p>12 0.61161256 <a title="216-lda-12" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>13 0.60142416 <a title="216-lda-13" href="../hunch_net-2005/hunch_net-2005-02-15-ESPgame_and_image_labeling.html">20 hunch net-2005-02-15-ESPgame and image labeling</a></p>
<p>14 0.58520347 <a title="216-lda-14" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>15 0.58420128 <a title="216-lda-15" href="../hunch_net-2011/hunch_net-2011-04-23-ICML_workshops_due.html">433 hunch net-2011-04-23-ICML workshops due</a></p>
<p>16 0.58377784 <a title="216-lda-16" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>17 0.56587237 <a title="216-lda-17" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>18 0.56142509 <a title="216-lda-18" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>19 0.55875516 <a title="216-lda-19" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>20 0.55502903 <a title="216-lda-20" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
