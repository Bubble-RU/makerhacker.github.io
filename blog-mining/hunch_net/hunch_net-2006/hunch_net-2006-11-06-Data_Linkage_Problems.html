<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>217 hunch net-2006-11-06-Data Linkage Problems</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-217" href="#">hunch_net-2006-217</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>217 hunch net-2006-11-06-Data Linkage Problems</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-217-html" href="http://hunch.net/?p=237">html</a></p><p>Introduction: Data linkage is a problem which seems to come up in various applied machine learning problems.  I have heard it mentioned in various data mining contexts, but it seems relatively less studied for systemic reasons.
 
A very simple version of the data linkage problem is a cross hospital patient record merge.  Suppose a patient (John Doe) is admitted to a hospital (General Health), treated, and released.  Later, John Doe is admitted to a second hospital (Health General), treated, and released.  Given a large number of records of this sort, it becomes very tempting to try and predict the outcomes of treatments.  This is reasonably straightforward as a machine learning problem if there is a shared unique identifier for John Doe used by General Health and Health General along with time stamps.  We can merge the records and create examples of the form “Given symptoms and treatment, did the patient come back to a hospital within the next year?”  These examples could be fed into a learning algo</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Data linkage is a problem which seems to come up in various applied machine learning problems. [sent-1, score-0.544]
</p><p>2 A very simple version of the data linkage problem is a cross hospital patient record merge. [sent-3, score-1.24]
</p><p>3 Suppose a patient (John Doe) is admitted to a hospital (General Health), treated, and released. [sent-4, score-0.574]
</p><p>4 Later, John Doe is admitted to a second hospital (Health General), treated, and released. [sent-5, score-0.402]
</p><p>5 Given a large number of records of this sort, it becomes very tempting to try and predict the outcomes of treatments. [sent-6, score-0.509]
</p><p>6 This is reasonably straightforward as a machine learning problem if there is a shared unique identifier for John Doe used by General Health and Health General along with time stamps. [sent-7, score-0.419]
</p><p>7 We can merge the records and create examples of the form “Given symptoms and treatment, did the patient come back to a hospital within the next year? [sent-8, score-0.676]
</p><p>8 ”  These examples could be fed into a learning algorithm, and we could attempt to predict whether a return occurs. [sent-9, score-0.238]
</p><p>9 The problem is that General Health and Health General don’t have any shared unique identifier for John Doe. [sent-10, score-0.419]
</p><p>10 Although this is just one example, data linkage problems seem to be endemic to learning applications. [sent-13, score-0.567]
</p><p>11 Sometimes minor changes to what information is recorded can strongly disambiguate. [sent-15, score-0.164]
</p><p>12 For example, there is a big difference between recording the pages visited at a website versus tracking the sequence of pages visited. [sent-16, score-0.292]
</p><p>13 The essential thing to think about when designing the information to record is: How will I track the consequences of decisions? [sent-17, score-0.243]
</p><p>14 First predict which records should be linked, based upon a smaller dataset that is hand checked. [sent-19, score-0.401]
</p><p>15 A common approach to improving performance is turning a double approximation (given x predict y, given y predict z) into a single approximation (given x predict z). [sent-29, score-0.982]
</p><p>16 A method for achieving single approximation here is tricky because we have ancillary information about the intermediate prediction. [sent-30, score-0.455]
</p><p>17 The Bayesian approach of “specify a prior, then use Bayes law to get a posterior, then predict with the posterior” is attractive here because we often have strong prior beliefs about at least the linkage portion of the problem. [sent-32, score-0.785]
</p><p>18 The data linkage problem also makes very clear the tension between privacy and machine learning. [sent-34, score-0.677]
</p><p>19 And yet, linking records can result in unexpectedly large pools of information on individuals. [sent-36, score-0.381]
</p><p>20 Furthermore explicitly sensitive information (like credit card numbers) might easily be the most useful bit of information for linkage. [sent-37, score-0.39]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('linkage', 0.488), ('hospital', 0.287), ('health', 0.263), ('records', 0.217), ('doe', 0.209), ('predict', 0.184), ('patient', 0.172), ('information', 0.164), ('link', 0.144), ('identifier', 0.139), ('john', 0.131), ('unique', 0.125), ('approximation', 0.118), ('admitted', 0.115), ('treated', 0.115), ('outcomes', 0.108), ('general', 0.099), ('shared', 0.099), ('posterior', 0.088), ('pages', 0.088), ('given', 0.086), ('data', 0.079), ('cross', 0.079), ('record', 0.079), ('improved', 0.07), ('intermediate', 0.062), ('card', 0.062), ('recording', 0.062), ('customized', 0.062), ('verified', 0.062), ('predictor', 0.059), ('systemic', 0.057), ('birthday', 0.057), ('representing', 0.057), ('stage', 0.057), ('attractive', 0.057), ('ancillary', 0.057), ('index', 0.057), ('linked', 0.057), ('treatments', 0.057), ('problem', 0.056), ('prior', 0.056), ('single', 0.054), ('suggestion', 0.054), ('tension', 0.054), ('versus', 0.054), ('jump', 0.054), ('fed', 0.054), ('contexts', 0.054), ('turning', 0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="217-tfidf-1" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>Introduction: Data linkage is a problem which seems to come up in various applied machine learning problems.  I have heard it mentioned in various data mining contexts, but it seems relatively less studied for systemic reasons.
 
A very simple version of the data linkage problem is a cross hospital patient record merge.  Suppose a patient (John Doe) is admitted to a hospital (General Health), treated, and released.  Later, John Doe is admitted to a second hospital (Health General), treated, and released.  Given a large number of records of this sort, it becomes very tempting to try and predict the outcomes of treatments.  This is reasonably straightforward as a machine learning problem if there is a shared unique identifier for John Doe used by General Health and Health General along with time stamps.  We can merge the records and create examples of the form “Given symptoms and treatment, did the patient come back to a hospital within the next year?”  These examples could be fed into a learning algo</p><p>2 0.18895254 <a title="217-tfidf-2" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: The  Heritage Health Prize  is potentially the largest prediction prize yet at $3M, which is sure to get many people interested.  Several elements of the competition may be worth discussing.
  
 The most straightforward way for HPN to deploy this predictor is in determining who to cover with insurance.  This might easily cover the costs of running the contest itself, but the value to the health system of a whole is minimal, as people not covered still exist.  While HPN itself is a provider network, they have active relationships with a number of insurance companies, and the right to resell any entrant.  It’s worth keeping in mind that the research and development may nevertheless end up being useful in the longer term, especially as entrants also keep the right to their code. 
 The  judging metric  is something I haven’t seen previously.  If a patient has probability 0.5 of being in the hospital 0 days and probability 0.5 of being in the hospital ~53.6 days, the optimal prediction in e</p><p>3 0.1554908 <a title="217-tfidf-3" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>Introduction: An argument is sometimes made that the Bayesian way is the “right” way to do machine learning.  This is a serious argument which deserves a serious reply.  The approximation argument is a serious reply for which I have not yet seen a reply 2 .
 
The idea for the Bayesian approach is quite simple, elegant, and general.  Essentially, you first specify a prior  P(D)  over possible processes  D  producing the data, observe the data, then condition on the data according to Bayes law to construct a posterior:   P(D|x) = P(x|D)P(D)/P(x)   
After this, hard decisions are made (such as “turn left” or “turn right”) by choosing the one which minimizes the expected (with respect to the posterior) loss.
 
This basic idea is reused thousands of times with various choices of  P(D)  and loss functions which is unsurprising given the many nice properties:
  
 There is an extremely strong associated guarantee: If the actual distribution generating the data is drawn from  P(D)  there is no better method.</p><p>4 0.11637949 <a title="217-tfidf-4" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>Introduction: Machine learning has a new kind of “scaling to larger problems” to worry about: scaling with the amount of contextual information.  The standard development path for a machine learning application in practice seems to be the following:
  
  Marginal . In the beginning, there was “majority vote”.  At this stage, it isn’t necessary to understand that you have a prediction problem.  People just realize that one answer is right sometimes and another answer other times.  In machine learning terms, this corresponds to making a prediction without side information. 
  First context . A clever person realizes that some bit of information  x 1   could be helpful.  If  x 1   is discrete, they condition on it and make a predictor  h(x 1 ) , typically by counting.  If they are clever, then they also do some smoothing.  If  x 1   is some real valued parameter, it’s very common to make a threshold cutoff.  Often, these tasks are simply done by hand. 
  Second . Another clever person (or perhaps the s</p><p>5 0.11438876 <a title="217-tfidf-5" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>Introduction: Aaron Hertzmann  points out the  health of conferences wiki , which has a great deal of information about how many different conferences function.</p><p>6 0.11222901 <a title="217-tfidf-6" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>7 0.10172231 <a title="217-tfidf-7" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>8 0.10124215 <a title="217-tfidf-8" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>9 0.10109858 <a title="217-tfidf-9" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>10 0.096520014 <a title="217-tfidf-10" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>11 0.09627381 <a title="217-tfidf-11" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>12 0.093401454 <a title="217-tfidf-12" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>13 0.085647956 <a title="217-tfidf-13" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>14 0.085383162 <a title="217-tfidf-14" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>15 0.084387735 <a title="217-tfidf-15" href="../hunch_net-2010/hunch_net-2010-09-21-Regretting_the_dead.html">411 hunch net-2010-09-21-Regretting the dead</a></p>
<p>16 0.078903452 <a title="217-tfidf-16" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>17 0.07659965 <a title="217-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>18 0.076444283 <a title="217-tfidf-18" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>19 0.075362727 <a title="217-tfidf-19" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>20 0.073674269 <a title="217-tfidf-20" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.19), (1, 0.065), (2, -0.026), (3, 0.013), (4, 0.004), (5, -0.021), (6, -0.032), (7, 0.048), (8, 0.081), (9, -0.08), (10, -0.086), (11, 0.055), (12, 0.017), (13, 0.024), (14, -0.008), (15, -0.08), (16, -0.034), (17, -0.028), (18, 0.044), (19, 0.014), (20, -0.027), (21, -0.04), (22, 0.109), (23, -0.009), (24, -0.049), (25, 0.04), (26, 0.056), (27, 0.119), (28, 0.002), (29, 0.007), (30, -0.02), (31, -0.063), (32, -0.005), (33, -0.03), (34, 0.026), (35, -0.004), (36, 0.005), (37, -0.001), (38, -0.105), (39, 0.036), (40, 0.03), (41, 0.05), (42, 0.043), (43, 0.027), (44, -0.074), (45, -0.018), (46, 0.001), (47, -0.077), (48, 0.01), (49, -0.119)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95010155 <a title="217-lsi-1" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>Introduction: Data linkage is a problem which seems to come up in various applied machine learning problems.  I have heard it mentioned in various data mining contexts, but it seems relatively less studied for systemic reasons.
 
A very simple version of the data linkage problem is a cross hospital patient record merge.  Suppose a patient (John Doe) is admitted to a hospital (General Health), treated, and released.  Later, John Doe is admitted to a second hospital (Health General), treated, and released.  Given a large number of records of this sort, it becomes very tempting to try and predict the outcomes of treatments.  This is reasonably straightforward as a machine learning problem if there is a shared unique identifier for John Doe used by General Health and Health General along with time stamps.  We can merge the records and create examples of the form “Given symptoms and treatment, did the patient come back to a hospital within the next year?”  These examples could be fed into a learning algo</p><p>2 0.68475592 <a title="217-lsi-2" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>Introduction: An argument is sometimes made that the Bayesian way is the “right” way to do machine learning.  This is a serious argument which deserves a serious reply.  The approximation argument is a serious reply for which I have not yet seen a reply 2 .
 
The idea for the Bayesian approach is quite simple, elegant, and general.  Essentially, you first specify a prior  P(D)  over possible processes  D  producing the data, observe the data, then condition on the data according to Bayes law to construct a posterior:   P(D|x) = P(x|D)P(D)/P(x)   
After this, hard decisions are made (such as “turn left” or “turn right”) by choosing the one which minimizes the expected (with respect to the posterior) loss.
 
This basic idea is reused thousands of times with various choices of  P(D)  and loss functions which is unsurprising given the many nice properties:
  
 There is an extremely strong associated guarantee: If the actual distribution generating the data is drawn from  P(D)  there is no better method.</p><p>3 0.68275607 <a title="217-lsi-3" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>Introduction: Machine learning has a new kind of “scaling to larger problems” to worry about: scaling with the amount of contextual information.  The standard development path for a machine learning application in practice seems to be the following:
  
  Marginal . In the beginning, there was “majority vote”.  At this stage, it isn’t necessary to understand that you have a prediction problem.  People just realize that one answer is right sometimes and another answer other times.  In machine learning terms, this corresponds to making a prediction without side information. 
  First context . A clever person realizes that some bit of information  x 1   could be helpful.  If  x 1   is discrete, they condition on it and make a predictor  h(x 1 ) , typically by counting.  If they are clever, then they also do some smoothing.  If  x 1   is some real valued parameter, it’s very common to make a threshold cutoff.  Often, these tasks are simply done by hand. 
  Second . Another clever person (or perhaps the s</p><p>4 0.65429246 <a title="217-lsi-4" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: The  Heritage Health Prize  is potentially the largest prediction prize yet at $3M, which is sure to get many people interested.  Several elements of the competition may be worth discussing.
  
 The most straightforward way for HPN to deploy this predictor is in determining who to cover with insurance.  This might easily cover the costs of running the contest itself, but the value to the health system of a whole is minimal, as people not covered still exist.  While HPN itself is a provider network, they have active relationships with a number of insurance companies, and the right to resell any entrant.  It’s worth keeping in mind that the research and development may nevertheless end up being useful in the longer term, especially as entrants also keep the right to their code. 
 The  judging metric  is something I haven’t seen previously.  If a patient has probability 0.5 of being in the hospital 0 days and probability 0.5 of being in the hospital ~53.6 days, the optimal prediction in e</p><p>5 0.64588386 <a title="217-lsi-5" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>Introduction: Machine Learning is rising in importance because data is being collected for all sorts of tasks where it either wasn’t previously collected, or for tasks that did not previously exist.  While this is great for Machine Learning, it has a downside—the massive data collection which is so useful can also lead to substantial privacy problems.  
 
It’s important to understand that this is a much harder problem than many people appreciate.  The  AOL   data   release  is a good example.  To those doing machine learning, the following strategies might be obvious:
  
 Just delete any names or other obviously personally identifiable information.  The logic here seems to be “if I can’t easily find the person then no one can”.  That doesn’t work as demonstrated by the people who were found circumstantially from the AOL data. 
 … then just hash all the search terms!  The logic here is “if I can’t read it, then no one can”.  It’s also trivially broken by a dictionary attack—just hash all the strings</p><p>6 0.64186931 <a title="217-lsi-6" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>7 0.58597577 <a title="217-lsi-7" href="../hunch_net-2006/hunch_net-2006-01-23-On_Coding_via_Mutual_Information_%26%23038%3B_Bayes_Nets.html">150 hunch net-2006-01-23-On Coding via Mutual Information &#038; Bayes Nets</a></p>
<p>8 0.57638747 <a title="217-lsi-8" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>9 0.57581383 <a title="217-lsi-9" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>10 0.56310284 <a title="217-lsi-10" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>11 0.55586183 <a title="217-lsi-11" href="../hunch_net-2008/hunch_net-2008-08-04-Electoralmarkets.com.html">312 hunch net-2008-08-04-Electoralmarkets.com</a></p>
<p>12 0.55337304 <a title="217-lsi-12" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>13 0.54350775 <a title="217-lsi-13" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>14 0.5324325 <a title="217-lsi-14" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>15 0.52775538 <a title="217-lsi-15" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>16 0.52060568 <a title="217-lsi-16" href="../hunch_net-2008/hunch_net-2008-04-26-Eliminating_the_Birthday_Paradox_for_Universal_Features.html">298 hunch net-2008-04-26-Eliminating the Birthday Paradox for Universal Features</a></p>
<p>17 0.51470703 <a title="217-lsi-17" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>18 0.51341087 <a title="217-lsi-18" href="../hunch_net-2006/hunch_net-2006-07-08-MaxEnt_contradicts_Bayes_Rule%3F.html">191 hunch net-2006-07-08-MaxEnt contradicts Bayes Rule?</a></p>
<p>19 0.51301736 <a title="217-lsi-19" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>20 0.51266605 <a title="217-lsi-20" href="../hunch_net-2007/hunch_net-2007-12-12-Workshop_Summary%26%238212%3BPrinciples_of_Learning_Problem_Design.html">277 hunch net-2007-12-12-Workshop Summary&#8212;Principles of Learning Problem Design</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.022), (10, 0.024), (13, 0.024), (27, 0.21), (38, 0.055), (53, 0.021), (55, 0.063), (74, 0.309), (77, 0.034), (84, 0.027), (94, 0.091), (95, 0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.92490023 <a title="217-lda-1" href="../hunch_net-2007/hunch_net-2007-12-17-New_Machine_Learning_mailing_list.html">278 hunch net-2007-12-17-New Machine Learning mailing list</a></p>
<p>Introduction: IMLS  (which is the nonprofit running ICML) has setup a new mailing list for  Machine Learning News .  The list address is ML-news@googlegroups.com, and signup requires a google account (which you can create).  Only members can send messages.</p><p>2 0.89187032 <a title="217-lda-2" href="../hunch_net-2010/hunch_net-2010-08-20-The_Workshop_on_Cores%2C_Clusters%2C_and_Clouds.html">404 hunch net-2010-08-20-The Workshop on Cores, Clusters, and Clouds</a></p>
<p>Introduction: Alekh ,  John ,  Ofer , and I are organizing a  workshop  at  NIPS  this year on learning in parallel and distributed environments.  The general interest level in parallel learning seems to be growing rapidly, so I expect quite a bit of attendance.  Please join us if you are parallel-interested.
 
And, if you are working in the area of parallel learning, please consider  submitting an abstract  due Oct. 17 for presentation at the workshop.</p><p>same-blog 3 0.85976237 <a title="217-lda-3" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>Introduction: Data linkage is a problem which seems to come up in various applied machine learning problems.  I have heard it mentioned in various data mining contexts, but it seems relatively less studied for systemic reasons.
 
A very simple version of the data linkage problem is a cross hospital patient record merge.  Suppose a patient (John Doe) is admitted to a hospital (General Health), treated, and released.  Later, John Doe is admitted to a second hospital (Health General), treated, and released.  Given a large number of records of this sort, it becomes very tempting to try and predict the outcomes of treatments.  This is reasonably straightforward as a machine learning problem if there is a shared unique identifier for John Doe used by General Health and Health General along with time stamps.  We can merge the records and create examples of the form “Given symptoms and treatment, did the patient come back to a hospital within the next year?”  These examples could be fed into a learning algo</p><p>4 0.71359909 <a title="217-lda-4" href="../hunch_net-2005/hunch_net-2005-05-06-Don%26%238217%3Bt_mix_the_solution_into_the_problem.html">67 hunch net-2005-05-06-Don&#8217;t mix the solution into the problem</a></p>
<p>Introduction: A common defect of many pieces of research is defining the problem in terms of the solution.  Here are some examples in learning:
  
 “The learning problem is finding a good seperating hyperplane.” 
 “The goal of learning is to minimize  (y-p) 2  + C w 2   where  y  = the observation,  p  = the prediction and  w  = a parameter vector.” 
 Defining the  loss  function to be the one that your algorithm optimizes rather than the one imposed by the world. 
  
The fundamental reason why this is a defect is that it creates artificial boundaries to problem solution.  Artificial boundaries lead to the possibility of being blind-sided.  For example, someone committing (1) or (2) above might find themselves themselves surprised to find a decision tree working well on a problem.  Example (3) might result in someone else solving a learning problem better for real world purposes, even if it’s worse with respect to the algorithm optimization.  This defect should be avoided so as to not artificially l</p><p>5 0.70706713 <a title="217-lda-5" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>Introduction: Researchers are typically confronted with big problems that they have no idea how to solve.  In trying to come up with a solution, a natural approach is to decompose the big problem into a set of subproblems whose solution yields a solution to the larger problem.  This approach can go wrong in several ways. 
  
  Decomposition failure .  The solution to the decomposition does not in fact yield a solution to the overall problem. 
  Artificial hardness .  The subproblems created are sufficient if solved to solve the overall problem, but they are harder than necessary. 
  
As you can see, computational complexity forms a relatively new (in research-history) razor by which to judge an approach sufficient but not necessary.
 
In my experience, the artificial hardness problem is very common.  Many researchers abdicate the responsibility of choosing a problem to work on to other people.  This process starts very naturally as a graduate student, when an incoming student might have relatively l</p><p>6 0.63337767 <a title="217-lda-6" href="../hunch_net-2005/hunch_net-2005-02-02-Kolmogorov_Complexity_and_Googling.html">10 hunch net-2005-02-02-Kolmogorov Complexity and Googling</a></p>
<p>7 0.62561369 <a title="217-lda-7" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>8 0.61312926 <a title="217-lda-8" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>9 0.61003393 <a title="217-lda-9" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>10 0.60912848 <a title="217-lda-10" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>11 0.60907733 <a title="217-lda-11" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>12 0.60842615 <a title="217-lda-12" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>13 0.60730827 <a title="217-lda-13" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>14 0.60681772 <a title="217-lda-14" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>15 0.60497177 <a title="217-lda-15" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>16 0.60429758 <a title="217-lda-16" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>17 0.6042707 <a title="217-lda-17" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>18 0.6034134 <a title="217-lda-18" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>19 0.60340869 <a title="217-lda-19" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>20 0.60323977 <a title="217-lda-20" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
