<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>164 hunch net-2006-03-17-Multitask learning is Black-Boxable</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-164" href="#">hunch_net-2006-164</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>164 hunch net-2006-03-17-Multitask learning is Black-Boxable</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-164-html" href="http://hunch.net/?p=175">html</a></p><p>Introduction: Multitask learning is the problem of jointly predicting multiple labels
simultaneously with one system. A basic question iswhether or not multitask
learning can be decomposed into one (or more) single prediction problems. It
seems the answer to this is "yes", in a fairly straightforward manner.The
basic idea is that a controlled input feature is equivalent to an extra
output. Suppose we have some process generating examples:(x,y1,y2) in
Swherey1andy2are labels for two different tasks. Then, we could reprocess the
data to the formSb(S) = {((x,i),yi): (x,y1,y2) in S, i in {1,2}}and then learn
a classifierc:X x {1,2} -> Y. Note that(x,i)is the (composite) input. At
testing time, given an inputx, we can querycfor the predicted values of y1and
y2using(x,1)and(x,2).A strong form of equivalence can be stated between these
tasks. In particular, suppose we have a multitask learning algorithmMLwhich
learns a multitask predictorm:X -> Y x Y. Then the following theorem can be
proved:For allMLfor a</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Multitask learning is the problem of jointly predicting multiple labels simultaneously with one system. [sent-1, score-0.519]
</p><p>2 A basic question iswhether or not multitask learning can be decomposed into one (or more) single prediction problems. [sent-2, score-1.054]
</p><p>3 It seems the answer to this is "yes", in a fairly straightforward manner. [sent-3, score-0.274]
</p><p>4 The basic idea is that a controlled input feature is equivalent to an extra output. [sent-4, score-0.541]
</p><p>5 Suppose we have some process generating examples:(x,y1,y2) in Swherey1andy2are labels for two different tasks. [sent-5, score-0.258]
</p><p>6 At testing time, given an inputx, we can querycfor the predicted values of y1and y2using(x,1)and(x,2). [sent-8, score-0.272]
</p><p>7 A strong form of equivalence can be stated between these tasks. [sent-9, score-0.208]
</p><p>8 In particular, suppose we have a multitask learning algorithmMLwhich learns a multitask predictorm:X -> Y x Y. [sent-10, score-1.573]
</p><p>9 Then the following theorem can be proved:For allMLfor allS, there exists an inverse reductionSmsuch thatML(S) = ML(Sm(Sb(S)). [sent-11, score-0.259]
</p><p>10 In other words, no information is lost in the transformationSbwhich means everything which was learnable previously remains learnable. [sent-12, score-0.446]
</p><p>11 This may not be the final answer to the question because there may be some algorithm-dependent (mis)behavior associated with controlled featurei. [sent-13, score-0.753]
</p><p>12 It may also be the case that single task classification is computationally distinguishable from multitask classification. [sent-14, score-1.139]
</p><p>13 Certainly, computational concerns are one of the reasons specialized multitask classification algorithms exist. [sent-15, score-0.954]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('multitask', 0.635), ('controlled', 0.226), ('suppose', 0.179), ('labels', 0.16), ('classifierc', 0.141), ('composite', 0.141), ('single', 0.128), ('decomposed', 0.124), ('learns', 0.124), ('equivalence', 0.124), ('jointly', 0.124), ('inverse', 0.124), ('classification', 0.122), ('mis', 0.118), ('learnable', 0.113), ('specialized', 0.106), ('answer', 0.104), ('proved', 0.103), ('behavior', 0.1), ('generating', 0.098), ('straightforward', 0.098), ('predicted', 0.095), ('task', 0.095), ('simultaneously', 0.093), ('question', 0.092), ('testing', 0.091), ('concerns', 0.091), ('lost', 0.09), ('may', 0.088), ('values', 0.086), ('remains', 0.085), ('equivalent', 0.084), ('stated', 0.084), ('previously', 0.082), ('yes', 0.082), ('words', 0.081), ('extra', 0.08), ('associated', 0.078), ('final', 0.077), ('input', 0.076), ('everything', 0.076), ('basic', 0.075), ('predicting', 0.075), ('fairly', 0.072), ('certainly', 0.072), ('computationally', 0.071), ('theorem', 0.069), ('exist', 0.067), ('multiple', 0.067), ('exists', 0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="164-tfidf-1" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>Introduction: Multitask learning is the problem of jointly predicting multiple labels
simultaneously with one system. A basic question iswhether or not multitask
learning can be decomposed into one (or more) single prediction problems. It
seems the answer to this is "yes", in a fairly straightforward manner.The
basic idea is that a controlled input feature is equivalent to an extra
output. Suppose we have some process generating examples:(x,y1,y2) in
Swherey1andy2are labels for two different tasks. Then, we could reprocess the
data to the formSb(S) = {((x,i),yi): (x,y1,y2) in S, i in {1,2}}and then learn
a classifierc:X x {1,2} -> Y. Note that(x,i)is the (composite) input. At
testing time, given an inputx, we can querycfor the predicted values of y1and
y2using(x,1)and(x,2).A strong form of equivalence can be stated between these
tasks. In particular, suppose we have a multitask learning algorithmMLwhich
learns a multitask predictorm:X -> Y x Y. Then the following theorem can be
proved:For allMLfor a</p><p>2 0.35370639 <a title="164-tfidf-2" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>Introduction: Multitask learning is the learning to predict multiple outputs given the same
input. Mathematically, we might think of this as trying to learn a functionf:X
-> {0,1}n. Structured learning is similar at this level of abstraction. Many
people have worked on solving multitask learning (for exampleRich Caruana)
using methods which share an internal representation. On other words, the the
computation and learning of theith prediction is shared with the computation
and learning of thejth prediction. Another way to ask this question is: can we
avoid sharing the internal representation?For example, itmightbe feasible to
solve multitask learning by some process feeding theith predictionf(x)iinto
thejth predictorf(x,f(x)i)j,If the answer is "no", then it implies we can not
take binary classification as a basic primitive in the process of solving
prediction problems. If the answer is "yes", then we can reuse binary
classification algorithms to solve multitask learning problems.Finding a
satisfyin</p><p>3 0.12579221 <a title="164-tfidf-3" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>Introduction: Fernando Pereirapointed outAndo andZhang'spaperon "structural" learning.
Structural learning is multitask learning on subproblems created from
unlabeled data.The basic idea is to take a look at the unlabeled data and
create many supervised problems. On text data, which they test on, these
subproblems might be of the form "Given surrounding words predict the middle
word". The hope here is that successfully predicting on these subproblems is
relevant to the prediction of your core problem.In the long run, the precise
mechanism used (essentially, linear predictors with parameters tied by a
common matrix) and the precise problems formed may not be critical. What seems
critical is that the hope is realized: the technique provides a significant
edge in practice.Some basic questions about this approach are:Are there
effective automated mechanisms for creating the subproblems?Is it necessary to
use a shared representation?</p><p>4 0.11355281 <a title="164-tfidf-4" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>Introduction: I'm offering a reward of $1000 for a solution to this problem. This joins
thecross validation problemwhich I'm offering a$500 rewardfor. I believe both
of these problems are hard but plausibly solvable, and plausibly with a
solution of substantial practical value. While it's unlikely these rewards are
worth your time on an hourly wage basis, the recognition for solving them
definitely should beThe ProblemThe problem is finding a general, robust, and
efficient mechanism for estimating a conditional probabilityP(y|x)where
robustness and efficiency are measured using techniques from learning
reductions.In particular, suppose we have access to a binary regression
oracleBwhich has two interfaces--one for specifying training information and
one for testing. Training information is specified asB(x',y')wherex'is a
feature vector andy'is a scalar in[0,1]with no value returned. Testing is done
according toB(x')with a value in[0,1]returned.A learning reduction consists of
two algorithmsRandR-1whi</p><p>5 0.089183658 <a title="164-tfidf-5" href="../hunch_net-2006/hunch_net-2006-07-08-Some_recent_papers.html">192 hunch net-2006-07-08-Some recent papers</a></p>
<p>Introduction: It was a fine time for learning in Pittsburgh. John and Sam mentioned some of
my favorites. Here's a few more worth checking out:Online Multitask
LearningOfer Dekel, Phil Long, Yoram SingerThis is on my reading list.
Definitely an area I'm interested in.Maximum Entropy Distribution Estimation
with Generalized RegularizationMiroslav DudÃƒÂ­k, Robert E. SchapireLearning
near-optimal policies with Bellman-residual minimization based fitted policy
iteration and a single sample pathAndrÃƒÂ¡s Antos, Csaba SzepesvÃƒÂ¡ri,
RÃƒÂ©mi MunosAgain, on the list to read. I saw Csaba and Remi talk about this
and related work at an ICML Workshop on Kernel Reinforcement Learning. The big
question in my head is how this compares/contrasts with existing work
inreductions to reinforcement learning.Are there
advantages/disadvantages?Higher Order Learning On Graphs>by Sameer Agarwal,
Kristin Branson, and Serge Belongie, looks to be interesteding. They seem to
poo-poo "tensorization" of existing graph algorithm</p><p>6 0.088211648 <a title="164-tfidf-6" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>7 0.085036516 <a title="164-tfidf-7" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>8 0.083920769 <a title="164-tfidf-8" href="../hunch_net-2005/hunch_net-2005-03-22-Active_learning.html">45 hunch net-2005-03-22-Active learning</a></p>
<p>9 0.082266815 <a title="164-tfidf-9" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>10 0.079885751 <a title="164-tfidf-10" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<p>11 0.078404702 <a title="164-tfidf-11" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>12 0.075352795 <a title="164-tfidf-12" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>13 0.073951989 <a title="164-tfidf-13" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>14 0.072924711 <a title="164-tfidf-14" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>15 0.071018524 <a title="164-tfidf-15" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>16 0.070219919 <a title="164-tfidf-16" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>17 0.069974303 <a title="164-tfidf-17" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>18 0.068547733 <a title="164-tfidf-18" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>19 0.061622888 <a title="164-tfidf-19" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>20 0.0614613 <a title="164-tfidf-20" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.152), (1, -0.094), (2, -0.015), (3, -0.009), (4, -0.004), (5, -0.019), (6, -0.035), (7, -0.016), (8, 0.075), (9, 0.051), (10, -0.001), (11, 0.015), (12, 0.102), (13, -0.0), (14, 0.042), (15, -0.037), (16, -0.044), (17, 0.039), (18, 0.025), (19, 0.006), (20, 0.049), (21, 0.02), (22, 0.127), (23, 0.026), (24, 0.065), (25, -0.04), (26, -0.011), (27, -0.019), (28, -0.029), (29, 0.039), (30, -0.037), (31, 0.079), (32, -0.102), (33, -0.142), (34, 0.048), (35, -0.039), (36, 0.007), (37, -0.039), (38, -0.196), (39, 0.132), (40, -0.084), (41, -0.072), (42, 0.058), (43, 0.221), (44, 0.005), (45, -0.021), (46, 0.103), (47, 0.056), (48, -0.001), (49, -0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97416633 <a title="164-lsi-1" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>Introduction: Multitask learning is the problem of jointly predicting multiple labels
simultaneously with one system. A basic question iswhether or not multitask
learning can be decomposed into one (or more) single prediction problems. It
seems the answer to this is "yes", in a fairly straightforward manner.The
basic idea is that a controlled input feature is equivalent to an extra
output. Suppose we have some process generating examples:(x,y1,y2) in
Swherey1andy2are labels for two different tasks. Then, we could reprocess the
data to the formSb(S) = {((x,i),yi): (x,y1,y2) in S, i in {1,2}}and then learn
a classifierc:X x {1,2} -> Y. Note that(x,i)is the (composite) input. At
testing time, given an inputx, we can querycfor the predicted values of y1and
y2using(x,1)and(x,2).A strong form of equivalence can be stated between these
tasks. In particular, suppose we have a multitask learning algorithmMLwhich
learns a multitask predictorm:X -> Y x Y. Then the following theorem can be
proved:For allMLfor a</p><p>2 0.86255389 <a title="164-lsi-2" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>Introduction: Multitask learning is the learning to predict multiple outputs given the same
input. Mathematically, we might think of this as trying to learn a functionf:X
-> {0,1}n. Structured learning is similar at this level of abstraction. Many
people have worked on solving multitask learning (for exampleRich Caruana)
using methods which share an internal representation. On other words, the the
computation and learning of theith prediction is shared with the computation
and learning of thejth prediction. Another way to ask this question is: can we
avoid sharing the internal representation?For example, itmightbe feasible to
solve multitask learning by some process feeding theith predictionf(x)iinto
thejth predictorf(x,f(x)i)j,If the answer is "no", then it implies we can not
take binary classification as a basic primitive in the process of solving
prediction problems. If the answer is "yes", then we can reuse binary
classification algorithms to solve multitask learning problems.Finding a
satisfyin</p><p>3 0.66560203 <a title="164-lsi-3" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>Introduction: Fernando Pereirapointed outAndo andZhang'spaperon "structural" learning.
Structural learning is multitask learning on subproblems created from
unlabeled data.The basic idea is to take a look at the unlabeled data and
create many supervised problems. On text data, which they test on, these
subproblems might be of the form "Given surrounding words predict the middle
word". The hope here is that successfully predicting on these subproblems is
relevant to the prediction of your core problem.In the long run, the precise
mechanism used (essentially, linear predictors with parameters tied by a
common matrix) and the precise problems formed may not be critical. What seems
critical is that the hope is realized: the technique provides a significant
edge in practice.Some basic questions about this approach are:Are there
effective automated mechanisms for creating the subproblems?Is it necessary to
use a shared representation?</p><p>4 0.60972703 <a title="164-lsi-4" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>Introduction: Suppose we had an infinitely powerful mathematician sitting in a room and
proving theorems about learning. Could he solve machine learning?The answer is
"no". This answer is both obvious and sometimes underappreciated.There are
several ways to conclude that somebiasis necessary in order to succesfully
learn. For example, suppose we are trying to solve classification. At
prediction time, we observe some featuresXand want to make a prediction of
either0or1. Bias is what makes us prefer one answer over the other based on
past experience. In order to learn we must:Have a bias. Always predicting0is
as likely as1is useless.Have the "right" bias. Predicting1when the answer
is0is also not helpful.The implication of "have a bias" is that we can not
design effective learning algorithms with "a uniform prior over all
possibilities". The implication of "have the 'right' bias" is that our
mathematician fails since "right" is defined with respect to the solutions to
problems encountered in the real</p><p>5 0.54935634 <a title="164-lsi-5" href="../hunch_net-2010/hunch_net-2010-07-02-MetaOptimize.html">402 hunch net-2010-07-02-MetaOptimize</a></p>
<p>Introduction: Joseph TuriancreatesMetaOptimizefor discussion of NLP and ML on big datasets.
This includes ablog, but perhaps more importantly aquestion and answer
section. I'm hopeful it will take off.</p><p>6 0.53897947 <a title="164-lsi-6" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>7 0.50090355 <a title="164-lsi-7" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>8 0.4852038 <a title="164-lsi-8" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>9 0.48494905 <a title="164-lsi-9" href="../hunch_net-2007/hunch_net-2007-07-28-Asking_questions.html">257 hunch net-2007-07-28-Asking questions</a></p>
<p>10 0.46042135 <a title="164-lsi-10" href="../hunch_net-2005/hunch_net-2005-09-20-Workshop_Proposal%3A_Atomic_Learning.html">114 hunch net-2005-09-20-Workshop Proposal: Atomic Learning</a></p>
<p>11 0.45380825 <a title="164-lsi-11" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>12 0.42667851 <a title="164-lsi-12" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>13 0.41354504 <a title="164-lsi-13" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>14 0.40683714 <a title="164-lsi-14" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>15 0.40376151 <a title="164-lsi-15" href="../hunch_net-2008/hunch_net-2008-05-25-Inappropriate_Mathematics_for_Machine_Learning.html">302 hunch net-2008-05-25-Inappropriate Mathematics for Machine Learning</a></p>
<p>16 0.39903969 <a title="164-lsi-16" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>17 0.39845791 <a title="164-lsi-17" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<p>18 0.39334384 <a title="164-lsi-18" href="../hunch_net-2008/hunch_net-2008-04-27-Watchword%3A_Supervised_Learning.html">299 hunch net-2008-04-27-Watchword: Supervised Learning</a></p>
<p>19 0.38403347 <a title="164-lsi-19" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>20 0.37903774 <a title="164-lsi-20" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(34, 0.306), (35, 0.028), (42, 0.349), (45, 0.05), (50, 0.045), (68, 0.026), (74, 0.058), (76, 0.02)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91908008 <a title="164-lda-1" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>Introduction: Multitask learning is the problem of jointly predicting multiple labels
simultaneously with one system. A basic question iswhether or not multitask
learning can be decomposed into one (or more) single prediction problems. It
seems the answer to this is "yes", in a fairly straightforward manner.The
basic idea is that a controlled input feature is equivalent to an extra
output. Suppose we have some process generating examples:(x,y1,y2) in
Swherey1andy2are labels for two different tasks. Then, we could reprocess the
data to the formSb(S) = {((x,i),yi): (x,y1,y2) in S, i in {1,2}}and then learn
a classifierc:X x {1,2} -> Y. Note that(x,i)is the (composite) input. At
testing time, given an inputx, we can querycfor the predicted values of y1and
y2using(x,1)and(x,2).A strong form of equivalence can be stated between these
tasks. In particular, suppose we have a multitask learning algorithmMLwhich
learns a multitask predictorm:X -> Y x Y. Then the following theorem can be
proved:For allMLfor a</p><p>2 0.9171012 <a title="164-lda-2" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notationg(n) = O(f(n))means that in the limit asnapproaches infinity there
exists a constantCsuch that theg(n)is less thanCf(n).In learning theory, there
are many statements about learning algorithms of the form "under
assumptionsx,y, andz, the classifier learned has an error rate of at
mostO(f(m))".There is one very good reason to use O(): it helps you understand
the big picture and neglect the minor details which are not important in the
big picture. However, there are some important reasons not to do this as
well.UnspeedupIn algorithm analysis, the use of O() for time complexity is
pervasive and well-justified. Determining the exact value of C is inherently
computer architecture dependent. (The "C" for x86 processors might differ from
the "C" on PowerPC processors.) Since many learning theorists come from a CS
theory background, the O() notation is applied to generalization error. The
O() abstraction breaks here--you can not generally change learning algorithm
and decrease your</p><p>3 0.89678454 <a title="164-lda-3" href="../hunch_net-2008/hunch_net-2008-04-12-Blog_compromised.html">294 hunch net-2008-04-12-Blog compromised</a></p>
<p>Introduction: Iainnoticed that hunch.net had zero width divs hiding spammy URLs. Some
investigation reveals that the wordpress version being used (2.0.3) had
security flaws. I've upgraded to the latest, rotated passwords, and removed
the spammy URLs. I don't believe any content was lost. You can check your own
and other sites for a similar problem by greping for "width:0″ or "width: 0″
in the delivered html source.</p><p>4 0.77394706 <a title="164-lda-4" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>Introduction: I justpresentedthecross validationproblem atCOLT.The problem now has a cash
prize (up to $500) associated with it--see thepresentationfor details
.Thewrite-up for colt.</p><p>5 0.75514776 <a title="164-lda-5" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<p>Introduction: Given John's recent posts on CMU's new machine learning department and "Deep
Learning," I asked for an opportunity to give a computational learning theory
perspective on these issues.To my mind, the answer to the question "Are the
core problems from machine learning different from the core problems of
statistics?" is a clear Yes. The point of this post is to describe a core
problem in machine learning that is computational in nature and will appeal to
statistical learning folk (as an extreme example note that if P=NP- which, for
all we know, is true- then we would suddenly find almost all of our favorite
machine learning problems considerably more tractable).If the central question
of statistical learning theory were crudely summarized as "given a hypothesis
with a certain loss bound over a test set, how well will it generalize?" then
the central question of computational learning theory might be "how can we
find such a hypothesis efficently (e.g., in polynomial-time)?"With this in
min</p><p>6 0.75478864 <a title="164-lda-6" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>7 0.75466192 <a title="164-lda-7" href="../hunch_net-2011/hunch_net-2011-04-20-The_End_of_the_Beginning_of_Active_Learning.html">432 hunch net-2011-04-20-The End of the Beginning of Active Learning</a></p>
<p>8 0.75406086 <a title="164-lda-8" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>9 0.75329971 <a title="164-lda-9" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>10 0.75226963 <a title="164-lda-10" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>11 0.75084889 <a title="164-lda-11" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>12 0.74883741 <a title="164-lda-12" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>13 0.74842185 <a title="164-lda-13" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>14 0.7472645 <a title="164-lda-14" href="../hunch_net-2009/hunch_net-2009-06-15-In_Active_Learning%2C_the_question_changes.html">360 hunch net-2009-06-15-In Active Learning, the question changes</a></p>
<p>15 0.74541318 <a title="164-lda-15" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>16 0.74514997 <a title="164-lda-16" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>17 0.74452329 <a title="164-lda-17" href="../hunch_net-2005/hunch_net-2005-03-29-Academic_Mechanism_Design.html">48 hunch net-2005-03-29-Academic Mechanism Design</a></p>
<p>18 0.7431823 <a title="164-lda-18" href="../hunch_net-2006/hunch_net-2006-06-15-IJCAI_is_out_of_season.html">184 hunch net-2006-06-15-IJCAI is out of season</a></p>
<p>19 0.7430746 <a title="164-lda-19" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>20 0.74279666 <a title="164-lda-20" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
