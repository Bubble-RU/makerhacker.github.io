<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-149" href="#">hunch_net-2006-149</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-149-html" href="http://hunch.net/?p=160">html</a></p><p>Introduction: Multitask learning is the learning to predict multiple outputs given the same input.  Mathematically, we might think of this as trying to learn a function  f:X -> {0,1} n  .  Structured learning is similar at this level of abstraction.  Many people have worked on solving multitask learning (for example  Rich Caruana ) using methods which share an internal representation.  On other words, the the computation and learning  of the  i th prediction is shared with the computation and learning of the  j th prediction.  Another way to ask this question is: can we avoid sharing the internal representation?  
 
For example, it  might  be feasible to solve multitask learning by some process feeding the  i th prediction  f(x) i   into the  j th predictor  f(x,f(x) i ) j  , 
 
If the answer is “no”, then it implies we can not take binary classification as a basic primitive in the process of solving prediction problems.  If the answer is “yes”, then we can reuse binary classification algorithms to</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Multitask learning is the learning to predict multiple outputs given the same input. [sent-1, score-0.238]
</p><p>2 Mathematically, we might think of this as trying to learn a function  f:X -> {0,1} n  . [sent-2, score-0.145]
</p><p>3 Structured learning is similar at this level of abstraction. [sent-3, score-0.157]
</p><p>4 Many people have worked on solving multitask learning (for example  Rich Caruana ) using methods which share an internal representation. [sent-4, score-0.742]
</p><p>5 On other words, the the computation and learning  of the  i th prediction is shared with the computation and learning of the  j th prediction. [sent-5, score-1.575]
</p><p>6 Another way to ask this question is: can we avoid sharing the internal representation? [sent-6, score-0.32]
</p><p>7 If the answer is “yes”, then we can reuse binary classification algorithms to solve multitask learning problems. [sent-8, score-0.98]
</p><p>8 Finding a satisfying answer to this question at a theoretical level appears tricky. [sent-9, score-0.438]
</p><p>9 If you consider the infinite data limit with IID samples for any finite  X , the answer is “yes” because any function can be learned. [sent-10, score-0.409]
</p><p>10 However, this does not take into account two important effects:     Using a shared representation alters the bias of the learning process. [sent-11, score-0.986]
</p><p>11 What this implies is that fewer examples may be required to learn all of the predictors. [sent-12, score-0.208]
</p><p>12 Of course, changing the input features also alters the bias of the learning process. [sent-13, score-0.449]
</p><p>13 Comparing these altered biases well enough to distinguish their power seems very tricky. [sent-14, score-0.231]
</p><p>14 For reference, Jonathon Baxter has done  some related analysis  (which still doesn’t answer the question). [sent-15, score-0.255]
</p><p>15 Using a shared representation may be computationally cheaper. [sent-16, score-0.534]
</p><p>16 One thing which  can  be said about multitask learning (in either black-box or shared representation form), is that it can make learning radically easier. [sent-17, score-1.194]
</p><p>17 For example, predicting the first bit output by a cryptographic circuit is (by design) extraordinarily hard. [sent-18, score-0.484]
</p><p>18 However, predicting the bits of every gate in the circuit (including the first bit output) is easily done based upon a few examples. [sent-19, score-0.373]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('th', 0.406), ('multitask', 0.38), ('shared', 0.325), ('representation', 0.209), ('alters', 0.203), ('circuit', 0.203), ('answer', 0.186), ('internal', 0.14), ('bias', 0.11), ('output', 0.11), ('yes', 0.109), ('binary', 0.103), ('feeding', 0.102), ('predicting', 0.101), ('computation', 0.1), ('question', 0.095), ('prediction', 0.094), ('outputs', 0.094), ('caruana', 0.089), ('level', 0.085), ('sharing', 0.085), ('mathematically', 0.085), ('reuse', 0.085), ('classification', 0.083), ('altered', 0.081), ('infinite', 0.081), ('primitive', 0.081), ('biases', 0.078), ('function', 0.078), ('implies', 0.077), ('solving', 0.075), ('using', 0.075), ('feasible', 0.074), ('comparing', 0.074), ('however', 0.073), ('learning', 0.072), ('distinguish', 0.072), ('satisfying', 0.072), ('solve', 0.071), ('extraordinarily', 0.07), ('rich', 0.07), ('said', 0.07), ('done', 0.069), ('take', 0.067), ('learn', 0.067), ('radically', 0.066), ('limit', 0.064), ('fewer', 0.064), ('effects', 0.064), ('changing', 0.064)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="149-tfidf-1" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>Introduction: Multitask learning is the learning to predict multiple outputs given the same input.  Mathematically, we might think of this as trying to learn a function  f:X -> {0,1} n  .  Structured learning is similar at this level of abstraction.  Many people have worked on solving multitask learning (for example  Rich Caruana ) using methods which share an internal representation.  On other words, the the computation and learning  of the  i th prediction is shared with the computation and learning of the  j th prediction.  Another way to ask this question is: can we avoid sharing the internal representation?  
 
For example, it  might  be feasible to solve multitask learning by some process feeding the  i th prediction  f(x) i   into the  j th predictor  f(x,f(x) i ) j  , 
 
If the answer is “no”, then it implies we can not take binary classification as a basic primitive in the process of solving prediction problems.  If the answer is “yes”, then we can reuse binary classification algorithms to</p><p>2 0.32959321 <a title="149-tfidf-2" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>Introduction: Multitask learning is the problem of jointly predicting multiple labels simultaneously with one system.   A basic question is  whether or not multitask learning can be decomposed into one (or more) single prediction problems .  It seems the answer to this is “yes”, in a fairly straightforward manner.
 
The basic idea is that a controlled input feature is equivalent to an extra output.  Suppose we have some process generating examples:  (x,y 1 ,y 2 ) in S  where  y 1   and  y 2   are labels for two different tasks.  Then, we could reprocess the data to the form  S b (S) = {((x,i),y i ): (x,y 1 ,y 2 ) in S, i in {1,2}}  and then learn a classifier  c:X x {1,2} -> Y . Note that  (x,i)  is the (composite) input. At testing time, given an input  x , we can query  c  for the predicted values of y 1  and y 2  using  (x,1)  and  (x,2) .
 
A strong form of equivalence can be stated between these tasks.  In particular, suppose we have a multitask learning algorithm  ML  which learns a multitask</p><p>3 0.17056786 <a title="149-tfidf-3" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>Introduction: Suppose we had an infinitely powerful mathematician sitting in a room and proving theorems about learning.  Could he solve machine learning?
 
The answer is “no”.   This answer is both obvious and sometimes underappreciated.   
 
There are several ways to conclude that some  bias  is necessary in order to succesfully learn.  For example, suppose we are trying to solve classification.  At prediction time, we observe some features  X  and want to make a prediction of either  0  or  1 .   Bias is what makes us prefer one answer over the other based on past experience.  In order to learn we must:
  
 Have a bias.  Always predicting  0  is as likely as  1  is useless. 
 Have the “right” bias.  Predicting  1  when the answer is  0  is also not helpful. 
  
The implication of “have a bias” is that we can not design effective learning algorithms with “a uniform prior over all possibilities”.  The implication of “have the ‘right’ bias” is that our mathematician fails since “right” is defined wi</p><p>4 0.15299278 <a title="149-tfidf-4" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>Introduction: “Deep learning” is used to describe learning architectures which have significant depth (as a circuit).  
 
 One claim  is that shallow architectures (one or two layers) can not concisely represent some functions while a circuit with more depth can concisely represent these same functions.  Proving lower bounds on the size of a circuit is substantially harder than upper bounds (which are constructive), but some results are known.   Luca Trevisan ‘s  class notes  detail how XOR is not concisely representable by “AC0″ (= constant depth unbounded fan-in AND, OR, NOT gates).  This doesn’t quite prove that depth is necessary for the representations commonly used in learning (such as a thresholded weighted sum), but it is strongly suggestive that this is so.
 
Examples like this are a bit disheartening because existing algorithms for deep learning (deep belief nets, gradient descent on deep neural networks, and a perhaps decision trees depending on who you ask) can’t learn XOR very easily.</p><p>5 0.15078394 <a title="149-tfidf-5" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>Introduction: Fernando Pereira   pointed out  Ando and  Zhang ‘s  paper  on “structural” learning.  Structural learning is multitask learning on subproblems created from unlabeled data.  
 
The basic idea is to take a look at the unlabeled data and create many supervised problems.  On text data, which they test on, these subproblems might be of the form “Given surrounding words predict the middle word”.   The hope here is that successfully predicting on these subproblems is relevant to the prediction of your core problem.
 
In the long run, the precise mechanism used (essentially, linear predictors with parameters tied by a common matrix) and the precise problems formed may not be critical.  What seems critical is that the hope is realized: the technique provides a significant edge in practice.
 
Some basic questions about this approach are:
  
 Are there effective automated mechanisms for creating the subproblems? 
 Is it necessary to use a shared representation?</p><p>6 0.11045328 <a title="149-tfidf-6" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>7 0.10199805 <a title="149-tfidf-7" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>8 0.1009552 <a title="149-tfidf-8" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>9 0.099688545 <a title="149-tfidf-9" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>10 0.09852016 <a title="149-tfidf-10" href="../hunch_net-2005/hunch_net-2005-02-09-Intuitions_from_applied_learning.html">16 hunch net-2005-02-09-Intuitions from applied learning</a></p>
<p>11 0.091394432 <a title="149-tfidf-11" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>12 0.08837498 <a title="149-tfidf-12" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>13 0.088321447 <a title="149-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>14 0.088074297 <a title="149-tfidf-14" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>15 0.08799725 <a title="149-tfidf-15" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>16 0.08523123 <a title="149-tfidf-16" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>17 0.084837571 <a title="149-tfidf-17" href="../hunch_net-2005/hunch_net-2005-08-18-SVM_Adaptability.html">103 hunch net-2005-08-18-SVM Adaptability</a></p>
<p>18 0.084670052 <a title="149-tfidf-18" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>19 0.083349988 <a title="149-tfidf-19" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>20 0.080800161 <a title="149-tfidf-20" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.197), (1, 0.115), (2, 0.008), (3, -0.018), (4, -0.004), (5, -0.053), (6, 0.047), (7, 0.023), (8, 0.025), (9, -0.059), (10, -0.138), (11, -0.063), (12, 0.013), (13, 0.04), (14, -0.055), (15, 0.044), (16, 0.004), (17, -0.037), (18, -0.031), (19, 0.031), (20, 0.006), (21, -0.009), (22, 0.128), (23, 0.041), (24, 0.037), (25, -0.121), (26, 0.065), (27, 0.018), (28, -0.046), (29, -0.009), (30, -0.031), (31, -0.028), (32, 0.0), (33, -0.124), (34, -0.151), (35, 0.065), (36, -0.038), (37, 0.134), (38, -0.124), (39, -0.097), (40, -0.037), (41, 0.006), (42, -0.052), (43, 0.071), (44, 0.051), (45, -0.182), (46, 0.037), (47, -0.087), (48, -0.071), (49, -0.111)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94666219 <a title="149-lsi-1" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>Introduction: Multitask learning is the learning to predict multiple outputs given the same input.  Mathematically, we might think of this as trying to learn a function  f:X -> {0,1} n  .  Structured learning is similar at this level of abstraction.  Many people have worked on solving multitask learning (for example  Rich Caruana ) using methods which share an internal representation.  On other words, the the computation and learning  of the  i th prediction is shared with the computation and learning of the  j th prediction.  Another way to ask this question is: can we avoid sharing the internal representation?  
 
For example, it  might  be feasible to solve multitask learning by some process feeding the  i th prediction  f(x) i   into the  j th predictor  f(x,f(x) i ) j  , 
 
If the answer is “no”, then it implies we can not take binary classification as a basic primitive in the process of solving prediction problems.  If the answer is “yes”, then we can reuse binary classification algorithms to</p><p>2 0.90458381 <a title="149-lsi-2" href="../hunch_net-2006/hunch_net-2006-03-17-Multitask_learning_is_Black-Boxable.html">164 hunch net-2006-03-17-Multitask learning is Black-Boxable</a></p>
<p>Introduction: Multitask learning is the problem of jointly predicting multiple labels simultaneously with one system.   A basic question is  whether or not multitask learning can be decomposed into one (or more) single prediction problems .  It seems the answer to this is “yes”, in a fairly straightforward manner.
 
The basic idea is that a controlled input feature is equivalent to an extra output.  Suppose we have some process generating examples:  (x,y 1 ,y 2 ) in S  where  y 1   and  y 2   are labels for two different tasks.  Then, we could reprocess the data to the form  S b (S) = {((x,i),y i ): (x,y 1 ,y 2 ) in S, i in {1,2}}  and then learn a classifier  c:X x {1,2} -> Y . Note that  (x,i)  is the (composite) input. At testing time, given an input  x , we can query  c  for the predicted values of y 1  and y 2  using  (x,1)  and  (x,2) .
 
A strong form of equivalence can be stated between these tasks.  In particular, suppose we have a multitask learning algorithm  ML  which learns a multitask</p><p>3 0.68421638 <a title="149-lsi-3" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>Introduction: Suppose we had an infinitely powerful mathematician sitting in a room and proving theorems about learning.  Could he solve machine learning?
 
The answer is “no”.   This answer is both obvious and sometimes underappreciated.   
 
There are several ways to conclude that some  bias  is necessary in order to succesfully learn.  For example, suppose we are trying to solve classification.  At prediction time, we observe some features  X  and want to make a prediction of either  0  or  1 .   Bias is what makes us prefer one answer over the other based on past experience.  In order to learn we must:
  
 Have a bias.  Always predicting  0  is as likely as  1  is useless. 
 Have the “right” bias.  Predicting  1  when the answer is  0  is also not helpful. 
  
The implication of “have a bias” is that we can not design effective learning algorithms with “a uniform prior over all possibilities”.  The implication of “have the ‘right’ bias” is that our mathematician fails since “right” is defined wi</p><p>4 0.65417624 <a title="149-lsi-4" href="../hunch_net-2006/hunch_net-2006-03-05-%26%238220%3BStructural%26%238221%3B_Learning.html">161 hunch net-2006-03-05-&#8220;Structural&#8221; Learning</a></p>
<p>Introduction: Fernando Pereira   pointed out  Ando and  Zhang ‘s  paper  on “structural” learning.  Structural learning is multitask learning on subproblems created from unlabeled data.  
 
The basic idea is to take a look at the unlabeled data and create many supervised problems.  On text data, which they test on, these subproblems might be of the form “Given surrounding words predict the middle word”.   The hope here is that successfully predicting on these subproblems is relevant to the prediction of your core problem.
 
In the long run, the precise mechanism used (essentially, linear predictors with parameters tied by a common matrix) and the precise problems formed may not be critical.  What seems critical is that the hope is realized: the technique provides a significant edge in practice.
 
Some basic questions about this approach are:
  
 Are there effective automated mechanisms for creating the subproblems? 
 Is it necessary to use a shared representation?</p><p>5 0.62669754 <a title="149-lsi-5" href="../hunch_net-2009/hunch_net-2009-04-02-Asymmophobia.html">348 hunch net-2009-04-02-Asymmophobia</a></p>
<p>Introduction: One striking feature of many machine learning algorithms is the gymnastics that designers go through to avoid symmetry breaking.  In the most basic form of machine learning, there are labeled examples composed of features.  Each of these can be treated symmetrically or asymmetrically by algorithms.
  
  feature symmetry   Every feature is treated the same.   In gradient update rules, the same update is applied whether the feature is first or last.  In metric-based predictions, every feature is just as important in computing the distance.   
  example symmetry   Every example is treated the same.  Batch learning algorithms are great exemplars of this approach. 
  label symmetry   Every label is treated the same.  This is particularly noticeable in multiclass classification systems which predict according to  arg max l  w l  x  but it occurs in many other places as well. 
  
Empirically, breaking symmetry well seems to yield great algorithms.
  
  feature asymmetry   For those who like t</p><p>6 0.57646435 <a title="149-lsi-6" href="../hunch_net-2006/hunch_net-2006-01-30-Should_the_Input_Representation_be_a_Vector%3F.html">152 hunch net-2006-01-30-Should the Input Representation be a Vector?</a></p>
<p>7 0.57050049 <a title="149-lsi-7" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>8 0.5656504 <a title="149-lsi-8" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>9 0.52769339 <a title="149-lsi-9" href="../hunch_net-2010/hunch_net-2010-07-02-MetaOptimize.html">402 hunch net-2010-07-02-MetaOptimize</a></p>
<p>10 0.51804459 <a title="149-lsi-10" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>11 0.50350618 <a title="149-lsi-11" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>12 0.49375939 <a title="149-lsi-12" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>13 0.49164739 <a title="149-lsi-13" href="../hunch_net-2008/hunch_net-2008-08-24-Mass_Customized_Medicine_in_the_Future%3F.html">314 hunch net-2008-08-24-Mass Customized Medicine in the Future?</a></p>
<p>14 0.4869183 <a title="149-lsi-14" href="../hunch_net-2007/hunch_net-2007-07-28-Asking_questions.html">257 hunch net-2007-07-28-Asking questions</a></p>
<p>15 0.47291738 <a title="149-lsi-15" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>16 0.46975321 <a title="149-lsi-16" href="../hunch_net-2005/hunch_net-2005-02-09-Intuitions_from_applied_learning.html">16 hunch net-2005-02-09-Intuitions from applied learning</a></p>
<p>17 0.46241817 <a title="149-lsi-17" href="../hunch_net-2005/hunch_net-2005-05-10-Learning_Reductions_are_Reductionist.html">68 hunch net-2005-05-10-Learning Reductions are Reductionist</a></p>
<p>18 0.46202052 <a title="149-lsi-18" href="../hunch_net-2009/hunch_net-2009-01-21-Nearly_all_natural_problems_require_nonlinearity.html">337 hunch net-2009-01-21-Nearly all natural problems require nonlinearity</a></p>
<p>19 0.45531392 <a title="149-lsi-19" href="../hunch_net-2005/hunch_net-2005-05-21-What_is_the_right_form_of_modularity_in_structured_prediction%3F.html">74 hunch net-2005-05-21-What is the right form of modularity in structured prediction?</a></p>
<p>20 0.45152581 <a title="149-lsi-20" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.015), (27, 0.227), (38, 0.048), (53, 0.093), (55, 0.136), (58, 0.286), (94, 0.063), (95, 0.025)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96292728 <a title="149-lda-1" href="../hunch_net-2009/hunch_net-2009-04-21-Interesting_Presentations_at_Snowbird.html">349 hunch net-2009-04-21-Interesting Presentations at Snowbird</a></p>
<p>Introduction: Here are a few of presentations interesting me at the  snowbird learning  workshop (which, amusingly, was in Florida with  AIStat ).  
  
  Thomas Breuel  described machine learning problems within OCR and an open source  OCR software/research  platform with modular learning components as well has a 60Million size dataset derived from  Google ‘s scanned books. 
  Kristen Grauman  and  Fei-Fei Li  discussed using active learning with different cost labels and large datasets for  image ontology .  Both of them used  Mechanical Turk  as a  labeling system , which looks to become routine, at least for vision problems. 
  Russ Tedrake  discussed using machine learning for control, with a basic claim that it was the way to go for problems involving a medium  Reynold’s number  such as in bird flight, where simulation is extremely intense. 
  Yann LeCun  presented a poster on an  FPGA for convolutional neural networks  yielding a factor of 100 speedup in processing.   In addition to the graphi</p><p>2 0.89889187 <a title="149-lda-2" href="../hunch_net-2012/hunch_net-2012-07-17-MUCMD_and_BayLearn.html">470 hunch net-2012-07-17-MUCMD and BayLearn</a></p>
<p>Introduction: The workshop on the  Meaningful Use of Complex Medical Data  is happening again, August 9-12 in LA, near  UAI  on Catalina Island August 15-17.  I enjoyed my visit last year, and expect this year to be interesting also.
 
The first  Bay Area Machine Learning Symposium  is August 30 at  Google .  Abstracts are due July 30.</p><p>same-blog 3 0.86795771 <a title="149-lda-3" href="../hunch_net-2006/hunch_net-2006-01-18-Is_Multitask_Learning_Black-Boxable%3F.html">149 hunch net-2006-01-18-Is Multitask Learning Black-Boxable?</a></p>
<p>Introduction: Multitask learning is the learning to predict multiple outputs given the same input.  Mathematically, we might think of this as trying to learn a function  f:X -> {0,1} n  .  Structured learning is similar at this level of abstraction.  Many people have worked on solving multitask learning (for example  Rich Caruana ) using methods which share an internal representation.  On other words, the the computation and learning  of the  i th prediction is shared with the computation and learning of the  j th prediction.  Another way to ask this question is: can we avoid sharing the internal representation?  
 
For example, it  might  be feasible to solve multitask learning by some process feeding the  i th prediction  f(x) i   into the  j th predictor  f(x,f(x) i ) j  , 
 
If the answer is “no”, then it implies we can not take binary classification as a basic primitive in the process of solving prediction problems.  If the answer is “yes”, then we can reuse binary classification algorithms to</p><p>4 0.85476577 <a title="149-lda-4" href="../hunch_net-2009/hunch_net-2009-02-16-KDNuggets.html">342 hunch net-2009-02-16-KDNuggets</a></p>
<p>Introduction: Eric Zaetsch points out  KDNuggets  which is a well-developed mailing list/news site with a  KDD  flavor.  This might particularly interest people looking for industrial jobs in machine learning, as the mailing list has many such.</p><p>5 0.70236886 <a title="149-lda-5" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>Introduction: Unfortunately, I ended up sick for much of this ICML.  I did manage to catch one interesting paper:
 
 Richard Socher ,  Cliff Lin ,  Andrew Y. Ng , and  Christopher D. Manning   Parsing Natural Scenes and Natural Language with Recursive Neural Networks .
 
I invited Richard to share his list of interesting papers, so hopefully we’ll hear from him soon.  In the meantime,  Paul  and  Hal  have posted some lists.
 
 the future 
 
 Joelle  and I are program chairs for ICML 2012 in  Edinburgh , which I previously enjoyed visiting in  2005 .  This is a huge responsibility, that we hope to accomplish well.  A part of this (perhaps the most fun part), is imagining how we can make ICML better.  A key and critical constraint is choosing things that can be accomplished.  So far we have:
  
  Colocation . The first thing we looked into was potential colocations.  We quickly discovered that many other conferences precomitted their location.  For the future, getting a colocation with  ACL  or  SIGI</p><p>6 0.69640678 <a title="149-lda-6" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>7 0.69123548 <a title="149-lda-7" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>8 0.69086868 <a title="149-lda-8" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>9 0.68959337 <a title="149-lda-9" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>10 0.68873578 <a title="149-lda-10" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>11 0.68831956 <a title="149-lda-11" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>12 0.68787092 <a title="149-lda-12" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>13 0.68782413 <a title="149-lda-13" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>14 0.68667334 <a title="149-lda-14" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>15 0.68623269 <a title="149-lda-15" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>16 0.68499959 <a title="149-lda-16" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>17 0.68440473 <a title="149-lda-17" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>18 0.68370795 <a title="149-lda-18" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>19 0.68357414 <a title="149-lda-19" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>20 0.68303633 <a title="149-lda-20" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
