<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-175" href="#">hunch_net-2006-175</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-175-html" href="http://hunch.net/?p=186">html</a></p><p>Introduction: I will join  Yahoo Research  (in New York) after my contract ends at  TTI-Chicago .
 
The deciding reasons are:
  
 Yahoo is running into many hard learning problems.  This is precisely the situation where basic research might hope to have the greatest impact. 
 Yahoo Research understands research including publishing, conferences, etc… 
 Yahoo Research is growing, so there is a chance I can help it grow well. 
 Yahoo understands the internet, including (but not at all limited to) experimenting with research blogs. 
  
In the end, Yahoo Research seems like the place where I might have a chance to make the greatest difference.  
 
Yahoo (as a company) has made a strong bet on Yahoo Research.  We-the-researchers all hope that bet will pay off, and this seems plausible.  I’ll certainly have fun trying.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I will join  Yahoo Research  (in New York) after my contract ends at  TTI-Chicago . [sent-1, score-0.369]
</p><p>2 The deciding reasons are:     Yahoo is running into many hard learning problems. [sent-2, score-0.313]
</p><p>3 This is precisely the situation where basic research might hope to have the greatest impact. [sent-3, score-0.873]
</p><p>4 Yahoo Research understands research including publishing, conferences, etc…   Yahoo Research is growing, so there is a chance I can help it grow well. [sent-4, score-0.931]
</p><p>5 Yahoo understands the internet, including (but not at all limited to) experimenting with research blogs. [sent-5, score-0.801]
</p><p>6 In the end, Yahoo Research seems like the place where I might have a chance to make the greatest difference. [sent-6, score-0.656]
</p><p>7 Yahoo (as a company) has made a strong bet on Yahoo Research. [sent-7, score-0.369]
</p><p>8 We-the-researchers all hope that bet will pay off, and this seems plausible. [sent-8, score-0.521]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('yahoo', 0.689), ('understands', 0.274), ('bet', 0.259), ('greatest', 0.259), ('research', 0.228), ('chance', 0.138), ('contract', 0.137), ('including', 0.12), ('ends', 0.118), ('join', 0.114), ('grow', 0.111), ('hope', 0.106), ('deciding', 0.105), ('experimenting', 0.102), ('company', 0.1), ('pay', 0.096), ('precisely', 0.092), ('fun', 0.092), ('publishing', 0.09), ('growing', 0.087), ('situation', 0.085), ('york', 0.081), ('internet', 0.078), ('limited', 0.077), ('certainly', 0.074), ('running', 0.073), ('place', 0.073), ('end', 0.065), ('might', 0.064), ('trying', 0.063), ('etc', 0.062), ('help', 0.06), ('seems', 0.06), ('reasons', 0.059), ('strong', 0.058), ('ll', 0.058), ('conferences', 0.057), ('made', 0.052), ('hard', 0.049), ('basic', 0.039), ('make', 0.033), ('like', 0.029), ('new', 0.026), ('many', 0.018), ('learning', 0.009)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="175-tfidf-1" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>Introduction: I will join  Yahoo Research  (in New York) after my contract ends at  TTI-Chicago .
 
The deciding reasons are:
  
 Yahoo is running into many hard learning problems.  This is precisely the situation where basic research might hope to have the greatest impact. 
 Yahoo Research understands research including publishing, conferences, etc… 
 Yahoo Research is growing, so there is a chance I can help it grow well. 
 Yahoo understands the internet, including (but not at all limited to) experimenting with research blogs. 
  
In the end, Yahoo Research seems like the place where I might have a chance to make the greatest difference.  
 
Yahoo (as a company) has made a strong bet on Yahoo Research.  We-the-researchers all hope that bet will pay off, and this seems plausible.  I’ll certainly have fun trying.</p><p>2 0.30142906 <a title="175-tfidf-2" href="../hunch_net-2006/hunch_net-2006-02-11-Yahoo%26%238217%3Bs_Learning_Problems..html">156 hunch net-2006-02-11-Yahoo&#8217;s Learning Problems.</a></p>
<p>Introduction: I just visited  Yahoo Research  which has several fundamental learning problems near to (or beyond) the set of problems we know how to solve well.  Here are 3 of them.
  
  Ranking   This is the canonical problem of all search engines.  It is made extra difficult for several reasons.
 
 There is relatively little “good” supervised learning data and a great deal of data with some signal (such as click through rates). 
 The learning must occur in a partially adversarial environment. Many people very actively attempt to place themselves at the top of 
rankings. 
 It is not even quite clear whether the problem should be posed as ‘ranking’ or as ‘regression’ which is then used to produce a 
ranking. 
 
 
  Collaborative filtering  Yahoo has a large number of recommendation systems for music, movies, etc…  In these sorts of systems, users specify how they liked a set of things, and then the system can (hopefully) find some more examples of things they might like 
by reasoning across multiple</p><p>3 0.26928869 <a title="175-tfidf-3" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>Introduction: Yahoo! laid off people .  Unlike every previous time there have been layoffs, this is serious for  Yahoo! Research .  
 
We had advanced warning from  Prabhakar  through the  simple act of leaving .  Yahoo! Research was a world class organization that Prabhakar recruited much of personally, so it is deeply implausible that he would spontaneously decide to leave.  My first thought when I saw the news was “Uhoh,  Rob  said that he knew it was serious when the head of ATnT Research left.”  In this case it was even more significant, because Prabhakar recruited me on the premise that Y!R was an experiment in how research should be done: via a combination of high quality people and high engagement with the company.  Prabhakar’s departure is a clear end to that experiment.
 
The result is ambiguous from a business perspective.  Y!R clearly was not capable of saving the company from its illnesses.  I’m not privy to the internal accounting of impact and this is the kind of subject where there c</p><p>4 0.19744368 <a title="175-tfidf-4" href="../hunch_net-2011/hunch_net-2011-02-25-Yahoo%21_Machine_Learning_grant_due_March_11.html">425 hunch net-2011-02-25-Yahoo! Machine Learning grant due March 11</a></p>
<p>Introduction: Yahoo!’s  Key Scientific Challenges  for  Machine Learning  grant applications are due March 11.  If you are a student working on relevant research, please consider applying.  It’s for $5K of unrestricted funding.</p><p>5 0.16417003 <a title="175-tfidf-5" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<p>Introduction: According to the  New York Times ,  Yahoo is releasing Project Panama shortly .  Project Panama is about better predicting which advertisements are relevant to a search, implying a higher click through rate, implying larger income for  Yahoo .  There are two things that seem interesting here:
  
 A significant portion of that improved accuracy is almost certainly machine learning at work. 
 The quantitative effect is huge—the estimate in the article is $600*10 6 . 
  
 Google  already has such improvements and  Microsoft Search  is surely working on them, which suggest this is (perhaps) a $10 9  per year machine learning problem. 
 
The exact methodology under use is unlikely to be publicly discussed in the near future because of the competitive enivironment.  Hopefully we’ll have some public “war stories” at some point in the future when this information becomes less sensitive.  For now, it’s reassuring to simply note that machine learning is having a big impact.</p><p>6 0.13365734 <a title="175-tfidf-6" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>7 0.12766729 <a title="175-tfidf-7" href="../hunch_net-2005/hunch_net-2005-10-03-Not_ICML.html">117 hunch net-2005-10-03-Not ICML</a></p>
<p>8 0.10688657 <a title="175-tfidf-8" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>9 0.10421078 <a title="175-tfidf-9" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>10 0.10342235 <a title="175-tfidf-10" href="../hunch_net-2005/hunch_net-2005-10-12-The_unrealized_potential_of_the_research_lab.html">121 hunch net-2005-10-12-The unrealized potential of the research lab</a></p>
<p>11 0.10163535 <a title="175-tfidf-11" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>12 0.095266514 <a title="175-tfidf-12" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>13 0.092388511 <a title="175-tfidf-13" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>14 0.087890036 <a title="175-tfidf-14" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>15 0.08476571 <a title="175-tfidf-15" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>16 0.083051659 <a title="175-tfidf-16" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>17 0.07367368 <a title="175-tfidf-17" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>18 0.073558405 <a title="175-tfidf-18" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>19 0.070456088 <a title="175-tfidf-19" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>20 0.070389099 <a title="175-tfidf-20" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">324 hunch net-2008-11-09-A Healthy  COLT</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.114), (1, -0.063), (2, -0.131), (3, 0.106), (4, -0.134), (5, -0.032), (6, -0.002), (7, 0.06), (8, -0.127), (9, -0.023), (10, 0.075), (11, 0.055), (12, -0.028), (13, 0.01), (14, -0.029), (15, 0.167), (16, -0.126), (17, -0.031), (18, -0.068), (19, -0.194), (20, 0.121), (21, 0.043), (22, 0.111), (23, -0.023), (24, 0.087), (25, 0.144), (26, 0.027), (27, -0.079), (28, -0.072), (29, -0.008), (30, 0.015), (31, -0.017), (32, -0.082), (33, 0.045), (34, 0.048), (35, 0.104), (36, -0.001), (37, 0.031), (38, -0.089), (39, 0.02), (40, -0.0), (41, -0.058), (42, -0.024), (43, 0.031), (44, 0.009), (45, 0.007), (46, 0.103), (47, 0.124), (48, 0.014), (49, 0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96654671 <a title="175-lsi-1" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>Introduction: I will join  Yahoo Research  (in New York) after my contract ends at  TTI-Chicago .
 
The deciding reasons are:
  
 Yahoo is running into many hard learning problems.  This is precisely the situation where basic research might hope to have the greatest impact. 
 Yahoo Research understands research including publishing, conferences, etc… 
 Yahoo Research is growing, so there is a chance I can help it grow well. 
 Yahoo understands the internet, including (but not at all limited to) experimenting with research blogs. 
  
In the end, Yahoo Research seems like the place where I might have a chance to make the greatest difference.  
 
Yahoo (as a company) has made a strong bet on Yahoo Research.  We-the-researchers all hope that bet will pay off, and this seems plausible.  I’ll certainly have fun trying.</p><p>2 0.7606135 <a title="175-lsi-2" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>Introduction: Yahoo! laid off people .  Unlike every previous time there have been layoffs, this is serious for  Yahoo! Research .  
 
We had advanced warning from  Prabhakar  through the  simple act of leaving .  Yahoo! Research was a world class organization that Prabhakar recruited much of personally, so it is deeply implausible that he would spontaneously decide to leave.  My first thought when I saw the news was “Uhoh,  Rob  said that he knew it was serious when the head of ATnT Research left.”  In this case it was even more significant, because Prabhakar recruited me on the premise that Y!R was an experiment in how research should be done: via a combination of high quality people and high engagement with the company.  Prabhakar’s departure is a clear end to that experiment.
 
The result is ambiguous from a business perspective.  Y!R clearly was not capable of saving the company from its illnesses.  I’m not privy to the internal accounting of impact and this is the kind of subject where there c</p><p>3 0.7382912 <a title="175-lsi-3" href="../hunch_net-2006/hunch_net-2006-02-11-Yahoo%26%238217%3Bs_Learning_Problems..html">156 hunch net-2006-02-11-Yahoo&#8217;s Learning Problems.</a></p>
<p>Introduction: I just visited  Yahoo Research  which has several fundamental learning problems near to (or beyond) the set of problems we know how to solve well.  Here are 3 of them.
  
  Ranking   This is the canonical problem of all search engines.  It is made extra difficult for several reasons.
 
 There is relatively little “good” supervised learning data and a great deal of data with some signal (such as click through rates). 
 The learning must occur in a partially adversarial environment. Many people very actively attempt to place themselves at the top of 
rankings. 
 It is not even quite clear whether the problem should be posed as ‘ranking’ or as ‘regression’ which is then used to produce a 
ranking. 
 
 
  Collaborative filtering  Yahoo has a large number of recommendation systems for music, movies, etc…  In these sorts of systems, users specify how they liked a set of things, and then the system can (hopefully) find some more examples of things they might like 
by reasoning across multiple</p><p>4 0.69051582 <a title="175-lsi-4" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<p>Introduction: According to the  New York Times ,  Yahoo is releasing Project Panama shortly .  Project Panama is about better predicting which advertisements are relevant to a search, implying a higher click through rate, implying larger income for  Yahoo .  There are two things that seem interesting here:
  
 A significant portion of that improved accuracy is almost certainly machine learning at work. 
 The quantitative effect is huge—the estimate in the article is $600*10 6 . 
  
 Google  already has such improvements and  Microsoft Search  is surely working on them, which suggest this is (perhaps) a $10 9  per year machine learning problem. 
 
The exact methodology under use is unlikely to be publicly discussed in the near future because of the competitive enivironment.  Hopefully we’ll have some public “war stories” at some point in the future when this information becomes less sensitive.  For now, it’s reassuring to simply note that machine learning is having a big impact.</p><p>5 0.65273643 <a title="175-lsi-5" href="../hunch_net-2011/hunch_net-2011-02-25-Yahoo%21_Machine_Learning_grant_due_March_11.html">425 hunch net-2011-02-25-Yahoo! Machine Learning grant due March 11</a></p>
<p>Introduction: Yahoo!’s  Key Scientific Challenges  for  Machine Learning  grant applications are due March 11.  If you are a student working on relevant research, please consider applying.  It’s for $5K of unrestricted funding.</p><p>6 0.64163709 <a title="175-lsi-6" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>7 0.59899819 <a title="175-lsi-7" href="../hunch_net-2005/hunch_net-2005-10-12-The_unrealized_potential_of_the_research_lab.html">121 hunch net-2005-10-12-The unrealized potential of the research lab</a></p>
<p>8 0.57493365 <a title="175-lsi-8" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>9 0.47752479 <a title="175-lsi-9" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>10 0.47312996 <a title="175-lsi-10" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>11 0.47039357 <a title="175-lsi-11" href="../hunch_net-2005/hunch_net-2005-12-22-Yes_%2C_I_am_applying.html">142 hunch net-2005-12-22-Yes , I am applying</a></p>
<p>12 0.46844351 <a title="175-lsi-12" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>13 0.45427507 <a title="175-lsi-13" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>14 0.4413 <a title="175-lsi-14" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>15 0.44115242 <a title="175-lsi-15" href="../hunch_net-2007/hunch_net-2007-07-13-The_View_From_China.html">255 hunch net-2007-07-13-The View From China</a></p>
<p>16 0.4202106 <a title="175-lsi-16" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>17 0.41834641 <a title="175-lsi-17" href="../hunch_net-2005/hunch_net-2005-10-03-Not_ICML.html">117 hunch net-2005-10-03-Not ICML</a></p>
<p>18 0.41220212 <a title="175-lsi-18" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>19 0.39497104 <a title="175-lsi-19" href="../hunch_net-2005/hunch_net-2005-05-17-A_Short_Guide_to_PhD_Graduate_Study.html">73 hunch net-2005-05-17-A Short Guide to PhD Graduate Study</a></p>
<p>20 0.38969931 <a title="175-lsi-20" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(27, 0.174), (38, 0.051), (53, 0.055), (55, 0.122), (94, 0.021), (95, 0.063), (96, 0.351)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91089463 <a title="175-lda-1" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>Introduction: I will join  Yahoo Research  (in New York) after my contract ends at  TTI-Chicago .
 
The deciding reasons are:
  
 Yahoo is running into many hard learning problems.  This is precisely the situation where basic research might hope to have the greatest impact. 
 Yahoo Research understands research including publishing, conferences, etc… 
 Yahoo Research is growing, so there is a chance I can help it grow well. 
 Yahoo understands the internet, including (but not at all limited to) experimenting with research blogs. 
  
In the end, Yahoo Research seems like the place where I might have a chance to make the greatest difference.  
 
Yahoo (as a company) has made a strong bet on Yahoo Research.  We-the-researchers all hope that bet will pay off, and this seems plausible.  I’ll certainly have fun trying.</p><p>2 0.81997424 <a title="175-lda-2" href="../hunch_net-2005/hunch_net-2005-04-06-Structured_Regret_Minimization.html">53 hunch net-2005-04-06-Structured Regret Minimization</a></p>
<p>Introduction: Geoff Gordon made an interesting presentation at the  snowbird learning workshop  discussing the use of no-regret algorithms for the use of several robot-related learning problems.    There seems to be a draft  here .  This seems interesting in two ways:
  
  Drawback Removal  One of the significant problems with these online algorithms is that they can’t cope with structure very easily.  This drawback is addressed for certain structures. 
  Experiments  One criticism of such algorithms is that they are too “worst case”.   Several experiments suggest that protecting yourself against this worst case does not necessarily incur a great loss.</p><p>3 0.7971096 <a title="175-lda-3" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<p>Introduction: Many Machine Learning related events are coming up this fall.
  
  September 9 ,  abstracts for the New York Machine Learning Symposium  are due.  Send a 2 page pdf, if interested, and note that we:
 
 widened submissions to be from anybody rather than students. 
 set aside a larger fraction of time for contributed submissions.  
 
 
  September 15 , there is a  machine learning meetup , where I’ll be discussing terascale learning at AOL. 
  September 16 , there is a  CS&Econ; day  at New York Academy of Sciences.  This is not ML focused, but it’s easy to imagine interest. 
  September 23 and later   NIPS workshop  submissions start coming due.  As usual, there are too many good ones, so I won’t be able to attend all those that interest me.  I do hope some workshop makers consider ICML this coming summer, as we are increasing to a 2 day format for you.  Here are a few that interest me:
 
  Big Learning  is about dealing with lots of data.  Abstracts are due  September 30 . 
 The  Bayes</p><p>4 0.76844376 <a title="175-lda-4" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provost  gave a talk at the ICML  metalearning workshop  on “metalearning” and the “no free lunch theorem” which seems worth summarizing.
 
As a review: the no free lunch theorem is the most complicated way we know of to say that a  bias  is required in order to learn.  The simplest way to see this is in a nonprobabilistic setting.  If you are given examples of the form  (x,y)  and you wish to predict  y  from  x  then any prediction mechanism errs half the time in expectation over all sequences of examples.  The proof of this is very simple: on every example a predictor must make some prediction and by symmetry over the set of sequences it will be wrong half the time and right half the time.  The basic idea of this proof has been applied to many other settings.
 
The simplistic interpretation of this theorem which many people jump to is “machine learning is dead” since there can be no single learning algorithm which can solve all learning problems.  This is the wrong way to thi</p><p>5 0.65599829 <a title="175-lda-5" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pool  and I recently discussed the similarities and differences between academia and open source programming.   
 
Similarities:
  
  Cost profile   Research and programming share approximately the same cost profile: A large upfront effort is required to produce something useful, and then “anyone” can use it.  (The “anyone” is not quite right for either group because only sufficiently technical people could use it.) 
  Wealth profile  A “wealthy” academic or open source programmer is someone who has contributed a lot to other people in research or programs.  Much of academia is a “gift culture”: whoever gives the most is most respected. 
  Problems   Both academia and open source programming suffer from similar problems.
 
 Whether or not (and which) open source program is used are perhaps too-often personality driven rather than driven by capability or usefulness.  Similar phenomena can happen in academia with respect to directions of research. 
 Funding is often a problem for</p><p>6 0.56518865 <a title="175-lda-6" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>7 0.53952265 <a title="175-lda-7" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>8 0.53460556 <a title="175-lda-8" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>9 0.53163165 <a title="175-lda-9" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>10 0.53101343 <a title="175-lda-10" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>11 0.52857721 <a title="175-lda-11" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>12 0.52853811 <a title="175-lda-12" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>13 0.52682167 <a title="175-lda-13" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>14 0.52539784 <a title="175-lda-14" href="../hunch_net-2010/hunch_net-2010-07-18-ICML_%26%23038%3B_COLT_2010.html">403 hunch net-2010-07-18-ICML &#038; COLT 2010</a></p>
<p>15 0.5247491 <a title="175-lda-15" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>16 0.52139848 <a title="175-lda-16" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>17 0.51992494 <a title="175-lda-17" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>18 0.51940644 <a title="175-lda-18" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>19 0.51834112 <a title="175-lda-19" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>20 0.51695681 <a title="175-lda-20" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
