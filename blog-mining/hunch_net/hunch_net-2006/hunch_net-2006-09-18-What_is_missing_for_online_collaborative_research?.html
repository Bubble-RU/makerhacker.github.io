<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>208 hunch net-2006-09-18-What is missing for online collaborative research?</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-208" href="#">hunch_net-2006-208</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>208 hunch net-2006-09-18-What is missing for online collaborative research?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-208-html" href="http://hunch.net/?p=214">html</a></p><p>Introduction: The internet has recently made the research process much smoother: papers are
easy to obtain, citations are easy to follow, and unpublished "tutorials" are
often available. Yet, new research fields can look very complicated to
outsiders or newcomers. Every paper is like a small piece of an unfinished
jigsaw puzzle: to understand just one publication, a researcher without
experience in the field will typically have to follow several layers of
citations, and many of the papers he encounters have a great deal of repeated
information. Furthermore, from one publication to the next, notation and
terminology may not be consistent which can further confuse the reader.But the
internet is now proving to be an extremely useful medium for collaboration and
knowledge aggregation. Online forums allow users to ask and answer questions
and to share ideas. The recent phenomenon of Wikipedia provides a proof-of-
concept for the "anyone can edit" system. Can such models be used to
facilitate research and</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wikipedia', 0.385), ('takeoff', 0.173), ('handles', 0.154), ('framework', 0.149), ('facilitate', 0.143), ('site', 0.141), ('handling', 0.135), ('contributed', 0.135), ('disagreements', 0.135), ('collaboration', 0.135), ('discussion', 0.129), ('incentives', 0.128), ('publication', 0.123), ('research', 0.122), ('entry', 0.119), ('citations', 0.109), ('version', 0.104), ('system', 0.102), ('achieved', 0.102), ('online', 0.101)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="208-tfidf-1" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>Introduction: The internet has recently made the research process much smoother: papers are
easy to obtain, citations are easy to follow, and unpublished "tutorials" are
often available. Yet, new research fields can look very complicated to
outsiders or newcomers. Every paper is like a small piece of an unfinished
jigsaw puzzle: to understand just one publication, a researcher without
experience in the field will typically have to follow several layers of
citations, and many of the papers he encounters have a great deal of repeated
information. Furthermore, from one publication to the next, notation and
terminology may not be consistent which can further confuse the reader.But the
internet is now proving to be an extremely useful medium for collaboration and
knowledge aggregation. Online forums allow users to ask and answer questions
and to share ideas. The recent phenomenon of Wikipedia provides a proof-of-
concept for the "anyone can edit" system. Can such models be used to
facilitate research and</p><p>2 0.2372344 <a title="208-tfidf-2" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>Introduction: The internet has significantly effected the way we do research but it's
capabilities have not yet been fully realized.First, let's acknowledge some
known effects.Self-publishingBy default, all researchers in machine learning
(and more generally computer science and physics) place their papers online
for anyone to download. The exact mechanism differs--physicists tend to use a
central repository (Arxiv) while computer scientists tend to place the papers
on their webpage. Arxiv has been slowly growing in subject breadth so it now
sometimes used by computer scientists.CollaborationEmail has enabled working
remotely with coauthors. This has allowed collaborationis which would not
otherwise have been possible and generally speeds research.Now, let's look at
attempts to go further.Blogs(like this one) allow public discussion about
topics which are not easily categorized as "a new idea in machine learning"
(like this topic).Organizationof some subfield of research. This
includesSatinder Singh</p><p>3 0.14805096 <a title="208-tfidf-3" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>Introduction: How do you create an optimal environment for research? Here are some essential
ingredients that I see.Stability. University-based research is relatively good
at this. On any particular day, researchers face choices in what they will
work on. A very common tradeoff is between:easy smalldifficult bigFor
researchers without stability, the 'easy small' option wins. This is often
"ok"--a series of incremental improvements on the state of the art can add up
to something very beneficial. However, it misses one of the big potentials of
research: finding entirely new and better ways of doing things.Stability comes
in many forms. The prototypical example is tenure at a university--a tenured
professor is almost imposssible to fire which means that the professor has the
freedom to consider far horizon activities. An iron-clad guarantee of a
paycheck is not necessary--industrial research labs have succeeded well with
research positions of indefinite duration. Atnt research was a great example
of th</p><p>4 0.12125604 <a title="208-tfidf-4" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>Introduction: In the quest to understand what good reviewing is, perhaps it's worthwhile to
think about what good research is. One way to think about good research is in
terms of a producer/consumer model.In the producer/consumer model of research,
for any element of research there are producers (authors and coauthors of
papers, for example) and consumers (people who use the papers to make new
papers or code solving problems). An produced bit of research is judged as
"good" if it is used by many consumers. There are two basic questions which
immediately arise:Is this a good model of research?Are there alternatives?The
producer/consumer model has some difficulties which can be (partially)
addressed.Disconnect.A group of people doing research on some subject may
become disconnected from the rest of the world. Each person uses the research
of other people in the group so it appears good research is being done, but
the group has no impact on the rest of the world. One way to detect this is by
looking at</p><p>5 0.11397922 <a title="208-tfidf-5" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>Introduction: One of the enduring stereotypes of academia is that people spend a great deal
of intelligence, time, and effort finding complexity rather than simplicity.
This is at least anecdotally true in my experience.Math++Several people have
found that adding useless math makes their paper more publishable as evidenced
by a reject-add-accept sequence.8 page minimumWho submitted a paper
toICMLviolating the 8 page minimum? Every author fears that the reviewers
won't take their work seriously unless the allowed length is fully used. The
best minimum violation I know isAdam's paper at SODA ongenerating random
factored numbers, but this is deeply exceptional. It's a fair bet that 90% of
papers submitted are exactly at the page limit. We could imagine that this is
because papers naturally take more space, but few people seem to be clamoring
for more space.JournalongHas anyone been asked to review a 100 page journal
paper? I have. Journal papers can be nice, because they give an author the
opportunity</p><p>6 0.11112233 <a title="208-tfidf-6" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>7 0.10665634 <a title="208-tfidf-7" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>8 0.10551248 <a title="208-tfidf-8" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>9 0.10531108 <a title="208-tfidf-9" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>10 0.10446614 <a title="208-tfidf-10" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>11 0.10439996 <a title="208-tfidf-11" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>12 0.10180961 <a title="208-tfidf-12" href="../hunch_net-2008/hunch_net-2008-07-04-More_Presentation_Preparation.html">307 hunch net-2008-07-04-More Presentation Preparation</a></p>
<p>13 0.098324783 <a title="208-tfidf-13" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>14 0.095992818 <a title="208-tfidf-14" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>15 0.095557123 <a title="208-tfidf-15" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>16 0.0952584 <a title="208-tfidf-16" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>17 0.091648377 <a title="208-tfidf-17" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>18 0.089955233 <a title="208-tfidf-18" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>19 0.089679621 <a title="208-tfidf-19" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>20 0.088955618 <a title="208-tfidf-20" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.244), (1, 0.076), (2, 0.058), (3, -0.094), (4, 0.035), (5, 0.039), (6, 0.05), (7, -0.009), (8, -0.052), (9, 0.043), (10, 0.036), (11, 0.044), (12, -0.041), (13, 0.04), (14, -0.053), (15, -0.007), (16, 0.044), (17, -0.015), (18, -0.051), (19, -0.023), (20, 0.036), (21, -0.037), (22, 0.002), (23, -0.058), (24, -0.068), (25, -0.081), (26, 0.011), (27, -0.019), (28, -0.109), (29, -0.024), (30, -0.01), (31, 0.092), (32, 0.006), (33, -0.057), (34, 0.031), (35, 0.044), (36, 0.081), (37, 0.031), (38, -0.044), (39, 0.066), (40, -0.077), (41, 0.025), (42, 0.112), (43, -0.031), (44, -0.103), (45, -0.005), (46, 0.038), (47, -0.071), (48, -0.001), (49, -0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96492064 <a title="208-lsi-1" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>Introduction: The internet has recently made the research process much smoother: papers are
easy to obtain, citations are easy to follow, and unpublished "tutorials" are
often available. Yet, new research fields can look very complicated to
outsiders or newcomers. Every paper is like a small piece of an unfinished
jigsaw puzzle: to understand just one publication, a researcher without
experience in the field will typically have to follow several layers of
citations, and many of the papers he encounters have a great deal of repeated
information. Furthermore, from one publication to the next, notation and
terminology may not be consistent which can further confuse the reader.But the
internet is now proving to be an extremely useful medium for collaboration and
knowledge aggregation. Online forums allow users to ask and answer questions
and to share ideas. The recent phenomenon of Wikipedia provides a proof-of-
concept for the "anyone can edit" system. Can such models be used to
facilitate research and</p><p>2 0.79376334 <a title="208-lsi-2" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>Introduction: The internet has significantly effected the way we do research but it's
capabilities have not yet been fully realized.First, let's acknowledge some
known effects.Self-publishingBy default, all researchers in machine learning
(and more generally computer science and physics) place their papers online
for anyone to download. The exact mechanism differs--physicists tend to use a
central repository (Arxiv) while computer scientists tend to place the papers
on their webpage. Arxiv has been slowly growing in subject breadth so it now
sometimes used by computer scientists.CollaborationEmail has enabled working
remotely with coauthors. This has allowed collaborationis which would not
otherwise have been possible and generally speeds research.Now, let's look at
attempts to go further.Blogs(like this one) allow public discussion about
topics which are not easily categorized as "a new idea in machine learning"
(like this topic).Organizationof some subfield of research. This
includesSatinder Singh</p><p>3 0.67427075 <a title="208-lsi-3" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<p>Introduction: I have decided to run a weblog on machine learning and learning theory
research. Here are some reasons:1) Weblogs enable new functionality:Public
comment on papers. No mechanism for this exists at conferences and most
journals. I have encountered it once for asciencepaper. Some communities have
mailing lists supporting this, but not machine learning or learning theory. I
have often read papers and found myself wishing there was some method to
consider other's questions and read the replies.Conference shortlists. One of
the most common conversations at a conference is "what did you find
interesting?" There is no explicit mechanism for sharing this information at
conferences, and it's easy to imagine that it would be handy to do
so.Evaluation and comment on research directions. Papers are almost
exclusively about new research, rather than evaluation (and consideration) of
research directions. This last role is satisfied by funding agencies to some
extent, but that is a private debate of</p><p>4 0.66926759 <a title="208-lsi-4" href="../hunch_net-2005/hunch_net-2005-02-25-Why_Papers%3F.html">30 hunch net-2005-02-25-Why Papers?</a></p>
<p>Introduction: Makc asked a goodquestionin comments--"Why bother to make a paper, at all?"
There are several reasons for writing papers which may not be immediately
obvious to people not in academia.The basic idea is that papers have
considerably more utility than the obvious "present an idea".Papers are a
formalized units of work. Academics (especially young ones) are often judged
on the number of papers they produce.Papers have a formalized method of citing
and crediting other--the bibliography. Academics (especially older ones) are
often judged on the number of citations they receive.Papers enable a "more
fair" anonymous review. Conferences receivemanypapers, from which a subset are
selected. Discussion forums are inherently not anonymous for anyone who wants
to build a reputation for good work.Papers are an excuse to meet your friends.
Papers are the content of conferences, but much of what you do is talk to
friends about interesting problems while there. Sometimes you even solve
them.Papers are</p><p>5 0.65435654 <a title="208-lsi-5" href="../hunch_net-2009/hunch_net-2009-12-09-Future_Publication_Models_%40_NIPS.html">382 hunch net-2009-12-09-Future Publication Models @ NIPS</a></p>
<p>Introduction: Yesterday, there was a discussion aboutfuture publication models at
NIPS.YannandZoubinhave specific detailed proposals which I'll add links to
when I get them (Yann's proposalandZoubin's proposal).What struck me about the
discussion is that there are many simultaneous concerns as well as many
simultaneous proposals, which makes it difficult to keep all the distinctions
straight in a verbal conversation. It also seemed like people were serious
enough about this that we may see some real movement. Certainly, my personal
experience motivates that as I'veposted many timesabout the substantial flaws
in our review process, including some very poor personal experiences.Concerns
include the following:(Several) Reviewers are overloaded, boosting the noise
in decision making.(Yann) A new system should run with as little built-in
delay and friction to the process of research as possible.(Hanna
Wallach(updated)) Double-blind review is particularly important for people who
are unknown or from an un</p><p>6 0.62622273 <a title="208-lsi-6" href="../hunch_net-2005/hunch_net-2005-03-29-Academic_Mechanism_Design.html">48 hunch net-2005-03-29-Academic Mechanism Design</a></p>
<p>7 0.62242031 <a title="208-lsi-7" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>8 0.61729574 <a title="208-lsi-8" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>9 0.61058378 <a title="208-lsi-9" href="../hunch_net-2006/hunch_net-2006-04-14-JMLR_is_a_success.html">172 hunch net-2006-04-14-JMLR is a success</a></p>
<p>10 0.59212452 <a title="208-lsi-10" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>11 0.59151906 <a title="208-lsi-11" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>12 0.58654863 <a title="208-lsi-12" href="../hunch_net-2013/hunch_net-2013-01-31-Remote_large_scale_learning_class_participation.html">479 hunch net-2013-01-31-Remote large scale learning class participation</a></p>
<p>13 0.58425397 <a title="208-lsi-13" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>14 0.57922369 <a title="208-lsi-14" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>15 0.56748688 <a title="208-lsi-15" href="../hunch_net-2008/hunch_net-2008-07-02-Proprietary_Data_in_Academic_Research%3F.html">306 hunch net-2008-07-02-Proprietary Data in Academic Research?</a></p>
<p>16 0.55812538 <a title="208-lsi-16" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>17 0.55802464 <a title="208-lsi-17" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>18 0.55601382 <a title="208-lsi-18" href="../hunch_net-2013/hunch_net-2013-06-29-The_Benefits_of_Double-Blind_Review.html">485 hunch net-2013-06-29-The Benefits of Double-Blind Review</a></p>
<p>19 0.55119449 <a title="208-lsi-19" href="../hunch_net-2009/hunch_net-2009-07-09-The_Machine_Learning_Forum.html">363 hunch net-2009-07-09-The Machine Learning Forum</a></p>
<p>20 0.54421991 <a title="208-lsi-20" href="../hunch_net-2005/hunch_net-2005-05-29-Bad_ideas.html">76 hunch net-2005-05-29-Bad ideas</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.034), (39, 0.019), (42, 0.187), (44, 0.022), (47, 0.022), (68, 0.013), (74, 0.621), (95, 0.012)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98282748 <a title="208-lda-1" href="../hunch_net-2007/hunch_net-2007-12-17-New_Machine_Learning_mailing_list.html">278 hunch net-2007-12-17-New Machine Learning mailing list</a></p>
<p>Introduction: IMLS(which is the nonprofit running ICML) has setup a new mailing list
forMachine Learning News. The list address is ML-news@googlegroups.com, and
signup requires a google account (which you can create). Only members can send
messages.</p><p>2 0.98117095 <a title="208-lda-2" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>Introduction: The health ofCOLT(Conference on Learning Theory or Computational Learning
Theory depending on who you ask) has been questioned over the last few years.
Low points for the conference occurred whenEuroCOLTmerged with COLT in 2001,
and the attendance at the 2002 Sydney COLT fell to a new low. This occurred in
the general context of machine learning conferences rising in both number and
size over the last decade.Any discussion ofwhyCOLT has had difficulties is
inherently controversial as is any story about well-intentioned people making
the wrong decisions. Nevertheless, this may be worth discussing in the hope of
avoiding problems in the future and general understanding. In any such
discussion there is a strong tendency to identify with a conference/community
in a patriotic manner that is detrimental to thinking. Keep in mind that
conferences exist to further research.My understanding (I wasn't around) is
that COLT started as a subcommunity of the computer science theory community.
This i</p><p>3 0.98072141 <a title="208-lda-3" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>4 0.97764575 <a title="208-lda-4" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>Introduction: We just finished theChicago 2005 Machine Learning Summer School. The school
was 2 weeks long with about 130 (or 140 counting the speakers) participants.
For perspective, this is perhaps the largest graduate level machine learning
class I am aware of anywhere and anytime (previousMLSSs have been close).
Overall, it seemed to go well, although the students are the real authority on
this. For those who missed it, DVDs will be available from our Slovenian
friends. EmailMrs Spela Sitarof the Jozsef Stefan Institute for details.The
following are some notes for future planning and those interested.Good
DecisionsAcquiring the larger-than-necessary "Assembly Hall" atInternational
House. Our attendance came in well above our expectations, so this was a
critical early decision that made a huge difference.The invited speakers were
key. They made a huge difference in the quality of the content.Delegating
early and often was important. One key difficulty here is gauging how much a
volunteer can (or</p><p>5 0.97661477 <a title="208-lda-5" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>same-blog 6 0.966479 <a title="208-lda-6" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>7 0.94206578 <a title="208-lda-7" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>8 0.93030286 <a title="208-lda-8" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>9 0.88646084 <a title="208-lda-9" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>10 0.88317198 <a title="208-lda-10" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>11 0.86231774 <a title="208-lda-11" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>12 0.85534042 <a title="208-lda-12" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>13 0.84893715 <a title="208-lda-13" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>14 0.84104866 <a title="208-lda-14" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>15 0.83394134 <a title="208-lda-15" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>16 0.83161485 <a title="208-lda-16" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>17 0.8285082 <a title="208-lda-17" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>18 0.82768685 <a title="208-lda-18" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>19 0.82470328 <a title="208-lda-19" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>20 0.81923759 <a title="208-lda-20" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
