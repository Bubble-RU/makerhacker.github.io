<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>194 hunch net-2006-07-11-New Models</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-194" href="#">hunch_net-2006-194</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>194 hunch net-2006-07-11-New Models</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-194-html" href="http://hunch.net/?p=202">html</a></p><p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mathematical', 0.403), ('model', 0.382), ('models', 0.208), ('barriers', 0.169), ('new', 0.149), ('success', 0.139), ('end', 0.129), ('recognition', 0.128), ('publishing', 0.12), ('fields', 0.12), ('improving', 0.116), ('research', 0.109), ('yield', 0.108), ('limited', 0.103), ('failure', 0.102), ('rightness', 0.097), ('abstracted', 0.097), ('blunt', 0.097), ('inspiration', 0.097), ('investigates', 0.097)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999976 <a title="194-tfidf-1" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>2 0.27546722 <a title="194-tfidf-2" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>Introduction: I wanted to expand on thispostand some of the previousproblems/research
directionsabout where learning theory might make large strides.Why theory?The
essential reason for theory is "intuition extension". A very good applied
learning person can master some particular application domain yielding the
best computer algorithms for solving that problem. A very good theory can take
the intuitions discovered by this and other applied learning people and extend
them to new domains in a relatively automatic fashion. To do this, we take
these basic intuitions and try to find a mathematical model that:Explains the
basic intuitions.Makes new testable predictions about how to learn.Succeeds in
so learning.This is "intuition extension": taking what we have learned
somewhere else and applying it in new domains. It is fundamentally useful to
everyone because it increases the level of automation in solving
problems.Where next for learning theory?I like the analogy with physics. Back
before we-the-humans</p><p>3 0.21546189 <a title="194-tfidf-3" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>Introduction: In everyday use a model is a system which explains the behavior of some
system, hopefully at the level where some alteration of the model predicts
some alteration of the real-world system. In machine learning "model" has
several variant definitions.Everyday. The common definition is sometimes
used.Parameterized. Sometimes model is a short-hand for "parameterized model".
Here, it refers to a model with unspecified free parameters. In the Bayesian
learning approach, you typically have a prior over (everyday)
models.Predictive. Even further from everyday use is the predictive model.
Examples of this are "my model is a decision tree" or "my model is a support
vector machine". Here, there is no real sense in which an SVM explains the
underlying process. For example, an SVM tells us nothing in particular about
how alterations to the real-world system would create a change.Which
definition is being used at any particular time is important information. For
example, if it's a parameterized or p</p><p>4 0.18365154 <a title="194-tfidf-4" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced theNetflix
Prizecontest. They published a comprehensive dataset including more than 100
million movie ratings, which were performed by about 480,000 real customers on
17,770 movies.Ã‚ÂCompetitors in the challenge are required to estimate a few
million ratings.Ã‚ÂTo win the "grand prize," they need to deliver a 10%
improvement in the prediction error compared with the results of Cinematch,
Netflix's proprietary recommender system. Best current results deliver
9.12%improvement, which is quite close to the 10% goal, yet painfully
distant.Ã‚ÂThe Netflix Prize breathed new life and excitement into recommender
systems research. The competition allowed the wide research community to
access a large scale, real life dataset. Beyond this, the competition changed
the rules of the game. Claiming that your nice idea could outperform some
mediocre algorithms on some toy dataset is no longer acceptable. Now
researchers should face a new gol</p><p>5 0.17737754 <a title="194-tfidf-5" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>Introduction: Arecent discussionindicated that one goal of this blog might be to allow
people to post comments about recent papers that they liked. I think this
could potentially be very useful, especially for those with diverse interests
but only finite time to read through conference proceedings.ACL 2005recently
completed, and here are four papers from that conference that I thought were
either good or perhaps of interest to a machine learning audience.David
Chiang,A Hierarchical Phrase-Based Model for Statistical Machine Translation.
(Best paper award.) This paper takes the standard phrase-based MT model that
is popular in our field (basically, translate a sentence by individually
translating phrases and reordering them according to a complicated statistical
model) and extends it to take into account hierarchy in phrases, so that you
can learn things like "X 's Y" -> "Y de X" in chinese, where X and Y are
arbitrary phrases. This takes a step toward linguistic syntax for MT, which
our group is wor</p><p>6 0.17180528 <a title="194-tfidf-6" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>7 0.16213536 <a title="194-tfidf-7" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>8 0.12463174 <a title="194-tfidf-8" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>9 0.12267397 <a title="194-tfidf-9" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>10 0.12003819 <a title="194-tfidf-10" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>11 0.11969493 <a title="194-tfidf-11" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>12 0.11618321 <a title="194-tfidf-12" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>13 0.11461009 <a title="194-tfidf-13" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>14 0.11435349 <a title="194-tfidf-14" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>15 0.11064669 <a title="194-tfidf-15" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>16 0.11008091 <a title="194-tfidf-16" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>17 0.10780486 <a title="194-tfidf-17" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>18 0.10404391 <a title="194-tfidf-18" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>19 0.10367896 <a title="194-tfidf-19" href="../hunch_net-2005/hunch_net-2005-02-17-Learning_Research_Programs.html">21 hunch net-2005-02-17-Learning Research Programs</a></p>
<p>20 0.10050755 <a title="194-tfidf-20" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.252), (1, 0.025), (2, 0.041), (3, -0.121), (4, -0.005), (5, -0.03), (6, -0.17), (7, -0.017), (8, -0.089), (9, -0.061), (10, 0.079), (11, 0.016), (12, -0.032), (13, 0.075), (14, 0.012), (15, 0.173), (16, 0.138), (17, -0.173), (18, -0.079), (19, -0.101), (20, -0.054), (21, -0.095), (22, 0.063), (23, 0.042), (24, -0.088), (25, 0.061), (26, 0.061), (27, 0.045), (28, -0.092), (29, 0.026), (30, 0.038), (31, 0.047), (32, -0.08), (33, -0.017), (34, -0.032), (35, 0.029), (36, -0.105), (37, -0.07), (38, -0.08), (39, 0.023), (40, 0.017), (41, 0.11), (42, 0.038), (43, -0.035), (44, 0.093), (45, 0.048), (46, -0.077), (47, 0.065), (48, -0.046), (49, 0.028)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97133178 <a title="194-lsi-1" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>2 0.86717957 <a title="194-lsi-2" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>Introduction: In everyday use a model is a system which explains the behavior of some
system, hopefully at the level where some alteration of the model predicts
some alteration of the real-world system. In machine learning "model" has
several variant definitions.Everyday. The common definition is sometimes
used.Parameterized. Sometimes model is a short-hand for "parameterized model".
Here, it refers to a model with unspecified free parameters. In the Bayesian
learning approach, you typically have a prior over (everyday)
models.Predictive. Even further from everyday use is the predictive model.
Examples of this are "my model is a decision tree" or "my model is a support
vector machine". Here, there is no real sense in which an SVM explains the
underlying process. For example, an SVM tells us nothing in particular about
how alterations to the real-world system would create a change.Which
definition is being used at any particular time is important information. For
example, if it's a parameterized or p</p><p>3 0.77646852 <a title="194-lsi-3" href="../hunch_net-2005/hunch_net-2005-07-23-Interesting_papers_at_ACL.html">97 hunch net-2005-07-23-Interesting papers at ACL</a></p>
<p>Introduction: Arecent discussionindicated that one goal of this blog might be to allow
people to post comments about recent papers that they liked. I think this
could potentially be very useful, especially for those with diverse interests
but only finite time to read through conference proceedings.ACL 2005recently
completed, and here are four papers from that conference that I thought were
either good or perhaps of interest to a machine learning audience.David
Chiang,A Hierarchical Phrase-Based Model for Statistical Machine Translation.
(Best paper award.) This paper takes the standard phrase-based MT model that
is popular in our field (basically, translate a sentence by individually
translating phrases and reordering them according to a complicated statistical
model) and extends it to take into account hierarchy in phrases, so that you
can learn things like "X 's Y" -> "Y de X" in chinese, where X and Y are
arbitrary phrases. This takes a step toward linguistic syntax for MT, which
our group is wor</p><p>4 0.76678818 <a title="194-lsi-4" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>Introduction: I wanted to expand on thispostand some of the previousproblems/research
directionsabout where learning theory might make large strides.Why theory?The
essential reason for theory is "intuition extension". A very good applied
learning person can master some particular application domain yielding the
best computer algorithms for solving that problem. A very good theory can take
the intuitions discovered by this and other applied learning people and extend
them to new domains in a relatively automatic fashion. To do this, we take
these basic intuitions and try to find a mathematical model that:Explains the
basic intuitions.Makes new testable predictions about how to learn.Succeeds in
so learning.This is "intuition extension": taking what we have learned
somewhere else and applying it in new domains. It is fundamentally useful to
everyone because it increases the level of automation in solving
problems.Where next for learning theory?I like the analogy with physics. Back
before we-the-humans</p><p>5 0.74424237 <a title="194-lsi-5" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced theNetflix
Prizecontest. They published a comprehensive dataset including more than 100
million movie ratings, which were performed by about 480,000 real customers on
17,770 movies.Ã‚ÂCompetitors in the challenge are required to estimate a few
million ratings.Ã‚ÂTo win the "grand prize," they need to deliver a 10%
improvement in the prediction error compared with the results of Cinematch,
Netflix's proprietary recommender system. Best current results deliver
9.12%improvement, which is quite close to the 10% goal, yet painfully
distant.Ã‚ÂThe Netflix Prize breathed new life and excitement into recommender
systems research. The competition allowed the wide research community to
access a large scale, real life dataset. Beyond this, the competition changed
the rules of the game. Claiming that your nice idea could outperform some
mediocre algorithms on some toy dataset is no longer acceptable. Now
researchers should face a new gol</p><p>6 0.6461395 <a title="194-lsi-6" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>7 0.63934493 <a title="194-lsi-7" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>8 0.6183461 <a title="194-lsi-8" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>9 0.52014738 <a title="194-lsi-9" href="../hunch_net-2006/hunch_net-2006-07-05-more_icml_papers.html">189 hunch net-2006-07-05-more icml papers</a></p>
<p>10 0.50681567 <a title="194-lsi-10" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>11 0.50197726 <a title="194-lsi-11" href="../hunch_net-2010/hunch_net-2010-10-17-Partha_Niyogi_has_died.html">414 hunch net-2010-10-17-Partha Niyogi has died</a></p>
<p>12 0.49680135 <a title="194-lsi-12" href="../hunch_net-2005/hunch_net-2005-07-07-The_Limits_of_Learning_Theory.html">90 hunch net-2005-07-07-The Limits of Learning Theory</a></p>
<p>13 0.48993525 <a title="194-lsi-13" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>14 0.48696947 <a title="194-lsi-14" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>15 0.48376691 <a title="194-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>16 0.48269984 <a title="194-lsi-16" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>17 0.47801682 <a title="194-lsi-17" href="../hunch_net-2010/hunch_net-2010-05-10-Aggregation_of_estimators%2C_sparsity_in_high_dimension_and_computational_feasibility.html">398 hunch net-2010-05-10-Aggregation of estimators, sparsity in high dimension and computational feasibility</a></p>
<p>18 0.47115508 <a title="194-lsi-18" href="../hunch_net-2006/hunch_net-2006-04-09-Progress_in_Machine_Translation.html">171 hunch net-2006-04-09-Progress in Machine Translation</a></p>
<p>19 0.46707776 <a title="194-lsi-19" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>20 0.46404991 <a title="194-lsi-20" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.021), (42, 0.179), (45, 0.024), (74, 0.643), (95, 0.043)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98619658 <a title="194-lda-1" href="../hunch_net-2007/hunch_net-2007-12-17-New_Machine_Learning_mailing_list.html">278 hunch net-2007-12-17-New Machine Learning mailing list</a></p>
<p>Introduction: IMLS(which is the nonprofit running ICML) has setup a new mailing list
forMachine Learning News. The list address is ML-news@googlegroups.com, and
signup requires a google account (which you can create). Only members can send
messages.</p><p>2 0.97932804 <a title="194-lda-2" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>3 0.97793472 <a title="194-lda-3" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>Introduction: The health ofCOLT(Conference on Learning Theory or Computational Learning
Theory depending on who you ask) has been questioned over the last few years.
Low points for the conference occurred whenEuroCOLTmerged with COLT in 2001,
and the attendance at the 2002 Sydney COLT fell to a new low. This occurred in
the general context of machine learning conferences rising in both number and
size over the last decade.Any discussion ofwhyCOLT has had difficulties is
inherently controversial as is any story about well-intentioned people making
the wrong decisions. Nevertheless, this may be worth discussing in the hope of
avoiding problems in the future and general understanding. In any such
discussion there is a strong tendency to identify with a conference/community
in a patriotic manner that is detrimental to thinking. Keep in mind that
conferences exist to further research.My understanding (I wasn't around) is
that COLT started as a subcommunity of the computer science theory community.
This i</p><p>same-blog 4 0.97559714 <a title="194-lda-4" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?The most
immediate measurable objective of computer science research is publishing a
paper. The most difficult aspect of publishing a paper is having reviewers
accept and recommend it for publication. The simplest mechanism for doing this
is to show theoretical progress on some standard, well-known easily understood
problem.In doing this, we often fall into a local minima of the research
process. The basic problem in machine learning is that it is very unclear that
the mathematical model is the right one for the (or some) real problem. A good
mathematical model in machine learning should have one fundamental trait: it
should aid the design of effective learning algorithms. To date, our ability
to solve interesting learning problems (speech recognition, machine
translation, object recognition, etcâ&euro;Ś) remains limited (although improving),
so the "rightness" of our models is in doubt.If our mathematical models are
bad, t</p><p>5 0.97537488 <a title="194-lda-5" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>Introduction: We just finished theChicago 2005 Machine Learning Summer School. The school
was 2 weeks long with about 130 (or 140 counting the speakers) participants.
For perspective, this is perhaps the largest graduate level machine learning
class I am aware of anywhere and anytime (previousMLSSs have been close).
Overall, it seemed to go well, although the students are the real authority on
this. For those who missed it, DVDs will be available from our Slovenian
friends. EmailMrs Spela Sitarof the Jozsef Stefan Institute for details.The
following are some notes for future planning and those interested.Good
DecisionsAcquiring the larger-than-necessary "Assembly Hall" atInternational
House. Our attendance came in well above our expectations, so this was a
critical early decision that made a huge difference.The invited speakers were
key. They made a huge difference in the quality of the content.Delegating
early and often was important. One key difficulty here is gauging how much a
volunteer can (or</p><p>6 0.95938981 <a title="194-lda-6" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>7 0.93953192 <a title="194-lda-7" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>8 0.92371053 <a title="194-lda-8" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>9 0.87614655 <a title="194-lda-9" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>10 0.8711108 <a title="194-lda-10" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>11 0.85746157 <a title="194-lda-11" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>12 0.85486257 <a title="194-lda-12" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>13 0.84841639 <a title="194-lda-13" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>14 0.84010565 <a title="194-lda-14" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>15 0.8350358 <a title="194-lda-15" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>16 0.82893711 <a title="194-lda-16" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>17 0.82631904 <a title="194-lda-17" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>18 0.82143611 <a title="194-lda-18" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>19 0.81528324 <a title="194-lda-19" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>20 0.81227934 <a title="194-lda-20" href="../hunch_net-2012/hunch_net-2012-08-24-Patterns_for_research_in_machine_learning.html">471 hunch net-2012-08-24-Patterns for research in machine learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
