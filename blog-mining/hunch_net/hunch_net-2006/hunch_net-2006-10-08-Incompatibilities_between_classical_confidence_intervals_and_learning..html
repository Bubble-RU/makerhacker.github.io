<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-213" href="#">hunch_net-2006-213</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-213-html" href="http://hunch.net/?p=233">html</a></p><p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data
sourcesD,PrS ~ D(f(D) > g(S)) > 1-dwherefis some function of the distribution
(such as the mean) andgis some function of the observed sampleS. The
constraints onDcan vary between "Independent and identically distributed (IID)
samples from a gaussian with an unknown mean" to "IID samples from an
arbitrary distributionD". There are even some confidence intervals which do
not require IID samples.Classical confidence intervals often confuse people.
They donotsay "with high probability, for my observed sample, the bounds
holds". Instead, they tell you that if you reason according to the confidence
interval in the future (and the constraints onDare satisfied), then you are
not often wrong. Restated, they tell you something about what a safe procedure
is in a stochastic world wheredis the safety parameter.There are a number of
results in theoretical machine learning which use confidence intervals. For
example,TheE3alg</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('confidence', 0.567), ('intervals', 0.508), ('interval', 0.242), ('ofg', 0.163), ('mismatch', 0.134), ('iid', 0.12), ('semantics', 0.116), ('classical', 0.112), ('state', 0.102), ('tell', 0.094), ('regression', 0.087), ('high', 0.087), ('arbitrary', 0.084), ('constraints', 0.084), ('mean', 0.079), ('observed', 0.075), ('samples', 0.074), ('quantile', 0.073), ('form', 0.07), ('safety', 0.067)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="213-tfidf-1" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data
sourcesD,PrS ~ D(f(D) > g(S)) > 1-dwherefis some function of the distribution
(such as the mean) andgis some function of the observed sampleS. The
constraints onDcan vary between "Independent and identically distributed (IID)
samples from a gaussian with an unknown mean" to "IID samples from an
arbitrary distributionD". There are even some confidence intervals which do
not require IID samples.Classical confidence intervals often confuse people.
They donotsay "with high probability, for my observed sample, the bounds
holds". Instead, they tell you that if you reason according to the confidence
interval in the future (and the constraints onDare satisfied), then you are
not often wrong. Restated, they tell you something about what a safe procedure
is in a stochastic world wheredis the safety parameter.There are a number of
results in theoretical machine learning which use confidence intervals. For
example,TheE3alg</p><p>2 0.71576196 <a title="213-tfidf-2" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>Introduction: In many machine learning papers experiments are done and little confidence
bars are reported for the results. This often seems quite clear, until you
actually try to figure out what it means. There are several different kinds of
'confidence' being used, and it's easy to become confused.Confidence =
Probability. For those who haven't worried about confidence for a long time,
confidence is simply the probability of some event. You are confident about
events which have a large probability. This meaning of confidence is
inadequate in many applications because we want to reason about how much more
information we have, how much more is needed, and where to get it. As an
example, a learning algorithm might predict that the probability of an event
is0.5, but it's unclear if the probability is0.5because no examples have been
provided or0.5because many examples have been provided and the event is simply
fundamentally uncertain.Classical Confidence Intervals. These are common in
learning theory.</p><p>3 0.12443026 <a title="213-tfidf-3" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>Introduction: Bob Williamsonand I are the learning theory PC members atNIPSthis year. This
is some attempt to state the standards and tests I applied to the papers. I
think it is a good idea to talk about this for two reasons:Making community
standards a matter of public record seems healthy. It give us a chance to
debate what is and is not the right standard. It might even give us a bit more
consistency across the years.It may save us all time. There are a number of
papers submitted which just aren't there yet. Avoiding submitting is the right
decision in this case.There are several criteria for judging a paper. All of
these were active this year. Some criteria are uncontroversial while others
may be so.The paper must have a theorem establishing something new for which
it is possible to derive high confidence in the correctness of the results. A
surprising number of papers fail this test. This criteria seems essential to
the definition of "theory".Missing theorem statementMissing proofThis isn't an</p><p>4 0.12402014 <a title="213-tfidf-4" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>Introduction: What?Bounds are mathematical formulas relating observations to future error
rates assuming that data is drawn independently. In classical statistics, they
are calld confidence intervals.Why?Good Judgement. In many applications of
learning, it is desirable to know how well the learned predictor works in the
future. This helps you decide if the problem is solved or not.Learning
Essence. The form of some of these bounds helps you understand what the
essence of learning is.Algorithm Design. Some of these bounds suggest,
motivate, or even directly imply learning algorithms.What We Know NowThere are
several families of bounds, based on how information is used.Testing Bounds.
These are methods which use labeled data not used in training to estimate the
future error rate. Examples include thetest set bound,progressive
validationalsohereandhere,train and test bounds, and cross-validation (but see
thebig open problem). These techniques are the best available for goal (1)
above, but provide littl</p><p>5 0.10657197 <a title="213-tfidf-5" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>Introduction: Sham Kakadepoints out that we are missing a bound.Suppose we
havemsamplesxdrawn IID from some distributionD. Through the magic of
exponential moment method we know that:If the range ofxis bounded by an
interval of sizeI, aChernoff/Hoeffding style boundgives us a bound on the
deviations likeO(I/m0.5)(at least in crude form). A proof is on page 9here.If
the range ofxis bounded, and the variance (or a bound on the variance) is
known, thenBennett's boundcan give tighter results (*). This can be a huge
improvment when the true variance small.What's missing here is a bound that
depends on the observed variance rather than a bound on the variance. This
means that many people attempt to use Bennett's bound (incorrectly) by
plugging the observed variance in as the true variance, invalidating the bound
application. Most of the time, they get away with it, but this is a dangerous
move when doing machine learning. In machine learning, we are typically trying
to find a predictor with 0 expected los</p><p>6 0.10541869 <a title="213-tfidf-6" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>7 0.10295598 <a title="213-tfidf-7" href="../hunch_net-2007/hunch_net-2007-05-12-Loss_Function_Semantics.html">245 hunch net-2007-05-12-Loss Function Semantics</a></p>
<p>8 0.099562734 <a title="213-tfidf-8" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>9 0.098693252 <a title="213-tfidf-9" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>10 0.094966948 <a title="213-tfidf-10" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>11 0.093607701 <a title="213-tfidf-11" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>12 0.091663018 <a title="213-tfidf-12" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>13 0.090088323 <a title="213-tfidf-13" href="../hunch_net-2006/hunch_net-2006-07-13-Regression_vs._Classification_as_a_Primitive.html">196 hunch net-2006-07-13-Regression vs. Classification as a Primitive</a></p>
<p>14 0.089942604 <a title="213-tfidf-14" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>15 0.089042768 <a title="213-tfidf-15" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>16 0.084923573 <a title="213-tfidf-16" href="../hunch_net-2009/hunch_net-2009-12-24-Top_graduates_this_season.html">384 hunch net-2009-12-24-Top graduates this season</a></p>
<p>17 0.08477506 <a title="213-tfidf-17" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>18 0.072901174 <a title="213-tfidf-18" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>19 0.072765455 <a title="213-tfidf-19" href="../hunch_net-2008/hunch_net-2008-07-10-Interesting_papers%2C_ICML_2008.html">309 hunch net-2008-07-10-Interesting papers, ICML 2008</a></p>
<p>20 0.072674811 <a title="213-tfidf-20" href="../hunch_net-2007/hunch_net-2007-06-14-Interesting_Papers_at_COLT_2007.html">247 hunch net-2007-06-14-Interesting Papers at COLT 2007</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.16), (1, -0.126), (2, -0.064), (3, 0.002), (4, -0.004), (5, -0.151), (6, -0.064), (7, -0.017), (8, -0.019), (9, -0.151), (10, -0.108), (11, 0.018), (12, -0.113), (13, -0.114), (14, -0.131), (15, -0.149), (16, 0.032), (17, 0.05), (18, 0.061), (19, 0.053), (20, -0.011), (21, -0.045), (22, -0.326), (23, 0.261), (24, 0.055), (25, 0.287), (26, -0.034), (27, 0.101), (28, -0.024), (29, 0.037), (30, -0.101), (31, 0.029), (32, -0.054), (33, -0.052), (34, -0.118), (35, 0.103), (36, 0.183), (37, -0.039), (38, 0.05), (39, 0.103), (40, 0.003), (41, 0.123), (42, -0.034), (43, -0.026), (44, -0.06), (45, 0.128), (46, 0.132), (47, -0.009), (48, -0.016), (49, -0.057)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98334348 <a title="213-lsi-1" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data
sourcesD,PrS ~ D(f(D) > g(S)) > 1-dwherefis some function of the distribution
(such as the mean) andgis some function of the observed sampleS. The
constraints onDcan vary between "Independent and identically distributed (IID)
samples from a gaussian with an unknown mean" to "IID samples from an
arbitrary distributionD". There are even some confidence intervals which do
not require IID samples.Classical confidence intervals often confuse people.
They donotsay "with high probability, for my observed sample, the bounds
holds". Instead, they tell you that if you reason according to the confidence
interval in the future (and the constraints onDare satisfied), then you are
not often wrong. Restated, they tell you something about what a safe procedure
is in a stochastic world wheredis the safety parameter.There are a number of
results in theoretical machine learning which use confidence intervals. For
example,TheE3alg</p><p>2 0.9468593 <a title="213-lsi-2" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>Introduction: In many machine learning papers experiments are done and little confidence
bars are reported for the results. This often seems quite clear, until you
actually try to figure out what it means. There are several different kinds of
'confidence' being used, and it's easy to become confused.Confidence =
Probability. For those who haven't worried about confidence for a long time,
confidence is simply the probability of some event. You are confident about
events which have a large probability. This meaning of confidence is
inadequate in many applications because we want to reason about how much more
information we have, how much more is needed, and where to get it. As an
example, a learning algorithm might predict that the probability of an event
is0.5, but it's unclear if the probability is0.5because no examples have been
provided or0.5because many examples have been provided and the event is simply
fundamentally uncertain.Classical Confidence Intervals. These are common in
learning theory.</p><p>3 0.42152172 <a title="213-lsi-3" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>Introduction: What?Bounds are mathematical formulas relating observations to future error
rates assuming that data is drawn independently. In classical statistics, they
are calld confidence intervals.Why?Good Judgement. In many applications of
learning, it is desirable to know how well the learned predictor works in the
future. This helps you decide if the problem is solved or not.Learning
Essence. The form of some of these bounds helps you understand what the
essence of learning is.Algorithm Design. Some of these bounds suggest,
motivate, or even directly imply learning algorithms.What We Know NowThere are
several families of bounds, based on how information is used.Testing Bounds.
These are methods which use labeled data not used in training to estimate the
future error rate. Examples include thetest set bound,progressive
validationalsohereandhere,train and test bounds, and cross-validation (but see
thebig open problem). These techniques are the best available for goal (1)
above, but provide littl</p><p>4 0.39031455 <a title="213-lsi-4" href="../hunch_net-2007/hunch_net-2007-08-28-Live_ML_Class.html">261 hunch net-2007-08-28-Live ML Class</a></p>
<p>Introduction: Davor andChunnanpoint out thatMLSS 2007 in Tuebingenhaslive videofor the
majority of the world that is not there (heh).</p><p>5 0.38689229 <a title="213-lsi-5" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.
There are at least 3 distinct ways the word is used.BayesianThe Bayesian
notion of probability is a 'degree of belief'. The degree of belief that some
event (i.e. "stock goes up" or "stock goes down") occurs can be measured by
asking a sequence of questions of the form "Would you bet the stock goes up or
down atYto 1 odds?" A consistent better will switch from 'for' to 'against' at
some single value ofY. The probability is thenY/(Y+1). Bayesian probabilities
express lack of knowledge rather than randomization. They are useful in
learning because we often lack knowledge and expressing that lack flexibly
makes the learning algorithms work better. Bayesian Learning uses
'probability' in this way exclusively.FrequentistThe Frequentist notion of
probability is a rate of occurence. A rate of occurrence can be measured by
doing an experiment many times. If an event occursktimes innexperiments then
it has probability ab</p><p>6 0.38538679 <a title="213-lsi-6" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>7 0.35741347 <a title="213-lsi-7" href="../hunch_net-2007/hunch_net-2007-05-09-The_Missing_Bound.html">244 hunch net-2007-05-09-The Missing Bound</a></p>
<p>8 0.35672736 <a title="213-lsi-8" href="../hunch_net-2010/hunch_net-2010-10-08-An_easy_proof_of_the_Chernoff-Hoeffding_bound.html">413 hunch net-2010-10-08-An easy proof of the Chernoff-Hoeffding bound</a></p>
<p>9 0.32268116 <a title="213-lsi-9" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>10 0.32096785 <a title="213-lsi-10" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>11 0.31479478 <a title="213-lsi-11" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>12 0.31135249 <a title="213-lsi-12" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>13 0.30176926 <a title="213-lsi-13" href="../hunch_net-2008/hunch_net-2008-11-16-Observations_on_Linearity_for_Reductions_to_Regression.html">327 hunch net-2008-11-16-Observations on Linearity for Reductions to Regression</a></p>
<p>14 0.28981957 <a title="213-lsi-14" href="../hunch_net-2005/hunch_net-2005-03-02-Prior%2C_%26%238220%3BPrior%26%238221%3B_and_Bias.html">34 hunch net-2005-03-02-Prior, &#8220;Prior&#8221; and Bias</a></p>
<p>15 0.28729042 <a title="213-lsi-15" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>16 0.28697485 <a title="213-lsi-16" href="../hunch_net-2009/hunch_net-2009-12-24-Top_graduates_this_season.html">384 hunch net-2009-12-24-Top graduates this season</a></p>
<p>17 0.28479972 <a title="213-lsi-17" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>18 0.26608053 <a title="213-lsi-18" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>19 0.26219189 <a title="213-lsi-19" href="../hunch_net-2005/hunch_net-2005-10-07-On-line_learning_of_regular_decision_rules.html">118 hunch net-2005-10-07-On-line learning of regular decision rules</a></p>
<p>20 0.25909105 <a title="213-lsi-20" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.207), (21, 0.093), (35, 0.052), (38, 0.041), (42, 0.233), (45, 0.018), (68, 0.06), (74, 0.075), (85, 0.023), (91, 0.032), (95, 0.039), (98, 0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93401325 <a title="213-lda-1" href="../hunch_net-2005/hunch_net-2005-03-18-Binomial_Weighting.html">43 hunch net-2005-03-18-Binomial Weighting</a></p>
<p>Introduction: Suppose we have a set of classifierscmaking binary predictions from an
inputxand we see examples in an online fashion. In particular, we repeatedly
see an unlabeled examplex, make a predictiony'(possibly based on the
classifiersc), and then see the correct labely.When one of these classifiers
is perfect, there is a great algorithm available: predict according to the
majority vote over every classifier consistent with every previous example.
This is called the Halving algorithm. It makes at mostlog2|c|mistakes since on
any mistake, at least half of the classifiers are eliminated.Obviously, we
can't generally hope that the there exists a classifier which never errs.
TheBinomial Weighting algorithmis an elegant technique allowing a variant
Halving algorithm to cope with errors by creating a set of virtual classifiers
for every classifier which occasionally disagree with the original classifier.
The Halving algorithm on this set of virtual classifiers satisfies a theorem
of the form:errors</p><p>same-blog 2 0.92176467 <a title="213-lda-2" href="../hunch_net-2006/hunch_net-2006-10-08-Incompatibilities_between_classical_confidence_intervals_and_learning..html">213 hunch net-2006-10-08-Incompatibilities between classical confidence intervals and learning.</a></p>
<p>Introduction: Classical confidence intervals satisfy a theorem of the form: For some data
sourcesD,PrS ~ D(f(D) > g(S)) > 1-dwherefis some function of the distribution
(such as the mean) andgis some function of the observed sampleS. The
constraints onDcan vary between "Independent and identically distributed (IID)
samples from a gaussian with an unknown mean" to "IID samples from an
arbitrary distributionD". There are even some confidence intervals which do
not require IID samples.Classical confidence intervals often confuse people.
They donotsay "with high probability, for my observed sample, the bounds
holds". Instead, they tell you that if you reason according to the confidence
interval in the future (and the constraints onDare satisfied), then you are
not often wrong. Restated, they tell you something about what a safe procedure
is in a stochastic world wheredis the safety parameter.There are a number of
results in theoretical machine learning which use confidence intervals. For
example,TheE3alg</p><p>3 0.8960349 <a title="213-lda-3" href="../hunch_net-2008/hunch_net-2008-02-17-The_Meaning_of_Confidence.html">289 hunch net-2008-02-17-The Meaning of Confidence</a></p>
<p>Introduction: In many machine learning papers experiments are done and little confidence
bars are reported for the results. This often seems quite clear, until you
actually try to figure out what it means. There are several different kinds of
'confidence' being used, and it's easy to become confused.Confidence =
Probability. For those who haven't worried about confidence for a long time,
confidence is simply the probability of some event. You are confident about
events which have a large probability. This meaning of confidence is
inadequate in many applications because we want to reason about how much more
information we have, how much more is needed, and where to get it. As an
example, a learning algorithm might predict that the probability of an event
is0.5, but it's unclear if the probability is0.5because no examples have been
provided or0.5because many examples have been provided and the event is simply
fundamentally uncertain.Classical Confidence Intervals. These are common in
learning theory.</p><p>4 0.89442551 <a title="213-lda-4" href="../hunch_net-2006/hunch_net-2006-05-08-Big_machine_learning.html">178 hunch net-2006-05-08-Big machine learning</a></p>
<p>Introduction: According to theNew York Times,Yahoo is releasing Project Panama shortly.
Project Panama is about better predicting which advertisements are relevant to
a search, implying a higher click through rate, implying larger income
forYahoo. There are two things that seem interesting here:A significant
portion of that improved accuracy is almost certainly machine learning at
work.The quantitative effect is huge--the estimate in the article is
$600*106.Googlealready has such improvements andMicrosoft Searchis surely
working on them, which suggest this is (perhaps) a $109per year machine
learning problem.The exact methodology under use is unlikely to be publicly
discussed in the near future because of the competitive enivironment.
Hopefully we'll have some public "war stories" at some point in the future
when this information becomes less sensitive. For now, it's reassuring to
simply note that machine learning is having a big impact.</p><p>5 0.87540364 <a title="213-lda-5" href="../hunch_net-2005/hunch_net-2005-02-26-Problem%3A_Reductions_and_Relative_Ranking_Metrics.html">31 hunch net-2005-02-26-Problem: Reductions and Relative Ranking Metrics</a></p>
<p>Introduction: This, again, is something of a research direction rather than a single
problem.There are several metrics people care about which depend upon the
relative ranking of examples and there are sometimes good reasons to care
about such metrics. Examples includeAROC, "F1â&euro;ł, the proportion of the time
that the top ranked element is in some class, the proportion of the top 10
examples in some class (google's problem), the lowest ranked example of some
class, and the "sort distance" from a predicted ranking to a correct ranking.
Seeherefor an example of some of these.ProblemWhat does the ability to
classify well imply about performance under these metrics?Past
WorkProbabilistic classification under squared errorcan be solved with a
classifier. A counterexample shows this does not imply a good AROC.Sample
complexity bounds forAROC(andhere).A paper on "Learning to Order
Things".DifficultySeveral of these may be easy. Some of them may be
hard.ImpactPositive or negative results will broaden our under</p><p>6 0.83692569 <a title="213-lda-6" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>7 0.80915421 <a title="213-lda-7" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>8 0.76927751 <a title="213-lda-8" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>9 0.762052 <a title="213-lda-9" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>10 0.75843781 <a title="213-lda-10" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>11 0.75834888 <a title="213-lda-11" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>12 0.75533241 <a title="213-lda-12" href="../hunch_net-2005/hunch_net-2005-04-25-Embeddings%3A_what_are_they_good_for%3F.html">61 hunch net-2005-04-25-Embeddings: what are they good for?</a></p>
<p>13 0.75019193 <a title="213-lda-13" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>14 0.74926734 <a title="213-lda-14" href="../hunch_net-2007/hunch_net-2007-01-10-A_Deep_Belief_Net_Learning_Problem.html">227 hunch net-2007-01-10-A Deep Belief Net Learning Problem</a></p>
<p>15 0.74605531 <a title="213-lda-15" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>16 0.7428903 <a title="213-lda-16" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>17 0.7424475 <a title="213-lda-17" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>18 0.74161232 <a title="213-lda-18" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>19 0.73889595 <a title="213-lda-19" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>20 0.73619789 <a title="213-lda-20" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
