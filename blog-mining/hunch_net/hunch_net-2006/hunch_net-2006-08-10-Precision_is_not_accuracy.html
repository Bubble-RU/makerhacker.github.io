<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>202 hunch net-2006-08-10-Precision is not accuracy</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-202" href="#">hunch_net-2006-202</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>202 hunch net-2006-08-10-Precision is not accuracy</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-202-html" href="http://hunch.net/?p=204">html</a></p><p>Introduction: In my experience, there are two different groups of people who believe the same thing: the mathematics encountered in typical machine learning conference papers is often of questionable value. 
The two groups who agree on this are applied machine learning people who have given up on math, and mature theoreticians who understand the limits of theory. 
 
Partly, this is just a statement about where we are with respect to machine learning.  In particular, we have no mechanism capable of generating a prescription for how to solve all learning problems.  In the absence of such certainty, people try to come up with formalisms that partially describe and motivate how and why they do things.  This is natural and healthy—we might hope that it will eventually lead to just such a mechanism.
 
But, part of this is simply an emphasis on complexity over clarity.  A very natural and simple theoretical statement is often obscured by complexifications.  Common sources of complexification include:</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In my experience, there are two different groups of people who believe the same thing: the mathematics encountered in typical machine learning conference papers is often of questionable value. [sent-1, score-0.442]
</p><p>2 The two groups who agree on this are applied machine learning people who have given up on math, and mature theoreticians who understand the limits of theory. [sent-2, score-0.322]
</p><p>3 Partly, this is just a statement about where we are with respect to machine learning. [sent-3, score-0.197]
</p><p>4 A very natural and simple theoretical statement is often obscured by complexifications. [sent-8, score-0.226]
</p><p>5 Common sources of complexification include:      Generalization  By trying to make a statement that applies in the most general possible setting, your theorem becomes excessively hard to read. [sent-9, score-0.63]
</p><p>6 Specialization  Your theorem relies upon so many assumptions that it is hard for a simple reader to hold them all in their head. [sent-10, score-0.674]
</p><p>7 Obscuration  Your theorem relies upon cumbersome notation full of subsubsuperscripts, badly named variables, etc…      There are several reasons why complexification occurs. [sent-11, score-0.893]
</p><p>8 Excessive generalization often happens when authors have an idea and want to completely exploit it. [sent-12, score-0.432]
</p><p>9 Excessive specialization often happens when authors have some algorithm they really want to prove works. [sent-14, score-0.394]
</p><p>10 Some of the worst obscurations come from using an old standard notation which has simply been pushed to far. [sent-17, score-0.348]
</p><p>11 After doing research for awhile, you realize that these complexifications are counterproductive. [sent-18, score-0.362]
</p><p>12 Type (1) complexifications make it double hard for others to do follow-on work: your paper is hard to read and you have eliminated the possibility. [sent-19, score-0.7]
</p><p>13 Type (2) complexifications look like “the tail wags the dog”—the math isn’t really working until it guides the algorithm design. [sent-20, score-0.78]
</p><p>14 The worst reason, I’ve saved for last: it’s that the reviewing process emphasizes precision over accuracy. [sent-24, score-0.428]
</p><p>15 Imagine shooting a math gun at a machine learning target. [sent-25, score-0.692]
</p><p>16 A high precision math gun will very carefully guide the bullets to strike a fixed location—even though the location may have little to do with the target. [sent-26, score-0.89]
</p><p>17 An accurate math gun will point at the correct target. [sent-27, score-0.653]
</p><p>18 A precision/accuracy tradeoff is often encountered: we don’t know how to think about the actual machine learning problem, so instead we very precisely think about another not-quite-right problem. [sent-28, score-0.301]
</p><p>19 A reviewer almost invariably prefers the more precise (but less accurate) paper because precision is the easy thing to check and think about. [sent-29, score-0.466]
</p><p>20 The hard fix for this is more time spent by everyone thinking about what the real machine learning problems are. [sent-31, score-0.302]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('complexifications', 0.362), ('gun', 0.271), ('math', 0.271), ('complexification', 0.181), ('obscuration', 0.181), ('relies', 0.181), ('precision', 0.18), ('notation', 0.18), ('type', 0.15), ('excessive', 0.14), ('specialization', 0.14), ('hard', 0.132), ('statement', 0.127), ('theorem', 0.116), ('accurate', 0.111), ('encountered', 0.108), ('generalization', 0.108), ('fix', 0.1), ('often', 0.099), ('worst', 0.098), ('groups', 0.098), ('location', 0.098), ('assumptions', 0.086), ('upon', 0.085), ('cumbersome', 0.08), ('formalisms', 0.08), ('prescription', 0.08), ('shooting', 0.08), ('invariably', 0.08), ('saved', 0.08), ('tail', 0.08), ('theoreticians', 0.08), ('authors', 0.08), ('happens', 0.075), ('prefers', 0.074), ('excessively', 0.074), ('eliminated', 0.074), ('mature', 0.074), ('reader', 0.074), ('exploit', 0.07), ('emphasizes', 0.07), ('pushed', 0.07), ('strike', 0.07), ('named', 0.07), ('machine', 0.07), ('guides', 0.067), ('questionable', 0.067), ('think', 0.066), ('thing', 0.066), ('motivate', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999958 <a title="202-tfidf-1" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>Introduction: In my experience, there are two different groups of people who believe the same thing: the mathematics encountered in typical machine learning conference papers is often of questionable value. 
The two groups who agree on this are applied machine learning people who have given up on math, and mature theoreticians who understand the limits of theory. 
 
Partly, this is just a statement about where we are with respect to machine learning.  In particular, we have no mechanism capable of generating a prescription for how to solve all learning problems.  In the absence of such certainty, people try to come up with formalisms that partially describe and motivate how and why they do things.  This is natural and healthy—we might hope that it will eventually lead to just such a mechanism.
 
But, part of this is simply an emphasis on complexity over clarity.  A very natural and simple theoretical statement is often obscured by complexifications.  Common sources of complexification include:</p><p>2 0.18650302 <a title="202-tfidf-2" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>Introduction: For most people, a mathematical notation is like a language: you learn it and stick with it.  For people doing mathematical research, however, this is not enough: they must design new notations for new problems.  The design of good notation is both hard and worthwhile since a bad initial notation can retard a line of research greatly.  
 
Before we had mathematical notation, equations were all written out in language.  Since words have multiple meanings and variable precedences, long equations written out in language can be extraordinarily difficult and sometimes fundamentally ambiguous.  A good representative example of this is the legalese in the tax code.  Since we want greater precision and clarity, we adopt mathematical notation.
 
One fundamental thing to understand about mathematical notation, is that humans as logic verifiers, are barely capable.  This is the fundamental reason why one notation can be much better than another.  This observation is easier to miss than you might</p><p>3 0.12413627 <a title="202-tfidf-3" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>Introduction: A type of prediction problem is specified by the type of samples produced by a data source (Example:  X x {0,1} ,  X x [0,1] ,  X x {1,2,3,4,5} , etc…) and a loss function (0/1 loss, squared error loss, cost sensitive losses, etc…).  For simplicity, we’ll assume that all losses have a minimum of zero.
 
For this post, we can think of a learning reduction as
  
 A mapping  R  from samples of one type  T  (like multiclass classification) to another type  T’  (like binary classification). 
 A mapping  Q  from predictors for type  T’  to predictors for type  T . 
  
The simplest sort of learning reduction is a “loss reduction”.  The idea in a loss reduction is to prove a statement of the form: 
 Theorem  For all base predictors  b , for all distributions  D  over examples of type  T : 
  E (x,y) ~ D  L T (y,Q(b,x)) <= f(E (x’,y’)~R(D)  L T’ (y’,b(x’)))   
Here  L T   is the loss for the type  T  problem and  L T’   is the loss for the type  T’  problem.  Also,  R(D)  is the distribution ov</p><p>4 0.12403981 <a title="202-tfidf-4" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>Introduction: Andrej Bauer has setup a  Mathematics and Computation  Blog.  As a first step he has tried to address the persistent and annoying problem of math on the web.  As a basic tool for precisely stating and transfering understanding of technical subjects, mathematics is very necessary.  Despite this necessity, every mechanism for expressing mathematics on the web seems unnaturally clumsy.  Here are some of the methods and their drawbacks:
  
  MathML   This was supposed to be the answer, but it has two severe drawbacks: “Internet Explorer” doesn’t read it and the language is an example of push-XML-to-the-limit which no one would ever consider writing in.  (In contrast, html is easy to write in.)  It’s also very annoying that math fonts must be installed independent of the browser, even for mozilla based browsers. 
 Create inline images.  This has several big drawbacks: font size is fixed for all viewers, you can’t cut & paste inside the images, and you can’t hyperlink from (say) symbol to de</p><p>5 0.11806416 <a title="202-tfidf-5" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>Introduction: Learning reductions  transform a solver of one type of learning problem into a solver of another type of learning problem.  When we analyze these for robustness we can make statement of the form “Reduction  R  has the property that regret  r  (or loss) on subproblems of type  A  implies regret at most   f ( r )  on the original problem of type  B “.
 
A lower bound for a learning reduction would have the form “for all reductions  R , there exists a learning problem of type  B  and learning algorithm for problems of type  A  where regret  r  on induced problems implies  at least  regret  f ( r )  for  B “.
 
The pursuit of lower bounds is often questionable because, unlike upper bounds, they do not yield practical algorithms.  Nevertheless, they may be helpful as a tool for thinking about what is learnable and how learnable it is.  This has already come up  here  and  here .
 
At the moment, there is no coherent theory of lower bounds for learning reductions, and we have little understa</p><p>6 0.11644432 <a title="202-tfidf-6" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>7 0.11585537 <a title="202-tfidf-7" href="../hunch_net-2006/hunch_net-2006-04-06-Bounds_greater_than_1.html">170 hunch net-2006-04-06-Bounds greater than 1</a></p>
<p>8 0.11474198 <a title="202-tfidf-8" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>9 0.10135854 <a title="202-tfidf-9" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>10 0.099565864 <a title="202-tfidf-10" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>11 0.099063545 <a title="202-tfidf-11" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>12 0.098526835 <a title="202-tfidf-12" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>13 0.097825326 <a title="202-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>14 0.095347457 <a title="202-tfidf-14" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>15 0.09354689 <a title="202-tfidf-15" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>16 0.093162328 <a title="202-tfidf-16" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>17 0.09204106 <a title="202-tfidf-17" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>18 0.091444671 <a title="202-tfidf-18" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>19 0.09131401 <a title="202-tfidf-19" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>20 0.089603886 <a title="202-tfidf-20" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.223), (1, -0.006), (2, 0.056), (3, 0.074), (4, -0.035), (5, -0.03), (6, 0.068), (7, 0.047), (8, 0.036), (9, -0.015), (10, -0.008), (11, -0.018), (12, 0.064), (13, 0.023), (14, 0.048), (15, -0.012), (16, 0.014), (17, -0.008), (18, -0.017), (19, -0.002), (20, 0.039), (21, 0.035), (22, -0.046), (23, -0.11), (24, -0.026), (25, -0.056), (26, -0.005), (27, -0.009), (28, -0.051), (29, -0.061), (30, -0.061), (31, 0.063), (32, -0.045), (33, 0.097), (34, -0.07), (35, -0.146), (36, -0.022), (37, 0.058), (38, 0.011), (39, -0.016), (40, -0.001), (41, 0.042), (42, -0.016), (43, -0.044), (44, -0.038), (45, 0.03), (46, 0.02), (47, 0.105), (48, 0.034), (49, 0.019)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94327652 <a title="202-lsi-1" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>Introduction: In my experience, there are two different groups of people who believe the same thing: the mathematics encountered in typical machine learning conference papers is often of questionable value. 
The two groups who agree on this are applied machine learning people who have given up on math, and mature theoreticians who understand the limits of theory. 
 
Partly, this is just a statement about where we are with respect to machine learning.  In particular, we have no mechanism capable of generating a prescription for how to solve all learning problems.  In the absence of such certainty, people try to come up with formalisms that partially describe and motivate how and why they do things.  This is natural and healthy—we might hope that it will eventually lead to just such a mechanism.
 
But, part of this is simply an emphasis on complexity over clarity.  A very natural and simple theoretical statement is often obscured by complexifications.  Common sources of complexification include:</p><p>2 0.80869502 <a title="202-lsi-2" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>Introduction: For most people, a mathematical notation is like a language: you learn it and stick with it.  For people doing mathematical research, however, this is not enough: they must design new notations for new problems.  The design of good notation is both hard and worthwhile since a bad initial notation can retard a line of research greatly.  
 
Before we had mathematical notation, equations were all written out in language.  Since words have multiple meanings and variable precedences, long equations written out in language can be extraordinarily difficult and sometimes fundamentally ambiguous.  A good representative example of this is the legalese in the tax code.  Since we want greater precision and clarity, we adopt mathematical notation.
 
One fundamental thing to understand about mathematical notation, is that humans as logic verifiers, are barely capable.  This is the fundamental reason why one notation can be much better than another.  This observation is easier to miss than you might</p><p>3 0.7555986 <a title="202-lsi-3" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<p>Introduction: When presenting part of the  Reinforcement Learning theory tutorial  at  ICML 2006 , I was forcibly reminded of this.
 
There are several difficulties.
  
  When creating the presentation, the correct level of detail is tricky.  With too much detail, the proof takes too much time and people may be lost to boredom.  With too little detail, the steps of the proof involve too-great a jump. This is very difficult to judge.
 
 What may be an easy step in the careful thought of a quiet room is not so easy when you are occupied by the process of presentation. 
 What may be easy after having gone over this (and other) proofs is not so easy to follow in the first pass by a viewer. 
 

  These problems seem only correctable by process of repeated test-and-revise.
 
 When presenting the proof, simply speaking with sufficient precision is substantially harder than in normal conversation (where precision is not so critical).  Practice can help here. 
 When presenting the proof, going at the right p</p><p>4 0.66993558 <a title="202-lsi-4" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>Introduction: Bob Williamson  and I are the learning theory PC members at  NIPS  this year.  This is some attempt to state the standards and tests I applied to the papers.  I think it is a good idea to talk about this for two reasons:
  
 Making community standards a matter of public record seems healthy.  It give us a chance to debate what is and is not the right standard.  It might even give us a bit more consistency across the years. 
 It may save us all time.  There are a number of papers submitted which just aren’t there yet.  Avoiding submitting is the right decision in this case. 
  
There are several criteria for judging a paper.  All of these were active this year.  Some criteria are uncontroversial while others may be so.
  
 The paper must have a theorem establishing something new for which it is possible to derive high confidence in the correctness of the results.  A surprising number of papers fail this test.  This criteria seems essential to the definition of “theory”.
 
  Missing theo</p><p>5 0.65044868 <a title="202-lsi-5" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>Introduction: The ideal of theoretical algorithm analysis is to construct an algorithm with accompanying optimality theorems proving that it is a useful algorithm.  This ideal often fails, particularly for learning algorithms and theory.  The general form of a theorem is:  If  preconditions  Then  postconditions     When we design learning algorithms it is very common to come up with precondition assumptions such as “the data is IID”, “the learning problem is drawn from a known distribution over learning problems”, or “there is a perfect classifier”.  All of these example preconditions can be false for real-world problems in ways that are not easily detectable.  This means that algorithms derived and justified by these very common forms of analysis may be prone to catastrophic failure in routine (mis)application.
 
We  can  hope for better.  Several different kinds of learning algorithm analysis have been developed some of which have fewer preconditions.  Simply demanding that these forms of analysi</p><p>6 0.63313681 <a title="202-lsi-6" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>7 0.63229519 <a title="202-lsi-7" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>8 0.62890363 <a title="202-lsi-8" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>9 0.61344689 <a title="202-lsi-9" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>10 0.59581625 <a title="202-lsi-10" href="../hunch_net-2005/hunch_net-2005-04-04-Grounds_for_Rejection.html">52 hunch net-2005-04-04-Grounds for Rejection</a></p>
<p>11 0.5949952 <a title="202-lsi-11" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>12 0.59188461 <a title="202-lsi-12" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>13 0.58813244 <a title="202-lsi-13" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>14 0.58605248 <a title="202-lsi-14" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>15 0.58092362 <a title="202-lsi-15" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>16 0.5805217 <a title="202-lsi-16" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>17 0.57555604 <a title="202-lsi-17" href="../hunch_net-2005/hunch_net-2005-07-10-Thinking_the_Unthought.html">91 hunch net-2005-07-10-Thinking the Unthought</a></p>
<p>18 0.57546467 <a title="202-lsi-18" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>19 0.5636971 <a title="202-lsi-19" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<p>20 0.55026424 <a title="202-lsi-20" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.014), (10, 0.029), (27, 0.191), (38, 0.068), (53, 0.085), (55, 0.096), (56, 0.281), (77, 0.013), (94, 0.1), (95, 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96897036 <a title="202-lda-1" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<p>Introduction: When presenting part of the  Reinforcement Learning theory tutorial  at  ICML 2006 , I was forcibly reminded of this.
 
There are several difficulties.
  
  When creating the presentation, the correct level of detail is tricky.  With too much detail, the proof takes too much time and people may be lost to boredom.  With too little detail, the steps of the proof involve too-great a jump. This is very difficult to judge.
 
 What may be an easy step in the careful thought of a quiet room is not so easy when you are occupied by the process of presentation. 
 What may be easy after having gone over this (and other) proofs is not so easy to follow in the first pass by a viewer. 
 

  These problems seem only correctable by process of repeated test-and-revise.
 
 When presenting the proof, simply speaking with sufficient precision is substantially harder than in normal conversation (where precision is not so critical).  Practice can help here. 
 When presenting the proof, going at the right p</p><p>2 0.91648346 <a title="202-lda-2" href="../hunch_net-2008/hunch_net-2008-07-04-More_Presentation_Preparation.html">307 hunch net-2008-07-04-More Presentation Preparation</a></p>
<p>Introduction: We’ve discussed  presentation preparation before , but I have one more thing to add:  transitioning .  For a research presentation, it is substantially helpful for the audience if transitions are clear.  A common outline for a research presentation in machine leanring is:
  
  The problem .  Presentations which don’t describe the problem almost immediately lose people, because the context is missing to understand the detail. 
  Prior relevant work .  In many cases, a paper builds on some previous bit of work which must be understood in order to understand what the paper does.  A common failure mode seems to be spending too much time on prior work.  Discuss just the relevant aspects of prior work in the language of your work.  Sometimes this is missing when unneeded. 
  What we did . For theory papers in particular, it is often not possible to really cover the details.  Prioritizing what you present can be very important. 
  How it worked .  Many papers in Machine Learning have some sor</p><p>3 0.90764982 <a title="202-lda-3" href="../hunch_net-2007/hunch_net-2007-06-23-Machine_Learning_Jobs_are_Growing_on_Trees.html">250 hunch net-2007-06-23-Machine Learning Jobs are Growing on Trees</a></p>
<p>Introduction: The consensus of several discussions at ICML is that the number of jobs for people knowing machine learning well substantially exceeds supply.  This is my experience as well.  Demand comes from many places, but I’ve seen particularly strong demand from trading companies and internet startups.
 
Like all interest bursts, this one will probably pass because of economic recession or other distractions.  Nevertheless, the general outlook for machine learning in business seems to be good.  Machine learning is all about optimization when there is uncertainty and lots of data.  The quantity of data available is growing quickly as computer-run processes and sensors become more common, and the quality of the data is dropping since there is little editorial control in it’s collection.  Machine Learning is a difficult subject to master (*), so those who do should remain in demand over the long term.
 
(*) In fact, it would be reasonable to claim that no one has mastered it—there are just some peo</p><p>same-blog 4 0.86887366 <a title="202-lda-4" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>Introduction: In my experience, there are two different groups of people who believe the same thing: the mathematics encountered in typical machine learning conference papers is often of questionable value. 
The two groups who agree on this are applied machine learning people who have given up on math, and mature theoreticians who understand the limits of theory. 
 
Partly, this is just a statement about where we are with respect to machine learning.  In particular, we have no mechanism capable of generating a prescription for how to solve all learning problems.  In the absence of such certainty, people try to come up with formalisms that partially describe and motivate how and why they do things.  This is natural and healthy—we might hope that it will eventually lead to just such a mechanism.
 
But, part of this is simply an emphasis on complexity over clarity.  A very natural and simple theoretical statement is often obscured by complexifications.  Common sources of complexification include:</p><p>5 0.8255797 <a title="202-lda-5" href="../hunch_net-2012/hunch_net-2012-03-24-David_Waltz.html">460 hunch net-2012-03-24-David Waltz</a></p>
<p>Introduction: has  died .   He lived a full life.  I know him personally as a founder of the  Center for Computational Learning Systems  and the  New York Machine Learning Symposium , both of which have sheltered and promoted the advancement of machine learning.  I expect much of the New York area machine learning community will miss him, as well as many others around the world.</p><p>6 0.74368155 <a title="202-lda-6" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>7 0.68910623 <a title="202-lda-7" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>8 0.68342495 <a title="202-lda-8" href="../hunch_net-2007/hunch_net-2007-06-21-Presentation_Preparation.html">249 hunch net-2007-06-21-Presentation Preparation</a></p>
<p>9 0.67336905 <a title="202-lda-9" href="../hunch_net-2010/hunch_net-2010-10-29-To_Vidoelecture_or_not.html">416 hunch net-2010-10-29-To Vidoelecture or not</a></p>
<p>10 0.67003638 <a title="202-lda-10" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>11 0.6685257 <a title="202-lda-11" href="../hunch_net-2005/hunch_net-2005-12-17-Workshops_as_Franchise_Conferences.html">141 hunch net-2005-12-17-Workshops as Franchise Conferences</a></p>
<p>12 0.66542 <a title="202-lda-12" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>13 0.66535574 <a title="202-lda-13" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>14 0.65966815 <a title="202-lda-14" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>15 0.65892041 <a title="202-lda-15" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>16 0.65675092 <a title="202-lda-16" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<p>17 0.65460283 <a title="202-lda-17" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>18 0.6543712 <a title="202-lda-18" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>19 0.65422279 <a title="202-lda-19" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>20 0.65384889 <a title="202-lda-20" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
