<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>162 hunch net-2006-03-09-Use of Notation</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-162" href="#">hunch_net-2006-162</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>162 hunch net-2006-03-09-Use of Notation</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-162-html" href="http://hunch.net/?p=173">html</a></p><p>Introduction: For most people, a mathematical notation is like a language: you learn it and stick with it.  For people doing mathematical research, however, this is not enough: they must design new notations for new problems.  The design of good notation is both hard and worthwhile since a bad initial notation can retard a line of research greatly.  
 
Before we had mathematical notation, equations were all written out in language.  Since words have multiple meanings and variable precedences, long equations written out in language can be extraordinarily difficult and sometimes fundamentally ambiguous.  A good representative example of this is the legalese in the tax code.  Since we want greater precision and clarity, we adopt mathematical notation.
 
One fundamental thing to understand about mathematical notation, is that humans as logic verifiers, are barely capable.  This is the fundamental reason why one notation can be much better than another.  This observation is easier to miss than you might</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 For most people, a mathematical notation is like a language: you learn it and stick with it. [sent-1, score-0.82]
</p><p>2 For people doing mathematical research, however, this is not enough: they must design new notations for new problems. [sent-2, score-0.402]
</p><p>3 The design of good notation is both hard and worthwhile since a bad initial notation can retard a line of research greatly. [sent-3, score-1.594]
</p><p>4 Before we had mathematical notation, equations were all written out in language. [sent-4, score-0.36]
</p><p>5 Since words have multiple meanings and variable precedences, long equations written out in language can be extraordinarily difficult and sometimes fundamentally ambiguous. [sent-5, score-0.501]
</p><p>6 One fundamental thing to understand about mathematical notation, is that humans as logic verifiers, are barely capable. [sent-8, score-0.345]
</p><p>7 This is the fundamental reason why one notation can be much better than another. [sent-9, score-0.714]
</p><p>8 This observation is easier to miss than you might expect because, for a problem that you are working on, you have already expended the effort to reach an understanding. [sent-10, score-0.236]
</p><p>9 I don’t know of any systematic method for designing notation, but there are a set of heuristics learned over time which may be more widely helpful. [sent-11, score-0.233]
</p><p>10 If notation is only used once, it should be removable (this often arises in presentations). [sent-14, score-0.725]
</p><p>11 A reasonable mechanism for notation design is to first name and define the quantities you are working with (for example, reward  r  and time  t ), and then make derived quantities by combination (for example  r t   is reward at time  t ). [sent-18, score-1.419]
</p><p>12 (For example, in reinforcement learning the MDP  M  you are working with is often suppressable because it never changes. [sent-27, score-0.177]
</p><p>13 )   A dependence must be either uniformly suppressed or uniformly explicit. [sent-28, score-0.32]
</p><p>14 There seem to be two styles of theorem statements: long including all definitions and short with definitions made before the statement. [sent-30, score-0.669]
</p><p>15 It is very easy to forget the quantification of a variable (“for all” or “there exists”) when you are working on a theorem, and it is essential for readers that you specify it explicitly. [sent-33, score-0.285]
</p><p>16 english lowercase > english upper case > greek lower case > greek upper case > hebrew > other strange things. [sent-36, score-0.956]
</p><p>17 The definitions section of a paper often should  not  contain all the definitions in a paper. [sent-37, score-0.431]
</p><p>18 These heuristics often come into conflict, which can be hard to resolve. [sent-40, score-0.36]
</p><p>19 When trying to resolve the conflict, it’s important to understand that it’s easy to fail to imagine what a notation would be like. [sent-41, score-0.772]
</p><p>20 Are there other useful heuristics for notation design? [sent-43, score-0.893]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('notation', 0.66), ('heuristics', 0.233), ('definitions', 0.183), ('mathematical', 0.16), ('greek', 0.142), ('notations', 0.142), ('collisions', 0.126), ('suppressed', 0.126), ('reward', 0.118), ('variable', 0.118), ('equations', 0.117), ('working', 0.112), ('english', 0.11), ('design', 0.1), ('uniformly', 0.097), ('conflict', 0.097), ('strange', 0.097), ('theorem', 0.091), ('short', 0.09), ('quantities', 0.087), ('written', 0.083), ('name', 0.077), ('upper', 0.077), ('statements', 0.076), ('humans', 0.076), ('long', 0.067), ('case', 0.067), ('often', 0.065), ('expended', 0.063), ('objectively', 0.063), ('hard', 0.062), ('easier', 0.061), ('language', 0.061), ('example', 0.06), ('resolve', 0.058), ('symbol', 0.058), ('retard', 0.058), ('sticking', 0.058), ('tax', 0.058), ('clarity', 0.055), ('styles', 0.055), ('meanings', 0.055), ('quantification', 0.055), ('barely', 0.055), ('disagreements', 0.055), ('divergence', 0.055), ('unfamiliar', 0.055), ('since', 0.054), ('trying', 0.054), ('fundamental', 0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="162-tfidf-1" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>Introduction: For most people, a mathematical notation is like a language: you learn it and stick with it.  For people doing mathematical research, however, this is not enough: they must design new notations for new problems.  The design of good notation is both hard and worthwhile since a bad initial notation can retard a line of research greatly.  
 
Before we had mathematical notation, equations were all written out in language.  Since words have multiple meanings and variable precedences, long equations written out in language can be extraordinarily difficult and sometimes fundamentally ambiguous.  A good representative example of this is the legalese in the tax code.  Since we want greater precision and clarity, we adopt mathematical notation.
 
One fundamental thing to understand about mathematical notation, is that humans as logic verifiers, are barely capable.  This is the fundamental reason why one notation can be much better than another.  This observation is easier to miss than you might</p><p>2 0.18906716 <a title="162-tfidf-2" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>Introduction: The notation  g(n) = O(f(n))  means that in the limit as  n  approaches infinity there exists a constant  C  such that the  g(n)  is less than  Cf(n) .
 
In learning theory, there are many statements about learning algorithms of the form “under assumptions  x , y , and  z , the classifier learned has an error rate of at most  O(f(m)) “.
 
There is one very good reason to use O(): it helps you understand the big picture and neglect the minor details which are not important in the big picture.  However, there are some important reasons not to do this as well.
  
  Unspeedup  In algorithm analysis, the use of O() for time complexity is pervasive and well-justified.  Determining the exact value of C is inherently computer architecture dependent.  (The “C” for x86 processors might differ from the “C” on PowerPC processors.)  Since many learning theorists come from a CS theory background, the O() notation is applied to generalization error.  The O() abstraction breaks here—you can not genera</p><p>3 0.18650302 <a title="162-tfidf-3" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>Introduction: In my experience, there are two different groups of people who believe the same thing: the mathematics encountered in typical machine learning conference papers is often of questionable value. 
The two groups who agree on this are applied machine learning people who have given up on math, and mature theoreticians who understand the limits of theory. 
 
Partly, this is just a statement about where we are with respect to machine learning.  In particular, we have no mechanism capable of generating a prescription for how to solve all learning problems.  In the absence of such certainty, people try to come up with formalisms that partially describe and motivate how and why they do things.  This is natural and healthy—we might hope that it will eventually lead to just such a mechanism.
 
But, part of this is simply an emphasis on complexity over clarity.  A very natural and simple theoretical statement is often obscured by complexifications.  Common sources of complexification include:</p><p>4 0.11564405 <a title="162-tfidf-4" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>Introduction: Many people in Machine Learning don’t fully understand the impact of computation, as demonstrated by a lack of  big-O  analysis of new learning algorithms.  This is important—some current active research programs are fundamentally flawed w.r.t. computation, and other research programs are directly motivated by it.  When considering a learning algorithm, I think about the following questions:
  
 How does the learning algorithm scale with the number of examples  m ?  Any algorithm using all of the data is at least  O(m) , but in many cases this is  O(m 2 )  (naive nearest neighbor for self-prediction) or unknown (k-means or many other optimization algorithms).  The unknown case is very common, and it can mean (for example) that the algorithm isn’t convergent or simply that the amount of computation isn’t controlled. 
 The above question can also be asked for test cases.  In some applications, test-time performance is of great importance. 
 How does the algorithm scale with the number of</p><p>5 0.10739357 <a title="162-tfidf-5" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>Introduction: How should we, as researchers in machine learning, organize ourselves?
 
The most immediate measurable objective of computer science research is publishing a paper.  The most difficult aspect of publishing a paper is having reviewers accept and recommend it for publication.  The simplest mechanism for doing this is to show theoretical progress on some standard, well-known easily understood problem.
 
In doing this, we often fall into a local minima of the research process.  The basic problem in machine learning is that it is very unclear that the mathematical model is the right one for the (or some) real problem.  A good mathematical model in machine learning should have one fundamental trait: it should aid the design of effective learning algorithms.  To date, our ability to solve interesting learning problems (speech recognition, machine translation, object recognition, etc…) remains limited (although improving), so the “rightness” of our models is in doubt.
 
If our mathematical mod</p><p>6 0.079201303 <a title="162-tfidf-6" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>7 0.078900851 <a title="162-tfidf-7" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>8 0.078373179 <a title="162-tfidf-8" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>9 0.073410384 <a title="162-tfidf-9" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>10 0.073381193 <a title="162-tfidf-10" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>11 0.073229618 <a title="162-tfidf-11" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>12 0.072674334 <a title="162-tfidf-12" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>13 0.072078951 <a title="162-tfidf-13" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>14 0.071571 <a title="162-tfidf-14" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>15 0.070170172 <a title="162-tfidf-15" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>16 0.06934268 <a title="162-tfidf-16" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>17 0.068825081 <a title="162-tfidf-17" href="../hunch_net-2008/hunch_net-2008-09-12-How_do_we_get_weak_action_dependence_for_learning_with_partial_observations%3F.html">317 hunch net-2008-09-12-How do we get weak action dependence for learning with partial observations?</a></p>
<p>18 0.067974314 <a title="162-tfidf-18" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>19 0.066669956 <a title="162-tfidf-19" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>20 0.066332921 <a title="162-tfidf-20" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.161), (1, 0.027), (2, -0.011), (3, 0.068), (4, -0.025), (5, -0.027), (6, 0.058), (7, 0.052), (8, 0.031), (9, 0.01), (10, -0.001), (11, -0.016), (12, 0.028), (13, 0.04), (14, 0.021), (15, -0.01), (16, 0.05), (17, 0.025), (18, -0.007), (19, 0.009), (20, -0.017), (21, 0.022), (22, 0.003), (23, -0.047), (24, -0.034), (25, -0.029), (26, 0.028), (27, -0.078), (28, -0.051), (29, -0.032), (30, -0.091), (31, 0.074), (32, 0.004), (33, 0.081), (34, 0.021), (35, -0.076), (36, 0.013), (37, 0.034), (38, 0.027), (39, -0.01), (40, -0.012), (41, 0.021), (42, -0.039), (43, -0.061), (44, -0.041), (45, 0.003), (46, 0.033), (47, 0.002), (48, 0.055), (49, 0.019)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9608627 <a title="162-lsi-1" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>Introduction: For most people, a mathematical notation is like a language: you learn it and stick with it.  For people doing mathematical research, however, this is not enough: they must design new notations for new problems.  The design of good notation is both hard and worthwhile since a bad initial notation can retard a line of research greatly.  
 
Before we had mathematical notation, equations were all written out in language.  Since words have multiple meanings and variable precedences, long equations written out in language can be extraordinarily difficult and sometimes fundamentally ambiguous.  A good representative example of this is the legalese in the tax code.  Since we want greater precision and clarity, we adopt mathematical notation.
 
One fundamental thing to understand about mathematical notation, is that humans as logic verifiers, are barely capable.  This is the fundamental reason why one notation can be much better than another.  This observation is easier to miss than you might</p><p>2 0.81235915 <a title="162-lsi-2" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>Introduction: In my experience, there are two different groups of people who believe the same thing: the mathematics encountered in typical machine learning conference papers is often of questionable value. 
The two groups who agree on this are applied machine learning people who have given up on math, and mature theoreticians who understand the limits of theory. 
 
Partly, this is just a statement about where we are with respect to machine learning.  In particular, we have no mechanism capable of generating a prescription for how to solve all learning problems.  In the absence of such certainty, people try to come up with formalisms that partially describe and motivate how and why they do things.  This is natural and healthy—we might hope that it will eventually lead to just such a mechanism.
 
But, part of this is simply an emphasis on complexity over clarity.  A very natural and simple theoretical statement is often obscured by complexifications.  Common sources of complexification include:</p><p>3 0.74080324 <a title="162-lsi-3" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<p>Introduction: When presenting part of the  Reinforcement Learning theory tutorial  at  ICML 2006 , I was forcibly reminded of this.
 
There are several difficulties.
  
  When creating the presentation, the correct level of detail is tricky.  With too much detail, the proof takes too much time and people may be lost to boredom.  With too little detail, the steps of the proof involve too-great a jump. This is very difficult to judge.
 
 What may be an easy step in the careful thought of a quiet room is not so easy when you are occupied by the process of presentation. 
 What may be easy after having gone over this (and other) proofs is not so easy to follow in the first pass by a viewer. 
 

  These problems seem only correctable by process of repeated test-and-revise.
 
 When presenting the proof, simply speaking with sufficient precision is substantially harder than in normal conversation (where precision is not so critical).  Practice can help here. 
 When presenting the proof, going at the right p</p><p>4 0.65229779 <a title="162-lsi-4" href="../hunch_net-2007/hunch_net-2007-06-21-Presentation_Preparation.html">249 hunch net-2007-06-21-Presentation Preparation</a></p>
<p>Introduction: A big part of doing research is presenting it at a conference.  Since many people start out shy of public presentations, this can be a substantial challenge.  Here are a few notes which might be helpful when thinking about preparing a presentation on research.
  
  Motivate .  Talks which don’t start by describing the problem to solve cause many people to zone out. 
  Prioritize .  It is typical that you have more things to say than time to say them, and many presenters fall into the failure mode of trying to say too much.  This is an easy-to-understand failure mode as it’s very natural to want to include everything.  A basic fact is: you can’t.  Example of this are:
 
 Your slides are so densely full of equations and words that you can’t cover them. 
 Your talk runs over and a moderator prioritizes for you by cutting you off. 
 You motor-mouth through the presentation, and the information absorption rate of the audience prioritizes in some uncontrolled fashion. 
 The rate of flow of c</p><p>5 0.64035696 <a title="162-lsi-5" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>Introduction: Foster Provost  gave a talk at the ICML  metalearning workshop  on “metalearning” and the “no free lunch theorem” which seems worth summarizing.
 
As a review: the no free lunch theorem is the most complicated way we know of to say that a  bias  is required in order to learn.  The simplest way to see this is in a nonprobabilistic setting.  If you are given examples of the form  (x,y)  and you wish to predict  y  from  x  then any prediction mechanism errs half the time in expectation over all sequences of examples.  The proof of this is very simple: on every example a predictor must make some prediction and by symmetry over the set of sequences it will be wrong half the time and right half the time.  The basic idea of this proof has been applied to many other settings.
 
The simplistic interpretation of this theorem which many people jump to is “machine learning is dead” since there can be no single learning algorithm which can solve all learning problems.  This is the wrong way to thi</p><p>6 0.64031404 <a title="162-lsi-6" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>7 0.63854736 <a title="162-lsi-7" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>8 0.62231457 <a title="162-lsi-8" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>9 0.6151517 <a title="162-lsi-9" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>10 0.6073786 <a title="162-lsi-10" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>11 0.59881443 <a title="162-lsi-11" href="../hunch_net-2008/hunch_net-2008-07-04-More_Presentation_Preparation.html">307 hunch net-2008-07-04-More Presentation Preparation</a></p>
<p>12 0.59240144 <a title="162-lsi-12" href="../hunch_net-2006/hunch_net-2006-01-08-Debugging_Your_Brain.html">147 hunch net-2006-01-08-Debugging Your Brain</a></p>
<p>13 0.59188759 <a title="162-lsi-13" href="../hunch_net-2005/hunch_net-2005-04-16-Which_Assumptions_are_Reasonable%3F.html">57 hunch net-2005-04-16-Which Assumptions are Reasonable?</a></p>
<p>14 0.58376777 <a title="162-lsi-14" href="../hunch_net-2005/hunch_net-2005-04-10-Is_the_Goal_Understanding_or_Prediction%3F.html">55 hunch net-2005-04-10-Is the Goal Understanding or Prediction?</a></p>
<p>15 0.57119596 <a title="162-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>16 0.56933004 <a title="162-lsi-16" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>17 0.56366074 <a title="162-lsi-17" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>18 0.56203496 <a title="162-lsi-18" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>19 0.56028646 <a title="162-lsi-19" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>20 0.55811924 <a title="162-lsi-20" href="../hunch_net-2005/hunch_net-2005-07-10-Thinking_the_Unthought.html">91 hunch net-2005-07-10-Thinking the Unthought</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.055), (10, 0.018), (27, 0.128), (38, 0.107), (48, 0.016), (53, 0.053), (55, 0.048), (79, 0.293), (94, 0.115), (95, 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.85709047 <a title="162-lda-1" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>Introduction: For most people, a mathematical notation is like a language: you learn it and stick with it.  For people doing mathematical research, however, this is not enough: they must design new notations for new problems.  The design of good notation is both hard and worthwhile since a bad initial notation can retard a line of research greatly.  
 
Before we had mathematical notation, equations were all written out in language.  Since words have multiple meanings and variable precedences, long equations written out in language can be extraordinarily difficult and sometimes fundamentally ambiguous.  A good representative example of this is the legalese in the tax code.  Since we want greater precision and clarity, we adopt mathematical notation.
 
One fundamental thing to understand about mathematical notation, is that humans as logic verifiers, are barely capable.  This is the fundamental reason why one notation can be much better than another.  This observation is easier to miss than you might</p><p>2 0.79168433 <a title="162-lda-2" href="../hunch_net-2007/hunch_net-2007-06-19-How_is_Compressed_Sensing_going_to_change_Machine_Learning_%3F.html">248 hunch net-2007-06-19-How is Compressed Sensing going to change Machine Learning ?</a></p>
<p>Introduction: Compressed Sensing  (CS) is a new framework developed by  Emmanuel Candes ,  Terry Tao  and  David Donoho . To summarize, if you acquire a signal in some basis that is incoherent with the basis in which you know the signal to be sparse in, it is very likely you will be able to reconstruct the signal from these incoherent projections. 
 
Terry Tao, the recent  Fields medalist , does a very nice job at explaining the framework  here . He goes further in the theory description in this  post  where he mentions the central issue of the Uniform Uncertainty Principle. It so happens that random projections are on average incoherent, within the UUP meaning, with most known basis (sines, polynomials, splines, wavelets, curvelets …) and are therefore an ideal basis for Compressed Sensing. [ For more in-depth information on the subject, the Rice group has done a very good job at providing a central library of papers relevant to the growing subject:  http://www.dsp.ece.rice.edu/cs/  ]
 
The Machine</p><p>3 0.77982777 <a title="162-lda-3" href="../hunch_net-2007/hunch_net-2007-07-12-ICML_Trends.html">254 hunch net-2007-07-12-ICML Trends</a></p>
<p>Introduction: Mark Reid  did a post on  ICML trends  that I found interesting.</p><p>4 0.75040662 <a title="162-lda-4" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>Introduction: The hunch.net server has been updated.  I’ve taken the opportunity to upgrade the version of wordpress which caused cascading changes.
  
 Old threaded comments are now flattened.  The system we used to use ( Brian’s threaded comments ) appears incompatible with the new threading system built into wordpress.  I haven’t yet figured out a workaround. 
 I setup a  feedburner account . 
 I added an RSS aggregator for both Machine Learning and other research blogs that I like to follow.  This is something that I’ve wanted to do for awhile. 
 Many other minor changes in font and format, with some help from  Alina . 
  
If you have any suggestions for site tweaks, please speak up.</p><p>5 0.70698071 <a title="162-lda-5" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>Introduction: I want to comment on the “Bing copies Google” discussion  here ,  here , and  here , because there are data-related issues which the general public may not understand, and some of the framing seems substantially misleading to me.
 
As a not-distant-outsider, let me mention the sources of bias I may have.  I work at  Yahoo! , which has started using  Bing .  This might predispose me towards Bing, but on the other hand I’m still at Yahoo!, and have been using  Linux  exclusively as an OS for many years, including even a couple minor kernel patches.  And,  on the gripping hand , I’ve spent quite a bit of time thinking about the basic  principles of incorporating user feedback in machine learning .  Also note, this post is not  related to official Yahoo! policy, it’s just my personal view.
 
 The issue  Google engineers inserted synthetic responses to synthetic queries on google.com, then executed the synthetic searches on google.com using Internet Explorer with the Bing toolbar and later</p><p>6 0.6971097 <a title="162-lda-6" href="../hunch_net-2005/hunch_net-2005-02-23-Problem%3A_Reinforcement_Learning_with_Classification.html">27 hunch net-2005-02-23-Problem: Reinforcement Learning with Classification</a></p>
<p>7 0.6957776 <a title="162-lda-7" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>8 0.56525296 <a title="162-lda-8" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>9 0.54940081 <a title="162-lda-9" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>10 0.54387957 <a title="162-lda-10" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>11 0.54381543 <a title="162-lda-11" href="../hunch_net-2008/hunch_net-2008-07-02-Proprietary_Data_in_Academic_Research%3F.html">306 hunch net-2008-07-02-Proprietary Data in Academic Research?</a></p>
<p>12 0.54242039 <a title="162-lda-12" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>13 0.5412513 <a title="162-lda-13" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>14 0.54111826 <a title="162-lda-14" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>15 0.5400942 <a title="162-lda-15" href="../hunch_net-2007/hunch_net-2007-03-15-Alternative_Machine_Learning_Reductions_Definitions.html">236 hunch net-2007-03-15-Alternative Machine Learning Reductions Definitions</a></p>
<p>16 0.53815973 <a title="162-lda-16" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>17 0.53799379 <a title="162-lda-17" href="../hunch_net-2009/hunch_net-2009-06-03-Functionally_defined_Nonlinear_Dynamic_Models.html">359 hunch net-2009-06-03-Functionally defined Nonlinear Dynamic Models</a></p>
<p>18 0.53785455 <a title="162-lda-18" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>19 0.53616464 <a title="162-lda-19" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>20 0.53370953 <a title="162-lda-20" href="../hunch_net-2006/hunch_net-2006-02-11-Yahoo%26%238217%3Bs_Learning_Problems..html">156 hunch net-2006-02-11-Yahoo&#8217;s Learning Problems.</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
