<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>153 hunch net-2006-02-02-Introspectionism as a Disease</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-153" href="#">hunch_net-2006-153</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>153 hunch net-2006-02-02-Introspectionism as a Disease</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-153-html" href="http://hunch.net/?p=164">html</a></p><p>Introduction: In the AI-related parts of machine learning, it is often tempting to examine
howyoudo things in order to imagine how a machine should do things. This is
introspection, and it can easily go awry. I will call introspection gone awry
introspectionism.Introspectionism is almost unique to AI (and the AI-related
parts of machine learning) and it can lead to huge wasted effort in research.
It's easiest to show how introspectionism arises by an example.Suppose we want
to solve the problem of navigating a robot from point A to point B given a
camera. Then, the following research action plan might seem natural when you
examine your own capabilities:Build an edge detector for still images.Build an
object recognition system given the edge detector.Build a system to predict
distance and orientation to objects given the object recognition system.Build
a system to plan a path through the scene you construct from {object
identification, distance, orientation} predictions.As you execute the above,
cons</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('detector', 0.337), ('introspection', 0.253), ('edge', 0.242), ('path', 0.24), ('energy', 0.231), ('avoids', 0.218), ('introspectionism', 0.169), ('computation', 0.151), ('orientation', 0.15), ('scene', 0.15), ('object', 0.143), ('scenes', 0.131), ('conservative', 0.12), ('examine', 0.116), ('fill', 0.116), ('might', 0.114), ('need', 0.111), ('objects', 0.109), ('distance', 0.103), ('parts', 0.103)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="153-tfidf-1" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>Introduction: In the AI-related parts of machine learning, it is often tempting to examine
howyoudo things in order to imagine how a machine should do things. This is
introspection, and it can easily go awry. I will call introspection gone awry
introspectionism.Introspectionism is almost unique to AI (and the AI-related
parts of machine learning) and it can lead to huge wasted effort in research.
It's easiest to show how introspectionism arises by an example.Suppose we want
to solve the problem of navigating a robot from point A to point B given a
camera. Then, the following research action plan might seem natural when you
examine your own capabilities:Build an edge detector for still images.Build an
object recognition system given the edge detector.Build a system to predict
distance and orientation to objects given the object recognition system.Build
a system to plan a path through the scene you construct from {object
identification, distance, orientation} predictions.As you execute the above,
cons</p><p>2 0.11750237 <a title="153-tfidf-2" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>Introduction: Manifold based dimension-reduction algorithms share the following general
outline.Given: a metricd()and a set of pointsSConstruct a graph with a point
in every node and every edge connecting to the node of one of thek-nearest
neighbors. Associate with the edge a weight which is the distance between the
points in the connected nodes.Digest the graph. This might include computing
the shortest path between all points or figuring out how to linearly
interpolate the point from it's neighbors.Find a set of points in a low
dimensional space which preserve the digested properties.Examples include LLE,
Isomap (which I worked on), Hessian-LLE, SDE, and many others. The hope with
these algorithms is that they can recover the low dimensional structure of
point sets in high dimensional spaces. Many of them can be shown to work in
interesting ways producing various compelling pictures.Despite doing some
early work in this direction, I suffer from a motivational problem: Why do we
want to recover the</p><p>3 0.085603669 <a title="153-tfidf-3" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>Introduction: David Mcallestergave a talk about thispaper(withPedro Felzenszwalb). I'll try
to give a high level summary of why it's interesting.Dynamic programming is
most familiar as instantiated by Viterbi decoding in a hidden markov model. It
is a general paradigm for problem solving where subproblems are solved and
used to solve larger problems. In the Viterbi decoding example, the subproblem
is "What is the most probable path ending at each state at timestept?", and
the larger problem is the same except at timestept+1. There are a few
optimizations you can do here:Dynamic Programming -> queued Dynamic
Programming. Keep track of the "cost so far" (or "most probable path") and
(carefully) only look at extensions to paths likely to yield the shortest
path. "Carefully" here is defined byDijkstra's shortest path algorithm.queued
Dynamic programming -> A*Add a lower bound on the cost to complete a path (or
an upper bound on the probability of a completion) for the priority queue of
Dijkstra's shorte</p><p>4 0.08474917 <a title="153-tfidf-4" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>Introduction: I recently had fun discussions with bothVikash MansinghkaandThomas Breuelabout
approaching AI with machine learning. The general interest in taking a crack
at AI with machine learning seems to be rising on many fronts
includingDARPA.As a matter of history, there was a great deal of interest in
AI which died down before I began research. There remain many projects and
conferences spawned in this earlier AI wave, as well as a good bit of
experience about what did not work, or at least did not work yet. Here are a
few examples of failure modes that people seem to run into:Supply/Product
confusion. Sometimes we think "Intelligences use X, so I'll create X and have
an Intelligence." An example of this is theCyc Projectwhich inspires some
people as "intelligences use ontologies, so I'll create an ontology and a
system using it to have an Intelligence." The flaw here is that
Intelligencescreateontologies, which they use, and without the ability to
create ontologies you don't have an Intellige</p><p>5 0.083754927 <a title="153-tfidf-5" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>6 0.083412871 <a title="153-tfidf-6" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>7 0.079516396 <a title="153-tfidf-7" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>8 0.077650577 <a title="153-tfidf-8" href="../hunch_net-2009/hunch_net-2009-08-03-Carbon_in_Computer_Science_Research.html">366 hunch net-2009-08-03-Carbon in Computer Science Research</a></p>
<p>9 0.074756287 <a title="153-tfidf-9" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>10 0.072034098 <a title="153-tfidf-10" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>11 0.071506217 <a title="153-tfidf-11" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>12 0.071154147 <a title="153-tfidf-12" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>13 0.070143461 <a title="153-tfidf-13" href="../hunch_net-2012/hunch_net-2012-05-12-ICML_accepted_papers_and_early_registration.html">465 hunch net-2012-05-12-ICML accepted papers and early registration</a></p>
<p>14 0.069858514 <a title="153-tfidf-14" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>15 0.069086768 <a title="153-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>16 0.068891399 <a title="153-tfidf-16" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>17 0.068242282 <a title="153-tfidf-17" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>18 0.067553125 <a title="153-tfidf-18" href="../hunch_net-2006/hunch_net-2006-08-07-The_Call_of_the_Deep.html">201 hunch net-2006-08-07-The Call of the Deep</a></p>
<p>19 0.066574141 <a title="153-tfidf-19" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>20 0.066478439 <a title="153-tfidf-20" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.171), (1, -0.015), (2, 0.058), (3, -0.068), (4, 0.012), (5, 0.024), (6, -0.046), (7, 0.034), (8, 0.033), (9, 0.025), (10, 0.031), (11, 0.021), (12, 0.026), (13, -0.013), (14, 0.042), (15, 0.037), (16, 0.003), (17, -0.016), (18, -0.014), (19, -0.028), (20, -0.015), (21, 0.11), (22, -0.021), (23, -0.014), (24, 0.016), (25, 0.014), (26, -0.048), (27, -0.052), (28, 0.031), (29, 0.054), (30, 0.024), (31, 0.052), (32, 0.032), (33, 0.016), (34, -0.04), (35, 0.046), (36, 0.024), (37, -0.009), (38, -0.025), (39, 0.014), (40, 0.038), (41, -0.09), (42, -0.006), (43, -0.022), (44, 0.079), (45, 0.024), (46, 0.013), (47, -0.034), (48, -0.002), (49, 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9418633 <a title="153-lsi-1" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>Introduction: In the AI-related parts of machine learning, it is often tempting to examine
howyoudo things in order to imagine how a machine should do things. This is
introspection, and it can easily go awry. I will call introspection gone awry
introspectionism.Introspectionism is almost unique to AI (and the AI-related
parts of machine learning) and it can lead to huge wasted effort in research.
It's easiest to show how introspectionism arises by an example.Suppose we want
to solve the problem of navigating a robot from point A to point B given a
camera. Then, the following research action plan might seem natural when you
examine your own capabilities:Build an edge detector for still images.Build an
object recognition system given the edge detector.Build a system to predict
distance and orientation to objects given the object recognition system.Build
a system to plan a path through the scene you construct from {object
identification, distance, orientation} predictions.As you execute the above,
cons</p><p>2 0.76498389 <a title="153-lsi-2" href="../hunch_net-2008/hunch_net-2008-01-28-Sufficient_Computation.html">287 hunch net-2008-01-28-Sufficient Computation</a></p>
<p>Introduction: Do we have computer hardware sufficient for AI? This question is difficult to
answer, but here's a try:One way to achieve AI is by simulating a human brain.
A human brain has about 1015synapses which operate at about 102per second
implying about 1017bit ops per second.A modern computer runs at
109cycles/second and operates on 102bits per cycle implying 1011bits processed
per second.The gap here is only 6 orders of magnitude, which can be plausibly
surpassed via cluster machines. For example, theBlueGene/Loperates 105nodes
(one order of magnitude short). It's peak recorded performance is about
0.5*1015FLOPS which translates to about 1016bit ops per second, which is
nearly 1017.There are many criticisms (both positive and negative) for this
argument.Simulation of a human brain might require substantially more detail.
Perhaps an additional 102is required per neuron.We may not need to simulate a
human brain to achieve AI. There are certainly many examples where we have
been able to design</p><p>3 0.6377328 <a title="153-lsi-3" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>Introduction: Watsonconvincingly beat the best championJeopardy!players. The apparent
significance of this varies hugely, depending on your background knowledge
about the related machine learning, NLP, and search technology. For a random
person, this might seem evidence of serious machine intelligence, while for
people working on the system itself, it probably seems like a reasonably good
assemblage of existing technologies with several twists to make the entire
system work.Above all, I think we should congratulate the people who managed
to put together and execute this project--many years of effort by a diverse
set of highly skilled people were needed to make this happen. In academia,
it's pretty difficult for one professor to assemble that quantity of talent,
and in industry it's rarely the case that such a capable group has both a
worthwhile project and the support needed to pursue something like this for
several years before success.Alinainvited me to the Jeopardy watching party
atIBM, which was</p><p>4 0.60329807 <a title="153-lsi-4" href="../hunch_net-2005/hunch_net-2005-11-05-The_design_of_a_computing_cluster.html">128 hunch net-2005-11-05-The design of a computing cluster</a></p>
<p>Introduction: This is about the design of a computing cluster from the viewpoint of applied
machine learning using current technology. We just built a small one at TTI so
this is some evidence of what is feasible and thoughts about the design
choices.ArchitectureThere are several architectural choices.AMD Athlon64 based
system. This seems to have the cheapest bang/buck. Maximum RAM is typically
2-3GB.AMD Opteron based system. Opterons provide the additional capability to
buy an SMP motherboard with two chips, and the motherboards often support 16GB
of RAM. The RAM is also the more expensive error correcting type.Intel PIV or
Xeon based system. The PIV and Xeon based systems are the intel analog of the
above 2. Due to architectural design reasons, these chips tend to run a bit
hotter and be a bit more expensive.Dual core chips. Both Intel and AMD have
chips that actually have 2 processors embedded in them.In the end, we decided
to go with option (2). Roughly speaking, the AMD system seemed like a bet</p><p>5 0.5945276 <a title="153-lsi-5" href="../hunch_net-2008/hunch_net-2008-04-12-It_Doesn%26%238217%3Bt_Stop.html">295 hunch net-2008-04-12-It Doesn&#8217;t Stop</a></p>
<p>Introduction: I've enjoyed theTerminatormovies and show. Neglecting the whacky aspects (time
travel and associated paradoxes), there is an enduring topic of discussion:
how do people deal with intelligent machines (and vice versa)?In Terminator-
land, the primary method for dealing with intelligent machines is to prevent
them from being made. This approach works pretty badly, because a new angle on
building an intelligent machine keeps coming up. This is partly a ploy for
writer's to avoid writing themselves out of a job, but there is a fundamental
truth to it as well: preventing progress in research is hard.The United
States, has been experimenting with trying to stop research onstem cells. It
hasn't worked very well--the net effect has been retarding research programs a
bit, and exporting some research to other countries. Another less recent
example was encryption technology, for which the United States generally did
not encourage early public research and evendiscouraged as a munition. This
slowe</p><p>6 0.59155607 <a title="153-lsi-6" href="../hunch_net-2009/hunch_net-2009-05-06-Machine_Learning_to_AI.html">352 hunch net-2009-05-06-Machine Learning to AI</a></p>
<p>7 0.58786857 <a title="153-lsi-7" href="../hunch_net-2011/hunch_net-2011-08-06-Interesting_thing_at_UAI_2011.html">440 hunch net-2011-08-06-Interesting thing at UAI 2011</a></p>
<p>8 0.57203186 <a title="153-lsi-8" href="../hunch_net-2007/hunch_net-2007-09-16-Optimizing_Machine_Learning_Programs.html">262 hunch net-2007-09-16-Optimizing Machine Learning Programs</a></p>
<p>9 0.56916595 <a title="153-lsi-9" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>10 0.56706703 <a title="153-lsi-10" href="../hunch_net-2009/hunch_net-2009-11-29-AI_Safety.html">380 hunch net-2009-11-29-AI Safety</a></p>
<p>11 0.56267762 <a title="153-lsi-11" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>12 0.55805671 <a title="153-lsi-12" href="../hunch_net-2007/hunch_net-2007-07-28-Asking_questions.html">257 hunch net-2007-07-28-Asking questions</a></p>
<p>13 0.53954101 <a title="153-lsi-13" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>14 0.5373829 <a title="153-lsi-14" href="../hunch_net-2007/hunch_net-2007-06-21-Presentation_Preparation.html">249 hunch net-2007-06-21-Presentation Preparation</a></p>
<p>15 0.53497595 <a title="153-lsi-15" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<p>16 0.52667999 <a title="153-lsi-16" href="../hunch_net-2009/hunch_net-2009-05-08-Computability_in_Artificial_Intelligence.html">353 hunch net-2009-05-08-Computability in Artificial Intelligence</a></p>
<p>17 0.5251326 <a title="153-lsi-17" href="../hunch_net-2006/hunch_net-2006-09-07-Objective_and_subjective_interpretations_of_probability.html">205 hunch net-2006-09-07-Objective and subjective interpretations of probability</a></p>
<p>18 0.52058154 <a title="153-lsi-18" href="../hunch_net-2005/hunch_net-2005-03-30-What_can_Type_Theory_teach_us_about_Machine_Learning%3F.html">49 hunch net-2005-03-30-What can Type Theory teach us about Machine Learning?</a></p>
<p>19 0.51157379 <a title="153-lsi-19" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>20 0.50243753 <a title="153-lsi-20" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(9, 0.341), (10, 0.012), (16, 0.011), (35, 0.03), (42, 0.237), (45, 0.014), (68, 0.035), (69, 0.048), (74, 0.132), (76, 0.027), (95, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97192335 <a title="153-lda-1" href="../hunch_net-2009/hunch_net-2009-01-28-Nielsen%26%238217%3Bs_talk.html">340 hunch net-2009-01-28-Nielsen&#8217;s talk</a></p>
<p>Introduction: I wanted to point toMichael Nielsen's talkabout blogging science, which I
found interesting.</p><p>same-blog 2 0.85631096 <a title="153-lda-2" href="../hunch_net-2006/hunch_net-2006-02-02-Introspectionism_as_a_Disease.html">153 hunch net-2006-02-02-Introspectionism as a Disease</a></p>
<p>Introduction: In the AI-related parts of machine learning, it is often tempting to examine
howyoudo things in order to imagine how a machine should do things. This is
introspection, and it can easily go awry. I will call introspection gone awry
introspectionism.Introspectionism is almost unique to AI (and the AI-related
parts of machine learning) and it can lead to huge wasted effort in research.
It's easiest to show how introspectionism arises by an example.Suppose we want
to solve the problem of navigating a robot from point A to point B given a
camera. Then, the following research action plan might seem natural when you
examine your own capabilities:Build an edge detector for still images.Build an
object recognition system given the edge detector.Build a system to predict
distance and orientation to objects given the object recognition system.Build
a system to plan a path through the scene you construct from {object
identification, distance, orientation} predictions.As you execute the above,
cons</p><p>3 0.79864049 <a title="153-lda-3" href="../hunch_net-2005/hunch_net-2005-02-21-Problem%3A_Cross_Validation.html">26 hunch net-2005-02-21-Problem: Cross Validation</a></p>
<p>Introduction: The essential problem here is the large gap between experimental observation
and theoretical understanding.MethodK-fold cross validation is a commonly used
technique which takes a set ofmexamples and partitions them intoKsets
("folds") of sizem/K. For each fold, a classifier is trained on the other
folds and then test on the fold.ProblemAssume only independent samples. Derive
a classifier from the K classifiers with a small bound on the true error
rate.Past Work(I'll add more as I remember/learn.)Devroye, Rogers, and Wagner
analyzed cross validation and found algorithm specific bounds. Not all of this
is online, but here is onepaper.Michael KearnsandDana Ronanalyzed cross
validationand found that under additional stability assumptions the bound for
the classifier which learns on all the data is not much worse than for a test
set of sizem/K.Avrim Blum,Adam Kalai, andmyselfanalyzed cross validationand
found that you can do at least as well as a test set of sizem/Kwith no
additional assum</p><p>4 0.62593967 <a title="153-lda-4" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>Introduction: Normally, I don't indulge in posters forICML, but this year is naturally an
exception for me. If you want one, there are a small numberleft here, if you
sign up before February.It also seems worthwhile to give some sense of the
scope and reviewing criteria for ICML for authors considering submitting
papers. At ICML, the (very large) program committee does the reviewing which
informs final decisions by area chairs on most papers. Program chairs setup
the process, deal with exceptions or disagreements, and provide advice for the
reviewing process. Providing advice is tricky (and easily misleading) because
a conference is a community, and in the end the aggregate interests of the
community determine the conference. Nevertheless, as a program chair this year
it seems worthwhile to state the overall philosophy I have and what I plan to
encourage (and occasionally discourage).At the highest level, I believe ICML
exists to further research into machine learning, which I generally think of
as</p><p>5 0.62395591 <a title="153-lda-5" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>Introduction: Few would mistake the process of academic paper review for a fair process, but
sometimes the unfairness seems particularly striking. This is most easily seen
by comparison:PaperBanditronOffset TreeNotesProblem ScopeMulticlass problems
where only the loss of one choice can be probed.Strictly greater: Cost
sensitive multiclass problems where only the loss of one choice can be
probed.Often generalizations don't matter. That's not the case here, since
every plausible application I've thought of involves loss functions
substantially different from 0/1.What's newAnalysis and ExperimentsAlgorithm,
Analysis, and ExperimentsAs far as I know, the essence of the more general
problem was first stated and analyzed with theEXP4 algorithm (page 16)(1998).
It's also the time horizon 1 simplification of the Reinforcement Learning
setting for therandom trajectory method (page 15)(2002). The Banditron
algorithm itself is functionally identical toOne-Step RL with Traces (page
122)(2003) inBianca's thesis</p><p>6 0.62387955 <a title="153-lda-6" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>7 0.62150282 <a title="153-lda-7" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>8 0.61952251 <a title="153-lda-8" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>9 0.61940759 <a title="153-lda-9" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>10 0.6169337 <a title="153-lda-10" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>11 0.61663198 <a title="153-lda-11" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>12 0.61449593 <a title="153-lda-12" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>13 0.61310107 <a title="153-lda-13" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>14 0.61273593 <a title="153-lda-14" href="../hunch_net-2008/hunch_net-2008-11-10-ICML_Reviewing_Criteria.html">325 hunch net-2008-11-10-ICML Reviewing Criteria</a></p>
<p>15 0.612441 <a title="153-lda-15" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>16 0.61192447 <a title="153-lda-16" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>17 0.61147314 <a title="153-lda-17" href="../hunch_net-2009/hunch_net-2009-09-18-Necessary_and_Sufficient_Research.html">370 hunch net-2009-09-18-Necessary and Sufficient Research</a></p>
<p>18 0.61091268 <a title="153-lda-18" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>19 0.6108734 <a title="153-lda-19" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>20 0.61045748 <a title="153-lda-20" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
