<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2011" href="../home/hunch_net-2011_home.html">hunch_net-2011</a> <a title="hunch_net-2011-445" href="#">hunch_net-2011-445</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2011-445-html" href="http://hunch.net/?p=2016">html</a></p><p>Introduction: Since we last discussedthe other online learning,Stanfordhas very visibly
started pushing mass teaching inAI,Machine Learning, andDatabases. In
retrospect, it's not too surprising that the next step up in serious online
teaching experiments are occurring at the computer science department of a
university embedded in the land of startups. Numbers on the order of100000are
quite significant--similar in scale to the number ofcomputer science
undergraduate students/yearin the US. Although these populations surely
differ, the fact that theycouldoverlap is worth considering for the
future.It's too soon to say how successful these classes will be and there are
many easy criticisms to make:Registration != Learning… but if only 1/10th
complete these classes, the scale of teaching still surpasses the scale of any
traditional process.1st year excitement != nth year routine… but if only
1/10th take future classes, the scale of teaching still surpasses the scale of
any traditional process.Hello, che</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('teaching', 0.493), ('classes', 0.296), ('prospect', 0.229), ('universities', 0.216), ('scale', 0.215), ('boutique', 0.172), ('surpasses', 0.172), ('students', 0.157), ('traditional', 0.151), ('make', 0.136), ('serious', 0.112), ('miss', 0.108), ('mass', 0.108), ('university', 0.105), ('soon', 0.101), ('online', 0.1), ('testing', 0.099), ('money', 0.093), ('means', 0.083), ('embedded', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="445-tfidf-1" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>Introduction: Since we last discussedthe other online learning,Stanfordhas very visibly
started pushing mass teaching inAI,Machine Learning, andDatabases. In
retrospect, it's not too surprising that the next step up in serious online
teaching experiments are occurring at the computer science department of a
university embedded in the land of startups. Numbers on the order of100000are
quite significant--similar in scale to the number ofcomputer science
undergraduate students/yearin the US. Although these populations surely
differ, the fact that theycouldoverlap is worth considering for the
future.It's too soon to say how successful these classes will be and there are
many easy criticisms to make:Registration != Learning… but if only 1/10th
complete these classes, the scale of teaching still surpasses the scale of any
traditional process.1st year excitement != nth year routine… but if only
1/10th take future classes, the scale of teaching still surpasses the scale of
any traditional process.Hello, che</p><p>2 0.27301183 <a title="445-tfidf-2" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>Introduction: If you search for "online learning" with anymajorsearchengine, it's
interesting to note that zero of the results are for online machine learning.
This may not be a mistake if you are committed to a global ordering. In other
words, the number of people specifically interested in the least interesting
top-10 online human learning result might exceed the number of people
interested in online machine learning, even given the presence of the other 9
results. The essential observation here is that the process of human learning
is a big business (around 5% of GDP) effecting virtually everyone.The internet
is changing this dramatically, by altering the economics of teaching. Consider
two possibilities:The classroom-style teaching environment continues as is,
with many teachers for the same subject.All the teachers for one subject get
together, along with perhaps a factor of 2 more people who are experts in
online delivery. They spend a factor of 4 more time designing the perfect
lecture & lear</p><p>3 0.1827341 <a title="445-tfidf-3" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>Introduction: Yann LeCunand I are coteaching a class onLarge Scale Machine Learningstarting
late Januaryat NYU. This class will cover many tricks to get machine learning
working well on datasets with many features, examples, and classes, along with
several elements of deep learning and support systems enabling the
previous.This is not a beginning class--you really need to have taken a basic
machine learning class previously to follow along. Students will be able to
run and experiment with large scale learning algorithms sinceYahoo!has donated
servers which are being configured into a small scaleHadoopcluster. We are
planning to cover the frontier of research in scalable learning algorithms, so
good class projects could easily lead to papers.For me, this is a chance to
teach on many topics of past research. In general, it seems like researchers
should engage in at least occasional teaching of research, both as a proof of
teachability and to see their own research through that lens. More generally,
I</p><p>4 0.16427423 <a title="445-tfidf-4" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>Introduction: How do you create an optimal environment for research? Here are some essential
ingredients that I see.Stability. University-based research is relatively good
at this. On any particular day, researchers face choices in what they will
work on. A very common tradeoff is between:easy smalldifficult bigFor
researchers without stability, the 'easy small' option wins. This is often
"ok"--a series of incremental improvements on the state of the art can add up
to something very beneficial. However, it misses one of the big potentials of
research: finding entirely new and better ways of doing things.Stability comes
in many forms. The prototypical example is tenure at a university--a tenured
professor is almost imposssible to fire which means that the professor has the
freedom to consider far horizon activities. An iron-clad guarantee of a
paycheck is not necessary--industrial research labs have succeeded well with
research positions of indefinite duration. Atnt research was a great example
of th</p><p>5 0.1559695 <a title="445-tfidf-5" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>Introduction: With a worldwide recession on, my impression is that the carnage in research
has not been as severe as might be feared, at least in the United States. I
know of two notable negative impacts:It's quite difficult to get a job this
year, as many companies and universities simply aren't hiring. This is
particularly tough on graduating students.Perhaps 10% ofIBM researchwas
fired.In contrast, around the time of the dot com bust,ATnT
ResearchandLucenthad one or several 50% size firings wiping out much of the
remainder ofBell Labs, triggering a notable diaspora for the respected machine
learning group there. As the recession progresses, we may easily see more
firings as companies in particular reach a point where they can no longer
support research.There are a couple positives to the recession as well.Both
the implosion of Wall Street (which siphoned off smart people) and the general
difficulty of getting a job coming out of an undergraduate education suggest
that the quality of admitted phd</p><p>6 0.1525737 <a title="445-tfidf-6" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>7 0.1272905 <a title="445-tfidf-7" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>8 0.12459824 <a title="445-tfidf-8" href="../hunch_net-2008/hunch_net-2008-02-10-Complexity_Illness.html">288 hunch net-2008-02-10-Complexity Illness</a></p>
<p>9 0.11926886 <a title="445-tfidf-9" href="../hunch_net-2007/hunch_net-2007-01-15-The_Machine_Learning_Department.html">228 hunch net-2007-01-15-The Machine Learning Department</a></p>
<p>10 0.10550572 <a title="445-tfidf-10" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>11 0.10472051 <a title="445-tfidf-11" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>12 0.099713013 <a title="445-tfidf-12" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>13 0.093197025 <a title="445-tfidf-13" href="../hunch_net-2005/hunch_net-2005-03-05-Funding_Research.html">36 hunch net-2005-03-05-Funding Research</a></p>
<p>14 0.09194044 <a title="445-tfidf-14" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>15 0.09142144 <a title="445-tfidf-15" href="../hunch_net-2005/hunch_net-2005-10-16-Complexity%3A_It%26%238217%3Bs_all_in_your_head.html">123 hunch net-2005-10-16-Complexity: It&#8217;s all in your head</a></p>
<p>16 0.090644546 <a title="445-tfidf-16" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>17 0.088335767 <a title="445-tfidf-17" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>18 0.086639352 <a title="445-tfidf-18" href="../hunch_net-2008/hunch_net-2008-02-27-The_Stats_Handicap.html">290 hunch net-2008-02-27-The Stats Handicap</a></p>
<p>19 0.086253576 <a title="445-tfidf-19" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>20 0.08373452 <a title="445-tfidf-20" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.196), (1, 0.052), (2, 0.134), (3, -0.074), (4, 0.066), (5, 0.026), (6, 0.108), (7, 0.077), (8, -0.041), (9, -0.084), (10, 0.045), (11, 0.018), (12, -0.057), (13, -0.071), (14, -0.025), (15, 0.067), (16, 0.031), (17, 0.107), (18, 0.003), (19, -0.012), (20, 0.052), (21, 0.06), (22, 0.006), (23, 0.007), (24, 0.008), (25, -0.157), (26, -0.062), (27, -0.02), (28, 0.008), (29, -0.004), (30, -0.069), (31, -0.104), (32, 0.04), (33, -0.007), (34, -0.074), (35, 0.021), (36, 0.033), (37, 0.033), (38, -0.014), (39, -0.046), (40, 0.114), (41, 0.051), (42, -0.021), (43, 0.201), (44, -0.041), (45, 0.097), (46, -0.048), (47, -0.078), (48, 0.052), (49, -0.001)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98040807 <a title="445-lsi-1" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>Introduction: Since we last discussedthe other online learning,Stanfordhas very visibly
started pushing mass teaching inAI,Machine Learning, andDatabases. In
retrospect, it's not too surprising that the next step up in serious online
teaching experiments are occurring at the computer science department of a
university embedded in the land of startups. Numbers on the order of100000are
quite significant--similar in scale to the number ofcomputer science
undergraduate students/yearin the US. Although these populations surely
differ, the fact that theycouldoverlap is worth considering for the
future.It's too soon to say how successful these classes will be and there are
many easy criticisms to make:Registration != Learning… but if only 1/10th
complete these classes, the scale of teaching still surpasses the scale of any
traditional process.1st year excitement != nth year routine… but if only
1/10th take future classes, the scale of teaching still surpasses the scale of
any traditional process.Hello, che</p><p>2 0.7157256 <a title="445-lsi-2" href="../hunch_net-2009/hunch_net-2009-11-15-The_Other_Online_Learning.html">378 hunch net-2009-11-15-The Other Online Learning</a></p>
<p>Introduction: If you search for "online learning" with anymajorsearchengine, it's
interesting to note that zero of the results are for online machine learning.
This may not be a mistake if you are committed to a global ordering. In other
words, the number of people specifically interested in the least interesting
top-10 online human learning result might exceed the number of people
interested in online machine learning, even given the presence of the other 9
results. The essential observation here is that the process of human learning
is a big business (around 5% of GDP) effecting virtually everyone.The internet
is changing this dramatically, by altering the economics of teaching. Consider
two possibilities:The classroom-style teaching environment continues as is,
with many teachers for the same subject.All the teachers for one subject get
together, along with perhaps a factor of 2 more people who are experts in
online delivery. They spend a factor of 4 more time designing the perfect
lecture & lear</p><p>3 0.63791043 <a title="445-lsi-3" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>Introduction: Yann LeCunand I are coteaching a class onLarge Scale Machine Learningstarting
late Januaryat NYU. This class will cover many tricks to get machine learning
working well on datasets with many features, examples, and classes, along with
several elements of deep learning and support systems enabling the
previous.This is not a beginning class--you really need to have taken a basic
machine learning class previously to follow along. Students will be able to
run and experiment with large scale learning algorithms sinceYahoo!has donated
servers which are being configured into a small scaleHadoopcluster. We are
planning to cover the frontier of research in scalable learning algorithms, so
good class projects could easily lead to papers.For me, this is a chance to
teach on many topics of past research. In general, it seems like researchers
should engage in at least occasional teaching of research, both as a proof of
teachability and to see their own research through that lens. More generally,
I</p><p>4 0.61321574 <a title="445-lsi-4" href="../hunch_net-2008/hunch_net-2008-02-27-The_Stats_Handicap.html">290 hunch net-2008-02-27-The Stats Handicap</a></p>
<p>Introduction: Graduating students in Statistics appear to be at a substantial handicap
compared to graduating students in Machine Learning, despite being in
substantially overlapping subjects.The problem seems to be cultural.
Statistics comes from a mathematics background which emphasizes large
publications slowly published under review at journals. Machine Learning comes
from a Computer Science background which emphasizes quick publishing at
reviewed conferences. This has a number of implications:Graduating statistics
PhDs often have 0-2 publications while graduating machine learning PhDs might
have 5-15.Graduating ML students have had a chance for others to build on
their work. Stats students have had no such chance.Graduating ML students have
attended a number of conferences and presented their work, giving them a
chance to meet people. Stats students have had fewer chances of this sort.In
short, Stats students have had relatively few chances to distinguish
themselves and are heavily reliant on t</p><p>5 0.60187262 <a title="445-lsi-5" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>Introduction: Thanksgiving is perhaps my favorite holiday, because pausing your life and
giving thanks provides a needed moment of perspective.As a researcher, I am
most thankful for my education, without which I could not function. I want to
share this, because it provides some sense of how a researcher starts.My long
term memory seems to function particularly well, which makes any education I
get is particularly useful.I am naturally obsessive, which makes me chase down
details until I fully understand things. Natural obsessiveness can go wrong,
of course, but it's a great ally when you absolutely must get things right.My
childhood was all in one hometown, which was a conscious sacrifice on the part
of my father, implying disruptions from moving around were eliminated. I'm not
sure how important this was since travel has it's own benefits, but it bears
thought.I had several great teachers in grade school, and naturally gravitated
towards teachers over classmates, as they seemed more interesting. I</p><p>6 0.57776004 <a title="445-lsi-6" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>7 0.57372898 <a title="445-lsi-7" href="../hunch_net-2005/hunch_net-2005-05-17-A_Short_Guide_to_PhD_Graduate_Study.html">73 hunch net-2005-05-17-A Short Guide to PhD Graduate Study</a></p>
<p>8 0.56347013 <a title="445-lsi-8" href="../hunch_net-2009/hunch_net-2009-10-03-Static_vs._Dynamic_multiclass_prediction.html">373 hunch net-2009-10-03-Static vs. Dynamic multiclass prediction</a></p>
<p>9 0.54567993 <a title="445-lsi-9" href="../hunch_net-2014/hunch_net-2014-02-16-Metacademy%3A_a_package_manager_for_knowledge.html">493 hunch net-2014-02-16-Metacademy: a package manager for knowledge</a></p>
<p>10 0.51233029 <a title="445-lsi-10" href="../hunch_net-2009/hunch_net-2009-01-27-Key_Scientific_Challenges.html">339 hunch net-2009-01-27-Key Scientific Challenges</a></p>
<p>11 0.48039442 <a title="445-lsi-11" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>12 0.46621296 <a title="445-lsi-12" href="../hunch_net-2005/hunch_net-2005-05-03-Conference_attendance_is_mandatory.html">66 hunch net-2005-05-03-Conference attendance is mandatory</a></p>
<p>13 0.46292159 <a title="445-lsi-13" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>14 0.46238092 <a title="445-lsi-14" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>15 0.46003106 <a title="445-lsi-15" href="../hunch_net-2011/hunch_net-2011-06-22-Ultra_LDA.html">436 hunch net-2011-06-22-Ultra LDA</a></p>
<p>16 0.4581885 <a title="445-lsi-16" href="../hunch_net-2013/hunch_net-2013-06-10-The_Large_Scale_Learning_class_notes.html">483 hunch net-2013-06-10-The Large Scale Learning class notes</a></p>
<p>17 0.44724134 <a title="445-lsi-17" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>18 0.44703141 <a title="445-lsi-18" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>19 0.44524625 <a title="445-lsi-19" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>20 0.44210806 <a title="445-lsi-20" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(6, 0.019), (35, 0.04), (42, 0.284), (45, 0.023), (68, 0.057), (69, 0.391), (74, 0.086), (95, 0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97352552 <a title="445-lda-1" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>Introduction: The DARPA grandchallenge is a big contest for autonomous robot vehicle
driving. It was run once in 2004 for the first time and all teams did badly.
This year was notably different with theStanfordandCMUteams succesfully
completing the course. A number of details arehereandwikipedia has continuing
coverage.A formal winner hasn't been declared yet although Stanford completed
the course quickest.The Stanford and CMU teams deserve a large round of
applause as they have strongly demonstrated the feasibility of autonomous
vehicles.The good news for machine learning is that the Stanford team (at
least) is using some machine learning techniques.</p><p>2 0.96805394 <a title="445-lda-2" href="../hunch_net-2010/hunch_net-2010-08-24-Alex_Smola_starts_a_blog.html">408 hunch net-2010-08-24-Alex Smola starts a blog</a></p>
<p>Introduction: Adventures in Data Land.</p><p>3 0.96506876 <a title="445-lda-3" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>Introduction: Registration for COLT 2007 is now open.The conference will take place on 13-15
June, 2007, in San Diego, California, as part of the 2007 Federated Computing
Research Conference (FCRC), which includes STOC, Complexity, and EC.The
website for COLT: http://www.learningtheory.org/colt2007/index.htmlThe early
registration deadline is May 11, and the cutoff date for discounted hotel
rates is May 9.Before registering, take note that the fees are substantially
lower for members of ACM and/or SIGACT than for nonmembers. If you've been
contemplating joining either of these two societies (annual dues: $99 for ACM,
$18 for SIGACT), now would be a good time!</p><p>4 0.94459438 <a title="445-lda-4" href="../hunch_net-2005/hunch_net-2005-07-10-Thinking_the_Unthought.html">91 hunch net-2005-07-10-Thinking the Unthought</a></p>
<p>Introduction: One thing common to much research is that the researcher must be the first
personeverto have some thought. How do you think of something that has never
been thought of? There seems to be no methodical manner of doing this, but
there are some tricks.The easiest method is to just have some connection come
to you. There is a trick here however: you should write it down and fill out
the idea immediately because it can just as easily go away.A harder method is
to set aside a block of time and simply think about an idea. Distraction
elimination is essential here because thinking about the unthought is hard
work which your mind will avoid.Another common method is in conversation.
Sometimes the process of verbalizing implies new ideas come up and sometimes
whoever you are talking to replies just the right way. This method is
dangerous though--you must speak to someone who helps you think rather than
someone who occupies your thoughts.Try to rephrase the problem so the answer
is simple. This is</p><p>5 0.94289929 <a title="445-lda-5" href="../hunch_net-2006/hunch_net-2006-03-24-NLPers.html">166 hunch net-2006-03-24-NLPers</a></p>
<p>Introduction: Hal Daumehas started theNLPersblog to discuss learning for language problems.</p><p>same-blog 6 0.93005079 <a title="445-lda-6" href="../hunch_net-2011/hunch_net-2011-09-28-Somebody%26%238217%3Bs_Eating_Your_Lunch.html">445 hunch net-2011-09-28-Somebody&#8217;s Eating Your Lunch</a></p>
<p>7 0.92958581 <a title="445-lda-7" href="../hunch_net-2005/hunch_net-2005-11-16-The_Everything_Ensemble_Edge.html">131 hunch net-2005-11-16-The Everything Ensemble Edge</a></p>
<p>8 0.9162851 <a title="445-lda-8" href="../hunch_net-2007/hunch_net-2007-10-15-NIPS_workshops_extended_to_3_days.html">266 hunch net-2007-10-15-NIPS workshops extended to 3 days</a></p>
<p>9 0.88922679 <a title="445-lda-9" href="../hunch_net-2007/hunch_net-2007-07-20-Motivation_should_be_the_Responsibility_of_the_Reviewer.html">256 hunch net-2007-07-20-Motivation should be the Responsibility of the Reviewer</a></p>
<p>10 0.78542417 <a title="445-lda-10" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>11 0.75516355 <a title="445-lda-11" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>12 0.72939909 <a title="445-lda-12" href="../hunch_net-2005/hunch_net-2005-09-04-Science_in_the_Government.html">106 hunch net-2005-09-04-Science in the Government</a></p>
<p>13 0.71983665 <a title="445-lda-13" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>14 0.70558345 <a title="445-lda-14" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>15 0.67460352 <a title="445-lda-15" href="../hunch_net-2011/hunch_net-2011-10-24-2011_ML_symposium_and_the_bears.html">448 hunch net-2011-10-24-2011 ML symposium and the bears</a></p>
<p>16 0.67046648 <a title="445-lda-16" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>17 0.670138 <a title="445-lda-17" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>18 0.66729122 <a title="445-lda-18" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>19 0.66402572 <a title="445-lda-19" href="../hunch_net-2005/hunch_net-2005-06-06-Exact_Online_Learning_for_Classification.html">78 hunch net-2005-06-06-Exact Online Learning for Classification</a></p>
<p>20 0.66390365 <a title="445-lda-20" href="../hunch_net-2006/hunch_net-2006-02-11-Yahoo%26%238217%3Bs_Learning_Problems..html">156 hunch net-2006-02-11-Yahoo&#8217;s Learning Problems.</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
