<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>429 hunch net-2011-04-06-COLT open questions</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2011" href="../home/hunch_net-2011_home.html">hunch_net-2011</a> <a title="hunch_net-2011-429" href="#">hunch_net-2011-429</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>429 hunch net-2011-04-06-COLT open questions</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2011-429-html" href="http://hunch.net/?p=1749">html</a></p><p>Introduction: AlinaandJakepoint out the COLTCall for Open Questionsdue May 11. In general,
this is cool, and worth doing if you can come up with a crisp question. In my
case, I particularly enjoyedcrafting an open questionwith precisely a form
such that acritic targeting my paperswould be forced to confront their fallacy
or make a case for the reward. But less esoterically, this is a way to get the
attention of some very smart people focused on a problem that really matters,
which is the real value.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('confront', 0.328), ('fallacy', 0.328), ('crisp', 0.303), ('open', 0.285), ('targeting', 0.262), ('matters', 0.253), ('case', 0.241), ('forced', 0.226), ('smart', 0.221), ('focused', 0.204), ('attention', 0.204), ('precisely', 0.204), ('cool', 0.197), ('worth', 0.173), ('really', 0.121), ('come', 0.118), ('value', 0.117), ('less', 0.111), ('form', 0.105), ('particularly', 0.105)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="429-tfidf-1" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>Introduction: AlinaandJakepoint out the COLTCall for Open Questionsdue May 11. In general,
this is cool, and worth doing if you can come up with a crisp question. In my
case, I particularly enjoyedcrafting an open questionwith precisely a form
such that acritic targeting my paperswould be forced to confront their fallacy
or make a case for the reward. But less esoterically, this is a way to get the
attention of some very smart people focused on a problem that really matters,
which is the real value.</p><p>2 0.1561113 <a title="429-tfidf-2" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>Introduction: COLT has acall for open problemsdue March 21. I encourage anyone with a
specifiable open problem to write it down and send it in. Just the effort of
specifying an open problem precisely and concisely has been very helpful for
my own solutions, and there is a substantial chance others will solve it. To
increase the chance someone will take it up, you can even put a bounty on the
solution. (Perhaps I should raise the$500 bountyon theK-fold cross-validation
problemas it hasn't yet been solved).</p><p>3 0.13466215 <a title="429-tfidf-3" href="../hunch_net-2005/hunch_net-2005-03-28-Open_Problems_for_Colt.html">47 hunch net-2005-03-28-Open Problems for Colt</a></p>
<p>Introduction: Adam KlivansandRocco Servedioare looking foropen (learning theory)
problemsforCOLT. This is a good idea in the same way that the KDDcup challenge
is a good idea: crisp problem definitions that anyone can attack yield
solutions that advance science.</p><p>4 0.13023593 <a title="429-tfidf-4" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>Introduction: Centmailis a scheme which makes charity donations have a secondary value, as a
stamp for email. When discussed onnewscientist,slashdot, and others, some of
the comments make the academic review process appear thoughtful. Some
prominent fallacies are:Costing money fallacy. Some commenters appear to
believe the system charges money per email. Instead, the basic idea is that
users get an extra benefit from donations to a charity and participation is
strictly voluntary. The solution to this fallacy is simply readingthe
details.Single solution fallacy. Some commenters seem to think this is
proposed as a complete solution to spam, and since not everyone will opt to
participate, it won't work. But a complete solution is not at all necessary or
even possible given theflag-day problem. Deployed machine learning systems for
fighting spam are great at taking advantage of a partial solution. The
solution to this fallacy is learning about machine learning. In the current
state of affairs, informed</p><p>5 0.10673914 <a title="429-tfidf-5" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pooland I recently discussed the similarities and differences between
academia and open source programming.Similarities:Cost profileResearch and
programming share approximately the same cost profile: A large upfront effort
is required to produce something useful, and then "anyone" can use it. (The
"anyone" is not quite right for either group because only sufficiently
technical people could use it.)Wealth profileA "wealthy" academic or open
source programmer is someone who has contributed a lot to other people in
research or programs. Much of academia is a "gift culture": whoever gives the
most is most respected.ProblemsBoth academia and open source programming
suffer from similar problems.Whether or not (and which) open source program is
used are perhaps too-often personality driven rather than driven by capability
or usefulness. Similar phenomena can happen in academia with respect to
directions of research.Funding is often a problem for both groups. Academics
often invest many</p><p>6 0.080005944 <a title="429-tfidf-6" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>7 0.075304963 <a title="429-tfidf-7" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>8 0.073224746 <a title="429-tfidf-8" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>9 0.07239449 <a title="429-tfidf-9" href="../hunch_net-2012/hunch_net-2012-03-06-COLT-ICML_Open_Questions_and_ICML_Instructions.html">458 hunch net-2012-03-06-COLT-ICML Open Questions and ICML Instructions</a></p>
<p>10 0.06115143 <a title="429-tfidf-10" href="../hunch_net-2008/hunch_net-2008-08-04-Electoralmarkets.com.html">312 hunch net-2008-08-04-Electoralmarkets.com</a></p>
<p>11 0.058431901 <a title="429-tfidf-11" href="../hunch_net-2006/hunch_net-2006-02-11-Yahoo%26%238217%3Bs_Learning_Problems..html">156 hunch net-2006-02-11-Yahoo&#8217;s Learning Problems.</a></p>
<p>12 0.058383331 <a title="429-tfidf-12" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>13 0.057561114 <a title="429-tfidf-13" href="../hunch_net-2005/hunch_net-2005-08-04-Why_Reinforcement_Learning_is_Important.html">100 hunch net-2005-08-04-Why Reinforcement Learning is Important</a></p>
<p>14 0.055362727 <a title="429-tfidf-14" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>15 0.055123761 <a title="429-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>16 0.05461961 <a title="429-tfidf-16" href="../hunch_net-2005/hunch_net-2005-06-10-Workshops_are_not_Conferences.html">80 hunch net-2005-06-10-Workshops are not Conferences</a></p>
<p>17 0.054603338 <a title="429-tfidf-17" href="../hunch_net-2005/hunch_net-2005-05-29-Bad_ideas.html">76 hunch net-2005-05-29-Bad ideas</a></p>
<p>18 0.054590024 <a title="429-tfidf-18" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>19 0.05432795 <a title="429-tfidf-19" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>20 0.053479053 <a title="429-tfidf-20" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.11), (1, 0.008), (2, 0.038), (3, -0.032), (4, 0.049), (5, -0.021), (6, 0.016), (7, 0.01), (8, 0.054), (9, 0.006), (10, -0.019), (11, -0.035), (12, 0.056), (13, 0.082), (14, -0.036), (15, -0.043), (16, -0.014), (17, -0.031), (18, 0.011), (19, 0.037), (20, -0.021), (21, 0.096), (22, -0.04), (23, 0.028), (24, 0.003), (25, 0.052), (26, -0.001), (27, -0.078), (28, -0.023), (29, 0.103), (30, 0.018), (31, -0.166), (32, 0.012), (33, 0.047), (34, 0.005), (35, -0.104), (36, -0.0), (37, 0.033), (38, 0.032), (39, 0.05), (40, -0.118), (41, 0.012), (42, -0.105), (43, -0.032), (44, 0.009), (45, 0.074), (46, -0.09), (47, -0.017), (48, 0.048), (49, 0.126)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98522538 <a title="429-lsi-1" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>Introduction: AlinaandJakepoint out the COLTCall for Open Questionsdue May 11. In general,
this is cool, and worth doing if you can come up with a crisp question. In my
case, I particularly enjoyedcrafting an open questionwith precisely a form
such that acritic targeting my paperswould be forced to confront their fallacy
or make a case for the reward. But less esoterically, this is a way to get the
attention of some very smart people focused on a problem that really matters,
which is the real value.</p><p>2 0.67205614 <a title="429-lsi-2" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>Introduction: Martin Pooland I recently discussed the similarities and differences between
academia and open source programming.Similarities:Cost profileResearch and
programming share approximately the same cost profile: A large upfront effort
is required to produce something useful, and then "anyone" can use it. (The
"anyone" is not quite right for either group because only sufficiently
technical people could use it.)Wealth profileA "wealthy" academic or open
source programmer is someone who has contributed a lot to other people in
research or programs. Much of academia is a "gift culture": whoever gives the
most is most respected.ProblemsBoth academia and open source programming
suffer from similar problems.Whether or not (and which) open source program is
used are perhaps too-often personality driven rather than driven by capability
or usefulness. Similar phenomena can happen in academia with respect to
directions of research.Funding is often a problem for both groups. Academics
often invest many</p><p>3 0.66070396 <a title="429-lsi-3" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>Introduction: COLT has acall for open problemsdue March 21. I encourage anyone with a
specifiable open problem to write it down and send it in. Just the effort of
specifying an open problem precisely and concisely has been very helpful for
my own solutions, and there is a substantial chance others will solve it. To
increase the chance someone will take it up, you can even put a bounty on the
solution. (Perhaps I should raise the$500 bountyon theK-fold cross-validation
problemas it hasn't yet been solved).</p><p>4 0.61690742 <a title="429-lsi-4" href="../hunch_net-2005/hunch_net-2005-03-28-Open_Problems_for_Colt.html">47 hunch net-2005-03-28-Open Problems for Colt</a></p>
<p>Introduction: Adam KlivansandRocco Servedioare looking foropen (learning theory)
problemsforCOLT. This is a good idea in the same way that the KDDcup challenge
is a good idea: crisp problem definitions that anyone can attack yield
solutions that advance science.</p><p>5 0.51894808 <a title="429-lsi-5" href="../hunch_net-2012/hunch_net-2012-03-06-COLT-ICML_Open_Questions_and_ICML_Instructions.html">458 hunch net-2012-03-06-COLT-ICML Open Questions and ICML Instructions</a></p>
<p>Introduction: Sashais theopen problemschair for bothCOLTandICML. Open problems will be
presented in a joint session in the evening of the COLT/ICML overlap day. COLT
has a history of open sessions, but this is new for ICML. If you have a
difficult theoretically definable problem in machine learning, consider
submitting it for review,due March 16. You'll benefit three ways:The effort of
writing down a precise formulation of what you want often helps you understand
the nature of the problem.Your problem will be officially published and
citable.You might have it solved by some very intelligent bored people.The
general idea could easily be applied to any problem which can be crisply
stated with an easily verifiable solution, and we may consider expanding this
in later years, but for this year all problems need to be of a theoretical
variety.Joelleand I (andMahdi, andLaurent) finished an initial assignment
ofProgram CommitteeandArea Chairsto papers. We'll be updatinginstructions for
the PCand ACsas we fi</p><p>6 0.49824089 <a title="429-lsi-6" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>7 0.49419522 <a title="429-lsi-7" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<p>8 0.4871127 <a title="429-lsi-8" href="../hunch_net-2011/hunch_net-2011-03-27-Vowpal_Wabbit%2C_v5.1.html">428 hunch net-2011-03-27-Vowpal Wabbit, v5.1</a></p>
<p>9 0.45425645 <a title="429-lsi-9" href="../hunch_net-2005/hunch_net-2005-06-17-Reopening_RL-%3EClassification.html">82 hunch net-2005-06-17-Reopening RL->Classification</a></p>
<p>10 0.45149195 <a title="429-lsi-10" href="../hunch_net-2005/hunch_net-2005-02-25-Solution%3A_Reinforcement_Learning_with_Classification.html">29 hunch net-2005-02-25-Solution: Reinforcement Learning with Classification</a></p>
<p>11 0.44747174 <a title="429-lsi-11" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>12 0.44189376 <a title="429-lsi-12" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>13 0.43646404 <a title="429-lsi-13" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>14 0.4238638 <a title="429-lsi-14" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>15 0.41933984 <a title="429-lsi-15" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>16 0.3876467 <a title="429-lsi-16" href="../hunch_net-2009/hunch_net-2009-08-16-Centmail_comments.html">367 hunch net-2009-08-16-Centmail comments</a></p>
<p>17 0.38503239 <a title="429-lsi-17" href="../hunch_net-2007/hunch_net-2007-06-21-Presentation_Preparation.html">249 hunch net-2007-06-21-Presentation Preparation</a></p>
<p>18 0.37882406 <a title="429-lsi-18" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>19 0.37334538 <a title="429-lsi-19" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>20 0.35145402 <a title="429-lsi-20" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.138), (88, 0.692)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99756646 <a title="429-lda-1" href="../hunch_net-2005/hunch_net-2005-04-08-Fast_SVMs.html">54 hunch net-2005-04-08-Fast SVMs</a></p>
<p>Introduction: There was apresentation at snowbirdabout parallelized support vector machines.
In many cases, people parallelize by ignoring serial operations, but that is
not what happened here--they parallelize with optimizations. Consequently,
this seems to be the fastest SVM in existence.There is a relatedpaper here.</p><p>2 0.94891644 <a title="429-lda-2" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>Introduction: Adam Klivans, points out theCOLT call for papers. The important points are:Due
Feb 13.Montreal, June 18-21.This year, there is author feedback.</p><p>same-blog 3 0.91533113 <a title="429-lda-3" href="../hunch_net-2011/hunch_net-2011-04-06-COLT_open_questions.html">429 hunch net-2011-04-06-COLT open questions</a></p>
<p>Introduction: AlinaandJakepoint out the COLTCall for Open Questionsdue May 11. In general,
this is cool, and worth doing if you can come up with a crisp question. In my
case, I particularly enjoyedcrafting an open questionwith precisely a form
such that acritic targeting my paperswould be forced to confront their fallacy
or make a case for the reward. But less esoterically, this is a way to get the
attention of some very smart people focused on a problem that really matters,
which is the real value.</p><p>4 0.8730188 <a title="429-lda-4" href="../hunch_net-2012/hunch_net-2012-12-29-Simons_Institute_Big_Data_Program.html">476 hunch net-2012-12-29-Simons Institute Big Data Program</a></p>
<p>Introduction: Michael Jordansends the below:The newSimons Institute for the Theory of
Computingwill begin organizing semester-long programs starting in 2013.One of
our first programs, set for Fall 2013, will be on the "Theoretical
Foundationsof Big Data Analysis". The organizers of this program are Michael
Jordan (chair),Stephen Boyd, Peter Buehlmann, Ravi Kannan, Michael Mahoney,
and Muthu
Muthukrishnan.Seehttp://simons.berkeley.edu/program_bigdata2013.htmlfor more
information onthe program.The Simons Institute has created a number of
"Research Fellowships" for youngresearchers (within at most six years of the
award of their PhD) who wish toparticipate in Institute programs, including
the Big Data program. Individualswho already hold postdoctoral positions or
who are junior faculty are welcometo apply, as are finishing PhDs.Please note
that the application deadline is January 15, 2013. Further detailsare
available athttp://simons.berkeley.edu/fellows.html.Mike Jordan</p><p>5 0.75438631 <a title="429-lda-5" href="../hunch_net-2011/hunch_net-2011-12-13-Vowpal_Wabbit_version_6.1_%26%23038%3B_the_NIPS_tutorial.html">451 hunch net-2011-12-13-Vowpal Wabbit version 6.1 &#038; the NIPS tutorial</a></p>
<p>Introduction: I just madeversion 6.1ofVowpal Wabbit. Relative to6.0, there are few new
features, but many refinements.The cluster parallel learning code better
supports multiple simultaneous runs, and other forms of parallelism have been
mostly removed. This incidentally significantly simplifies the learning
core.The online learning algorithms are more general, with support for l1(via
a truncated gradient variant) and l2regularization, and a generalized form of
variable metric learning.There is a solid persistent server mode which can
train online, as well as serve answers to many simultaneous queries, either in
text or binary.This should be a very good release if you are just getting
started, as we've made it compile more automatically out of the box, have
several newexamplesand updated documentation.Aspertradition, we're planning to
do a tutorial at NIPS during the break at theparallel learning workshopat 2pm
Spanish time Friday. I'll cover the basics, leaving the fun stuff for
others.Mirowill cov</p><p>6 0.75344932 <a title="429-lda-6" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>7 0.73804635 <a title="429-lda-7" href="../hunch_net-2007/hunch_net-2007-05-08-Conditional_Tournaments_for_Multiclass_to_Binary.html">243 hunch net-2007-05-08-Conditional Tournaments for Multiclass to Binary</a></p>
<p>8 0.65453154 <a title="429-lda-8" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>9 0.47732395 <a title="429-lda-9" href="../hunch_net-2013/hunch_net-2013-01-07-NYU_Large_Scale_Machine_Learning_Class.html">478 hunch net-2013-01-07-NYU Large Scale Machine Learning Class</a></p>
<p>10 0.36140943 <a title="429-lda-10" href="../hunch_net-2006/hunch_net-2006-05-23-What_is_the_best_regret_transform_reduction_from_multiclass_to_binary%3F.html">181 hunch net-2006-05-23-What is the best regret transform reduction from multiclass to binary?</a></p>
<p>11 0.35774171 <a title="429-lda-11" href="../hunch_net-2005/hunch_net-2005-05-16-Regret_minimizing_vs_error_limiting_reductions.html">72 hunch net-2005-05-16-Regret minimizing vs error limiting reductions</a></p>
<p>12 0.32870311 <a title="429-lda-12" href="../hunch_net-2008/hunch_net-2008-03-15-COLT_Open_Problems.html">292 hunch net-2008-03-15-COLT Open Problems</a></p>
<p>13 0.32651597 <a title="429-lda-13" href="../hunch_net-2011/hunch_net-2011-03-27-Vowpal_Wabbit%2C_v5.1.html">428 hunch net-2011-03-27-Vowpal Wabbit, v5.1</a></p>
<p>14 0.28835601 <a title="429-lda-14" href="../hunch_net-2011/hunch_net-2011-08-15-Vowpal_Wabbit_6.0.html">441 hunch net-2011-08-15-Vowpal Wabbit 6.0</a></p>
<p>15 0.27483767 <a title="429-lda-15" href="../hunch_net-2010/hunch_net-2010-03-15-The_Efficient_Robust_Conditional_Probability_Estimation_Problem.html">391 hunch net-2010-03-15-The Efficient Robust Conditional Probability Estimation Problem</a></p>
<p>16 0.2720814 <a title="429-lda-16" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>17 0.26674646 <a title="429-lda-17" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>18 0.26594603 <a title="429-lda-18" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>19 0.2656725 <a title="429-lda-19" href="../hunch_net-2005/hunch_net-2005-12-04-Watchword%3A_model.html">135 hunch net-2005-12-04-Watchword: model</a></p>
<p>20 0.26389748 <a title="429-lda-20" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
