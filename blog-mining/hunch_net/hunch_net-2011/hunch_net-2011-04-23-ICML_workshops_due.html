<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>433 hunch net-2011-04-23-ICML workshops due</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2011" href="../home/hunch_net-2011_home.html">hunch_net-2011</a> <a title="hunch_net-2011-433" href="#">hunch_net-2011-433</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>433 hunch net-2011-04-23-ICML workshops due</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2011-433-html" href="http://hunch.net/?p=1814">html</a></p><p>Introduction: Lihongpoints out thatICMLworkshopsubmissions are due April 29.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('april', 0.91), ('due', 0.415)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="433-tfidf-1" href="../hunch_net-2011/hunch_net-2011-04-23-ICML_workshops_due.html">433 hunch net-2011-04-23-ICML workshops due</a></p>
<p>Introduction: Lihongpoints out thatICMLworkshopsubmissions are due April 29.</p><p>2 0.31805548 <a title="433-tfidf-2" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<p>Introduction: Adam Kalaipoints out theNew England Machine Learning DayMay 1 at MSR New
England. There is a poster session with abstracts due April 19. I understand
last year'sNEMLwent well and it's great to meet your neighbors at regional
workshops like this.</p><p>3 0.20956019 <a title="433-tfidf-3" href="../hunch_net-2008/hunch_net-2008-09-04-Fall_ML_Conferences.html">316 hunch net-2008-09-04-Fall ML Conferences</a></p>
<p>Introduction: If you are in the New York area and interested in machine learning, consider
submitting a 2 page abstract to theML symposiumby tomorrow (Sept 5th)
midnight. It's a fun one day affair on October 10 in an awesome location
overlooking the world trade center site.A bit further off (but a real
conference) is theAI and Statsdeadline on November 5, to be held in Florida
April 16-19.</p><p>4 0.16778831 <a title="433-tfidf-4" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>Introduction: A good workshop is often far more interesting than the papers at a conference.
This happens because a workshop has a much tighter focus than a conference.
Since you choose the workshops fitting your interest, the increased relevance
can greatly enhance the level of your interest and attention. Roughly
speaking, a workshop program consists of elements related to a subject of your
interest. The main conference program consists of elements related to
someone's interest (which is rarely your own). Workshops are more about doing
research while conferences are more about presenting research.Several
conferences have associated workshop programs, some with deadlines due
shortly.ICML workshopsDue April 1IJCAI workshopsDeadlines VaryKDD workshopsNot
yet finalizedAnyone going to these conferences should examine the workshops
and see if any are of interest. (If none are, then maybe you should organize
one next year.)</p><p>5 0.12262475 <a title="433-tfidf-5" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>Introduction: Many of theNIPS workshopshave a deadline about now, and the NIPSearly
registration deadline is Nov. 6. Several interest me:Adaptive Sensing, Active
Learning, and Experimental Designdue 10/27.Discrete Optimization in Machine
Learning: Submodularity, Sparsity & Polyhedra, due Nov. 6.Large-Scale Machine
Learning: Parallelism and Massive Datasets, due 10/23 (i.e. past)Analysis and
Design of Algorithms for Interactive Machine Learning, due 10/30.And I'm sure
many of the others interest others. Workshops are great as a mechanism for
research, so take a look if there is any chance you might be interested.</p><p>6 0.094846405 <a title="433-tfidf-6" href="../hunch_net-2008/hunch_net-2008-01-07-2008_Summer_Machine_Learning_Conference_Schedule.html">283 hunch net-2008-01-07-2008 Summer Machine Learning Conference Schedule</a></p>
<p>7 0.082404457 <a title="433-tfidf-7" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>8 0.080132015 <a title="433-tfidf-8" href="../hunch_net-2011/hunch_net-2011-05-09-CI_Fellows%2C_again.html">434 hunch net-2011-05-09-CI Fellows, again</a></p>
<p>9 0.07889764 <a title="433-tfidf-9" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>10 0.071909085 <a title="433-tfidf-10" href="../hunch_net-2005/hunch_net-2005-10-19-Workshop%3A_Atomic_Learning.html">124 hunch net-2005-10-19-Workshop: Atomic Learning</a></p>
<p>11 0.07053367 <a title="433-tfidf-11" href="../hunch_net-2011/hunch_net-2011-02-25-Yahoo%21_Machine_Learning_grant_due_March_11.html">425 hunch net-2011-02-25-Yahoo! Machine Learning grant due March 11</a></p>
<p>12 0.068797603 <a title="433-tfidf-12" href="../hunch_net-2013/hunch_net-2013-05-04-COLT_and_ICML_registration.html">482 hunch net-2013-05-04-COLT and ICML registration</a></p>
<p>13 0.064136773 <a title="433-tfidf-13" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>14 0.057671092 <a title="433-tfidf-14" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>15 0.05753668 <a title="433-tfidf-15" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>16 0.055691779 <a title="433-tfidf-16" href="../hunch_net-2009/hunch_net-2009-11-23-ICML_2009_Workshops_%28and_Tutorials%29.html">379 hunch net-2009-11-23-ICML 2009 Workshops (and Tutorials)</a></p>
<p>17 0.051012691 <a title="433-tfidf-17" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>18 0.046164144 <a title="433-tfidf-18" href="../hunch_net-2011/hunch_net-2011-01-03-Herman_Goldstine_2011.html">421 hunch net-2011-01-03-Herman Goldstine 2011</a></p>
<p>19 0.045867473 <a title="433-tfidf-19" href="../hunch_net-2010/hunch_net-2010-11-18-ICML_2011_%26%238211%3B_Call_for_Tutorials.html">417 hunch net-2010-11-18-ICML 2011 &#8211; Call for Tutorials</a></p>
<p>20 0.043290786 <a title="433-tfidf-20" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.023), (1, 0.05), (2, 0.051), (3, 0.147), (4, 0.006), (5, -0.084), (6, -0.031), (7, 0.01), (8, 0.001), (9, -0.036), (10, 0.03), (11, -0.006), (12, -0.044), (13, -0.114), (14, 0.12), (15, -0.056), (16, -0.087), (17, -0.171), (18, -0.053), (19, 0.031), (20, 0.006), (21, -0.02), (22, 0.04), (23, -0.057), (24, 0.035), (25, 0.101), (26, 0.018), (27, -0.126), (28, -0.049), (29, -0.017), (30, 0.026), (31, -0.057), (32, 0.022), (33, 0.102), (34, -0.007), (35, 0.069), (36, 0.06), (37, -0.019), (38, 0.037), (39, 0.069), (40, 0.115), (41, -0.109), (42, 0.009), (43, 0.021), (44, -0.061), (45, -0.04), (46, -0.046), (47, -0.108), (48, -0.047), (49, 0.034)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98811519 <a title="433-lsi-1" href="../hunch_net-2011/hunch_net-2011-04-23-ICML_workshops_due.html">433 hunch net-2011-04-23-ICML workshops due</a></p>
<p>Introduction: Lihongpoints out thatICMLworkshopsubmissions are due April 29.</p><p>2 0.76991612 <a title="433-lsi-2" href="../hunch_net-2013/hunch_net-2013-04-15-NEML_II.html">481 hunch net-2013-04-15-NEML II</a></p>
<p>Introduction: Adam Kalaipoints out theNew England Machine Learning DayMay 1 at MSR New
England. There is a poster session with abstracts due April 19. I understand
last year'sNEMLwent well and it's great to meet your neighbors at regional
workshops like this.</p><p>3 0.63505179 <a title="433-lsi-3" href="../hunch_net-2008/hunch_net-2008-01-07-2008_Summer_Machine_Learning_Conference_Schedule.html">283 hunch net-2008-01-07-2008 Summer Machine Learning Conference Schedule</a></p>
<p>Introduction: ConferencePaper due dateConference DateLocationAAAIJanuary 22/23/25/30July
13-17Chicago, IllinoisICMLFeb 8July 5-9Helsinki, FinlandCOLTFeb 20July
9-12Helsinki, FinlandKDDFeb 23/29August 24-27Las Vegas, NevadaUAIFeb 27/Feb
29July 9-12Helsinki, FinlandHelsinki is a fun place to visit.</p><p>4 0.51826537 <a title="433-lsi-4" href="../hunch_net-2005/hunch_net-2005-10-19-Workshop%3A_Atomic_Learning.html">124 hunch net-2005-10-19-Workshop: Atomic Learning</a></p>
<p>Introduction: We are planning to have a workshop on atomic learning Jan 7 & 8 at TTI-
Chicago.Details are here.The earlier request for interest ishere.The primary
deadline is abstracts due Nov. 20 to jl@tti-c.org.</p><p>5 0.49324739 <a title="433-lsi-5" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>Introduction: Adam Klivans, points out theCOLT call for papers. The important points are:Due
Feb 13.Montreal, June 18-21.This year, there is author feedback.</p><p>6 0.44196644 <a title="433-lsi-6" href="../hunch_net-2008/hunch_net-2008-09-04-Fall_ML_Conferences.html">316 hunch net-2008-09-04-Fall ML Conferences</a></p>
<p>7 0.43453345 <a title="433-lsi-7" href="../hunch_net-2009/hunch_net-2009-10-26-NIPS_workshops.html">375 hunch net-2009-10-26-NIPS workshops</a></p>
<p>8 0.42292032 <a title="433-lsi-8" href="../hunch_net-2011/hunch_net-2011-01-03-Herman_Goldstine_2011.html">421 hunch net-2011-01-03-Herman Goldstine 2011</a></p>
<p>9 0.42252418 <a title="433-lsi-9" href="../hunch_net-2011/hunch_net-2011-09-03-Fall_Machine_Learning_Events.html">443 hunch net-2011-09-03-Fall Machine Learning Events</a></p>
<p>10 0.40436503 <a title="433-lsi-10" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>11 0.40345544 <a title="433-lsi-11" href="../hunch_net-2012/hunch_net-2012-07-17-MUCMD_and_BayLearn.html">470 hunch net-2012-07-17-MUCMD and BayLearn</a></p>
<p>12 0.38877952 <a title="433-lsi-12" href="../hunch_net-2005/hunch_net-2005-05-14-NIPS.html">71 hunch net-2005-05-14-NIPS</a></p>
<p>13 0.36241674 <a title="433-lsi-13" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>14 0.34623879 <a title="433-lsi-14" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>15 0.33581901 <a title="433-lsi-15" href="../hunch_net-2012/hunch_net-2012-04-20-Both_new%3A_STOC_workshops_and_NEML.html">462 hunch net-2012-04-20-Both new: STOC workshops and NEML</a></p>
<p>16 0.3304503 <a title="433-lsi-16" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>17 0.32180282 <a title="433-lsi-17" href="../hunch_net-2013/hunch_net-2013-05-04-COLT_and_ICML_registration.html">482 hunch net-2013-05-04-COLT and ICML registration</a></p>
<p>18 0.31213191 <a title="433-lsi-18" href="../hunch_net-2011/hunch_net-2011-05-09-CI_Fellows%2C_again.html">434 hunch net-2011-05-09-CI Fellows, again</a></p>
<p>19 0.29376322 <a title="433-lsi-19" href="../hunch_net-2011/hunch_net-2011-02-25-Yahoo%21_Machine_Learning_grant_due_March_11.html">425 hunch net-2011-02-25-Yahoo! Machine Learning grant due March 11</a></p>
<p>20 0.29368323 <a title="433-lsi-20" href="../hunch_net-2006/hunch_net-2006-09-19-Luis_von_Ahn_is_awarded_a_MacArthur_fellowship..html">209 hunch net-2006-09-19-Luis von Ahn is awarded a MacArthur fellowship.</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(71, 0.574)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="433-lda-1" href="../hunch_net-2011/hunch_net-2011-04-23-ICML_workshops_due.html">433 hunch net-2011-04-23-ICML workshops due</a></p>
<p>Introduction: Lihongpoints out thatICMLworkshopsubmissions are due April 29.</p><p>2 0.88308442 <a title="433-lda-2" href="../hunch_net-2014/hunch_net-2014-03-11-The_New_York_ML_Symposium%2C_take_2.html">494 hunch net-2014-03-11-The New York ML Symposium, take 2</a></p>
<p>Introduction: The 201314 isNew York Machine Learning Symposiumis finally happening on March
28th at theNew York Academy of Science. Every invited speaker interests me
personally. They are:Rayid Ghani(Chief Scientist at Obama 2012)Brian
Kingsbury(Speech Recognition @ IBM)Jorge Nocedal(who did LBFGS)We've been
somewhat disorganized in advertising this. As a consequence, anyone who has
not submitted an abstract but would like to do so may send one directly to me
(jl@hunch.net title NYASMLS) by Friday March 14. I will forward them to the
rest of the committee for consideration.</p><p>3 0.088913344 <a title="433-lda-3" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>4 0.085928418 <a title="433-lda-4" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>Introduction: In the quest to understand what good reviewing is, perhaps it's worthwhile to
think about what good research is. One way to think about good research is in
terms of a producer/consumer model.In the producer/consumer model of research,
for any element of research there are producers (authors and coauthors of
papers, for example) and consumers (people who use the papers to make new
papers or code solving problems). An produced bit of research is judged as
"good" if it is used by many consumers. There are two basic questions which
immediately arise:Is this a good model of research?Are there alternatives?The
producer/consumer model has some difficulties which can be (partially)
addressed.Disconnect.A group of people doing research on some subject may
become disconnected from the rest of the world. Each person uses the research
of other people in the group so it appears good research is being done, but
the group has no impact on the rest of the world. One way to detect this is by
looking at</p><p>5 0.042559113 <a title="433-lda-5" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>Introduction: Many conference deadlines are coming soon.DeadlineDouble Blind / Author
FeedbackTime/PlaceICMLJanuary 18((workshops) / February 1 (Papers) / February
13 (Tutorials)Y/YHaifa, Israel, June 21-25KDDFebruary 1(Workshops) / February
2&5 (Papers) / February 26 (Tutorials & Panels)) / April 17
(Demos)N/SWashington DC, July 25-28COLTJanuary 18 (Workshops) / February 19
(Papers)N/SHaifa, Israel, June 25-29UAIMarch 11 (Papers)N?/YCatalina Island,
California, July 8-11ICML continues to experiment with the reviewing process,
although perhaps less so than last year.The S "sort-of" for COLT is because
author feedback occurs only after decisions are made.KDD is notable for being
the most comprehensive in terms of {Tutorials, Workshops, Challenges, Panels,
Papers (two tracks), Demos}. The S for KDD is because there is sometimes
author feedback at the decision of the SPC.The (past) January 18 deadline for
workshops at ICML is nominal, as I (as workshop chair) almost missed it myself
and we have space f</p><p>6 0.037942272 <a title="433-lda-6" href="../hunch_net-2005/hunch_net-2005-03-24-The_Role_of_Workshops.html">46 hunch net-2005-03-24-The Role of Workshops</a></p>
<p>7 0.0 <a title="433-lda-7" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<p>8 0.0 <a title="433-lda-8" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>9 0.0 <a title="433-lda-9" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>10 0.0 <a title="433-lda-10" href="../hunch_net-2005/hunch_net-2005-01-26-Summer_Schools.html">4 hunch net-2005-01-26-Summer Schools</a></p>
<p>11 0.0 <a title="433-lda-11" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>12 0.0 <a title="433-lda-12" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>13 0.0 <a title="433-lda-13" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>14 0.0 <a title="433-lda-14" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>15 0.0 <a title="433-lda-15" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>16 0.0 <a title="433-lda-16" href="../hunch_net-2005/hunch_net-2005-02-02-Kolmogorov_Complexity_and_Googling.html">10 hunch net-2005-02-02-Kolmogorov Complexity and Googling</a></p>
<p>17 0.0 <a title="433-lda-17" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>18 0.0 <a title="433-lda-18" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>19 0.0 <a title="433-lda-19" href="../hunch_net-2005/hunch_net-2005-02-04-JMLG.html">13 hunch net-2005-02-04-JMLG</a></p>
<p>20 0.0 <a title="433-lda-20" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
