<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>430 hunch net-2011-04-11-The Heritage Health Prize</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2011" href="../home/hunch_net-2011_home.html">hunch_net-2011</a> <a title="hunch_net-2011-430" href="#">hunch_net-2011-430</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>430 hunch net-2011-04-11-The Heritage Health Prize</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2011-430-html" href="http://hunch.net/?p=1762">html</a></p><p>Introduction: TheHeritage Health Prizeis potentially the largest prediction prize yet at
$3M, which is sure to get many people interested. Several elements of the
competition may be worth discussing.The most straightforward way for HPN to
deploy this predictor is in determining who to cover with insurance. This
might easily cover the costs of running the contest itself, but the value to
the health system of a whole is minimal, as people not covered still exist.
While HPN itself is a provider network, they have active relationships with a
number of insurance companies, and the right to resell any entrant. It's worth
keeping in mind that the research and development may nevertheless end up
being useful in the longer term, especially as entrants also keep the right to
their code.Thejudging metricis something I haven't seen previously. If a
patient has probability 0.5 of being in the hospital 0 days and probability
0.5 of being in the hospital ~53.6 days, the optimal prediction in expectation
is ~6.4 da</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 TheHeritage Health Prizeis potentially the largest prediction prize yet at $3M, which is sure to get many people interested. [sent-1, score-0.533]
</p><p>2 Several elements of the competition may be worth discussing. [sent-2, score-0.112]
</p><p>3 The most straightforward way for HPN to deploy this predictor is in determining who to cover with insurance. [sent-3, score-0.4]
</p><p>4 This might easily cover the costs of running the contest itself, but the value to the health system of a whole is minimal, as people not covered still exist. [sent-4, score-0.935]
</p><p>5 While HPN itself is a provider network, they have active relationships with a number of insurance companies, and the right to resell any entrant. [sent-5, score-0.293]
</p><p>6 It's worth keeping in mind that the research and development may nevertheless end up being useful in the longer term, especially as entrants also keep the right to their code. [sent-6, score-0.423]
</p><p>7 5 of being in the hospital 0 days and probability 0. [sent-9, score-0.527]
</p><p>8 This is evidence against point (1) above, since cost is probably closer to linear in the number of hospital days. [sent-13, score-0.517]
</p><p>9 As a starting point, I suspect many people will simply optimize conditional squared loss and then back out an inferred prediction according top=ex-1, with clipping. [sent-14, score-0.402]
</p><p>10 I'm not sure there is a good reason for it from a prediction point of view and 8 may be too hard a limit on team size, imposing bin packing problems on the entrants. [sent-17, score-0.645]
</p><p>11 They anonymized the data, require entrants to protect the data, and admonish people to not try to break privacy. [sent-19, score-0.603]
</p><p>12 Despite that, the data will be released to large numbers of people, so I wouldn't be surprised if someone attempts a join attack of some sort. [sent-20, score-0.565]
</p><p>13 Whether or not a join attack succeeds could make a huge difference in how this contest is viewed in the long term. [sent-21, score-0.84]
</p><p>14 If they set it at an out-of-reach point (which they could easily do), the size of the prize becomes 0. [sent-23, score-0.462]
</p><p>15 This part of the contest is supposed to be determined next month. [sent-25, score-0.491]
</p><p>16 This contest is not a slam-dunk, but is has the potential to become one, and I'll be interested to see how it turns out. [sent-26, score-0.309]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('contest', 0.309), ('hospital', 0.295), ('entrants', 0.239), ('hpn', 0.239), ('team', 0.186), ('join', 0.17), ('attack', 0.155), ('health', 0.155), ('prize', 0.143), ('days', 0.14), ('prediction', 0.139), ('cover', 0.132), ('point', 0.129), ('worth', 0.112), ('huge', 0.108), ('size', 0.107), ('anonymized', 0.106), ('relationships', 0.106), ('deploy', 0.106), ('succeeds', 0.098), ('provider', 0.098), ('inferred', 0.098), ('bin', 0.098), ('whole', 0.098), ('patient', 0.098), ('protect', 0.098), ('sure', 0.093), ('determined', 0.093), ('closer', 0.093), ('probability', 0.092), ('determining', 0.089), ('supposed', 0.089), ('insurance', 0.089), ('data', 0.085), ('released', 0.085), ('threshold', 0.085), ('people', 0.085), ('easily', 0.083), ('strange', 0.082), ('suspect', 0.08), ('minimal', 0.075), ('top', 0.075), ('break', 0.075), ('costs', 0.073), ('largest', 0.073), ('straightforward', 0.073), ('keeping', 0.072), ('accuracy', 0.07), ('despite', 0.07), ('surprised', 0.07)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="430-tfidf-1" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: TheHeritage Health Prizeis potentially the largest prediction prize yet at
$3M, which is sure to get many people interested. Several elements of the
competition may be worth discussing.The most straightforward way for HPN to
deploy this predictor is in determining who to cover with insurance. This
might easily cover the costs of running the contest itself, but the value to
the health system of a whole is minimal, as people not covered still exist.
While HPN itself is a provider network, they have active relationships with a
number of insurance companies, and the right to resell any entrant. It's worth
keeping in mind that the research and development may nevertheless end up
being useful in the longer term, especially as entrants also keep the right to
their code.Thejudging metricis something I haven't seen previously. If a
patient has probability 0.5 of being in the hospital 0 days and probability
0.5 of being in the hospital ~53.6 days, the optimal prediction in expectation
is ~6.4 da</p><p>2 0.25315103 <a title="430-tfidf-2" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended theNetflix prizeceremony this morning. The press conference part
iscovered fine elsewhere, with the basic outcome being thatBellKor's Pragmatic
Chaoswon overThe Ensembleby 15-20minutes, because they were tied in
performance on the ultimate holdout set. I'm sure the individual participants
will have many chances to speak about the solution. One of these is Bell at
theNYAS ML symposium on Nov. 6.Several additional details may interest ML
people.The degree of overfitting exhibited by the difference in performance on
theleaderboard test setand the ultimate hold out set was small, but
determining at .02 to .03%.A tie was possible, because the rules cut off
measurements below the fourth digit based on significance concerns. In
actuality, of course, the scores do differ before rounding, but everyone I
spoke to claimed not to know how. The complete dataset has beenreleased on
UCI, so each team could compute their own score to whatever accuracy desired.I
was impressed by the slick sy</p><p>3 0.19164529 <a title="430-tfidf-3" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>Introduction: Data linkage is a problem which seems to come up in various applied machine
learning problems. I have heard it mentioned in various data mining contexts,
but it seems relatively less studied for systemic reasons.A very simple
version of the data linkage problem is a cross hospital patient record merge.
Suppose a patient (John Doe) is admitted to a hospital (General Health),
treated, and released. Later, John Doe is admitted to a second hospital
(Health General), treated, and released. Given a large number of records of
this sort, it becomes very tempting to try and predict the outcomes of
treatments. This is reasonably straightforward as a machine learning problem
if there is a shared unique identifier for John Doe used by General Health and
Health General along with time stamps. We can merge the records and create
examples of the form "Given symptoms and treatment, did the patient come back
to a hospital within the next year?" These examples could be fed into a
learning algorithm, and</p><p>4 0.16120906 <a title="430-tfidf-4" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>Introduction: There are two prediction competitions currently in the air.ThePerformance
Prediction ChallengebyIsabelle Guyon. Good entries minimize a weighted 0/1
loss + the difference between a prediction of this loss and the observed truth
on 5 datasets. Isabelle tells me all of the problems are "real world" and the
test datasets are large enough (17K minimum) that the winner should be well
determined by ability rather than luck. This is due March 1.ThePredictive
Uncertainty ChallengebyGavin Cawley. Good entries minimize log loss on real
valued output variables for one synthetic and 3 "real" datasets related to
atmospheric prediction. The use of log loss (which can be infinite and hence
is never convergent) and smaller test sets of size 1K to 7K examples makes the
winner of this contest more luck dependent. Nevertheless, the contest may be
of some interest particularly to the branch of learning (typically Bayes
learning) which prefers to optimize log loss.May the best predictor win.</p><p>5 0.16057271 <a title="430-tfidf-5" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><p>6 0.13040984 <a title="430-tfidf-6" href="../hunch_net-2011/hunch_net-2011-03-20-KDD_Cup_2011.html">427 hunch net-2011-03-20-KDD Cup 2011</a></p>
<p>7 0.12955141 <a title="430-tfidf-7" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>8 0.10355881 <a title="430-tfidf-8" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>9 0.098356649 <a title="430-tfidf-9" href="../hunch_net-2009/hunch_net-2009-08-27-New_York_Area_Machine_Learning_Events.html">369 hunch net-2009-08-27-New York Area Machine Learning Events</a></p>
<p>10 0.097215667 <a title="430-tfidf-10" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>11 0.094837837 <a title="430-tfidf-11" href="../hunch_net-2009/hunch_net-2009-02-04-Optimal_Proxy_Loss_for_Classification.html">341 hunch net-2009-02-04-Optimal Proxy Loss for Classification</a></p>
<p>12 0.092230313 <a title="430-tfidf-12" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>13 0.089179754 <a title="430-tfidf-13" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>14 0.083831958 <a title="430-tfidf-14" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>15 0.083739087 <a title="430-tfidf-15" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>16 0.081750304 <a title="430-tfidf-16" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>17 0.081141897 <a title="430-tfidf-17" href="../hunch_net-2007/hunch_net-2007-11-28-Computational_Consequences_of_Classification.html">274 hunch net-2007-11-28-Computational Consequences of Classification</a></p>
<p>18 0.077288106 <a title="430-tfidf-18" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>19 0.076837488 <a title="430-tfidf-19" href="../hunch_net-2008/hunch_net-2008-01-06-Research_Political_Issues.html">282 hunch net-2008-01-06-Research Political Issues</a></p>
<p>20 0.076794222 <a title="430-tfidf-20" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.205), (1, -0.052), (2, 0.022), (3, 0.03), (4, 0.119), (5, 0.128), (6, -0.011), (7, 0.025), (8, 0.102), (9, -0.025), (10, -0.21), (11, 0.027), (12, -0.107), (13, 0.061), (14, 0.075), (15, -0.016), (16, -0.093), (17, 0.006), (18, -0.096), (19, 0.016), (20, 0.008), (21, 0.103), (22, 0.055), (23, 0.056), (24, 0.052), (25, 0.035), (26, 0.013), (27, 0.012), (28, -0.041), (29, 0.051), (30, -0.05), (31, -0.025), (32, 0.028), (33, -0.024), (34, 0.15), (35, -0.135), (36, -0.003), (37, 0.022), (38, 0.006), (39, 0.033), (40, 0.047), (41, 0.022), (42, -0.024), (43, 0.006), (44, 0.015), (45, -0.054), (46, -0.026), (47, -0.072), (48, 0.049), (49, -0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95931178 <a title="430-lsi-1" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: TheHeritage Health Prizeis potentially the largest prediction prize yet at
$3M, which is sure to get many people interested. Several elements of the
competition may be worth discussing.The most straightforward way for HPN to
deploy this predictor is in determining who to cover with insurance. This
might easily cover the costs of running the contest itself, but the value to
the health system of a whole is minimal, as people not covered still exist.
While HPN itself is a provider network, they have active relationships with a
number of insurance companies, and the right to resell any entrant. It's worth
keeping in mind that the research and development may nevertheless end up
being useful in the longer term, especially as entrants also keep the right to
their code.Thejudging metricis something I haven't seen previously. If a
patient has probability 0.5 of being in the hospital 0 days and probability
0.5 of being in the hospital ~53.6 days, the optimal prediction in expectation
is ~6.4 da</p><p>2 0.75682467 <a title="430-lsi-2" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>Introduction: I attended theNetflix prizeceremony this morning. The press conference part
iscovered fine elsewhere, with the basic outcome being thatBellKor's Pragmatic
Chaoswon overThe Ensembleby 15-20minutes, because they were tied in
performance on the ultimate holdout set. I'm sure the individual participants
will have many chances to speak about the solution. One of these is Bell at
theNYAS ML symposium on Nov. 6.Several additional details may interest ML
people.The degree of overfitting exhibited by the difference in performance on
theleaderboard test setand the ultimate hold out set was small, but
determining at .02 to .03%.A tie was possible, because the rules cut off
measurements below the fourth digit based on significance concerns. In
actuality, of course, the scores do differ before rounding, but everyone I
spoke to claimed not to know how. The complete dataset has beenreleased on
UCI, so each team could compute their own score to whatever accuracy desired.I
was impressed by the slick sy</p><p>3 0.72048211 <a title="430-lsi-3" href="../hunch_net-2006/hunch_net-2006-10-02-%241M_Netflix_prediction_contest.html">211 hunch net-2006-10-02-$1M Netflix prediction contest</a></p>
<p>Introduction: Netflix isrunning a contestto improve recommender prediction systems. A 10%
improvement over their current system yields a $1M prize. Failing that, the
best smaller improvement yields a smaller $50K prize. This contest looks quite
real, and the $50K prize money is almost certainly achievable with a bit of
thought. The contest also comes with a dataset which is apparently 2 orders of
magnitude larger than any other public recommendation system datasets.</p><p>4 0.59835899 <a title="430-lsi-4" href="../hunch_net-2005/hunch_net-2005-11-07-Prediction_Competitions.html">129 hunch net-2005-11-07-Prediction Competitions</a></p>
<p>Introduction: There are two prediction competitions currently in the air.ThePerformance
Prediction ChallengebyIsabelle Guyon. Good entries minimize a weighted 0/1
loss + the difference between a prediction of this loss and the observed truth
on 5 datasets. Isabelle tells me all of the problems are "real world" and the
test datasets are large enough (17K minimum) that the winner should be well
determined by ability rather than luck. This is due March 1.ThePredictive
Uncertainty ChallengebyGavin Cawley. Good entries minimize log loss on real
valued output variables for one synthetic and 3 "real" datasets related to
atmospheric prediction. The use of log loss (which can be infinite and hence
is never convergent) and smaller test sets of size 1K to 7K examples makes the
winner of this contest more luck dependent. Nevertheless, the contest may be
of some interest particularly to the branch of learning (typically Bayes
learning) which prefers to optimize log loss.May the best predictor win.</p><p>5 0.57270575 <a title="430-lsi-5" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>Introduction: A couple security researchersclaim to have cracked the netflix dataset. The
claims of success appear somewhat overstated to me, but the method of attack
is valid and could plausibly be substantially improved so as to reveal the
movie preferences of a small fraction of Netflix users.The basic idea is to
use a heuristic similarity function between ratings in a public database (from
IMDB) and an anonymized database (Netflix) to link ratings in the private
database to public identities (in IMDB). They claim to have linked two of a
few dozen IMDB users to anonymized netflix users.The claims seem a bit
inflated to me, because (a) knowing the IMDB identity isn't equivalent to
knowing the person and (b) the claims of statistical significance are with
respect to a model of the world they created (rather than one they
created).Overall, this is another example showing that completeprivacy is
hard. It may be worth remembering that there are some substantial benefits
from the Netflix challenge as w</p><p>6 0.56372094 <a title="430-lsi-6" href="../hunch_net-2005/hunch_net-2005-10-08-We_have_a_winner.html">119 hunch net-2005-10-08-We have a winner</a></p>
<p>7 0.56205672 <a title="430-lsi-7" href="../hunch_net-2011/hunch_net-2011-03-20-KDD_Cup_2011.html">427 hunch net-2011-03-20-KDD Cup 2011</a></p>
<p>8 0.56136632 <a title="430-lsi-8" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>9 0.55863184 <a title="430-lsi-9" href="../hunch_net-2009/hunch_net-2009-06-26-Netflix_nearly_done.html">362 hunch net-2009-06-26-Netflix nearly done</a></p>
<p>10 0.50202775 <a title="430-lsi-10" href="../hunch_net-2006/hunch_net-2006-11-06-Data_Linkage_Problems.html">217 hunch net-2006-11-06-Data Linkage Problems</a></p>
<p>11 0.47821432 <a title="430-lsi-11" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>12 0.47365212 <a title="430-lsi-12" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>13 0.456806 <a title="430-lsi-13" href="../hunch_net-2007/hunch_net-2007-11-14-BellKor_wins_Netflix.html">272 hunch net-2007-11-14-BellKor wins Netflix</a></p>
<p>14 0.44861686 <a title="430-lsi-14" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>15 0.43136844 <a title="430-lsi-15" href="../hunch_net-2006/hunch_net-2006-11-20-Context_and_the_calculation_misperception.html">218 hunch net-2006-11-20-Context and the calculation misperception</a></p>
<p>16 0.42779288 <a title="430-lsi-16" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>17 0.42156705 <a title="430-lsi-17" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>18 0.42063585 <a title="430-lsi-18" href="../hunch_net-2007/hunch_net-2007-08-19-Choice_of_Metrics.html">259 hunch net-2007-08-19-Choice of Metrics</a></p>
<p>19 0.41792232 <a title="430-lsi-19" href="../hunch_net-2006/hunch_net-2006-07-06-Branch_Prediction_Competition.html">190 hunch net-2006-07-06-Branch Prediction Competition</a></p>
<p>20 0.41208762 <a title="430-lsi-20" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.026), (42, 0.201), (45, 0.075), (68, 0.066), (69, 0.048), (73, 0.318), (74, 0.122), (76, 0.014), (88, 0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94222069 <a title="430-lda-1" href="../hunch_net-2005/hunch_net-2005-07-13-Text_Entailment_at_AAAI.html">94 hunch net-2005-07-13-Text Entailment at AAAI</a></p>
<p>Introduction: Rajat Rainapresented a paper on the technique they used for
thePASCALRecognizing Textual Entailmentchallenge."Text entailment" is the
problem of deciding if one sentence implies another. For example the previous
sentence entails:Text entailment is a decision problem.One sentence can imply
another.The challenge was of the form: given an original sentence and another
sentence predict whether there was an entailment. All current techniques for
predicting correctness of an entailment are at the "flail" stage--accuracies
of around 58% where humans could achieve near 100% accuracy, so there is much
room to improve. Apparently, there may be another PASCAL challenge on this
problem in the near future.</p><p>2 0.89726019 <a title="430-lda-2" href="../hunch_net-2013/hunch_net-2013-06-10-The_Large_Scale_Learning_class_notes.html">483 hunch net-2013-06-10-The Large Scale Learning class notes</a></p>
<p>Introduction: Thelarge scale machine learning classI taught withYann LeCunhas finished. As I
expected, it took quite a bit of time. We had about 25 people attending in
person on average and 400 regularly watching therecorded lectureswhich is
substantially more sustained interest than I expected for an advanced ML
class. We also had some fun with class projects--I'm hopeful that several will
eventually turn into papers.I expect there are a number of professors
interested in lecturing on this and related topics. Everyone will have their
personal taste in subjects of course, but hopefully there will be some
convergence to common course materials as well. To help with this, I am making
thesources to my presentations available. Feel free to
use/improve/embelish/ridicule/etcâ&euro;Ś in the pursuit of the perfect course.</p><p>3 0.89318371 <a title="430-lda-3" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>Introduction: I only managed to make it out to the NIPS workshops this year soI'll give my
comments on what I saw there.The Learing and Robotics workshops lives again. I
hope itcontinues and gets more high quality papers in the future. Themost
interesting talk for me was Larry Jackel's on the LAGRprogram (see John's
previous post on said program). I got someideas as to what progress has been
made. Larry really explainedthe types of benchmarks and the tradeoffs that had
to be made tomake the goals achievable but challenging.Hal Daume gave a very
interesting talk about structuredprediction using RL techniques, something
near and dear to my ownheart. He achieved rather impressive results using only
a verygreedy search.The non-parametric Bayes workshop was great. I enjoyed the
entiremorning session I spent there, and particularly (the usuallydesultory)
discussion periods. One interesting topic was theGibbs/Variational inference
divide. I won't try to summarizeespecially as no conclusion was reached. It</p><p>same-blog 4 0.8724789 <a title="430-lda-4" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>Introduction: TheHeritage Health Prizeis potentially the largest prediction prize yet at
$3M, which is sure to get many people interested. Several elements of the
competition may be worth discussing.The most straightforward way for HPN to
deploy this predictor is in determining who to cover with insurance. This
might easily cover the costs of running the contest itself, but the value to
the health system of a whole is minimal, as people not covered still exist.
While HPN itself is a provider network, they have active relationships with a
number of insurance companies, and the right to resell any entrant. It's worth
keeping in mind that the research and development may nevertheless end up
being useful in the longer term, especially as entrants also keep the right to
their code.Thejudging metricis something I haven't seen previously. If a
patient has probability 0.5 of being in the hospital 0 days and probability
0.5 of being in the hospital ~53.6 days, the optimal prediction in expectation
is ~6.4 da</p><p>5 0.86831307 <a title="430-lda-5" href="../hunch_net-2007/hunch_net-2007-11-16-MLSS_2008.html">273 hunch net-2007-11-16-MLSS 2008</a></p>
<p>Introduction: â&euro;Ś is in Kioloa, Australia from March 3 to March 14. It's a great chance to
learn something about Machine Learning and I've enjoyed severalprevious
Machine Learning Summer Schools.Thewebsite has many more details, but
registration is open now for the first 80 to sign up.</p><p>6 0.85114866 <a title="430-lda-6" href="../hunch_net-2008/hunch_net-2008-10-20-New_York%26%238217%3Bs_ML_Day.html">322 hunch net-2008-10-20-New York&#8217;s ML Day</a></p>
<p>7 0.71546704 <a title="430-lda-7" href="../hunch_net-2005/hunch_net-2005-03-15-The_State_of_Tight_Bounds.html">41 hunch net-2005-03-15-The State of Tight Bounds</a></p>
<p>8 0.61105663 <a title="430-lda-8" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>9 0.61105293 <a title="430-lda-9" href="../hunch_net-2005/hunch_net-2005-09-26-Prediction_Bounds_as_the_Mathematics_of_Science.html">115 hunch net-2005-09-26-Prediction Bounds as the Mathematics of Science</a></p>
<p>10 0.60918725 <a title="430-lda-10" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>11 0.60902202 <a title="430-lda-11" href="../hunch_net-2011/hunch_net-2011-02-17-What_does_Watson_mean%3F.html">424 hunch net-2011-02-17-What does Watson mean?</a></p>
<p>12 0.60422111 <a title="430-lda-12" href="../hunch_net-2011/hunch_net-2011-11-26-Giving_Thanks.html">449 hunch net-2011-11-26-Giving Thanks</a></p>
<p>13 0.60059178 <a title="430-lda-13" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>14 0.59968984 <a title="430-lda-14" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>15 0.59789753 <a title="430-lda-15" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>16 0.59757787 <a title="430-lda-16" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>17 0.59604663 <a title="430-lda-17" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>18 0.59571481 <a title="430-lda-18" href="../hunch_net-2005/hunch_net-2005-02-14-Clever_Methods_of_Overfitting.html">19 hunch net-2005-02-14-Clever Methods of Overfitting</a></p>
<p>19 0.59508169 <a title="430-lda-19" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>20 0.59313506 <a title="430-lda-20" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
