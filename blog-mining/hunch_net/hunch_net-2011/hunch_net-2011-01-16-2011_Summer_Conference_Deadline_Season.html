<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2011" href="../home/hunch_net-2011_home.html">hunch_net-2011</a> <a title="hunch_net-2011-422" href="#">hunch_net-2011-422</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2011-422-html" href="http://hunch.net/?p=1632">html</a></p><p>Introduction: Machine learning always welcomes the new year with paper deadlines for summer
conferences. This year, we have:ConferencePaper DeadlineWhen/WhereDouble
blind?Author Feedback?NotesICMLFebruary 1June 28-July 2, Bellevue, Washington,
USAYYWeak colocation withACLCOLTFebruary 11July 9-July 11, Budapest,
HungaryNNcolocated withFOCMKDDFebruary 11/18August 21-24, San Diego,
California, USANNUAIMarch 18July 14-17, Barcelona, SpainYNThe larger
conferences are on the west coast in the United States, while the smaller ones
are in Europe.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('coast', 0.294), ('west', 0.294), ('conferencepaper', 0.294), ('washington', 0.294), ('europe', 0.257), ('diego', 0.257), ('california', 0.245), ('san', 0.235), ('united', 0.227), ('colocation', 0.22), ('deadlines', 0.208), ('year', 0.182), ('states', 0.177), ('smaller', 0.171), ('blind', 0.169), ('ones', 0.166), ('summer', 0.159), ('feedback', 0.134), ('author', 0.134), ('larger', 0.127)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="422-tfidf-1" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>Introduction: Machine learning always welcomes the new year with paper deadlines for summer
conferences. This year, we have:ConferencePaper DeadlineWhen/WhereDouble
blind?Author Feedback?NotesICMLFebruary 1June 28-July 2, Bellevue, Washington,
USAYYWeak colocation withACLCOLTFebruary 11July 9-July 11, Budapest,
HungaryNNcolocated withFOCMKDDFebruary 11/18August 21-24, San Diego,
California, USANNUAIMarch 18July 14-17, Barcelona, SpainYNThe larger
conferences are on the west coast in the United States, while the smaller ones
are in Europe.</p><p>2 0.32009581 <a title="422-tfidf-2" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>Introduction: It's conference season once again.ConferenceDue?When?Where?double blind?author
feedback?Workshops?AAAIFebruary 1/6 (and 27)July 22-26Vancouver, British
ColumbiaYesYesDoneUAIFebruary 28/March 2July 19-22Vancouver, British
ColumbiaNoNoNoCOLTJanuary 16June 13-15San Diego, California
(withFCRC)NoNoNoICMLFebruary 7/9June 20-24Corvallis, OregonYesYesFebruary
16KDDFebruary 23/28August 12-15San Jose, CaliforniaYesNo?February 28The
geowinner this year is the west coast of North America.Last year's geowinner
was the Northeastern US, and theyear beforeit was mostly Europe. It's notable
how tightly the conferences cluster, even when they don't colocate.</p><p>3 0.19101447 <a title="422-tfidf-3" href="../hunch_net-2008/hunch_net-2008-01-07-2008_Summer_Machine_Learning_Conference_Schedule.html">283 hunch net-2008-01-07-2008 Summer Machine Learning Conference Schedule</a></p>
<p>Introduction: ConferencePaper due dateConference DateLocationAAAIJanuary 22/23/25/30July
13-17Chicago, IllinoisICMLFeb 8July 5-9Helsinki, FinlandCOLTFeb 20July
9-12Helsinki, FinlandKDDFeb 23/29August 24-27Las Vegas, NevadaUAIFeb 27/Feb
29July 9-12Helsinki, FinlandHelsinki is a fun place to visit.</p><p>4 0.17468548 <a title="422-tfidf-4" href="../hunch_net-2006/hunch_net-2006-07-25-Upcoming_conference.html">198 hunch net-2006-07-25-Upcoming conference</a></p>
<p>Introduction: The Workshop for Women in Machine Learning will be held in San Diego on
October 4, 2006.For details see the workshop
website:http://www.seas.upenn.edu/~wiml/</p><p>5 0.14263278 <a title="422-tfidf-5" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>6 0.13531609 <a title="422-tfidf-6" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>7 0.12588741 <a title="422-tfidf-7" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>8 0.11996163 <a title="422-tfidf-8" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>9 0.10174036 <a title="422-tfidf-9" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>10 0.09650664 <a title="422-tfidf-10" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>11 0.085827015 <a title="422-tfidf-11" href="../hunch_net-2008/hunch_net-2008-11-09-A_Healthy__COLT.html">324 hunch net-2008-11-09-A Healthy  COLT</a></p>
<p>12 0.084836163 <a title="422-tfidf-12" href="../hunch_net-2012/hunch_net-2012-02-29-Key_Scientific_Challenges_and_the_Franklin_Symposium.html">457 hunch net-2012-02-29-Key Scientific Challenges and the Franklin Symposium</a></p>
<p>13 0.084417015 <a title="422-tfidf-13" href="../hunch_net-2010/hunch_net-2010-10-28-NY_ML_Symposium_2010.html">415 hunch net-2010-10-28-NY ML Symposium 2010</a></p>
<p>14 0.080218241 <a title="422-tfidf-14" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>15 0.077739939 <a title="422-tfidf-15" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>16 0.075975649 <a title="422-tfidf-16" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>17 0.071821257 <a title="422-tfidf-17" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>18 0.067945056 <a title="422-tfidf-18" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>19 0.067417137 <a title="422-tfidf-19" href="../hunch_net-2006/hunch_net-2006-04-27-Conferences%2C_Workshops%2C_and_Tutorials.html">174 hunch net-2006-04-27-Conferences, Workshops, and Tutorials</a></p>
<p>20 0.066504754 <a title="422-tfidf-20" href="../hunch_net-2005/hunch_net-2005-01-26-Summer_Schools.html">4 hunch net-2005-01-26-Summer Schools</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.086), (1, 0.149), (2, -0.03), (3, 0.113), (4, -0.007), (5, -0.037), (6, -0.018), (7, 0.054), (8, 0.027), (9, -0.075), (10, -0.01), (11, -0.195), (12, 0.023), (13, -0.081), (14, 0.108), (15, -0.073), (16, 0.054), (17, 0.147), (18, -0.009), (19, -0.162), (20, -0.009), (21, -0.021), (22, 0.004), (23, 0.115), (24, -0.106), (25, 0.034), (26, 0.053), (27, -0.007), (28, -0.007), (29, 0.014), (30, 0.039), (31, -0.073), (32, 0.005), (33, -0.0), (34, -0.07), (35, -0.047), (36, -0.04), (37, -0.041), (38, -0.049), (39, 0.062), (40, -0.008), (41, -0.108), (42, 0.117), (43, -0.048), (44, -0.044), (45, -0.091), (46, 0.008), (47, 0.015), (48, -0.001), (49, -0.101)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9678815 <a title="422-lsi-1" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>Introduction: Machine learning always welcomes the new year with paper deadlines for summer
conferences. This year, we have:ConferencePaper DeadlineWhen/WhereDouble
blind?Author Feedback?NotesICMLFebruary 1June 28-July 2, Bellevue, Washington,
USAYYWeak colocation withACLCOLTFebruary 11July 9-July 11, Budapest,
HungaryNNcolocated withFOCMKDDFebruary 11/18August 21-24, San Diego,
California, USANNUAIMarch 18July 14-17, Barcelona, SpainYNThe larger
conferences are on the west coast in the United States, while the smaller ones
are in Europe.</p><p>2 0.83454609 <a title="422-lsi-2" href="../hunch_net-2007/hunch_net-2007-01-04-2007_Summer_Machine_Learning_Conferences.html">226 hunch net-2007-01-04-2007 Summer Machine Learning Conferences</a></p>
<p>Introduction: It's conference season once again.ConferenceDue?When?Where?double blind?author
feedback?Workshops?AAAIFebruary 1/6 (and 27)July 22-26Vancouver, British
ColumbiaYesYesDoneUAIFebruary 28/March 2July 19-22Vancouver, British
ColumbiaNoNoNoCOLTJanuary 16June 13-15San Diego, California
(withFCRC)NoNoNoICMLFebruary 7/9June 20-24Corvallis, OregonYesYesFebruary
16KDDFebruary 23/28August 12-15San Jose, CaliforniaYesNo?February 28The
geowinner this year is the west coast of North America.Last year's geowinner
was the Northeastern US, and theyear beforeit was mostly Europe. It's notable
how tightly the conferences cluster, even when they don't colocate.</p><p>3 0.57661039 <a title="422-lsi-3" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>Introduction: Here's a handy table for the summer conferences.ConferenceDeadlineReviewer
TargetingDouble BlindAuthor FeedbackLocationDateICML(wrong ICML)January
26YesYesYesMontreal, CanadaJune 14-17COLTFebruary 13NoNoYesMontrealJune
19-21UAIMarch 13NoYesNoMontrealJune 19-21KDDFebruary 2/6NoNoNoParis,
FranceJune 28-July 1Reviewer targeting is new this year. The idea is that many
poor decisions happen because the papers go to reviewers who are unqualified,
and the hope is that allowing authors to point out who is qualified results in
better decisions. In my experience, this is a reasonable idea to test.Both UAI
and COLT are experimenting this year as well with double blind and author
feedback, respectively. Of the two, I believe author feedback is more
important, as I've seen it make a difference. However, I still consider double
blind reviewing a net win, as it's a substantial public commitment to
fairness.</p><p>4 0.49212736 <a title="422-lsi-4" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>5 0.48758048 <a title="422-lsi-5" href="../hunch_net-2012/hunch_net-2012-07-17-MUCMD_and_BayLearn.html">470 hunch net-2012-07-17-MUCMD and BayLearn</a></p>
<p>Introduction: The workshop on theMeaningful Use of Complex Medical Datais happening again,
August 9-12 in LA, nearUAIon Catalina Island August 15-17. I enjoyed my visit
last year, and expect this year to be interesting also.The firstBay Area
Machine Learning Symposiumis August 30 atGoogle. Abstracts are due July 30.</p><p>6 0.43152219 <a title="422-lsi-6" href="../hunch_net-2008/hunch_net-2008-11-11-COLT_CFP.html">326 hunch net-2008-11-11-COLT CFP</a></p>
<p>7 0.42825934 <a title="422-lsi-7" href="../hunch_net-2010/hunch_net-2010-01-19-Deadline_Season%2C_2010.html">387 hunch net-2010-01-19-Deadline Season, 2010</a></p>
<p>8 0.42705154 <a title="422-lsi-8" href="../hunch_net-2007/hunch_net-2007-04-30-COLT_2007.html">242 hunch net-2007-04-30-COLT 2007</a></p>
<p>9 0.41519204 <a title="422-lsi-9" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>10 0.41285628 <a title="422-lsi-10" href="../hunch_net-2006/hunch_net-2006-06-15-IJCAI_is_out_of_season.html">184 hunch net-2006-06-15-IJCAI is out of season</a></p>
<p>11 0.4060666 <a title="422-lsi-11" href="../hunch_net-2005/hunch_net-2005-11-16-MLSS_2006.html">130 hunch net-2005-11-16-MLSS 2006</a></p>
<p>12 0.40002412 <a title="422-lsi-12" href="../hunch_net-2012/hunch_net-2012-06-15-Normal_Deviate_and_the_UCSC_Machine_Learning_Summer_School.html">467 hunch net-2012-06-15-Normal Deviate and the UCSC Machine Learning Summer School</a></p>
<p>13 0.39356583 <a title="422-lsi-13" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>14 0.38316262 <a title="422-lsi-14" href="../hunch_net-2005/hunch_net-2005-12-29-Deadline_Season.html">145 hunch net-2005-12-29-Deadline Season</a></p>
<p>15 0.3789776 <a title="422-lsi-15" href="../hunch_net-2005/hunch_net-2005-01-26-Summer_Schools.html">4 hunch net-2005-01-26-Summer Schools</a></p>
<p>16 0.36802381 <a title="422-lsi-16" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>17 0.36758745 <a title="422-lsi-17" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>18 0.36260232 <a title="422-lsi-18" href="../hunch_net-2009/hunch_net-2009-11-09-NYAS_ML_Symposium_this_year..html">377 hunch net-2009-11-09-NYAS ML Symposium this year.</a></p>
<p>19 0.3622022 <a title="422-lsi-19" href="../hunch_net-2009/hunch_net-2009-05-30-Many_ways_to_Learn_this_summer.html">357 hunch net-2009-05-30-Many ways to Learn this summer</a></p>
<p>20 0.35714924 <a title="422-lsi-20" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(25, 0.549), (74, 0.149), (82, 0.13)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91918653 <a title="422-lda-1" href="../hunch_net-2011/hunch_net-2011-01-16-2011_Summer_Conference_Deadline_Season.html">422 hunch net-2011-01-16-2011 Summer Conference Deadline Season</a></p>
<p>Introduction: Machine learning always welcomes the new year with paper deadlines for summer
conferences. This year, we have:ConferencePaper DeadlineWhen/WhereDouble
blind?Author Feedback?NotesICMLFebruary 1June 28-July 2, Bellevue, Washington,
USAYYWeak colocation withACLCOLTFebruary 11July 9-July 11, Budapest,
HungaryNNcolocated withFOCMKDDFebruary 11/18August 21-24, San Diego,
California, USANNUAIMarch 18July 14-17, Barcelona, SpainYNThe larger
conferences are on the west coast in the United States, while the smaller ones
are in Europe.</p><p>2 0.46432042 <a title="422-lda-2" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>Introduction: Probability is one of the most confusingly used words in machine learning.
There are at least 3 distinct ways the word is used.BayesianThe Bayesian
notion of probability is a 'degree of belief'. The degree of belief that some
event (i.e. "stock goes up" or "stock goes down") occurs can be measured by
asking a sequence of questions of the form "Would you bet the stock goes up or
down atYto 1 odds?" A consistent better will switch from 'for' to 'against' at
some single value ofY. The probability is thenY/(Y+1). Bayesian probabilities
express lack of knowledge rather than randomization. They are useful in
learning because we often lack knowledge and expressing that lack flexibly
makes the learning algorithms work better. Bayesian Learning uses
'probability' in this way exclusively.FrequentistThe Frequentist notion of
probability is a rate of occurence. A rate of occurrence can be measured by
doing an experiment many times. If an event occursktimes innexperiments then
it has probability ab</p><p>3 0.41115361 <a title="422-lda-3" href="../hunch_net-2005/hunch_net-2005-02-04-JMLG.html">13 hunch net-2005-02-04-JMLG</a></p>
<p>Introduction: TheJournal of Machine Learning Gossiphas some fine satire about learning
research. In particular, theguidesare amusing and remarkably true.As in all
things, it's easy to criticize the way things are and harder to make them
better.</p><p>4 0.28680646 <a title="422-lda-4" href="../hunch_net-2005/hunch_net-2005-05-02-Reviewing_techniques_for_conferences.html">65 hunch net-2005-05-02-Reviewing techniques for conferences</a></p>
<p>Introduction: The many reviews following the many paper deadlines are just about over. AAAI
and ICML in particular were experimenting with several reviewing
techniques.Double Blind: AAAI and ICML were both double blind this year. It
seemed (overall) beneficial, but two problems arose.For theoretical papers,
with a lot to say, authors often leave out the proofs. This is very hard to
cope with under a double blind review because (1) you can not trust the
authors got the proof right but (2) a blanket "reject" hits many probably-good
papers. Perhaps authors should more strongly favor proof-complete papers sent
to double blind conferences.On the author side, double blind reviewing is
actually somewhat disruptive to research. In particular, it discourages the
author from talking about the subject, which is one of the mechanisms of
research. This is not a great drawback, but it is one not previously
appreciated.Author feedback: AAAI and ICML did author feedback this year. It
seemed helpful for several pape</p><p>5 0.27100581 <a title="422-lda-5" href="../hunch_net-2005/hunch_net-2005-02-19-Loss_Functions_for_Discriminative_Training_of_Energy-Based_Models.html">23 hunch net-2005-02-19-Loss Functions for Discriminative Training of Energy-Based Models</a></p>
<p>Introduction: This is apaperby Yann LeCun and Fu Jie Huang published atAISTAT 2005. I found
this paper very difficult to read, but it does have some point about a
computational shortcut.This paper takes for granted that the method of solving
a problem is gradient descent on parameters. Given this assumption, the
question arises: Do you want to do gradient descent on a probabilistic model
or something else?All (conditional) probabilistic models have the formp(y|x) =
f(x,y)/Z(x)whereZ(x) = sumyf(x,y)(the paper calls- log f(x,y)an "energy").
Iffis parameterized by somew, the gradient has a term forZ(x), and hence for
every value ofy. The paper claims, that such models can be optimized for
classification purposes using only the correctyand the othery' not ywhich
maximizesf(x,y). This can even be done on unnormalizable models. The paper
further claims that this can be done with an approximate maximum. These claims
are plausible based on experimental results and intuition.It wouldn't surprise
me to learn</p><p>6 0.2698288 <a title="422-lda-6" href="../hunch_net-2008/hunch_net-2008-12-12-Summer_Conferences.html">331 hunch net-2008-12-12-Summer Conferences</a></p>
<p>7 0.26532122 <a title="422-lda-7" href="../hunch_net-2010/hunch_net-2010-09-13-AIStats.html">409 hunch net-2010-09-13-AIStats</a></p>
<p>8 0.25340861 <a title="422-lda-8" href="../hunch_net-2007/hunch_net-2007-12-17-New_Machine_Learning_mailing_list.html">278 hunch net-2007-12-17-New Machine Learning mailing list</a></p>
<p>9 0.24664989 <a title="422-lda-9" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>10 0.2466446 <a title="422-lda-10" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>11 0.23483847 <a title="422-lda-11" href="../hunch_net-2005/hunch_net-2005-07-04-The_Health_of_COLT.html">89 hunch net-2005-07-04-The Health of COLT</a></p>
<p>12 0.23348621 <a title="422-lda-12" href="../hunch_net-2006/hunch_net-2006-07-09-The_Stock_Prediction_Machine_Learning_Problem.html">193 hunch net-2006-07-09-The Stock Prediction Machine Learning Problem</a></p>
<p>13 0.2287319 <a title="422-lda-13" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>14 0.22531015 <a title="422-lda-14" href="../hunch_net-2005/hunch_net-2005-05-28-Running_A_Machine_Learning_Summer_School.html">75 hunch net-2005-05-28-Running A Machine Learning Summer School</a></p>
<p>15 0.22430079 <a title="422-lda-15" href="../hunch_net-2006/hunch_net-2006-07-11-New_Models.html">194 hunch net-2006-07-11-New Models</a></p>
<p>16 0.22233576 <a title="422-lda-16" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>17 0.21895818 <a title="422-lda-17" href="../hunch_net-2006/hunch_net-2006-04-30-John_Langford_%26%238211%3B%3E_Yahoo_Research%2C_NY.html">175 hunch net-2006-04-30-John Langford &#8211;> Yahoo Research, NY</a></p>
<p>18 0.21735013 <a title="422-lda-18" href="../hunch_net-2006/hunch_net-2006-09-18-What_is_missing_for_online_collaborative_research%3F.html">208 hunch net-2006-09-18-What is missing for online collaborative research?</a></p>
<p>19 0.21425751 <a title="422-lda-19" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>20 0.21138115 <a title="422-lda-20" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
