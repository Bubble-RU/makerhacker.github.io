<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2012" href="../home/high_scalability-2012_home.html">high_scalability-2012</a> <a title="high_scalability-2012-1197" href="#">high_scalability-2012-1197</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2012-1197-html" href="http://highscalability.com//blog/2012/2/21/pixable-architecture-crawling-analyzing-and-ranking-20-milli.html">html</a></p><p>Introduction: This is a guest post by Alberto Lopez Toledo, PHD, CTO of Pixable, and Julio Viera, VP of Engineering at Pixable. 
 
   Pixable  aggregates photos from across your different social networks and finds the best ones so you never miss an important moment. That means currently processing the metadata of more than 20 million new photos per day: crawling, analyzing, ranking, and sorting them along with the other 5+ billion that are already stored in our database. Making sense of all that data has challenges, but two in particular rise above the rest:
  
 How to access millions of photos per day from Facebook, Twitter, Instagram, and other services in the most efficient manner. 
 How to process, organize, index, and store all the meta-data related to those photos. 
  
Sure, Pixable’s infrastructure is changing continuously, but there are some things that we have learned over the last year. As a result, we have been able to build a scalable infrastructure that takes advantage of today’s tools,</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Pixable  aggregates photos from across your different social networks and finds the best ones so you never miss an important moment. [sent-2, score-0.346]
</p><p>2 That means currently processing the metadata of more than 20 million new photos per day: crawling, analyzing, ranking, and sorting them along with the other 5+ billion that are already stored in our database. [sent-3, score-0.581]
</p><p>3 Making sense of all that data has challenges, but two in particular rise above the rest:     How to access millions of photos per day from Facebook, Twitter, Instagram, and other services in the most efficient manner. [sent-4, score-0.407]
</p><p>4 To compensate for these load fluctuations, we developed our own auto-scaling technology that forecasts how many servers we need of each type according to the current and historic load for a particular time of the day. [sent-14, score-0.302]
</p><p>5 Then we launch or terminate instances just to keep the right level of provisioning. [sent-15, score-0.275]
</p><p>6 So for sudden spikes in traffic, we do some clever launch scheduling of on-demand instances (that launch much faster), and then swapping them out for spot-instances in the next hour. [sent-20, score-0.299]
</p><p>7 Work queue- jobs for crawling and ranking photos, send notifications and more   Virtually all processing at Pixable is done via an asynchronous job (e. [sent-31, score-0.605]
</p><p>8 , crawling new photos from different users from Facebook, sending push notifications, calculating friend rankings, etc). [sent-33, score-0.697]
</p><p>9 We have several dozen worker servers crawling metadata from photos from different services and processing that data. [sent-34, score-0.873]
</p><p>10 As expected, we have different types of jobs: some with high priority, such as real time user calls, messaging, and crawling photos for currently active  users. [sent-36, score-0.838]
</p><p>11 Lower priority jobs include offline crawling and long data-intensive deferred tasks. [sent-37, score-0.577]
</p><p>12 by devoting the job server time to the high priority jobs and pausing the lower priority ones when certain sets of conditions on the platform-wide level are met. [sent-41, score-0.459]
</p><p>13 Some are obvious, such as the average waiting time of jobs or the lag of the slaves (ssshhh, we never have lag on our slaves :-) ), to more complex metrics such as the status of our own PHP synchronization mutex locks for distributed environments. [sent-43, score-0.47]
</p><p>14 Crawling Engine - crawl new photos across Facebook, Twitter and more 24/7   We are constantly improving our crawling technology, which is a complex parallel algorithm that uses a mutex locking library, developed in-house, to synchronize all the processes for a particular user. [sent-45, score-0.997]
</p><p>15 This algorithm has helped us to improve our Facebook crawling speed by at least 5x since launch. [sent-46, score-0.424]
</p><p>16 We can now easily fetch in excess of 20 million new photos every day. [sent-47, score-0.404]
</p><p>17 We’ll get deeper into our crawling engine in a subsidiary document. [sent-49, score-0.351]
</p><p>18 Data Storage - indexing photos and metadata   Naturally, our data storage grows every day. [sent-50, score-0.495]
</p><p>19 Logging, Profiling and Analytics   We developed a highly flexible logging and profiling framework that allows us to record events with high granularity--down to a single line of code. [sent-58, score-0.45]
</p><p>20 On top of that, we can dynamically profile the time between any of the logging events, allowing us to build real-time profiling of our entire system. [sent-62, score-0.294]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('crawling', 0.351), ('photos', 0.346), ('pixable', 0.262), ('developed', 0.156), ('profiling', 0.134), ('frontends', 0.131), ('priority', 0.115), ('amazon', 0.115), ('launch', 0.112), ('jobs', 0.111), ('android', 0.093), ('fluctuations', 0.092), ('metadata', 0.091), ('terminate', 0.088), ('logging', 0.087), ('servers', 0.085), ('mutex', 0.083), ('api', 0.083), ('ranking', 0.079), ('mobile', 0.078), ('actual', 0.077), ('lag', 0.075), ('instances', 0.075), ('currently', 0.075), ('priorities', 0.075), ('us', 0.073), ('stored', 0.069), ('tables', 0.068), ('calls', 0.067), ('mongodb', 0.067), ('user', 0.066), ('mysql', 0.065), ('notifications', 0.064), ('facebook', 0.064), ('slaves', 0.063), ('tracking', 0.062), ('virtually', 0.062), ('backend', 0.061), ('particular', 0.061), ('heavily', 0.06), ('php', 0.06), ('endthe', 0.059), ('devoting', 0.059), ('rankings', 0.059), ('pausing', 0.059), ('web', 0.058), ('every', 0.058), ('considering', 0.056), ('loving', 0.056), ('moneyball', 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="1197-tfidf-1" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<p>Introduction: This is a guest post by Alberto Lopez Toledo, PHD, CTO of Pixable, and Julio Viera, VP of Engineering at Pixable. 
 
   Pixable  aggregates photos from across your different social networks and finds the best ones so you never miss an important moment. That means currently processing the metadata of more than 20 million new photos per day: crawling, analyzing, ranking, and sorting them along with the other 5+ billion that are already stored in our database. Making sense of all that data has challenges, but two in particular rise above the rest:
  
 How to access millions of photos per day from Facebook, Twitter, Instagram, and other services in the most efficient manner. 
 How to process, organize, index, and store all the meta-data related to those photos. 
  
Sure, Pixable’s infrastructure is changing continuously, but there are some things that we have learned over the last year. As a result, we have been able to build a scalable infrastructure that takes advantage of today’s tools,</p><p>2 0.21963686 <a title="1197-tfidf-2" href="../high_scalability-2007/high_scalability-2007-11-13-Flickr_Architecture.html">152 high scalability-2007-11-13-Flickr Architecture</a></p>
<p>Introduction: Update:  Flickr hits  2 Billion photos  served. That's a lot of hamburgers.   Flickr is both my favorite  bird  and the web's leading photo sharing site. Flickr has an amazing challenge, they must handle a vast sea of ever expanding new content, ever increasing legions of  users, and a constant stream of new features, all while providing excellent performance.  How do they do it?
 
Site: http://www.flickr.com
  Information Sources     Flickr and PHP  (an early document)     Capacity Planning for LAMP      Federation at Flickr: Doing Billions of Queries a Day  by Dathan Pattishall.     Building Scalable Web Sites  by Cal Henderson from Flickr.    Database War Stories #3: Flickr  by Tim O'Reilly    Cal Henderson's Talks . A lot of useful PowerPoint presentations. 
 Platform 
    PHP    MySQL    Shards    Memcached for a caching layer.    Squid in reverse-proxy for html and images.    Linux (RedHat)    Smarty for templating    Perl    PEAR for XML and Email parsing    ImageMagick, for ima</p><p>3 0.20260662 <a title="1197-tfidf-3" href="../high_scalability-2011/high_scalability-2011-12-06-Instagram_Architecture%3A_14_Million_users%2C_Terabytes_of_Photos%2C_100s_of_Instances%2C_Dozens_of_Technologies.html">1152 high scalability-2011-12-06-Instagram Architecture: 14 Million users, Terabytes of Photos, 100s of Instances, Dozens of Technologies</a></p>
<p>Introduction: Instagram  is a free photo sharing and social networking service for your iPhone that has been an  instant success . Growing to  14 million users  in just over a year, they reached 150 million photos in August while amassing several terabytes of photos, and they did this with just 3 Instaneers, all on the Amazon stack.
 
The Instagram team has written up what can be considered the canonical description of an early stage startup in this era:  What Powers Instagram: Hundreds of Instances, Dozens of Technologies .
 
Instagram uses a pastiche of different technologies and strategies. The team is small yet has experience rapid growth riding the crest of a rising social and mobile wave, it uses a hybrid of SQL and NoSQL, it uses a ton of open source projects, they chose the cloud over colo, Amazon services are highly leveraged rather than building their own, reliability is through availability zones, async work scheduling links components together, the system is composed as much as possible</p><p>4 0.19289829 <a title="1197-tfidf-4" href="../high_scalability-2012/high_scalability-2012-04-09-The_Instagram_Architecture_Facebook_Bought_for_a_Cool_Billion_Dollars.html">1224 high scalability-2012-04-09-The Instagram Architecture Facebook Bought for a Cool Billion Dollars</a></p>
<p>Introduction: It's been a well kept secret, but you may have heard  Facebook will Buy Photo-Sharing Service Instagram for $1 Billion . Just what is Facebook buying? Here's a quick gloss I did a little over a year ago on a presentation Instagram gave on their architecture. In that article I called Instagram's architecture the " canonical description of an early stage startup in this era." Little did we know how true that would turn out to be. If you want to learn how they did it then don't take a picture, just keep on reading...  
 
 
 
 Instagram  is a free photo sharing and social networking service for your iPhone that has been an  instant success . Growing to  14 million users  in just over a year (now 30 million users), they reached 150 million photos in August while amassing several terabytes of photos, and they did this with just 3 Instaneers, all on the Amazon stack.
 
The Instagram team has written up what can be considered the canonical description of an early stage startup in this era:  Wh</p><p>5 0.18068299 <a title="1197-tfidf-5" href="../high_scalability-2007/high_scalability-2007-10-02-Secrets_to_Fotolog%27s_Scaling_Success.html">106 high scalability-2007-10-02-Secrets to Fotolog's Scaling Success</a></p>
<p>Introduction: Fotolog, a social blogging site centered around photos, grew from about 300 thousand users in 2004 to over 11 million users in 2007. Though they initially experienced the inevitable pains of rapid growth, they overcame their problems and now manage over 300 million photos and 800,000 new photos are added each day. Generating all that fabulous content are 20 million unique monthly visitors and a volunteer army of 30,000 new users each day. They did so well a very impressed suitor bought them out for a cool $90 million. That's scale meets success by anyone standards. How did they do it?
 
Site: http://www.fotolog.com
  Information Sources     Scaling the World's Largest Photo Blogging Community      Congrats to Fotolog on $90mm sale to Hi-Media      Fotolog overtaking Flickr?      Fotolog Hits 11 Million Members and 300 Million Photos Posted      Site of the Week: Fotolog.com   by PC Magazine     CEO John Borthwick's Blog .     DBA Frank Mash's Blog     Fotolog, lessons learnt  by John B</p><p>6 0.17178982 <a title="1197-tfidf-6" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>7 0.16169482 <a title="1197-tfidf-7" href="../high_scalability-2010/high_scalability-2010-05-03-MocoSpace_Architecture_-_3_Billion_Mobile_Page_Views_a_Month.html">821 high scalability-2010-05-03-MocoSpace Architecture - 3 Billion Mobile Page Views a Month</a></p>
<p>8 0.1612488 <a title="1197-tfidf-8" href="../high_scalability-2010/high_scalability-2010-06-10-The_Four_Meta_Secrets_of_Scaling_at_Facebook.html">840 high scalability-2010-06-10-The Four Meta Secrets of Scaling at Facebook</a></p>
<p>9 0.15567321 <a title="1197-tfidf-9" href="../high_scalability-2010/high_scalability-2010-04-12-Poppen.de_Architecture.html">808 high scalability-2010-04-12-Poppen.de Architecture</a></p>
<p>10 0.14767541 <a title="1197-tfidf-10" href="../high_scalability-2012/high_scalability-2012-05-28-The_Anatomy_of_Search_Technology%3A_Crawling_using_Combinators.html">1253 high scalability-2012-05-28-The Anatomy of Search Technology: Crawling using Combinators</a></p>
<p>11 0.14625901 <a title="1197-tfidf-11" href="../high_scalability-2011/high_scalability-2011-06-06-Apple_iCloud%3A_Syncing_and_Distributed_Storage_Over_Streaming_and_Centralized_Storage.html">1053 high scalability-2011-06-06-Apple iCloud: Syncing and Distributed Storage Over Streaming and Centralized Storage</a></p>
<p>12 0.14554583 <a title="1197-tfidf-12" href="../high_scalability-2014/high_scalability-2014-02-17-How_the_AOL.com_Architecture_Evolved_to_99.999%25_Availability%2C_8_Million_Visitors_Per_Day%2C_and_200%2C000_Requests_Per_Second.html">1597 high scalability-2014-02-17-How the AOL.com Architecture Evolved to 99.999% Availability, 8 Million Visitors Per Day, and 200,000 Requests Per Second</a></p>
<p>13 0.14331168 <a title="1197-tfidf-13" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>14 0.14243202 <a title="1197-tfidf-14" href="../high_scalability-2012/high_scalability-2012-04-16-Instagram_Architecture_Update%3A_What%E2%80%99s_new_with_Instagram%3F.html">1228 high scalability-2012-04-16-Instagram Architecture Update: What’s new with Instagram?</a></p>
<p>15 0.14215393 <a title="1197-tfidf-15" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>16 0.14023551 <a title="1197-tfidf-16" href="../high_scalability-2010/high_scalability-2010-08-16-Scaling_an_AWS_infrastructure_-_Tools_and_Patterns.html">881 high scalability-2010-08-16-Scaling an AWS infrastructure - Tools and Patterns</a></p>
<p>17 0.1400924 <a title="1197-tfidf-17" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>18 0.1390413 <a title="1197-tfidf-18" href="../high_scalability-2013/high_scalability-2013-01-14-MongoDB_and_GridFS_for_Inter_and_Intra_Datacenter_Data_Replication_.html">1386 high scalability-2013-01-14-MongoDB and GridFS for Inter and Intra Datacenter Data Replication </a></p>
<p>19 0.13855614 <a title="1197-tfidf-19" href="../high_scalability-2012/high_scalability-2012-04-25-The_Anatomy_of_Search_Technology%3A_blekko%E2%80%99s_NoSQL_database.html">1233 high scalability-2012-04-25-The Anatomy of Search Technology: blekko’s NoSQL database</a></p>
<p>20 0.13786788 <a title="1197-tfidf-20" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.281), (1, 0.101), (2, -0.018), (3, -0.085), (4, -0.002), (5, -0.036), (6, 0.035), (7, -0.044), (8, 0.07), (9, -0.021), (10, 0.034), (11, 0.041), (12, 0.091), (13, -0.065), (14, -0.067), (15, 0.043), (16, -0.021), (17, 0.029), (18, 0.061), (19, 0.018), (20, 0.043), (21, -0.02), (22, -0.01), (23, 0.056), (24, 0.03), (25, -0.034), (26, -0.034), (27, -0.018), (28, 0.01), (29, -0.002), (30, -0.051), (31, 0.012), (32, -0.037), (33, -0.01), (34, 0.061), (35, -0.065), (36, 0.015), (37, -0.082), (38, -0.049), (39, 0.022), (40, 0.005), (41, 0.03), (42, -0.017), (43, -0.017), (44, -0.053), (45, -0.018), (46, -0.056), (47, -0.045), (48, -0.019), (49, -0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95386451 <a title="1197-lsi-1" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<p>Introduction: This is a guest post by Alberto Lopez Toledo, PHD, CTO of Pixable, and Julio Viera, VP of Engineering at Pixable. 
 
   Pixable  aggregates photos from across your different social networks and finds the best ones so you never miss an important moment. That means currently processing the metadata of more than 20 million new photos per day: crawling, analyzing, ranking, and sorting them along with the other 5+ billion that are already stored in our database. Making sense of all that data has challenges, but two in particular rise above the rest:
  
 How to access millions of photos per day from Facebook, Twitter, Instagram, and other services in the most efficient manner. 
 How to process, organize, index, and store all the meta-data related to those photos. 
  
Sure, Pixable’s infrastructure is changing continuously, but there are some things that we have learned over the last year. As a result, we have been able to build a scalable infrastructure that takes advantage of today’s tools,</p><p>2 0.81004441 <a title="1197-lsi-2" href="../high_scalability-2012/high_scalability-2012-04-09-The_Instagram_Architecture_Facebook_Bought_for_a_Cool_Billion_Dollars.html">1224 high scalability-2012-04-09-The Instagram Architecture Facebook Bought for a Cool Billion Dollars</a></p>
<p>Introduction: It's been a well kept secret, but you may have heard  Facebook will Buy Photo-Sharing Service Instagram for $1 Billion . Just what is Facebook buying? Here's a quick gloss I did a little over a year ago on a presentation Instagram gave on their architecture. In that article I called Instagram's architecture the " canonical description of an early stage startup in this era." Little did we know how true that would turn out to be. If you want to learn how they did it then don't take a picture, just keep on reading...  
 
 
 
 Instagram  is a free photo sharing and social networking service for your iPhone that has been an  instant success . Growing to  14 million users  in just over a year (now 30 million users), they reached 150 million photos in August while amassing several terabytes of photos, and they did this with just 3 Instaneers, all on the Amazon stack.
 
The Instagram team has written up what can be considered the canonical description of an early stage startup in this era:  Wh</p><p>3 0.80740148 <a title="1197-lsi-3" href="../high_scalability-2011/high_scalability-2011-12-06-Instagram_Architecture%3A_14_Million_users%2C_Terabytes_of_Photos%2C_100s_of_Instances%2C_Dozens_of_Technologies.html">1152 high scalability-2011-12-06-Instagram Architecture: 14 Million users, Terabytes of Photos, 100s of Instances, Dozens of Technologies</a></p>
<p>Introduction: Instagram  is a free photo sharing and social networking service for your iPhone that has been an  instant success . Growing to  14 million users  in just over a year, they reached 150 million photos in August while amassing several terabytes of photos, and they did this with just 3 Instaneers, all on the Amazon stack.
 
The Instagram team has written up what can be considered the canonical description of an early stage startup in this era:  What Powers Instagram: Hundreds of Instances, Dozens of Technologies .
 
Instagram uses a pastiche of different technologies and strategies. The team is small yet has experience rapid growth riding the crest of a rising social and mobile wave, it uses a hybrid of SQL and NoSQL, it uses a ton of open source projects, they chose the cloud over colo, Amazon services are highly leveraged rather than building their own, reliability is through availability zones, async work scheduling links components together, the system is composed as much as possible</p><p>4 0.74792635 <a title="1197-lsi-4" href="../high_scalability-2014/high_scalability-2014-03-11-Building_a_Social_Music_Service_Using_AWS%2C_Scala%2C_Akka%2C_Play%2C_MongoDB%2C_and_Elasticsearch.html">1609 high scalability-2014-03-11-Building a Social Music Service Using AWS, Scala, Akka, Play, MongoDB, and Elasticsearch</a></p>
<p>Introduction: This is a  guest repost  by  Rotem Hermon , former Chief Architect for  serendip.me , on the architecture and scaling considerations behind making a startup music service. 
 
 serendip.me  is a social music service that helps people discover great music shared by their friends, and also introduces them to their “music soulmates” - people outside their immediate social circle that shares a similar taste in music.
 
Serendip is running on AWS and is built on the following stack:  scala  (and some Java),  akka  (for handling concurrency),  Play framework  (for the web and API front-ends),  MongoDB  and  Elasticsearch .
  Choosing the stack  
One of the challenges of building serendip was the need to handle a large amount of data from day one, since a main feature of serendip is that it collects  every piece of music being shared on Twitter  from public music services. So when we approached the question of choosing the language and technologies to use, an important consideration was the ab</p><p>5 0.740789 <a title="1197-lsi-5" href="../high_scalability-2013/high_scalability-2013-12-02-Evolution_of_Bazaarvoice%E2%80%99s_Architecture_to_500M_Unique_Users_Per_Month.html">1557 high scalability-2013-12-02-Evolution of Bazaarvoice’s Architecture to 500M Unique Users Per Month</a></p>
<p>Introduction: This is a guest post written by    Victor Trac   , Cloud Architect at    Bazaarvoice   .  
   Bazaarvoice is a company that people interact with on a regular basis but have probably never heard of. If you read customer reviews on sites like bestbuy.com, nike.com, or walmart.com, you are using Bazaarvoice services. These sites, along with thousands of others, rely on Bazaarvoice to supply the software and technology to collect and display user conversations about products and services. All of this means that Bazaarvoice processes a lot of sentiment data on most of the products we all use daily. 
     Bazaarvoice helps our clients make better products by using a combination of machine learning and natural language processing to extract useful information and user sentiments from the millions of free-text reviews that go through our platform. This data gets boiled down into reports that clients can use to improve their products and services. We are also starting to look at how to show per</p><p>6 0.74053317 <a title="1197-lsi-6" href="../high_scalability-2010/high_scalability-2010-04-12-Poppen.de_Architecture.html">808 high scalability-2010-04-12-Poppen.de Architecture</a></p>
<p>7 0.73624158 <a title="1197-lsi-7" href="../high_scalability-2012/high_scalability-2012-04-16-Instagram_Architecture_Update%3A_What%E2%80%99s_new_with_Instagram%3F.html">1228 high scalability-2012-04-16-Instagram Architecture Update: What’s new with Instagram?</a></p>
<p>8 0.72760665 <a title="1197-lsi-8" href="../high_scalability-2010/high_scalability-2010-05-03-MocoSpace_Architecture_-_3_Billion_Mobile_Page_Views_a_Month.html">821 high scalability-2010-05-03-MocoSpace Architecture - 3 Billion Mobile Page Views a Month</a></p>
<p>9 0.72530371 <a title="1197-lsi-9" href="../high_scalability-2014/high_scalability-2014-01-06-How_HipChat_Stores_and_Indexes_Billions_of_Messages_Using_ElasticSearch_and_Redis.html">1573 high scalability-2014-01-06-How HipChat Stores and Indexes Billions of Messages Using ElasticSearch and Redis</a></p>
<p>10 0.71727854 <a title="1197-lsi-10" href="../high_scalability-2010/high_scalability-2010-08-16-Scaling_an_AWS_infrastructure_-_Tools_and_Patterns.html">881 high scalability-2010-08-16-Scaling an AWS infrastructure - Tools and Patterns</a></p>
<p>11 0.7157352 <a title="1197-lsi-11" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>12 0.71101528 <a title="1197-lsi-12" href="../high_scalability-2014/high_scalability-2014-04-28-How_Disqus_Went_Realtime_with_165K_Messages_Per_Second_and_Less_than_.2_Seconds_Latency.html">1638 high scalability-2014-04-28-How Disqus Went Realtime with 165K Messages Per Second and Less than .2 Seconds Latency</a></p>
<p>13 0.70679063 <a title="1197-lsi-13" href="../high_scalability-2008/high_scalability-2008-10-27-Notify.me_Architecture_-_Synchronicity_Kills.html">431 high scalability-2008-10-27-Notify.me Architecture - Synchronicity Kills</a></p>
<p>14 0.70543838 <a title="1197-lsi-14" href="../high_scalability-2011/high_scalability-2011-10-28-Stuff_The_Internet_Says_On_Scalability_For_October_28%2C_2011.html">1134 high scalability-2011-10-28-Stuff The Internet Says On Scalability For October 28, 2011</a></p>
<p>15 0.70361549 <a title="1197-lsi-15" href="../high_scalability-2013/high_scalability-2013-09-13-Stuff_The_Internet_Says_On_Scalability_For_September_13%2C_2013.html">1516 high scalability-2013-09-13-Stuff The Internet Says On Scalability For September 13, 2013</a></p>
<p>16 0.70287943 <a title="1197-lsi-16" href="../high_scalability-2012/high_scalability-2012-05-21-Pinterest_Architecture_Update_-_18_Million_Visitors%2C_10x_Growth%2C12_Employees%2C_410_TB_of_Data.html">1248 high scalability-2012-05-21-Pinterest Architecture Update - 18 Million Visitors, 10x Growth,12 Employees, 410 TB of Data</a></p>
<p>17 0.70127225 <a title="1197-lsi-17" href="../high_scalability-2007/high_scalability-2007-11-13-Flickr_Architecture.html">152 high scalability-2007-11-13-Flickr Architecture</a></p>
<p>18 0.69833356 <a title="1197-lsi-18" href="../high_scalability-2014/high_scalability-2014-02-26-The_WhatsApp_Architecture_Facebook_Bought_For_%2419_Billion.html">1602 high scalability-2014-02-26-The WhatsApp Architecture Facebook Bought For $19 Billion</a></p>
<p>19 0.69613802 <a title="1197-lsi-19" href="../high_scalability-2012/high_scalability-2012-07-06-Stuff_The_Internet_Says_On_Scalability_For_July_6%2C_2012.html">1278 high scalability-2012-07-06-Stuff The Internet Says On Scalability For July 6, 2012</a></p>
<p>20 0.69511282 <a title="1197-lsi-20" href="../high_scalability-2012/high_scalability-2012-07-30-Prismatic_Architecture_-_Using_Machine_Learning_on_Social_Networks_to_Figure_Out_What_You_Should_Read_on_the_Web_.html">1293 high scalability-2012-07-30-Prismatic Architecture - Using Machine Learning on Social Networks to Figure Out What You Should Read on the Web </a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.162), (2, 0.185), (10, 0.074), (30, 0.019), (47, 0.018), (51, 0.012), (61, 0.091), (76, 0.011), (77, 0.021), (79, 0.093), (85, 0.053), (89, 0.112), (94, 0.049), (96, 0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97703248 <a title="1197-lda-1" href="../high_scalability-2013/high_scalability-2013-08-19-What_can_the_Amazing_Race_to_the_South_Pole_Teach_us_About_Startups%3F.html">1503 high scalability-2013-08-19-What can the Amazing Race to the South Pole Teach us About Startups?</a></p>
<p>Introduction: At the heart of every software adventure exists a journey in service of a quest. Melodramatic much? Sorry, but while wandering dazzled through  Race to the End of the Earth , a fantastic exhibit at the  Royal BC Museum  on the 1911-1912  race to the South Pole  between Norwegian explorer  Roald Amundsen  and British naval officer  Robert Scott , I couldn’t help but think of the two radically different approaches each team took to the race and it shocked me to see that some of the same principles that lead to success or failure in software development also seem to lead to success or failure in exploration.
  I wish I could reproduce the experience of  walking through the exhibit . Plaque after plaque I remember wondering out loud at Scott’s choices and then nod in agreement with Amundsen’s approach. The core conflict was straight out of any ancient Agile (Amundsen) vs Waterfall (Scott) thread you can find on Usenet. And Waterfall lost.
   As background here are some sources you may want</p><p>same-blog 2 0.95496356 <a title="1197-lda-2" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<p>Introduction: This is a guest post by Alberto Lopez Toledo, PHD, CTO of Pixable, and Julio Viera, VP of Engineering at Pixable. 
 
   Pixable  aggregates photos from across your different social networks and finds the best ones so you never miss an important moment. That means currently processing the metadata of more than 20 million new photos per day: crawling, analyzing, ranking, and sorting them along with the other 5+ billion that are already stored in our database. Making sense of all that data has challenges, but two in particular rise above the rest:
  
 How to access millions of photos per day from Facebook, Twitter, Instagram, and other services in the most efficient manner. 
 How to process, organize, index, and store all the meta-data related to those photos. 
  
Sure, Pixable’s infrastructure is changing continuously, but there are some things that we have learned over the last year. As a result, we have been able to build a scalable infrastructure that takes advantage of today’s tools,</p><p>3 0.94654447 <a title="1197-lda-3" href="../high_scalability-2012/high_scalability-2012-03-16-Stuff_The_Internet_Says_On_Scalability_For_March_16%2C_2012.html">1210 high scalability-2012-03-16-Stuff The Internet Says On Scalability For March 16, 2012</a></p>
<p>Introduction: HighScalability is What We Do:
  
  454,400 : Number of Amazon servers;  45PB : Facebook Data Warehouse, grows exponentially;  5 Atoms : Ultimate limit of thermodynamics;  YouTube : 4 billion views/day, 60 hours of video uploaded every minute, revenue doubled in 2010  
 Quotable quotes:                       
 
  @adrianco : Walmart labs run large single region Cassandra clusters with Intel SSDs and have been in production for two years. Working well for them.  
  @mybellemac : Scalability is a mother. #pinterest 
  @fakesigi :  Thanks for the correction. I saw cloud computing, scalability and my brain turned off.  
  @BVA100 : I disagree with "If it ain't broke, don't fix it". We ought to be forward thinkers, concerned with leading indicators and scalability. 
 
 
 Dilbert on the  meaning of it all . 
  Cassandra and Solid State Drives . DataStax's Rick Branson with a sweet explanation of how Cassandra was built for a world of spinning disks, which means it only writes sequentially, w</p><p>4 0.93940306 <a title="1197-lda-4" href="../high_scalability-2012/high_scalability-2012-02-03-Stuff_The_Internet_Says_On_Scalability_For_February_3%2C_2012.html">1187 high scalability-2012-02-03-Stuff The Internet Says On Scalability For February 3, 2012</a></p>
<p>Introduction: I'm only here for the HighScalability:
  
  762 billion : objects stored on S3;  $1B/Quarter : Google spend on servers;  100 Petabytes : Storage for Facebook's photos and videos. 
 Quotable Quotes:
 
  @knorth2 : #IPO filing says #Facebook is "dependent on our ability to maintain and scale our technical infrastructure" 
  @debuggist : Scalability trumps politics. 
  @cagedether : Hype of #Hadoop is driving pressure on people to keep everything 
  @nanreh : My MongoDB t shirt has never helped me get laid. This is typical with #nosql databases. 
  @lusis : I kenna do it, Capt'n. IO is pegged, disk is saturated…I lost 3 good young men when the cache blew up! 
  Kenton Varda : Jeff Dean puts his pants on one leg at a time, but if he had more than two legs, you'd see that his approach is actually O(log n) 
 
 
 One upon a time manufacturing located near rivers for power. Likewise software will be located next to storage, CPU, and analytics resources in a small cartel of clouds. That's the c</p><p>5 0.93750644 <a title="1197-lda-5" href="../high_scalability-2009/high_scalability-2009-01-20-Product%3A_Amazon%27s_SimpleDB.html">498 high scalability-2009-01-20-Product: Amazon's SimpleDB</a></p>
<p>Introduction: Update 35  :   How and Why Glue is Using Amazon SimpleDB instead of a Relational Database  . Discusses a key design decision that required duplicating data in order to mimic RDBMS joins:   Given the trade off between potential inconsistencies and scalability, social services have to choose the latter.      Update 34  : Apparently Amazon pulled this article. I'm not sure what that means. Maybe time went backwards or something?   Amazon dramatically drops SimpleDB pricing to $0.25 per GB per month from $1.50 per GB  . This puts SimpleDB on par with   Google App Engine  . They also announced  a few new features:   a SQL-like SELECT API as well as a Batch Put operation to streamline uploading of multiple items or attributes  . One of the complaints against SimpleDB is that programmers end up writing too much code to do simple things. These features and a much cheaper price should help considerably. And you can store lots of data now. GAE is still capped.    Update 33  : Amazon announces</p><p>6 0.93323547 <a title="1197-lda-6" href="../high_scalability-2007/high_scalability-2007-11-19-Tailrank_Architecture_-_Learn_How_to_Track_Memes_Across_the_Entire_Blogosphere.html">160 high scalability-2007-11-19-Tailrank Architecture - Learn How to Track Memes Across the Entire Blogosphere</a></p>
<p>7 0.92223471 <a title="1197-lda-7" href="../high_scalability-2007/high_scalability-2007-10-02-Secrets_to_Fotolog%27s_Scaling_Success.html">106 high scalability-2007-10-02-Secrets to Fotolog's Scaling Success</a></p>
<p>8 0.91740763 <a title="1197-lda-8" href="../high_scalability-2010/high_scalability-2010-08-16-Scaling_an_AWS_infrastructure_-_Tools_and_Patterns.html">881 high scalability-2010-08-16-Scaling an AWS infrastructure - Tools and Patterns</a></p>
<p>9 0.91735029 <a title="1197-lda-9" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>10 0.91704309 <a title="1197-lda-10" href="../high_scalability-2011/high_scalability-2011-08-05-Stuff_The_Internet_Says_On_Scalability_For_August_5%2C_2011.html">1093 high scalability-2011-08-05-Stuff The Internet Says On Scalability For August 5, 2011</a></p>
<p>11 0.91699117 <a title="1197-lda-11" href="../high_scalability-2012/high_scalability-2012-08-10-Stuff_The_Internet_Says_On_Scalability_For_August_10%2C_2012.html">1302 high scalability-2012-08-10-Stuff The Internet Says On Scalability For August 10, 2012</a></p>
<p>12 0.9167853 <a title="1197-lda-12" href="../high_scalability-2011/high_scalability-2011-09-02-Stuff_The_Internet_Says_On_Scalability_For_September_2%2C_2011.html">1109 high scalability-2011-09-02-Stuff The Internet Says On Scalability For September 2, 2011</a></p>
<p>13 0.91388625 <a title="1197-lda-13" href="../high_scalability-2012/high_scalability-2012-01-24-The_State_of_NoSQL_in_2012.html">1180 high scalability-2012-01-24-The State of NoSQL in 2012</a></p>
<p>14 0.91387683 <a title="1197-lda-14" href="../high_scalability-2008/high_scalability-2008-09-30-Scalability_Worst_Practices.html">398 high scalability-2008-09-30-Scalability Worst Practices</a></p>
<p>15 0.91379046 <a title="1197-lda-15" href="../high_scalability-2007/high_scalability-2007-11-13-Flickr_Architecture.html">152 high scalability-2007-11-13-Flickr Architecture</a></p>
<p>16 0.91349643 <a title="1197-lda-16" href="../high_scalability-2014/high_scalability-2014-04-04-Stuff_The_Internet_Says_On_Scalability_For_April_4th%2C_2014.html">1626 high scalability-2014-04-04-Stuff The Internet Says On Scalability For April 4th, 2014</a></p>
<p>17 0.91256261 <a title="1197-lda-17" href="../high_scalability-2007/high_scalability-2007-08-22-Wikimedia_architecture.html">72 high scalability-2007-08-22-Wikimedia architecture</a></p>
<p>18 0.91188562 <a title="1197-lda-18" href="../high_scalability-2011/high_scalability-2011-11-04-Stuff_The_Internet_Says_On_Scalability_For_November_4%2C_2011.html">1137 high scalability-2011-11-04-Stuff The Internet Says On Scalability For November 4, 2011</a></p>
<p>19 0.91154492 <a title="1197-lda-19" href="../high_scalability-2011/high_scalability-2011-04-22-Stuff_The_Internet_Says_On_Scalability_For_April_22%2C_2011.html">1028 high scalability-2011-04-22-Stuff The Internet Says On Scalability For April 22, 2011</a></p>
<p>20 0.91148013 <a title="1197-lda-20" href="../high_scalability-2011/high_scalability-2011-06-27-TripAdvisor_Architecture_-_40M_Visitors%2C_200M_Dynamic_Page_Views%2C_30TB_Data.html">1068 high scalability-2011-06-27-TripAdvisor Architecture - 40M Visitors, 200M Dynamic Page Views, 30TB Data</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
