<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1273 high scalability-2012-06-27-Paper: Logic and Lattices for Distributed Programming</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2012" href="../home/high_scalability-2012_home.html">high_scalability-2012</a> <a title="high_scalability-2012-1273" href="#">high_scalability-2012-1273</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1273 high scalability-2012-06-27-Paper: Logic and Lattices for Distributed Programming</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2012-1273-html" href="http://highscalability.com//blog/2012/6/27/paper-logic-and-lattices-for-distributed-programming.html">html</a></p><p>Introduction: Neil Conwayfrom Berkeley CS is giving an advanced level talk ata meetup today
in San Francisco on a new paper: Logic and Lattices for Distributed
Programming \- extending set logic to support CRDT-style lattices. The
description of the meetup is probably the clearest introduction to the
paper:Developers are increasingly choosing datastores that sacrifice strong
consistency guarantees in exchange for improved performance and availability.
Unfortunately, writing reliable distributed programs without the benefit of
strong consistency can be very challenging. In this talk, I'll discuss work
from our group at UC Berkeley that aims to make it easier to write distributed
programs without relying on strong consistency. Bloom is a declarative
programming language for distributed computing, while CALM is an analysis
technique that identifies programs that are guaranteed to be eventually
consistent. I'll then discuss our recent work on extending CALM to support a
broader range of programs, drawin</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('calm', 0.423), ('blooml', 0.397), ('programs', 0.306), ('bloom', 0.292), ('lattices', 0.27), ('commutative', 0.143), ('logic', 0.125), ('extending', 0.121), ('consistency', 0.118), ('meetup', 0.116), ('berkeley', 0.113), ('paper', 0.112), ('guaranteed', 0.107), ('strong', 0.102), ('technique', 0.091), ('monotonic', 0.09), ('analysis', 0.088), ('vocabulary', 0.085), ('discuss', 0.084), ('interpreter', 0.081)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1273-tfidf-1" href="../high_scalability-2012/high_scalability-2012-06-27-Paper%3A_Logic_and_Lattices_for_Distributed_Programming.html">1273 high scalability-2012-06-27-Paper: Logic and Lattices for Distributed Programming</a></p>
<p>Introduction: Neil Conwayfrom Berkeley CS is giving an advanced level talk ata meetup today
in San Francisco on a new paper: Logic and Lattices for Distributed
Programming \- extending set logic to support CRDT-style lattices. The
description of the meetup is probably the clearest introduction to the
paper:Developers are increasingly choosing datastores that sacrifice strong
consistency guarantees in exchange for improved performance and availability.
Unfortunately, writing reliable distributed programs without the benefit of
strong consistency can be very challenging. In this talk, I'll discuss work
from our group at UC Berkeley that aims to make it easier to write distributed
programs without relying on strong consistency. Bloom is a declarative
programming language for distributed computing, while CALM is an analysis
technique that identifies programs that are guaranteed to be eventually
consistent. I'll then discuss our recent work on extending CALM to support a
broader range of programs, drawin</p><p>2 0.27359784 <a title="1273-tfidf-2" href="../high_scalability-2010/high_scalability-2010-06-18-Paper%3A_The_Declarative_Imperative%3A_Experiences_and_Conjectures_in_Distributed_Logic.html">844 high scalability-2010-06-18-Paper: The Declarative Imperative: Experiences and Conjectures in Distributed Logic</a></p>
<p>Introduction: The Declarative Imperative: Experiences and Conjectures in Distributed Logic
is written by UC Berkeley's Joseph Hellersteinfor a keynote speech he gave at
PODS. The video version of the talk is here. You may have heard about Mr.
Hellerstein through theBerkeley Orders Of Magnitude project (BOOM), whose
purpose is to help people build systems that are OOM (orders of magnitude)
bigger than are building today, with OOM less effort than traditional
programming methodologies. A noble goal which may be why BOOM was rated as a
top 10 emerging technology for 2010 byMIT Technology Review. Quite an
honor.The motivation for the talk is a familiar one: it's a dark period for
computer programming and if we don't learn how to write parallel programs the
children of Moore's law will destroy us all. We have more and more processors,
yet we are stuck on figuring out how the average programmer can exploit them.
The BOOM solution is the Bloom language which is based onDedalus: Dedalus is a
temporal logic</p><p>3 0.1135193 <a title="1273-tfidf-3" href="../high_scalability-2009/high_scalability-2009-05-06-Dyrad.html">591 high scalability-2009-05-06-Dyrad</a></p>
<p>Introduction: The Dryad Project is investigating programming models for writing parallel and
distributed programs to scale from a small cluster to a large data-center.</p><p>4 0.099860646 <a title="1273-tfidf-4" href="../high_scalability-2012/high_scalability-2012-04-13-Stuff_The_Internet_Says_On_Scalability_For_April_13%2C_2012.html">1227 high scalability-2012-04-13-Stuff The Internet Says On Scalability For April 13, 2012</a></p>
<p>Introduction: It's HighScalability Time:50 million in 50 days: Draw Something downloads;40
million concurrent users: SkypeKey to making sensors ubiquitous is getting the
BOM cost down. Here's a dream way of making that happen: Bye-Bye Batteries:
Radio Waves as a Low-Power Source. "Silicon technology has advanced to the
point where even tiny amounts of energy can do useful work." No batteries ==
cheaper, smaller products == ubiquity.The MySQL "swap insanity" problem and
the effects of the NUMA architecture. Jeremy Cole with a spectacular article
on the differences between NUMA and SMP/UMA systems and the mostly
unsatisfactory tricks required to get MySQL to perform on NUMA systems. There
are really two issues: the evils of an OS controlled swap and NUMA performance
effects due to a single node (in the NUMA sense) running out of memory. This
is the kind of stuff you only see when you push your systems to the edge.
Also,Measuring NUMA effects with the STREAM benchmark,MongoDB on NUMA, and You
Buy a NUM</p><p>5 0.093595713 <a title="1273-tfidf-5" href="../high_scalability-2014/high_scalability-2014-04-03-Leslie_Lamport_to_Programmers%3A_You%27re_Doing_it_Wrong.html">1625 high scalability-2014-04-03-Leslie Lamport to Programmers: You're Doing it Wrong</a></p>
<p>Introduction: Famous computer scientist Leslie Lamport is definitely not a worse is
betterkind of guy. In Computation and State Machines he wants to make the case
that to get better programs we need to teach programmers to think better. And
programmers will think better when they learn to think in terms of concepts
firmly grounded in the language of mathematics.I was disappointed that there
was so much English in the paper. Surely it would have been more convincing if
it was written as a mathematical proof. Or would it?This whole topic has been
argued extensively throughout thousands of years of philosophy. Mathematics
has always been a strange attractor for those trying to escape a flawed human
rationality. In the end as alluring as the utopia of mathematics is, it lacks
a coherent theory of meaning and programming is not about rearranging
ungrounded symbols, it's about manipulating and shaping meaning.For
programmers I thinkLudwig Wittgensteinhas the right sense of things. Meaning
is derived by us</p><p>6 0.091345802 <a title="1273-tfidf-6" href="../high_scalability-2010/high_scalability-2010-12-23-Paper%3A_CRDTs%3A_Consistency_without_concurrency_control.html">963 high scalability-2010-12-23-Paper: CRDTs: Consistency without concurrency control</a></p>
<p>7 0.087343529 <a title="1273-tfidf-7" href="../high_scalability-2010/high_scalability-2010-03-03-Hot_Scalability_Links_for_March_3%2C_2010.html">787 high scalability-2010-03-03-Hot Scalability Links for March 3, 2010</a></p>
<p>8 0.087123089 <a title="1273-tfidf-8" href="../high_scalability-2013/high_scalability-2013-08-30-Stuff_The_Internet_Says_On_Scalability_For_August_30%2C_2013.html">1509 high scalability-2013-08-30-Stuff The Internet Says On Scalability For August 30, 2013</a></p>
<p>9 0.083319604 <a title="1273-tfidf-9" href="../high_scalability-2009/high_scalability-2009-05-05-Drop_ACID_and_Think_About_Data.html">589 high scalability-2009-05-05-Drop ACID and Think About Data</a></p>
<p>10 0.082171068 <a title="1273-tfidf-10" href="../high_scalability-2009/high_scalability-2009-08-24-How_Google_Serves_Data_from_Multiple_Datacenters.html">687 high scalability-2009-08-24-How Google Serves Data from Multiple Datacenters</a></p>
<p>11 0.081616394 <a title="1273-tfidf-11" href="../high_scalability-2012/high_scalability-2012-08-10-Stuff_The_Internet_Says_On_Scalability_For_August_10%2C_2012.html">1302 high scalability-2012-08-10-Stuff The Internet Says On Scalability For August 10, 2012</a></p>
<p>12 0.078682706 <a title="1273-tfidf-12" href="../high_scalability-2009/high_scalability-2009-09-13-How_is_Berkely_DB_fare_against_other_Key-Value_Database.html">704 high scalability-2009-09-13-How is Berkely DB fare against other Key-Value Database</a></p>
<p>13 0.074845687 <a title="1273-tfidf-13" href="../high_scalability-2011/high_scalability-2011-11-23-Paper%3A_Don%E2%80%99t_Settle_for_Eventual%3A_Scalable_Causal_Consistency_for_Wide-Area_Storage_with_COPS.html">1146 high scalability-2011-11-23-Paper: Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</a></p>
<p>14 0.074151859 <a title="1273-tfidf-14" href="../high_scalability-2008/high_scalability-2008-09-28-Product%3A_Happy_%3D_Hadoop_%2B_Python.html">397 high scalability-2008-09-28-Product: Happy = Hadoop + Python</a></p>
<p>15 0.07385923 <a title="1273-tfidf-15" href="../high_scalability-2011/high_scalability-2011-04-13-Paper%3A_NoSQL_Databases_-_NoSQL_Introduction_and_Overview.html">1022 high scalability-2011-04-13-Paper: NoSQL Databases - NoSQL Introduction and Overview</a></p>
<p>16 0.068445966 <a title="1273-tfidf-16" href="../high_scalability-2014/high_scalability-2014-04-25-Stuff_The_Internet_Says_On_Scalability_For_April_25th%2C_2014.html">1637 high scalability-2014-04-25-Stuff The Internet Says On Scalability For April 25th, 2014</a></p>
<p>17 0.068035975 <a title="1273-tfidf-17" href="../high_scalability-2009/high_scalability-2009-03-05-Strategy%3A__In_Cloud_Computing_Systematically_Drive_Load_to_the_CPU.html">526 high scalability-2009-03-05-Strategy:  In Cloud Computing Systematically Drive Load to the CPU</a></p>
<p>18 0.066412456 <a title="1273-tfidf-18" href="../high_scalability-2012/high_scalability-2012-10-12-Stuff_The_Internet_Says_On_Scalability_For_October_12%2C_2012.html">1339 high scalability-2012-10-12-Stuff The Internet Says On Scalability For October 12, 2012</a></p>
<p>19 0.066014148 <a title="1273-tfidf-19" href="../high_scalability-2012/high_scalability-2012-12-18-Georeplication%3A_When_Bad_Things_Happen_to_Good_Systems.html">1374 high scalability-2012-12-18-Georeplication: When Bad Things Happen to Good Systems</a></p>
<p>20 0.065875031 <a title="1273-tfidf-20" href="../high_scalability-2011/high_scalability-2011-12-08-Update_on_Scalable_Causal_Consistency_For_Wide-Area_Storage_With_COPS.html">1153 high scalability-2011-12-08-Update on Scalable Causal Consistency For Wide-Area Storage With COPS</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.091), (1, 0.038), (2, 0.037), (3, 0.068), (4, -0.004), (5, 0.068), (6, -0.002), (7, 0.002), (8, -0.031), (9, 0.021), (10, 0.013), (11, 0.016), (12, -0.035), (13, -0.05), (14, 0.016), (15, -0.0), (16, 0.034), (17, 0.007), (18, 0.026), (19, -0.039), (20, 0.041), (21, 0.035), (22, -0.052), (23, 0.035), (24, -0.072), (25, -0.015), (26, 0.016), (27, -0.021), (28, 0.014), (29, -0.033), (30, 0.03), (31, 0.021), (32, -0.062), (33, 0.028), (34, -0.031), (35, -0.065), (36, -0.009), (37, 0.023), (38, 0.018), (39, 0.058), (40, -0.013), (41, 0.038), (42, -0.023), (43, -0.028), (44, 0.009), (45, -0.009), (46, -0.022), (47, 0.011), (48, 0.019), (49, -0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97504133 <a title="1273-lsi-1" href="../high_scalability-2012/high_scalability-2012-06-27-Paper%3A_Logic_and_Lattices_for_Distributed_Programming.html">1273 high scalability-2012-06-27-Paper: Logic and Lattices for Distributed Programming</a></p>
<p>Introduction: Neil Conwayfrom Berkeley CS is giving an advanced level talk ata meetup today
in San Francisco on a new paper: Logic and Lattices for Distributed
Programming \- extending set logic to support CRDT-style lattices. The
description of the meetup is probably the clearest introduction to the
paper:Developers are increasingly choosing datastores that sacrifice strong
consistency guarantees in exchange for improved performance and availability.
Unfortunately, writing reliable distributed programs without the benefit of
strong consistency can be very challenging. In this talk, I'll discuss work
from our group at UC Berkeley that aims to make it easier to write distributed
programs without relying on strong consistency. Bloom is a declarative
programming language for distributed computing, while CALM is an analysis
technique that identifies programs that are guaranteed to be eventually
consistent. I'll then discuss our recent work on extending CALM to support a
broader range of programs, drawin</p><p>2 0.82686836 <a title="1273-lsi-2" href="../high_scalability-2012/high_scalability-2012-05-10-Paper%3A_Paxos_Made_Moderately_Complex.html">1243 high scalability-2012-05-10-Paper: Paxos Made Moderately Complex</a></p>
<p>Introduction: If you are a normal human being and find thePaxos protocolconfusing, then this
paper, Paxos Made Moderately Complex, is a great find. Robbert van Renesse
from Cornell University has written a clear and well written paper with
excellent explanations.The Abstract:For anybody who has ever tried to
implement it, Paxos is by no means a simple protocol, even though it is based
on relatively simple invariants. This paper provides imperative pseudo-code
for the full Paxos (or Multi-Paxos) protocol without shying away from
discussing various implementation details. The initial description avoids
optimizations that complicate comprehension. Next we discuss liveness, and
list various optimizations that make the protocol practical.Related
ArticlesPaxos on HighScalability.com</p><p>3 0.76785338 <a title="1273-lsi-3" href="../high_scalability-2012/high_scalability-2012-12-18-Georeplication%3A_When_Bad_Things_Happen_to_Good_Systems.html">1374 high scalability-2012-12-18-Georeplication: When Bad Things Happen to Good Systems</a></p>
<p>Introduction: Georeplication is one of the standard techniques for dealing when bad things--
failure and latency--happen to good systems. The problem is always: how do you
do that? Murat Demirbas, Associate Professor at SUNY Buffalo, has a couple of
really good posts that can help:MDCC: Multi-Data Center Consistency andMaking
Geo-Replicated Systems Fast as Possible, Consistent when Necessary. In MDCC:
Multi-Data Center Consistency Murat discusses a paper that says synchronous
wide-area replication can be feasible. There's a quick and clear explanation
of Paxos and various optimizations that is worth the price of admission. We
find that strong consistency doesn't have to be lost across a WAN:The good
thing about using Paxos over the WAN is you /almost/ get the full CAP  (all
three properties: consistency, availability, and partition-freedom). As we
discussed earlier (Paxos taught), Paxos is CP, that is, in the presence of a
partition, Paxos keeps consistency over availability. But, Paxos can still
pr</p><p>4 0.76586711 <a title="1273-lsi-4" href="../high_scalability-2010/high_scalability-2010-12-23-Paper%3A_CRDTs%3A_Consistency_without_concurrency_control.html">963 high scalability-2010-12-23-Paper: CRDTs: Consistency without concurrency control</a></p>
<p>Introduction: For a great Christmas read forgetThe Night Before Christmas, a heart warming
poem written by Clement Moore for his children, that created the modern idea
of Santa Clause we all know and anticipate each Christmas eve. Instead, curl
up with a some potent eggnog, nog being any drink made with rum, and read
CRDTs: Consistency without concurrency control by Mihai Letia, Nuno Preguiรงa,
and Marc Shapiro, which talks about CRDTs (Commutative Replicated Data Type),a
data type whose operations commute when they are concurrent.From the
introduction, which also serves as a nice concise overview of distributed
consistency issues:Shared read-only data is easy to scale by using well-
understood replication techniques. However, sharing mutable data at a large
scale is a difficult problem, because of the CAP impossibility result [5]. Two
approaches dominate in practice. One ensures scalability by giving up
consistency guarantees, for instance using the Last-Writer-Wins (LWW) approach
[7]. The alternati</p><p>5 0.75920421 <a title="1273-lsi-5" href="../high_scalability-2009/high_scalability-2009-02-03-Paper%3A_Optimistic_Replication.html">507 high scalability-2009-02-03-Paper: Optimistic Replication</a></p>
<p>Introduction: To scale in the large you have to partition. Data has to be spread around,
replicated, and kept consistent (keeping replicas sufficiently similar to one
another despite operations being submittedindependently at different sites).
The result is a highly available, well performing, and scalable
system.Partitioning is required, but it's a pain to do efficiently and
correctly. UntilQuantum teleportationbecomes a reality how data is kept
consistent across a bewildering number of failure scenarios is a key design
decision.This excellent paper by Yasushi Saito and Marc Shapiro takes us on a
wild ride (OK, maybe not so wild) of different approaches to achieving
consistency.What's cool about this paper is they go over some real systems
that we are familiar with and cover how they work: DNS (single-master, state-
transfer), Usenet (multi-master), PDAs (multi-master, state-transfer, manual
or application-specific conflict resolution), Bayou (multi-master, operation-
transfer, epidemic propagation</p><p>6 0.74751693 <a title="1273-lsi-6" href="../high_scalability-2010/high_scalability-2010-06-18-Paper%3A_The_Declarative_Imperative%3A_Experiences_and_Conjectures_in_Distributed_Logic.html">844 high scalability-2010-06-18-Paper: The Declarative Imperative: Experiences and Conjectures in Distributed Logic</a></p>
<p>7 0.74579918 <a title="1273-lsi-7" href="../high_scalability-2013/high_scalability-2013-05-16-Paper%3A_Warp%3A_Multi-Key_Transactions_for_Key-Value_Stores.html">1459 high scalability-2013-05-16-Paper: Warp: Multi-Key Transactions for Key-Value Stores</a></p>
<p>8 0.71090621 <a title="1273-lsi-8" href="../high_scalability-2007/high_scalability-2007-10-03-Paper%3A_Brewer%27s_Conjecture_and_the_Feasibility_of_Consistent_Available_Partition-Tolerant_Web_Services.html">108 high scalability-2007-10-03-Paper: Brewer's Conjecture and the Feasibility of Consistent Available Partition-Tolerant Web Services</a></p>
<p>9 0.69814533 <a title="1273-lsi-9" href="../high_scalability-2011/high_scalability-2011-11-23-Paper%3A_Don%E2%80%99t_Settle_for_Eventual%3A_Scalable_Causal_Consistency_for_Wide-Area_Storage_with_COPS.html">1146 high scalability-2011-11-23-Paper: Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</a></p>
<p>10 0.697752 <a title="1273-lsi-10" href="../high_scalability-2010/high_scalability-2010-09-01-Paper%3A_The_Case_for_Determinism_in_Database_Systems__.html">890 high scalability-2010-09-01-Paper: The Case for Determinism in Database Systems  </a></p>
<p>11 0.69419765 <a title="1273-lsi-11" href="../high_scalability-2011/high_scalability-2011-12-08-Update_on_Scalable_Causal_Consistency_For_Wide-Area_Storage_With_COPS.html">1153 high scalability-2011-12-08-Update on Scalable Causal Consistency For Wide-Area Storage With COPS</a></p>
<p>12 0.67890203 <a title="1273-lsi-12" href="../high_scalability-2013/high_scalability-2013-05-01-Myth%3A_Eric_Brewer_on_Why_Banks_are_BASE_Not_ACID_-_Availability_Is_Revenue_.html">1450 high scalability-2013-05-01-Myth: Eric Brewer on Why Banks are BASE Not ACID - Availability Is Revenue </a></p>
<p>13 0.67452592 <a title="1273-lsi-13" href="../high_scalability-2008/high_scalability-2008-07-26-Google%27s_Paxos_Made_Live_%E2%80%93_An_Engineering_Perspective.html">357 high scalability-2008-07-26-Google's Paxos Made Live – An Engineering Perspective</a></p>
<p>14 0.67242843 <a title="1273-lsi-14" href="../high_scalability-2013/high_scalability-2013-05-23-Paper%3A_Calvin%3A_Fast_Distributed_Transactions_for_Partitioned_Database_Systems.html">1463 high scalability-2013-05-23-Paper: Calvin: Fast Distributed Transactions for Partitioned Database Systems</a></p>
<p>15 0.6550439 <a title="1273-lsi-15" href="../high_scalability-2010/high_scalability-2010-06-30-Paper%3A_GraphLab%3A_A_New_Framework_For_Parallel_Machine_Learning.html">850 high scalability-2010-06-30-Paper: GraphLab: A New Framework For Parallel Machine Learning</a></p>
<p>16 0.65052706 <a title="1273-lsi-16" href="../high_scalability-2014/high_scalability-2014-03-12-Paper%3A_Scalable_Eventually_Consistent_Counters_over_Unreliable_Networks.html">1611 high scalability-2014-03-12-Paper: Scalable Eventually Consistent Counters over Unreliable Networks</a></p>
<p>17 0.64733553 <a title="1273-lsi-17" href="../high_scalability-2012/high_scalability-2012-08-06-Paper%3A_High-Performance_Concurrency_Control_Mechanisms_for_Main-Memory_Databases.html">1299 high scalability-2012-08-06-Paper: High-Performance Concurrency Control Mechanisms for Main-Memory Databases</a></p>
<p>18 0.64517456 <a title="1273-lsi-18" href="../high_scalability-2010/high_scalability-2010-11-30-NoCAP_%E2%80%93_Part_III_%E2%80%93_GigaSpaces_clustering_explained...html">950 high scalability-2010-11-30-NoCAP – Part III – GigaSpaces clustering explained..</a></p>
<p>19 0.64192086 <a title="1273-lsi-19" href="../high_scalability-2009/high_scalability-2009-09-16-Paper%3A_A_practical_scalable_distributed_B-tree.html">705 high scalability-2009-09-16-Paper: A practical scalable distributed B-tree</a></p>
<p>20 0.63319999 <a title="1273-lsi-20" href="../high_scalability-2009/high_scalability-2009-08-08-Yahoo%21%27s_PNUTS_Database%3A_Too_Hot%2C_Too_Cold_or_Just_Right%3F.html">676 high scalability-2009-08-08-Yahoo!'s PNUTS Database: Too Hot, Too Cold or Just Right?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.132), (2, 0.211), (5, 0.293), (30, 0.04), (40, 0.015), (61, 0.087), (77, 0.031), (79, 0.026), (85, 0.019), (94, 0.049)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95361817 <a title="1273-lda-1" href="../high_scalability-2009/high_scalability-2009-03-12-Google_TechTalk%3A_Amdahl%27s_Law_in_the_Multicore_Era.html">534 high scalability-2009-03-12-Google TechTalk: Amdahl's Law in the Multicore Era</a></p>
<p>Introduction: Over the last several decades computer architects have been phenomenally
successful turning the transistor bounty provided by Moore's Law into chips
with ever increasing single-threaded performance. During many of these
successful years, however, many researchers paid scant attention to
multiprocessor work. Now as vendors turn to multicore chips, researchers are
reacting with more papers on multi-threaded systems. While this is good, we
are concerned that further work on single-thread performance will be
squashed.To help understand future high-level trade-offs, we develop a
corollary to Amdahl's Law for multicore chips [Hill & Marty, IEEE Computer
2008]. It models fixed chip resources for alternative designs that use
symmetric cores, asymmetric cores, or dynamic techniques that allow cores to
work together on sequential execution. Our results encourage multicore
designers to view performance of the entire chip rather than focus on core
efficiencies. Moreover, we observe that obtaining</p><p>same-blog 2 0.88202035 <a title="1273-lda-2" href="../high_scalability-2012/high_scalability-2012-06-27-Paper%3A_Logic_and_Lattices_for_Distributed_Programming.html">1273 high scalability-2012-06-27-Paper: Logic and Lattices for Distributed Programming</a></p>
<p>Introduction: Neil Conwayfrom Berkeley CS is giving an advanced level talk ata meetup today
in San Francisco on a new paper: Logic and Lattices for Distributed
Programming \- extending set logic to support CRDT-style lattices. The
description of the meetup is probably the clearest introduction to the
paper:Developers are increasingly choosing datastores that sacrifice strong
consistency guarantees in exchange for improved performance and availability.
Unfortunately, writing reliable distributed programs without the benefit of
strong consistency can be very challenging. In this talk, I'll discuss work
from our group at UC Berkeley that aims to make it easier to write distributed
programs without relying on strong consistency. Bloom is a declarative
programming language for distributed computing, while CALM is an analysis
technique that identifies programs that are guaranteed to be eventually
consistent. I'll then discuss our recent work on extending CALM to support a
broader range of programs, drawin</p><p>3 0.83521092 <a title="1273-lda-3" href="../high_scalability-2007/high_scalability-2007-11-13-Friendster_Lost_Lead_Because_of_a_Failure_to_Scale.html">153 high scalability-2007-11-13-Friendster Lost Lead Because of a Failure to Scale</a></p>
<p>Introduction: Hey, this scaling stuff might just be important. Jim Scheinman, former Bebo
and Friendster exec, puts the blame squarely on Friendster's inability to
scale as why they lost the social networking race:VB: Can you tell me a bit
about what you learned in your time at Friendster? JS:For me, it basically
came down to failed execution on the technology side -- we had millions of
Friendster members begging us to get the site working faster so they could log
in and spend hours social networking with their friends. I remember coming in
to the office for months reading thousands of customer service emails telling
us that if we didn't get our site working better soon, they'd be 'forced to
join' a new social networking site that had just launched called MySpaceâ&euro;Śthe
rest is history. To be fair to Friendster's technology team at the time, they
were on the forefront of many new scaling and database issues that web sites
simply hadn't had to deal with prior to Friendster. As is often the case, the
ear</p><p>4 0.83307379 <a title="1273-lda-4" href="../high_scalability-2008/high_scalability-2008-06-06-GigaOm_Structure_08_Conference_on_June_25th_in_San_Francisco.html">341 high scalability-2008-06-06-GigaOm Structure 08 Conference on June 25th in San Francisco</a></p>
<p>Introduction: If you just can't get enough high scalability talk you might want to take a
look GigaOm's Structure 08 conference. The slate of speakers looks
appropriately interesting and San Francisco is truly magical this time of
year. High Scalability readers even get a price break is you use the HIGHSCALE
discount code! I'll be on vacation so I won't see you there, but it looks like
a good time. For a nice change of pace consider visitingMoMAnext door. Here's
a blurb on the conference:A reminder to our readers about Structure 08,
GigaOm's upcomingconference dedicated to web infrastructure. In addition to
keynotesfrom leaders like Jim Crowe, chairman and CEO of Level 3Communications
and Werner Vogels, CTO of Amazon, the event willfeature workshops from Google
App Engine, Microsoft and a specialworkshop from Fenwick and West who will
cover how to raise money foran infrastructure start up. Learn from the guru's
at Amazon, Google,Microsoft, Sun, VMWare and more about what the future of
internetinfras</p><p>5 0.81476414 <a title="1273-lda-5" href="../high_scalability-2011/high_scalability-2011-09-09-Stuff_The_Internet_Says_On_Scalability_For_September_9%2C_2011.html">1113 high scalability-2011-09-09-Stuff The Internet Says On Scalability For September 9, 2011</a></p>
<p>Introduction: Scale the modern way/ No brush / No lather / No rub-in / Big tube 35 cents -
Drug stores /HighScalability:GAEServes 1.5 Billion Pages a
DayPotentquotables:@kendallmiller : The code changes I'm most proud of are the
ones few people will ever see - like I just tripled the scalability of our
session analysis.@Kellblog: Heard: "Cassandra is more a system on which you
build aDBMSthan aDBMSitself."@DDevine_au:  Ahdammit. I'm thinking of using a
#NoSQL database. Down the rabbit hole I go.A comprehensive guide to parallel
video decoding. EmericGrange with a sweet explanation of the decoding process.
Node.js vs. Scala - "Scaling in the large". tedsuo tldrs it: in node, there is
only one concurrency model.  A number of other platforms offer multiple
concurrency models.  If you want access to one of those other models down the
line, you will have to carve off that part of your application and rewrite it
in another language. Quora: How doesHBasewrite performance differ from write
performance in Ca</p><p>6 0.79057771 <a title="1273-lda-6" href="../high_scalability-2010/high_scalability-2010-09-09-How_did_Google_Instant_become_Faster_with_5-7X_More_Results_Pages%3F.html">899 high scalability-2010-09-09-How did Google Instant become Faster with 5-7X More Results Pages?</a></p>
<p>7 0.77815479 <a title="1273-lda-7" href="../high_scalability-2013/high_scalability-2013-07-05-Stuff_The_Internet_Says_On_Scalability_For_July_5%2C_2013.html">1487 high scalability-2013-07-05-Stuff The Internet Says On Scalability For July 5, 2013</a></p>
<p>8 0.77590835 <a title="1273-lda-8" href="../high_scalability-2009/high_scalability-2009-01-05-Messaging_is_not_just_for_investment_banks.html">485 high scalability-2009-01-05-Messaging is not just for investment banks</a></p>
<p>9 0.77385825 <a title="1273-lda-9" href="../high_scalability-2013/high_scalability-2013-09-27-Stuff_The_Internet_Says_On_Scalability_For_September_27%2C_2013.html">1523 high scalability-2013-09-27-Stuff The Internet Says On Scalability For September 27, 2013</a></p>
<p>10 0.77340758 <a title="1273-lda-10" href="../high_scalability-2012/high_scalability-2012-05-18-Stuff_The_Internet_Says_On_Scalability_For_May_18%2C_2012.html">1247 high scalability-2012-05-18-Stuff The Internet Says On Scalability For May 18, 2012</a></p>
<p>11 0.76799339 <a title="1273-lda-11" href="../high_scalability-2008/high_scalability-2008-02-26-Architecture_to_Allow_High_Availability_File_Upload.html">262 high scalability-2008-02-26-Architecture to Allow High Availability File Upload</a></p>
<p>12 0.74447119 <a title="1273-lda-12" href="../high_scalability-2013/high_scalability-2013-03-15-Stuff_The_Internet_Says_On_Scalability_For_March_15%2C_2013.html">1424 high scalability-2013-03-15-Stuff The Internet Says On Scalability For March 15, 2013</a></p>
<p>13 0.73933452 <a title="1273-lda-13" href="../high_scalability-2007/high_scalability-2007-12-05-Product%3A_Tugela_Cache.html">174 high scalability-2007-12-05-Product: Tugela Cache</a></p>
<p>14 0.73752534 <a title="1273-lda-14" href="../high_scalability-2014/high_scalability-2014-05-15-Paper%3A_SwiftCloud%3A_Fault-Tolerant_Geo-Replication_Integrated_all_the_Way_to_the_Client_Machine.html">1648 high scalability-2014-05-15-Paper: SwiftCloud: Fault-Tolerant Geo-Replication Integrated all the Way to the Client Machine</a></p>
<p>15 0.72144932 <a title="1273-lda-15" href="../high_scalability-2007/high_scalability-2007-07-30-Product%3A_GridLayer._Utility_computing_for_online_application.html">42 high scalability-2007-07-30-Product: GridLayer. Utility computing for online application</a></p>
<p>16 0.69337058 <a title="1273-lda-16" href="../high_scalability-2007/high_scalability-2007-10-20-Should_you_build_your_next_website_using_3tera%27s_grid_OS%3F.html">126 high scalability-2007-10-20-Should you build your next website using 3tera's grid OS?</a></p>
<p>17 0.68475187 <a title="1273-lda-17" href="../high_scalability-2009/high_scalability-2009-05-08-Publish-subscribe_model_does_not_scale%3F.html">595 high scalability-2009-05-08-Publish-subscribe model does not scale?</a></p>
<p>18 0.68460494 <a title="1273-lda-18" href="../high_scalability-2010/high_scalability-2010-12-23-Paper%3A_CRDTs%3A_Consistency_without_concurrency_control.html">963 high scalability-2010-12-23-Paper: CRDTs: Consistency without concurrency control</a></p>
<p>19 0.67708302 <a title="1273-lda-19" href="../high_scalability-2011/high_scalability-2011-05-17-Facebook%3A_An_Example_Canonical_Architecture_for_Scaling_Billions_of_Messages.html">1042 high scalability-2011-05-17-Facebook: An Example Canonical Architecture for Scaling Billions of Messages</a></p>
<p>20 0.67672688 <a title="1273-lda-20" href="../high_scalability-2014/high_scalability-2014-05-02-Stuff_The_Internet_Says_On_Scalability_For_May_2nd%2C_2014.html">1642 high scalability-2014-05-02-Stuff The Internet Says On Scalability For May 2nd, 2014</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
