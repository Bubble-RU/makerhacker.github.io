<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1253 high scalability-2012-05-28-The Anatomy of Search Technology: Crawling using Combinators</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2012" href="../home/high_scalability-2012_home.html">high_scalability-2012</a> <a title="high_scalability-2012-1253" href="#">high_scalability-2012-1253</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1253 high scalability-2012-05-28-The Anatomy of Search Technology: Crawling using Combinators</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2012-1253-html" href="http://highscalability.com//blog/2012/5/28/the-anatomy-of-search-technology-crawling-using-combinators.html">html</a></p><p>Introduction: This is the second guest post ( part 1 ,  part 3 ) of a series by Greg Lindahl, CTO of blekko, the spam free search engine.  Previously, Greg was Founder and Distinguished Engineer at PathScale, at which he was the architect of the InfiniPath low-latency InfiniBand HCA, used to build tightly-coupled supercomputing clusters.  
  What's so hard about crawling the web?  
Web crawlers have been around as long as the Web has -- and before the web, there were crawlers for gopher and ftp. You would think that 25 years of experience would render crawling a solved problem, but the vast growth of the web and new inventions in the technology of webspam and other unsavory content results in a constant supply of new challenges. The general difficulty of tightly-coupled parallel programming also rears its head, as the web has scaled from millions to 100s of billions of pages.
  Existing Open-Source Crawlers and Crawls  
This article is mainly going to discuss blekko's crawler and its use of combinat</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 It's rumored that Google's web crawl and index is over 100 billion  webpages, and Google announced in 2008 that their "crawl frontier"-- the list of all of the urls that they had seen on other webpages-- was over. [sent-8, score-0.542]
</p><p>2 That's only a fraction of a  percent of the webpages in Google's crawl frontier, so we need to be very good at crawling the best pages, and only the best pages. [sent-10, score-0.861]
</p><p>3 One way to do this is to compute the ranks of webpages as we crawl, including the ranks of the pages we haven't crawled yet. [sent-11, score-0.584]
</p><p>4 The rank of a page is dependent upon the number and quality of incoming links, plus many other on-page measures, such as the text on the page, the number of ads compared to the amount of text, and so forth. [sent-12, score-0.502]
</p><p>5 The on-page measures can't be known before the page is first crawled, but the incoming links are known, from crawling other pages. [sent-13, score-0.969]
</p><p>6 Using incoming links to rank a webpage is, of course, something which is already well-gamed by a lot of Internet spammers. [sent-14, score-0.687]
</p><p>7 Some of these bogus links come from other spammer websites, and some come from legitimate websites with reasonable content. [sent-15, score-0.464]
</p><p>8 Finding and ignoring bad links from legitimate websites is much more difficult, and often can't be done until many linked pages have been fully crawled. [sent-17, score-0.586]
</p><p>9 First, we have many things which we'd like to make unique counts of: the geographic diversity of incoming links, the network diversity of incoming links, and so forth. [sent-19, score-0.72]
</p><p>10 A page with a lot of incoming links is less interesting if all of the incoming links come from the same class-C IP network. [sent-20, score-1.135]
</p><p>11 We use the  logcount  combinator to count  these quantities efficiently (in both time and space -- 16 bytes per count), without double-counting anything as we crawl and recrawl the web. [sent-21, score-0.591]
</p><p>12 Next, we frequently need to manipulate the lists of outgoing and incoming links to a webpage. [sent-23, score-0.749]
</p><p>13 This is an expensive operation,  and since the number of inbound links can be large (millions, in many cases), we would need some sort of way of getting rid of less important (lower-ranked) rows in this table, in order to keep the table size reasonable. [sent-25, score-0.455]
</p><p>14 As an example of why we might want to manipulate this list of incoming webpages at crawl time, consider the fact that traded or purchased links often have identical  anchortext . [sent-28, score-1.294]
</p><p>15 By examining the incoming anchortext before crawling a page, we can avoid crawling it at all. [sent-29, score-0.939]
</p><p>16 All that other stuff   In addition to what we've discussed already -- finding outgoing links, and computing the ranks of uncrawled pages -- blekko's crawler does quite a bit of other work. [sent-33, score-0.589]
</p><p>17 ) The crawler also immediately updates a bunch of lists such as the list of domains using a given IP address, the list of domains using a given analytics or advertising ID, and the lists of checksums which drive our duplicate text discovery system. [sent-35, score-0.834]
</p><p>18 One important lesson is that it's critical to have an email address that webmasters can use to contact us privately if there's a crawler problem. [sent-37, score-0.659]
</p><p>19 We also found that a significant fraction of websites, including many US government websites, only allow a small whitelist of crawlers to crawl their pages. [sent-42, score-0.642]
</p><p>20 More and more of the web is hidden behind javascript, and while webmasters are somewhat careful to not hide their content where it can't be seen by most search engines, many webmasters do have an incentive to hide their analytics and advertising IDs so that they aren't as visible. [sent-45, score-0.829]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('crawl', 0.307), ('crawling', 0.296), ('links', 0.292), ('webmasters', 0.276), ('crawler', 0.272), ('blekko', 0.26), ('incoming', 0.236), ('crawlers', 0.225), ('webpages', 0.199), ('ranks', 0.117), ('anchortext', 0.111), ('logcount', 0.1), ('websites', 0.094), ('webpage', 0.09), ('frontier', 0.087), ('quantities', 0.082), ('counts', 0.081), ('crawled', 0.08), ('page', 0.079), ('legitimate', 0.078), ('manipulate', 0.076), ('outgoing', 0.073), ('list', 0.073), ('lists', 0.072), ('pages', 0.071), ('rank', 0.069), ('text', 0.067), ('measures', 0.066), ('link', 0.063), ('trading', 0.061), ('hide', 0.061), ('important', 0.06), ('fraction', 0.059), ('diversity', 0.058), ('index', 0.057), ('discussed', 0.056), ('web', 0.055), ('domains', 0.054), ('bytes', 0.053), ('table', 0.052), ('contact', 0.051), ('many', 0.051), ('rumored', 0.05), ('topn', 0.05), ('theprevious', 0.05), ('greg', 0.05), ('count', 0.049), ('advertising', 0.049), ('bunch', 0.048), ('newsthe', 0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="1253-tfidf-1" href="../high_scalability-2012/high_scalability-2012-05-28-The_Anatomy_of_Search_Technology%3A_Crawling_using_Combinators.html">1253 high scalability-2012-05-28-The Anatomy of Search Technology: Crawling using Combinators</a></p>
<p>Introduction: This is the second guest post ( part 1 ,  part 3 ) of a series by Greg Lindahl, CTO of blekko, the spam free search engine.  Previously, Greg was Founder and Distinguished Engineer at PathScale, at which he was the architect of the InfiniPath low-latency InfiniBand HCA, used to build tightly-coupled supercomputing clusters.  
  What's so hard about crawling the web?  
Web crawlers have been around as long as the Web has -- and before the web, there were crawlers for gopher and ftp. You would think that 25 years of experience would render crawling a solved problem, but the vast growth of the web and new inventions in the technology of webspam and other unsavory content results in a constant supply of new challenges. The general difficulty of tightly-coupled parallel programming also rears its head, as the web has scaled from millions to 100s of billions of pages.
  Existing Open-Source Crawlers and Crawls  
This article is mainly going to discuss blekko's crawler and its use of combinat</p><p>2 0.27762261 <a title="1253-tfidf-2" href="../high_scalability-2012/high_scalability-2012-04-25-The_Anatomy_of_Search_Technology%3A_blekko%E2%80%99s_NoSQL_database.html">1233 high scalability-2012-04-25-The Anatomy of Search Technology: blekko’s NoSQL database</a></p>
<p>Introduction: This is a guest post ( part 2 ,  part 3 ) by Greg Lindahl, CTO of blekko, the spam free search engine that had over 3.5 million unique visitors in March. Greg Lindahl was Founder and Distinguished Engineer at PathScale, at which he was the architect of the InfiniPath low-latency InfiniBand HCA, used to build tightly-coupled supercomputing clusters. 
 
Imagine that you're crazy enough to think about building a search engine.  It's a huge task: the minimum index size needed to answer most queries is a few billion webpages. Crawling and indexing a few billion webpages requires a cluster with several petabytes of usable disk -- that's several thousand 1 terabyte disks -- and produces an index that's about 100 terabytes in size.
 
Serving query results quickly involves having most of the index in RAM or on solid state (flash) disk. If you can buy a server with 100 gigabytes of RAM for about $3,000, that's 1,000 servers at a capital cost of $3 million, plus about $1 million per year of serve</p><p>3 0.14767541 <a title="1253-tfidf-3" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<p>Introduction: This is a guest post by Alberto Lopez Toledo, PHD, CTO of Pixable, and Julio Viera, VP of Engineering at Pixable. 
 
   Pixable  aggregates photos from across your different social networks and finds the best ones so you never miss an important moment. That means currently processing the metadata of more than 20 million new photos per day: crawling, analyzing, ranking, and sorting them along with the other 5+ billion that are already stored in our database. Making sense of all that data has challenges, but two in particular rise above the rest:
  
 How to access millions of photos per day from Facebook, Twitter, Instagram, and other services in the most efficient manner. 
 How to process, organize, index, and store all the meta-data related to those photos. 
  
Sure, Pixable’s infrastructure is changing continuously, but there are some things that we have learned over the last year. As a result, we have been able to build a scalable infrastructure that takes advantage of today’s tools,</p><p>4 0.12149394 <a title="1253-tfidf-4" href="../high_scalability-2010/high_scalability-2010-05-17-7_Lessons_Learned_While_Building_Reddit_to_270_Million_Page_Views_a_Month.html">828 high scalability-2010-05-17-7 Lessons Learned While Building Reddit to 270 Million Page Views a Month</a></p>
<p>Introduction: Steve Huffman , co-founder of social news site  Reddit , gave an excellent  presentation  ( slides ,  transcript ) on the lessons he learned while building and growing Reddit to 7.5 million users per month, 270 million page views per month, and 20+ database servers.
 
Steve says a lot of the lessons were really obvious, so you may not find a lot of completely new ideas in the presentation. But Steve has an earnestness and genuineness about him that is so obviously grounded in experience that you can't help but think deeply about what you could be doing different. And if Steve didn't know about these lessons, I'm betting others don't either.
 
There are seven lessons, each has their own summary section: Lesson one: Crash Often; Lesson 2: Separation of Services; Lesson 3: Open Schema; Lesson 4: Keep it Stateless; Lesson 5: Memcache; Lesson 6: Store Redundant Data; Lesson 7: Work Offline.
 
By far the most surprising feature of their architecture is in Lesson Six, whose essential idea is:</p><p>5 0.10891184 <a title="1253-tfidf-5" href="../high_scalability-2012/high_scalability-2012-06-20-iDoneThis_-_Scaling_an_Email-based_App_from_Scratch.html">1269 high scalability-2012-06-20-iDoneThis - Scaling an Email-based App from Scratch</a></p>
<p>Introduction: This is a guest post by Rodrigo Guzman, CTO of  iDoneThis , which makes status reporting happen at your company with the lightest possible touch. 
 
 iDoneThis  is a simple management application that emails your team at the end of every day to ask, "What'd you get done today?"  Just reply with a few lines of what you got done. The following morning everyone on your team gets a digest with what the team accomplished the previous day to keep everyone in the loop and kickstart another awesome day.
 
Before we launched, we built iDoneThis over a weekend in the most rudimentary way possible.  I kid you not, we sent the first few batches of daily emails using the BCC field of a Gmail inbox.  The upshot is that we’ve had users on the site from Day 3 of its existence on.
 
We’ve gone from launch in January 2011 when we sent hundreds of emails out per day by hand to sending out over 1 million emails and handling over 200,000 incoming emails per month.  In total, customers have recorded over 1.</p><p>6 0.1054178 <a title="1253-tfidf-6" href="../high_scalability-2007/high_scalability-2007-11-19-Tailrank_Architecture_-_Learn_How_to_Track_Memes_Across_the_Entire_Blogosphere.html">160 high scalability-2007-11-19-Tailrank Architecture - Learn How to Track Memes Across the Entire Blogosphere</a></p>
<p>7 0.10345107 <a title="1253-tfidf-7" href="../high_scalability-2010/high_scalability-2010-09-09-How_did_Google_Instant_become_Faster_with_5-7X_More_Results_Pages%3F.html">899 high scalability-2010-09-09-How did Google Instant become Faster with 5-7X More Results Pages?</a></p>
<p>8 0.10228054 <a title="1253-tfidf-8" href="../high_scalability-2009/high_scalability-2009-09-12-How_Google_Taught_Me_to_Cache_and_Cash-In.html">703 high scalability-2009-09-12-How Google Taught Me to Cache and Cash-In</a></p>
<p>9 0.095810488 <a title="1253-tfidf-9" href="../high_scalability-2014/high_scalability-2014-05-19-A_Short_On_How_the_Wayback_Machine_Stores_More_Pages_than_Stars_in_the_Milky_Way.html">1650 high scalability-2014-05-19-A Short On How the Wayback Machine Stores More Pages than Stars in the Milky Way</a></p>
<p>10 0.091560051 <a title="1253-tfidf-10" href="../high_scalability-2010/high_scalability-2010-03-26-Strategy%3A_Caching_404s_Saved_the_Onion_66%25_on_Server_Time.html">800 high scalability-2010-03-26-Strategy: Caching 404s Saved the Onion 66% on Server Time</a></p>
<p>11 0.083753273 <a title="1253-tfidf-11" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>12 0.083739683 <a title="1253-tfidf-12" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>13 0.083417632 <a title="1253-tfidf-13" href="../high_scalability-2013/high_scalability-2013-08-13-In_Memoriam%3A_Lavabit_Architecture_-_Creating_a_Scalable_Email_Service.html">1501 high scalability-2013-08-13-In Memoriam: Lavabit Architecture - Creating a Scalable Email Service</a></p>
<p>14 0.081500188 <a title="1253-tfidf-14" href="../high_scalability-2007/high_scalability-2007-07-06-Start_Here.html">1 high scalability-2007-07-06-Start Here</a></p>
<p>15 0.077914089 <a title="1253-tfidf-15" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>16 0.077127472 <a title="1253-tfidf-16" href="../high_scalability-2009/high_scalability-2009-11-26-Kngine_Snippet_Search_New_Indexing_Technology.html">746 high scalability-2009-11-26-Kngine Snippet Search New Indexing Technology</a></p>
<p>17 0.076791413 <a title="1253-tfidf-17" href="../high_scalability-2010/high_scalability-2010-04-14-Parallel_Information_Retrieval_and_Other_Search_Engine_Goodness.html">810 high scalability-2010-04-14-Parallel Information Retrieval and Other Search Engine Goodness</a></p>
<p>18 0.076281875 <a title="1253-tfidf-18" href="../high_scalability-2012/high_scalability-2012-07-09-Data_Replication_in_NoSQL_Databases.html">1279 high scalability-2012-07-09-Data Replication in NoSQL Databases</a></p>
<p>19 0.075594001 <a title="1253-tfidf-19" href="../high_scalability-2012/high_scalability-2012-11-15-Gone_Fishin%27%3A_Justin.Tv%27s_Live_Video_Broadcasting_Architecture.html">1359 high scalability-2012-11-15-Gone Fishin': Justin.Tv's Live Video Broadcasting Architecture</a></p>
<p>20 0.075512148 <a title="1253-tfidf-20" href="../high_scalability-2010/high_scalability-2010-03-16-Justin.tv%27s_Live_Video_Broadcasting_Architecture.html">796 high scalability-2010-03-16-Justin.tv's Live Video Broadcasting Architecture</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.141), (1, 0.062), (2, -0.02), (3, -0.029), (4, 0.016), (5, -0.017), (6, -0.039), (7, 0.023), (8, 0.012), (9, 0.024), (10, 0.003), (11, -0.018), (12, -0.018), (13, -0.012), (14, 0.047), (15, -0.015), (16, -0.061), (17, -0.005), (18, 0.042), (19, -0.01), (20, 0.023), (21, -0.034), (22, -0.001), (23, 0.034), (24, -0.017), (25, -0.038), (26, -0.032), (27, 0.06), (28, -0.029), (29, 0.028), (30, -0.05), (31, -0.001), (32, -0.049), (33, 0.036), (34, 0.035), (35, 0.008), (36, 0.027), (37, 0.034), (38, -0.005), (39, -0.03), (40, 0.055), (41, 0.015), (42, -0.003), (43, 0.02), (44, -0.001), (45, 0.071), (46, 0.027), (47, -0.025), (48, 0.024), (49, -0.012)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95314485 <a title="1253-lsi-1" href="../high_scalability-2012/high_scalability-2012-05-28-The_Anatomy_of_Search_Technology%3A_Crawling_using_Combinators.html">1253 high scalability-2012-05-28-The Anatomy of Search Technology: Crawling using Combinators</a></p>
<p>Introduction: This is the second guest post ( part 1 ,  part 3 ) of a series by Greg Lindahl, CTO of blekko, the spam free search engine.  Previously, Greg was Founder and Distinguished Engineer at PathScale, at which he was the architect of the InfiniPath low-latency InfiniBand HCA, used to build tightly-coupled supercomputing clusters.  
  What's so hard about crawling the web?  
Web crawlers have been around as long as the Web has -- and before the web, there were crawlers for gopher and ftp. You would think that 25 years of experience would render crawling a solved problem, but the vast growth of the web and new inventions in the technology of webspam and other unsavory content results in a constant supply of new challenges. The general difficulty of tightly-coupled parallel programming also rears its head, as the web has scaled from millions to 100s of billions of pages.
  Existing Open-Source Crawlers and Crawls  
This article is mainly going to discuss blekko's crawler and its use of combinat</p><p>2 0.81543595 <a title="1253-lsi-2" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>Introduction: This is an interview with  Gabriel Weinberg , founder of  Duck Duck Go  and general  all around startup guru , on what DDG’s architecture looks like in 2012. 
 
Innovative search engine upstart DuckDuckGo had   30 million searches   in February 2012 and averages over 1 million searches a day. It’s being positioned by   super investor Fred Wilson   as a clean, private, impartial and fast search engine. After talking with Gabriel I like what Fred Wilson said earlier, it seems closer to the heart of the matter:   We invested in DuckDuckGo for the Reddit, Hacker News anarchists  .                      Choosing DuckDuckGo can be thought of as not just a technical choice, but a vote for revolution. In an age when knowing your essence is not about about love or friendship, but about more effectively selling you to advertisers, DDG is positioning themselves as the   do not track alternative  , keepers of the  privacy flame . You will still be monetized of course, but in a more civilized and an</p><p>3 0.79205781 <a title="1253-lsi-3" href="../high_scalability-2008/high_scalability-2008-02-24-Yandex_Architecture.html">258 high scalability-2008-02-24-Yandex Architecture</a></p>
<p>Introduction: Update:   Anatomy of a crash in a new part of Yandex written in Django . Writing to a magic session variable caused an unexpected write into an InnoDB database on every request. Writes took 6-7 seconds because of index rebuilding. Lots of useful details on the sizing of their system, what went wrong, and how they fixed it.   Yandex is a Russian search engine with 3.5 billion pages in their search index. We only know a few fun facts about how they do things, nothing at a detailed architecture level. Hopefully we'll learn more later, but I thought it would still be interesting. From Allen Stern's interview with Yandex's CTO Ilya Segalovich, we learn:
   3.5 billion pages in the search index.    Over several thousand servers.    35 million searches a day.    Several data centers around Russia.    Two-layer architecture.    The database is split in pieces and when a search is requested, it pulls the bits from the different database servers and brings it together for the user.    Languages</p><p>4 0.77377462 <a title="1253-lsi-4" href="../high_scalability-2010/high_scalability-2010-09-09-How_did_Google_Instant_become_Faster_with_5-7X_More_Results_Pages%3F.html">899 high scalability-2010-09-09-How did Google Instant become Faster with 5-7X More Results Pages?</a></p>
<p>Introduction: We don't have a lot of details on how Google pulled off their technically very impressive Google Instant release, but in  Google Instant behind the scenes , they did share some interesting facts:
  
 Google was serving more than a billion searches per day. 
 With Google Instant they served 5-7X more results pages than previously. 
 Typical search results were returned in less than a quarter of second. 
 A team of 50+ worked on the project for an extended period of time. 
  
Although  Google  is associated with muscular data centers, they just didn't throw more server capacity at the problem, they worked smarter too. What were their general strategies?
  
 Increase backend server capacity. 
 Add new caches to handle high request rates while keeping results fresh while the web is continuously crawled and re-indexed. 
 Add User-state data to the back-ends to keep track of the results pages already shown to a given user, preventing the same results from being re-fetched repeatedly. 
 Optim</p><p>5 0.77101153 <a title="1253-lsi-5" href="../high_scalability-2009/high_scalability-2009-06-14-kngine_%27Knowledge_Engine%27_milestone_2.html">630 high scalability-2009-06-14-kngine 'Knowledge Engine' milestone 2</a></p>
<p>Introduction: Kngine is Knowledge Web search engine designed to provide meaningful search results, such as: semantic information about the keywords/concepts, answer the user’s questions, discover the relations between the keywords/concepts, and link the different kind of data together, such as: Movies, Subtitles, Photos, Price at sale store, User reviews, and Influenced story    Goals  
Kngine long-term goal is to make all human beings systematic knowledge and experience accessible to everyone. I aim to collect and organize all objective data, and make it possible and easy to access. Our goal is to build on the advances of Web search engine, semantic web, data representation technologies a new form of Web search engine that will unleash a revolution of new possibilities.  Kngine tries to combine the power of Web search engines with the power of Semantic search and the data representation to provide meaningful search results compromising user needs.
  Status  
Kngine starts as a research project in O</p><p>6 0.7644732 <a title="1253-lsi-6" href="../high_scalability-2008/high_scalability-2008-06-08-Search_fast_in_million_rows.html">342 high scalability-2008-06-08-Search fast in million rows</a></p>
<p>7 0.76181352 <a title="1253-lsi-7" href="../high_scalability-2014/high_scalability-2014-02-25-Peter_Norvig%27s_9_Master_Steps_to_Improving_a_Program.html">1601 high scalability-2014-02-25-Peter Norvig's 9 Master Steps to Improving a Program</a></p>
<p>8 0.75524366 <a title="1253-lsi-8" href="../high_scalability-2009/high_scalability-2009-11-26-Kngine_Snippet_Search_New_Indexing_Technology.html">746 high scalability-2009-11-26-Kngine Snippet Search New Indexing Technology</a></p>
<p>9 0.75152773 <a title="1253-lsi-9" href="../high_scalability-2014/high_scalability-2014-05-19-A_Short_On_How_the_Wayback_Machine_Stores_More_Pages_than_Stars_in_the_Milky_Way.html">1650 high scalability-2014-05-19-A Short On How the Wayback Machine Stores More Pages than Stars in the Milky Way</a></p>
<p>10 0.73507631 <a title="1253-lsi-10" href="../high_scalability-2008/high_scalability-2008-05-28-Job_queue_and_search_engine.html">332 high scalability-2008-05-28-Job queue and search engine</a></p>
<p>11 0.71605223 <a title="1253-lsi-11" href="../high_scalability-2008/high_scalability-2008-02-12-Search_the_tags_across_all_post.html">246 high scalability-2008-02-12-Search the tags across all post</a></p>
<p>12 0.71598011 <a title="1253-lsi-12" href="../high_scalability-2012/high_scalability-2012-04-25-The_Anatomy_of_Search_Technology%3A_blekko%E2%80%99s_NoSQL_database.html">1233 high scalability-2012-04-25-The Anatomy of Search Technology: blekko’s NoSQL database</a></p>
<p>13 0.70508367 <a title="1253-lsi-13" href="../high_scalability-2008/high_scalability-2008-08-16-Strategy%3A_Serve_Pre-generated_Static_Files_Instead_Of_Dynamic_Pages.html">365 high scalability-2008-08-16-Strategy: Serve Pre-generated Static Files Instead Of Dynamic Pages</a></p>
<p>14 0.7009598 <a title="1253-lsi-14" href="../high_scalability-2010/high_scalability-2010-04-14-Parallel_Information_Retrieval_and_Other_Search_Engine_Goodness.html">810 high scalability-2010-04-14-Parallel Information Retrieval and Other Search Engine Goodness</a></p>
<p>15 0.70035547 <a title="1253-lsi-15" href="../high_scalability-2014/high_scalability-2014-03-10-Let%27s_Play_a_Game_of_Take_It_or_Leave_It__-_Game_1.html">1608 high scalability-2014-03-10-Let's Play a Game of Take It or Leave It  - Game 1</a></p>
<p>16 0.69793242 <a title="1253-lsi-16" href="../high_scalability-2010/high_scalability-2010-09-11-Google%27s_Colossus_Makes_Search_Real-time_by_Dumping_MapReduce.html">900 high scalability-2010-09-11-Google's Colossus Makes Search Real-time by Dumping MapReduce</a></p>
<p>17 0.68666172 <a title="1253-lsi-17" href="../high_scalability-2008/high_scalability-2008-01-04-For_%245_Million_You_Can_Buy_Enough_Storage_to_Compete_with_Google.html">201 high scalability-2008-01-04-For $5 Million You Can Buy Enough Storage to Compete with Google</a></p>
<p>18 0.68605804 <a title="1253-lsi-18" href="../high_scalability-2008/high_scalability-2008-12-05-Scalability_Perspectives_%234%3A_Kevin_Kelly_%E2%80%93_One_Machine.html">460 high scalability-2008-12-05-Scalability Perspectives #4: Kevin Kelly – One Machine</a></p>
<p>19 0.67045271 <a title="1253-lsi-19" href="../high_scalability-2010/high_scalability-2010-03-26-Strategy%3A_Caching_404s_Saved_the_Onion_66%25_on_Server_Time.html">800 high scalability-2010-03-26-Strategy: Caching 404s Saved the Onion 66% on Server Time</a></p>
<p>20 0.66645813 <a title="1253-lsi-20" href="../high_scalability-2011/high_scalability-2011-09-26-17_Techniques_Used_to_Scale_Turntable.fm_and_Labmeeting_to_Millions_of_Users.html">1124 high scalability-2011-09-26-17 Techniques Used to Scale Turntable.fm and Labmeeting to Millions of Users</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.141), (2, 0.155), (10, 0.02), (14, 0.201), (30, 0.042), (47, 0.013), (56, 0.028), (61, 0.113), (77, 0.016), (79, 0.046), (85, 0.02), (93, 0.031), (94, 0.085)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.90777427 <a title="1253-lda-1" href="../high_scalability-2008/high_scalability-2008-10-07-Help_a_Scoble_out._What_should_Robert_ask_in_his_scalability_interview%3F.html">405 high scalability-2008-10-07-Help a Scoble out. What should Robert ask in his scalability interview?</a></p>
<p>Introduction: One of the cool things about Mr. Scoble is he doesn't pretend to know everything, which can be an deadly boring affliction in this field. In this case Robert is asking for help in an upcoming interview. Maybe we can help? Here's Robert's plight:     I’m really freaked out. I have one of the biggest interviews of my life coming up and I’m way under qualified to host it.  It’s on Thursday and it’s about Scalability and Performance of Web Services.  Look at who will be on. Matt Mullenweg, founder of Automattic, the company behind WordPress (and behind this blog). Paul Bucheit, one of the founders of FriendFeed and the creator of Gmail (he’s also the guy who gave Google the “don’t be evil” admonishion). Nat Brown, CTO of iLike, which got six million users on Facebook in about 10 days.       What would you ask?</p><p>same-blog 2 0.89604533 <a title="1253-lda-2" href="../high_scalability-2012/high_scalability-2012-05-28-The_Anatomy_of_Search_Technology%3A_Crawling_using_Combinators.html">1253 high scalability-2012-05-28-The Anatomy of Search Technology: Crawling using Combinators</a></p>
<p>Introduction: This is the second guest post ( part 1 ,  part 3 ) of a series by Greg Lindahl, CTO of blekko, the spam free search engine.  Previously, Greg was Founder and Distinguished Engineer at PathScale, at which he was the architect of the InfiniPath low-latency InfiniBand HCA, used to build tightly-coupled supercomputing clusters.  
  What's so hard about crawling the web?  
Web crawlers have been around as long as the Web has -- and before the web, there were crawlers for gopher and ftp. You would think that 25 years of experience would render crawling a solved problem, but the vast growth of the web and new inventions in the technology of webspam and other unsavory content results in a constant supply of new challenges. The general difficulty of tightly-coupled parallel programming also rears its head, as the web has scaled from millions to 100s of billions of pages.
  Existing Open-Source Crawlers and Crawls  
This article is mainly going to discuss blekko's crawler and its use of combinat</p><p>3 0.88368803 <a title="1253-lda-3" href="../high_scalability-2011/high_scalability-2011-02-01-Google_Strategy%3A_Tree_Distribution_of_Requests_and_Responses.html">981 high scalability-2011-02-01-Google Strategy: Tree Distribution of Requests and Responses</a></p>
<p>Introduction: If a large number of leaf node machines send requests to a central root node then that root node can become overwhelmed:
  
 The CPU becomes a bottleneck, for either processing requests or sending replies, because it can't possibly deal with the flood of requests. 
 The network interface becomes a bottleneck because a wide fan-in causes TCP drops and retransmissions, which causes latency. Then clients start retrying requests which quickly causes a spiral of death in an undisciplined system. 
  
One solution to this problem is a strategy given by Dr.  Jeff Dean , Head of Google's School of Infrastructure Wizardry, in this  Stanford video presentation :  Tree Distribution of Requests and Responses .
 
 
 
Instead of having a root node connected to leaves in a flat topology, the idea is to create a tree of nodes. So a root node talks to a number of parent nodes and the parent nodes talk to a number of leaf nodes. Requests are pushed down the tree through the parents and only hit a subset</p><p>4 0.86961406 <a title="1253-lda-4" href="../high_scalability-2009/high_scalability-2009-10-21-Manage_virtualized_sprawl_with_VRMs.html">725 high scalability-2009-10-21-Manage virtualized sprawl with VRMs</a></p>
<p>Introduction: The essence of my work is coming into daily contact with innovative technologies. A recent example was at the request of a partner company who wanted to answer- which one of these tools will best solve my virtualized datacenter headache? After initial analysis all the products could be classified as tools that troubleshoot VM sprawl, but there was no universally accepted term for them. The most descriptive term  that I found was Virtual Resource Manager (VRM) from  DynamicOps . As I delved deeper into their workings, the distinction between VRMs and Private Clouds became blurred. What are the differences?
 
Read more at:  http://bigdatamatters.com/bigdatamatters/2009/10/cloud-vs-vrm.html</p><p>5 0.84812796 <a title="1253-lda-5" href="../high_scalability-2009/high_scalability-2009-03-12-QCon_London_2009%3A_Database_projects_to_watch_closely.html">537 high scalability-2009-03-12-QCon London 2009: Database projects to watch closely</a></p>
<p>Introduction: Geir Magnusson from 10gen presented a talk titled Cloud Data Persistence or ‘We’re in a database reneaissance - pay attention” today at QCon London 2009. The main message of his talk was that “physical limitations of today’s technology combined with the computational complexity of conventional relational databases are driving databases into new exciting spaces”, or to put it simpler the database landscape is changing and we should keep our eyes on that.</p><p>6 0.84372586 <a title="1253-lda-6" href="../high_scalability-2009/high_scalability-2009-09-04-Hot_Links_for_2009-9-4_.html">694 high scalability-2009-09-04-Hot Links for 2009-9-4 </a></p>
<p>7 0.83129889 <a title="1253-lda-7" href="../high_scalability-2008/high_scalability-2008-11-13-CloudCamp_London_2%3A_private_clouds_and_standardisation.html">441 high scalability-2008-11-13-CloudCamp London 2: private clouds and standardisation</a></p>
<p>8 0.81492817 <a title="1253-lda-8" href="../high_scalability-2009/high_scalability-2009-01-17-Intro_to_Caching%2CCaching_algorithms_and_caching_frameworks_part_1.html">495 high scalability-2009-01-17-Intro to Caching,Caching algorithms and caching frameworks part 1</a></p>
<p>9 0.79703575 <a title="1253-lda-9" href="../high_scalability-2007/high_scalability-2007-10-21-Paper%3A_Standardizing_Storage_Clusters_%28with_pNFS%29.html">128 high scalability-2007-10-21-Paper: Standardizing Storage Clusters (with pNFS)</a></p>
<p>10 0.79049355 <a title="1253-lda-10" href="../high_scalability-2009/high_scalability-2009-01-08-Paper%3A_Sharding_with_Oracle_Database.html">487 high scalability-2009-01-08-Paper: Sharding with Oracle Database</a></p>
<p>11 0.7875368 <a title="1253-lda-11" href="../high_scalability-2012/high_scalability-2012-07-06-Stuff_The_Internet_Says_On_Scalability_For_July_6%2C_2012.html">1278 high scalability-2012-07-06-Stuff The Internet Says On Scalability For July 6, 2012</a></p>
<p>12 0.77926731 <a title="1253-lda-12" href="../high_scalability-2009/high_scalability-2009-11-24-Hot_Scalability_Links_for_Nov_24_2009.html">744 high scalability-2009-11-24-Hot Scalability Links for Nov 24 2009</a></p>
<p>13 0.76627886 <a title="1253-lda-13" href="../high_scalability-2010/high_scalability-2010-11-17-Some_Services_are_More_Equal_than_Others.html">944 high scalability-2010-11-17-Some Services are More Equal than Others</a></p>
<p>14 0.75945032 <a title="1253-lda-14" href="../high_scalability-2009/high_scalability-2009-05-14-Who_Has_the_Most_Web_Servers%3F.html">599 high scalability-2009-05-14-Who Has the Most Web Servers?</a></p>
<p>15 0.75795829 <a title="1253-lda-15" href="../high_scalability-2010/high_scalability-2010-02-10-ElasticSearch_-_Open_Source%2C_Distributed%2C_RESTful_Search_Engine.html">775 high scalability-2010-02-10-ElasticSearch - Open Source, Distributed, RESTful Search Engine</a></p>
<p>16 0.75528741 <a title="1253-lda-16" href="../high_scalability-2010/high_scalability-2010-07-12-Creating_Scalable_Digital_Libraries.html">856 high scalability-2010-07-12-Creating Scalable Digital Libraries</a></p>
<p>17 0.75492918 <a title="1253-lda-17" href="../high_scalability-2010/high_scalability-2010-03-03-Hot_Scalability_Links_for_March_3%2C_2010.html">787 high scalability-2010-03-03-Hot Scalability Links for March 3, 2010</a></p>
<p>18 0.75342423 <a title="1253-lda-18" href="../high_scalability-2012/high_scalability-2012-07-23-State_of_the_CDN%3A_More_Traffic%2C_Stable_Prices%2C_More_Products%2C_Profits_-_Not_So_Much.html">1289 high scalability-2012-07-23-State of the CDN: More Traffic, Stable Prices, More Products, Profits - Not So Much</a></p>
<p>19 0.75318599 <a title="1253-lda-19" href="../high_scalability-2010/high_scalability-2010-10-28-Notes_from_A_NOSQL_Evening_in_Palo_Alto_.html">931 high scalability-2010-10-28-Notes from A NOSQL Evening in Palo Alto </a></p>
<p>20 0.75292706 <a title="1253-lda-20" href="../high_scalability-2011/high_scalability-2011-01-20-75%25_Chance_of_Scale_-_Leveraging_the_New_Scaleogenic_Environment_for_Growth.html">976 high scalability-2011-01-20-75% Chance of Scale - Leveraging the New Scaleogenic Environment for Growth</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
