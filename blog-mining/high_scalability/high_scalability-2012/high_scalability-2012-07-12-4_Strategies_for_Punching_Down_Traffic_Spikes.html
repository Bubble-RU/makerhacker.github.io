<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1282 high scalability-2012-07-12-4 Strategies for Punching Down Traffic Spikes</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2012" href="../home/high_scalability-2012_home.html">high_scalability-2012</a> <a title="high_scalability-2012-1282" href="#">high_scalability-2012-1282</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1282 high scalability-2012-07-12-4 Strategies for Punching Down Traffic Spikes</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2012-1282-html" href="http://highscalability.com//blog/2012/7/12/4-strategies-for-punching-down-traffic-spikes.html">html</a></p><p>Introduction: Travis Reeder inSpikability - An Application's Ability to Handle Unknown
and/or Inconsistent Load gives four good ways of handling spikey loads:Have
more resources than you'll ever need. Estimate the maximum traffic you'll need
and keep that many servers running. Downside is you are paying for capacity
you aren't using.Disable features during high loads. Reduce load by disabling
features or substituting in lighter weight features. Downside is users to have
access to features.Auto scaling. Launch new servers in response to load.
Downsides are it's complicated to setup and slow to respond. Random spikes
will cause cycling of instances going up and down.Use message queues. Queues
soak up work requests during traffic spikes. More servers can be started to
process work from the queue. Resources aren't wasted and features are
disabled. Downside is increased latency.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('downside', 0.42), ('cycling', 0.233), ('travis', 0.233), ('spikey', 0.222), ('substituting', 0.222), ('disabling', 0.214), ('soak', 0.202), ('lighter', 0.197), ('wasted', 0.188), ('downsides', 0.185), ('inconsistent', 0.176), ('features', 0.163), ('unknown', 0.163), ('weight', 0.15), ('estimate', 0.15), ('resources', 0.134), ('spikes', 0.129), ('paying', 0.126), ('traffic', 0.121), ('launch', 0.117)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1282-tfidf-1" href="../high_scalability-2012/high_scalability-2012-07-12-4_Strategies_for_Punching_Down_Traffic_Spikes.html">1282 high scalability-2012-07-12-4 Strategies for Punching Down Traffic Spikes</a></p>
<p>Introduction: Travis Reeder inSpikability - An Application's Ability to Handle Unknown
and/or Inconsistent Load gives four good ways of handling spikey loads:Have
more resources than you'll ever need. Estimate the maximum traffic you'll need
and keep that many servers running. Downside is you are paying for capacity
you aren't using.Disable features during high loads. Reduce load by disabling
features or substituting in lighter weight features. Downside is users to have
access to features.Auto scaling. Launch new servers in response to load.
Downsides are it's complicated to setup and slow to respond. Random spikes
will cause cycling of instances going up and down.Use message queues. Queues
soak up work requests during traffic spikes. More servers can be started to
process work from the queue. Resources aren't wasted and features are
disabled. Downside is increased latency.</p><p>2 0.14890954 <a title="1282-tfidf-2" href="../high_scalability-2012/high_scalability-2012-09-19-The_4_Building_Blocks_of_Architecting_Systems_for_Scale.html">1325 high scalability-2012-09-19-The 4 Building Blocks of Architecting Systems for Scale</a></p>
<p>Introduction: If you are looking for an excellent overview of general architecture
principles then take a look at Will Larson's Introduction to Architecting
Systems for Scale. Based on his experiences at Yahoo! and Digg, Will covers
key concepts in some depth. A quick gloss on the building blocks:Load
Balancing: Scalability & Redundancy.Horizontal scalability and redundancy are
usually achieved via load balancing, the spreading of requests across multiple
resources.Smart Clients.The client has a list of hosts and load balances
across that list of hosts. Upside is simple for programmers. Downside is it's
hard to update and change.Hardware Load Balancers.Targeted at larger
companies, this is dedicated load balancing hardware. Upside is performance.
Downside is cost and complexity.Software Load Balancers.The recommended
approach, it's  software that handles load balancing, health checks,
etc.Caching.Make better use of resources you already have. Precalculate
results for later use. Application Versus Da</p><p>3 0.11405331 <a title="1282-tfidf-3" href="../high_scalability-2009/high_scalability-2009-03-11-The_Implications_of_Punctuated_Scalabilium_for_Website_Architecture.html">533 high scalability-2009-03-11-The Implications of Punctuated Scalabilium for Website Architecture</a></p>
<p>Introduction: Update:How do you design and handle peak load on the Cloud?by Cloudiquity.
Gives a formula to try and predict and plan for peak load and talks about how
GigaSpaces XAP, Scalr, RightScale and FreedomOSS can be used to handle peak
load within EC2.Theo Schlossnagle, with his usual insight, talks about
inDissecting today's surgeshow the nature of internet traffic has evolved over
time. Traffic now spikes like a heart attack, larger and more quickly than
ever from traffic inflow sources like Digg and The New York Times. Theo
relates howAt least eight times in the past month, we've experienced from 100%
to 1000% sudden increases in traffic across many of our clientsand those spike
can happen as quickly as 60 seconds. To me this sounds a lot likePunctuated
equilibriumin evolution, a force that accounts for much creative growth in
species...breakVMs don't spin up in less than 60 seconds so your ability to
respond to such massive quick spikes is limited. This assumes of course that
you've creat</p><p>4 0.10623845 <a title="1282-tfidf-4" href="../high_scalability-2013/high_scalability-2013-04-10-Check_Yourself_Before_You_Wreck_Yourself_-_Avocado%27s_5_Early_Stages_of_Architecture_Evolution.html">1438 high scalability-2013-04-10-Check Yourself Before You Wreck Yourself - Avocado's 5 Early Stages of Architecture Evolution</a></p>
<p>Introduction: In Don't panic! Here's how to quickly scale your mobile apps Mike
Maelzerpaints a wonderful picture of howAvocado, a mobile app for connecting
couples, evolved to handle 30x traffic within a few weeks. If you are just
getting started then this is a great example to learn from.What I liked: it's
well written, packing a lot of useful information in a little space; it's
failure driven, showing the process of incremental change driven by purposeful
testing and production experience; it shows awareness of what's important, in
their case, user signup; a replica setup was used for testing, a nice cloud
benefit. Their Biggest lesson learned is a good one:It would have been great
to start the scaling process much earlier. Due to time pressure we had to make
compromises -like dropping four of our media resizer boxes. While throwing
more hardware at some scaling problems does work, it's less than ideal.Here's
my gloss on the article:Evolution One - Make it WorkWhen just starting you
just want to</p><p>5 0.10562833 <a title="1282-tfidf-5" href="../high_scalability-2009/high_scalability-2009-06-29-How_to_Succeed_at_Capacity_Planning_Without_Really_Trying_%3A__An_Interview_with_Flickr%27s_John_Allspaw_on_His_New_Book.html">643 high scalability-2009-06-29-How to Succeed at Capacity Planning Without Really Trying :  An Interview with Flickr's John Allspaw on His New Book</a></p>
<p>Introduction: Update 2:Velocity 09: John Allspaw, 10+ Deploys Per Day: Dev and Ops
Cooperation at Flickr. Insightful talk. Some highlights: Change is good if you
can build tools and culture to lower the risk of change. Operations and
developers need to become of one mind and respect each other. An automated
infrastructure is the one tool you need most. Common source control. One step
build. One step deploy. Don't be a pussy, deploy. Always ship trunk. Feature
flags - don't branch code, make features runtime configurable in code. Dark
launch - release data paths early without UI component. Shared metrics.
Adaptive feedback to prioritize important features. IRC for communication for
human context. Best solutions occur when dev and op work together and trust
each other. Trust is earned by helping each other solve their problems. Look
at what new features imply for operations, what can go wrong, and how to
recover. Provide knobs and levers to help operations. Devs should have access
to production machin</p><p>6 0.096449032 <a title="1282-tfidf-6" href="../high_scalability-2013/high_scalability-2013-03-13-Iron.io_Moved_From_Ruby_to_Go%3A_28_Servers_Cut_and_Colossal_Clusterf%2A%2Aks_Prevented.html">1423 high scalability-2013-03-13-Iron.io Moved From Ruby to Go: 28 Servers Cut and Colossal Clusterf**ks Prevented</a></p>
<p>7 0.093895636 <a title="1282-tfidf-7" href="../high_scalability-2012/high_scalability-2012-12-17-11_Uses_For_the_Humble_Presents_Queue%2C_er%2C_Message_Queue.html">1373 high scalability-2012-12-17-11 Uses For the Humble Presents Queue, er, Message Queue</a></p>
<p>8 0.092396334 <a title="1282-tfidf-8" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>9 0.086590663 <a title="1282-tfidf-9" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>10 0.082577333 <a title="1282-tfidf-10" href="../high_scalability-2010/high_scalability-2010-03-04-How_MySpace_Tested_Their_Live_Site_with_1_Million_Concurrent_Users.html">788 high scalability-2010-03-04-How MySpace Tested Their Live Site with 1 Million Concurrent Users</a></p>
<p>11 0.080673762 <a title="1282-tfidf-11" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>12 0.076792233 <a title="1282-tfidf-12" href="../high_scalability-2013/high_scalability-2013-03-11-Low_Level_Scalability_Solutions_-_The_Conditioning_Collection.html">1421 high scalability-2013-03-11-Low Level Scalability Solutions - The Conditioning Collection</a></p>
<p>13 0.076482028 <a title="1282-tfidf-13" href="../high_scalability-2008/high_scalability-2008-06-06-Economies_of_Non-Scale.html">340 high scalability-2008-06-06-Economies of Non-Scale</a></p>
<p>14 0.072537839 <a title="1282-tfidf-14" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>15 0.070103243 <a title="1282-tfidf-15" href="../high_scalability-2013/high_scalability-2013-03-06-Low_Level_Scalability_Solutions_-_The_Aggregation_Collection.html">1418 high scalability-2013-03-06-Low Level Scalability Solutions - The Aggregation Collection</a></p>
<p>16 0.069776773 <a title="1282-tfidf-16" href="../high_scalability-2008/high_scalability-2008-10-08-Strategy%3A_Flickr_-_Do_the_Essential_Work_Up-front_and_Queue_the_Rest_.html">406 high scalability-2008-10-08-Strategy: Flickr - Do the Essential Work Up-front and Queue the Rest </a></p>
<p>17 0.068506561 <a title="1282-tfidf-17" href="../high_scalability-2013/high_scalability-2013-03-18-Beyond_Threads_and_Callbacks_-_Application_Architecture_Pros_and_Cons.html">1425 high scalability-2013-03-18-Beyond Threads and Callbacks - Application Architecture Pros and Cons</a></p>
<p>18 0.068085141 <a title="1282-tfidf-18" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>19 0.067943156 <a title="1282-tfidf-19" href="../high_scalability-2011/high_scalability-2011-09-07-What_Google_App_Engine_Price_Changes_Say_About_the_Future_of_Web_Architecture.html">1112 high scalability-2011-09-07-What Google App Engine Price Changes Say About the Future of Web Architecture</a></p>
<p>20 0.067719333 <a title="1282-tfidf-20" href="../high_scalability-2010/high_scalability-2010-04-19-Strategy%3A_Order_Two_Mediums_Instead_of_Two_Smalls_and_the_EC2_Buffet.html">812 high scalability-2010-04-19-Strategy: Order Two Mediums Instead of Two Smalls and the EC2 Buffet</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.104), (1, 0.062), (2, -0.012), (3, -0.066), (4, -0.039), (5, -0.051), (6, 0.05), (7, -0.003), (8, -0.044), (9, -0.06), (10, -0.001), (11, 0.016), (12, -0.006), (13, -0.008), (14, -0.025), (15, -0.01), (16, 0.036), (17, 0.009), (18, -0.025), (19, 0.03), (20, -0.0), (21, 0.005), (22, 0.005), (23, -0.05), (24, 0.02), (25, 0.018), (26, -0.007), (27, 0.07), (28, -0.01), (29, -0.042), (30, 0.03), (31, 0.022), (32, 0.007), (33, 0.044), (34, -0.0), (35, -0.016), (36, -0.048), (37, -0.039), (38, -0.043), (39, -0.052), (40, 0.017), (41, -0.024), (42, 0.017), (43, 0.014), (44, -0.073), (45, -0.018), (46, 0.014), (47, -0.006), (48, 0.017), (49, 0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9669711 <a title="1282-lsi-1" href="../high_scalability-2012/high_scalability-2012-07-12-4_Strategies_for_Punching_Down_Traffic_Spikes.html">1282 high scalability-2012-07-12-4 Strategies for Punching Down Traffic Spikes</a></p>
<p>Introduction: Travis Reeder inSpikability - An Application's Ability to Handle Unknown
and/or Inconsistent Load gives four good ways of handling spikey loads:Have
more resources than you'll ever need. Estimate the maximum traffic you'll need
and keep that many servers running. Downside is you are paying for capacity
you aren't using.Disable features during high loads. Reduce load by disabling
features or substituting in lighter weight features. Downside is users to have
access to features.Auto scaling. Launch new servers in response to load.
Downsides are it's complicated to setup and slow to respond. Random spikes
will cause cycling of instances going up and down.Use message queues. Queues
soak up work requests during traffic spikes. More servers can be started to
process work from the queue. Resources aren't wasted and features are
disabled. Downside is increased latency.</p><p>2 0.73560959 <a title="1282-lsi-2" href="../high_scalability-2009/high_scalability-2009-03-11-The_Implications_of_Punctuated_Scalabilium_for_Website_Architecture.html">533 high scalability-2009-03-11-The Implications of Punctuated Scalabilium for Website Architecture</a></p>
<p>Introduction: Update:How do you design and handle peak load on the Cloud?by Cloudiquity.
Gives a formula to try and predict and plan for peak load and talks about how
GigaSpaces XAP, Scalr, RightScale and FreedomOSS can be used to handle peak
load within EC2.Theo Schlossnagle, with his usual insight, talks about
inDissecting today's surgeshow the nature of internet traffic has evolved over
time. Traffic now spikes like a heart attack, larger and more quickly than
ever from traffic inflow sources like Digg and The New York Times. Theo
relates howAt least eight times in the past month, we've experienced from 100%
to 1000% sudden increases in traffic across many of our clientsand those spike
can happen as quickly as 60 seconds. To me this sounds a lot likePunctuated
equilibriumin evolution, a force that accounts for much creative growth in
species...breakVMs don't spin up in less than 60 seconds so your ability to
respond to such massive quick spikes is limited. This assumes of course that
you've creat</p><p>3 0.72255814 <a title="1282-lsi-3" href="../high_scalability-2010/high_scalability-2010-02-05-High_Availability_Principle_%3A_Concurrency_Control.html">772 high scalability-2010-02-05-High Availability Principle : Concurrency Control</a></p>
<p>Introduction: One important high availability principle is concurrency control.  The idea is
to allow only that much traffic through to your system which your system can
handle successfully.  For example: if your system is certified to handle a
concurrency of 100 then the 101st request should either timeout, be asked to
try later  or wait until one of the previous 100 requests finish.  The 101st
request should not be allowed to negatively impact the experience of the other
100 users.  Only the 101st request should be impacted.Read more here...</p><p>4 0.69282949 <a title="1282-lsi-4" href="../high_scalability-2013/high_scalability-2013-03-11-Low_Level_Scalability_Solutions_-_The_Conditioning_Collection.html">1421 high scalability-2013-03-11-Low Level Scalability Solutions - The Conditioning Collection</a></p>
<p>Introduction: We talked about 42 Monster Problems That Attack As Loads Increase. And inThe
Aggregation Collection we talked about the value of prioritizing work and
making smart queues as a way of absorbing and not reflecting traffic
spikes.Now we move on to our next batch of strategies where the theme
isconditioning, which is the idea of shaping and controlling flows of work
within your application...Use Resources Proportional To a Fixed LimitThis is
probably the most important rule for achieving scalability within an
application. What it means:Find the resource that has a fixed limit that you
know you can support. For example, a guarantee to handle a certain number of
objects in memory. So if we always use resources proportional to the number of
objects it is likely we can prevent resource exhaustion.Devise ways of tying
what you need to do to the individual resources.Some examples:Keep a list of
purchase orders with line items over $20 (or whatever). Do not keep a list of
the line items because t</p><p>5 0.68437701 <a title="1282-lsi-5" href="../high_scalability-2013/high_scalability-2013-03-13-Iron.io_Moved_From_Ruby_to_Go%3A_28_Servers_Cut_and_Colossal_Clusterf%2A%2Aks_Prevented.html">1423 high scalability-2013-03-13-Iron.io Moved From Ruby to Go: 28 Servers Cut and Colossal Clusterf**ks Prevented</a></p>
<p>Introduction: For the last few months I've been programming a system in Go, so I'm always on
the lookout for information to feed my confirmation bias. An opportunity
popped up when Iron.io wrote about theirexperience using Go to rewrite
IronWorker, their ever busy job execution system, originally coded in Ruby.The
result:Dropped from 30 to 2 servers and the second server was used only for
redundancy.CPU utilization dropped to less than 5%.Memory usage dropped. Only
a "few hundred KB's of memory (on startup) vs our Rails apps which were ~50MB
(on startup)". Cascading failures are now a thing of the past.New services
running on hundreds of servers are all written in Go.They believe using Go
allows them to "build great products, to grow and scale, and attract grade A
talent. And I believe it will continue to help us grow for the foreseeable
future." Picking a language based on the size of the talent pool is a common
recommendation, they've found selecting Go helps them attract top
talent.Deployment is</p><p>6 0.66436619 <a title="1282-lsi-6" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>7 0.65752387 <a title="1282-lsi-7" href="../high_scalability-2008/high_scalability-2008-03-14-Problem%3A_Mobbing_the_Least_Used_Resource_Error.html">275 high scalability-2008-03-14-Problem: Mobbing the Least Used Resource Error</a></p>
<p>8 0.65630543 <a title="1282-lsi-8" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>9 0.65592933 <a title="1282-lsi-9" href="../high_scalability-2008/high_scalability-2008-10-08-Strategy%3A_Flickr_-_Do_the_Essential_Work_Up-front_and_Queue_the_Rest_.html">406 high scalability-2008-10-08-Strategy: Flickr - Do the Essential Work Up-front and Queue the Rest </a></p>
<p>10 0.65213954 <a title="1282-lsi-10" href="../high_scalability-2013/high_scalability-2013-03-04-7_Life_Saving_Scalability_Defenses_Against_Load_Monster_Attacks.html">1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</a></p>
<p>11 0.6483115 <a title="1282-lsi-11" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>12 0.64261955 <a title="1282-lsi-12" href="../high_scalability-2014/high_scalability-2014-03-31-How_WhatsApp_Grew_to_Nearly_500_Million_Users%2C_11%2C000_cores%2C_and_70_Million_Messages_a_Second.html">1622 high scalability-2014-03-31-How WhatsApp Grew to Nearly 500 Million Users, 11,000 cores, and 70 Million Messages a Second</a></p>
<p>13 0.64195883 <a title="1282-lsi-13" href="../high_scalability-2013/high_scalability-2013-04-10-Check_Yourself_Before_You_Wreck_Yourself_-_Avocado%27s_5_Early_Stages_of_Architecture_Evolution.html">1438 high scalability-2013-04-10-Check Yourself Before You Wreck Yourself - Avocado's 5 Early Stages of Architecture Evolution</a></p>
<p>14 0.63891065 <a title="1282-lsi-14" href="../high_scalability-2008/high_scalability-2008-02-16-S3_Failed_Because_of_Authentication_Overload.html">249 high scalability-2008-02-16-S3 Failed Because of Authentication Overload</a></p>
<p>15 0.63797563 <a title="1282-lsi-15" href="../high_scalability-2012/high_scalability-2012-06-07-Case_Study_on_Scaling_PaaS_infrastructure_.html">1260 high scalability-2012-06-07-Case Study on Scaling PaaS infrastructure </a></p>
<p>16 0.63180971 <a title="1282-lsi-16" href="../high_scalability-2013/high_scalability-2013-02-06-Super_Bowl_Advertisers_Ready_for_the_Traffic%3F_Nope..It%27s_Lights_Out..html">1401 high scalability-2013-02-06-Super Bowl Advertisers Ready for the Traffic? Nope..It's Lights Out.</a></p>
<p>17 0.62923622 <a title="1282-lsi-17" href="../high_scalability-2013/high_scalability-2013-03-06-Low_Level_Scalability_Solutions_-_The_Aggregation_Collection.html">1418 high scalability-2013-03-06-Low Level Scalability Solutions - The Aggregation Collection</a></p>
<p>18 0.62817788 <a title="1282-lsi-18" href="../high_scalability-2011/high_scalability-2011-12-28-Strategy%3A_Guaranteed_Availability_Requires_Reserving_Instances_in_Specific_Zones.html">1165 high scalability-2011-12-28-Strategy: Guaranteed Availability Requires Reserving Instances in Specific Zones</a></p>
<p>19 0.61962527 <a title="1282-lsi-19" href="../high_scalability-2010/high_scalability-2010-02-06-GEO-aware_traffic_load_balancing_and_caching_at_CNBC.com.html">773 high scalability-2010-02-06-GEO-aware traffic load balancing and caching at CNBC.com</a></p>
<p>20 0.61811179 <a title="1282-lsi-20" href="../high_scalability-2009/high_scalability-2009-04-16-Serving_250M_quotes-day_at_CNBC.com_with_aiCache.html">573 high scalability-2009-04-16-Serving 250M quotes-day at CNBC.com with aiCache</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.065), (2, 0.25), (10, 0.068), (13, 0.333), (79, 0.096), (90, 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.85185546 <a title="1282-lda-1" href="../high_scalability-2012/high_scalability-2012-07-12-4_Strategies_for_Punching_Down_Traffic_Spikes.html">1282 high scalability-2012-07-12-4 Strategies for Punching Down Traffic Spikes</a></p>
<p>Introduction: Travis Reeder inSpikability - An Application's Ability to Handle Unknown
and/or Inconsistent Load gives four good ways of handling spikey loads:Have
more resources than you'll ever need. Estimate the maximum traffic you'll need
and keep that many servers running. Downside is you are paying for capacity
you aren't using.Disable features during high loads. Reduce load by disabling
features or substituting in lighter weight features. Downside is users to have
access to features.Auto scaling. Launch new servers in response to load.
Downsides are it's complicated to setup and slow to respond. Random spikes
will cause cycling of instances going up and down.Use message queues. Queues
soak up work requests during traffic spikes. More servers can be started to
process work from the queue. Resources aren't wasted and features are
disabled. Downside is increased latency.</p><p>2 0.77785188 <a title="1282-lda-2" href="../high_scalability-2007/high_scalability-2007-07-27-Product%3A_Munin_Monitoriting_Tool.html">34 high scalability-2007-07-27-Product: Munin Monitoriting Tool</a></p>
<p>Introduction: Muninthe monitoring tool surveys all your computers and remembers what it saw.
It presents all the information in graphs through a web interface. Its
emphasis is on plug and play capabilities. After completing a installation a
high number of monitoring plugins will be playing with no more effort.Using
Munin you can easily monitor the performance of your computers, networks,
SANs, applications, weather measurements and whatever comes to mind. It makes
it easy to determine "what's different today" when a performance problem crops
up. It makes it easy to see how you're doing capacity-wise on any resources.</p><p>3 0.73192841 <a title="1282-lda-3" href="../high_scalability-2008/high_scalability-2008-12-29-100%25_on_Amazon_Web_Services%3A_Soocial.com_-_a_lesson_of_porting_your_service_to_Amazon.html">477 high scalability-2008-12-29-100% on Amazon Web Services: Soocial.com - a lesson of porting your service to Amazon</a></p>
<p>Introduction: Simone Brunozzi, technology evangelist for Amazon Web Services in Europe,
describes how Soocial.com was fully ported to Amazon web services.
----------------This period of the year I decided to dedicate some time to
better understand how our customers use AWS, therefore I spent some online
time with Stefan Fountain and the nice guys at Soocial.com, a "one address
book solution to contact management", and I would like to share with you some
details of their IT infrastructure, which now runs 100% on Amazon Web
Services!In the last few months, they've been working hard to cope with tens
of thousands of users and to get ready to easily scale to millions. To make
this possible, they decided to move ALL their architecture to Amazon Web
Services. Despite the fact that they were quite happy with their previous
hosting provider, Amazon proved to be the way to go.-----------------Read the
rest of the article here.</p><p>4 0.72268325 <a title="1282-lda-4" href="../high_scalability-2013/high_scalability-2013-04-25-Paper%3A_Making_reliable_distributed_systems_in_the_presence_of_software_errors.html">1446 high scalability-2013-04-25-Paper: Making reliable distributed systems in the presence of software errors</a></p>
<p>Introduction: Joe Armstrong is a co-inventor ofErlang and general all around renaissance
software tinkerer as shown by his excellent work on writing aC Compiler and
his voluminous work on GitHub.Given the success of Erlang it's probably no
surprise that he wrote his thesis on the ground breaking ideas behind Erlang:
Making reliable distributed systems in the presence of software errors.Even if
you have yet to join the cult of Erlang the principles behind Erlang are
universal and well worth exploring for your own designs. Highly
recommended.Introduction:How can we program systems which behave in a
reasonable manner in the presence of software errors? This is the central
question that I hope to answer in this thesis. Large systems will probably
always be delivered containing a number of errors in the software,
nevertheless such systems are expected to behave in a reasonable manner.To
make a reliable system from faulty components places certain requirements on
the system. The requirements can be satisf</p><p>5 0.71418035 <a title="1282-lda-5" href="../high_scalability-2011/high_scalability-2011-06-29-Second_Hand_Seizure_%3A_A_New_Cause_of_Site_Death.html">1070 high scalability-2011-06-29-Second Hand Seizure : A New Cause of Site Death</a></p>
<p>Introduction: Like a digital SWAT team that implodes the wrong door on a raid, the FBI
seized multiple racks of computers from DigitalOne, theseracks host websites
from many clients that just happened to be in the same racks as whomever they
are investigating. Downed sites include Instapaper, Curbed Network,
andPinboard. With thedensity of serversthese days many 1000s of sites could
easily have been effected.Sites like Pinboard were victims by association,
they did not inhale. This is an association sites have no control over. On a
shared hosting service, you have no control over your fellow VM mates. In a
cloud or a managed service, you have no control over which racks your servers
are in. So like second hand smoke, you get the disease by random association.
There's something inherently unfair about that.Acomment by illumin8 shows just
how Darth insidious this process can be:A popular method used by hackers is to
sign up for a virtual server with a stolen credit card. If they are careful
and only a</p><p>6 0.71389508 <a title="1282-lda-6" href="../high_scalability-2010/high_scalability-2010-01-11-Have_We_Reached_the_End_of_Scaling%3F.html">758 high scalability-2010-01-11-Have We Reached the End of Scaling?</a></p>
<p>7 0.71122056 <a title="1282-lda-7" href="../high_scalability-2008/high_scalability-2008-09-23-The_7_Stages_of_Scaling_Web_Apps.html">391 high scalability-2008-09-23-The 7 Stages of Scaling Web Apps</a></p>
<p>8 0.70151472 <a title="1282-lda-8" href="../high_scalability-2007/high_scalability-2007-10-04-You_Can_Now_Store_All_Your_Stuff_on_Your_Own_Google_Like_File_System.html">112 high scalability-2007-10-04-You Can Now Store All Your Stuff on Your Own Google Like File System</a></p>
<p>9 0.69321859 <a title="1282-lda-9" href="../high_scalability-2014/high_scalability-2014-01-10-Stuff_The_Internet_Says_On_Scalability_For_January_10th%2C_2014.html">1576 high scalability-2014-01-10-Stuff The Internet Says On Scalability For January 10th, 2014</a></p>
<p>10 0.68139744 <a title="1282-lda-10" href="../high_scalability-2009/high_scalability-2009-07-29-Strategy%3A_Devirtualize_for_More_Vroom.html">664 high scalability-2009-07-29-Strategy: Devirtualize for More Vroom</a></p>
<p>11 0.63533932 <a title="1282-lda-11" href="../high_scalability-2010/high_scalability-2010-09-01-Paper%3A_The_Case_for_Determinism_in_Database_Systems__.html">890 high scalability-2010-09-01-Paper: The Case for Determinism in Database Systems  </a></p>
<p>12 0.63343757 <a title="1282-lda-12" href="../high_scalability-2009/high_scalability-2009-08-07-Strategy%3A_Break_Up_the_Memcache_Dog_Pile_.html">673 high scalability-2009-08-07-Strategy: Break Up the Memcache Dog Pile </a></p>
<p>13 0.63343078 <a title="1282-lda-13" href="../high_scalability-2013/high_scalability-2013-03-18-Beyond_Threads_and_Callbacks_-_Application_Architecture_Pros_and_Cons.html">1425 high scalability-2013-03-18-Beyond Threads and Callbacks - Application Architecture Pros and Cons</a></p>
<p>14 0.63282096 <a title="1282-lda-14" href="../high_scalability-2013/high_scalability-2013-03-29-Stuff_The_Internet_Says_On_Scalability_For_March_29%2C_2013.html">1431 high scalability-2013-03-29-Stuff The Internet Says On Scalability For March 29, 2013</a></p>
<p>15 0.62925982 <a title="1282-lda-15" href="../high_scalability-2012/high_scalability-2012-03-06-Ask_For_Forgiveness_Programming_-_Or_How_We%27ll_Program_1000_Cores.html">1204 high scalability-2012-03-06-Ask For Forgiveness Programming - Or How We'll Program 1000 Cores</a></p>
<p>16 0.62468088 <a title="1282-lda-16" href="../high_scalability-2008/high_scalability-2008-10-15-Outside.in_Scales_Up_with_Engine_Yard_and_moving_from_PHP_to_Ruby_on_Rails.html">417 high scalability-2008-10-15-Outside.in Scales Up with Engine Yard and moving from PHP to Ruby on Rails</a></p>
<p>17 0.62378407 <a title="1282-lda-17" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>18 0.62322158 <a title="1282-lda-18" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>19 0.62274212 <a title="1282-lda-19" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>20 0.62267709 <a title="1282-lda-20" href="../high_scalability-2007/high_scalability-2007-12-19-How_can_I_learn_to_scale_my_project%3F.html">188 high scalability-2007-12-19-How can I learn to scale my project?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
