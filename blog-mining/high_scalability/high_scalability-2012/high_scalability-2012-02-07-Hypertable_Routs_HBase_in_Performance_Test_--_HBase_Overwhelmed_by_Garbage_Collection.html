<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1189 high scalability-2012-02-07-Hypertable Routs HBase in Performance Test -- HBase Overwhelmed by Garbage Collection</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2012" href="../home/high_scalability-2012_home.html">high_scalability-2012</a> <a title="high_scalability-2012-1189" href="#">high_scalability-2012-1189</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1189 high scalability-2012-02-07-Hypertable Routs HBase in Performance Test -- HBase Overwhelmed by Garbage Collection</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2012-1189-html" href="http://highscalability.com//blog/2012/2/7/hypertable-routs-hbase-in-performance-test-hbase-overwhelmed.html">html</a></p><p>Introduction: This is a guest post byDoug Judd, original creator of Hypertable and the CEO
of Hypertable, Inc.Hypertable delivers 2X better throughput in most tests --
HBase fails 41 and 167 billion record insert tests, overwhelmed by garbage
collection -- Both systems deliver similar results for random read uniform
testWe recently conducted a test comparing the performance of Hypertable
(@hypertable) version 0.9.5.5 to that of HBase (@HBase) version 0.90.4
(CDH3u2) running Zookeeper 3.3.4.  In this post, we summarize the results and
offer explanations for the discrepancies. For the full test report,
seeHypertable vs. HBase II.IntroductionHypertable and HBase are both open
source, scalable databases modeled after Google's proprietary Bigtable
database.  The primary difference between the two systems is that Hypertable
is written in C++, while HBase is written in Java.  We modeled this test after
the one described in section 7 of theBigtable paperand tuned both systems for
maximum performance.  The t</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hypertable', 0.59), ('hbase', 0.447), ('test', 0.26), ('garbage', 0.154), ('following', 0.126), ('regionservers', 0.1), ('keys', 0.1), ('ms', 0.094), ('uniform', 0.093), ('tests', 0.092), ('loaded', 0.092), ('measurements', 0.092), ('detrimental', 0.085), ('size', 0.079), ('snappy', 0.078), ('results', 0.078), ('provided', 0.077), ('followed', 0.074), ('exact', 0.072), ('random', 0.072)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="1189-tfidf-1" href="../high_scalability-2012/high_scalability-2012-02-07-Hypertable_Routs_HBase_in_Performance_Test_--_HBase_Overwhelmed_by_Garbage_Collection.html">1189 high scalability-2012-02-07-Hypertable Routs HBase in Performance Test -- HBase Overwhelmed by Garbage Collection</a></p>
<p>Introduction: This is a guest post byDoug Judd, original creator of Hypertable and the CEO
of Hypertable, Inc.Hypertable delivers 2X better throughput in most tests --
HBase fails 41 and 167 billion record insert tests, overwhelmed by garbage
collection -- Both systems deliver similar results for random read uniform
testWe recently conducted a test comparing the performance of Hypertable
(@hypertable) version 0.9.5.5 to that of HBase (@HBase) version 0.90.4
(CDH3u2) running Zookeeper 3.3.4.  In this post, we summarize the results and
offer explanations for the discrepancies. For the full test report,
seeHypertable vs. HBase II.IntroductionHypertable and HBase are both open
source, scalable databases modeled after Google's proprietary Bigtable
database.  The primary difference between the two systems is that Hypertable
is written in C++, while HBase is written in Java.  We modeled this test after
the one described in section 7 of theBigtable paperand tuned both systems for
maximum performance.  The t</p><p>2 0.43642318 <a title="1189-tfidf-2" href="../high_scalability-2009/high_scalability-2009-07-02-Hypertable_is_a_New_BigTable_Clone_that_Runs_on_HDFS_or_KFS.html">647 high scalability-2009-07-02-Hypertable is a New BigTable Clone that Runs on HDFS or KFS</a></p>
<p>Introduction: Update 3: Presentation from theNoSQL conference:slides,video 1,video 2.Update
2: The folks at Hypertable would like you to know that Hypertable is now
officiallysponsored by Baidu, China's Leading Search Engine.As a sponsor of
Hypertable, Baidu has committed an industrious team of engineers, numerous
servers, and support resources to improve the quality and development of the
open source technology.Update: InfoQ interview onHypertable Lead Discusses
Hadoop and Distributed Databases. Hypertable differs from HBase in that it is
a higher performance implementation of Bigtable.Skrentabloggives the heads up
onHypertable,Zvents'open-source BigTable clone. It's written in C++ and can
run on top of either HDFS or KFS. Performance looks encouraging at28M rows of
data inserted at a per-node write rate of 7mb/sec.</p><p>3 0.28570682 <a title="1189-tfidf-3" href="../high_scalability-2010/high_scalability-2010-03-16-1_Billion_Reasons_Why_Adobe_Chose_HBase_.html">795 high scalability-2010-03-16-1 Billion Reasons Why Adobe Chose HBase </a></p>
<p>Introduction: Cosmin Lehene ďťżwrote two excellent articles on Adobe's experiences with
HBase:Why we're using HBase: Part 1andWhy we're using HBase: Part 2. Adobe
needed ageneric,real-time, structured data storage and processing system that
could handle any data volume, with access times under 50ms, with no downtime
andno data loss. The article goes into great detail about their experiences
with HBase and their evaluation process, providing a "well reasoned impartial
use case from a commercial user". It talks about failure handling,
availability, write performance, read performance, random reads, sequential
scans, and consistency. One of the knocks against HBase has been it's
complexity, as it has many parts that need installation and configuration. All
is not lost according to the Adobe team:HBase is more complex than other
systems (you need Hadoop, Zookeeper, cluster machines have multiple roles). We
believe that for HBase, this is not accidental complexity and that the
argument that "HBase is not a</p><p>4 0.26904881 <a title="1189-tfidf-4" href="../high_scalability-2010/high_scalability-2010-11-16-Facebook%27s_New_Real-time_Messaging_System%3A_HBase_to_Store_135%2B_Billion_Messages_a_Month.html">943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</a></p>
<p>Introduction: You may have read somewhere that Facebook has introduced a newSocial Inbox
integrating email, IM, SMS,  text messages, on-site Facebook messages. All-in-
all they need to store over 135 billion messages a month. Where do they store
all that stuff? Facebook's Kannan Muthukkaruppan gives the surprise answer
inThe Underlying Technology of Messages:HBase. HBase beat out MySQL,
Cassandra, and a few others.Why a surprise? Facebook created Cassandra and it
was purpose built for an inbox type application, but they found Cassandra's
eventual consistency model wasn't a good match for their new real-time
Messages product. Facebook also has an extensiveMySQL infrastructure, but they
found performance suffered as data set and indexes grew larger. And they could
have built their own, but they chose HBase.HBase is ascaleout table store
supporting very high rates of row-level updates over massive amounts of data.
Exactly what is needed for a Messaging system. HBase is also a column based
key-value sto</p><p>5 0.18407792 <a title="1189-tfidf-5" href="../high_scalability-2010/high_scalability-2010-06-25-Hot_Scalability_Links_for_June_25%2C_2010.html">848 high scalability-2010-06-25-Hot Scalability Links for June 25, 2010</a></p>
<p>Introduction: Royans Tharakan is blogging like a mad man at theVelocity Conference. Read a
summary of many of the presentations on hisblog.Zuckerberg almostguarantees 1
billion Facebook users. AndI almost believe him.Northscale introducesMembase,
a new distributed key-value NoSQL competitor featuring a memcache compatible
interface, yet is persistent like a database. Hopefully we'll have more on
their internals later.Notable Tweets: Aaron Cordova - scalability means "can
change size" and also "works at large sizes" - this conflates two orthogonal
features of cloud computing. Jaime Garcia Reinoso- It's the scalability,
stupid! Alex Averbuch \- when I read/hear "unlimited/inifinite scalability" I
stop reading/listening and start thinking about cake.Dennis Clark- I used to
smirk at developers whose main DB experience was in MUMPS or Pick, until I
realized those are old-school #NoSQL engines.Hypertable vs. HBase Performance
Evaluation. Hypertable's benchmarking shows Hypertable has up to 10 times
better</p><p>6 0.16210514 <a title="1189-tfidf-6" href="../high_scalability-2009/high_scalability-2009-10-29-Digg_-_Looking_to_the_Future_with_Cassandra.html">732 high scalability-2009-10-29-Digg - Looking to the Future with Cassandra</a></p>
<p>7 0.15179239 <a title="1189-tfidf-7" href="../high_scalability-2011/high_scalability-2011-09-02-Stuff_The_Internet_Says_On_Scalability_For_September_2%2C_2011.html">1109 high scalability-2011-09-02-Stuff The Internet Says On Scalability For September 2, 2011</a></p>
<p>8 0.14199482 <a title="1189-tfidf-8" href="../high_scalability-2009/high_scalability-2009-07-02-Product%3A_Hbase.html">650 high scalability-2009-07-02-Product: Hbase</a></p>
<p>9 0.14064446 <a title="1189-tfidf-9" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>10 0.13897496 <a title="1189-tfidf-10" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>11 0.13687074 <a title="1189-tfidf-11" href="../high_scalability-2010/high_scalability-2010-11-05-Hot_Scalability_Links_For_November_5th%2C_2010.html">935 high scalability-2010-11-05-Hot Scalability Links For November 5th, 2010</a></p>
<p>12 0.12916121 <a title="1189-tfidf-12" href="../high_scalability-2012/high_scalability-2012-08-03-Stuff_The_Internet_Says_On_Scalability_For_August_3%2C_2012.html">1297 high scalability-2012-08-03-Stuff The Internet Says On Scalability For August 3, 2012</a></p>
<p>13 0.1278899 <a title="1189-tfidf-13" href="../high_scalability-2010/high_scalability-2010-02-25-Paper%3A_High_Performance_Scalable_Data_Stores_.html">784 high scalability-2010-02-25-Paper: High Performance Scalable Data Stores </a></p>
<p>14 0.1210873 <a title="1189-tfidf-14" href="../high_scalability-2012/high_scalability-2012-02-13-Tumblr_Architecture_-_15_Billion_Page_Views_a_Month_and_Harder_to_Scale_than_Twitter.html">1191 high scalability-2012-02-13-Tumblr Architecture - 15 Billion Page Views a Month and Harder to Scale than Twitter</a></p>
<p>15 0.1210873 <a title="1189-tfidf-15" href="../high_scalability-2012/high_scalability-2012-11-19-Gone_Fishin%27%3A_Tumblr_Architecture_-_15_Billion_Page_Views_A_Month_And_Harder_To_Scale_Than_Twitter.html">1360 high scalability-2012-11-19-Gone Fishin': Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a></p>
<p>16 0.12034811 <a title="1189-tfidf-16" href="../high_scalability-2013/high_scalability-2013-05-20-The_Tumblr_Architecture_Yahoo_Bought_for_a_Cool_Billion_Dollars.html">1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</a></p>
<p>17 0.12012128 <a title="1189-tfidf-17" href="../high_scalability-2013/high_scalability-2013-04-03-5_Steps_to_Benchmarking_Managed_NoSQL_-_DynamoDB_vs_Cassandra.html">1434 high scalability-2013-04-03-5 Steps to Benchmarking Managed NoSQL - DynamoDB vs Cassandra</a></p>
<p>18 0.11960918 <a title="1189-tfidf-18" href="../high_scalability-2011/high_scalability-2011-04-12-Caching_and_Processing_2TB_Mozilla_Crash_Reports_in_memory_with_Hazelcast.html">1020 high scalability-2011-04-12-Caching and Processing 2TB Mozilla Crash Reports in memory with Hazelcast</a></p>
<p>19 0.11920044 <a title="1189-tfidf-19" href="../high_scalability-2009/high_scalability-2009-11-05-A_Yes_for_a_NoSQL_Taxonomy.html">737 high scalability-2009-11-05-A Yes for a NoSQL Taxonomy</a></p>
<p>20 0.1147966 <a title="1189-tfidf-20" href="../high_scalability-2014/high_scalability-2014-01-28-How_Next_Big_Sound_Tracks_Over_a_Trillion_Song_Plays%2C_Likes%2C_and_More_Using_a_Version_Control_System_for_Hadoop_Data.html">1586 high scalability-2014-01-28-How Next Big Sound Tracks Over a Trillion Song Plays, Likes, and More Using a Version Control System for Hadoop Data</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.15), (1, 0.064), (2, -0.034), (3, 0.022), (4, 0.027), (5, 0.109), (6, 0.038), (7, 0.008), (8, 0.02), (9, 0.01), (10, 0.048), (11, -0.014), (12, 0.074), (13, -0.026), (14, -0.053), (15, 0.007), (16, -0.032), (17, -0.086), (18, -0.079), (19, -0.092), (20, -0.015), (21, 0.028), (22, 0.004), (23, -0.006), (24, -0.035), (25, -0.06), (26, -0.005), (27, 0.007), (28, -0.036), (29, -0.051), (30, 0.009), (31, 0.062), (32, 0.1), (33, -0.042), (34, 0.088), (35, 0.13), (36, 0.022), (37, 0.027), (38, -0.011), (39, -0.018), (40, -0.025), (41, 0.03), (42, 0.129), (43, 0.041), (44, -0.056), (45, 0.048), (46, 0.005), (47, 0.031), (48, 0.089), (49, 0.028)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95709234 <a title="1189-lsi-1" href="../high_scalability-2012/high_scalability-2012-02-07-Hypertable_Routs_HBase_in_Performance_Test_--_HBase_Overwhelmed_by_Garbage_Collection.html">1189 high scalability-2012-02-07-Hypertable Routs HBase in Performance Test -- HBase Overwhelmed by Garbage Collection</a></p>
<p>Introduction: This is a guest post byDoug Judd, original creator of Hypertable and the CEO
of Hypertable, Inc.Hypertable delivers 2X better throughput in most tests --
HBase fails 41 and 167 billion record insert tests, overwhelmed by garbage
collection -- Both systems deliver similar results for random read uniform
testWe recently conducted a test comparing the performance of Hypertable
(@hypertable) version 0.9.5.5 to that of HBase (@HBase) version 0.90.4
(CDH3u2) running Zookeeper 3.3.4.  In this post, we summarize the results and
offer explanations for the discrepancies. For the full test report,
seeHypertable vs. HBase II.IntroductionHypertable and HBase are both open
source, scalable databases modeled after Google's proprietary Bigtable
database.  The primary difference between the two systems is that Hypertable
is written in C++, while HBase is written in Java.  We modeled this test after
the one described in section 7 of theBigtable paperand tuned both systems for
maximum performance.  The t</p><p>2 0.76376539 <a title="1189-lsi-2" href="../high_scalability-2009/high_scalability-2009-07-02-Hypertable_is_a_New_BigTable_Clone_that_Runs_on_HDFS_or_KFS.html">647 high scalability-2009-07-02-Hypertable is a New BigTable Clone that Runs on HDFS or KFS</a></p>
<p>Introduction: Update 3: Presentation from theNoSQL conference:slides,video 1,video 2.Update
2: The folks at Hypertable would like you to know that Hypertable is now
officiallysponsored by Baidu, China's Leading Search Engine.As a sponsor of
Hypertable, Baidu has committed an industrious team of engineers, numerous
servers, and support resources to improve the quality and development of the
open source technology.Update: InfoQ interview onHypertable Lead Discusses
Hadoop and Distributed Databases. Hypertable differs from HBase in that it is
a higher performance implementation of Bigtable.Skrentabloggives the heads up
onHypertable,Zvents'open-source BigTable clone. It's written in C++ and can
run on top of either HDFS or KFS. Performance looks encouraging at28M rows of
data inserted at a per-node write rate of 7mb/sec.</p><p>3 0.7217201 <a title="1189-lsi-3" href="../high_scalability-2010/high_scalability-2010-03-16-1_Billion_Reasons_Why_Adobe_Chose_HBase_.html">795 high scalability-2010-03-16-1 Billion Reasons Why Adobe Chose HBase </a></p>
<p>Introduction: Cosmin Lehene ďťżwrote two excellent articles on Adobe's experiences with
HBase:Why we're using HBase: Part 1andWhy we're using HBase: Part 2. Adobe
needed ageneric,real-time, structured data storage and processing system that
could handle any data volume, with access times under 50ms, with no downtime
andno data loss. The article goes into great detail about their experiences
with HBase and their evaluation process, providing a "well reasoned impartial
use case from a commercial user". It talks about failure handling,
availability, write performance, read performance, random reads, sequential
scans, and consistency. One of the knocks against HBase has been it's
complexity, as it has many parts that need installation and configuration. All
is not lost according to the Adobe team:HBase is more complex than other
systems (you need Hadoop, Zookeeper, cluster machines have multiple roles). We
believe that for HBase, this is not accidental complexity and that the
argument that "HBase is not a</p><p>4 0.61033595 <a title="1189-lsi-4" href="../high_scalability-2012/high_scalability-2012-11-29-Performance_data_for_LevelDB%2C_Berkley_DB_and_BangDB_for_Random_Operations.html">1364 high scalability-2012-11-29-Performance data for LevelDB, Berkley DB and BangDB for Random Operations</a></p>
<p>Introduction: This is a guest post bySachin Sinha, Founder ofIqlectand developer
ofBangDB.The goal for the paper is to provide the performances data for
following embedded databases under various scenarios for random operations
such as write and read. The data is presented in graphical manner to make the
data self explanatory to some extent.LevelDB:LevelDB is a fast key-value
storage library written at Google that provides an ordered mapping from string
keys to string values. Leveldb is based on LSM (Log-Structured Merge-Tree) and
uses SSTable and MemTable for the database implementation. It's written in C++
and availabe under BSD license. LevelDB treats key and value as arbitrary byte
arrays and stores keys in ordered fashion. It uses snappy compression for the
data compression. Write and Read are concurrent for the db, but write performs
best with single thread whereas Read scales with number of
coresBerkleyDB:BerkleyDB (BDB) is a library that provides high performance
embedded database for key/va</p><p>5 0.59108293 <a title="1189-lsi-5" href="../high_scalability-2013/high_scalability-2013-04-03-5_Steps_to_Benchmarking_Managed_NoSQL_-_DynamoDB_vs_Cassandra.html">1434 high scalability-2013-04-03-5 Steps to Benchmarking Managed NoSQL - DynamoDB vs Cassandra</a></p>
<p>Introduction: This is a guest post byBen BromheadfromInstaclustrDeciding to use a managed
NoSQL datastore is a great step in ensuring you run a fast, scalable and
resilient application without needing to be an expert in highly available
architecture. How do you know which technology is the best for your
application? How do you know whether the provider's performance claims are
true? You are putting your application on someone else’s infrastructure and
that requires some hard answers about their claims.To determine the
suitability of a provider, your first port of call is to benchmark. Choosing a
service provider is often done in a number of stages. First is to shortlist
providers based on capabilities and claimed performance, ruling out those that
do not meet your application requirements. Second is to look for benchmarks
conducted by third parties, if any. The final stage is to benchmark the
service yourself.In this article we will show you how to run some preliminary
benchmarks against two managed</p><p>6 0.58524954 <a title="1189-lsi-6" href="../high_scalability-2010/high_scalability-2010-11-16-Facebook%27s_New_Real-time_Messaging_System%3A_HBase_to_Store_135%2B_Billion_Messages_a_Month.html">943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</a></p>
<p>7 0.58024126 <a title="1189-lsi-7" href="../high_scalability-2011/high_scalability-2011-04-12-Caching_and_Processing_2TB_Mozilla_Crash_Reports_in_memory_with_Hazelcast.html">1020 high scalability-2011-04-12-Caching and Processing 2TB Mozilla Crash Reports in memory with Hazelcast</a></p>
<p>8 0.56817394 <a title="1189-lsi-8" href="../high_scalability-2012/high_scalability-2012-04-30-Masstree_-_Much_Faster_than_MongoDB%2C_VoltDB%2C_Redis%2C_and_Competitive_with_Memcached.html">1236 high scalability-2012-04-30-Masstree - Much Faster than MongoDB, VoltDB, Redis, and Competitive with Memcached</a></p>
<p>9 0.5543319 <a title="1189-lsi-9" href="../high_scalability-2012/high_scalability-2012-08-03-Stuff_The_Internet_Says_On_Scalability_For_August_3%2C_2012.html">1297 high scalability-2012-08-03-Stuff The Internet Says On Scalability For August 3, 2012</a></p>
<p>10 0.55060405 <a title="1189-lsi-10" href="../high_scalability-2012/high_scalability-2012-04-03-Hazelcast_2.0%3A_Big_Data_In-Memory.html">1221 high scalability-2012-04-03-Hazelcast 2.0: Big Data In-Memory</a></p>
<p>11 0.54282641 <a title="1189-lsi-11" href="../high_scalability-2011/high_scalability-2011-09-02-Stuff_The_Internet_Says_On_Scalability_For_September_2%2C_2011.html">1109 high scalability-2011-09-02-Stuff The Internet Says On Scalability For September 2, 2011</a></p>
<p>12 0.52279764 <a title="1189-lsi-12" href="../high_scalability-2009/high_scalability-2009-11-05-A_Yes_for_a_NoSQL_Taxonomy.html">737 high scalability-2009-11-05-A Yes for a NoSQL Taxonomy</a></p>
<p>13 0.5225634 <a title="1189-lsi-13" href="../high_scalability-2011/high_scalability-2011-01-10-Riak%27s_Bitcask_-_A_Log-Structured_Hash_Table_for_Fast_Key-Value_Data.html">971 high scalability-2011-01-10-Riak's Bitcask - A Log-Structured Hash Table for Fast Key-Value Data</a></p>
<p>14 0.51132756 <a title="1189-lsi-14" href="../high_scalability-2012/high_scalability-2012-02-10-Stuff_The_Internet_Says_On_Scalability_For_February_10%2C_2012.html">1190 high scalability-2012-02-10-Stuff The Internet Says On Scalability For February 10, 2012</a></p>
<p>15 0.508232 <a title="1189-lsi-15" href="../high_scalability-2012/high_scalability-2012-01-05-Shutterfly_Saw_a_Speedup_of_500%25_With_Flashcache.html">1169 high scalability-2012-01-05-Shutterfly Saw a Speedup of 500% With Flashcache</a></p>
<p>16 0.50761235 <a title="1189-lsi-16" href="../high_scalability-2009/high_scalability-2009-10-29-Digg_-_Looking_to_the_Future_with_Cassandra.html">732 high scalability-2009-10-29-Digg - Looking to the Future with Cassandra</a></p>
<p>17 0.49733725 <a title="1189-lsi-17" href="../high_scalability-2011/high_scalability-2011-08-25-Colmux_-_Finding_Memory_Leaks%2C_High_I-O_Wait_Times%2C_and_Hotness_on_3000_Node_Clusters.html">1104 high scalability-2011-08-25-Colmux - Finding Memory Leaks, High I-O Wait Times, and Hotness on 3000 Node Clusters</a></p>
<p>18 0.49521956 <a title="1189-lsi-18" href="../high_scalability-2011/high_scalability-2011-09-30-Stuff_The_Internet_Says_On_Scalability_For_September_30%2C_2011.html">1129 high scalability-2011-09-30-Stuff The Internet Says On Scalability For September 30, 2011</a></p>
<p>19 0.49258059 <a title="1189-lsi-19" href="../high_scalability-2011/high_scalability-2011-02-15-Wordnik_-_10_million_API_Requests_a_Day_on_MongoDB_and_Scala.html">990 high scalability-2011-02-15-Wordnik - 10 million API Requests a Day on MongoDB and Scala</a></p>
<p>20 0.49125311 <a title="1189-lsi-20" href="../high_scalability-2008/high_scalability-2008-02-19-Hadoop_Getting_Closer_to_1.0_Release.html">254 high scalability-2008-02-19-Hadoop Getting Closer to 1.0 Release</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.137), (2, 0.146), (10, 0.086), (17, 0.024), (23, 0.013), (39, 0.145), (40, 0.022), (61, 0.138), (79, 0.098), (85, 0.04), (94, 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9127515 <a title="1189-lda-1" href="../high_scalability-2012/high_scalability-2012-02-07-Hypertable_Routs_HBase_in_Performance_Test_--_HBase_Overwhelmed_by_Garbage_Collection.html">1189 high scalability-2012-02-07-Hypertable Routs HBase in Performance Test -- HBase Overwhelmed by Garbage Collection</a></p>
<p>Introduction: This is a guest post byDoug Judd, original creator of Hypertable and the CEO
of Hypertable, Inc.Hypertable delivers 2X better throughput in most tests --
HBase fails 41 and 167 billion record insert tests, overwhelmed by garbage
collection -- Both systems deliver similar results for random read uniform
testWe recently conducted a test comparing the performance of Hypertable
(@hypertable) version 0.9.5.5 to that of HBase (@HBase) version 0.90.4
(CDH3u2) running Zookeeper 3.3.4.  In this post, we summarize the results and
offer explanations for the discrepancies. For the full test report,
seeHypertable vs. HBase II.IntroductionHypertable and HBase are both open
source, scalable databases modeled after Google's proprietary Bigtable
database.  The primary difference between the two systems is that Hypertable
is written in C++, while HBase is written in Java.  We modeled this test after
the one described in section 7 of theBigtable paperand tuned both systems for
maximum performance.  The t</p><p>2 0.89270753 <a title="1189-lda-2" href="../high_scalability-2009/high_scalability-2009-08-31-Scaling_MySQL_on_Amazon_Web_Services.html">690 high scalability-2009-08-31-Scaling MySQL on Amazon Web Services</a></p>
<p>Introduction: I've recently started working with a large company who is looking to take one
of their heavily utilized applications and move it to Amazon Web Services. I'm
not looking to start a debate on the merits of EC2, the decision to move to
aws is already made (and is a much better decision than paying a vendor
millions to host it).I've done my reasearch and I'm comfortable with creating
this environment with one exception, scaling MySQL. I havent done much work
with MySQL, i'm more of an Oracle guy up to now. I'm struggling to determine a
way to scale MySQL on the fly in a way so that replication works, the server
takes its proper place in line for master candidacy, and the apache servers
become aware of it.So this is really three questions:1. What are some proven
methods of load balancing the read traffic going from apache to MySQL.2. How
do I let the load balancing mechanism know when I scale up / down a new Mysql
Server?3. How to alert the master of the new server and initiate replication</p><p>3 0.88931286 <a title="1189-lda-3" href="../high_scalability-2010/high_scalability-2010-09-16-How_Can_the_Large_Hadron_Collider_Withstand_One_Petabyte_of_Data_a_Second%3F.html">901 high scalability-2010-09-16-How Can the Large Hadron Collider Withstand One Petabyte of Data a Second?</a></p>
<p>Introduction: Why is there something rather than nothing? That's the kind of question
theLarge Hadron Colliderin CERN is hopefully poised to answer. And what is the
output of this beautiful 17-mile long,6 billion dollar wabi-sabishproton
smashing machine? Data. Great heaping torrents of Grand Canyon sized data. 15
million gigabytes every year. That's 1000 times the information printed in
books every year. It's so much data 10,000 scientists will use agridof80,000+
computers, in 300 computer centers , in 50 different countries just to help
make sense of it all.How will all this data be collected, transported, stored,
and analyzed? It turns out, using what amounts to sort of Internet of
Particles instead of an Internet of Things.Two good articles have recently
shed some electro-magnetic energy in the human visible spectrum on the IT
aspects of the collider:LHC computing grid pushes petabytes of data, beats
expectations by John Timmer on Ars Technica and an overview of theBrookhaven's
RHIC/ATLAS Comput</p><p>4 0.88490492 <a title="1189-lda-4" href="../high_scalability-2010/high_scalability-2010-06-16-Hot_Scalability_Links_for_June_16%2C_2010.html">842 high scalability-2010-06-16-Hot Scalability Links for June 16, 2010</a></p>
<p>Introduction: You're Doing it Wrong by Poul-Henning Kamp. Don't look so guilty, he's not
talking about you know what, he's talking about writing high-performance
server programs: Not just wrong as in not perfect, but wrong as in wasting
half, or more, of your performance. What good is an O(log2(n)) algorithm if
those operations cause page faults and slow disk operations? For most relevant
datasets an O(n) or even an O(n^2) algorithm, which avoids page faults, will
run circles around it. A Microsoft Windows Azure primer: the basicsby Peter
Bright. Nice article explaining the basics of Azure and how it compares to
Google and Amazon.A call to change the name from NoSQL to Postmodern
Databases. Interesting idea, but the problem is the same one I have for
Postmodern Art, when is it? I always feel like I'm in the post-post modern
period, yet for art it's really in the early 1900s. Let's save future
developers from this existential time crisis.Constructions from Dots and
Linesby Marko A. Rodriguez, Peter N</p><p>5 0.86943263 <a title="1189-lda-5" href="../high_scalability-2011/high_scalability-2011-11-29-DataSift_Architecture%3A_Realtime_Datamining_at_120%2C000_Tweets_Per_Second.html">1148 high scalability-2011-11-29-DataSift Architecture: Realtime Datamining at 120,000 Tweets Per Second</a></p>
<p>Introduction: I remember the excitement of when Twitter first opened up their firehose. As
an early adopter of the Twitter API I could easily imagine some of the cool
things you could do with all that data. I also remember the disappointment of
learning that in the land of BigData, data has a price, and that price would
be too high for little fish like me. It was like learning for the first time
there would be no BigData Santa Clause.For a while though I had the pleasure
of pondering just how I would handle all that data. It's a fascinating
problem. You have to be able to reliably consume it, normalize it, merge it
with other data, apply functions on it, store it, query it, distribute it, and
oh yah, monetize it. Most of that in realish-time. And if you are trying to
create a platform for allowing the entire Internet do to the same thing to the
firehose, the challenge is exponentially harder.DataSift is in the exciting
position of creating just such a firehose eating, data chomping machine. You
see,</p><p>6 0.86054373 <a title="1189-lda-6" href="../high_scalability-2008/high_scalability-2008-09-10-Shard_servers_--_go_big_or_small%3F.html">383 high scalability-2008-09-10-Shard servers -- go big or small?</a></p>
<p>7 0.85682118 <a title="1189-lda-7" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>8 0.85674065 <a title="1189-lda-8" href="../high_scalability-2013/high_scalability-2013-08-07-RAFT_-_In_Search_of_an_Understandable_Consensus_Algorithm.html">1498 high scalability-2013-08-07-RAFT - In Search of an Understandable Consensus Algorithm</a></p>
<p>9 0.85566092 <a title="1189-lda-9" href="../high_scalability-2012/high_scalability-2012-07-23-State_of_the_CDN%3A_More_Traffic%2C_Stable_Prices%2C_More_Products%2C_Profits_-_Not_So_Much.html">1289 high scalability-2012-07-23-State of the CDN: More Traffic, Stable Prices, More Products, Profits - Not So Much</a></p>
<p>10 0.85521072 <a title="1189-lda-10" href="../high_scalability-2012/high_scalability-2012-01-24-The_State_of_NoSQL_in_2012.html">1180 high scalability-2012-01-24-The State of NoSQL in 2012</a></p>
<p>11 0.85222137 <a title="1189-lda-11" href="../high_scalability-2011/high_scalability-2011-05-13-Stuff_The_Internet_Says_On_Scalability_For_May_13%2C_2011.html">1040 high scalability-2011-05-13-Stuff The Internet Says On Scalability For May 13, 2011</a></p>
<p>12 0.85082471 <a title="1189-lda-12" href="../high_scalability-2011/high_scalability-2011-03-09-Productivity_vs._Control_tradeoffs_in_PaaS.html">1002 high scalability-2011-03-09-Productivity vs. Control tradeoffs in PaaS</a></p>
<p>13 0.8506189 <a title="1189-lda-13" href="../high_scalability-2013/high_scalability-2013-12-11-Using_Node.js_PayPal_Doubles_RPS%2C_Lowers_Latency%2C_with_Fewer_Developers%2C_but_Where_Do_the_Improvements_Really_Come_From%3F.html">1563 high scalability-2013-12-11-Using Node.js PayPal Doubles RPS, Lowers Latency, with Fewer Developers, but Where Do the Improvements Really Come From?</a></p>
<p>14 0.84736866 <a title="1189-lda-14" href="../high_scalability-2013/high_scalability-2013-04-29-AWS_v_GCE_Face-off_and_Why_Innovation_Needs_Lower_Cost_Infrastructures.html">1448 high scalability-2013-04-29-AWS v GCE Face-off and Why Innovation Needs Lower Cost Infrastructures</a></p>
<p>15 0.84659165 <a title="1189-lda-15" href="../high_scalability-2010/high_scalability-2010-10-28-Notes_from_A_NOSQL_Evening_in_Palo_Alto_.html">931 high scalability-2010-10-28-Notes from A NOSQL Evening in Palo Alto </a></p>
<p>16 0.84610689 <a title="1189-lda-16" href="../high_scalability-2007/high_scalability-2007-12-11-Hosting_and_CDN_for_startup_video_sharing_site.html">181 high scalability-2007-12-11-Hosting and CDN for startup video sharing site</a></p>
<p>17 0.84577203 <a title="1189-lda-17" href="../high_scalability-2011/high_scalability-2011-11-18-Stuff_The_Internet_Says_On_Scalability_For_November_18%2C_2011.html">1145 high scalability-2011-11-18-Stuff The Internet Says On Scalability For November 18, 2011</a></p>
<p>18 0.84500414 <a title="1189-lda-18" href="../high_scalability-2011/high_scalability-2011-07-29-Stuff_The_Internet_Says_On_Scalability_For_July_29%2C_2011.html">1089 high scalability-2011-07-29-Stuff The Internet Says On Scalability For July 29, 2011</a></p>
<p>19 0.84493226 <a title="1189-lda-19" href="../high_scalability-2011/high_scalability-2011-04-28-PaaS_on_OpenStack_-_Run_Applications_on_Any_Cloud%2C_Any_Time_Using_Any_Thing.html">1031 high scalability-2011-04-28-PaaS on OpenStack - Run Applications on Any Cloud, Any Time Using Any Thing</a></p>
<p>20 0.84367514 <a title="1189-lda-20" href="../high_scalability-2009/high_scalability-2009-01-20-Product%3A_Amazon%27s_SimpleDB.html">498 high scalability-2009-01-20-Product: Amazon's SimpleDB</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
