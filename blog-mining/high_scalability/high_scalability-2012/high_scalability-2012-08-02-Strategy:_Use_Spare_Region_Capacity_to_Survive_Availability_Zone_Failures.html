<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1296 high scalability-2012-08-02-Strategy: Use Spare Region Capacity to Survive Availability Zone Failures</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2012" href="../home/high_scalability-2012_home.html">high_scalability-2012</a> <a title="high_scalability-2012-1296" href="#">high_scalability-2012-1296</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1296 high scalability-2012-08-02-Strategy: Use Spare Region Capacity to Survive Availability Zone Failures</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2012-1296-html" href="http://highscalability.com//blog/2012/8/2/strategy-use-spare-region-capacity-to-survive-availability-z.html">html</a></p><p>Introduction: In the wake of the recent Amazon problemsRyan Lackey offers some practical
first responder cloud survival advice:If you're a large site (particularly a
PaaS) on AWS and care about availability, you need to have spare capacity in
your region (using Reserve Instances, like Netflix does) to cover when a
single AZ disappears, and your own external to AWS load balancing (not DNS
based), with your own per-AZ subsidiary load balancers (nginx or whatever)
running within EC2.You need a robust database layer, ideally multi-region or
AWS + nonAWS, but that's more site specific. Going multiregion is the next
step, and the above is an essential part of getting to that point.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('disappears', 0.292), ('responder', 0.292), ('subsidiary', 0.274), ('aws', 0.269), ('az', 0.231), ('wake', 0.218), ('reserve', 0.214), ('survival', 0.21), ('ideally', 0.201), ('spare', 0.186), ('balancers', 0.152), ('region', 0.152), ('essential', 0.15), ('cover', 0.143), ('paas', 0.138), ('nginx', 0.137), ('advice', 0.136), ('whatever', 0.135), ('particularly', 0.132), ('robust', 0.129)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1296-tfidf-1" href="../high_scalability-2012/high_scalability-2012-08-02-Strategy%3A_Use_Spare_Region_Capacity_to_Survive_Availability_Zone_Failures.html">1296 high scalability-2012-08-02-Strategy: Use Spare Region Capacity to Survive Availability Zone Failures</a></p>
<p>Introduction: In the wake of the recent Amazon problemsRyan Lackey offers some practical
first responder cloud survival advice:If you're a large site (particularly a
PaaS) on AWS and care about availability, you need to have spare capacity in
your region (using Reserve Instances, like Netflix does) to cover when a
single AZ disappears, and your own external to AWS load balancing (not DNS
based), with your own per-AZ subsidiary load balancers (nginx or whatever)
running within EC2.You need a robust database layer, ideally multi-region or
AWS + nonAWS, but that's more site specific. Going multiregion is the next
step, and the above is an essential part of getting to that point.</p><p>2 0.136002 <a title="1296-tfidf-2" href="../high_scalability-2013/high_scalability-2013-11-05-10_Things_You_Should_Know_About_AWS.html">1543 high scalability-2013-11-05-10 Things You Should Know About AWS</a></p>
<p>Introduction: Authored by Chris Fregly:  Former Netflix Streaming Platform Engineer, AWS
Certified Solution Architect and Purveyor of fluxcapacitor.com.Ahead of the
upcoming 2nd annual re:Invent conference, inspired by Simone Brunozzi's
recentpresentationat an AWS Meetup in San Francisco, and collected from a few
of my recentFluxcapacitor.com consulting engagements, I've compiled a list of
10 useful time and clock-tick saving tips about AWS.1) Query AWS resource
metadata Can't remember the EBS-Optimized IO throughput of your c1.xlarge
cluster?  How about the size limit of an S3 object on a single PUT?
awsnow.infois the answer to all of your AWS-resource metadata questions.
Interested in integrating awsnow.info with your application?  You're in luck.
There's now aREST API, as well!Note:  These are default soft limits and will
vary by account.2) Tame your S3 buckets Delete an entire S3 bucket with a
single CLI command:  aws s3 rb s3://\--forceRecursively copy a
local directory to S3:aws</p><p>3 0.12825935 <a title="1296-tfidf-3" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>Introduction: This is a guest post byFrederic Faure(architect atYsance)on the differences
between using a cloud infrastructure and building your own. Frederic was kind
enough to translate the original French version of this article into
English.I've been noticing many questions about the differences inherent in
choosing between a Cloud infrastructure such asAWS(Amazon Web Services) and a
traditional physical infrastructure. Firstly, there are a certain number of
preconceived notions on this subject that I will attempt to decode for you.
Then, it must be understood that each infrastructure has its advantages and
disadvantages: a Cloud-type infrastructure does not necessarily fulfill your
requirements in every case, however, it can satisfy some of them by optimizing
or facilitating the features offered by a traditional physical infrastructure.
I will therefore demonstrate the differences between the two that I have
noticed, in order to help you make up your own mind.The FrameworkCloudThere
are several</p><p>4 0.12795554 <a title="1296-tfidf-4" href="../high_scalability-2011/high_scalability-2011-10-27-Strategy%3A_Survive_a_Comet_Strike_in_the_East_With_Reserved_Instances_in_the_West.html">1133 high scalability-2011-10-27-Strategy: Survive a Comet Strike in the East With Reserved Instances in the West</a></p>
<p>Introduction: Ali Sadat ofMuleSoft gave interesting presentation at Saturday's Talk Cloudy
to Me! event about their experiences movingMule iON, their ESB (enterprise
service bus) product to the cloud.First, a little aboutTalk Cloudy to Me. This
event is the second one day cloud event put on by Sebastian Stadil, founder of
Scalr, as part of the Cloud Computing Meetup group, also created by Sebastian.
Sebastian has become a master at running these mini-conference style events.
Really a quality job by him and his dedicated crew. These events are free,
sponsored by various vendors; they are short, 11-5; the food is good, Thai;
the venue is nice, eBay; they are on topic, with cloud and other speakers
giving 30-45 minute talks.  More on the event when the video comes out. I type
as fast as I can but I can't do much without the video.Back to Ali Sadat.
While he gave a lot of lessons--the integration will your billing system will
take a lot longer than you think; talk to your Amazon account reps as they
hav</p><p>5 0.11882683 <a title="1296-tfidf-5" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>Introduction: This is a guest post byShawn Hsiao,Luke Massa, andVictor Luu. Shawn
runsTripAdvisor's Technical Operations team, Luke and Victor interned on his
team this past summer. This post is introduced byAndy Gelfond, TripAdvisor's
head of engineering.It's been a little over a year since our last post about
theTripAdvisor architecture. It has been an exciting year. Our business and
team continues to grow, we are now an independent public company, and we have
continued to keep/scale our development process and culture as we have grown -
we still run dozens of independent teams, and each team continues to work
across the entire stack. All that has changed are the numbers:56M visitors per
month350M+ pages requests a day120TB+ of warehouse data running on a large
Hadoop cluster, and quickly growingWe also had a very successful college
intern program that brought on over 60 interns this past summer, all who were
quickly on boarded and doing the same kind of work as our full time
engineers.One recurri</p><p>6 0.11277705 <a title="1296-tfidf-6" href="../high_scalability-2008/high_scalability-2008-05-03-Product%3A_nginx.html">314 high scalability-2008-05-03-Product: nginx</a></p>
<p>7 0.10966193 <a title="1296-tfidf-7" href="../high_scalability-2014/high_scalability-2014-04-14-How_do_you_even_do_anything_without_using_EBS%3F.html">1631 high scalability-2014-04-14-How do you even do anything without using EBS?</a></p>
<p>8 0.10297538 <a title="1296-tfidf-8" href="../high_scalability-2013/high_scalability-2013-12-02-Evolution_of_Bazaarvoice%E2%80%99s_Architecture_to_500M_Unique_Users_Per_Month.html">1557 high scalability-2013-12-02-Evolution of Bazaarvoiceâ€™s Architecture to 500M Unique Users Per Month</a></p>
<p>9 0.10117762 <a title="1296-tfidf-9" href="../high_scalability-2011/high_scalability-2011-12-12-Netflix%3A_Developing%2C_Deploying%2C_and_Supporting_Software_According_to_the_Way_of_the_Cloud.html">1155 high scalability-2011-12-12-Netflix: Developing, Deploying, and Supporting Software According to the Way of the Cloud</a></p>
<p>10 0.099652484 <a title="1296-tfidf-10" href="../high_scalability-2012/high_scalability-2012-12-21-Stuff_The_Internet_Says_On_Scalability_For_December_21%2C_2012.html">1375 high scalability-2012-12-21-Stuff The Internet Says On Scalability For December 21, 2012</a></p>
<p>11 0.097822085 <a title="1296-tfidf-11" href="../high_scalability-2012/high_scalability-2012-10-25-Not_All_Regions_are_Created_Equal_-_South_America_Es_Bueno.html">1347 high scalability-2012-10-25-Not All Regions are Created Equal - South America Es Bueno</a></p>
<p>12 0.096296445 <a title="1296-tfidf-12" href="../high_scalability-2012/high_scalability-2012-09-26-WordPress.com_Serves_70%2C000_req-sec_and_over_15_Gbit-sec_of_Traffic_using_NGINX.html">1329 high scalability-2012-09-26-WordPress.com Serves 70,000 req-sec and over 15 Gbit-sec of Traffic using NGINX</a></p>
<p>13 0.093320847 <a title="1296-tfidf-13" href="../high_scalability-2012/high_scalability-2012-11-01-Cost_Analysis%3A_TripAdvisor_and_Pinterest_costs_on_the_AWS_cloud.html">1353 high scalability-2012-11-01-Cost Analysis: TripAdvisor and Pinterest costs on the AWS cloud</a></p>
<p>14 0.091386035 <a title="1296-tfidf-14" href="../high_scalability-2008/high_scalability-2008-10-22-Server_load_balancing_architectures%2C_Part_2%3A_Application-level_load_balancing.html">427 high scalability-2008-10-22-Server load balancing architectures, Part 2: Application-level load balancing</a></p>
<p>15 0.085788026 <a title="1296-tfidf-15" href="../high_scalability-2010/high_scalability-2010-08-16-Scaling_an_AWS_infrastructure_-_Tools_and_Patterns.html">881 high scalability-2010-08-16-Scaling an AWS infrastructure - Tools and Patterns</a></p>
<p>16 0.084238276 <a title="1296-tfidf-16" href="../high_scalability-2012/high_scalability-2012-03-27-Big_Data_In_the_Cloud_Using_Cloudify.html">1216 high scalability-2012-03-27-Big Data In the Cloud Using Cloudify</a></p>
<p>17 0.083872594 <a title="1296-tfidf-17" href="../high_scalability-2013/high_scalability-2013-06-05-A_Simple_6_Step_Transition_Guide_for_Moving_Away_from_X_to_AWS_.html">1470 high scalability-2013-06-05-A Simple 6 Step Transition Guide for Moving Away from X to AWS </a></p>
<p>18 0.082427822 <a title="1296-tfidf-18" href="../high_scalability-2013/high_scalability-2013-09-16-The_Hidden_DNS_Tax_-_Cascading_Timeouts_and_Errors.html">1517 high scalability-2013-09-16-The Hidden DNS Tax - Cascading Timeouts and Errors</a></p>
<p>19 0.082315274 <a title="1296-tfidf-19" href="../high_scalability-2013/high_scalability-2013-06-24-Update_on_How_29_Cloud_Price_Drops_Changed_the_Bottom_Line_of_TripAdvisor_and_Pinterest_-_Results_Mixed.html">1480 high scalability-2013-06-24-Update on How 29 Cloud Price Drops Changed the Bottom Line of TripAdvisor and Pinterest - Results Mixed</a></p>
<p>20 0.08013469 <a title="1296-tfidf-20" href="../high_scalability-2011/high_scalability-2011-04-25-The_Big_List_of_Articles_on_the_Amazon_Outage.html">1029 high scalability-2011-04-25-The Big List of Articles on the Amazon Outage</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.11), (1, 0.035), (2, -0.043), (3, 0.002), (4, -0.069), (5, -0.085), (6, 0.027), (7, -0.115), (8, 0.053), (9, -0.069), (10, -0.011), (11, -0.029), (12, -0.009), (13, -0.06), (14, -0.058), (15, -0.041), (16, 0.068), (17, -0.006), (18, 0.051), (19, 0.029), (20, 0.015), (21, 0.007), (22, -0.039), (23, 0.004), (24, -0.033), (25, -0.026), (26, -0.032), (27, 0.038), (28, -0.009), (29, -0.035), (30, 0.006), (31, 0.053), (32, 0.004), (33, -0.002), (34, -0.025), (35, -0.003), (36, -0.03), (37, -0.057), (38, -0.053), (39, 0.005), (40, -0.009), (41, 0.023), (42, 0.023), (43, -0.003), (44, 0.071), (45, 0.023), (46, -0.006), (47, 0.011), (48, 0.017), (49, 0.003)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96817183 <a title="1296-lsi-1" href="../high_scalability-2012/high_scalability-2012-08-02-Strategy%3A_Use_Spare_Region_Capacity_to_Survive_Availability_Zone_Failures.html">1296 high scalability-2012-08-02-Strategy: Use Spare Region Capacity to Survive Availability Zone Failures</a></p>
<p>Introduction: In the wake of the recent Amazon problemsRyan Lackey offers some practical
first responder cloud survival advice:If you're a large site (particularly a
PaaS) on AWS and care about availability, you need to have spare capacity in
your region (using Reserve Instances, like Netflix does) to cover when a
single AZ disappears, and your own external to AWS load balancing (not DNS
based), with your own per-AZ subsidiary load balancers (nginx or whatever)
running within EC2.You need a robust database layer, ideally multi-region or
AWS + nonAWS, but that's more site specific. Going multiregion is the next
step, and the above is an essential part of getting to that point.</p><p>2 0.77904648 <a title="1296-lsi-2" href="../high_scalability-2013/high_scalability-2013-11-05-10_Things_You_Should_Know_About_AWS.html">1543 high scalability-2013-11-05-10 Things You Should Know About AWS</a></p>
<p>Introduction: Authored by Chris Fregly:  Former Netflix Streaming Platform Engineer, AWS
Certified Solution Architect and Purveyor of fluxcapacitor.com.Ahead of the
upcoming 2nd annual re:Invent conference, inspired by Simone Brunozzi's
recentpresentationat an AWS Meetup in San Francisco, and collected from a few
of my recentFluxcapacitor.com consulting engagements, I've compiled a list of
10 useful time and clock-tick saving tips about AWS.1) Query AWS resource
metadata Can't remember the EBS-Optimized IO throughput of your c1.xlarge
cluster?  How about the size limit of an S3 object on a single PUT?
awsnow.infois the answer to all of your AWS-resource metadata questions.
Interested in integrating awsnow.info with your application?  You're in luck.
There's now aREST API, as well!Note:  These are default soft limits and will
vary by account.2) Tame your S3 buckets Delete an entire S3 bucket with a
single CLI command:  aws s3 rb s3://\--forceRecursively copy a
local directory to S3:aws</p><p>3 0.70304424 <a title="1296-lsi-3" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>Introduction: This is a guest post byShawn Hsiao,Luke Massa, andVictor Luu. Shawn
runsTripAdvisor's Technical Operations team, Luke and Victor interned on his
team this past summer. This post is introduced byAndy Gelfond, TripAdvisor's
head of engineering.It's been a little over a year since our last post about
theTripAdvisor architecture. It has been an exciting year. Our business and
team continues to grow, we are now an independent public company, and we have
continued to keep/scale our development process and culture as we have grown -
we still run dozens of independent teams, and each team continues to work
across the entire stack. All that has changed are the numbers:56M visitors per
month350M+ pages requests a day120TB+ of warehouse data running on a large
Hadoop cluster, and quickly growingWe also had a very successful college
intern program that brought on over 60 interns this past summer, all who were
quickly on boarded and doing the same kind of work as our full time
engineers.One recurri</p><p>4 0.69479221 <a title="1296-lsi-4" href="../high_scalability-2007/high_scalability-2007-10-30-Feedblendr_Architecture_-_Using_EC2_to_Scale.html">138 high scalability-2007-10-30-Feedblendr Architecture - Using EC2 to Scale</a></p>
<p>Introduction: A man had a dream. His dream was to blend a bunch of RSS/Atom/RDF feeds into a
single feed. The man is Beau Lebens ofFeedvilleand like most dreamers he was a
little short on coin. So he took refuge in the home of a cheap hosting
provider and Beau realized his dream, creatingFEEDblendr. But FEEDblendr
chewed up so much CPU creating blended feeds that the cheap hosting provider
ordered Beau to find another home. Where was Beau to go? He eventually found a
new home in the virtual machine room of Amazon's EC2. This is the story of how
Beau was finally able to create his one feeds safe within the cradle of
affordable CPU cycles.Site: http://feedblendr.com/The PlatformEC2 (Fedora Core
6 Lite distro)S3ApachePHPMySQLDynDNS (for round robin DNS)The StatsBeau is a
developer with some sysadmin skills, not a web server admin, so a lot of
learning was involved in creating FEEDblendr.FEEDblendr uses 2 EC2 instances.
The same Amazon Instance (AMI) is used for both instances.Over 10,000 blends
have be</p><p>5 0.6892727 <a title="1296-lsi-5" href="../high_scalability-2012/high_scalability-2012-10-18-Save_up_to_30%25_by_Selecting_Better_Performing_Amazon_Instances.html">1343 high scalability-2012-10-18-Save up to 30% by Selecting Better Performing Amazon Instances</a></p>
<p>Introduction: If you like the idea of exploiting market inconsistencies to lower your costs
then you will love thispaperand video from the Hot Cloud '12
conference:Exploiting Hardware Heterogeneity within the Same Instance Type of
Amazon EC2.The conclusion is interesting and is a source of good
guidance:Amazon EC2 uses diversified hardware to host the same type of
instance.  The hardware diversity results in performance variation.In general,
the variation between the fast instances and slow  instances can reach 40%. In
some applications, the variation can even approach up to 60%.  By selecting
fast instances within the same instance type,  Amazon EC2 users can acquire up
to 30% of cost saving, if the fast instances have a relatively low
probability.The abstract:Cloud computing providers might start with near-
homogeneous hardware environment. Over time, the homogeneous environment will
most likely evolve into heterogeneous one because of possible upgrades and
replacement of outdated hardware. In tur</p><p>6 0.68390554 <a title="1296-lsi-6" href="../high_scalability-2012/high_scalability-2012-07-18-Strategy%3A_Kill_Off_Multi-tenant_Instances_with_High_CPU_Stolen_Time.html">1286 high scalability-2012-07-18-Strategy: Kill Off Multi-tenant Instances with High CPU Stolen Time</a></p>
<p>7 0.67951179 <a title="1296-lsi-7" href="../high_scalability-2011/high_scalability-2011-12-28-Strategy%3A_Guaranteed_Availability_Requires_Reserving_Instances_in_Specific_Zones.html">1165 high scalability-2011-12-28-Strategy: Guaranteed Availability Requires Reserving Instances in Specific Zones</a></p>
<p>8 0.67842108 <a title="1296-lsi-8" href="../high_scalability-2011/high_scalability-2011-06-13-Automation_on_AWS_with_Ruby_and_Puppet.html">1058 high scalability-2011-06-13-Automation on AWS with Ruby and Puppet</a></p>
<p>9 0.67503113 <a title="1296-lsi-9" href="../high_scalability-2012/high_scalability-2012-10-25-Not_All_Regions_are_Created_Equal_-_South_America_Es_Bueno.html">1347 high scalability-2012-10-25-Not All Regions are Created Equal - South America Es Bueno</a></p>
<p>10 0.6713466 <a title="1296-lsi-10" href="../high_scalability-2010/high_scalability-2010-04-19-Strategy%3A_Order_Two_Mediums_Instead_of_Two_Smalls_and_the_EC2_Buffet.html">812 high scalability-2010-04-19-Strategy: Order Two Mediums Instead of Two Smalls and the EC2 Buffet</a></p>
<p>11 0.66775274 <a title="1296-lsi-11" href="../high_scalability-2008/high_scalability-2008-03-27-Amazon_Announces_Static_IP_Addresses_and_Multiple_Datacenter_Operation.html">289 high scalability-2008-03-27-Amazon Announces Static IP Addresses and Multiple Datacenter Operation</a></p>
<p>12 0.64338028 <a title="1296-lsi-12" href="../high_scalability-2012/high_scalability-2012-12-12-Pinterest_Cut_Costs_from_%2454_to_%2420_Per_Hour_by_Automatically_Shutting_Down_Systems.html">1371 high scalability-2012-12-12-Pinterest Cut Costs from $54 to $20 Per Hour by Automatically Shutting Down Systems</a></p>
<p>13 0.63318956 <a title="1296-lsi-13" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>14 0.62860012 <a title="1296-lsi-14" href="../high_scalability-2011/high_scalability-2011-10-27-Strategy%3A_Survive_a_Comet_Strike_in_the_East_With_Reserved_Instances_in_the_West.html">1133 high scalability-2011-10-27-Strategy: Survive a Comet Strike in the East With Reserved Instances in the West</a></p>
<p>15 0.62797028 <a title="1296-lsi-15" href="../high_scalability-2014/high_scalability-2014-04-14-How_do_you_even_do_anything_without_using_EBS%3F.html">1631 high scalability-2014-04-14-How do you even do anything without using EBS?</a></p>
<p>16 0.61971712 <a title="1296-lsi-16" href="../high_scalability-2013/high_scalability-2013-06-05-A_Simple_6_Step_Transition_Guide_for_Moving_Away_from_X_to_AWS_.html">1470 high scalability-2013-06-05-A Simple 6 Step Transition Guide for Moving Away from X to AWS </a></p>
<p>17 0.61195385 <a title="1296-lsi-17" href="../high_scalability-2012/high_scalability-2012-05-21-Pinterest_Architecture_Update_-_18_Million_Visitors%2C_10x_Growth%2C12_Employees%2C_410_TB_of_Data.html">1248 high scalability-2012-05-21-Pinterest Architecture Update - 18 Million Visitors, 10x Growth,12 Employees, 410 TB of Data</a></p>
<p>18 0.59686977 <a title="1296-lsi-18" href="../high_scalability-2011/high_scalability-2011-12-12-Netflix%3A_Developing%2C_Deploying%2C_and_Supporting_Software_According_to_the_Way_of_the_Cloud.html">1155 high scalability-2011-12-12-Netflix: Developing, Deploying, and Supporting Software According to the Way of the Cloud</a></p>
<p>19 0.59115303 <a title="1296-lsi-19" href="../high_scalability-2012/high_scalability-2012-02-06-The_Design_of_99designs_-_A_Clean_Tens_of_Millions_Pageviews_Architecture.html">1188 high scalability-2012-02-06-The Design of 99designs - A Clean Tens of Millions Pageviews Architecture</a></p>
<p>20 0.58761793 <a title="1296-lsi-20" href="../high_scalability-2007/high_scalability-2007-10-08-Paper%3A_Understanding_and_Building_High_Availability-Load_Balanced_Clusters.html">117 high scalability-2007-10-08-Paper: Understanding and Building High Availability-Load Balanced Clusters</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.04), (2, 0.237), (10, 0.132), (61, 0.104), (65, 0.253), (94, 0.104)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.84616411 <a title="1296-lda-1" href="../high_scalability-2008/high_scalability-2008-01-30-The_AOL_XMPP_scalability_challenge.html">234 high scalability-2008-01-30-The AOL XMPP scalability challenge</a></p>
<p>Introduction: Large scale distributed instant messaging, presence based protocol are a real
challenge. With big players adopting the standard, the XMPP (eXtensible
Messaging and Presence Protocol) community is facing the need to validate
protocol and implementations to even larger scale.</p><p>2 0.83894938 <a title="1296-lda-2" href="../high_scalability-2008/high_scalability-2008-12-09-Rules_of_Thumb_in_Data_Engineering.html">463 high scalability-2008-12-09-Rules of Thumb in Data Engineering</a></p>
<p>Introduction: This is an interesting and still relevant research paper by Jim Gray, Prashant
Shenoy at Microsoft Research that examines the rules of thumb for the design
of data storage systems. It looks at storage, processing, and networking
costs, ratios, and trends with a particular focus on performance and
price/performance.Jim Gray has an updated presentation on this interesting
topic:Long Term Storage Trends and You. Robin Harris has a great post that
reflects on the Rules of Thumb whitepaper on his StorageMojo blog:Architecting
the Internet Data Center - Parts I-IV.</p><p>same-blog 3 0.83870852 <a title="1296-lda-3" href="../high_scalability-2012/high_scalability-2012-08-02-Strategy%3A_Use_Spare_Region_Capacity_to_Survive_Availability_Zone_Failures.html">1296 high scalability-2012-08-02-Strategy: Use Spare Region Capacity to Survive Availability Zone Failures</a></p>
<p>Introduction: In the wake of the recent Amazon problemsRyan Lackey offers some practical
first responder cloud survival advice:If you're a large site (particularly a
PaaS) on AWS and care about availability, you need to have spare capacity in
your region (using Reserve Instances, like Netflix does) to cover when a
single AZ disappears, and your own external to AWS load balancing (not DNS
based), with your own per-AZ subsidiary load balancers (nginx or whatever)
running within EC2.You need a robust database layer, ideally multi-region or
AWS + nonAWS, but that's more site specific. Going multiregion is the next
step, and the above is an essential part of getting to that point.</p><p>4 0.78325135 <a title="1296-lda-4" href="../high_scalability-2010/high_scalability-2010-03-26-Strategy%3A_Caching_404s_Saved_the_Onion_66%25_on_Server_Time.html">800 high scalability-2010-03-26-Strategy: Caching 404s Saved the Onion 66% on Server Time</a></p>
<p>Introduction: In the articleThe Onion Uses Django, And Why It Matters To Us, a lot of
interesting points are made about their ambitious infrastructure move from
Drupal/PHP to Django/Python: the move wasn't that hard, it just took time and
work because of their previous experience moving the A.V. Club website; churn
in core framework APIs make it more attractive to move than stay; supporting
the structure of older versions of the site is an unsolved problem; the built-
in Django admin saved a lot of work; group development is easier with "fewer
specialized or hacked together pieces"; they use IRC for distributed
development; sphinx for full-text search; nginx is the media server and
reverse proxy; haproxy made the launch process a 5 second procedure;
capistrano for deployment; clean component separation makes moving easier; Git
for version control; ORM with complicated querysets is a performance problem;
memcached for caching rendered pages; the CDN checks for updates every 10
minutes; videos, articl</p><p>5 0.7713908 <a title="1296-lda-5" href="../high_scalability-2007/high_scalability-2007-11-17-Can_How_Bees_Solve_their_Load_Balancing_Problems_Help_Build_More_Scalable_Websites%3F.html">158 high scalability-2007-11-17-Can How Bees Solve their Load Balancing Problems Help Build More Scalable Websites?</a></p>
<p>Introduction: Bees have a similar problem to website servers: how to do a lot of work with
limited resources in an ever changing environment. Usually lessons from
biology are hard to apply to computer problems. Nature throws hardware at
problems. Billions and billions of cells cooperate at different levels of
organizations to find food, fight lions, and make sure your DNA is passed
on.Nature's software is "simple," but her hardware rocks. We do the opposite.
For us hardware is in short supply so we use limited hardware and leverage
"smart" software to work around our inability to throw hardware at problems.
But we might be able to borrow some load balancing techniques from bees. What
do bees do that we can learn from?Bees do a dance to indicate the quality and
location of a nectar source. When a bee finds a better source they do a better
dance and resources shift to the new location. This approach may seem
inefficient, but it turns out to be "optimal for the unpredictable nectar
world." Craig Tovey</p><p>6 0.74398053 <a title="1296-lda-6" href="../high_scalability-2014/high_scalability-2014-01-17-Stuff_The_Internet_Says_On_Scalability_For_January_17th%2C_2014.html">1581 high scalability-2014-01-17-Stuff The Internet Says On Scalability For January 17th, 2014</a></p>
<p>7 0.73199904 <a title="1296-lda-7" href="../high_scalability-2009/high_scalability-2009-08-28-Strategy%3A_Solve_Only_80_Percent_of_the_Problem.html">689 high scalability-2009-08-28-Strategy: Solve Only 80 Percent of the Problem</a></p>
<p>8 0.73068392 <a title="1296-lda-8" href="../high_scalability-2012/high_scalability-2012-12-17-11_Uses_For_the_Humble_Presents_Queue%2C_er%2C_Message_Queue.html">1373 high scalability-2012-12-17-11 Uses For the Humble Presents Queue, er, Message Queue</a></p>
<p>9 0.72579288 <a title="1296-lda-9" href="../high_scalability-2008/high_scalability-2008-03-08-Audiogalaxy.com_Architecture.html">269 high scalability-2008-03-08-Audiogalaxy.com Architecture</a></p>
<p>10 0.72007143 <a title="1296-lda-10" href="../high_scalability-2013/high_scalability-2013-07-08-The_Architecture_Twitter_Uses_to_Deal_with_150M_Active_Users%2C_300K_QPS%2C_a_22_MB-S_Firehose%2C_and_Send_Tweets_in_Under_5_Seconds.html">1488 high scalability-2013-07-08-The Architecture Twitter Uses to Deal with 150M Active Users, 300K QPS, a 22 MB-S Firehose, and Send Tweets in Under 5 Seconds</a></p>
<p>11 0.71836895 <a title="1296-lda-11" href="../high_scalability-2012/high_scalability-2012-11-30-Stuff_The_Internet_Says_On_Scalability_For_November_30%2C_2012.html">1365 high scalability-2012-11-30-Stuff The Internet Says On Scalability For November 30, 2012</a></p>
<p>12 0.71088451 <a title="1296-lda-12" href="../high_scalability-2012/high_scalability-2012-01-10-A_Perfect_Fifth_of_Notes_on_Scalability.html">1172 high scalability-2012-01-10-A Perfect Fifth of Notes on Scalability</a></p>
<p>13 0.70538187 <a title="1296-lda-13" href="../high_scalability-2009/high_scalability-2009-04-21-Thread_Pool_Engine_in_MS_CLR_4%2C_and_Work-Stealing_scheduling_algorithm.html">575 high scalability-2009-04-21-Thread Pool Engine in MS CLR 4, and Work-Stealing scheduling algorithm</a></p>
<p>14 0.69937319 <a title="1296-lda-14" href="../high_scalability-2011/high_scalability-2011-03-14-Twitter_by_the_Numbers_-_460%2C000_New_Accounts_and_140_Million_Tweets_Per_Day.html">1004 high scalability-2011-03-14-Twitter by the Numbers - 460,000 New Accounts and 140 Million Tweets Per Day</a></p>
<p>15 0.69205803 <a title="1296-lda-15" href="../high_scalability-2007/high_scalability-2007-10-03-Save_on_a_Load_Balancer_By_Using_Client_Side_Load_Balancing.html">109 high scalability-2007-10-03-Save on a Load Balancer By Using Client Side Load Balancing</a></p>
<p>16 0.68954241 <a title="1296-lda-16" href="../high_scalability-2012/high_scalability-2012-05-11-Stuff_The_Internet_Says_On_Scalability_For_May_11%2C_2012.html">1244 high scalability-2012-05-11-Stuff The Internet Says On Scalability For May 11, 2012</a></p>
<p>17 0.68910486 <a title="1296-lda-17" href="../high_scalability-2009/high_scalability-2009-09-12-How_Google_Taught_Me_to_Cache_and_Cash-In.html">703 high scalability-2009-09-12-How Google Taught Me to Cache and Cash-In</a></p>
<p>18 0.68328404 <a title="1296-lda-18" href="../high_scalability-2010/high_scalability-2010-11-16-Facebook%27s_New_Real-time_Messaging_System%3A_HBase_to_Store_135%2B_Billion_Messages_a_Month.html">943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</a></p>
<p>19 0.68179935 <a title="1296-lda-19" href="../high_scalability-2010/high_scalability-2010-09-23-Working_With_Large_Data_Sets.html">907 high scalability-2010-09-23-Working With Large Data Sets</a></p>
<p>20 0.68163973 <a title="1296-lda-20" href="../high_scalability-2013/high_scalability-2013-02-15-Stuff_The_Internet_Says_On_Scalability_For_February_15%2C_2013.html">1407 high scalability-2013-02-15-Stuff The Internet Says On Scalability For February 15, 2013</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
