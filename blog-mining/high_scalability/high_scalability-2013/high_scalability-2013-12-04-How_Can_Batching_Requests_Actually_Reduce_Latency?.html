<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1558 high scalability-2013-12-04-How Can Batching Requests Actually Reduce Latency?</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2013" href="../home/high_scalability-2013_home.html">high_scalability-2013</a> <a title="high_scalability-2013-1558" href="#">high_scalability-2013-1558</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1558 high scalability-2013-12-04-How Can Batching Requests Actually Reduce Latency?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2013-1558-html" href="http://highscalability.com//blog/2013/12/4/how-can-batching-requests-actually-reduce-latency.html">html</a></p><p>Introduction: Jeremy Edberg gave a talk on Scaling Reddit from 1 Million to 1 Billion-
Pitfalls and Lessons andone of the issuesthey had was that they:Did not
account for increased latency after moving to EC2. In the datacenter they had
submillisecond access between machines so it was possible to make a 1000 calls
to memache for one page load. Not so on EC2. Memcache access times increased
10x to a millisecond which made their old approach unusable. Fix was to batch
calls to memcache so a large number of gets are in one request.Dave Pacheco
had aninteresting questionabout batching requests and its impact on latency:I
was confused about the memcached problem after moving to the cloud. I
understand why network latency may have gone from submillisecond to
milliseconds, but how could you improve latency by batching requests?
Shouldn't that improve efficiency, not latency, at the possible expense of
latency (since some requests will wait on the client as they get batched)?
Jeremy cleared it up by saying:</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Jeremy Edberg gave a talk on Scaling Reddit from 1 Million to 1 Billion- Pitfalls and Lessons andone of the issuesthey had was that they:Did not account for increased latency after moving to EC2. [sent-1, score-0.709]
</p><p>2 In the datacenter they had submillisecond access between machines so it was possible to make a 1000 calls to memache for one page load. [sent-2, score-0.948]
</p><p>3 Memcache access times increased 10x to a millisecond which made their old approach unusable. [sent-4, score-0.375]
</p><p>4 Fix was to batch calls to memcache so a large number of gets are in one request. [sent-5, score-0.622]
</p><p>5 Dave Pacheco had aninteresting questionabout batching requests and its impact on latency:I was confused about the memcached problem after moving to the cloud. [sent-6, score-1.1]
</p><p>6 I understand why network latency may have gone from submillisecond to milliseconds, but how could you improve latency by batching requests? [sent-7, score-1.522]
</p><p>7 Shouldn't that improve efficiency, not latency, at the possible expense of latency (since some requests will wait on the client as they get batched)? [sent-8, score-0.819]
</p><p>8 Jeremy cleared it up by saying:The latency didn't get better, but what happened is that instead of having to make a lot of calls to memcache it was just one (well, just a few), so while that one took longer, the total time was much less. [sent-9, score-1.323]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('batching', 0.353), ('latency', 0.321), ('submillisecond', 0.281), ('memcache', 0.23), ('jeremy', 0.217), ('calls', 0.201), ('questionabout', 0.177), ('pacheco', 0.177), ('memache', 0.177), ('cleared', 0.166), ('rosenthal', 0.159), ('graphic', 0.144), ('edberg', 0.144), ('aninteresting', 0.141), ('batched', 0.141), ('requests', 0.135), ('increased', 0.131), ('pitfalls', 0.13), ('dave', 0.128), ('total', 0.126), ('confused', 0.126), ('millisecond', 0.115), ('moving', 0.108), ('improve', 0.107), ('expense', 0.104), ('decrease', 0.101), ('milliseconds', 0.099), ('reddit', 0.093), ('happened', 0.088), ('showing', 0.087), ('possible', 0.083), ('efficiency', 0.083), ('gone', 0.082), ('gave', 0.077), ('access', 0.076), ('saying', 0.075), ('account', 0.072), ('batch', 0.071), ('wait', 0.069), ('datacenter', 0.067), ('lessons', 0.065), ('took', 0.065), ('one', 0.063), ('fact', 0.062), ('impact', 0.06), ('fix', 0.06), ('longer', 0.058), ('understand', 0.057), ('gets', 0.057), ('old', 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1558-tfidf-1" href="../high_scalability-2013/high_scalability-2013-12-04-How_Can_Batching_Requests_Actually_Reduce_Latency%3F.html">1558 high scalability-2013-12-04-How Can Batching Requests Actually Reduce Latency?</a></p>
<p>Introduction: Jeremy Edberg gave a talk on Scaling Reddit from 1 Million to 1 Billion-
Pitfalls and Lessons andone of the issuesthey had was that they:Did not
account for increased latency after moving to EC2. In the datacenter they had
submillisecond access between machines so it was possible to make a 1000 calls
to memache for one page load. Not so on EC2. Memcache access times increased
10x to a millisecond which made their old approach unusable. Fix was to batch
calls to memcache so a large number of gets are in one request.Dave Pacheco
had aninteresting questionabout batching requests and its impact on latency:I
was confused about the memcached problem after moving to the cloud. I
understand why network latency may have gone from submillisecond to
milliseconds, but how could you improve latency by batching requests?
Shouldn't that improve efficiency, not latency, at the possible expense of
latency (since some requests will wait on the client as they get batched)?
Jeremy cleared it up by saying:</p><p>2 0.23715171 <a title="1558-tfidf-2" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>Introduction: Update 8:The Cost of Latency by James Hamilton. James summarizing some latency
info from Steve Souder,Greg Linden, andMarissa Mayer. Speed [is] an
undervalued and under-discussed asset on the web.Update 7:How do you know when
you need more memcache servers?. Dathan Pattishall talks about using memcache
not to scale, but to reduce latency and reduce I/O spikes, and how to use
stats to know when more servers are needed.Update 6:Stock Traders Find Speed
Pays, in Milliseconds. Goldman Sachs is making record profits off a500
millisecondtrading advantage. Yes, latency matters. As an interesting aside,
Libet found 500 msecs is about the time it takes the brain to weave together
an experience of consciousness from all our sensor inputs.Update 5:Shopzilla's
Site Redo - You Get What You Measure. At theVelocityconference Phil Dixon,
from Shopzilla, presented data showing a 5 second speed up resulted in a 25%
increase in page views, a 10% increase in revenue, a 50% reduction in
hardware, and a 120</p><p>3 0.1806062 <a title="1558-tfidf-3" href="../high_scalability-2013/high_scalability-2013-08-26-Reddit%3A_Lessons_Learned_from_Mistakes_Made_Scaling_to_1_Billion_Pageviews_a_Month.html">1507 high scalability-2013-08-26-Reddit: Lessons Learned from Mistakes Made Scaling to 1 Billion Pageviews a Month</a></p>
<p>Introduction: Jeremy Edberg, the first paid employee at reddit, teaches us a lot about how
to create a successful social site in a really good talk he gave at the RAMP
conference. Watch it here at Scaling Reddit from 1 Million to 1 Billion-
Pitfalls and Lessons.Jeremy uses a virtue and sin approach. Examples of the
mistakes made in scaling reddit are shared and it turns out they did a lot of
good stuff too. Somewhat of a shocker is that Jeremy is now a Reliability
Architect at Netflix, so we get a little Netflix perspective thrown in for
free.Some of the lessons that stood out most for me: Think of SSDs as cheap
RAM, not expensive disk. When reddit moved from spinning disks to SSDs for the
database the number of servers was reduced from 12 to 1 with a ton of
headroom. SSDs are 4x more expensive but you get 16x the performance. Worth
the cost. Give users a little bit of power, see what they do with it, and turn
the good stuff into features. One of the biggest revelations for me was how
much reddit le</p><p>4 0.16863942 <a title="1558-tfidf-4" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>Introduction: Likewise the current belief that, in the case of artificial machines the very
large and the very small are equally feasible and lasting is a manifest error.
Thus, for example, a small obelisk or column or other solid figure can
certainly be laid down or set up without danger of breaking, while the large
ones will go to pieces under the slightest provocation, and that purely on
account of their own weight. -- GalileoGalileo observed how things broke if
they were naively scaled up. Interestingly, Google noticed a similar pattern
when building larger software systems using the same techniques used to build
smaller systems. Luiz Andre Barroso, Distinguished Engineer at Google, talks
about this fundamental property of scaling systems in his fascinating talk,
Warehouse-Scale Computing: Entering the Teenage Decade. Google found the
larger the scale the greater the impact of latency variability. When a request
is implemented by work done in parallel, as is common with today's service
oriented</p><p>5 0.13819784 <a title="1558-tfidf-5" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>Introduction: InTaming The Long Latency Tailwe coveredLuiz Barroso's exploration of the long
tail latency (some operations are really slow) problems generated by large
fanout architectures (a request is composed of potentially thousands of other
requests). You may have noticed there weren't a lot of solutions. That's where
a talk I attended,Achieving Rapid Response Times in Large Online
Services(slide deck), byJeff Dean, also of Google, comes in:In this talk, I'll
describe a collection of techniques and practices lowering response times in
large distributed systems whose components run on shared clusters of machines,
where pieces of these systems are subject to interference by other tasks, and
where unpredictable latency hiccups are the norm, not the exception.The goal
is to use software techniques to reduce variability given the increasing
variability in underlying hardware, the need to handle dynamic workloads on a
shared infrastructure, and the need to use large fanout architectures to
operate at</p><p>6 0.12955335 <a title="1558-tfidf-6" href="../high_scalability-2011/high_scalability-2011-09-27-Use_Instance_Caches_to_Save_Money%3A_Latency_%3D%3D_%24%24%24.html">1126 high scalability-2011-09-27-Use Instance Caches to Save Money: Latency == $$$</a></p>
<p>7 0.12752306 <a title="1558-tfidf-7" href="../high_scalability-2011/high_scalability-2011-09-15-Paper%3A_It%27s_Time_for_Low_Latency_-_Inventing_the_1_Microsecond_Datacenter.html">1116 high scalability-2011-09-15-Paper: It's Time for Low Latency - Inventing the 1 Microsecond Datacenter</a></p>
<p>8 0.12081449 <a title="1558-tfidf-8" href="../high_scalability-2009/high_scalability-2009-01-04-Alternative_Memcache_Usage%3A_A_Highly_Scalable%2C_Highly_Available%2C_In-Memory_Shard_Index.html">482 high scalability-2009-01-04-Alternative Memcache Usage: A Highly Scalable, Highly Available, In-Memory Shard Index</a></p>
<p>9 0.11628993 <a title="1558-tfidf-9" href="../high_scalability-2011/high_scalability-2011-10-31-15_Ways_to_Make_Your_Application_Feel_More_Responsive_under_Google_App_Engine.html">1135 high scalability-2011-10-31-15 Ways to Make Your Application Feel More Responsive under Google App Engine</a></p>
<p>10 0.10559731 <a title="1558-tfidf-10" href="../high_scalability-2010/high_scalability-2010-06-01-Web_Speed_Can_Push_You_Off_of_Google_Search_Rankings%21_What_Can_You_Do%3F.html">834 high scalability-2010-06-01-Web Speed Can Push You Off of Google Search Rankings! What Can You Do?</a></p>
<p>11 0.10475584 <a title="1558-tfidf-11" href="../high_scalability-2013/high_scalability-2013-01-15-More_Numbers_Every_Awesome_Programmer_Must_Know.html">1387 high scalability-2013-01-15-More Numbers Every Awesome Programmer Must Know</a></p>
<p>12 0.10381208 <a title="1558-tfidf-12" href="../high_scalability-2010/high_scalability-2010-10-26-Marrying_memcached_and_NoSQL.html">927 high scalability-2010-10-26-Marrying memcached and NoSQL</a></p>
<p>13 0.094996162 <a title="1558-tfidf-13" href="../high_scalability-2014/high_scalability-2014-02-05-Little%E2%80%99s_Law%2C_Scalability_and_Fault_Tolerance%3A_The_OS_is_your_bottleneck._What_you_can_do%3F.html">1591 high scalability-2014-02-05-Little’s Law, Scalability and Fault Tolerance: The OS is your bottleneck. What you can do?</a></p>
<p>14 0.092279077 <a title="1558-tfidf-14" href="../high_scalability-2010/high_scalability-2010-05-17-7_Lessons_Learned_While_Building_Reddit_to_270_Million_Page_Views_a_Month.html">828 high scalability-2010-05-17-7 Lessons Learned While Building Reddit to 270 Million Page Views a Month</a></p>
<p>15 0.091556162 <a title="1558-tfidf-15" href="../high_scalability-2009/high_scalability-2009-10-26-Facebook%27s_Memcached_Multiget_Hole%3A_More_machines_%21%3D_More_Capacity_.html">728 high scalability-2009-10-26-Facebook's Memcached Multiget Hole: More machines != More Capacity </a></p>
<p>16 0.090670824 <a title="1558-tfidf-16" href="../high_scalability-2010/high_scalability-2010-12-20-Netflix%3A_Use_Less_Chatty_Protocols_in_the_Cloud_-_Plus_26_Fixes.html">960 high scalability-2010-12-20-Netflix: Use Less Chatty Protocols in the Cloud - Plus 26 Fixes</a></p>
<p>17 0.08970657 <a title="1558-tfidf-17" href="../high_scalability-2013/high_scalability-2013-03-04-7_Life_Saving_Scalability_Defenses_Against_Load_Monster_Attacks.html">1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</a></p>
<p>18 0.086578645 <a title="1558-tfidf-18" href="../high_scalability-2008/high_scalability-2008-04-01-How_to_update_video_views_count_effectively%3F.html">294 high scalability-2008-04-01-How to update video views count effectively?</a></p>
<p>19 0.083811767 <a title="1558-tfidf-19" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>20 0.082040444 <a title="1558-tfidf-20" href="../high_scalability-2009/high_scalability-2009-08-24-How_Google_Serves_Data_from_Multiple_Datacenters.html">687 high scalability-2009-08-24-How Google Serves Data from Multiple Datacenters</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.107), (1, 0.089), (2, -0.027), (3, -0.022), (4, -0.022), (5, -0.016), (6, 0.023), (7, 0.09), (8, -0.056), (9, -0.051), (10, 0.006), (11, -0.016), (12, -0.002), (13, 0.026), (14, -0.031), (15, 0.013), (16, -0.012), (17, -0.004), (18, 0.016), (19, -0.038), (20, 0.04), (21, 0.026), (22, 0.055), (23, -0.023), (24, -0.002), (25, 0.041), (26, -0.024), (27, 0.014), (28, -0.024), (29, -0.062), (30, 0.06), (31, -0.046), (32, -0.002), (33, 0.001), (34, 0.06), (35, 0.076), (36, 0.031), (37, -0.02), (38, -0.047), (39, -0.046), (40, 0.034), (41, 0.052), (42, -0.046), (43, -0.039), (44, 0.006), (45, -0.089), (46, 0.035), (47, -0.028), (48, -0.001), (49, -0.0)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98168099 <a title="1558-lsi-1" href="../high_scalability-2013/high_scalability-2013-12-04-How_Can_Batching_Requests_Actually_Reduce_Latency%3F.html">1558 high scalability-2013-12-04-How Can Batching Requests Actually Reduce Latency?</a></p>
<p>Introduction: Jeremy Edberg gave a talk on Scaling Reddit from 1 Million to 1 Billion-
Pitfalls and Lessons andone of the issuesthey had was that they:Did not
account for increased latency after moving to EC2. In the datacenter they had
submillisecond access between machines so it was possible to make a 1000 calls
to memache for one page load. Not so on EC2. Memcache access times increased
10x to a millisecond which made their old approach unusable. Fix was to batch
calls to memcache so a large number of gets are in one request.Dave Pacheco
had aninteresting questionabout batching requests and its impact on latency:I
was confused about the memcached problem after moving to the cloud. I
understand why network latency may have gone from submillisecond to
milliseconds, but how could you improve latency by batching requests?
Shouldn't that improve efficiency, not latency, at the possible expense of
latency (since some requests will wait on the client as they get batched)?
Jeremy cleared it up by saying:</p><p>2 0.79720539 <a title="1558-lsi-2" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>Introduction: Likewise the current belief that, in the case of artificial machines the very
large and the very small are equally feasible and lasting is a manifest error.
Thus, for example, a small obelisk or column or other solid figure can
certainly be laid down or set up without danger of breaking, while the large
ones will go to pieces under the slightest provocation, and that purely on
account of their own weight. -- GalileoGalileo observed how things broke if
they were naively scaled up. Interestingly, Google noticed a similar pattern
when building larger software systems using the same techniques used to build
smaller systems. Luiz Andre Barroso, Distinguished Engineer at Google, talks
about this fundamental property of scaling systems in his fascinating talk,
Warehouse-Scale Computing: Entering the Teenage Decade. Google found the
larger the scale the greater the impact of latency variability. When a request
is implemented by work done in parallel, as is common with today's service
oriented</p><p>3 0.75456923 <a title="1558-lsi-3" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>Introduction: InTaming The Long Latency Tailwe coveredLuiz Barroso's exploration of the long
tail latency (some operations are really slow) problems generated by large
fanout architectures (a request is composed of potentially thousands of other
requests). You may have noticed there weren't a lot of solutions. That's where
a talk I attended,Achieving Rapid Response Times in Large Online
Services(slide deck), byJeff Dean, also of Google, comes in:In this talk, I'll
describe a collection of techniques and practices lowering response times in
large distributed systems whose components run on shared clusters of machines,
where pieces of these systems are subject to interference by other tasks, and
where unpredictable latency hiccups are the norm, not the exception.The goal
is to use software techniques to reduce variability given the increasing
variability in underlying hardware, the need to handle dynamic workloads on a
shared infrastructure, and the need to use large fanout architectures to
operate at</p><p>4 0.74868709 <a title="1558-lsi-4" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>Introduction: Update 8:The Cost of Latency by James Hamilton. James summarizing some latency
info from Steve Souder,Greg Linden, andMarissa Mayer. Speed [is] an
undervalued and under-discussed asset on the web.Update 7:How do you know when
you need more memcache servers?. Dathan Pattishall talks about using memcache
not to scale, but to reduce latency and reduce I/O spikes, and how to use
stats to know when more servers are needed.Update 6:Stock Traders Find Speed
Pays, in Milliseconds. Goldman Sachs is making record profits off a500
millisecondtrading advantage. Yes, latency matters. As an interesting aside,
Libet found 500 msecs is about the time it takes the brain to weave together
an experience of consciousness from all our sensor inputs.Update 5:Shopzilla's
Site Redo - You Get What You Measure. At theVelocityconference Phil Dixon,
from Shopzilla, presented data showing a 5 second speed up resulted in a 25%
increase in page views, a 10% increase in revenue, a 50% reduction in
hardware, and a 120</p><p>5 0.70428109 <a title="1558-lsi-5" href="../high_scalability-2011/high_scalability-2011-09-15-Paper%3A_It%27s_Time_for_Low_Latency_-_Inventing_the_1_Microsecond_Datacenter.html">1116 high scalability-2011-09-15-Paper: It's Time for Low Latency - Inventing the 1 Microsecond Datacenter</a></p>
<p>Introduction: In It's Time for Low Latency  Stephen Rumble et al. explore the idea that it's
time to rearchitect our stack to live in the modern era of low-latency
datacenter instead of high-latency WANs. The implications for
programarchitectures will be revolutionary.  Luiz Andre Barroso, Distinguished
Engineer at Google, sees ultra low latency as a way to make computer
resources, to be as much as possible, fungible, that is they are
interchangeable and location independent, effectively turning a datacenter
into single computer. Abstract from the paper:The operating systems community
has ignored network latency for too long. In the past, speed-of-light delays
in wide area networks and unoptimized network hardware have made sub-100µs
round-trip times impossible. However, in the next few years datacenters will
be deployed with low-latency Ethernet. Without the burden of propagation
delays in the datacenter campus and network delays in the Ethernet devices, it
will be up to us to ﬁnish the job and see</p><p>6 0.67962152 <a title="1558-lsi-6" href="../high_scalability-2010/high_scalability-2010-11-15-Strategy%3A_Biggest_Performance_Impact_is_to_Reduce_the_Number_of_HTTP_Requests.html">942 high scalability-2010-11-15-Strategy: Biggest Performance Impact is to Reduce the Number of HTTP Requests</a></p>
<p>7 0.66444355 <a title="1558-lsi-7" href="../high_scalability-2013/high_scalability-2013-01-15-More_Numbers_Every_Awesome_Programmer_Must_Know.html">1387 high scalability-2013-01-15-More Numbers Every Awesome Programmer Must Know</a></p>
<p>8 0.64811933 <a title="1558-lsi-8" href="../high_scalability-2011/high_scalability-2011-02-01-Google_Strategy%3A_Tree_Distribution_of_Requests_and_Responses.html">981 high scalability-2011-02-01-Google Strategy: Tree Distribution of Requests and Responses</a></p>
<p>9 0.62838089 <a title="1558-lsi-9" href="../high_scalability-2010/high_scalability-2010-12-20-Netflix%3A_Use_Less_Chatty_Protocols_in_the_Cloud_-_Plus_26_Fixes.html">960 high scalability-2010-12-20-Netflix: Use Less Chatty Protocols in the Cloud - Plus 26 Fixes</a></p>
<p>10 0.59813613 <a title="1558-lsi-10" href="../high_scalability-2009/high_scalability-2009-10-01-Moving_Beyond_End-to-End_Path_Information_to_Optimize_CDN_Performance.html">712 high scalability-2009-10-01-Moving Beyond End-to-End Path Information to Optimize CDN Performance</a></p>
<p>11 0.59728575 <a title="1558-lsi-11" href="../high_scalability-2009/high_scalability-2009-10-26-Facebook%27s_Memcached_Multiget_Hole%3A_More_machines_%21%3D_More_Capacity_.html">728 high scalability-2009-10-26-Facebook's Memcached Multiget Hole: More machines != More Capacity </a></p>
<p>12 0.58181113 <a title="1558-lsi-12" href="../high_scalability-2011/high_scalability-2011-06-01-Why_is_your_network_so_slow%3F_Your_switch_should_tell_you..html">1051 high scalability-2011-06-01-Why is your network so slow? Your switch should tell you.</a></p>
<p>13 0.57653779 <a title="1558-lsi-13" href="../high_scalability-2010/high_scalability-2010-11-22-Strategy%3A_Google_Sends_Canary_Requests_into_the_Data_Mine.html">946 high scalability-2010-11-22-Strategy: Google Sends Canary Requests into the Data Mine</a></p>
<p>14 0.56865126 <a title="1558-lsi-14" href="../high_scalability-2009/high_scalability-2009-06-30-Hot_New_Trend%3A_Linking_Clouds_Through_Cheap_IP_VPNs_Instead_of_Private_Lines_.html">645 high scalability-2009-06-30-Hot New Trend: Linking Clouds Through Cheap IP VPNs Instead of Private Lines </a></p>
<p>15 0.56646973 <a title="1558-lsi-15" href="../high_scalability-2010/high_scalability-2010-11-15-How_Google%27s_Instant_Previews_Reduces_HTTP_Requests.html">941 high scalability-2010-11-15-How Google's Instant Previews Reduces HTTP Requests</a></p>
<p>16 0.55610973 <a title="1558-lsi-16" href="../high_scalability-2011/high_scalability-2011-10-31-15_Ways_to_Make_Your_Application_Feel_More_Responsive_under_Google_App_Engine.html">1135 high scalability-2011-10-31-15 Ways to Make Your Application Feel More Responsive under Google App Engine</a></p>
<p>17 0.55516249 <a title="1558-lsi-17" href="../high_scalability-2012/high_scalability-2012-06-18-The_Clever_Ways_Chrome_Hides_Latency_by_Anticipating_Your_Every_Need.html">1267 high scalability-2012-06-18-The Clever Ways Chrome Hides Latency by Anticipating Your Every Need</a></p>
<p>18 0.5512659 <a title="1558-lsi-18" href="../high_scalability-2013/high_scalability-2013-02-11-At_Scale_Even_Little_Wins_Pay_Off_Big_-_Google_and_Facebook_Examples.html">1404 high scalability-2013-02-11-At Scale Even Little Wins Pay Off Big - Google and Facebook Examples</a></p>
<p>19 0.54899371 <a title="1558-lsi-19" href="../high_scalability-2011/high_scalability-2011-03-09-Google_and_Netflix_Strategy%3A_Use_Partial_Responses_to_Reduce_Request_Sizes.html">1001 high scalability-2011-03-09-Google and Netflix Strategy: Use Partial Responses to Reduce Request Sizes</a></p>
<p>20 0.54896843 <a title="1558-lsi-20" href="../high_scalability-2008/high_scalability-2008-01-10-Letting_Clients_Know_What%27s_Changed%3A_Push_Me_or_Pull_Me%3F.html">205 high scalability-2008-01-10-Letting Clients Know What's Changed: Push Me or Pull Me?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.298), (16, 0.313), (40, 0.025), (61, 0.059), (77, 0.024), (79, 0.157)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94416314 <a title="1558-lda-1" href="../high_scalability-2007/high_scalability-2007-10-03-Why_most_large-scale_Web_sites_are_not_written_in_Java.html">110 high scalability-2007-10-03-Why most large-scale Web sites are not written in Java</a></p>
<p>Introduction: Thereis alot ofinformation in the blogosphere describing the architecture of
many popular sites, such as Google, Amazon, eBay, LinkedIn, TypePad, WikiPedia
and others.I've summarized this issue in a blog posthereI would really
appreciate your opinion on this matter.</p><p>same-blog 2 0.88684076 <a title="1558-lda-2" href="../high_scalability-2013/high_scalability-2013-12-04-How_Can_Batching_Requests_Actually_Reduce_Latency%3F.html">1558 high scalability-2013-12-04-How Can Batching Requests Actually Reduce Latency?</a></p>
<p>Introduction: Jeremy Edberg gave a talk on Scaling Reddit from 1 Million to 1 Billion-
Pitfalls and Lessons andone of the issuesthey had was that they:Did not
account for increased latency after moving to EC2. In the datacenter they had
submillisecond access between machines so it was possible to make a 1000 calls
to memache for one page load. Not so on EC2. Memcache access times increased
10x to a millisecond which made their old approach unusable. Fix was to batch
calls to memcache so a large number of gets are in one request.Dave Pacheco
had aninteresting questionabout batching requests and its impact on latency:I
was confused about the memcached problem after moving to the cloud. I
understand why network latency may have gone from submillisecond to
milliseconds, but how could you improve latency by batching requests?
Shouldn't that improve efficiency, not latency, at the possible expense of
latency (since some requests will wait on the client as they get batched)?
Jeremy cleared it up by saying:</p><p>3 0.83213621 <a title="1558-lda-3" href="../high_scalability-2011/high_scalability-2011-07-20-Netflix%3A_Harden_Systems_Using_a_Barrel_of_Problem_Causing_Monkeys_-_Latency%2C_Conformity%2C_Doctor%2C_Janitor%2C_Security%2C_Internationalization%2C_Chaos.html">1083 high scalability-2011-07-20-Netflix: Harden Systems Using a Barrel of Problem Causing Monkeys - Latency, Conformity, Doctor, Janitor, Security, Internationalization, Chaos</a></p>
<p>Introduction: With a new Planet of the Apes coming out, this may be a touchy subject with
our new overlords, but Netflix is using a whole lot more trouble injecting
monkeys to test and iteratively harden their systems. We learned previously
how Netflix used Chaos Monkey, a tool to test failover handling by
continuously failing EC2 nodes. That was just a start. More monkeys have been
added to the barrel. Node failure is just one problem in a system. Imagine a
problem and you can imagine creating a monkey to test if your system is
handling that problem properly. Yury Izrailevsky talks about just this
approach in this very interesting post: The Netflix Simian Army.I know what
you are thinking, if monkeys are so great then why has Netflix been down
lately. Dmuino addressedthis potential embarrassment, putting all fears of
cloud inferiority to rest:Unfortunately we're not running 100% on the cloud
today. We're working on it, and we could use more help. The latest outage was
caused by a component that sti</p><p>4 0.7676971 <a title="1558-lda-4" href="../high_scalability-2011/high_scalability-2011-07-01-Stuff_The_Internet_Says_On_Scalability_For_July_1%2C_2011.html">1071 high scalability-2011-07-01-Stuff The Internet Says On Scalability For July 1, 2011</a></p>
<p>Introduction: Submitted for your scaling pleasure: Twitterers tweet 200 million tweetsa day.
Popular topics are eclectic, ranging from Swine Flu to Rebecca Black. Twitter
has a really cool video on the global flow oftweets in the world. Worth
watching. It looks like a rainbow arcing across the northern hemisphere.Amazon
Cloud Now Stores 339 Billion Objects, more than doubling last years volume.
Quotable quotes for independence Alex:n8foo: My fav part about the new #AWS
pricing announcement - 500TB is the level where they say 'contact
us'.RoeyYaniv: Scalability guidelines - Technology can and will fail. The
business should not. stevedekorte: Are the folks advocating FP for scalability
unaware of the Von Neumann bottleneck?nivertech: #Hadoop is a guy with a
machete in front of a jungle - it made a trail, but there are new better
#BigData middleware offerings in the junglelhazlewood: I don't think I've ever
had a Love/Hate relationship like I've had with NoSQL. It's all awesome. And
it all sucks.dmccre</p><p>5 0.76154363 <a title="1558-lda-5" href="../high_scalability-2014/high_scalability-2014-01-14-Ask_HS%3A_Design_and_Implementation_of_scalable_services%3F.html">1578 high scalability-2014-01-14-Ask HS: Design and Implementation of scalable services?</a></p>
<p>Introduction: We have written agents deployed/distributed across the network. Agents sends
data every 15 Secs may be even 5 secs. Working on a service/system to which
all agent can post data/tuples with marginal payload. Upto 5% drop rate is
acceptable. Ultimately the data will be segregated and stored into DBMS System
(currently we are using MSQL).Question(s) I am looking for answer1.
Client/Server Communication: Agent(s) can post data. Status of sending data is
not that important. But there is a remote where Agent(s) to be notified if the
server side system generates an event based on the data sent.- Lot of advices
from internet suggests using Message Bus (ActiveMQ) for async communication.
Multicast and UDP are the alternatives.2. Persistence: After some evaluation
data to be stored in DBMS System.- End of processing data is an aggregated
record for which MySql looks scalable. But on the volume of data is
exponential. Considering HBase as an option.Looking if there are any
alternatives for above</p><p>6 0.72343475 <a title="1558-lda-6" href="../high_scalability-2008/high_scalability-2008-01-29-Speed_up_%28Oracle%29_database_code_with_result_caching.html">230 high scalability-2008-01-29-Speed up (Oracle) database code with result caching</a></p>
<p>7 0.71731806 <a title="1558-lda-7" href="../high_scalability-2008/high_scalability-2008-09-23-Event%3A_CloudCamp_Silicon_Valley_Unconference_on_30th_September.html">388 high scalability-2008-09-23-Event: CloudCamp Silicon Valley Unconference on 30th September</a></p>
<p>8 0.71233636 <a title="1558-lda-8" href="../high_scalability-2010/high_scalability-2010-07-20-Strategy%3A_Consider_When_a_Service_Starts_Billing_in_Your_Algorithm_Cost.html">862 high scalability-2010-07-20-Strategy: Consider When a Service Starts Billing in Your Algorithm Cost</a></p>
<p>9 0.7087878 <a title="1558-lda-9" href="../high_scalability-2014/high_scalability-2014-04-30-10_Tips_for_Optimizing_NGINX_and_PHP-fpm_for_High_Traffic_Sites.html">1640 high scalability-2014-04-30-10 Tips for Optimizing NGINX and PHP-fpm for High Traffic Sites</a></p>
<p>10 0.70476025 <a title="1558-lda-10" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>11 0.70162129 <a title="1558-lda-11" href="../high_scalability-2008/high_scalability-2008-02-18-limit_on_the_number_of_databases_open.html">252 high scalability-2008-02-18-limit on the number of databases open</a></p>
<p>12 0.70078605 <a title="1558-lda-12" href="../high_scalability-2008/high_scalability-2008-02-03-Ideas_on_how_to_scale_a_shared_inventory_database%3F%3F%3F.html">236 high scalability-2008-02-03-Ideas on how to scale a shared inventory database???</a></p>
<p>13 0.70070499 <a title="1558-lda-13" href="../high_scalability-2009/high_scalability-2009-06-05-SSL_RPC_API_Scalability.html">620 high scalability-2009-06-05-SSL RPC API Scalability</a></p>
<p>14 0.69942343 <a title="1558-lda-14" href="../high_scalability-2011/high_scalability-2011-04-06-Netflix%3A_Run_Consistency_Checkers_All_the_time_to_Fixup_Transactions.html">1017 high scalability-2011-04-06-Netflix: Run Consistency Checkers All the time to Fixup Transactions</a></p>
<p>15 0.6991564 <a title="1558-lda-15" href="../high_scalability-2010/high_scalability-2010-06-18-Paper%3A_The_Declarative_Imperative%3A_Experiences_and_Conjectures_in_Distributed_Logic.html">844 high scalability-2010-06-18-Paper: The Declarative Imperative: Experiences and Conjectures in Distributed Logic</a></p>
<p>16 0.69694018 <a title="1558-lda-16" href="../high_scalability-2009/high_scalability-2009-03-11-The_Implications_of_Punctuated_Scalabilium_for_Website_Architecture.html">533 high scalability-2009-03-11-The Implications of Punctuated Scalabilium for Website Architecture</a></p>
<p>17 0.69650733 <a title="1558-lda-17" href="../high_scalability-2012/high_scalability-2012-04-17-YouTube_Strategy%3A_Adding_Jitter_isn%27t_a_Bug.html">1229 high scalability-2012-04-17-YouTube Strategy: Adding Jitter isn't a Bug</a></p>
<p>18 0.69618237 <a title="1558-lda-18" href="../high_scalability-2008/high_scalability-2008-07-29-Ehcache_-_A_Java_Distributed_Cache_.html">359 high scalability-2008-07-29-Ehcache - A Java Distributed Cache </a></p>
<p>19 0.69429135 <a title="1558-lda-19" href="../high_scalability-2007/high_scalability-2007-12-19-How_can_I_learn_to_scale_my_project%3F.html">188 high scalability-2007-12-19-How can I learn to scale my project?</a></p>
<p>20 0.69415647 <a title="1558-lda-20" href="../high_scalability-2009/high_scalability-2009-05-08-Publish-subscribe_model_does_not_scale%3F.html">595 high scalability-2009-05-08-Publish-subscribe model does not scale?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
