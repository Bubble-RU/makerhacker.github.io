<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1404 high scalability-2013-02-11-At Scale Even Little Wins Pay Off Big - Google and Facebook Examples</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2013" href="../home/high_scalability-2013_home.html">high_scalability-2013</a> <a title="high_scalability-2013-1404" href="#">high_scalability-2013-1404</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1404 high scalability-2013-02-11-At Scale Even Little Wins Pay Off Big - Google and Facebook Examples</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2013-1404-html" href="http://highscalability.com//blog/2013/2/11/at-scale-even-little-wins-pay-off-big-google-and-facebook-ex.html">html</a></p><p>Introduction: There's a popular line of thought that says don't waste time on optimization because developing features is more important than saving money. True, you can always add resources, but at some point, especially in a more mature part of a product lifecycle: performance equals $$$.   Two great examples of this evolution come from Facebook and Google. The upshot is that when you spend time and money on optimizing your tool chain you can get huge wins in performance, control, and costs. Certainly, don’t bother if you are just starting, but at some point you may want to switch to big development efforts in improving efficiency. 
   Facebook and HipHop   
 The Facebook example is quite well known:    HipHop   , a static PHP compiler released in 2010, after two years of development. PHP because Facebook implements their web tier    in PHP   . They've now developed a dynamic compiler,    HipHop VM   , using techniques like JIT, side exits, HipHop bytecode, type prediction, and parallel tracelet l</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 There's a popular line of thought that says don't waste time on optimization because developing features is more important than saving money. [sent-1, score-0.155]
</p><p>2 True, you can always add resources, but at some point, especially in a more mature part of a product lifecycle: performance equals $$$. [sent-2, score-0.298]
</p><p>3 The upshot is that when you spend time and money on optimizing your tool chain you can get huge wins in performance, control, and costs. [sent-4, score-0.081]
</p><p>4 Certainly, don’t bother if you are just starting, but at some point you may want to switch to big development efforts in improving efficiency. [sent-5, score-0.095]
</p><p>5 They've now developed a dynamic compiler,    HipHop VM   , using techniques like JIT, side exits, HipHop bytecode, type prediction, and parallel tracelet linking. [sent-8, score-0.102]
</p><p>6 This is an incredible development effort as well as an immense effort in migrating their development and deployment infrastructure. [sent-9, score-0.505]
</p><p>7 With more development effort Facebook was able to serve    70% more traffic    with the same hardware. [sent-13, score-0.218]
</p><p>8 The new HipHop VM, for example, will reduce releases times as only thin bytecode deltas need to be shipped. [sent-16, score-0.243]
</p><p>9 First, it helps to know that Google runs    mixed loads on their servers , because this is   why processor cache efficiency matters. [sent-18, score-0.184]
</p><p>10 They use most of their machines as generalized job execution engines. [sent-19, score-0.07]
</p><p>11 Every node runs linux and participates with a scheduling daemon that schedules work across the cluster. [sent-22, score-0.091]
</p><p>12 Jobs of various types (CPU intensive, MapReduce, etc)  will be running on the same machine that runs a Bigtable tablet server. [sent-23, score-0.078]
</p><p>13 Jobs impact each other and those impacts must be managed. [sent-25, score-0.069]
</p><p>14 According to the paper, in a function proﬁle across all Google datacenter applications, string operations like memcpy, memset, and memcmp, take 2 of the top 10 spots. [sent-26, score-0.367]
</p><p>15 The problem is:     String operations can cause performance problems because they ﬂush large portions of the processor caches. [sent-27, score-0.235]
</p><p>16 Consider the case where the memcpy source is read again immediately thereafter, but the destination is not reused for a while. [sent-28, score-0.522]
</p><p>17 If the destination memory is not in cache, this will have a doubly negative effect. [sent-29, score-0.235]
</p><p>18 Moreover, since the cache lines will not be reused for a while, this effectively reduces the usable size of the cache. [sent-33, score-0.251]
</p><p>19 Google has an unknown but probably ginormous number of servers and these functions are a source of performance problems, so there’s a substantial payback for solving the problem. [sent-38, score-0.15]
</p><p>20 The paper describes a rather involved solution to predict string operations with a large reuse distance and replace them cache pollution reducing operations. [sent-39, score-0.809]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hiphop', 0.316), ('string', 0.299), ('memcpy', 0.225), ('reused', 0.158), ('bytecode', 0.152), ('equals', 0.149), ('destination', 0.139), ('facebook', 0.137), ('distance', 0.136), ('reuse', 0.132), ('effort', 0.123), ('substantial', 0.122), ('jobs', 0.114), ('google', 0.108), ('vm', 0.103), ('facebookfacebook', 0.102), ('tracelet', 0.102), ('doubly', 0.096), ('development', 0.095), ('cache', 0.093), ('participates', 0.091), ('deltas', 0.091), ('thereafter', 0.091), ('exits', 0.091), ('processor', 0.091), ('optimization', 0.089), ('ginormous', 0.083), ('taming', 0.083), ('resources', 0.083), ('add', 0.082), ('upshot', 0.081), ('jit', 0.081), ('le', 0.081), ('pollution', 0.081), ('tablet', 0.078), ('portions', 0.076), ('lifecycle', 0.076), ('cpu', 0.07), ('generalized', 0.07), ('immense', 0.069), ('php', 0.069), ('impacts', 0.069), ('recommends', 0.069), ('operations', 0.068), ('spanner', 0.068), ('mature', 0.067), ('articlesthe', 0.067), ('unknown', 0.067), ('moreover', 0.067), ('line', 0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1404-tfidf-1" href="../high_scalability-2013/high_scalability-2013-02-11-At_Scale_Even_Little_Wins_Pay_Off_Big_-_Google_and_Facebook_Examples.html">1404 high scalability-2013-02-11-At Scale Even Little Wins Pay Off Big - Google and Facebook Examples</a></p>
<p>Introduction: There's a popular line of thought that says don't waste time on optimization because developing features is more important than saving money. True, you can always add resources, but at some point, especially in a more mature part of a product lifecycle: performance equals $$$.   Two great examples of this evolution come from Facebook and Google. The upshot is that when you spend time and money on optimizing your tool chain you can get huge wins in performance, control, and costs. Certainly, don’t bother if you are just starting, but at some point you may want to switch to big development efforts in improving efficiency. 
   Facebook and HipHop   
 The Facebook example is quite well known:    HipHop   , a static PHP compiler released in 2010, after two years of development. PHP because Facebook implements their web tier    in PHP   . They've now developed a dynamic compiler,    HipHop VM   , using techniques like JIT, side exits, HipHop bytecode, type prediction, and parallel tracelet l</p><p>2 0.22255643 <a title="1404-tfidf-2" href="../high_scalability-2013/high_scalability-2013-12-09-Site_Moves_from_PHP_to_Facebook%27s_HipHop%2C_Now_Pages_Load_in_.6_Seconds_Instead_of_Five.html">1561 high scalability-2013-12-09-Site Moves from PHP to Facebook's HipHop, Now Pages Load in .6 Seconds Instead of Five</a></p>
<p>Introduction: If you code in PHP have you ever wondered about moving to Facebook's  HipHop JIT Virtual Machine for PHP ? With HipHop Facebook achieved over a 9x increase in web request throughput and over a 5x reduction in memory consumption compared to Zend PHP 5.2 engine + APC.
 
But will HipHop really work for you? Is it really drop-in compatible? Is it really as fast as they say?
 
To answer questions like this nothing beats a good experience report and here's a great one:  Adventures in Configuring and Running Facebook's HipHopVM (hhvm) JIT Compiler for PHP  by Yermo Lamers.
 
Yermo selected PHP to implement a number of content web sites. He took an interesting approach, he created a forms, views, validation, and business logic description language to remove the drudgery of creating the same code over and over again for each page. Having done this in Perl I think it's a great a approach. The problem is it can be slow. PHP's slow string handling makes dynamically evaluating a description templat</p><p>3 0.17829539 <a title="1404-tfidf-3" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>Introduction: In   Taming The Long Latency Tail   we covered   Luiz Barroso  ’s exploration of the long tail latency (some operations are really slow) problems generated by large fanout architectures (a request is composed of potentially thousands of other requests). You may have noticed there weren’t a lot of solutions. That’s where a talk I attended,   Achieving Rapid Response Times in Large Online Services   (  slide deck  ), by  Jeff Dean , also of Google, comes in:
  
  In this talk, I’ll describe a collection of techniques and practices lowering response times in large distributed systems whose components run on shared clusters of machines, where pieces of these systems are subject to interference by other tasks, and where unpredictable latency hiccups are the norm, not the exception. 

  
 The goal is to use software techniques to reduce variability given the increasing variability in underlying hardware, the need to handle dynamic workloads on a shared infrastructure, and the need to use lar</p><p>4 0.156643 <a title="1404-tfidf-4" href="../high_scalability-2010/high_scalability-2010-06-10-The_Four_Meta_Secrets_of_Scaling_at_Facebook.html">840 high scalability-2010-06-10-The Four Meta Secrets of Scaling at Facebook</a></p>
<p>Introduction: Aditya Agarwal, Director of Engineering at Facebook, gave an excellent  Scale at Facebook  talk that covers their architecture, but the talk is really more about how to scale an organization by preserving the best parts of its culture. The key take home of the talk is: 
  

You can get the code right, you can get the products right, but you need to get the culture right first. If you don't get the culture right then your company won't scale.

  
This leads into the four meta secrets of scaling at Facebook:
  
 Scaling takes Iteration 
 Don't Over Design 
 Choose the right tool for the job, but realize that your choice comes with overhead. 
 Get the culture right. Move Fast - break things. Huge Impact - small teams. Be bold - innovate. 
      Some Background    
  Facebook is big : 400 million active users; users spend an average of 20 minutes a day; 5 billion pieces of content (status updates, comments, likes, photo uploads, video uploads, chat messages, inbox messages, group events, f</p><p>5 0.13947389 <a title="1404-tfidf-5" href="../high_scalability-2007/high_scalability-2007-08-08-Partial_String_Matching.html">62 high scalability-2007-08-08-Partial String Matching</a></p>
<p>Introduction: Is there any alternative to LIKE '%...%' OR LIKE '%...%' in MySQL if you have to offer partial string matching on a large dataset?</p><p>6 0.1341151 <a title="1404-tfidf-6" href="../high_scalability-2013/high_scalability-2013-04-23-Facebook_Secrets_of_Web_Performance.html">1444 high scalability-2013-04-23-Facebook Secrets of Web Performance</a></p>
<p>7 0.13263176 <a title="1404-tfidf-7" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>8 0.13226682 <a title="1404-tfidf-8" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>9 0.12379242 <a title="1404-tfidf-9" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>10 0.12246394 <a title="1404-tfidf-10" href="../high_scalability-2013/high_scalability-2013-11-13-Google%3A_Multiplex_Multiple_Works_Loads_on_Computers_to_Increase_Machine_Utilization_and_Save_Money.html">1548 high scalability-2013-11-13-Google: Multiplex Multiple Works Loads on Computers to Increase Machine Utilization and Save Money</a></p>
<p>11 0.11969742 <a title="1404-tfidf-11" href="../high_scalability-2012/high_scalability-2012-09-24-Google_Spanner%27s_Most_Surprising_Revelation%3A_NoSQL_is_Out_and_NewSQL_is_In.html">1328 high scalability-2012-09-24-Google Spanner's Most Surprising Revelation: NoSQL is Out and NewSQL is In</a></p>
<p>12 0.11732607 <a title="1404-tfidf-12" href="../high_scalability-2012/high_scalability-2012-11-30-Stuff_The_Internet_Says_On_Scalability_For_November_30%2C_2012.html">1365 high scalability-2012-11-30-Stuff The Internet Says On Scalability For November 30, 2012</a></p>
<p>13 0.11369781 <a title="1404-tfidf-13" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>14 0.11354403 <a title="1404-tfidf-14" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>15 0.11326357 <a title="1404-tfidf-15" href="../high_scalability-2012/high_scalability-2012-10-24-Saving_Cash_Using_Less_Cache_-__90%25_Savings_in_the_Caching_Tier.html">1346 high scalability-2012-10-24-Saving Cash Using Less Cache -  90% Savings in the Caching Tier</a></p>
<p>16 0.11075214 <a title="1404-tfidf-16" href="../high_scalability-2010/high_scalability-2010-04-12-Poppen.de_Architecture.html">808 high scalability-2010-04-12-Poppen.de Architecture</a></p>
<p>17 0.11063869 <a title="1404-tfidf-17" href="../high_scalability-2008/high_scalability-2008-04-21-Using_Google_AppEngine_for_a_Little_Micro-Scalability.html">307 high scalability-2008-04-21-Using Google AppEngine for a Little Micro-Scalability</a></p>
<p>18 0.11053944 <a title="1404-tfidf-18" href="../high_scalability-2008/high_scalability-2008-07-29-Ehcache_-_A_Java_Distributed_Cache_.html">359 high scalability-2008-07-29-Ehcache - A Java Distributed Cache </a></p>
<p>19 0.11014791 <a title="1404-tfidf-19" href="../high_scalability-2012/high_scalability-2012-04-06-Stuff_The_Internet_Says_On_Scalability_For_April_6%2C_2012.html">1223 high scalability-2012-04-06-Stuff The Internet Says On Scalability For April 6, 2012</a></p>
<p>20 0.10948814 <a title="1404-tfidf-20" href="../high_scalability-2012/high_scalability-2012-07-02-C_is_for_Compute_-_Google_Compute_Engine_%28GCE%29.html">1275 high scalability-2012-07-02-C is for Compute - Google Compute Engine (GCE)</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.203), (1, 0.111), (2, 0.013), (3, -0.001), (4, 0.013), (5, 0.013), (6, 0.039), (7, 0.084), (8, -0.024), (9, 0.018), (10, -0.015), (11, -0.029), (12, 0.043), (13, 0.027), (14, -0.041), (15, -0.048), (16, -0.015), (17, -0.044), (18, 0.05), (19, 0.01), (20, 0.082), (21, 0.065), (22, 0.09), (23, -0.043), (24, 0.044), (25, 0.059), (26, 0.011), (27, -0.017), (28, -0.031), (29, -0.048), (30, -0.061), (31, -0.013), (32, 0.001), (33, -0.003), (34, -0.008), (35, 0.057), (36, 0.02), (37, -0.066), (38, -0.043), (39, 0.068), (40, -0.056), (41, -0.031), (42, 0.023), (43, -0.041), (44, -0.047), (45, -0.033), (46, -0.008), (47, -0.064), (48, 0.077), (49, -0.084)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97530717 <a title="1404-lsi-1" href="../high_scalability-2013/high_scalability-2013-02-11-At_Scale_Even_Little_Wins_Pay_Off_Big_-_Google_and_Facebook_Examples.html">1404 high scalability-2013-02-11-At Scale Even Little Wins Pay Off Big - Google and Facebook Examples</a></p>
<p>Introduction: There's a popular line of thought that says don't waste time on optimization because developing features is more important than saving money. True, you can always add resources, but at some point, especially in a more mature part of a product lifecycle: performance equals $$$.   Two great examples of this evolution come from Facebook and Google. The upshot is that when you spend time and money on optimizing your tool chain you can get huge wins in performance, control, and costs. Certainly, don’t bother if you are just starting, but at some point you may want to switch to big development efforts in improving efficiency. 
   Facebook and HipHop   
 The Facebook example is quite well known:    HipHop   , a static PHP compiler released in 2010, after two years of development. PHP because Facebook implements their web tier    in PHP   . They've now developed a dynamic compiler,    HipHop VM   , using techniques like JIT, side exits, HipHop bytecode, type prediction, and parallel tracelet l</p><p>2 0.73638886 <a title="1404-lsi-2" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>Introduction: In   Taming The Long Latency Tail   we covered   Luiz Barroso  ’s exploration of the long tail latency (some operations are really slow) problems generated by large fanout architectures (a request is composed of potentially thousands of other requests). You may have noticed there weren’t a lot of solutions. That’s where a talk I attended,   Achieving Rapid Response Times in Large Online Services   (  slide deck  ), by  Jeff Dean , also of Google, comes in:
  
  In this talk, I’ll describe a collection of techniques and practices lowering response times in large distributed systems whose components run on shared clusters of machines, where pieces of these systems are subject to interference by other tasks, and where unpredictable latency hiccups are the norm, not the exception. 

  
 The goal is to use software techniques to reduce variability given the increasing variability in underlying hardware, the need to handle dynamic workloads on a shared infrastructure, and the need to use lar</p><p>3 0.73030645 <a title="1404-lsi-3" href="../high_scalability-2010/high_scalability-2010-11-22-Strategy%3A_Google_Sends_Canary_Requests_into_the_Data_Mine.html">946 high scalability-2010-11-22-Strategy: Google Sends Canary Requests into the Data Mine</a></p>
<p>Introduction: Google runs queries against thousands of in-memory index nodes in parallel and then merges the results. One of the interesting problems with this approach, explains Google's Jeff Dean in this  lecture at Stanford , is the  Query of Death .
 
A query can cause a program to fail because of bugs or various other issues. This means that a single query can take down an entire cluster of machines, which is not good for availability and response times, as it takes quite a while for thousands of machines to recover. Thus the Query of Death. New queries are always coming into the system and when you are always rolling out new software, it's impossible to completely get rid of the problem.
 
Two solutions:
  
  Test against logs . Google replays a month's worth of logs to see if any of those queries kill anything. That helps, but Queries of Death may still happen. 
  Send a canary request . A request is sent to one machine. If the request succeeds then it will probably succeedÂ on all machines, s</p><p>4 0.72264141 <a title="1404-lsi-4" href="../high_scalability-2013/high_scalability-2013-11-13-Google%3A_Multiplex_Multiple_Works_Loads_on_Computers_to_Increase_Machine_Utilization_and_Save_Money.html">1548 high scalability-2013-11-13-Google: Multiplex Multiple Works Loads on Computers to Increase Machine Utilization and Save Money</a></p>
<p>Introduction: Jeff Dean  gave a talk at   SFBay ACM   and at about 3 minutes in he goes over how Google runs jobs on computers, which is different than how most shops distribute workloads.
   It’s common for machines to be dedicated to one service, say run a database, run a cache, run this, or run that. The logic is: 
  
 
  Better control over responsiveness as you generally know the traffic loads a machine will experience and you can over provision a box to be safe. 

 
 
  Easier to manage, load balance, configure, upgrade, create and make highly available. Since you know what a machine does another machine can be provisioned to do the same work. 

 
    The problem is monocropping hardware though conceptually clean for humans and safe for applications, is hugely wasteful. Machines are woefully underutilized, even in a virtualized world. 
  What Google does is use a  shared environment  in a datacenter where all kinds of stuff run on each computer. Batch computation and interactive computations a</p><p>5 0.70158255 <a title="1404-lsi-5" href="../high_scalability-2008/high_scalability-2008-12-13-Strategy%3A_Facebook_Tweaks_to_Handle_6_Time_as_Many_Memcached_Requests.html">464 high scalability-2008-12-13-Strategy: Facebook Tweaks to Handle 6 Time as Many Memcached Requests</a></p>
<p>Introduction: Our latest strategy is taken from a  great post by Paul Saab of Facebook , detailing how with changes Facebook has made to memcached they have:
  ...been able to scale memcached to handle 200,000 UDP requests per second with an average latency of 173 microseconds. The total throughput achieved is 300,000 UDP requests/s, but the latency at that request rate is too high to be useful in our system. This is an amazing increase from 50,000 UDP requests/s using the stock version of Linux and memcached.  
To scale Facebook has hundreds of thousands of TCP connections open to their memcached processes. First, this is still amazing. It's not so long ago you could have never done this. Optimizing connection use was always a priority because the OS simply couldn't handle large numbers of connections or large numbers of threads or large numbers of CPUs. To get to this point is a big accomplishment. Still, at that scale there are problems that are often solved.  Some of the problem Facebook faced a</p><p>6 0.69433141 <a title="1404-lsi-6" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>7 0.68340611 <a title="1404-lsi-7" href="../high_scalability-2013/high_scalability-2013-12-09-Site_Moves_from_PHP_to_Facebook%27s_HipHop%2C_Now_Pages_Load_in_.6_Seconds_Instead_of_Five.html">1561 high scalability-2013-12-09-Site Moves from PHP to Facebook's HipHop, Now Pages Load in .6 Seconds Instead of Five</a></p>
<p>8 0.68268836 <a title="1404-lsi-8" href="../high_scalability-2014/high_scalability-2014-03-21-Stuff_The_Internet_Says_On_Scalability_For_March_21st%2C_2014.html">1617 high scalability-2014-03-21-Stuff The Internet Says On Scalability For March 21st, 2014</a></p>
<p>9 0.67742747 <a title="1404-lsi-9" href="../high_scalability-2013/high_scalability-2013-08-16-Stuff_The_Internet_Says_On_Scalability_For_August_16%2C_2013.html">1502 high scalability-2013-08-16-Stuff The Internet Says On Scalability For August 16, 2013</a></p>
<p>10 0.67695487 <a title="1404-lsi-10" href="../high_scalability-2010/high_scalability-2010-04-27-Paper%3A__Dapper%2C_Google%27s_Large-Scale_Distributed_Systems_Tracing_Infrastructure.html">815 high scalability-2010-04-27-Paper:  Dapper, Google's Large-Scale Distributed Systems Tracing Infrastructure</a></p>
<p>11 0.6679402 <a title="1404-lsi-11" href="../high_scalability-2013/high_scalability-2013-05-30-Google_Finds_NUMA_Up_to_20%25_Slower_for_Gmail_and_Websearch.html">1467 high scalability-2013-05-30-Google Finds NUMA Up to 20% Slower for Gmail and Websearch</a></p>
<p>12 0.66145533 <a title="1404-lsi-12" href="../high_scalability-2012/high_scalability-2012-07-02-C_is_for_Compute_-_Google_Compute_Engine_%28GCE%29.html">1275 high scalability-2012-07-02-C is for Compute - Google Compute Engine (GCE)</a></p>
<p>13 0.65861315 <a title="1404-lsi-13" href="../high_scalability-2012/high_scalability-2012-04-06-Stuff_The_Internet_Says_On_Scalability_For_April_6%2C_2012.html">1223 high scalability-2012-04-06-Stuff The Internet Says On Scalability For April 6, 2012</a></p>
<p>14 0.65769368 <a title="1404-lsi-14" href="../high_scalability-2012/high_scalability-2012-09-24-Google_Spanner%27s_Most_Surprising_Revelation%3A_NoSQL_is_Out_and_NewSQL_is_In.html">1328 high scalability-2012-09-24-Google Spanner's Most Surprising Revelation: NoSQL is Out and NewSQL is In</a></p>
<p>15 0.65374559 <a title="1404-lsi-15" href="../high_scalability-2013/high_scalability-2013-11-08-Stuff_The_Internet_Says_On_Scalability_For_November_8th%2C_2013.html">1545 high scalability-2013-11-08-Stuff The Internet Says On Scalability For November 8th, 2013</a></p>
<p>16 0.65034294 <a title="1404-lsi-16" href="../high_scalability-2014/high_scalability-2014-02-13-Snabb_Switch_-_Skip_the_OS_and_Get_40_million_Requests_Per_Second_in_Lua.html">1595 high scalability-2014-02-13-Snabb Switch - Skip the OS and Get 40 million Requests Per Second in Lua</a></p>
<p>17 0.64879525 <a title="1404-lsi-17" href="../high_scalability-2012/high_scalability-2012-10-19-Stuff_The_Internet_Says_On_Scalability_For_October_19%2C_2012.html">1344 high scalability-2012-10-19-Stuff The Internet Says On Scalability For October 19, 2012</a></p>
<p>18 0.64371848 <a title="1404-lsi-18" href="../high_scalability-2011/high_scalability-2011-05-27-Stuff_The_Internet_Says_On_Scalability_For_May_27%2C_2011.html">1048 high scalability-2011-05-27-Stuff The Internet Says On Scalability For May 27, 2011</a></p>
<p>19 0.63925117 <a title="1404-lsi-19" href="../high_scalability-2011/high_scalability-2011-06-17-Stuff_The_Internet_Says_On_Scalability_For_June_17%2C_2011.html">1063 high scalability-2011-06-17-Stuff The Internet Says On Scalability For June 17, 2011</a></p>
<p>20 0.63909084 <a title="1404-lsi-20" href="../high_scalability-2014/high_scalability-2014-03-07-Stuff_The_Internet_Says_On_Scalability_For_March_7th%2C_2014.html">1607 high scalability-2014-03-07-Stuff The Internet Says On Scalability For March 7th, 2014</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.124), (2, 0.196), (10, 0.058), (30, 0.016), (40, 0.019), (47, 0.027), (61, 0.084), (77, 0.03), (79, 0.135), (85, 0.03), (90, 0.127), (94, 0.064)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94735032 <a title="1404-lda-1" href="../high_scalability-2013/high_scalability-2013-02-11-At_Scale_Even_Little_Wins_Pay_Off_Big_-_Google_and_Facebook_Examples.html">1404 high scalability-2013-02-11-At Scale Even Little Wins Pay Off Big - Google and Facebook Examples</a></p>
<p>Introduction: There's a popular line of thought that says don't waste time on optimization because developing features is more important than saving money. True, you can always add resources, but at some point, especially in a more mature part of a product lifecycle: performance equals $$$.   Two great examples of this evolution come from Facebook and Google. The upshot is that when you spend time and money on optimizing your tool chain you can get huge wins in performance, control, and costs. Certainly, don’t bother if you are just starting, but at some point you may want to switch to big development efforts in improving efficiency. 
   Facebook and HipHop   
 The Facebook example is quite well known:    HipHop   , a static PHP compiler released in 2010, after two years of development. PHP because Facebook implements their web tier    in PHP   . They've now developed a dynamic compiler,    HipHop VM   , using techniques like JIT, side exits, HipHop bytecode, type prediction, and parallel tracelet l</p><p>2 0.93028009 <a title="1404-lda-2" href="../high_scalability-2013/high_scalability-2013-01-02-Why_Pinterest_Uses_the_Cloud_Instead_of_Going_Solo_-_To_Be_Or_Not_To_Be.html">1380 high scalability-2013-01-02-Why Pinterest Uses the Cloud Instead of Going Solo - To Be Or Not To Be</a></p>
<p>Introduction: I love it when a somewhat older article like  Pinterest Cut Costs From $54 To $20 Per Hour By Automatically Shutting Down Systems  hits Hacker News and generates a  good conversation . One of the common sentiments about the cloud was raised: why doesn't Pinterest save a lot of money by running their own hardware instead of using the cloud?
 
 Ryan Park , Operations Engineer at Pinterest, responds in what I think is the perfect  modern response  to that ultimate existential design dilemma:
  

Our #1 requirement has been to keep up with the growth in traffic on the site. We've been growing so fast that there's literally no way we could have ordered and racked equipment fast enough. We were also a very small team -- a year ago there were only about a dozen people in the whole company. At this point we're much larger, which gives us room to consider more options like colo or multiple cloud providers.


 AWS certainly feels pretty costly when you compare colo prices to the list price for o</p><p>3 0.92613536 <a title="1404-lda-3" href="../high_scalability-2008/high_scalability-2008-06-09-FaceStat%27s_Rousing_Tale_of_Scaling_Woe_and_Wisdom_Won.html">344 high scalability-2008-06-09-FaceStat's Rousing Tale of Scaling Woe and Wisdom Won</a></p>
<p>Introduction: Lukas Biewald shares a fascinating  slam by slam recount  of how his  FaceStat  (upload your picture and be judged by the masses) site was battered by a link on Yahoo's main page that caused an almost instantaneous 650,000 page view jump on their site. Yahoo spends considerable effort making sure its own properties can handle the truly massive flow from the main page. Turning the  Great Eye  of the Internet towards an unsuspecting newborn site must be quite the diaper ready experience. Theo Schlossnagle eerily prophesized about such events in  The Implications of Punctuated Scalabilium for Website Architecture : massive, unexpected and sudden traffic spikes will become more common as a fickle internet seeks ever for new entertainments (my summary). Exactly FaceStat's situation.   This is also one of our first exposures to an application written on Merb, a popular Ruby on Rails competitor. For those who think Ruby is the problem, their architecture now serves 100 times the original load</p><p>4 0.92233288 <a title="1404-lda-4" href="../high_scalability-2010/high_scalability-2010-11-05-Hot_Scalability_Links_For_November_5th%2C_2010.html">935 high scalability-2010-11-05-Hot Scalability Links For November 5th, 2010</a></p>
<p>Introduction: So much good stuff this week...
  
 Adrian Cockcroft  Compares NoSQL Availability Models .  Let's risk feeding the CAP trolls, and try to get some insight into the differences between the many NoSQL contenders . Adrian asks how each NoSQL product will add a movie to its favorites list, read it back, and how this works across availability zones. Much trickier than it sounds with multiple writers. Cassandra and MongoDB answer back. 
 Stuff the Internet Says:              
 
  @jerng : Reading up on scalability. WHY THE HELL FOR? Because I want to know the future. 
  @freerangedata : The #nosql options are the micro brews/craft beers of data stores. So many good ones, so little time to try them all. 
  @edward_ribeiro : Soon, Darwinism will start to play its role on #NoSQL systems. You know, only the fittest will survive. 
  @connectionreq : I'm always wowed when I hear how Facebook abuses their MySQL databases in crazy ways 
  @louismrose : This is the kind of scalability we should be wo</p><p>5 0.92080855 <a title="1404-lda-5" href="../high_scalability-2013/high_scalability-2013-11-11-Ask_HS%3A_What_is_a_good_OLAP_database_choice_with_node.js%3F.html">1546 high scalability-2013-11-11-Ask HS: What is a good OLAP database choice with node.js?</a></p>
<p>Introduction: This question was asked over email and I thought a larger audience might want to take a whack at it. 
 
With a business associate, I am trying to develop a financial software that handles financial reports of listed companies. We managed to create this database with all the data necessary to do financial analysis. My associate is a Business Intelligence specialist so he is keen to use OLAPs databases like Microsoft Analysis Services or Jedox Palo, which enables in-memory calculations and very fast aggregation, slicing and dicing of data or write-backs.
 
At the same time I did an online course (MOOC) from Stanford CS184 called Startup Engineering which promoted/talked a lot about javascript and especially node.js as the language of the future for servers.
 
As I am keen to use open-source technologies (would be keen to avoid MS SSAS) for the development of a website to access this financial data , and there are so many choices for databases out there (Postgre, MongoDB, MySQL etc..but d</p><p>6 0.91415769 <a title="1404-lda-6" href="../high_scalability-2007/high_scalability-2007-12-19-How_can_I_learn_to_scale_my_project%3F.html">188 high scalability-2007-12-19-How can I learn to scale my project?</a></p>
<p>7 0.91203713 <a title="1404-lda-7" href="../high_scalability-2008/high_scalability-2008-02-22-Kevin%27s_Great_Adventures_in_SSDland.html">257 high scalability-2008-02-22-Kevin's Great Adventures in SSDland</a></p>
<p>8 0.90690929 <a title="1404-lda-8" href="../high_scalability-2008/high_scalability-2008-04-08-Google_AppEngine_-_A_First_Look.html">301 high scalability-2008-04-08-Google AppEngine - A First Look</a></p>
<p>9 0.90667337 <a title="1404-lda-9" href="../high_scalability-2009/high_scalability-2009-02-21-Google_AppEngine_-_A_Second_Look.html">517 high scalability-2009-02-21-Google AppEngine - A Second Look</a></p>
<p>10 0.90648359 <a title="1404-lda-10" href="../high_scalability-2011/high_scalability-2011-11-29-DataSift_Architecture%3A_Realtime_Datamining_at_120%2C000_Tweets_Per_Second.html">1148 high scalability-2011-11-29-DataSift Architecture: Realtime Datamining at 120,000 Tweets Per Second</a></p>
<p>11 0.90599495 <a title="1404-lda-11" href="../high_scalability-2014/high_scalability-2014-05-16-Stuff_The_Internet_Says_On_Scalability_For_May_16th%2C_2014.html">1649 high scalability-2014-05-16-Stuff The Internet Says On Scalability For May 16th, 2014</a></p>
<p>12 0.90575314 <a title="1404-lda-12" href="../high_scalability-2011/high_scalability-2011-09-07-What_Google_App_Engine_Price_Changes_Say_About_the_Future_of_Web_Architecture.html">1112 high scalability-2011-09-07-What Google App Engine Price Changes Say About the Future of Web Architecture</a></p>
<p>13 0.90384859 <a title="1404-lda-13" href="../high_scalability-2013/high_scalability-2013-01-07-Analyzing_billions_of_credit_card_transactions_and_serving_low-latency_insights_in_the_cloud.html">1382 high scalability-2013-01-07-Analyzing billions of credit card transactions and serving low-latency insights in the cloud</a></p>
<p>14 0.903696 <a title="1404-lda-14" href="../high_scalability-2009/high_scalability-2009-10-06-Building_a_Unique_Data_Warehouse.html">716 high scalability-2009-10-06-Building a Unique Data Warehouse</a></p>
<p>15 0.90360904 <a title="1404-lda-15" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>16 0.90304989 <a title="1404-lda-16" href="../high_scalability-2013/high_scalability-2013-01-18-Stuff_The_Internet_Says_On_Scalability_For_January_18%2C_2013.html">1389 high scalability-2013-01-18-Stuff The Internet Says On Scalability For January 18, 2013</a></p>
<p>17 0.90289855 <a title="1404-lda-17" href="../high_scalability-2013/high_scalability-2013-03-29-Stuff_The_Internet_Says_On_Scalability_For_March_29%2C_2013.html">1431 high scalability-2013-03-29-Stuff The Internet Says On Scalability For March 29, 2013</a></p>
<p>18 0.90244752 <a title="1404-lda-18" href="../high_scalability-2008/high_scalability-2008-03-27-Amazon_Announces_Static_IP_Addresses_and_Multiple_Datacenter_Operation.html">289 high scalability-2008-03-27-Amazon Announces Static IP Addresses and Multiple Datacenter Operation</a></p>
<p>19 0.90229732 <a title="1404-lda-19" href="../high_scalability-2012/high_scalability-2012-12-18-Georeplication%3A_When_Bad_Things_Happen_to_Good_Systems.html">1374 high scalability-2012-12-18-Georeplication: When Bad Things Happen to Good Systems</a></p>
<p>20 0.90183914 <a title="1404-lda-20" href="../high_scalability-2014/high_scalability-2014-03-14-Stuff_The_Internet_Says_On_Scalability_For_March_14th%2C_2014.html">1612 high scalability-2014-03-14-Stuff The Internet Says On Scalability For March 14th, 2014</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
