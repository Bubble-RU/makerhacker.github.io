<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1475 high scalability-2013-06-13-Busting 4 Modern Hardware Myths - Are Memory, HDDs, and SSDs Really Random Access?</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2013" href="../home/high_scalability-2013_home.html">high_scalability-2013</a> <a title="high_scalability-2013-1475" href="#">high_scalability-2013-1475</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1475 high scalability-2013-06-13-Busting 4 Modern Hardware Myths - Are Memory, HDDs, and SSDs Really Random Access?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2013-1475-html" href="http://highscalability.com//blog/2013/6/13/busting-4-modern-hardware-myths-are-memory-hdds-and-ssds-rea.html">html</a></p><p>Introduction: "It’s all a numbers game – the dirty little secret of scalable systems" 
      
 Martin Thompson  is a High Performance Computing Specialist with a real mission to teach programmers how to understand the innards of modern computing systems. He has many talks and classes (listed below) on caches, buffers, memory controllers, processor architectures, cache lines, etc.
 
His thought is programmers do not put a proper value on understanding how the underpinnings of our systems work. We gravitate to the shiny and trendy. His approach is not to teach people specific programming strategies, but to teach programmers to fish so they can feed themselves. Without a real understanding strategies are easy to apply wrongly.  It's strange how programmers will put a lot of effort into understanding complicated frameworks like Hibernate, but little effort into understanding the underlying hardware on which their programs run.
 
A major tenant of Martin's approach is to "lead by experimental observation</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 "It’s all a numbers game – the dirty little secret of scalable systems"          Martin Thompson  is a High Performance Computing Specialist with a real mission to teach programmers how to understand the innards of modern computing systems. [sent-1, score-0.328]
</p><p>2 His approach is not to teach people specific programming strategies, but to teach programmers to fish so they can feed themselves. [sent-5, score-0.414]
</p><p>3 It's strange how programmers will put a lot of effort into understanding complicated frameworks like Hibernate, but little effort into understanding the underlying hardware on which their programs run. [sent-7, score-0.286]
</p><p>4 "  Mechanical Sympathy is term coined by  Jackie Stewart , the race car driver, to say you get the best out of a racing car when you have a good understanding of how a car works. [sent-9, score-0.463]
</p><p>5 The most surprising part of the talk is the counter intuitive idea that many of the devices we think of as random access, like RAM, HDDs, and SSDs, effectively become serial devices in certain circumstances. [sent-17, score-0.295]
</p><p>6 As we run CPUs faster (higher clock speeds) they get hotter and hotter and heat dissipation at these small scales is incredibly difficult. [sent-21, score-0.529]
</p><p>7 The reason CPUs are getting faster is not faster clock speed, but instructions are being fed into the CPU faster. [sent-41, score-0.253]
</p><p>8 On Sandy Bridge sequentially walking through memory will take you 3 clocks for L1D, 11 clocks for L2, 14 clocks for L3, and 6ns for memory. [sent-56, score-1.142]
</p><p>9 In-page random is 3 clocks, 11 clocks, 18 clocks,  22ns. [sent-57, score-0.295]
</p><p>10 Full random access is 3 clocks, 11 clocks, 38 clocks, 65. [sent-58, score-0.386]
</p><p>11 Since you can't walk memory sequentially you want to reduce coupling and increase cohesion. [sent-63, score-0.377]
</p><p>12 More sectors are put on the outer parts of the disk so you get greater density. [sent-69, score-0.444]
</p><p>13 For one revolution of the disk you are going to see more sectors so you'll get greater throughput. [sent-70, score-0.318]
</p><p>14 On a 10K disk when sequentially reading the outer tracks you'll get 220 MB/s and when reading the innter tracks you'll get 140 MB/s. [sent-71, score-0.541]
</p><p>15 For random access of a 4K block, the random latency is 10ms or 100 IOPS. [sent-85, score-0.681]
</p><p>16 Throughput at random is less than 1 MB a second, maybe 2 MB a second with really clever hardware. [sent-86, score-0.373]
</p><p>17 Reading or writing a random page sized thing is really fast, there's no moving parts. [sent-96, score-0.447]
</p><p>18 Bits are marked as deleted because you don't want to erase a whole block at a time because there's a limited number times you can read and write a block. [sent-103, score-0.261]
</p><p>19 Reads have great random and sequential performance. [sent-113, score-0.295]
</p><p>20 At 40K IOPs with 4K random reads and writes, average operation times are 100-300 microseconds with large up to half a second pauses during garbage collection. [sent-115, score-0.372]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('clocks', 0.301), ('random', 0.295), ('mechanical', 0.146), ('cpus', 0.141), ('sympathy', 0.137), ('martin', 0.136), ('disk', 0.136), ('hotter', 0.129), ('feed', 0.128), ('outer', 0.126), ('clock', 0.125), ('memory', 0.124), ('alus', 0.117), ('sequentially', 0.115), ('voltage', 0.106), ('teach', 0.102), ('bridge', 0.102), ('understanding', 0.102), ('sectors', 0.1), ('bits', 0.099), ('alice', 0.095), ('branched', 0.095), ('sandy', 0.095), ('car', 0.093), ('block', 0.092), ('erase', 0.092), ('access', 0.091), ('hdds', 0.089), ('programmers', 0.082), ('get', 0.082), ('ssds', 0.082), ('writes', 0.08), ('really', 0.078), ('garbage', 0.077), ('marked', 0.077), ('tape', 0.077), ('myth', 0.077), ('thompson', 0.077), ('modern', 0.076), ('writing', 0.074), ('coupling', 0.074), ('caches', 0.071), ('processor', 0.071), ('hibernate', 0.071), ('detail', 0.069), ('understand', 0.068), ('ports', 0.068), ('ca', 0.066), ('walk', 0.064), ('faster', 0.064)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="1475-tfidf-1" href="../high_scalability-2013/high_scalability-2013-06-13-Busting_4_Modern_Hardware_Myths_-_Are_Memory%2C_HDDs%2C_and_SSDs_Really_Random_Access%3F.html">1475 high scalability-2013-06-13-Busting 4 Modern Hardware Myths - Are Memory, HDDs, and SSDs Really Random Access?</a></p>
<p>Introduction: "It’s all a numbers game – the dirty little secret of scalable systems" 
      
 Martin Thompson  is a High Performance Computing Specialist with a real mission to teach programmers how to understand the innards of modern computing systems. He has many talks and classes (listed below) on caches, buffers, memory controllers, processor architectures, cache lines, etc.
 
His thought is programmers do not put a proper value on understanding how the underpinnings of our systems work. We gravitate to the shiny and trendy. His approach is not to teach people specific programming strategies, but to teach programmers to fish so they can feed themselves. Without a real understanding strategies are easy to apply wrongly.  It's strange how programmers will put a lot of effort into understanding complicated frameworks like Hibernate, but little effort into understanding the underlying hardware on which their programs run.
 
A major tenant of Martin's approach is to "lead by experimental observation</p><p>2 0.17644161 <a title="1475-tfidf-2" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>Introduction: We are on the edge of two potent technological changes: Clouds and Memory Based Architectures. This evolution will rip open a chasm where new players can enter and prosper. Google is the master of disk. You can't beat them at a game they perfected. Disk based databases like SimpleDB and BigTable are complicated beasts, typical last gasp products of any aging technology before a change. The next era is the age of Memory and Cloud which will allow for new players to succeed. The tipping point will be soon.   Let's take a short trip down web architecture lane:
  It's 1993: Yahoo runs on FreeBSD, Apache, Perl scripts and a SQL database   It's 1995: Scale-up the database.   It's 1998: LAMP   It's 1999: Stateless + Load Balanced + Database + SAN   It's 2001: In-memory data-grid.   It's 2003: Add a caching layer.   It's 2004: Add scale-out and partitioning.   It's 2005: Add asynchronous job scheduling and maybe a distributed file system.   It's 2007: Move it all into the cloud.   It's 2008: C</p><p>3 0.16174047 <a title="1475-tfidf-3" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>Introduction: Likewise the current belief that, in the case of artificial machines the very large and the very small are equally feasible and lasting is a manifest error. Thus, for example, a small obelisk or column or other solid figure can certainly be laid down or set up without danger of breaking, while the large ones will go to pieces under the slightest provocation, and that purely on account of their own weight. -- Galileo  
Galileo observed how things broke if they were naively scaled up. Interestingly, Google noticed a similar pattern when building larger software systems using the same techniques used to build smaller systems. 
 
 Luiz André Barroso , Distinguished Engineer at Google, talks about this fundamental property of scaling systems in his fascinating talk,  Warehouse-Scale Computing: Entering the Teenage Decade . Google found the larger the scale the greater the impact of latency variability. When a request is implemented by work done in parallel, as is common with today's service</p><p>4 0.15831803 <a title="1475-tfidf-4" href="../high_scalability-2011/high_scalability-2011-06-22-It%27s_the_Fraking_IOPS_-_1_SSD_is_44%2C000_IOPS%2C_Hard_Drive_is_180.html">1066 high scalability-2011-06-22-It's the Fraking IOPS - 1 SSD is 44,000 IOPS, Hard Drive is 180</a></p>
<p>Introduction: Planning your next buildout and thinking SSDs are still far in the future? Still too expensive, too low density. Hard disks are cheap, familiar, and store lots of stuff. In this short and entertaining video Wikia's  Artur Bergman  wants to change your mind about SSDs. SSDs are for today, get with the math already.
 
Here's Artur's logic:
  
 Wikia is all SSD in production. The new Wikia file servers have a theoretical read rate of ~10GB/sec sequential, 6GB/sec random and 1.2 million IOPs. If you can't do math or love the past, you love spinning rust. If you are awesome you love SSDs. 
 SSDs are cheaper than drives using the most relevant metric: $/GB/IOPS. 1 SSD is 44,000 IOPS and one hard drive is 180 IOPS. Need 1 SSD instead of 50 hard drives. 
 With 8 million files there's a 9 minute fsck. Full backup in 12 minutes (X-25M based). 
 4 GB/sec random read average latency 1 msec. 
 2.2 GB/sec random write average latency 1 msec. 
 50TBs of SSDs in one machine for $80,000. With the densi</p><p>5 0.15829675 <a title="1475-tfidf-5" href="../high_scalability-2012/high_scalability-2012-12-10-Switch_your_databases_to_Flash_storage._Now._Or_you%27re_doing_it_wrong..html">1369 high scalability-2012-12-10-Switch your databases to Flash storage. Now. Or you're doing it wrong.</a></p>
<p>Introduction: This is a guest post by   Brian  Bulkowski  , CTO and co-founder of   Aerospike  , a leading clustered NoSQL  database, has worked in the area of high performance commodity systems  since 1989. 
   Why flash rules for databases     The economics of flash memory are staggering.    If you’re not using SSD, you are doing it wrong.   
   Not quite true, but close. Some small applications fit entirely in memory – less than 100GB – great for in-memory solutions. There’s a place for rotational drives (HDD) in massive streaming analytics and petabytes of data. But for the vast space between, flash has become the only sensible option.  
   For example, the Samsung 840 costs $180 for 250GB. The speed rating for this drive is rated by the manufacturer at 96,000 random 4K read IOPS, and 61,000 random 4K write IOPS. The Samsung 840 is not alone at this price performance. A 300GB Intel 320 is $450. An OCZ Vertex 4 256GB is $235, with the Intel being rated as slowest, but our internal testing showing</p><p>6 0.156956 <a title="1475-tfidf-6" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>7 0.15042308 <a title="1475-tfidf-7" href="../high_scalability-2012/high_scalability-2012-07-25-Vertical_Scaling_Ascendant_-_How_are_SSDs_Changing__Architectures%3F.html">1291 high scalability-2012-07-25-Vertical Scaling Ascendant - How are SSDs Changing  Architectures?</a></p>
<p>8 0.14778034 <a title="1475-tfidf-8" href="../high_scalability-2013/high_scalability-2013-05-31-Stuff_The_Internet_Says_On_Scalability_For_May_31%2C_2013.html">1468 high scalability-2013-05-31-Stuff The Internet Says On Scalability For May 31, 2013</a></p>
<p>9 0.14361441 <a title="1475-tfidf-9" href="../high_scalability-2011/high_scalability-2011-09-19-Big_Iron_Returns_with_BigMemory.html">1118 high scalability-2011-09-19-Big Iron Returns with BigMemory</a></p>
<p>10 0.14239973 <a title="1475-tfidf-10" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>11 0.1415419 <a title="1475-tfidf-11" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>12 0.13675296 <a title="1475-tfidf-12" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>13 0.13228643 <a title="1475-tfidf-13" href="../high_scalability-2014/high_scalability-2014-01-31-Stuff_The_Internet_Says_On_Scalability_For_January_31st%2C_2014.html">1588 high scalability-2014-01-31-Stuff The Internet Says On Scalability For January 31st, 2014</a></p>
<p>14 0.1318846 <a title="1475-tfidf-14" href="../high_scalability-2013/high_scalability-2013-01-15-More_Numbers_Every_Awesome_Programmer_Must_Know.html">1387 high scalability-2013-01-15-More Numbers Every Awesome Programmer Must Know</a></p>
<p>15 0.13143972 <a title="1475-tfidf-15" href="../high_scalability-2011/high_scalability-2011-09-13-Must_see%3A_5_Steps_to_Scaling_MongoDB_%28Or_Any_DB%29_in_8_Minutes.html">1114 high scalability-2011-09-13-Must see: 5 Steps to Scaling MongoDB (Or Any DB) in 8 Minutes</a></p>
<p>16 0.12861094 <a title="1475-tfidf-16" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>17 0.12722036 <a title="1475-tfidf-17" href="../high_scalability-2012/high_scalability-2012-07-09-Data_Replication_in_NoSQL_Databases.html">1279 high scalability-2012-07-09-Data Replication in NoSQL Databases</a></p>
<p>18 0.12588078 <a title="1475-tfidf-18" href="../high_scalability-2009/high_scalability-2009-06-23-Learn_How_to_Exploit_Multiple_Cores_for_Better_Performance_and_Scalability.html">636 high scalability-2009-06-23-Learn How to Exploit Multiple Cores for Better Performance and Scalability</a></p>
<p>19 0.12369037 <a title="1475-tfidf-19" href="../high_scalability-2009/high_scalability-2009-05-05-Drop_ACID_and_Think_About_Data.html">589 high scalability-2009-05-05-Drop ACID and Think About Data</a></p>
<p>20 0.12305509 <a title="1475-tfidf-20" href="../high_scalability-2013/high_scalability-2013-11-08-Stuff_The_Internet_Says_On_Scalability_For_November_8th%2C_2013.html">1545 high scalability-2013-11-08-Stuff The Internet Says On Scalability For November 8th, 2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.211), (1, 0.149), (2, -0.017), (3, 0.03), (4, -0.013), (5, 0.07), (6, 0.047), (7, 0.126), (8, -0.054), (9, -0.05), (10, -0.02), (11, -0.085), (12, 0.013), (13, 0.076), (14, -0.03), (15, -0.007), (16, -0.039), (17, -0.011), (18, -0.065), (19, 0.015), (20, -0.031), (21, 0.006), (22, -0.004), (23, 0.075), (24, -0.056), (25, -0.021), (26, -0.001), (27, -0.063), (28, -0.031), (29, 0.003), (30, 0.021), (31, -0.035), (32, 0.077), (33, -0.018), (34, 0.014), (35, 0.029), (36, 0.012), (37, 0.022), (38, -0.002), (39, -0.023), (40, -0.068), (41, 0.038), (42, 0.017), (43, 0.019), (44, 0.048), (45, -0.044), (46, 0.021), (47, -0.03), (48, 0.049), (49, -0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97876257 <a title="1475-lsi-1" href="../high_scalability-2013/high_scalability-2013-06-13-Busting_4_Modern_Hardware_Myths_-_Are_Memory%2C_HDDs%2C_and_SSDs_Really_Random_Access%3F.html">1475 high scalability-2013-06-13-Busting 4 Modern Hardware Myths - Are Memory, HDDs, and SSDs Really Random Access?</a></p>
<p>Introduction: "It’s all a numbers game – the dirty little secret of scalable systems" 
      
 Martin Thompson  is a High Performance Computing Specialist with a real mission to teach programmers how to understand the innards of modern computing systems. He has many talks and classes (listed below) on caches, buffers, memory controllers, processor architectures, cache lines, etc.
 
His thought is programmers do not put a proper value on understanding how the underpinnings of our systems work. We gravitate to the shiny and trendy. His approach is not to teach people specific programming strategies, but to teach programmers to fish so they can feed themselves. Without a real understanding strategies are easy to apply wrongly.  It's strange how programmers will put a lot of effort into understanding complicated frameworks like Hibernate, but little effort into understanding the underlying hardware on which their programs run.
 
A major tenant of Martin's approach is to "lead by experimental observation</p><p>2 0.84356737 <a title="1475-lsi-2" href="../high_scalability-2013/high_scalability-2013-01-15-More_Numbers_Every_Awesome_Programmer_Must_Know.html">1387 high scalability-2013-01-15-More Numbers Every Awesome Programmer Must Know</a></p>
<p>Introduction: Colin Scott   , a Berkeley researcher, updated Jeff Dean’s famous    Numbers Everyone Should Know    with his    Latency Numbers Every Programmer Should Know    interactive graphic. The interactive aspect is cool because it has a slider that let’s you see numbers back from as early as 1990 to the far far future of 2020.  
 
Colin explained his  motivation for updating the numbers :
  The other day, a friend mentioned a latency number to me, and I realized that it was an order of magnitude smaller than what I had memorized from Jeff’s talk. The problem, of course, is that hardware performance increases exponentially! After some digging, I actually found that the numbers Jeff quotes are over a decade old  
 Since numbers without interpretation are simply data, take a look at    Google Pro Tip: Use Back-Of-The-Envelope-Calculations To Choose The Best Design . The idea is back-of-the-envelope calculations are estimates you create using a combination of thought experiments and common perfor</p><p>3 0.80939192 <a title="1475-lsi-3" href="../high_scalability-2011/high_scalability-2011-06-22-It%27s_the_Fraking_IOPS_-_1_SSD_is_44%2C000_IOPS%2C_Hard_Drive_is_180.html">1066 high scalability-2011-06-22-It's the Fraking IOPS - 1 SSD is 44,000 IOPS, Hard Drive is 180</a></p>
<p>Introduction: Planning your next buildout and thinking SSDs are still far in the future? Still too expensive, too low density. Hard disks are cheap, familiar, and store lots of stuff. In this short and entertaining video Wikia's  Artur Bergman  wants to change your mind about SSDs. SSDs are for today, get with the math already.
 
Here's Artur's logic:
  
 Wikia is all SSD in production. The new Wikia file servers have a theoretical read rate of ~10GB/sec sequential, 6GB/sec random and 1.2 million IOPs. If you can't do math or love the past, you love spinning rust. If you are awesome you love SSDs. 
 SSDs are cheaper than drives using the most relevant metric: $/GB/IOPS. 1 SSD is 44,000 IOPS and one hard drive is 180 IOPS. Need 1 SSD instead of 50 hard drives. 
 With 8 million files there's a 9 minute fsck. Full backup in 12 minutes (X-25M based). 
 4 GB/sec random read average latency 1 msec. 
 2.2 GB/sec random write average latency 1 msec. 
 50TBs of SSDs in one machine for $80,000. With the densi</p><p>4 0.80840629 <a title="1475-lsi-4" href="../high_scalability-2012/high_scalability-2012-05-16-Big_List_of_20_Common_Bottlenecks.html">1246 high scalability-2012-05-16-Big List of 20 Common Bottlenecks</a></p>
<p>Introduction: In   Zen And The Art Of Scaling - A Koan And Epigram Approach  ,   Russell Sullivan   offered an interesting conjecture: there are 20 classic bottlenecks. This sounds suspiciously like the idea that there only   20 basic story plots  . And depending on how you chunkify things, it may be true, but in practice we all know bottlenecks come in infinite flavors, all tasting of sour and ash.  One day  Aurelien Broszniowski  from Terracotta emailed me his list of bottlenecks, we cc’ed Russell in on the conversation, he gave me his list, I have a list, and here’s the resulting stone soup.   Russell said this is his “I wish I knew when I was younger" list and I think that’s an enriching way to look at it. The more experience you have, the more different types of projects you tackle, the more lessons you’ll be able add to a list like this. So when you read this list, and when you make your own, you are stepping through years of accumulated experience and more than a little frustration, but in ea</p><p>5 0.80201167 <a title="1475-lsi-5" href="../high_scalability-2013/high_scalability-2013-06-06-Paper%3A_Memory_Barriers%3A_a_Hardware_View_for_Software_Hackers.html">1471 high scalability-2013-06-06-Paper: Memory Barriers: a Hardware View for Software Hackers</a></p>
<p>Introduction: It's not often you get so enthusiastic a recommendation for a paper as  Sergio Bossa  gives  Memory Barriers: a Hardware View for Software Hackers : If you only want to read one piece about CPUs architecture, cache coherency and memory barriers, make it this one.
 
It is a clear and well written article. It even has a quiz. What's it about?
  

So what possessed CPU designers to cause them to inﬂict memory barriers on poor unsuspecting SMP software designers?


In short, because reordering memory references allows much better performance, and so memory barriers are needed to force ordering in things like synchronization primitives whose correct operation depends on ordered memory references.


Getting a more detailed answer to this question requires a good understanding of how CPU caches work, and especially what is required to make caches really work well. The following sections:

 
 present the structure of a cache, 
 describe how cache-coherency protocols ensure that CPUs agree on t</p><p>6 0.79139525 <a title="1475-lsi-6" href="../high_scalability-2014/high_scalability-2014-01-31-Stuff_The_Internet_Says_On_Scalability_For_January_31st%2C_2014.html">1588 high scalability-2014-01-31-Stuff The Internet Says On Scalability For January 31st, 2014</a></p>
<p>7 0.78360683 <a title="1475-lsi-7" href="../high_scalability-2014/high_scalability-2014-05-21-9_Principles_of_High_Performance_Programs.html">1652 high scalability-2014-05-21-9 Principles of High Performance Programs</a></p>
<p>8 0.76999009 <a title="1475-lsi-8" href="../high_scalability-2012/high_scalability-2012-12-10-Switch_your_databases_to_Flash_storage._Now._Or_you%27re_doing_it_wrong..html">1369 high scalability-2012-12-10-Switch your databases to Flash storage. Now. Or you're doing it wrong.</a></p>
<p>9 0.7631247 <a title="1475-lsi-9" href="../high_scalability-2013/high_scalability-2013-02-15-Stuff_The_Internet_Says_On_Scalability_For_February_15%2C_2013.html">1407 high scalability-2013-02-15-Stuff The Internet Says On Scalability For February 15, 2013</a></p>
<p>10 0.75995898 <a title="1475-lsi-10" href="../high_scalability-2011/high_scalability-2011-01-28-Stuff_The_Internet_Says_On_Scalability_For_January_28%2C_2011.html">980 high scalability-2011-01-28-Stuff The Internet Says On Scalability For January 28, 2011</a></p>
<p>11 0.75694424 <a title="1475-lsi-11" href="../high_scalability-2012/high_scalability-2012-05-02-12_Ways_to_Increase_Throughput_by_32X_and_Reduce_Latency_by__20X.html">1237 high scalability-2012-05-02-12 Ways to Increase Throughput by 32X and Reduce Latency by  20X</a></p>
<p>12 0.75270361 <a title="1475-lsi-12" href="../high_scalability-2013/high_scalability-2013-01-09-The_Story_of_How_Turning_Disk_Into_a_Service_Lead_to_a_Deluge_of_Density.html">1384 high scalability-2013-01-09-The Story of How Turning Disk Into a Service Lead to a Deluge of Density</a></p>
<p>13 0.74836254 <a title="1475-lsi-13" href="../high_scalability-2014/high_scalability-2014-03-20-Paper%3A_Log-structured_Memory_for_DRAM-based_Storage_-_High_Memory_Utilization_Plus_High_Performance.html">1616 high scalability-2014-03-20-Paper: Log-structured Memory for DRAM-based Storage - High Memory Utilization Plus High Performance</a></p>
<p>14 0.74330926 <a title="1475-lsi-14" href="../high_scalability-2011/high_scalability-2011-01-10-Riak%27s_Bitcask_-_A_Log-Structured_Hash_Table_for_Fast_Key-Value_Data.html">971 high scalability-2011-01-10-Riak's Bitcask - A Log-Structured Hash Table for Fast Key-Value Data</a></p>
<p>15 0.74106377 <a title="1475-lsi-15" href="../high_scalability-2013/high_scalability-2013-09-04-Wide_Fast_SATA%3A_the_Recipe_for_Hot_Performance.html">1511 high scalability-2013-09-04-Wide Fast SATA: the Recipe for Hot Performance</a></p>
<p>16 0.73968351 <a title="1475-lsi-16" href="../high_scalability-2012/high_scalability-2012-07-25-Vertical_Scaling_Ascendant_-_How_are_SSDs_Changing__Architectures%3F.html">1291 high scalability-2012-07-25-Vertical Scaling Ascendant - How are SSDs Changing  Architectures?</a></p>
<p>17 0.73787105 <a title="1475-lsi-17" href="../high_scalability-2010/high_scalability-2010-05-05-How_will_memristors_change_everything%3F_.html">823 high scalability-2010-05-05-How will memristors change everything? </a></p>
<p>18 0.73507833 <a title="1475-lsi-18" href="../high_scalability-2013/high_scalability-2013-05-22-Strategy%3A_Stop_Using_Linked-Lists.html">1462 high scalability-2013-05-22-Strategy: Stop Using Linked-Lists</a></p>
<p>19 0.72813219 <a title="1475-lsi-19" href="../high_scalability-2013/high_scalability-2013-11-08-Stuff_The_Internet_Says_On_Scalability_For_November_8th%2C_2013.html">1545 high scalability-2013-11-08-Stuff The Internet Says On Scalability For November 8th, 2013</a></p>
<p>20 0.72804123 <a title="1475-lsi-20" href="../high_scalability-2011/high_scalability-2011-01-26-Google_Pro_Tip%3A_Use_Back-of-the-envelope-calculations_to_Choose_the_Best_Design.html">978 high scalability-2011-01-26-Google Pro Tip: Use Back-of-the-envelope-calculations to Choose the Best Design</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.077), (2, 0.217), (10, 0.086), (30, 0.03), (40, 0.017), (43, 0.122), (47, 0.021), (56, 0.023), (61, 0.075), (77, 0.021), (79, 0.112), (84, 0.012), (85, 0.067), (93, 0.011), (94, 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94566733 <a title="1475-lda-1" href="../high_scalability-2012/high_scalability-2012-01-27-Stuff_The_Internet_Says_On_Scalability_For_January_27%2C_2012.html">1182 high scalability-2012-01-27-Stuff The Internet Says On Scalability For January 27, 2012</a></p>
<p>Introduction: If you’ve got the time, we’ve got the HighScalability:
  
  9nm  : IBM's carbon nanotube transistor that outperforms silicon;  YouTube : 4 Billion Views/Day;  864GB RAM : 37signals Memcache,  $12K  
 Quotable Quotes:                 
 
  Chad Dickerson : You can only get growth by feeding opportunities. 
  @launchany : It amazes me how many NoSQL database vendors spend more time detailing their scalability and no time detailing the data model and design 
  Google : Let's make TCP faster. 
  WhatsApp : we are now able to easily push our systems to over 2 million tcp connections! 
  Sidney Dekker : In a complex system…doing the same thing twice will not predictably or necessarily lead to the same results. 
  @Rasmusfjord : Just heard about an Umbraco site running on Azure that handles 20.000 requests /*second* 
 
 
 Herb Sutter with an epic post,  Welcome to the Jungle , touching on a lot of themes we've explored on HighScalability, only in a dramatically more competent way. What's after</p><p>2 0.94330156 <a title="1475-lda-2" href="../high_scalability-2012/high_scalability-2012-10-09-Batoo_JPA_-_The_new_JPA_Implementation_that_runs_over_15_times_faster....html">1336 high scalability-2012-10-09-Batoo JPA - The new JPA Implementation that runs over 15 times faster...</a></p>
<p>Introduction: This post is by  Hasan Ceylan , an Open Source software enthusiast from Istanbul. 
 
I loved the JPA 1.0 back in early 2000s. I started using it together with EJB 3.0 even before the stable releases. I loved it so much that I contributed bits and parts for JBoss 3.x implementations.
  Those were the days our company was considerably still small in size. Creating new features and applications were more priority than the performance, because there were a lot of ideas that we have and we needed to develop and market those as fast as we can. Now, we no longer needed to write tedious and error prone xml descriptions for the data model and deployment descriptors. Nor we needed to use the curse called “XDoclet”.  On the other side, our company grew steadily, our web site has become the top portal in the country for live events and ticketing. We now had the performance problems! Although the company grew considerably, due to the economics in the industry, we did not make a lot of money. The ch</p><p>same-blog 3 0.9333356 <a title="1475-lda-3" href="../high_scalability-2013/high_scalability-2013-06-13-Busting_4_Modern_Hardware_Myths_-_Are_Memory%2C_HDDs%2C_and_SSDs_Really_Random_Access%3F.html">1475 high scalability-2013-06-13-Busting 4 Modern Hardware Myths - Are Memory, HDDs, and SSDs Really Random Access?</a></p>
<p>Introduction: "It’s all a numbers game – the dirty little secret of scalable systems" 
      
 Martin Thompson  is a High Performance Computing Specialist with a real mission to teach programmers how to understand the innards of modern computing systems. He has many talks and classes (listed below) on caches, buffers, memory controllers, processor architectures, cache lines, etc.
 
His thought is programmers do not put a proper value on understanding how the underpinnings of our systems work. We gravitate to the shiny and trendy. His approach is not to teach people specific programming strategies, but to teach programmers to fish so they can feed themselves. Without a real understanding strategies are easy to apply wrongly.  It's strange how programmers will put a lot of effort into understanding complicated frameworks like Hibernate, but little effort into understanding the underlying hardware on which their programs run.
 
A major tenant of Martin's approach is to "lead by experimental observation</p><p>4 0.93021971 <a title="1475-lda-4" href="../high_scalability-2014/high_scalability-2014-02-28-Stuff_The_Internet_Says_On_Scalability_For_February_28th%2C_2014.html">1603 high scalability-2014-02-28-Stuff The Internet Says On Scalability For February 28th, 2014</a></p>
<p>Introduction: Hey, it's HighScalability time:
     Plus ça change, plus c'est la même chose  ( full )   
 Quotable Quotes:                      
 
  @ML_Hipster : A machine learning researcher, a crypto-currency expert, and an Erlang programmer walk into a bar. Facebook buys the bar for $27 billion. 
 OH: Network effects don't happen on toll roads. 
  Benedict Evans : Google is a vast machine learning engine... and it spent 10-15 years building that learning engine and feeding it data. 
 
 
  Mining Experiment: Running 600 Servers for a Year Yields 0.4 Bitcoin . Yes, this is a far superior way of doing things. Chew up the commons for marginal gain. It's like old times. 
  Game designers, forget the sardines and go hunt some whale .  Swrve found : half of free-to-play games’ in-app purchases came from 0.15 percent of players. Only 1.5 percent of players of games in the Swrve network spent any money at all. 
 Google has a beta version of their  cloud pricing calculator .  The interface is a little fun</p><p>5 0.92726249 <a title="1475-lda-5" href="../high_scalability-2011/high_scalability-2011-07-27-Making_Hadoop_1000x_Faster_for_Graph_Problems.html">1088 high scalability-2011-07-27-Making Hadoop 1000x Faster for Graph Problems</a></p>
<p>Introduction: Dr. Daniel Abadi, author of the  DBMS Musings blog  and Cofounder of  Hadapt , which offers a product improving Hadoop performance by 50x on relational data, is now taking his talents to graph data in  Hadoop's tremendous inefficiency on graph data management (and how to avoid it) , which shares the secrets of getting Hadoop to perform 1000x better on graph data.
 
TL;DR:
  
 Analysing graph data is at the heart of  important data mining problems . 
 Hadoop is the tool of choice for many of these problems. 
 Hadoop style MapReduce works best on KeyValue processing, not graph processing, and can be well over a factor of 1000 less efficient than it needs to be. 
 Hadoop inefficiency has consequences in real world. Inefficiencies on graph data problems like improving power utilization, minimizing carbon emissions, and improving product designs, leads to a lot value being left on the table in the form of negative environmental consequences, increased server costs, increased data center spa</p><p>6 0.92218018 <a title="1475-lda-6" href="../high_scalability-2009/high_scalability-2009-02-01-More_Chips_Means_Less_Salsa.html">505 high scalability-2009-02-01-More Chips Means Less Salsa</a></p>
<p>7 0.91105491 <a title="1475-lda-7" href="../high_scalability-2013/high_scalability-2013-05-17-Stuff_The_Internet_Says_On_Scalability_For_May_17%2C_2013.html">1460 high scalability-2013-05-17-Stuff The Internet Says On Scalability For May 17, 2013</a></p>
<p>8 0.90206128 <a title="1475-lda-8" href="../high_scalability-2011/high_scalability-2011-10-24-StackExchange_Architecture_Updates_-_Running_Smoothly%2C_Amazon_4x_More_Expensive.html">1131 high scalability-2011-10-24-StackExchange Architecture Updates - Running Smoothly, Amazon 4x More Expensive</a></p>
<p>9 0.89616352 <a title="1475-lda-9" href="../high_scalability-2010/high_scalability-2010-03-22-7_Secrets_to_Successfully_Scaling_with_Scalr_%28on_Amazon%29_by_Sebastian_Stadil.html">798 high scalability-2010-03-22-7 Secrets to Successfully Scaling with Scalr (on Amazon) by Sebastian Stadil</a></p>
<p>10 0.89397019 <a title="1475-lda-10" href="../high_scalability-2010/high_scalability-2010-09-01-Paper%3A_The_Case_for_Determinism_in_Database_Systems__.html">890 high scalability-2010-09-01-Paper: The Case for Determinism in Database Systems  </a></p>
<p>11 0.8934238 <a title="1475-lda-11" href="../high_scalability-2012/high_scalability-2012-07-25-Vertical_Scaling_Ascendant_-_How_are_SSDs_Changing__Architectures%3F.html">1291 high scalability-2012-07-25-Vertical Scaling Ascendant - How are SSDs Changing  Architectures?</a></p>
<p>12 0.89328402 <a title="1475-lda-12" href="../high_scalability-2011/high_scalability-2011-11-18-Stuff_The_Internet_Says_On_Scalability_For_November_18%2C_2011.html">1145 high scalability-2011-11-18-Stuff The Internet Says On Scalability For November 18, 2011</a></p>
<p>13 0.89300454 <a title="1475-lda-13" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>14 0.8912645 <a title="1475-lda-14" href="../high_scalability-2011/high_scalability-2011-09-07-What_Google_App_Engine_Price_Changes_Say_About_the_Future_of_Web_Architecture.html">1112 high scalability-2011-09-07-What Google App Engine Price Changes Say About the Future of Web Architecture</a></p>
<p>15 0.89112175 <a title="1475-lda-15" href="../high_scalability-2009/high_scalability-2009-06-05-HotPads_Shows_the_True_Cost_of_Hosting_on_Amazon.html">619 high scalability-2009-06-05-HotPads Shows the True Cost of Hosting on Amazon</a></p>
<p>16 0.89011508 <a title="1475-lda-16" href="../high_scalability-2013/high_scalability-2013-04-12-Stuff_The_Internet_Says_On_Scalability_For_April_12%2C_2013.html">1439 high scalability-2013-04-12-Stuff The Internet Says On Scalability For April 12, 2013</a></p>
<p>17 0.88910812 <a title="1475-lda-17" href="../high_scalability-2007/high_scalability-2007-08-29-Skype_Failed_the_Boot_Scalability_Test%3A_Is_P2P_fundamentally_flawed%3F.html">76 high scalability-2007-08-29-Skype Failed the Boot Scalability Test: Is P2P fundamentally flawed?</a></p>
<p>18 0.88895631 <a title="1475-lda-18" href="../high_scalability-2012/high_scalability-2012-06-22-Stuff_The_Internet_Says_On_Scalability_For_June_22%2C_2012.html">1270 high scalability-2012-06-22-Stuff The Internet Says On Scalability For June 22, 2012</a></p>
<p>19 0.88837034 <a title="1475-lda-19" href="../high_scalability-2009/high_scalability-2009-01-20-Product%3A_Amazon%27s_SimpleDB.html">498 high scalability-2009-01-20-Product: Amazon's SimpleDB</a></p>
<p>20 0.88763565 <a title="1475-lda-20" href="../high_scalability-2010/high_scalability-2010-11-09-Paper%3A_Hyder_-_Scaling_Out_without_Partitioning_.html">937 high scalability-2010-11-09-Paper: Hyder - Scaling Out without Partitioning </a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
