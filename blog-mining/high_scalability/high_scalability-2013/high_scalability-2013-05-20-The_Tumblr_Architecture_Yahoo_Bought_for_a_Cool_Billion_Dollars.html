<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2013" href="../home/high_scalability-2013_home.html">high_scalability-2013</a> <a title="high_scalability-2013-1461" href="#">high_scalability-2013-1461</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2013-1461-html" href="http://highscalability.com//blog/2013/5/20/the-tumblr-architecture-yahoo-bought-for-a-cool-billion-doll.html">html</a></p><p>Introduction: It's being reportedYahoo bought Tumblr for $1.1 billion. You may
recallInstagram was profiled on HighScalabilityand they were also bought by
Facebook for a ton of money. A coincidence? You be the judge.Just what is
Yahoo buying? The business acumen of the deal is not something I can judge,
but if you are doing due diligence on the technology then Tumblr would
probably get a big thumbs up. To see why, please keep on reading...With over
15 billion page views a month Tumblr has become an insanely popular blogging
platform. Users may like Tumblr for its simplicity, its beauty, its strong
focus on user experience, or its friendly and engaged community, but like it
they do.Growing at over 30% a month has not been without challenges. Some
reliability problems among them. It helps to realize that Tumblr operates at
surprisingly huge scales: 500 million page views a day, a peak rate of ~40k
requests per second, ~3TB of new data to store a day, all running on 1000+
servers.One of the common patt</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The direction they are moving in now is towards a distributed services model built around Scala, HBase, Redis, Kafka, Finagle, and an intriguing cell based architecture for powering their Dashboard. [sent-21, score-0.49]
</p><p>2 Users form a connection with other users so they will go hundreds of pages back into the dashboard to read content. [sent-44, score-0.411]
</p><p>3 Includes dashboard notifications, dashboard secondary index, URL shortener, and a memcache proxy to handle transparent sharding. [sent-135, score-0.632]
</p><p>4 Notifications show up in a user's dashboard to indicate actions other users have taken on their content. [sent-162, score-0.411]
</p><p>5 The firehose model is very flexible, not like Twitter's firehose in which data is assumed to be lost. [sent-189, score-0.47]
</p><p>6 You just ask what is in the inbox so it's less expensive then going to each user a user follows. [sent-206, score-0.394]
</p><p>7 Users are homed to a cell and all cells consume all posts via firehose updates. [sent-223, score-0.999]
</p><p>8 Each cell is Finagle based and populates HBase via the firehose and service requests over Thrift. [sent-224, score-0.621]
</p><p>9 A user comes into the Dashboard, users home to a particular cell, a service node reads their dashboard via HBase, and passes the data back. [sent-225, score-0.567]
</p><p>10 Request flow: a user publishes a post, the post is written to the firehose, all of the cells consume the posts and write that post content to post database, the cells lookup to see if any of the followers of the post creator are in the cell, if so the follower inboxes are updated with the post ID. [sent-228, score-1.266]
</p><p>11 Advantages of cell design:Massive scale requires parallelization and parallelization requires components be isolated from each other so there is no interaction. [sent-229, score-0.46]
</p><p>12 Applications don't ask for all the post IDs and then ask for the posts for those IDs. [sent-237, score-0.388]
</p><p>13 Every cell has all the data needed to fulfill a Dashboard request without doing any cross cell communication. [sent-239, score-0.712]
</p><p>14 The second table tells what the user's dashboard looks like which means they don't have to go fetch all the users a user is following. [sent-242, score-0.565]
</p><p>15 So the ID is put in the inbox and the post content is put in the cell just once. [sent-246, score-0.641]
</p><p>16 A user's dashboard doesn't contain the text of a post, just post IDs, and the majority of the growth is in the IDs. [sent-253, score-0.382]
</p><p>17 If only follower posts were stored in a cell then cell would be out of date as the followers changed and some sort of back fill process would be needed. [sent-255, score-1.048]
</p><p>18 Using the cell design and post replication to all cells creates a very robust architecture. [sent-258, score-0.576]
</p><p>19 The number of users homed to a cell is the impact. [sent-267, score-0.479]
</p><p>20 As more cells are added cells can be placed into a cell group that reads from the firehose and then replicates to all cells within the group. [sent-271, score-0.943]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cell', 0.356), ('dashboard', 0.288), ('tumblr', 0.262), ('firehose', 0.209), ('finagle', 0.201), ('posts', 0.192), ('scala', 0.149), ('hbase', 0.146), ('inbox', 0.143), ('redis', 0.142), ('cells', 0.126), ('users', 0.123), ('user', 0.1), ('post', 0.094), ('blake', 0.089), ('services', 0.082), ('php', 0.079), ('follower', 0.077), ('month', 0.076), ('kafka', 0.075), ('jvm', 0.073), ('sharding', 0.07), ('consumer', 0.067), ('followers', 0.067), ('team', 0.066), ('used', 0.066), ('func', 0.065), ('consume', 0.06), ('terms', 0.059), ('started', 0.059), ('mysql', 0.057), ('updates', 0.056), ('memcache', 0.056), ('via', 0.056), ('gearman', 0.055), ('second', 0.054), ('model', 0.052), ('people', 0.052), ('parallelization', 0.052), ('views', 0.052), ('ask', 0.051), ('tumblelog', 0.049), ('startup', 0.049), ('clients', 0.048), ('content', 0.048), ('distribution', 0.047), ('focused', 0.047), ('pulled', 0.046), ('haproxy', 0.045), ('million', 0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999911 <a title="1461-tfidf-1" href="../high_scalability-2013/high_scalability-2013-05-20-The_Tumblr_Architecture_Yahoo_Bought_for_a_Cool_Billion_Dollars.html">1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</a></p>
<p>Introduction: It's being reportedYahoo bought Tumblr for $1.1 billion. You may
recallInstagram was profiled on HighScalabilityand they were also bought by
Facebook for a ton of money. A coincidence? You be the judge.Just what is
Yahoo buying? The business acumen of the deal is not something I can judge,
but if you are doing due diligence on the technology then Tumblr would
probably get a big thumbs up. To see why, please keep on reading...With over
15 billion page views a month Tumblr has become an insanely popular blogging
platform. Users may like Tumblr for its simplicity, its beauty, its strong
focus on user experience, or its friendly and engaged community, but like it
they do.Growing at over 30% a month has not been without challenges. Some
reliability problems among them. It helps to realize that Tumblr operates at
surprisingly huge scales: 500 million page views a day, a peak rate of ~40k
requests per second, ~3TB of new data to store a day, all running on 1000+
servers.One of the common patt</p><p>2 0.9975341 <a title="1461-tfidf-2" href="../high_scalability-2012/high_scalability-2012-02-13-Tumblr_Architecture_-_15_Billion_Page_Views_a_Month_and_Harder_to_Scale_than_Twitter.html">1191 high scalability-2012-02-13-Tumblr Architecture - 15 Billion Page Views a Month and Harder to Scale than Twitter</a></p>
<p>Introduction: With over 15 billion page views a month Tumblr has become an insanely popular
blogging platform. Users may like Tumblr for its simplicity, its beauty, its
strong focus on user experience, or its friendly and engaged community, but
like it they do.Growing at over 30% a month has not been without challenges.
Some reliability problems among them. It helps to realize that Tumblr operates
at surprisingly huge scales: 500 million page views a day, a peak rate of ~40k
requests per second, ~3TB of new data to store a day, all running on 1000+
servers.One of the common patterns across successful startups is the perilous
chasm crossing from startup to wildly successful startup. Finding people,
evolving infrastructures, servicing old infrastructures, while handling huge
month over month increases in traffic, all with only four engineers, means you
have to make difficult choices about what to work on. This was Tumblr's
situation. Now with twenty engineers there's enough energy to work on issues
an</p><p>3 0.9975341 <a title="1461-tfidf-3" href="../high_scalability-2012/high_scalability-2012-11-19-Gone_Fishin%27%3A_Tumblr_Architecture_-_15_Billion_Page_Views_A_Month_And_Harder_To_Scale_Than_Twitter.html">1360 high scalability-2012-11-19-Gone Fishin': Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a></p>
<p>Introduction: With over 15 billion page views a month Tumblr has become an insanely popular
blogging platform. Users may like Tumblr for its simplicity, its beauty, its
strong focus on user experience, or its friendly and engaged community, but
like it they do.Growing at over 30% a month has not been without challenges.
Some reliability problems among them. It helps to realize that Tumblr operates
at surprisingly huge scales: 500 million page views a day, a peak rate of ~40k
requests per second, ~3TB of new data to store a day, all running on 1000+
servers.One of the common patterns across successful startups is the perilous
chasm crossing from startup to wildly successful startup. Finding people,
evolving infrastructures, servicing old infrastructures, while handling huge
month over month increases in traffic, all with only four engineers, means you
have to make difficult choices about what to work on. This was Tumblr's
situation. Now with twenty engineers there's enough energy to work on issues
an</p><p>4 0.43142697 <a title="1461-tfidf-4" href="../high_scalability-2012/high_scalability-2012-05-09-Cell_Architectures.html">1242 high scalability-2012-05-09-Cell Architectures</a></p>
<p>Introduction: A consequence of Service Oriented Architectures is the burning need to provide
services at scale. The architecture that has evolved to satisfy these
requirements is a little known technique called the Cell Architecture.A Cell
Architecture is based on the idea that massive scale requires parallelization
and parallelization requires components be isolated from each other. These
islands of isolation are called cells. A cell is a self-contained installation
that can satisfy all the operations for a shard. A shard is a subset of a much
larger dataset, typically a range of users, for example. Cell Architectures
have several advantages:Cells provide a unit of parallelization that can be
adjusted to any size as the user base grows.Cell are added in an incremental
fashion as more capacity is required.Cells isolate failures. One cell failure
does not impact other cells.Cells provide isolation as the storage and
application horsepower to process requests is independent of other cells.Cells
enable</p><p>5 0.35844985 <a title="1461-tfidf-5" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>Introduction: It remains that, from the same principles, I now demonstrate the frame of the
System of the World.-- Isaac NewtonThe practice of IT reminds me a lot of the
practice of science before Isaac Newton. Aristotelianism was dead, but there
was nothing to replace it. Then Newton came along, created a scientific
revolution with hisSystem of the World. And everything changed. That was New
System of the World number one.New System of the World number two was written
about by the incomparable Neal Stephenson in his incredible Baroque Cycle
series. It explores the singular creation of a new way of organizing society
grounded in new modes of thought in business, religion, politics, and science.
Our modern world emerged Enlightened as it could from this roiling cauldron of
forces.In IT we may have had a Leonardo da Vinci or even a Galileo, but we've
never had our Newton. Maybe we don't need a towering genius to make everything
clear? For years startups, like the frenetically inventive age of the 17th</p><p>6 0.29530352 <a title="1461-tfidf-6" href="../high_scalability-2011/high_scalability-2011-05-17-Facebook%3A_An_Example_Canonical_Architecture_for_Scaling_Billions_of_Messages.html">1042 high scalability-2011-05-17-Facebook: An Example Canonical Architecture for Scaling Billions of Messages</a></p>
<p>7 0.23157325 <a title="1461-tfidf-7" href="../high_scalability-2011/high_scalability-2011-01-20-75%25_Chance_of_Scale_-_Leveraging_the_New_Scaleogenic_Environment_for_Growth.html">976 high scalability-2011-01-20-75% Chance of Scale - Leveraging the New Scaleogenic Environment for Growth</a></p>
<p>8 0.20593175 <a title="1461-tfidf-8" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>9 0.19618209 <a title="1461-tfidf-9" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>10 0.19521129 <a title="1461-tfidf-10" href="../high_scalability-2010/high_scalability-2010-11-16-Facebook%27s_New_Real-time_Messaging_System%3A_HBase_to_Store_135%2B_Billion_Messages_a_Month.html">943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</a></p>
<p>11 0.18654613 <a title="1461-tfidf-11" href="../high_scalability-2008/high_scalability-2008-05-02-Friends_for_Sale_Architecture_-_A_300_Million_Page_View-Month_Facebook_RoR_App.html">313 high scalability-2008-05-02-Friends for Sale Architecture - A 300 Million Page View-Month Facebook RoR App</a></p>
<p>12 0.17822592 <a title="1461-tfidf-12" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>13 0.17731151 <a title="1461-tfidf-13" href="../high_scalability-2012/high_scalability-2012-01-17-Paper%3A_Feeding_Frenzy%3A_Selectively_Materializing_Users%E2%80%99_Event_Feeds.html">1175 high scalability-2012-01-17-Paper: Feeding Frenzy: Selectively Materializing Users’ Event Feeds</a></p>
<p>14 0.16894053 <a title="1461-tfidf-14" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>15 0.16883516 <a title="1461-tfidf-15" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>16 0.16709292 <a title="1461-tfidf-16" href="../high_scalability-2012/high_scalability-2012-08-13-Ask_HighScalability%3A_Facing_scaling_issues_with_news_feeds_on_Redis.__Any_advice%3F.html">1303 high scalability-2012-08-13-Ask HighScalability: Facing scaling issues with news feeds on Redis.  Any advice?</a></p>
<p>17 0.16668609 <a title="1461-tfidf-17" href="../high_scalability-2010/high_scalability-2010-06-10-The_Four_Meta_Secrets_of_Scaling_at_Facebook.html">840 high scalability-2010-06-10-The Four Meta Secrets of Scaling at Facebook</a></p>
<p>18 0.16358045 <a title="1461-tfidf-18" href="../high_scalability-2011/high_scalability-2011-06-27-TripAdvisor_Architecture_-_40M_Visitors%2C_200M_Dynamic_Page_Views%2C_30TB_Data.html">1068 high scalability-2011-06-27-TripAdvisor Architecture - 40M Visitors, 200M Dynamic Page Views, 30TB Data</a></p>
<p>19 0.15932921 <a title="1461-tfidf-19" href="../high_scalability-2014/high_scalability-2014-02-17-How_the_AOL.com_Architecture_Evolved_to_99.999%25_Availability%2C_8_Million_Visitors_Per_Day%2C_and_200%2C000_Requests_Per_Second.html">1597 high scalability-2014-02-17-How the AOL.com Architecture Evolved to 99.999% Availability, 8 Million Visitors Per Day, and 200,000 Requests Per Second</a></p>
<p>20 0.15708245 <a title="1461-tfidf-20" href="../high_scalability-2011/high_scalability-2011-11-29-DataSift_Architecture%3A_Realtime_Datamining_at_120%2C000_Tweets_Per_Second.html">1148 high scalability-2011-11-29-DataSift Architecture: Realtime Datamining at 120,000 Tweets Per Second</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.343), (1, 0.151), (2, -0.045), (3, -0.104), (4, 0.131), (5, -0.065), (6, -0.038), (7, -0.008), (8, 0.093), (9, 0.031), (10, 0.07), (11, 0.321), (12, 0.13), (13, -0.054), (14, -0.087), (15, 0.22), (16, -0.163), (17, -0.292), (18, -0.087), (19, -0.199), (20, -0.209), (21, -0.006), (22, -0.272), (23, -0.149), (24, -0.123), (25, 0.01), (26, -0.029), (27, 0.017), (28, 0.027), (29, -0.077), (30, 0.059), (31, 0.095), (32, 0.17), (33, 0.017), (34, -0.04), (35, 0.149), (36, 0.026), (37, 0.043), (38, 0.078), (39, -0.005), (40, -0.021), (41, -0.023), (42, -0.043), (43, -0.081), (44, -0.021), (45, 0.001), (46, 0.032), (47, -0.009), (48, 0.127), (49, -0.059)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94783092 <a title="1461-lsi-1" href="../high_scalability-2012/high_scalability-2012-02-13-Tumblr_Architecture_-_15_Billion_Page_Views_a_Month_and_Harder_to_Scale_than_Twitter.html">1191 high scalability-2012-02-13-Tumblr Architecture - 15 Billion Page Views a Month and Harder to Scale than Twitter</a></p>
<p>Introduction: With over 15 billion page views a month Tumblr has become an insanely popular
blogging platform. Users may like Tumblr for its simplicity, its beauty, its
strong focus on user experience, or its friendly and engaged community, but
like it they do.Growing at over 30% a month has not been without challenges.
Some reliability problems among them. It helps to realize that Tumblr operates
at surprisingly huge scales: 500 million page views a day, a peak rate of ~40k
requests per second, ~3TB of new data to store a day, all running on 1000+
servers.One of the common patterns across successful startups is the perilous
chasm crossing from startup to wildly successful startup. Finding people,
evolving infrastructures, servicing old infrastructures, while handling huge
month over month increases in traffic, all with only four engineers, means you
have to make difficult choices about what to work on. This was Tumblr's
situation. Now with twenty engineers there's enough energy to work on issues
an</p><p>2 0.94783092 <a title="1461-lsi-2" href="../high_scalability-2012/high_scalability-2012-11-19-Gone_Fishin%27%3A_Tumblr_Architecture_-_15_Billion_Page_Views_A_Month_And_Harder_To_Scale_Than_Twitter.html">1360 high scalability-2012-11-19-Gone Fishin': Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a></p>
<p>Introduction: With over 15 billion page views a month Tumblr has become an insanely popular
blogging platform. Users may like Tumblr for its simplicity, its beauty, its
strong focus on user experience, or its friendly and engaged community, but
like it they do.Growing at over 30% a month has not been without challenges.
Some reliability problems among them. It helps to realize that Tumblr operates
at surprisingly huge scales: 500 million page views a day, a peak rate of ~40k
requests per second, ~3TB of new data to store a day, all running on 1000+
servers.One of the common patterns across successful startups is the perilous
chasm crossing from startup to wildly successful startup. Finding people,
evolving infrastructures, servicing old infrastructures, while handling huge
month over month increases in traffic, all with only four engineers, means you
have to make difficult choices about what to work on. This was Tumblr's
situation. Now with twenty engineers there's enough energy to work on issues
an</p><p>same-blog 3 0.94689316 <a title="1461-lsi-3" href="../high_scalability-2013/high_scalability-2013-05-20-The_Tumblr_Architecture_Yahoo_Bought_for_a_Cool_Billion_Dollars.html">1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</a></p>
<p>Introduction: It's being reportedYahoo bought Tumblr for $1.1 billion. You may
recallInstagram was profiled on HighScalabilityand they were also bought by
Facebook for a ton of money. A coincidence? You be the judge.Just what is
Yahoo buying? The business acumen of the deal is not something I can judge,
but if you are doing due diligence on the technology then Tumblr would
probably get a big thumbs up. To see why, please keep on reading...With over
15 billion page views a month Tumblr has become an insanely popular blogging
platform. Users may like Tumblr for its simplicity, its beauty, its strong
focus on user experience, or its friendly and engaged community, but like it
they do.Growing at over 30% a month has not been without challenges. Some
reliability problems among them. It helps to realize that Tumblr operates at
surprisingly huge scales: 500 million page views a day, a peak rate of ~40k
requests per second, ~3TB of new data to store a day, all running on 1000+
servers.One of the common patt</p><p>4 0.89845121 <a title="1461-lsi-4" href="../high_scalability-2012/high_scalability-2012-05-09-Cell_Architectures.html">1242 high scalability-2012-05-09-Cell Architectures</a></p>
<p>Introduction: A consequence of Service Oriented Architectures is the burning need to provide
services at scale. The architecture that has evolved to satisfy these
requirements is a little known technique called the Cell Architecture.A Cell
Architecture is based on the idea that massive scale requires parallelization
and parallelization requires components be isolated from each other. These
islands of isolation are called cells. A cell is a self-contained installation
that can satisfy all the operations for a shard. A shard is a subset of a much
larger dataset, typically a range of users, for example. Cell Architectures
have several advantages:Cells provide a unit of parallelization that can be
adjusted to any size as the user base grows.Cell are added in an incremental
fashion as more capacity is required.Cells isolate failures. One cell failure
does not impact other cells.Cells provide isolation as the storage and
application horsepower to process requests is independent of other cells.Cells
enable</p><p>5 0.70934832 <a title="1461-lsi-5" href="../high_scalability-2011/high_scalability-2011-05-17-Facebook%3A_An_Example_Canonical_Architecture_for_Scaling_Billions_of_Messages.html">1042 high scalability-2011-05-17-Facebook: An Example Canonical Architecture for Scaling Billions of Messages</a></p>
<p>Introduction: What should the architecture of your scalable, real-time, highly available
service look like? There are as many options as there are developers, but if
you are looking for a general template, this architecture as described by
Prashant Malik, Facebook's lead for theMessagesback end team, in Scaling the
Messages Application Back End, is a very good example to consider. Although
Messages is tasked with handling 135+ billion messages a month, from email,
IM, SMS,  text messages, and Facebook messages, you may think this is an
example of BigArchitecture and doesn't apply to smaller sites. Not so. It's a
good, well thought out example of a non-cloud architecture exhibiting many
qualities any mom would be proud of:Layered- components are independent and
isolated. Service/API Driven- each layer is connected via well defined
interface that is the sole entry point for accessing that service. This
prevents nasty complicated interdependencies. Clients hide behind an
application API. Applications u</p><p>6 0.69931376 <a title="1461-lsi-6" href="../high_scalability-2007/high_scalability-2007-12-22-This_was_a_porn-spam_post.html">190 high scalability-2007-12-22-This was a porn-spam post</a></p>
<p>7 0.55329216 <a title="1461-lsi-7" href="../high_scalability-2010/high_scalability-2010-03-16-1_Billion_Reasons_Why_Adobe_Chose_HBase_.html">795 high scalability-2010-03-16-1 Billion Reasons Why Adobe Chose HBase </a></p>
<p>8 0.55122381 <a title="1461-lsi-8" href="../high_scalability-2012/high_scalability-2012-01-17-Paper%3A_Feeding_Frenzy%3A_Selectively_Materializing_Users%E2%80%99_Event_Feeds.html">1175 high scalability-2012-01-17-Paper: Feeding Frenzy: Selectively Materializing Users’ Event Feeds</a></p>
<p>9 0.54925197 <a title="1461-lsi-9" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>10 0.54345775 <a title="1461-lsi-10" href="../high_scalability-2012/high_scalability-2012-02-16-A_Super_Short_on_the_Youporn_Stack_-_300K_QPS_and_100_Million_Page_Views_Per_Day.html">1194 high scalability-2012-02-16-A Super Short on the Youporn Stack - 300K QPS and 100 Million Page Views Per Day</a></p>
<p>11 0.53598917 <a title="1461-lsi-11" href="../high_scalability-2013/high_scalability-2013-10-28-Design_Decisions_for_Scaling_Your_High_Traffic_Feeds.html">1538 high scalability-2013-10-28-Design Decisions for Scaling Your High Traffic Feeds</a></p>
<p>12 0.53304946 <a title="1461-lsi-12" href="../high_scalability-2011/high_scalability-2011-01-20-75%25_Chance_of_Scale_-_Leveraging_the_New_Scaleogenic_Environment_for_Growth.html">976 high scalability-2011-01-20-75% Chance of Scale - Leveraging the New Scaleogenic Environment for Growth</a></p>
<p>13 0.50973725 <a title="1461-lsi-13" href="../high_scalability-2008/high_scalability-2008-08-18-Forum_sort_order.html">370 high scalability-2008-08-18-Forum sort order</a></p>
<p>14 0.49153945 <a title="1461-lsi-14" href="../high_scalability-2014/high_scalability-2014-01-13-NYTimes_Architecture%3A_No_Head%2C_No_Master%2C_No_Single_Point_of_Failure.html">1577 high scalability-2014-01-13-NYTimes Architecture: No Head, No Master, No Single Point of Failure</a></p>
<p>15 0.4805961 <a title="1461-lsi-15" href="../high_scalability-2014/high_scalability-2014-04-28-How_Disqus_Went_Realtime_with_165K_Messages_Per_Second_and_Less_than_.2_Seconds_Latency.html">1638 high scalability-2014-04-28-How Disqus Went Realtime with 165K Messages Per Second and Less than .2 Seconds Latency</a></p>
<p>16 0.47968006 <a title="1461-lsi-16" href="../high_scalability-2010/high_scalability-2010-11-16-Facebook%27s_New_Real-time_Messaging_System%3A_HBase_to_Store_135%2B_Billion_Messages_a_Month.html">943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</a></p>
<p>17 0.4772557 <a title="1461-lsi-17" href="../high_scalability-2011/high_scalability-2011-07-06-11_Common_Web_Use_Cases_Solved_in_Redis.html">1074 high scalability-2011-07-06-11 Common Web Use Cases Solved in Redis</a></p>
<p>18 0.47667775 <a title="1461-lsi-18" href="../high_scalability-2013/high_scalability-2013-09-18-If_You%27re_Programming_a_Cell_Phone_Like_a_Server_You%27re_Doing_it_Wrong.html">1519 high scalability-2013-09-18-If You're Programming a Cell Phone Like a Server You're Doing it Wrong</a></p>
<p>19 0.47637129 <a title="1461-lsi-19" href="../high_scalability-2012/high_scalability-2012-08-13-Ask_HighScalability%3A_Facing_scaling_issues_with_news_feeds_on_Redis.__Any_advice%3F.html">1303 high scalability-2012-08-13-Ask HighScalability: Facing scaling issues with news feeds on Redis.  Any advice?</a></p>
<p>20 0.47263038 <a title="1461-lsi-20" href="../high_scalability-2012/high_scalability-2012-02-07-Hypertable_Routs_HBase_in_Performance_Test_--_HBase_Overwhelmed_by_Garbage_Collection.html">1189 high scalability-2012-02-07-Hypertable Routs HBase in Performance Test -- HBase Overwhelmed by Garbage Collection</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.111), (2, 0.193), (10, 0.04), (30, 0.027), (33, 0.014), (40, 0.014), (61, 0.31), (73, 0.015), (77, 0.012), (79, 0.093), (85, 0.029), (94, 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98747146 <a title="1461-lda-1" href="../high_scalability-2013/high_scalability-2013-02-22-Stuff_The_Internet_Says_On_Scalability_For_February_22%2C_2013.html">1411 high scalability-2013-02-22-Stuff The Internet Says On Scalability For February 22, 2013</a></p>
<p>Introduction: Hey, it's HighScalability time: Quotable Quotes:@p337er: I have committed some
truly horrendous crimes against scalability today.@ErrataRob: doubling
performance doesn't double scalability.@rsingel: In 2008 when Yahoo.com
linked out, I had a Wired story get 1M visitors in an hour from their
homepage.@philiph: Lets solve this scalability problem with a queuing
system@jaykreps: Transferring data across data centers? Read this page and go
tune your TCP buffer sizes...@gwestr: In which the node community showers
schadenfreude upon the rails community for "scalability is not my problem"
architectures@pbailis:  Makes sense, though I think there's a tradeoff re:
coordination and scalability (always homogeneous vs dynamically
heterogenous)@pembleton: To summarize Yoav's philosophy: we started as quick
as we can and then we accelerated #operationgrandma in #reversim@surfichris:
"We chose Heroku because we believed we could just `heroku scale web=X` when
needed." \- Yeah, because scalability is</p><p>2 0.98441172 <a title="1461-lda-2" href="../high_scalability-2012/high_scalability-2012-07-20-Stuff_The_Internet_Says_On_Scalability_For_July_20%2C_2012.html">1287 high scalability-2012-07-20-Stuff The Internet Says On Scalability For July 20, 2012</a></p>
<p>Introduction: It's HighScalability Time:4 Trillion Objects:Windows Azure StorageQuotable
Quotes:@benjchristensen: "What if we could make the data dense and cheap
instead of sparse and expensive?" James Gosling @liquidrinc@sinetpd360: People
trying new things and sharing is what helps create scalability. Jim Rickabaugh
#siis2012@rbranson: This h1.4xlarge running 160GB PostgreSQL database pushing
~17,200 index scan rows/sec. r_await is 0.79ms, box is 92% idle.@sturadnidge:
faster net and disk greatly reduces repair time and impact so we can load up
the instances with far more datWith Amazonannouncing 2TB SSD instancesthe age
of SSD has almost arrived. Netflix has alreadypublished a very thorough poston
the wonderfulness of SSD for both performance and taming thelong latency tail.
They see100K IOPS or 1GByte/secon a untuned system. Netflix projects: The
hi1.4xlarge configuration is about half the system cost for the same
throughput; The mean read request latency was reduced from 10ms to 2.2ms; The
99th</p><p>3 0.9839049 <a title="1461-lda-3" href="../high_scalability-2008/high_scalability-2008-07-07-Five_Ways_to_Stop_Framework_Fixation_from_Crashing_Your_Scaling_Strategy.html">347 high scalability-2008-07-07-Five Ways to Stop Framework Fixation from Crashing Your Scaling Strategy</a></p>
<p>Introduction: If you've wondered why I haven't been posting lately it's because I've been on
an amazingBeach's motorcycle tourof theAlps(and,and,and,and,and,and,and,and).
My wife (Linda) and I rode two-up on a BMW 1200 GS through the alps in
Germany, Austria, Switzerland, Italy, Slovenia, and Lichtenstein.The trip was
more beautiful than I ever imagined. We rode challenging mountain pass after
mountain pass, froze in the rain, baked in the heat, woke up on excellent
Italian coffee, ate slice after slice of tasty apple strudel, drank dazzling
local wines, smelled the fresh cut grass as the Swiss en masse cut hay for the
winter feeding of their dairy cows, rode the amazing Munich train system,
listened as cow bells tinkled like wind chimes throughout small valleys, drank
water from a pure alpine spring on a blisteringly hot hike, watched local
German folk dancers represent their regions, and had fun in the company of
fellow riders. Magical.They say you'll ride more twists and turns on this trip
than a</p><p>4 0.97361511 <a title="1461-lda-4" href="../high_scalability-2007/high_scalability-2007-11-12-Slashdot_Architecture_-_How_the_Old_Man_of_the_Internet_Learned_to_Scale.html">150 high scalability-2007-11-12-Slashdot Architecture - How the Old Man of the Internet Learned to Scale</a></p>
<p>Introduction: Slashdot effect: overwhelming unprepared sites with an avalanche of reader's
clicks after being mentioned on Slashdot. Sure, we now have the "Digg effect"
and other hot new stars, but Slashdot was the original. And like many stars
from generations past, Slashdot plays the elder statesman's role with with
class, dignity, and restraint. Yet with millions and millions of users
Slashdot is still box office gold and more than keeps up with the young'ins.
And with age comes the wisdom of learning how to handle all those users. Just
how does Slashdot scale and what can you learn by going old school?breakSite:
http://slashdot.orgInformation SourcesSlashdot's Setup, Part 1-
HardwareSlashdot's Setup, Part 2- SoftwareHistory of Slashdot Part 3- Going
CorporateThe History of Slashdot Part 4 - Yesterday, Today, TomorrowThe
PlatformMySQLLinux (CentOS/RHEL)PoundApachePerlMemcachedLVSThe StatsStarted
building the system in 1999.5.5 million user visits per month.7,000 comments
are added every day.Over</p><p>5 0.97158277 <a title="1461-lda-5" href="../high_scalability-2012/high_scalability-2012-01-31-Performance_in_the_Cloud%3A_Business_Jitter_is_Bad.html">1184 high scalability-2012-01-31-Performance in the Cloud: Business Jitter is Bad</a></p>
<p>Introduction: One of the benefits of web applications is that they are generally
transported via TCP, which is a connection-oriented protocol designed to
assure delivery. TCP has a variety of native mechanisms through which delivery
issues can be addressed - from window sizes to selective acks to idle time
specification to ramp up parameters. All these technical knobs and buttons
serve as a way for operators and administrators to tweak the protocol, often
at run time, to ensure the exchange of requests and responses upon which web
applications rely. This is unlike UDP, which is more of a "fire and forget"
protocol in which the server doesn't really care if you receive the data or
not.Now, voice and streaming video and audio over the web has always leveraged
UDP and thus it has always been highly sensitive to jitter. Jitter is, without
getting into layer one (physical) jargon, an undesirable delay in the
otherwise consistent delivery of packets. It causes the delay of and sometimes
outright loss of p</p><p>6 0.97016621 <a title="1461-lda-6" href="../high_scalability-2010/high_scalability-2010-10-28-NoSQL_Took_Away_the_Relational_Model_and_Gave_Nothing_Back.html">930 high scalability-2010-10-28-NoSQL Took Away the Relational Model and Gave Nothing Back</a></p>
<p>7 0.96127278 <a title="1461-lda-7" href="../high_scalability-2009/high_scalability-2009-01-25-Where_do_I_start%3F.html">501 high scalability-2009-01-25-Where do I start?</a></p>
<p>8 0.95817822 <a title="1461-lda-8" href="../high_scalability-2011/high_scalability-2011-11-14-Using_Gossip_Protocols_for_Failure_Detection%2C_Monitoring%2C_Messaging_and_Other_Good_Things.html">1142 high scalability-2011-11-14-Using Gossip Protocols for Failure Detection, Monitoring, Messaging and Other Good Things</a></p>
<p>9 0.95399225 <a title="1461-lda-9" href="../high_scalability-2007/high_scalability-2007-12-05-Easier_Production_Releases_.html">173 high scalability-2007-12-05-Easier Production Releases </a></p>
<p>10 0.9535017 <a title="1461-lda-10" href="../high_scalability-2009/high_scalability-2009-08-08-1dbase_vs._many_and_cloud_hosting_vs._dedicated_server%28s%29%3F.html">675 high scalability-2009-08-08-1dbase vs. many and cloud hosting vs. dedicated server(s)?</a></p>
<p>11 0.95310038 <a title="1461-lda-11" href="../high_scalability-2012/high_scalability-2012-11-19-Gone_Fishin%27%3A_Tumblr_Architecture_-_15_Billion_Page_Views_A_Month_And_Harder_To_Scale_Than_Twitter.html">1360 high scalability-2012-11-19-Gone Fishin': Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a></p>
<p>12 0.9531002 <a title="1461-lda-12" href="../high_scalability-2012/high_scalability-2012-02-13-Tumblr_Architecture_-_15_Billion_Page_Views_a_Month_and_Harder_to_Scale_than_Twitter.html">1191 high scalability-2012-02-13-Tumblr Architecture - 15 Billion Page Views a Month and Harder to Scale than Twitter</a></p>
<p>same-blog 13 0.95289093 <a title="1461-lda-13" href="../high_scalability-2013/high_scalability-2013-05-20-The_Tumblr_Architecture_Yahoo_Bought_for_a_Cool_Billion_Dollars.html">1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</a></p>
<p>14 0.95152134 <a title="1461-lda-14" href="../high_scalability-2010/high_scalability-2010-03-10-Saying_Yes_to_NoSQL%3B_Going_Steady_with_Cassandra_at_Digg.html">793 high scalability-2010-03-10-Saying Yes to NoSQL; Going Steady with Cassandra at Digg</a></p>
<p>15 0.94809151 <a title="1461-lda-15" href="../high_scalability-2010/high_scalability-2010-02-10-ElasticSearch_-_Open_Source%2C_Distributed%2C_RESTful_Search_Engine.html">775 high scalability-2010-02-10-ElasticSearch - Open Source, Distributed, RESTful Search Engine</a></p>
<p>16 0.94524759 <a title="1461-lda-16" href="../high_scalability-2008/high_scalability-2008-05-28-Job_queue_and_search_engine.html">332 high scalability-2008-05-28-Job queue and search engine</a></p>
<p>17 0.94393468 <a title="1461-lda-17" href="../high_scalability-2009/high_scalability-2009-11-09-10_NoSQL_Systems_Reviewed.html">739 high scalability-2009-11-09-10 NoSQL Systems Reviewed</a></p>
<p>18 0.94306946 <a title="1461-lda-18" href="../high_scalability-2008/high_scalability-2008-05-19-Conference%3A_Infoscale_2008_in_Italy_%28June_4-6%29.html">322 high scalability-2008-05-19-Conference: Infoscale 2008 in Italy (June 4-6)</a></p>
<p>19 0.9427917 <a title="1461-lda-19" href="../high_scalability-2007/high_scalability-2007-11-05-Quick_question_about_efficiently_implementing_Facebook_%27news_feed%27_like_functionality.html">141 high scalability-2007-11-05-Quick question about efficiently implementing Facebook 'news feed' like functionality</a></p>
<p>20 0.94263643 <a title="1461-lda-20" href="../high_scalability-2011/high_scalability-2011-04-28-PaaS_on_OpenStack_-_Run_Applications_on_Any_Cloud%2C_Any_Time_Using_Any_Thing.html">1031 high scalability-2011-04-28-PaaS on OpenStack - Run Applications on Any Cloud, Any Time Using Any Thing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
