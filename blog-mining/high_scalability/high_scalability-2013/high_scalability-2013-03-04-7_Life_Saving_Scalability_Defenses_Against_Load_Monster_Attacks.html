<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2013" href="../home/high_scalability-2013_home.html">high_scalability-2013</a> <a title="high_scalability-2013-1415" href="#">high_scalability-2013-1415</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2013-1415-html" href="http://highscalability.com//blog/2013/3/4/7-life-saving-scalability-defenses-against-load-monster-atta.html">html</a></p><p>Introduction: We talked about  42 Monster Problems That Attack As Loads Increase . Here are a few ways you can defend yourself, secrets revealed by scaling masters across the ages. Note that these are low level programming level moves, not large architecture type strategies.
  Use Resources Proportional To a Fixed Limit  
This is probably the most important rule for achieving scalability within an application. What it means:
  
 Find the resource that has a fixed limit that you know you can support. For example, a guarantee to handle a certain number of objects in memory. So if we always use resources proportional to the number of objects it is likely we can prevent resource exhaustion. 
 Devise ways of tying what you need to do to the individual resources. 
  
Some examples:
  
 Keep a list of purchase orders with line items over $20 (or whatever). Do not keep a list of the line items because the number of items can be much larger than the number of purchase orders. You have kept the resource usage</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 What it means:     Find the resource that has a fixed limit that you know you can support. [sent-5, score-0.299]
</p><p>2 So if we always use resources proportional to the number of objects it is likely we can prevent resource exhaustion. [sent-7, score-0.664]
</p><p>3 Some examples:     Keep a list of purchase orders with line items over $20 (or whatever). [sent-9, score-0.341]
</p><p>4 Do not keep a list of the line items because the number of items can be much larger than the number of purchase orders. [sent-10, score-0.675]
</p><p>5 You have kept the resource usage proportional to the number purchase orders and you know how many purchases orders you can support. [sent-11, score-0.808]
</p><p>6 Merging, via aggregation, all operations for an object into one request instead of having a separate request for each operation. [sent-12, score-0.491]
</p><p>7 Merge Aggregation   In merge aggregation separate pieces of data and/or commands are merged into one piece. [sent-14, score-0.779]
</p><p>8 For example, let's say an object has the following command sequence:     create   update   update     These three separate requests can be merged into one request instead of 3. [sent-16, score-0.428]
</p><p>9 Individual changes can be merged into one change event. [sent-19, score-0.317]
</p><p>10 Queues would never grow larger than the number of objects no matter how many events happened. [sent-21, score-0.316]
</p><p>11 Delete Aggregation   In delete aggregation data and/or requests are deleted when possible. [sent-23, score-0.428]
</p><p>12 For example, take the following operations:     create   delete      This would cause the create and delete operations to be deleted. [sent-24, score-0.271]
</p><p>13 Sending operations one by one is much slower than sending all operations in larger batches. [sent-27, score-0.554]
</p><p>14 In change aggregation we are keeping the state that something changed so no matter how many times it has changed we only note that it has changed once. [sent-32, score-0.877]
</p><p>15 In a large system we won't be able to keep a history of everyting that has changed in the system. [sent-35, score-0.237]
</p><p>16 An alarm is only set when an integration period has passed. [sent-38, score-0.291]
</p><p>17 Otherwise we can create alarm storms when hardware is defective or wave after wave of a condition hits. [sent-39, score-0.517]
</p><p>18 For example, in a call processing system, the number of calls would be limited. [sent-41, score-0.302]
</p><p>19 Some examples of load shedding:     limit the number of ftp sessions a node can support. [sent-46, score-0.312]
</p><p>20 a web server redirecting to another server when it is too busy    the public telephone system saying all calls are busy which prevents new calls from being accepted          There are many more strategies and we'll see more of them in later posts. [sent-47, score-0.415]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('aggregationin', 0.358), ('aggregation', 0.277), ('proportional', 0.238), ('calls', 0.17), ('merged', 0.165), ('shedding', 0.155), ('delete', 0.151), ('changed', 0.147), ('alarm', 0.139), ('example', 0.132), ('number', 0.132), ('orders', 0.129), ('resources', 0.121), ('operations', 0.12), ('fixed', 0.113), ('items', 0.11), ('limit', 0.108), ('request', 0.108), ('wave', 0.104), ('purchase', 0.102), ('merge', 0.096), ('objects', 0.095), ('aggregationfrom', 0.09), ('busythe', 0.09), ('createdelete', 0.09), ('createupdateupdatethese', 0.09), ('defective', 0.09), ('everyting', 0.09), ('limitthis', 0.09), ('larger', 0.089), ('pieces', 0.086), ('separate', 0.083), ('period', 0.081), ('sending', 0.081), ('reroutes', 0.08), ('facets', 0.08), ('storms', 0.08), ('change', 0.08), ('note', 0.079), ('resource', 0.078), ('redirecting', 0.075), ('collapsed', 0.075), ('defend', 0.073), ('batch', 0.072), ('one', 0.072), ('examples', 0.072), ('integration', 0.071), ('shed', 0.071), ('rejected', 0.07), ('cooperate', 0.07)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1415-tfidf-1" href="../high_scalability-2013/high_scalability-2013-03-04-7_Life_Saving_Scalability_Defenses_Against_Load_Monster_Attacks.html">1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</a></p>
<p>Introduction: We talked about  42 Monster Problems That Attack As Loads Increase . Here are a few ways you can defend yourself, secrets revealed by scaling masters across the ages. Note that these are low level programming level moves, not large architecture type strategies.
  Use Resources Proportional To a Fixed Limit  
This is probably the most important rule for achieving scalability within an application. What it means:
  
 Find the resource that has a fixed limit that you know you can support. For example, a guarantee to handle a certain number of objects in memory. So if we always use resources proportional to the number of objects it is likely we can prevent resource exhaustion. 
 Devise ways of tying what you need to do to the individual resources. 
  
Some examples:
  
 Keep a list of purchase orders with line items over $20 (or whatever). Do not keep a list of the line items because the number of items can be much larger than the number of purchase orders. You have kept the resource usage</p><p>2 0.49108973 <a title="1415-tfidf-2" href="../high_scalability-2013/high_scalability-2013-03-06-Low_Level_Scalability_Solutions_-_The_Aggregation_Collection.html">1418 high scalability-2013-03-06-Low Level Scalability Solutions - The Aggregation Collection</a></p>
<p>Introduction: What good are problems without solutions? In  42 Monster Problems That Attack As Loads Increase  we talked about problems. In this first post (OK, there was an earlier post, but I'm doing some reorganizing), we'll cover what I call  aggregation  strategies.
 
Keep in mind these are low level architecture type suggestions of how to structure the components of your code and how they interact. We're not talking about massive scale-out clusters here, but of what your applications might like like internally, way below the service level interface level. There's a lot more to the world than evented architectures.
 
Aggregation simply means we aren't using stupid queues. Our queues will be smart. We are deeply aware of queues as containers of work that eventually dictate how the entire system performs. As work containers we know intimately what requests and data sit in our queues and we can use that intelligence to our great advantage.
  Prioritize Work  
The key idea to it all is an almost mi</p><p>3 0.32193846 <a title="1415-tfidf-3" href="../high_scalability-2013/high_scalability-2013-03-11-Low_Level_Scalability_Solutions_-_The_Conditioning_Collection.html">1421 high scalability-2013-03-11-Low Level Scalability Solutions - The Conditioning Collection</a></p>
<p>Introduction: We talked about  42 Monster Problems That Attack As Loads Increase . And in  The Aggregation Collection  we talked about the value of prioritizing work and making smart queues as a way of absorbing and not reflecting traffic spikes.
 
Now we move on to our next batch of strategies where the theme is  conditioning , which is the idea of shaping and controlling flows of work within your application...
  Use Resources Proportional To a Fixed Limit  
This is probably the most important rule for achieving scalability within an application. What it means:
  
 Find the resource that has a fixed limit that you know you can support. For example, a guarantee to handle a certain number of objects in memory. So if we always use resources proportional to the number of objects it is likely we can prevent resource exhaustion. 
 Devise ways of tying what you need to do to the individual resources. 
  
Some examples:
  
 Keep a list of purchase orders with line items over $20 (or whatever). Do not keep</p><p>4 0.16392978 <a title="1415-tfidf-4" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>Introduction: For solutions take a look at:  7 Life Saving Scalability Defenses Against Load Monster Attacks . 
 
This is a look at all the bad things that can happen to your carefully crafted program as loads increase: all hell breaks lose. Sure, you can scale out or scale up, but you can also choose to program better. Make your system handle larger loads. This saves money because fewer boxes are needed and it will make the entire application more reliable and have better response times. And it can be quite satisfying as a programmer.
  Large Number Of Objects  
We usually get into scaling problems when the number of objects gets  larger. Clearly resource usage of all types is stressed as the number of objects grow.
  Continuous Failures Makes An Infinite Event Stream  
During large network failure scenarios there is never time for the system recover. We are in a continual state of stress.
  Lots of High Priority Work  
For example, rerouting is a high priority activity. If there is a large amount</p><p>5 0.11940979 <a title="1415-tfidf-5" href="../high_scalability-2008/high_scalability-2008-10-08-Strategy%3A_Flickr_-_Do_the_Essential_Work_Up-front_and_Queue_the_Rest_.html">406 high scalability-2008-10-08-Strategy: Flickr - Do the Essential Work Up-front and Queue the Rest </a></p>
<p>Introduction: This strategy is stated perfectly by Flickr's Myles Grant:   The Flickr engineering team is obsessed with making pages load as quickly as possible. To that end, weâ&euro;&trade;re refactoring large amounts of our code to do only the essential work up front, and rely on our queuing system to do the rest.   Flickr uses a queuing system to process 11 million tasks a day. Leslie Michael Orchard also does a great job explaining the queuing meme in his excellent post   Queue everything and delight everyone  . Asynchronous work queues are how you scalably solve problems that are too big to handle in real-time.     The process:     Identify the minimum feedback the client (UI, API) needs to know an operation succeeded . It's enough, for example, to update a client's view when a posting a message to a microblogging service. The client probably isn't aware of all the other steps that happen when a message is added and doesn't really care when they happen as long as the obvious cases happen in an appropariate</p><p>6 0.11668457 <a title="1415-tfidf-6" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>7 0.11668102 <a title="1415-tfidf-7" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>8 0.11349083 <a title="1415-tfidf-8" href="../high_scalability-2007/high_scalability-2007-09-18-Amazon_Architecture.html">96 high scalability-2007-09-18-Amazon Architecture</a></p>
<p>9 0.11184981 <a title="1415-tfidf-9" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>10 0.11167137 <a title="1415-tfidf-10" href="../high_scalability-2008/high_scalability-2008-06-06-Economies_of_Non-Scale.html">340 high scalability-2008-06-06-Economies of Non-Scale</a></p>
<p>11 0.1066509 <a title="1415-tfidf-11" href="../high_scalability-2014/high_scalability-2014-02-05-Little%E2%80%99s_Law%2C_Scalability_and_Fault_Tolerance%3A_The_OS_is_your_bottleneck._What_you_can_do%3F.html">1591 high scalability-2014-02-05-Little’s Law, Scalability and Fault Tolerance: The OS is your bottleneck. What you can do?</a></p>
<p>12 0.10433201 <a title="1415-tfidf-12" href="../high_scalability-2010/high_scalability-2010-01-17-Applications_Become_Black_Boxes_Using_Markets_to_Scale_and_Control_Costs.html">761 high scalability-2010-01-17-Applications Become Black Boxes Using Markets to Scale and Control Costs</a></p>
<p>13 0.10325781 <a title="1415-tfidf-13" href="../high_scalability-2013/high_scalability-2013-03-25-AppBackplane_-_A_Framework_for_Supporting_Multiple_Application_Architectures.html">1429 high scalability-2013-03-25-AppBackplane - A Framework for Supporting Multiple Application Architectures</a></p>
<p>14 0.096135601 <a title="1415-tfidf-14" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>15 0.093657397 <a title="1415-tfidf-15" href="../high_scalability-2010/high_scalability-2010-12-20-Netflix%3A_Use_Less_Chatty_Protocols_in_the_Cloud_-_Plus_26_Fixes.html">960 high scalability-2010-12-20-Netflix: Use Less Chatty Protocols in the Cloud - Plus 26 Fixes</a></p>
<p>16 0.092823431 <a title="1415-tfidf-16" href="../high_scalability-2008/high_scalability-2008-02-21-Tracking_usage_of_public_resources_-_throttling_accesses_per_hour.html">256 high scalability-2008-02-21-Tracking usage of public resources - throttling accesses per hour</a></p>
<p>17 0.092331275 <a title="1415-tfidf-17" href="../high_scalability-2009/high_scalability-2009-10-26-Facebook%27s_Memcached_Multiget_Hole%3A_More_machines_%21%3D_More_Capacity_.html">728 high scalability-2009-10-26-Facebook's Memcached Multiget Hole: More machines != More Capacity </a></p>
<p>18 0.092101969 <a title="1415-tfidf-18" href="../high_scalability-2010/high_scalability-2010-08-16-Scaling_an_AWS_infrastructure_-_Tools_and_Patterns.html">881 high scalability-2010-08-16-Scaling an AWS infrastructure - Tools and Patterns</a></p>
<p>19 0.091360509 <a title="1415-tfidf-19" href="../high_scalability-2011/high_scalability-2011-07-06-11_Common_Web_Use_Cases_Solved_in_Redis.html">1074 high scalability-2011-07-06-11 Common Web Use Cases Solved in Redis</a></p>
<p>20 0.090910569 <a title="1415-tfidf-20" href="../high_scalability-2011/high_scalability-2011-09-26-17_Techniques_Used_to_Scale_Turntable.fm_and_Labmeeting_to_Millions_of_Users.html">1124 high scalability-2011-09-26-17 Techniques Used to Scale Turntable.fm and Labmeeting to Millions of Users</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.171), (1, 0.102), (2, -0.013), (3, -0.023), (4, -0.021), (5, -0.006), (6, 0.075), (7, 0.068), (8, -0.107), (9, -0.074), (10, -0.011), (11, 0.094), (12, -0.007), (13, -0.016), (14, 0.069), (15, -0.038), (16, -0.016), (17, -0.012), (18, 0.023), (19, 0.042), (20, -0.008), (21, -0.043), (22, 0.06), (23, 0.014), (24, 0.052), (25, -0.01), (26, 0.031), (27, 0.104), (28, 0.052), (29, -0.024), (30, 0.031), (31, 0.009), (32, 0.097), (33, 0.037), (34, 0.037), (35, 0.013), (36, -0.01), (37, -0.067), (38, -0.01), (39, -0.036), (40, -0.0), (41, -0.006), (42, 0.038), (43, 0.018), (44, -0.041), (45, -0.034), (46, -0.029), (47, 0.059), (48, -0.008), (49, 0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9663555 <a title="1415-lsi-1" href="../high_scalability-2013/high_scalability-2013-03-04-7_Life_Saving_Scalability_Defenses_Against_Load_Monster_Attacks.html">1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</a></p>
<p>Introduction: We talked about  42 Monster Problems That Attack As Loads Increase . Here are a few ways you can defend yourself, secrets revealed by scaling masters across the ages. Note that these are low level programming level moves, not large architecture type strategies.
  Use Resources Proportional To a Fixed Limit  
This is probably the most important rule for achieving scalability within an application. What it means:
  
 Find the resource that has a fixed limit that you know you can support. For example, a guarantee to handle a certain number of objects in memory. So if we always use resources proportional to the number of objects it is likely we can prevent resource exhaustion. 
 Devise ways of tying what you need to do to the individual resources. 
  
Some examples:
  
 Keep a list of purchase orders with line items over $20 (or whatever). Do not keep a list of the line items because the number of items can be much larger than the number of purchase orders. You have kept the resource usage</p><p>2 0.9122622 <a title="1415-lsi-2" href="../high_scalability-2013/high_scalability-2013-03-06-Low_Level_Scalability_Solutions_-_The_Aggregation_Collection.html">1418 high scalability-2013-03-06-Low Level Scalability Solutions - The Aggregation Collection</a></p>
<p>Introduction: What good are problems without solutions? In  42 Monster Problems That Attack As Loads Increase  we talked about problems. In this first post (OK, there was an earlier post, but I'm doing some reorganizing), we'll cover what I call  aggregation  strategies.
 
Keep in mind these are low level architecture type suggestions of how to structure the components of your code and how they interact. We're not talking about massive scale-out clusters here, but of what your applications might like like internally, way below the service level interface level. There's a lot more to the world than evented architectures.
 
Aggregation simply means we aren't using stupid queues. Our queues will be smart. We are deeply aware of queues as containers of work that eventually dictate how the entire system performs. As work containers we know intimately what requests and data sit in our queues and we can use that intelligence to our great advantage.
  Prioritize Work  
The key idea to it all is an almost mi</p><p>3 0.88591361 <a title="1415-lsi-3" href="../high_scalability-2013/high_scalability-2013-03-11-Low_Level_Scalability_Solutions_-_The_Conditioning_Collection.html">1421 high scalability-2013-03-11-Low Level Scalability Solutions - The Conditioning Collection</a></p>
<p>Introduction: We talked about  42 Monster Problems That Attack As Loads Increase . And in  The Aggregation Collection  we talked about the value of prioritizing work and making smart queues as a way of absorbing and not reflecting traffic spikes.
 
Now we move on to our next batch of strategies where the theme is  conditioning , which is the idea of shaping and controlling flows of work within your application...
  Use Resources Proportional To a Fixed Limit  
This is probably the most important rule for achieving scalability within an application. What it means:
  
 Find the resource that has a fixed limit that you know you can support. For example, a guarantee to handle a certain number of objects in memory. So if we always use resources proportional to the number of objects it is likely we can prevent resource exhaustion. 
 Devise ways of tying what you need to do to the individual resources. 
  
Some examples:
  
 Keep a list of purchase orders with line items over $20 (or whatever). Do not keep</p><p>4 0.85435963 <a title="1415-lsi-4" href="../high_scalability-2013/high_scalability-2013-03-25-AppBackplane_-_A_Framework_for_Supporting_Multiple_Application_Architectures.html">1429 high scalability-2013-03-25-AppBackplane - A Framework for Supporting Multiple Application Architectures</a></p>
<p>Introduction: Hidden in every computer is a hardware backplane for moving signals around. Hidden in every application are ways of moving messages around and giving code CPU time to process them. Unhiding those capabilities and making them first class facilities for the programmer to control is the idea behind AppBackplane.
 
This goes directly against the trend of hiding everything from the programmer and doing it all automagically. Which is great, until it doesn't work. Then it sucks. And the approach of giving the programmer all the power also sucks, until it's tuned to work together and performance is incredible even under increasing loads. Then it's great.
 
These are two different curves going in opposite directions. You need to decide for your application which curve you need to be on.
 
AppBackplane is an example framework supporting the multiple  application architectures we talked about in  Beyond Threads And Callbacks .  It provides a scheduling system that supports continuous and high loa</p><p>5 0.83227676 <a title="1415-lsi-5" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>Introduction: For solutions take a look at:  7 Life Saving Scalability Defenses Against Load Monster Attacks . 
 
This is a look at all the bad things that can happen to your carefully crafted program as loads increase: all hell breaks lose. Sure, you can scale out or scale up, but you can also choose to program better. Make your system handle larger loads. This saves money because fewer boxes are needed and it will make the entire application more reliable and have better response times. And it can be quite satisfying as a programmer.
  Large Number Of Objects  
We usually get into scaling problems when the number of objects gets  larger. Clearly resource usage of all types is stressed as the number of objects grow.
  Continuous Failures Makes An Infinite Event Stream  
During large network failure scenarios there is never time for the system recover. We are in a continual state of stress.
  Lots of High Priority Work  
For example, rerouting is a high priority activity. If there is a large amount</p><p>6 0.80353457 <a title="1415-lsi-6" href="../high_scalability-2013/high_scalability-2013-03-18-Beyond_Threads_and_Callbacks_-_Application_Architecture_Pros_and_Cons.html">1425 high scalability-2013-03-18-Beyond Threads and Callbacks - Application Architecture Pros and Cons</a></p>
<p>7 0.79827142 <a title="1415-lsi-7" href="../high_scalability-2008/high_scalability-2008-10-08-Strategy%3A_Flickr_-_Do_the_Essential_Work_Up-front_and_Queue_the_Rest_.html">406 high scalability-2008-10-08-Strategy: Flickr - Do the Essential Work Up-front and Queue the Rest </a></p>
<p>8 0.77707601 <a title="1415-lsi-8" href="../high_scalability-2010/high_scalability-2010-02-05-High_Availability_Principle_%3A_Concurrency_Control.html">772 high scalability-2010-02-05-High Availability Principle : Concurrency Control</a></p>
<p>9 0.74539465 <a title="1415-lsi-9" href="../high_scalability-2011/high_scalability-2011-03-09-Google_and_Netflix_Strategy%3A_Use_Partial_Responses_to_Reduce_Request_Sizes.html">1001 high scalability-2011-03-09-Google and Netflix Strategy: Use Partial Responses to Reduce Request Sizes</a></p>
<p>10 0.71015608 <a title="1415-lsi-10" href="../high_scalability-2009/high_scalability-2009-04-10-counting_%23_of_views%2C_calculating_most-least_viewed.html">564 high scalability-2009-04-10-counting # of views, calculating most-least viewed</a></p>
<p>11 0.70561397 <a title="1415-lsi-11" href="../high_scalability-2013/high_scalability-2013-05-08-Typesafe_Interview%3A_Scala_%2B_Akka_is_an_IaaS_for_Your_Process_Architecture.html">1454 high scalability-2013-05-08-Typesafe Interview: Scala + Akka is an IaaS for Your Process Architecture</a></p>
<p>12 0.70105916 <a title="1415-lsi-12" href="../high_scalability-2010/high_scalability-2010-12-20-Netflix%3A_Use_Less_Chatty_Protocols_in_the_Cloud_-_Plus_26_Fixes.html">960 high scalability-2010-12-20-Netflix: Use Less Chatty Protocols in the Cloud - Plus 26 Fixes</a></p>
<p>13 0.69238532 <a title="1415-lsi-13" href="../high_scalability-2007/high_scalability-2007-12-21-Strategy%3A_Limit_Result_Sets.html">189 high scalability-2007-12-21-Strategy: Limit Result Sets</a></p>
<p>14 0.68850672 <a title="1415-lsi-14" href="../high_scalability-2012/high_scalability-2012-12-17-11_Uses_For_the_Humble_Presents_Queue%2C_er%2C_Message_Queue.html">1373 high scalability-2012-12-17-11 Uses For the Humble Presents Queue, er, Message Queue</a></p>
<p>15 0.68650794 <a title="1415-lsi-15" href="../high_scalability-2014/high_scalability-2014-02-05-Little%E2%80%99s_Law%2C_Scalability_and_Fault_Tolerance%3A_The_OS_is_your_bottleneck._What_you_can_do%3F.html">1591 high scalability-2014-02-05-Little’s Law, Scalability and Fault Tolerance: The OS is your bottleneck. What you can do?</a></p>
<p>16 0.67446208 <a title="1415-lsi-16" href="../high_scalability-2008/high_scalability-2008-09-30-Scalability_Worst_Practices.html">398 high scalability-2008-09-30-Scalability Worst Practices</a></p>
<p>17 0.67040336 <a title="1415-lsi-17" href="../high_scalability-2014/high_scalability-2014-03-31-How_WhatsApp_Grew_to_Nearly_500_Million_Users%2C_11%2C000_cores%2C_and_70_Million_Messages_a_Second.html">1622 high scalability-2014-03-31-How WhatsApp Grew to Nearly 500 Million Users, 11,000 cores, and 70 Million Messages a Second</a></p>
<p>18 0.66800714 <a title="1415-lsi-18" href="../high_scalability-2008/high_scalability-2008-07-15-ZooKeeper_-_A_Reliable%2C_Scalable_Distributed_Coordination_System_.html">350 high scalability-2008-07-15-ZooKeeper - A Reliable, Scalable Distributed Coordination System </a></p>
<p>19 0.66018015 <a title="1415-lsi-19" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>20 0.65728939 <a title="1415-lsi-20" href="../high_scalability-2012/high_scalability-2012-04-17-YouTube_Strategy%3A_Adding_Jitter_isn%27t_a_Bug.html">1229 high scalability-2012-04-17-YouTube Strategy: Adding Jitter isn't a Bug</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.084), (2, 0.309), (10, 0.055), (26, 0.018), (30, 0.023), (37, 0.222), (40, 0.022), (61, 0.064), (79, 0.093), (94, 0.024)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9359442 <a title="1415-lda-1" href="../high_scalability-2010/high_scalability-2010-09-01-Scale-out_vs_Scale-up.html">891 high scalability-2010-09-01-Scale-out vs Scale-up</a></p>
<p>Introduction: In this post I'll cover the difference between multi-core concurrency that is often referred to as Scale-Up and distributed computing that is often referred to as Scale-Out mode.Â 
 
 more ..</p><p>2 0.92277527 <a title="1415-lda-2" href="../high_scalability-2012/high_scalability-2012-12-31-Designing_for_Resiliency_will_be_so_2013.html">1379 high scalability-2012-12-31-Designing for Resiliency will be so 2013</a></p>
<p>Introduction: A big part of engineering for a quality experience is bringing in the  long tail . An improbable severe failure can ruin your experience of a site, even if your average experience is quite good. That's where building for  resilience  comes in. Resiliency used to be outside the realm of possibility for the common system. It was simply too complex and too expensive.
 
An evolution has been underway, making 2013 possibly the first time resiliency is truly on the table as a standard part of system architectures. We are getting the clouds, we are getting the tools, and prices are almost low enough.
 
Even Netflix,  real leaders  in the resiliency architecture game, took some heat for relying completely on Amazon's ELB and not having a backup load balancing system, leading to a prolonged  Christmas Eve failure . Adrian Cockcroft, Cloud Architect at Netflix,  said they've investigated  creating their own load balancing service, but that "we try not to invest in undifferentiated heavy lifting.</p><p>3 0.92244238 <a title="1415-lda-3" href="../high_scalability-2007/high_scalability-2007-09-28-Kosmos_File_System_%28KFS%29_is_a_New_High_End_Google_File_System_Option.html">103 high scalability-2007-09-28-Kosmos File System (KFS) is a New High End Google File System Option</a></p>
<p>Introduction: There's a new clustered file system on the spindle:   Kosmos File System (KFS)  .  Thanks to Rich Skrenta for turning me on to KFS and I think his blog   post   says it all.  KFS is an open source project written in C++ by search startup   Kosmix  . The team members have a good   pedigree   so there's a better than average chance this software will be worth considering.     After you stop trying to turn KFS into "Kentucky Fried File System" in your mind,  take a look at KFS' intriguing feature set:           Incremental scalability: New chunkserver nodes can be added as storage needs increase; the system automatically adapts to the new nodes.  Availability: Replication is used to provide availability due to chunk server failures. Typically, files are replicated 3-way.   Per file degree of replication: The degree of replication is configurable on a per file basis, with a max. limit of 64.   Re-replication: Whenever the degree of replication for a file drops below the configured amount (</p><p>4 0.90765297 <a title="1415-lda-4" href="../high_scalability-2010/high_scalability-2010-12-29-Pinboard.in_Architecture_-_Pay_to_Play_to_Keep_a_System_Small__.html">965 high scalability-2010-12-29-Pinboard.in Architecture - Pay to Play to Keep a System Small  </a></p>
<p>Introduction: How do you keep a system small enough, while still being successful, that a simple scale-up strategy becomes the preferred architecture?  StackOverflow , for example, could stick with a tool chain they were comfortable with because they had a natural brake on how fast they could grow: there are only so many programmers in the world. If this doesn't work for you, here's another natural braking strategy to consider:  charge for your service .  Paul Houle  summarized this nicely as:  avoid scaling problems by building a service that's profitable at a small scale .
 
This interesting point, one I hadn't properly considered before, was brought up by Maciej Ceglowski, co-founder of  Pinboard.in , in an interview with Leo Laporte and Amber MacArthur on their their  net@night  show.
 
Pinboard is a lean, mean, pay for bookmarking machine, a timely replacement for the nearly departed Delicious. And as a self professed anti-social bookmarking site, it  emphasizes speed over socializing . Maciej</p><p>same-blog 5 0.9071548 <a title="1415-lda-5" href="../high_scalability-2013/high_scalability-2013-03-04-7_Life_Saving_Scalability_Defenses_Against_Load_Monster_Attacks.html">1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</a></p>
<p>Introduction: We talked about  42 Monster Problems That Attack As Loads Increase . Here are a few ways you can defend yourself, secrets revealed by scaling masters across the ages. Note that these are low level programming level moves, not large architecture type strategies.
  Use Resources Proportional To a Fixed Limit  
This is probably the most important rule for achieving scalability within an application. What it means:
  
 Find the resource that has a fixed limit that you know you can support. For example, a guarantee to handle a certain number of objects in memory. So if we always use resources proportional to the number of objects it is likely we can prevent resource exhaustion. 
 Devise ways of tying what you need to do to the individual resources. 
  
Some examples:
  
 Keep a list of purchase orders with line items over $20 (or whatever). Do not keep a list of the line items because the number of items can be much larger than the number of purchase orders. You have kept the resource usage</p><p>6 0.90340656 <a title="1415-lda-6" href="../high_scalability-2011/high_scalability-2011-04-25-The_Big_List_of_Articles_on_the_Amazon_Outage.html">1029 high scalability-2011-04-25-The Big List of Articles on the Amazon Outage</a></p>
<p>7 0.90032113 <a title="1415-lda-7" href="../high_scalability-2011/high_scalability-2011-05-02-The_Updated_Big_List_of_Articles_on_the_Amazon_Outage.html">1033 high scalability-2011-05-02-The Updated Big List of Articles on the Amazon Outage</a></p>
<p>8 0.8962577 <a title="1415-lda-8" href="../high_scalability-2011/high_scalability-2011-10-27-Strategy%3A_Survive_a_Comet_Strike_in_the_East_With_Reserved_Instances_in_the_West.html">1133 high scalability-2011-10-27-Strategy: Survive a Comet Strike in the East With Reserved Instances in the West</a></p>
<p>9 0.88600796 <a title="1415-lda-9" href="../high_scalability-2008/high_scalability-2008-04-29-Strategy%3A_Sample_to_Reduce_Data_Set.html">311 high scalability-2008-04-29-Strategy: Sample to Reduce Data Set</a></p>
<p>10 0.87554276 <a title="1415-lda-10" href="../high_scalability-2009/high_scalability-2009-06-05-SSL_RPC_API_Scalability.html">620 high scalability-2009-06-05-SSL RPC API Scalability</a></p>
<p>11 0.8632372 <a title="1415-lda-11" href="../high_scalability-2012/high_scalability-2012-12-03-Resiliency_is_the_New_Normal_-_A_Deep_Look_at_What_It_Means_and_How_to_Build_It.html">1366 high scalability-2012-12-03-Resiliency is the New Normal - A Deep Look at What It Means and How to Build It</a></p>
<p>12 0.86121118 <a title="1415-lda-12" href="../high_scalability-2013/high_scalability-2013-03-06-Low_Level_Scalability_Solutions_-_The_Aggregation_Collection.html">1418 high scalability-2013-03-06-Low Level Scalability Solutions - The Aggregation Collection</a></p>
<p>13 0.85252261 <a title="1415-lda-13" href="../high_scalability-2008/high_scalability-2008-05-03-Product%3A_nginx.html">314 high scalability-2008-05-03-Product: nginx</a></p>
<p>14 0.83868837 <a title="1415-lda-14" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>15 0.83537078 <a title="1415-lda-15" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>16 0.83374184 <a title="1415-lda-16" href="../high_scalability-2013/high_scalability-2013-03-11-Low_Level_Scalability_Solutions_-_The_Conditioning_Collection.html">1421 high scalability-2013-03-11-Low Level Scalability Solutions - The Conditioning Collection</a></p>
<p>17 0.83317763 <a title="1415-lda-17" href="../high_scalability-2008/high_scalability-2008-01-24-Mailinator_Architecture.html">221 high scalability-2008-01-24-Mailinator Architecture</a></p>
<p>18 0.83263266 <a title="1415-lda-18" href="../high_scalability-2010/high_scalability-2010-12-20-Netflix%3A_Use_Less_Chatty_Protocols_in_the_Cloud_-_Plus_26_Fixes.html">960 high scalability-2010-12-20-Netflix: Use Less Chatty Protocols in the Cloud - Plus 26 Fixes</a></p>
<p>19 0.83054978 <a title="1415-lda-19" href="../high_scalability-2013/high_scalability-2013-01-15-More_Numbers_Every_Awesome_Programmer_Must_Know.html">1387 high scalability-2013-01-15-More Numbers Every Awesome Programmer Must Know</a></p>
<p>20 0.83026946 <a title="1415-lda-20" href="../high_scalability-2013/high_scalability-2013-12-23-What_Happens_While_Your_Brain_Sleeps_is_Surprisingly_Like_How_Computers_Stay_Sane.html">1568 high scalability-2013-12-23-What Happens While Your Brain Sleeps is Surprisingly Like How Computers Stay Sane</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
