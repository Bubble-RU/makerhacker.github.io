<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1488 high scalability-2013-07-08-The Architecture Twitter Uses to Deal with 150M Active Users, 300K QPS, a 22 MB-S Firehose, and Send Tweets in Under 5 Seconds</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2013" href="../home/high_scalability-2013_home.html">high_scalability-2013</a> <a title="high_scalability-2013-1488" href="#">high_scalability-2013-1488</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1488 high scalability-2013-07-08-The Architecture Twitter Uses to Deal with 150M Active Users, 300K QPS, a 22 MB-S Firehose, and Send Tweets in Under 5 Seconds</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2013-1488-html" href="http://highscalability.com//blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html">html</a></p><p>Introduction: Toy solutions solving Twitter's "problems" are a favorite scalability trope.
Everybody has this idea that Twitter is easy. With a little architectural hand
waving we have a scalable Twitter, just that simple. Well, it's not that
simple asRaffi Krikorian, VP of Engineering at Twitter, describes in his
superb and very detailed presentation onTimelines at Scale. If you want to
know how Twitter works - then start here.It happened gradually so you may have
missed it, but Twitter has grown up. It started as a strugglingthree-tierish
Ruby on Railswebsite to become a beautifully service driven core that we
actually go to now to see if other services are down. Quite a change.Twitter
now has 150M world wide active users, handles 300K QPS to generate timelines,
and a firehose that churns out 22 MB/sec. 400 million tweets a day flow
through the system and it can take up to 5 minutes for a tweet to flow from
Lady Gaga's fingers to her 31 million followers.A couple of points stood
out:Twitter no lon</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 400 million tweets a day flow through the system and it can take up to 5 minutes for a tweet to flow from Lady Gaga's fingers to her 31 million followers. [sent-10, score-0.907]
</p><p>2 Twitter tries to do it under 5 seconds, but it doesn't always work, especially when celebrities tweet and tweet each other, which is happening more and more. [sent-17, score-1.014]
</p><p>3 Your home timeline sits in a Redis cluster and has a maximum of 800 entries. [sent-20, score-0.637]
</p><p>4 Do a lot of processing when tweets arrive to figure out where tweets should go. [sent-34, score-0.658]
</p><p>5 Two main types of timelines: user timeline and home timeline. [sent-55, score-0.683]
</p><p>6 A user timeline is all the tweets a particular user has sent. [sent-56, score-0.944]
</p><p>7 A home timeline is a temporal merge of all the user timelines of the people are you are following. [sent-57, score-0.955]
</p><p>8 When you login they look at your social graph and only send messages out from people you follow, recreating the home timeline experience. [sent-80, score-0.748]
</p><p>9 What is being stored is the tweet ID of the generated tweet, the user ID of the originator of the tweet, and 4 bytes of bits used to mark if it's a retweet or a reply or something else. [sent-103, score-0.73]
</p><p>10 Your home timeline sits in a Redis cluster and is 800 entries long. [sent-104, score-0.637]
</p><p>11 When you query for your home timeline the Timeline Service is queried. [sent-118, score-0.644]
</p><p>12 Since the timeline only contains tweet IDs they must "hydrate" those tweets, that is find the text of the tweets. [sent-125, score-0.974]
</p><p>13 In fanout a tweet may be stored in N home timelines of how many people are following you, in Early Bird a tweet is only stored in one Early Bird machine (except for replication). [sent-139, score-1.753]
</p><p>14 As you are favoriting and replying to tweets an activity timeline is maintained, similar to the home timeline, it is a series of IDs of pieces of activity, so there's favorite ID, a reply ID, etc. [sent-146, score-1.035]
</p><p>15 when a tweet  comes in there's an O(n) process to write to Redis clusters, where n is the number of people following you. [sent-155, score-0.641]
</p><p>16 All the Redis clusters are backing disk, the Flock cluster stores the user timeline to disk, but usually timelines are found in RAM in the Redis cluster. [sent-157, score-0.795]
</p><p>17 If it takes minutes for a tweet from Lady Gaga to fanout then people are seeing her tweets at different points in time. [sent-199, score-1.107]
</p><p>18 Let's say a person on the early receive list replies then the fanout for that reply is being processed while her fanout is still occurring so the reply is injected before the original tweet in the people receiving her tweets later. [sent-201, score-1.63]
</p><p>19 For people like Taylor Swift don't bother with fanout anymore, instead merge in her timeline at read time. [sent-207, score-0.798]
</p><p>20 Ingesting a tweet into the tweet API takes up to 145 msecs and then all the clients are disconnected. [sent-215, score-0.976]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tweet', 0.488), ('timeline', 0.445), ('tweets', 0.329), ('fanout', 0.244), ('timelines', 0.226), ('twitter', 0.199), ('home', 0.153), ('redis', 0.117), ('path', 0.086), ('bird', 0.085), ('user', 0.085), ('gaga', 0.075), ('lady', 0.07), ('search', 0.067), ('write', 0.066), ('read', 0.063), ('replies', 0.063), ('follow', 0.063), ('reply', 0.06), ('early', 0.059), ('social', 0.055), ('irrelevant', 0.055), ('stored', 0.054), ('seconds', 0.053), ('id', 0.051), ('ingester', 0.051), ('tweetypie', 0.051), ('spent', 0.049), ('content', 0.049), ('graph', 0.049), ('activity', 0.048), ('hit', 0.047), ('service', 0.047), ('people', 0.046), ('pull', 0.046), ('query', 0.046), ('qps', 0.046), ('million', 0.045), ('deliveries', 0.043), ('retweet', 0.043), ('couple', 0.042), ('comes', 0.041), ('retweets', 0.041), ('flock', 0.041), ('text', 0.041), ('ids', 0.04), ('materialization', 0.04), ('cluster', 0.039), ('celebrities', 0.038), ('original', 0.037)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1488-tfidf-1" href="../high_scalability-2013/high_scalability-2013-07-08-The_Architecture_Twitter_Uses_to_Deal_with_150M_Active_Users%2C_300K_QPS%2C_a_22_MB-S_Firehose%2C_and_Send_Tweets_in_Under_5_Seconds.html">1488 high scalability-2013-07-08-The Architecture Twitter Uses to Deal with 150M Active Users, 300K QPS, a 22 MB-S Firehose, and Send Tweets in Under 5 Seconds</a></p>
<p>Introduction: Toy solutions solving Twitter's "problems" are a favorite scalability trope.
Everybody has this idea that Twitter is easy. With a little architectural hand
waving we have a scalable Twitter, just that simple. Well, it's not that
simple asRaffi Krikorian, VP of Engineering at Twitter, describes in his
superb and very detailed presentation onTimelines at Scale. If you want to
know how Twitter works - then start here.It happened gradually so you may have
missed it, but Twitter has grown up. It started as a strugglingthree-tierish
Ruby on Railswebsite to become a beautifully service driven core that we
actually go to now to see if other services are down. Quite a change.Twitter
now has 150M world wide active users, handles 300K QPS to generate timelines,
and a firehose that churns out 22 MB/sec. 400 million tweets a day flow
through the system and it can take up to 5 minutes for a tweet to flow from
Lady Gaga's fingers to her 31 million followers.A couple of points stood
out:Twitter no lon</p><p>2 0.34593755 <a title="1488-tfidf-2" href="../high_scalability-2013/high_scalability-2013-07-15-Ask_HS%3A_What%27s_Wrong_with_Twitter%2C_Why_Isn%27t_One_Machine_Enough%3F.html">1491 high scalability-2013-07-15-Ask HS: What's Wrong with Twitter, Why Isn't One Machine Enough?</a></p>
<p>Introduction: Can anyone convincingly explain why properties sporting traffic statistics
that may seem in-line with with the capabilities of a single big-iron machine
need so many machines in their architecture?This is a common reaction to
architecture profiles on High Scalability: I could do all that on a few
machines so they must be doing something really stupid. Lo and behold this
same reaction also occurred to the articleThe Architecture Twitter Uses to
Deal with 150M Active Users. On Hacker Newspapsosouid voiced what a lot of
people may have been thinking:I really question the current trend of creating
big, complex, fragile architectures to "be able to scale". These numbers are a
great example of why, the entire thing could run on a single server, in a very
straight forward setup. When you are creating a cluster for scalability, and
it has less CPU, RAM and IO than a single server, what are you gaining? They
are only doing 6k writes a second for crying out loud.This is a surprisingly
hard react</p><p>3 0.31226927 <a title="1488-tfidf-3" href="../high_scalability-2011/high_scalability-2011-12-19-How_Twitter_Stores_250_Million_Tweets_a_Day_Using_MySQL.html">1159 high scalability-2011-12-19-How Twitter Stores 250 Million Tweets a Day Using MySQL</a></p>
<p>Introduction: Jeremy Cole, a DBA Team Lead/Database Architect at Twitter, gave a really good
talk at the O'Reilly MySQL conference:Big and Small Data at @Twitter, where
the topic was thinking of Twitter from the data perspective.One of the
interesting stories he told was of the transition from Twitter's old way of
storing tweets using temporalsharding, to a more distributed approach using a
new tweet store called T-bird, which is built on top ofGizzard, which is built
using MySQL.Twitter's original tweet store:Temporally sharded tweets was a
good-idea-at-the-time architecture. Temporal sharding simply means tweets from
the same date range are stored together on the same shard.The problem is
tweets filled up one machine, then a second, and then a third. You end up
filling up one machine after another.This is a pretty common approach and one
that has some real flaws:Load balancing. Most of the old machines didn't get
any traffic because people are interested in what is happening now, especially
with T</p><p>4 0.29727903 <a title="1488-tfidf-4" href="../high_scalability-2012/high_scalability-2012-01-23-Facebook_Timeline%3A_Brought_to_You_by_the_Power_of_Denormalization.html">1179 high scalability-2012-01-23-Facebook Timeline: Brought to You by the Power of Denormalization</a></p>
<p>Introduction: Facebook Timeline is audacious in scope. It wants to compile a complete
scrollable version of your life story from photos, locations, videos, status
updates, and everything you do. That could be many decades of data (hopefully)
that must stored and made quickly available at any point in time. A huge
technical challenge, even for Facebook, which we know are experts inhanding
big data. And they built it all in 6 months.Facebook's Ryan Mack shares quite
a bit of Timeline's own implementation story in his excellent article:Building
Timeline: Scaling up to hold your life story. Five big takeaways from the
article are:Leverage infrastructure rather than build something new. You might
expect that they would pioneer a new infrastructure for Timeline, but given
the short schedule, they decided to go with proven technologies inside
Facebook: MySQL,Multifeed (a custom distributed system which takes the tens of
thousands of updates from friends and picks the most relevant), Thrift,
Memcached,Opera</p><p>5 0.24053279 <a title="1488-tfidf-5" href="../high_scalability-2011/high_scalability-2011-03-14-Twitter_by_the_Numbers_-_460%2C000_New_Accounts_and_140_Million_Tweets_Per_Day.html">1004 high scalability-2011-03-14-Twitter by the Numbers - 460,000 New Accounts and 140 Million Tweets Per Day</a></p>
<p>Introduction: Twitter has taken some hits lately, but they are still pumping out the tweets
and adding massive numbers of new users. Here are some numbers theyjust
published, hot off the analytics engine:Tweets3 years, 2 months and 1 day. The
time it took from the first Tweet to the billionth Tweet.1 week. The time it
now takes for users to send a billion Tweets.50 million. The average number of
Tweets people sent per day, one year ago.140 million. The average number of
Tweets people sent per day, in the last month.177 million. Tweets sent on
March 11, 2011.456. Tweets per second (TPS) when Michael Jackson died on June
25, 2009 (a record at that time).6,939. Current TPS record, set 4 seconds
after midnight in Japan on New Year's Day.Accounts572,000. Number of new
accounts created on March 12, 2011.460,000. Average number of new accounts per
day over the last month.182%. Increase in number of mobile users over the past
year.Employees8. 29. 130. 350. 400. Number of Twitter employees in Jan 2008,
Jan 2</p><p>6 0.23850089 <a title="1488-tfidf-6" href="../high_scalability-2011/high_scalability-2011-11-29-DataSift_Architecture%3A_Realtime_Datamining_at_120%2C000_Tweets_Per_Second.html">1148 high scalability-2011-11-29-DataSift Architecture: Realtime Datamining at 120,000 Tweets Per Second</a></p>
<p>7 0.20412359 <a title="1488-tfidf-7" href="../high_scalability-2009/high_scalability-2009-06-27-Scaling_Twitter%3A_Making_Twitter_10000_Percent_Faster.html">639 high scalability-2009-06-27-Scaling Twitter: Making Twitter 10000 Percent Faster</a></p>
<p>8 0.20321041 <a title="1488-tfidf-8" href="../high_scalability-2010/high_scalability-2010-07-11-So%2C_Why_is_Twitter_Really_Not_Using_Cassandra_to_Store_Tweets%3F.html">855 high scalability-2010-07-11-So, Why is Twitter Really Not Using Cassandra to Store Tweets?</a></p>
<p>9 0.20212175 <a title="1488-tfidf-9" href="../high_scalability-2012/high_scalability-2012-05-24-Build_your_own_twitter_like_real_time_analytics_-_a_step_by_step_guide.html">1251 high scalability-2012-05-24-Build your own twitter like real time analytics - a step by step guide</a></p>
<p>10 0.1989651 <a title="1488-tfidf-10" href="../high_scalability-2010/high_scalability-2010-06-07-Six_Ways_Twitter_May_Reach_its_Big_Hairy_Audacious_Goal_of_One_Billion_Users.html">837 high scalability-2010-06-07-Six Ways Twitter May Reach its Big Hairy Audacious Goal of One Billion Users</a></p>
<p>11 0.19319698 <a title="1488-tfidf-11" href="../high_scalability-2010/high_scalability-2010-02-19-Twitter%E2%80%99s_Plan_to_Analyze_100_Billion_Tweets.html">780 high scalability-2010-02-19-Twitter’s Plan to Analyze 100 Billion Tweets</a></p>
<p>12 0.15028769 <a title="1488-tfidf-12" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>13 0.13393769 <a title="1488-tfidf-13" href="../high_scalability-2012/high_scalability-2012-02-13-Tumblr_Architecture_-_15_Billion_Page_Views_a_Month_and_Harder_to_Scale_than_Twitter.html">1191 high scalability-2012-02-13-Tumblr Architecture - 15 Billion Page Views a Month and Harder to Scale than Twitter</a></p>
<p>14 0.13393769 <a title="1488-tfidf-14" href="../high_scalability-2012/high_scalability-2012-11-19-Gone_Fishin%27%3A_Tumblr_Architecture_-_15_Billion_Page_Views_A_Month_And_Harder_To_Scale_Than_Twitter.html">1360 high scalability-2012-11-19-Gone Fishin': Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a></p>
<p>15 0.13290776 <a title="1488-tfidf-15" href="../high_scalability-2013/high_scalability-2013-05-20-The_Tumblr_Architecture_Yahoo_Bought_for_a_Cool_Billion_Dollars.html">1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</a></p>
<p>16 0.13049176 <a title="1488-tfidf-16" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>17 0.1277425 <a title="1488-tfidf-17" href="../high_scalability-2013/high_scalability-2013-10-28-Design_Decisions_for_Scaling_Your_High_Traffic_Feeds.html">1538 high scalability-2013-10-28-Design Decisions for Scaling Your High Traffic Feeds</a></p>
<p>18 0.12742275 <a title="1488-tfidf-18" href="../high_scalability-2012/high_scalability-2012-07-30-Prismatic_Architecture_-_Using_Machine_Learning_on_Social_Networks_to_Figure_Out_What_You_Should_Read_on_the_Web_.html">1293 high scalability-2012-07-30-Prismatic Architecture - Using Machine Learning on Social Networks to Figure Out What You Should Read on the Web </a></p>
<p>19 0.1122157 <a title="1488-tfidf-19" href="../high_scalability-2009/high_scalability-2009-10-13-Why_are_Facebook%2C_Digg%2C_and_Twitter_so_hard_to_scale%3F.html">721 high scalability-2009-10-13-Why are Facebook, Digg, and Twitter so hard to scale?</a></p>
<p>20 0.1088284 <a title="1488-tfidf-20" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.185), (1, 0.099), (2, -0.022), (3, -0.035), (4, 0.072), (5, -0.008), (6, -0.061), (7, 0.089), (8, 0.068), (9, -0.007), (10, 0.045), (11, 0.133), (12, 0.041), (13, 0.004), (14, -0.074), (15, 0.058), (16, -0.066), (17, -0.036), (18, -0.031), (19, -0.011), (20, -0.063), (21, -0.058), (22, 0.027), (23, 0.039), (24, -0.013), (25, -0.0), (26, 0.001), (27, -0.002), (28, -0.018), (29, 0.067), (30, 0.118), (31, -0.132), (32, -0.102), (33, 0.054), (34, -0.135), (35, -0.009), (36, 0.008), (37, 0.053), (38, -0.172), (39, -0.025), (40, 0.078), (41, 0.028), (42, -0.029), (43, 0.02), (44, -0.014), (45, -0.019), (46, -0.024), (47, -0.033), (48, 0.061), (49, 0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96614933 <a title="1488-lsi-1" href="../high_scalability-2013/high_scalability-2013-07-08-The_Architecture_Twitter_Uses_to_Deal_with_150M_Active_Users%2C_300K_QPS%2C_a_22_MB-S_Firehose%2C_and_Send_Tweets_in_Under_5_Seconds.html">1488 high scalability-2013-07-08-The Architecture Twitter Uses to Deal with 150M Active Users, 300K QPS, a 22 MB-S Firehose, and Send Tweets in Under 5 Seconds</a></p>
<p>Introduction: Toy solutions solving Twitter's "problems" are a favorite scalability trope.
Everybody has this idea that Twitter is easy. With a little architectural hand
waving we have a scalable Twitter, just that simple. Well, it's not that
simple asRaffi Krikorian, VP of Engineering at Twitter, describes in his
superb and very detailed presentation onTimelines at Scale. If you want to
know how Twitter works - then start here.It happened gradually so you may have
missed it, but Twitter has grown up. It started as a strugglingthree-tierish
Ruby on Railswebsite to become a beautifully service driven core that we
actually go to now to see if other services are down. Quite a change.Twitter
now has 150M world wide active users, handles 300K QPS to generate timelines,
and a firehose that churns out 22 MB/sec. 400 million tweets a day flow
through the system and it can take up to 5 minutes for a tweet to flow from
Lady Gaga's fingers to her 31 million followers.A couple of points stood
out:Twitter no lon</p><p>2 0.86489433 <a title="1488-lsi-2" href="../high_scalability-2010/high_scalability-2010-06-07-Six_Ways_Twitter_May_Reach_its_Big_Hairy_Audacious_Goal_of_One_Billion_Users.html">837 high scalability-2010-06-07-Six Ways Twitter May Reach its Big Hairy Audacious Goal of One Billion Users</a></p>
<p>Introduction: Twitter has a big hairy audacious goal of reaching one billion users by 2013.
Three forces stand against Twitter. The world will end in2012. But let's be
optimistic and assume we'll make it. Next is Facebook. Currently Facebook is
the user leader with over 400 million users. Will Facebook stumble or will
they rocket to one billion users before Twitter? And lastly, there's Twitter's
"low" starting point and "slow" growth rate. Twitter currently has106
millionregistered users and adds about 300,000 new users a day. That doesn't
add up to a billion in three years. Twitter needs to triple the number of
registered users they add per day. How will Twitter reach its goal of over one
billion users served?From recent infrastructure announcements and information
gleaned atChirp (videos) and other talks, it has become a little clearer how
they hope to reach their billion user goal: 1) Make a Big Hairy Audacious Goal
2) Hire Lots of Quality People 3) Hug Developers and Users 4) Drive the
Technolog</p><p>3 0.82455039 <a title="1488-lsi-3" href="../high_scalability-2013/high_scalability-2013-07-15-Ask_HS%3A_What%27s_Wrong_with_Twitter%2C_Why_Isn%27t_One_Machine_Enough%3F.html">1491 high scalability-2013-07-15-Ask HS: What's Wrong with Twitter, Why Isn't One Machine Enough?</a></p>
<p>Introduction: Can anyone convincingly explain why properties sporting traffic statistics
that may seem in-line with with the capabilities of a single big-iron machine
need so many machines in their architecture?This is a common reaction to
architecture profiles on High Scalability: I could do all that on a few
machines so they must be doing something really stupid. Lo and behold this
same reaction also occurred to the articleThe Architecture Twitter Uses to
Deal with 150M Active Users. On Hacker Newspapsosouid voiced what a lot of
people may have been thinking:I really question the current trend of creating
big, complex, fragile architectures to "be able to scale". These numbers are a
great example of why, the entire thing could run on a single server, in a very
straight forward setup. When you are creating a cluster for scalability, and
it has less CPU, RAM and IO than a single server, what are you gaining? They
are only doing 6k writes a second for crying out loud.This is a surprisingly
hard react</p><p>4 0.80096424 <a title="1488-lsi-4" href="../high_scalability-2009/high_scalability-2009-06-27-Scaling_Twitter%3A_Making_Twitter_10000_Percent_Faster.html">639 high scalability-2009-06-27-Scaling Twitter: Making Twitter 10000 Percent Faster</a></p>
<p>Introduction: Update 6:Some interesting changes from Twitter'sEvan Weaver: everything in RAM
now, database is a backup; peaks at 300 tweets/second; every tweet followed by
average 126 people; vector cache of tweet IDs; row cache; fragment cache; page
cache; keep separate caches; GC makes Ruby optimization resistant so went with
Scala; Thrift and HTTP are used internally; 100s internal requests for every
external request; rewrote MQ but kept interface the same; 3 queues are used to
load balance requests; extensive A/B testing for backwards capability;
switched to C memcached client for speed; optimize critical path; faster to
get the cached results from the network memory than recompute them
locally.Update 5:Twitter on Scala. A Conversation with Steve Jenson, Alex
Payne, and Robey Pointer by Bill Venners. A fascinating discussion of why
Twitter moved to the Java JVM for their server infrastructure (long lived
processes) and why they moved toScalato program against it (high level
language, static typi</p><p>5 0.79205227 <a title="1488-lsi-5" href="../high_scalability-2011/high_scalability-2011-12-19-How_Twitter_Stores_250_Million_Tweets_a_Day_Using_MySQL.html">1159 high scalability-2011-12-19-How Twitter Stores 250 Million Tweets a Day Using MySQL</a></p>
<p>Introduction: Jeremy Cole, a DBA Team Lead/Database Architect at Twitter, gave a really good
talk at the O'Reilly MySQL conference:Big and Small Data at @Twitter, where
the topic was thinking of Twitter from the data perspective.One of the
interesting stories he told was of the transition from Twitter's old way of
storing tweets using temporalsharding, to a more distributed approach using a
new tweet store called T-bird, which is built on top ofGizzard, which is built
using MySQL.Twitter's original tweet store:Temporally sharded tweets was a
good-idea-at-the-time architecture. Temporal sharding simply means tweets from
the same date range are stored together on the same shard.The problem is
tweets filled up one machine, then a second, and then a third. You end up
filling up one machine after another.This is a pretty common approach and one
that has some real flaws:Load balancing. Most of the old machines didn't get
any traffic because people are interested in what is happening now, especially
with T</p><p>6 0.78212541 <a title="1488-lsi-6" href="../high_scalability-2012/high_scalability-2012-05-24-Build_your_own_twitter_like_real_time_analytics_-_a_step_by_step_guide.html">1251 high scalability-2012-05-24-Build your own twitter like real time analytics - a step by step guide</a></p>
<p>7 0.77885377 <a title="1488-lsi-7" href="../high_scalability-2011/high_scalability-2011-03-14-Twitter_by_the_Numbers_-_460%2C000_New_Accounts_and_140_Million_Tweets_Per_Day.html">1004 high scalability-2011-03-14-Twitter by the Numbers - 460,000 New Accounts and 140 Million Tweets Per Day</a></p>
<p>8 0.75820696 <a title="1488-lsi-8" href="../high_scalability-2009/high_scalability-2009-03-18-QCon_London_2009%3A_Upgrading_Twitter_without_service_disruptions.html">544 high scalability-2009-03-18-QCon London 2009: Upgrading Twitter without service disruptions</a></p>
<p>9 0.72970682 <a title="1488-lsi-9" href="../high_scalability-2008/high_scalability-2008-05-19-Twitter_as_a_scalability_case_study.html">323 high scalability-2008-05-19-Twitter as a scalability case study</a></p>
<p>10 0.7294997 <a title="1488-lsi-10" href="../high_scalability-2011/high_scalability-2011-11-29-DataSift_Architecture%3A_Realtime_Datamining_at_120%2C000_Tweets_Per_Second.html">1148 high scalability-2011-11-29-DataSift Architecture: Realtime Datamining at 120,000 Tweets Per Second</a></p>
<p>11 0.72896612 <a title="1488-lsi-11" href="../high_scalability-2010/high_scalability-2010-02-19-Twitter%E2%80%99s_Plan_to_Analyze_100_Billion_Tweets.html">780 high scalability-2010-02-19-Twitter’s Plan to Analyze 100 Billion Tweets</a></p>
<p>12 0.71788591 <a title="1488-lsi-12" href="../high_scalability-2010/high_scalability-2010-07-11-So%2C_Why_is_Twitter_Really_Not_Using_Cassandra_to_Store_Tweets%3F.html">855 high scalability-2010-07-11-So, Why is Twitter Really Not Using Cassandra to Store Tweets?</a></p>
<p>13 0.70880502 <a title="1488-lsi-13" href="../high_scalability-2009/high_scalability-2009-04-05-At_Some_Point_the_Cost_of_Servers_Outweighs_the_Cost_of_Programmers.html">556 high scalability-2009-04-05-At Some Point the Cost of Servers Outweighs the Cost of Programmers</a></p>
<p>14 0.70767796 <a title="1488-lsi-14" href="../high_scalability-2009/high_scalability-2009-04-20-Some_things_about_Memcached_from_a_Twitter_software_developer.html">574 high scalability-2009-04-20-Some things about Memcached from a Twitter software developer</a></p>
<p>15 0.67999655 <a title="1488-lsi-15" href="../high_scalability-2009/high_scalability-2009-04-14-Designing_a_Scalable_Twitter.html">568 high scalability-2009-04-14-Designing a Scalable Twitter</a></p>
<p>16 0.63008457 <a title="1488-lsi-16" href="../high_scalability-2013/high_scalability-2013-10-28-Design_Decisions_for_Scaling_Your_High_Traffic_Feeds.html">1538 high scalability-2013-10-28-Design Decisions for Scaling Your High Traffic Feeds</a></p>
<p>17 0.62611973 <a title="1488-lsi-17" href="../high_scalability-2007/high_scalability-2007-11-27-Solving_the_Client_Side_API_Scalability_Problem_with_a_Little_Game_Theory.html">166 high scalability-2007-11-27-Solving the Client Side API Scalability Problem with a Little Game Theory</a></p>
<p>18 0.62077636 <a title="1488-lsi-18" href="../high_scalability-2008/high_scalability-2008-08-12-Strategy%3A_Limit_The_New%2C_Not_The_Old.html">363 high scalability-2008-08-12-Strategy: Limit The New, Not The Old</a></p>
<p>19 0.61758381 <a title="1488-lsi-19" href="../high_scalability-2012/high_scalability-2012-01-17-Paper%3A_Feeding_Frenzy%3A_Selectively_Materializing_Users%E2%80%99_Event_Feeds.html">1175 high scalability-2012-01-17-Paper: Feeding Frenzy: Selectively Materializing Users’ Event Feeds</a></p>
<p>20 0.61427873 <a title="1488-lsi-20" href="../high_scalability-2007/high_scalability-2007-10-08-Lessons_from_Pownce_-_The_Early_Years.html">116 high scalability-2007-10-08-Lessons from Pownce - The Early Years</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.099), (2, 0.211), (10, 0.277), (30, 0.024), (33, 0.011), (61, 0.114), (73, 0.017), (77, 0.02), (79, 0.038), (85, 0.038), (94, 0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97355795 <a title="1488-lda-1" href="../high_scalability-2009/high_scalability-2009-08-28-Strategy%3A_Solve_Only_80_Percent_of_the_Problem.html">689 high scalability-2009-08-28-Strategy: Solve Only 80 Percent of the Problem</a></p>
<p>Introduction: Solve only 80% of a problem. That's usually good enough and you'll not only
get done faster, you'll actually have a chance of getting done at all.This
strategy is given by Amix inHOW TWITTER (AND FACEBOOK) SOLVE PROBLEMS
PARTIALLY. The idea is solving 100% of a complex problem can be so hard and so
expensive that you'll end up wasting all your bullets on a problem that could
have been satisfactoraly solved in a much simpler way.The example given is for
Twitter's real-time search. Real-time search almost by definition is focussed
on recent events. So in the design should you be able to search historically
back from the beginning of time or should you just be able to search for
recent time periods? A complete historical search is the 100% solution. The
recent data only search is the 80% solution. Which should you choose?breakThe
100% solution is dramatically more difficult to solve. It requires searching
disk in real-time which is a killer. So it makes more sense to work on the 80%
probl</p><p>2 0.96368313 <a title="1488-lda-2" href="../high_scalability-2014/high_scalability-2014-04-21-This_is_why_Microsoft_won._And_why_they_lost..html">1635 high scalability-2014-04-21-This is why Microsoft won. And why they lost.</a></p>
<p>Introduction: My favorite kind of histories are those told from an insider's perspective.
The story of Richard the Lionheart is full of great battles and dynastic
intrigue. The story of one of his soldiers, not so much. Yet the soldiers'
story, as someone who has experienced the real consequences of decisions made
and actions taken, is more revealing.We get such a history in Chat Wars, a
wonderful article written by David Auerbach, who in 1998 worked at Microsoft
on MSN Messenger Service, Microsoft's instant messaging app (for a related
story see The Rise and Fall of AIM, the Breakthrough AOL Never Wanted).It's as
if Herodotus visited Microsoft and wrote down his experiences. It has that
same sort of conversational tone, insightful on-the-ground observations, and
facts no outsider might ever believe.Much of the article is a play-by-play
account of the cat and mouse game David plays changing Messenger to track
AOL's Instant Messenger protocol changes. AOL repeatedly tried to make it so
Messenger coul</p><p>3 0.96205765 <a title="1488-lda-3" href="../high_scalability-2010/high_scalability-2010-03-10-How_FarmVille_Scales_-_The_Follow-up.html">792 high scalability-2010-03-10-How FarmVille Scales - The Follow-up</a></p>
<p>Introduction: Several readers had follow-up questions in response toHow FarmVille Scales to
Harvest 75 Million Players a Month. Here are Luke's response to those
questions (and a few of mine).How does social networking makes things easier
or harder?The primary interesting aspect of social networking games is how you
wind up with a graph of connected users who need to be access each other's
data on a frequent basis. This makes the overall dataset difficult if not
impossible to partition.What are examples of the Facebook calls you try to
avoid and how they impact game play?We can make a call for facebook friend
data to retrieve information about your friends playing the game. Normally, we
show a friend ladder at the bottom of the game that shows friend information,
including name and facebook photo. Can you say where your cache is, what form
it takes, and how much cached there is? Do you have a peering relationship
with Facebook, as one might expect at that bandwidth?We use memcache as our
caching tec</p><p>4 0.95871675 <a title="1488-lda-4" href="../high_scalability-2009/high_scalability-2009-04-27-Some_Questions_from_a_newbie.html">584 high scalability-2009-04-27-Some Questions from a newbie</a></p>
<p>Introduction: Hello highscalability world. I just discovered this site yesterday in a search
for a scalability resource and was very pleased to find such useful
information. I have some questions regarding distributed caching that I was
hoping the scalability intelligentsia trafficking this forum could answer. I
apologize for my lack of technical knowledge; I'm hoping this site will
increase said knowledge! Feel free to answer all or as much as you want. Thank
you in advance for your responses and thank you for a great resource!1.) What
are the standard benchmarks used to measure the performance of memcached or
mySQL/memcached working together (from web 2.0 companies etc)?2.) The little
research I've conducted on this site suggests that most web 2.0 companies use
a combination of mySQL and a hacked memcached (and potentially sharding). Does
anyone know if any of these companies use an enterprise vendor for their
distributed caching layer? (At this point in time I've only heard of Jive
software using</p><p>5 0.95785451 <a title="1488-lda-5" href="../high_scalability-2011/high_scalability-2011-06-22-It%27s_the_Fraking_IOPS_-_1_SSD_is_44%2C000_IOPS%2C_Hard_Drive_is_180.html">1066 high scalability-2011-06-22-It's the Fraking IOPS - 1 SSD is 44,000 IOPS, Hard Drive is 180</a></p>
<p>Introduction: Planning your next buildout and thinking SSDs are still far in the future?
Still too expensive, too low density. Hard disks are cheap, familiar, and
store lots of stuff. In this short and entertaining video Wikia's Artur
Bergmanwants to change your mind about SSDs. SSDs are for today, get with the
math already.Here's Artur's logic:Wikia is all SSD in production. The new
Wikia file servers have a theoretical read rate of ~10GB/sec sequential,
6GB/sec random and 1.2 million IOPs. If you can't do math or love the past,
you love spinning rust. If you are awesome you love SSDs.SSDs are cheaper than
drives using the most relevant metric: $/GB/IOPS. 1 SSD is 44,000 IOPS and one
hard drive is 180 IOPS. Need 1 SSD instead of 50 hard drives.With 8 million
files there's a 9 minute fsck. Full backup in 12 minutes (X-25M based).4
GB/sec random read average latency 1 msec.2.2 GB/sec random write average
latency 1 msec.50TBs of SSDs in one machine for $80,000. With the densities
most products can ski</p><p>6 0.95645833 <a title="1488-lda-6" href="../high_scalability-2011/high_scalability-2011-05-23-Evernote_Architecture_-_9_Million_Users_and_150_Million_Requests_a_Day.html">1046 high scalability-2011-05-23-Evernote Architecture - 9 Million Users and 150 Million Requests a Day</a></p>
<p>7 0.95427704 <a title="1488-lda-7" href="../high_scalability-2013/high_scalability-2013-06-24-Update_on_How_29_Cloud_Price_Drops_Changed_the_Bottom_Line_of_TripAdvisor_and_Pinterest_-_Results_Mixed.html">1480 high scalability-2013-06-24-Update on How 29 Cloud Price Drops Changed the Bottom Line of TripAdvisor and Pinterest - Results Mixed</a></p>
<p>8 0.94952786 <a title="1488-lda-8" href="../high_scalability-2014/high_scalability-2014-01-24-Stuff_The_Internet_Says_On_Scalability_For_January_24th%2C_2014.html">1585 high scalability-2014-01-24-Stuff The Internet Says On Scalability For January 24th, 2014</a></p>
<p>9 0.94727314 <a title="1488-lda-9" href="../high_scalability-2012/high_scalability-2012-08-06-Paper%3A_High-Performance_Concurrency_Control_Mechanisms_for_Main-Memory_Databases.html">1299 high scalability-2012-08-06-Paper: High-Performance Concurrency Control Mechanisms for Main-Memory Databases</a></p>
<p>10 0.94419903 <a title="1488-lda-10" href="../high_scalability-2014/high_scalability-2014-04-14-How_do_you_even_do_anything_without_using_EBS%3F.html">1631 high scalability-2014-04-14-How do you even do anything without using EBS?</a></p>
<p>11 0.93270862 <a title="1488-lda-11" href="../high_scalability-2010/high_scalability-2010-08-07-ArchCamp%3A_Scalable_Databases_%28NoSQL%29.html">874 high scalability-2010-08-07-ArchCamp: Scalable Databases (NoSQL)</a></p>
<p>12 0.92838281 <a title="1488-lda-12" href="../high_scalability-2008/high_scalability-2008-10-26-Should_you_use_a_SAN_to_scale_your_architecture%3F_.html">430 high scalability-2008-10-26-Should you use a SAN to scale your architecture? </a></p>
<p>same-blog 13 0.92729312 <a title="1488-lda-13" href="../high_scalability-2013/high_scalability-2013-07-08-The_Architecture_Twitter_Uses_to_Deal_with_150M_Active_Users%2C_300K_QPS%2C_a_22_MB-S_Firehose%2C_and_Send_Tweets_in_Under_5_Seconds.html">1488 high scalability-2013-07-08-The Architecture Twitter Uses to Deal with 150M Active Users, 300K QPS, a 22 MB-S Firehose, and Send Tweets in Under 5 Seconds</a></p>
<p>14 0.91933626 <a title="1488-lda-14" href="../high_scalability-2007/high_scalability-2007-11-05-Strategy%3A_Diagonal_Scaling_-_Don%27t_Forget_to_Scale_Out_AND_Up.html">142 high scalability-2007-11-05-Strategy: Diagonal Scaling - Don't Forget to Scale Out AND Up</a></p>
<p>15 0.91873306 <a title="1488-lda-15" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>16 0.91683543 <a title="1488-lda-16" href="../high_scalability-2010/high_scalability-2010-01-27-Hot_Scalability_Links_for_January_28_2010.html">767 high scalability-2010-01-27-Hot Scalability Links for January 28 2010</a></p>
<p>17 0.90680319 <a title="1488-lda-17" href="../high_scalability-2011/high_scalability-2011-03-14-Twitter_by_the_Numbers_-_460%2C000_New_Accounts_and_140_Million_Tweets_Per_Day.html">1004 high scalability-2011-03-14-Twitter by the Numbers - 460,000 New Accounts and 140 Million Tweets Per Day</a></p>
<p>18 0.90577161 <a title="1488-lda-18" href="../high_scalability-2008/high_scalability-2008-02-22-Kevin%27s_Great_Adventures_in_SSDland.html">257 high scalability-2008-02-22-Kevin's Great Adventures in SSDland</a></p>
<p>19 0.89808053 <a title="1488-lda-19" href="../high_scalability-2007/high_scalability-2007-12-10-1_Master%2C_N_Slaves.html">178 high scalability-2007-12-10-1 Master, N Slaves</a></p>
<p>20 0.88403964 <a title="1488-lda-20" href="../high_scalability-2013/high_scalability-2013-09-23-Salesforce_Architecture_-_How_they_Handle_1.3_Billion_Transactions_a_Day.html">1521 high scalability-2013-09-23-Salesforce Architecture - How they Handle 1.3 Billion Transactions a Day</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
