<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1638 high scalability-2014-04-28-How Disqus Went Realtime with 165K Messages Per Second and Less than .2 Seconds Latency</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2014" href="../home/high_scalability-2014_home.html">high_scalability-2014</a> <a title="high_scalability-2014-1638" href="#">high_scalability-2014-1638</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1638 high scalability-2014-04-28-How Disqus Went Realtime with 165K Messages Per Second and Less than .2 Seconds Latency</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2014-1638-html" href="http://highscalability.com//blog/2014/4/28/how-disqus-went-realtime-with-165k-messages-per-second-and-l.html">html</a></p><p>Introduction: Here's anUpdate On Disqus: It's Still About Realtime, But Go Demolishes
Python.How do you add realtime functionality to a web scale application?
That's whatAdam Hitchcock, a Software Engineer at Disqus talks about in an
excellent talk: Making DISQUS Realtime (slides).Disqus had to take their
commenting system and add realtime capabilities to it. Not something that's
easy to do when at the time of the talk (2013) they had had just hit a billion
unique visitors a month.What Disqus developed is a realtime commenting system
called "realertime" that was tested to handle 1.5 million concurrently
connected users, 45,000 new connections per second, 165,000 messages/second,
with less than .2 seconds latency end-to-end.The nature of a commenting system
is that it is IO bound and has a high fanout, that is a comment comes in and
must be sent out to a lot of readers. It's a problem very similar to
whatTwitter must solve. Disqus' solution was quite interesting as was the path
to their solution. The</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 How do you add realtime functionality to a web scale application? [sent-2, score-0.297]
</p><p>2 Disqus had to take their commenting system and add realtime capabilities to it. [sent-4, score-0.447]
</p><p>3 What Disqus developed is a realtime commenting system called "realertime" that was tested to handle 1. [sent-6, score-0.447]
</p><p>4 So let's see how Disqus evolved their realtime commenting architecture and created something both old and new in the process. [sent-19, score-0.542]
</p><p>5 NginxPush Stream Module- A pure stream http push technology for your Nginx setup. [sent-24, score-0.242]
</p><p>6 More people comment after realtime than they did before. [sent-32, score-0.346]
</p><p>7 Old realtime system:The Disqus app, written in Django, would post to memcache on many keys: forum:id, thread:id, user:id, post:id. [sent-35, score-0.297]
</p><p>8 So  the new flow: New Posts -> Disqus -> redis queue -> "python glue" Gevent formatting server (2 servers for redundancy) -> redis pub/sub (6 servers) -> Flask FE (front end) Cluster (14 big servers) <\- HA Proxy (5 servers) <\- clientsThis worked well. [sent-48, score-0.643]
</p><p>9 Third and winning approach:Uses apipelined architecturewhere messages pass from queue to queue while being acted upon by filters. [sent-51, score-0.254]
</p><p>10 This replaced redis pub/sub, flask servers and the HAProxy cluster. [sent-53, score-0.405]
</p><p>11 5 push stream servers were required because of network memory limitations in the kernel. [sent-55, score-0.295]
</p><p>12 The Disqus part of the flow is a Django web app that uses post_save and post_delete hooks to put stuff onto a thoonk queue. [sent-58, score-0.317]
</p><p>13 These hooks are very useful for generating notifications for realtime data. [sent-59, score-0.353]
</p><p>14 They already had thoonk so used it instead of spinning up a HA cluster of RabbitMQ machines. [sent-61, score-0.249]
</p><p>15 Originally did formatting in the flask cluster, but that took too much CPU. [sent-71, score-0.408]
</p><p>16 The python glue program is structured as a data pipeline, there are stages the data must go through: parsing, computation, publish it to another place. [sent-78, score-0.285]
</p><p>17 A message would come off of thoonk and run through a pipeline: JSONAnnonHTTPPipeline, JSONSecureHTTPPipeline, JSONAnnonFilePipeline. [sent-82, score-0.26]
</p><p>18 Great when bringing up a new feature you can make a new pipeline stage, make a new pipeline, and have the old pipeline run side by side with the new pipeline. [sent-84, score-0.542]
</p><p>19 Good monitoring built-in and accessible over a push stream status endpoint. [sent-99, score-0.242]
</p><p>20 They were able to make a great realtime map of traffic without any prior planning because messages were published over all channels. [sent-133, score-0.365]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('disqus', 0.557), ('realtime', 0.297), ('flask', 0.222), ('thoonk', 0.204), ('formatting', 0.186), ('commenting', 0.15), ('pipeline', 0.147), ('nginx', 0.139), ('stream', 0.134), ('redis', 0.13), ('python', 0.115), ('django', 0.111), ('push', 0.108), ('module', 0.106), ('glue', 0.101), ('queue', 0.093), ('slides', 0.082), ('greenlet', 0.082), ('hitchcock', 0.082), ('robenolt', 0.082), ('endpoint', 0.081), ('eventsource', 0.074), ('publish', 0.069), ('messages', 0.068), ('acks', 0.066), ('gevent', 0.066), ('haproxy', 0.064), ('stage', 0.062), ('browser', 0.061), ('claimed', 0.059), ('flow', 0.057), ('concurrent', 0.057), ('hooks', 0.056), ('pipelined', 0.056), ('fanout', 0.056), ('message', 0.056), ('servers', 0.053), ('new', 0.051), ('couple', 0.05), ('comment', 0.049), ('subscribers', 0.049), ('posts', 0.048), ('sockets', 0.047), ('march', 0.046), ('library', 0.046), ('comments', 0.045), ('cluster', 0.045), ('ha', 0.045), ('old', 0.044), ('socket', 0.043)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1638-tfidf-1" href="../high_scalability-2014/high_scalability-2014-04-28-How_Disqus_Went_Realtime_with_165K_Messages_Per_Second_and_Less_than_.2_Seconds_Latency.html">1638 high scalability-2014-04-28-How Disqus Went Realtime with 165K Messages Per Second and Less than .2 Seconds Latency</a></p>
<p>Introduction: Here's anUpdate On Disqus: It's Still About Realtime, But Go Demolishes
Python.How do you add realtime functionality to a web scale application?
That's whatAdam Hitchcock, a Software Engineer at Disqus talks about in an
excellent talk: Making DISQUS Realtime (slides).Disqus had to take their
commenting system and add realtime capabilities to it. Not something that's
easy to do when at the time of the talk (2013) they had had just hit a billion
unique visitors a month.What Disqus developed is a realtime commenting system
called "realertime" that was tested to handle 1.5 million concurrently
connected users, 45,000 new connections per second, 165,000 messages/second,
with less than .2 seconds latency end-to-end.The nature of a commenting system
is that it is IO bound and has a high fanout, that is a comment comes in and
must be sent out to a lot of readers. It's a problem very similar to
whatTwitter must solve. Disqus' solution was quite interesting as was the path
to their solution. The</p><p>2 0.49882594 <a title="1638-tfidf-2" href="../high_scalability-2014/high_scalability-2014-05-07-Update_on_Disqus%3A_It%27s_Still_About_Realtime%2C_But_Go_Demolishes_Python.html">1644 high scalability-2014-05-07-Update on Disqus: It's Still About Realtime, But Go Demolishes Python</a></p>
<p>Introduction: Our last article on Disqus: How Disqus Went Realtime With 165K Messages Per
Second And Less Than .2 Seconds Latency, was a little out of date, but the
folks at Disqus have been busy implementing, not talking, so we don't know a
lot about what they are doing now, but we do have a short update in C1MM and
NGINXby John Watson and an article Trying out this Go thing.So Disqus has
grown a bit:1.3 billion unique visitors10 billion page views500 million users
engaged in discussions3 million communities25 million commentsThey are still
all about realtime, but Go replaced Python in their Realtime system:Original
Realtime backend was written in a pretty lightweight Python + gevent.The
realtime service is a hybrid of CPU intensive tasks + lots of network IO.
Gevent was handling the network IO without an issue, but at higher contention,
the CPU was choking everything. Switching over to Go removed that contention,
which was the primary issue that was being seen.Still runs on 5 machines Nginx
machin</p><p>3 0.27178523 <a title="1638-tfidf-3" href="../high_scalability-2010/high_scalability-2010-10-26-Scaling_DISQUS_to_75_Million_Comments_and_17%2C000_RPS.html">928 high scalability-2010-10-26-Scaling DISQUS to 75 Million Comments and 17,000 RPS</a></p>
<p>Introduction: Thispresentation andvideoby Jason Yan and David Cramer discusses how they
scaled DISQUS, a comments as a service service for easily adding comments to
your site and connecting communities. The presentation is very good, so here
are just a few highlights: Traffic: 17,000 requests/second peak; 450,000
websites; 15 million profiles; 75 million comments; 250 million visitors; 40
million monthly users / developer.Forces: unpredictable traffic patterns
because of celebrity gossip and events like disasters; discussion never expire
which means they can't fit in memory; must always be up.Machines: 100 servers;
30% web servers (Appache + mod_wsgi); 10% databases (PostgreSQL); 25% cache
servers (memcached); 20% load balancing / high availability (HAProxy +
heartbeat); 15% Utility servers (Python scripts).Architecture: Requests are
load balanced across an Apache cluster. Apache talks to memcached,
HAProxy/pgbouncer to handle connection pooling to the database, and a central
queue service. Strategi</p><p>4 0.14237885 <a title="1638-tfidf-4" href="../high_scalability-2010/high_scalability-2010-04-12-Poppen.de_Architecture.html">808 high scalability-2010-04-12-Poppen.de Architecture</a></p>
<p>Introduction: This is a guest a post by Alvaro Videla describing their architecture
forPoppen.de, a popular German dating site. This site is very much NSFW, so be
careful before clicking on the link. What I found most interesting is how they
manage to sucessfully blend a little of the old with a little of the new,
using technologies like Nginx, MySQL, CouchDB, and Erlang, Memcached,
RabbitMQ, PHP, Graphite, Red5, and Tsung.What is Poppen.de?Poppen.de (NSFW) is
the top dating website in Germany, and while it may be a small site compared
to giants like Flickr or Facebook, we believe it's a nice architecture to
learn from if you are starting to get some scaling problems.The Stats2.000.000
users20.000 concurrent users300.000 private messages per day250.000 logins per
dayWe have a team of eleven developers, two designers and two sysadmins for
this project.Business ModelThe site works with a freemium model, where users
can do for free things like: Search for other users.Write private messages to
each othe</p><p>5 0.13695964 <a title="1638-tfidf-5" href="../high_scalability-2010/high_scalability-2010-09-17-Hot_Scalability_Links_For_Sep_17%2C_2010.html">903 high scalability-2010-09-17-Hot Scalability Links For Sep 17, 2010</a></p>
<p>Introduction: Disqus - Scaling the Worlds Largest Django App. Interesting overview of a
commenting system with 75 million comments and 250 million visitors. Lots of
good details on how they partition their database, testing, continuous
integration, feature switches, caching, delayed signals, and more.Things I
learnt tracking a billion events in 24 hours: Know your host, Scaling isn't
just servers, My servers need to talk to me more, Kill switches for users,
What you don't know is the problem, Don't mix server roles, Know your most
important users outside of your site.Tweets of Gold:georgebarnett: I read High
Scalability for useful articles about large scaling. Sadly though, nothing
useful ever shows up. #NoLongerBotheringnorthscale: wow that is fast! :) RT
@cgoldberg: was just running > 100k ops/sec against my 2-node #Membase
cluster... zazooom #nosqlturbofunctor: The root of many (horizontal)
scalability problems is an application level access to a writable filesystem.
(Thus, #appengine.)gwenshap:</p><p>6 0.13333929 <a title="1638-tfidf-6" href="../high_scalability-2008/high_scalability-2008-05-03-Product%3A_nginx.html">314 high scalability-2008-05-03-Product: nginx</a></p>
<p>7 0.12860429 <a title="1638-tfidf-7" href="../high_scalability-2009/high_scalability-2009-05-17-Scaling_Django_Web_Apps_by_Mike_Malone.html">602 high scalability-2009-05-17-Scaling Django Web Apps by Mike Malone</a></p>
<p>8 0.12734561 <a title="1638-tfidf-8" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>9 0.12565982 <a title="1638-tfidf-9" href="../high_scalability-2012/high_scalability-2012-02-13-Tumblr_Architecture_-_15_Billion_Page_Views_a_Month_and_Harder_to_Scale_than_Twitter.html">1191 high scalability-2012-02-13-Tumblr Architecture - 15 Billion Page Views a Month and Harder to Scale than Twitter</a></p>
<p>10 0.12565982 <a title="1638-tfidf-10" href="../high_scalability-2012/high_scalability-2012-11-19-Gone_Fishin%27%3A_Tumblr_Architecture_-_15_Billion_Page_Views_A_Month_And_Harder_To_Scale_Than_Twitter.html">1360 high scalability-2012-11-19-Gone Fishin': Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a></p>
<p>11 0.12486699 <a title="1638-tfidf-11" href="../high_scalability-2013/high_scalability-2013-05-20-The_Tumblr_Architecture_Yahoo_Bought_for_a_Cool_Billion_Dollars.html">1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</a></p>
<p>12 0.1206044 <a title="1638-tfidf-12" href="../high_scalability-2013/high_scalability-2013-09-13-Stuff_The_Internet_Says_On_Scalability_For_September_13%2C_2013.html">1516 high scalability-2013-09-13-Stuff The Internet Says On Scalability For September 13, 2013</a></p>
<p>13 0.11885005 <a title="1638-tfidf-13" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>14 0.11882421 <a title="1638-tfidf-14" href="../high_scalability-2013/high_scalability-2013-04-10-Check_Yourself_Before_You_Wreck_Yourself_-_Avocado%27s_5_Early_Stages_of_Architecture_Evolution.html">1438 high scalability-2013-04-10-Check Yourself Before You Wreck Yourself - Avocado's 5 Early Stages of Architecture Evolution</a></p>
<p>15 0.11724067 <a title="1638-tfidf-15" href="../high_scalability-2007/high_scalability-2007-08-30-Log_Everything_All_the_Time.html">77 high scalability-2007-08-30-Log Everything All the Time</a></p>
<p>16 0.1161325 <a title="1638-tfidf-16" href="../high_scalability-2014/high_scalability-2014-02-10-13_Simple_Tricks_for_Scaling_Python_and_Django_with_Apache_from_HackerEarth.html">1593 high scalability-2014-02-10-13 Simple Tricks for Scaling Python and Django with Apache from HackerEarth</a></p>
<p>17 0.11491259 <a title="1638-tfidf-17" href="../high_scalability-2008/high_scalability-2008-01-10-Letting_Clients_Know_What%27s_Changed%3A_Push_Me_or_Pull_Me%3F.html">205 high scalability-2008-01-10-Letting Clients Know What's Changed: Push Me or Pull Me?</a></p>
<p>18 0.11463889 <a title="1638-tfidf-18" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>19 0.11335955 <a title="1638-tfidf-19" href="../high_scalability-2012/high_scalability-2012-07-30-Prismatic_Architecture_-_Using_Machine_Learning_on_Social_Networks_to_Figure_Out_What_You_Should_Read_on_the_Web_.html">1293 high scalability-2012-07-30-Prismatic Architecture - Using Machine Learning on Social Networks to Figure Out What You Should Read on the Web </a></p>
<p>20 0.1128393 <a title="1638-tfidf-20" href="../high_scalability-2012/high_scalability-2012-02-16-A_Short_on_the_Pinterest_Stack_for_Handling_3%2B_Million_Users.html">1193 high scalability-2012-02-16-A Short on the Pinterest Stack for Handling 3+ Million Users</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.202), (1, 0.097), (2, -0.035), (3, -0.08), (4, 0.026), (5, -0.034), (6, 0.026), (7, 0.069), (8, -0.001), (9, 0.005), (10, 0.007), (11, 0.056), (12, 0.077), (13, -0.053), (14, -0.075), (15, 0.023), (16, 0.0), (17, -0.012), (18, -0.025), (19, -0.029), (20, -0.016), (21, -0.06), (22, -0.048), (23, -0.019), (24, 0.054), (25, -0.003), (26, 0.025), (27, 0.075), (28, -0.017), (29, 0.001), (30, 0.018), (31, -0.034), (32, -0.027), (33, 0.003), (34, 0.058), (35, -0.036), (36, -0.021), (37, 0.036), (38, 0.003), (39, 0.076), (40, 0.019), (41, 0.045), (42, -0.006), (43, -0.021), (44, 0.055), (45, -0.016), (46, -0.039), (47, -0.028), (48, -0.047), (49, 0.019)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93021834 <a title="1638-lsi-1" href="../high_scalability-2014/high_scalability-2014-04-28-How_Disqus_Went_Realtime_with_165K_Messages_Per_Second_and_Less_than_.2_Seconds_Latency.html">1638 high scalability-2014-04-28-How Disqus Went Realtime with 165K Messages Per Second and Less than .2 Seconds Latency</a></p>
<p>Introduction: Here's anUpdate On Disqus: It's Still About Realtime, But Go Demolishes
Python.How do you add realtime functionality to a web scale application?
That's whatAdam Hitchcock, a Software Engineer at Disqus talks about in an
excellent talk: Making DISQUS Realtime (slides).Disqus had to take their
commenting system and add realtime capabilities to it. Not something that's
easy to do when at the time of the talk (2013) they had had just hit a billion
unique visitors a month.What Disqus developed is a realtime commenting system
called "realertime" that was tested to handle 1.5 million concurrently
connected users, 45,000 new connections per second, 165,000 messages/second,
with less than .2 seconds latency end-to-end.The nature of a commenting system
is that it is IO bound and has a high fanout, that is a comment comes in and
must be sent out to a lot of readers. It's a problem very similar to
whatTwitter must solve. Disqus' solution was quite interesting as was the path
to their solution. The</p><p>2 0.84916717 <a title="1638-lsi-2" href="../high_scalability-2014/high_scalability-2014-05-07-Update_on_Disqus%3A_It%27s_Still_About_Realtime%2C_But_Go_Demolishes_Python.html">1644 high scalability-2014-05-07-Update on Disqus: It's Still About Realtime, But Go Demolishes Python</a></p>
<p>Introduction: Our last article on Disqus: How Disqus Went Realtime With 165K Messages Per
Second And Less Than .2 Seconds Latency, was a little out of date, but the
folks at Disqus have been busy implementing, not talking, so we don't know a
lot about what they are doing now, but we do have a short update in C1MM and
NGINXby John Watson and an article Trying out this Go thing.So Disqus has
grown a bit:1.3 billion unique visitors10 billion page views500 million users
engaged in discussions3 million communities25 million commentsThey are still
all about realtime, but Go replaced Python in their Realtime system:Original
Realtime backend was written in a pretty lightweight Python + gevent.The
realtime service is a hybrid of CPU intensive tasks + lots of network IO.
Gevent was handling the network IO without an issue, but at higher contention,
the CPU was choking everything. Switching over to Go removed that contention,
which was the primary issue that was being seen.Still runs on 5 machines Nginx
machin</p><p>3 0.75127393 <a title="1638-lsi-3" href="../high_scalability-2013/high_scalability-2013-10-28-Design_Decisions_for_Scaling_Your_High_Traffic_Feeds.html">1538 high scalability-2013-10-28-Design Decisions for Scaling Your High Traffic Feeds</a></p>
<p>Introduction: Guest post by Thierry Schellenbach, Founder/CTO of Fashiolista.com, follow
@tschellenbach on Twitter and GithubFashiolistastarted out as a hobby project
which we built on the side. We had absolutely no idea it would grow into one
of the largest online fashion communities. The entire first version took about
two weeks to develop and our feed implementation was dead simple. We've come a
long way since then and I'd like to share our experience with scaling feed
systems.Feeds are a core component of many large startups such as Pinterest,
Instagram, Wanelo and Fashiolista. At Fashiolista the feed system powers
theflat feed,aggregated feedand thenotification system. This article will
explain the troubles we ran into when scaling our feeds and the design
decisions involved with building your own solution. Understanding the basics
of how these feed systems work is essential as more and more applications rely
on them.Furthermore we've open sourcedFeedly, the Python module powering our
feeds. Wh</p><p>4 0.74971247 <a title="1638-lsi-4" href="../high_scalability-2011/high_scalability-2011-07-06-11_Common_Web_Use_Cases_Solved_in_Redis.html">1074 high scalability-2011-07-06-11 Common Web Use Cases Solved in Redis</a></p>
<p>Introduction: In How to take advantage of Redis just adding it to your stack Salvatore
'antirez' Sanfilippo shows how to solve some common problems in Redis by
taking advantage of its unique data structure handling capabilities. Common
Redis primitives like LPUSH, and LTRIM, and LREM are used to accomplish tasks
programmers need to get done, but that can be hard or slow in more traditional
stores. A very useful and practical article. How would you accomplish these
tasks in your framework?Show latest items listings in your home page. This is
a live in-memory cache and is very fast.LPUSHis used to insert a content ID at
the head of the list stored at a key.LTRIMis used to limit the number of items
in the list to 5000. If the user needs to page beyond this cache only then are
they sent to the database.Deletion and filtering. If a cached article is
deleted it can be removed from the cache using LREM.Leaderboards and related
problems. A leader board is a set sorted by score. TheZADDcommands implements
th</p><p>5 0.73767483 <a title="1638-lsi-5" href="../high_scalability-2012/high_scalability-2012-10-15-Simpler%2C_Cheaper%2C_Faster%3A_Playtomic%27s_Move_from_.NET_to_Node_and_Heroku.html">1340 high scalability-2012-10-15-Simpler, Cheaper, Faster: Playtomic's Move from .NET to Node and Heroku</a></p>
<p>Introduction: This is a guest post by Ben Lowry, CEO ofPlaytomic. Playtomic is a game
analytics service implemented in about 8000 mobile, web and downloadable games
played by approximately 20 million people daily.Here's a good summary quote by
Ben Lowry on Hacker News:Just over 20,000,000 people hit my API yesterday
700,749,252 times, playing the ~8,000 games my analytics platform is
integrated in for a bit under 600 years in total play time. That's just
yesterday. There are lots of different bottlenecks waiting for people
operating at scale. Heroku and NodeJS, for my use case, eventually alleviated
a whole bunch of them very cheaply.Playtomic began with an almost exclusively
Microsoft.NET and Windows architecture which held up for 3 years before being
replaced with a complete rewrite using NodeJS.  During its lifetime the entire
platform grew from shared space on a single server to a full dedicated, then
spread to second dedicated, then the API server was offloaded to a VPS
provider and 4 - 6 fairl</p><p>6 0.71230513 <a title="1638-lsi-6" href="../high_scalability-2010/high_scalability-2010-10-26-Scaling_DISQUS_to_75_Million_Comments_and_17%2C000_RPS.html">928 high scalability-2010-10-26-Scaling DISQUS to 75 Million Comments and 17,000 RPS</a></p>
<p>7 0.70507616 <a title="1638-lsi-7" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>8 0.70398307 <a title="1638-lsi-8" href="../high_scalability-2012/high_scalability-2012-12-17-11_Uses_For_the_Humble_Presents_Queue%2C_er%2C_Message_Queue.html">1373 high scalability-2012-12-17-11 Uses For the Humble Presents Queue, er, Message Queue</a></p>
<p>9 0.70218807 <a title="1638-lsi-9" href="../high_scalability-2007/high_scalability-2007-11-08-ID_generator.html">145 high scalability-2007-11-08-ID generator</a></p>
<p>10 0.69888908 <a title="1638-lsi-10" href="../high_scalability-2012/high_scalability-2012-04-16-Instagram_Architecture_Update%3A_What%E2%80%99s_new_with_Instagram%3F.html">1228 high scalability-2012-04-16-Instagram Architecture Update: What’s new with Instagram?</a></p>
<p>11 0.69829327 <a title="1638-lsi-11" href="../high_scalability-2010/high_scalability-2010-04-12-Poppen.de_Architecture.html">808 high scalability-2010-04-12-Poppen.de Architecture</a></p>
<p>12 0.69306058 <a title="1638-lsi-12" href="../high_scalability-2014/high_scalability-2014-02-26-The_WhatsApp_Architecture_Facebook_Bought_For_%2419_Billion.html">1602 high scalability-2014-02-26-The WhatsApp Architecture Facebook Bought For $19 Billion</a></p>
<p>13 0.69181132 <a title="1638-lsi-13" href="../high_scalability-2012/high_scalability-2012-06-20-iDoneThis_-_Scaling_an_Email-based_App_from_Scratch.html">1269 high scalability-2012-06-20-iDoneThis - Scaling an Email-based App from Scratch</a></p>
<p>14 0.68983221 <a title="1638-lsi-14" href="../high_scalability-2011/high_scalability-2011-02-08-Mollom_Architecture_-_Killing_Over_373_Million_Spams_at_100_Requests_Per_Second.html">985 high scalability-2011-02-08-Mollom Architecture - Killing Over 373 Million Spams at 100 Requests Per Second</a></p>
<p>15 0.68320256 <a title="1638-lsi-15" href="../high_scalability-2008/high_scalability-2008-10-27-Notify.me_Architecture_-_Synchronicity_Kills.html">431 high scalability-2008-10-27-Notify.me Architecture - Synchronicity Kills</a></p>
<p>16 0.68207663 <a title="1638-lsi-16" href="../high_scalability-2013/high_scalability-2013-09-13-Stuff_The_Internet_Says_On_Scalability_For_September_13%2C_2013.html">1516 high scalability-2013-09-13-Stuff The Internet Says On Scalability For September 13, 2013</a></p>
<p>17 0.6819343 <a title="1638-lsi-17" href="../high_scalability-2013/high_scalability-2013-04-10-Check_Yourself_Before_You_Wreck_Yourself_-_Avocado%27s_5_Early_Stages_of_Architecture_Evolution.html">1438 high scalability-2013-04-10-Check Yourself Before You Wreck Yourself - Avocado's 5 Early Stages of Architecture Evolution</a></p>
<p>18 0.68170714 <a title="1638-lsi-18" href="../high_scalability-2014/high_scalability-2014-01-06-How_HipChat_Stores_and_Indexes_Billions_of_Messages_Using_ElasticSearch_and_Redis.html">1573 high scalability-2014-01-06-How HipChat Stores and Indexes Billions of Messages Using ElasticSearch and Redis</a></p>
<p>19 0.67435932 <a title="1638-lsi-19" href="../high_scalability-2009/high_scalability-2009-03-19-Product%3A_Redis_-_Not_Just_Another_Key-Value_Store.html">545 high scalability-2009-03-19-Product: Redis - Not Just Another Key-Value Store</a></p>
<p>20 0.67276406 <a title="1638-lsi-20" href="../high_scalability-2014/high_scalability-2014-01-13-NYTimes_Architecture%3A_No_Head%2C_No_Master%2C_No_Single_Point_of_Failure.html">1577 high scalability-2014-01-13-NYTimes Architecture: No Head, No Master, No Single Point of Failure</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.124), (2, 0.223), (10, 0.054), (30, 0.032), (39, 0.103), (40, 0.011), (51, 0.087), (61, 0.082), (79, 0.093), (85, 0.034), (94, 0.059)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95143569 <a title="1638-lda-1" href="../high_scalability-2013/high_scalability-2013-08-07-RAFT_-_In_Search_of_an_Understandable_Consensus_Algorithm.html">1498 high scalability-2013-08-07-RAFT - In Search of an Understandable Consensus Algorithm</a></p>
<p>Introduction: If like many humans you've found evenPaxos Made Simplea bit difficult to
understand, you might enjoy RAFT as described inIn Search of an Understandable
Consensus Algorithm by Stanford'sDiego Ongaroand John Ousterhout. The video
presentation of the paper is given byJohn Ousterhout. Both the paper and the
video are delightfully accessible.mcherm has a good summary of the paper:A
consensus algorithm is: a cluster of servers should record a series of records
("log entries") in response to requests from clients of the cluster. (It may
also take action based on those entries.) It does so in a way that guarantees
that the responses seen by clients of the cluster will be consistent EVEN in
the face of servers crashing in unpredictable ways (but not loosing data that
was synched to disk), and networks introducing unpredictable delays or
communication blockages.Here's what Raft does. First, it elects a leader, then
the leader records the master version of the log, telling other cluster
servers w</p><p>same-blog 2 0.94200003 <a title="1638-lda-2" href="../high_scalability-2014/high_scalability-2014-04-28-How_Disqus_Went_Realtime_with_165K_Messages_Per_Second_and_Less_than_.2_Seconds_Latency.html">1638 high scalability-2014-04-28-How Disqus Went Realtime with 165K Messages Per Second and Less than .2 Seconds Latency</a></p>
<p>Introduction: Here's anUpdate On Disqus: It's Still About Realtime, But Go Demolishes
Python.How do you add realtime functionality to a web scale application?
That's whatAdam Hitchcock, a Software Engineer at Disqus talks about in an
excellent talk: Making DISQUS Realtime (slides).Disqus had to take their
commenting system and add realtime capabilities to it. Not something that's
easy to do when at the time of the talk (2013) they had had just hit a billion
unique visitors a month.What Disqus developed is a realtime commenting system
called "realertime" that was tested to handle 1.5 million concurrently
connected users, 45,000 new connections per second, 165,000 messages/second,
with less than .2 seconds latency end-to-end.The nature of a commenting system
is that it is IO bound and has a high fanout, that is a comment comes in and
must be sent out to a lot of readers. It's a problem very similar to
whatTwitter must solve. Disqus' solution was quite interesting as was the path
to their solution. The</p><p>3 0.93729711 <a title="1638-lda-3" href="../high_scalability-2012/high_scalability-2012-06-25-StubHub_Architecture%3A_The_Surprising_Complexity_Behind_the_World%E2%80%99s_Largest_Ticket_Marketplace.html">1271 high scalability-2012-06-25-StubHub Architecture: The Surprising Complexity Behind the World’s Largest Ticket Marketplace</a></p>
<p>Introduction: StubHub is an interesting architecture to take a look at because, as market
makers for tickets, they are in a different business than we normally get to
consider.StubHub is surprisingly large, growing at 20% a year, serving 800K
complex pages per hour, selling 5 million tickets per year, and handling 2
million API calls per hour. And the ticket space is surprisingly rich in
complexity. StubHub's traffic is tricky. It's bursty, centering around
unpredictable game outcomes, events, schedules, and seasons. There's a lot of
money involved. There are a lot of different actors involved. There are a lot
of complex business processes involved. And StubHub has several complementary
but very different parts of their business: they have an ad server component
serving ads to sites like ESPN, a rich interactive UI, and a real-time ticket
market component.Most interesting to me is how StubHub is bringing into the
digital realm the once quintessentially high-touch physical world of tickets,
point-of-</p><p>4 0.93702716 <a title="1638-lda-4" href="../high_scalability-2011/high_scalability-2011-10-28-Stuff_The_Internet_Says_On_Scalability_For_October_28%2C_2011.html">1134 high scalability-2011-10-28-Stuff The Internet Says On Scalability For October 28, 2011</a></p>
<p>Introduction: You deserve a HighScalability today:S3: 566 Billion Objects, 370K
requests/sec;Titan: 38,400-processor, 20-petaflop1,000,000 daily users and no
cache. Wooga flash game with 50K DB updates/second, Ruby backend. They hit an
IO wall with MySQL at 1000 DB updates/sec. They needed more so they went with
Redis. Not quite honest to say no cache was used as everything is RAM, but
maybe that's the point. Use a lot of automation. Inactive users are archived.
Moved away from EBS. Making dynamic sitesscale like static sites by Wim
Godden. Use Varnish, Nginx, and memcached. The Lifecycle of a Web Page on
StumbleUpon infographic. 2.2 mllion web pages are added to StumbleUpon each
month. Nice discussion ofbounce rate. James Hamilton with an excellent
overview of the Storage Infrastructure Behind Facebook Messages. That's 6B+
messages a day.Scaling Twilio. Twilio has scaled traffic by more 100x over the
past year, and expanded their server infrastructure from a few servers to
100â&euro;˛s running in the clou</p><p>5 0.93645763 <a title="1638-lda-5" href="../high_scalability-2010/high_scalability-2010-09-16-How_Can_the_Large_Hadron_Collider_Withstand_One_Petabyte_of_Data_a_Second%3F.html">901 high scalability-2010-09-16-How Can the Large Hadron Collider Withstand One Petabyte of Data a Second?</a></p>
<p>Introduction: Why is there something rather than nothing? That's the kind of question
theLarge Hadron Colliderin CERN is hopefully poised to answer. And what is the
output of this beautiful 17-mile long,6 billion dollar wabi-sabishproton
smashing machine? Data. Great heaping torrents of Grand Canyon sized data. 15
million gigabytes every year. That's 1000 times the information printed in
books every year. It's so much data 10,000 scientists will use agridof80,000+
computers, in 300 computer centers , in 50 different countries just to help
make sense of it all.How will all this data be collected, transported, stored,
and analyzed? It turns out, using what amounts to sort of Internet of
Particles instead of an Internet of Things.Two good articles have recently
shed some electro-magnetic energy in the human visible spectrum on the IT
aspects of the collider:LHC computing grid pushes petabytes of data, beats
expectations by John Timmer on Ars Technica and an overview of theBrookhaven's
RHIC/ATLAS Comput</p><p>6 0.93503439 <a title="1638-lda-6" href="../high_scalability-2010/high_scalability-2010-06-16-Hot_Scalability_Links_for_June_16%2C_2010.html">842 high scalability-2010-06-16-Hot Scalability Links for June 16, 2010</a></p>
<p>7 0.93241906 <a title="1638-lda-7" href="../high_scalability-2007/high_scalability-2007-10-30-Feedblendr_Architecture_-_Using_EC2_to_Scale.html">138 high scalability-2007-10-30-Feedblendr Architecture - Using EC2 to Scale</a></p>
<p>8 0.92691231 <a title="1638-lda-8" href="../high_scalability-2009/high_scalability-2009-11-16-Building_Scalable_Systems_Using_Data_as_a_Composite_Material.html">741 high scalability-2009-11-16-Building Scalable Systems Using Data as a Composite Material</a></p>
<p>9 0.92597091 <a title="1638-lda-9" href="../high_scalability-2011/high_scalability-2011-11-18-Stuff_The_Internet_Says_On_Scalability_For_November_18%2C_2011.html">1145 high scalability-2011-11-18-Stuff The Internet Says On Scalability For November 18, 2011</a></p>
<p>10 0.92484194 <a title="1638-lda-10" href="../high_scalability-2014/high_scalability-2014-04-10-Paper%3A_Scalable_Atomic_Visibility_with_RAMP_Transactions_-_Scale_Linearly_to_100_Servers.html">1629 high scalability-2014-04-10-Paper: Scalable Atomic Visibility with RAMP Transactions - Scale Linearly to 100 Servers</a></p>
<p>11 0.92428058 <a title="1638-lda-11" href="../high_scalability-2011/high_scalability-2011-11-29-DataSift_Architecture%3A_Realtime_Datamining_at_120%2C000_Tweets_Per_Second.html">1148 high scalability-2011-11-29-DataSift Architecture: Realtime Datamining at 120,000 Tweets Per Second</a></p>
<p>12 0.91906458 <a title="1638-lda-12" href="../high_scalability-2013/high_scalability-2013-12-11-Using_Node.js_PayPal_Doubles_RPS%2C_Lowers_Latency%2C_with_Fewer_Developers%2C_but_Where_Do_the_Improvements_Really_Come_From%3F.html">1563 high scalability-2013-12-11-Using Node.js PayPal Doubles RPS, Lowers Latency, with Fewer Developers, but Where Do the Improvements Really Come From?</a></p>
<p>13 0.9139387 <a title="1638-lda-13" href="../high_scalability-2010/high_scalability-2010-12-03-GPU_vs_CPU_Smackdown_%3A_The_Rise_of_Throughput-Oriented_Architectures.html">953 high scalability-2010-12-03-GPU vs CPU Smackdown : The Rise of Throughput-Oriented Architectures</a></p>
<p>14 0.91374171 <a title="1638-lda-14" href="../high_scalability-2014/high_scalability-2014-05-07-Update_on_Disqus%3A_It%27s_Still_About_Realtime%2C_But_Go_Demolishes_Python.html">1644 high scalability-2014-05-07-Update on Disqus: It's Still About Realtime, But Go Demolishes Python</a></p>
<p>15 0.91212171 <a title="1638-lda-15" href="../high_scalability-2014/high_scalability-2014-01-28-How_Next_Big_Sound_Tracks_Over_a_Trillion_Song_Plays%2C_Likes%2C_and_More_Using_a_Version_Control_System_for_Hadoop_Data.html">1586 high scalability-2014-01-28-How Next Big Sound Tracks Over a Trillion Song Plays, Likes, and More Using a Version Control System for Hadoop Data</a></p>
<p>16 0.91199625 <a title="1638-lda-16" href="../high_scalability-2009/high_scalability-2009-01-02-Strategy%3A_Understanding_Your_Data_Leads_to_the_Best_Scalability_Solutions.html">481 high scalability-2009-01-02-Strategy: Understanding Your Data Leads to the Best Scalability Solutions</a></p>
<p>17 0.9107641 <a title="1638-lda-17" href="../high_scalability-2012/high_scalability-2012-01-04-How_Facebook_Handled_the_New_Year%27s_Eve_Onslaught.html">1168 high scalability-2012-01-04-How Facebook Handled the New Year's Eve Onslaught</a></p>
<p>18 0.91075641 <a title="1638-lda-18" href="../high_scalability-2008/high_scalability-2008-07-26-Google%27s_Paxos_Made_Live_%E2%80%93_An_Engineering_Perspective.html">357 high scalability-2008-07-26-Google's Paxos Made Live – An Engineering Perspective</a></p>
<p>19 0.90772378 <a title="1638-lda-19" href="../high_scalability-2011/high_scalability-2011-08-22-Strategy%3A_Run_a_Scalable%2C_Available%2C_and_Cheap_Static_Site_on_S3_or_GitHub.html">1102 high scalability-2011-08-22-Strategy: Run a Scalable, Available, and Cheap Static Site on S3 or GitHub</a></p>
<p>20 0.90657568 <a title="1638-lda-20" href="../high_scalability-2009/high_scalability-2009-08-31-Scaling_MySQL_on_Amazon_Web_Services.html">690 high scalability-2009-08-31-Scaling MySQL on Amazon Web Services</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
