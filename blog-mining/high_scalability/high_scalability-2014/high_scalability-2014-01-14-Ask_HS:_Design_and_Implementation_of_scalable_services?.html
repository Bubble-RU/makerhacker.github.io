<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1578 high scalability-2014-01-14-Ask HS: Design and Implementation of scalable services?</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2014" href="../home/high_scalability-2014_home.html">high_scalability-2014</a> <a title="high_scalability-2014-1578" href="#">high_scalability-2014-1578</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1578 high scalability-2014-01-14-Ask HS: Design and Implementation of scalable services?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2014-1578-html" href="http://highscalability.com//blog/2014/1/14/ask-hs-design-and-implementation-of-scalable-services.html">html</a></p><p>Introduction: We have written agents deployed/distributed across the network. Agents sends
data every 15 Secs may be even 5 secs. Working on a service/system to which
all agent can post data/tuples with marginal payload. Upto 5% drop rate is
acceptable. Ultimately the data will be segregated and stored into DBMS System
(currently we are using MSQL).Question(s) I am looking for answer1.
Client/Server Communication: Agent(s) can post data. Status of sending data is
not that important. But there is a remote where Agent(s) to be notified if the
server side system generates an event based on the data sent.- Lot of advices
from internet suggests using Message Bus (ActiveMQ) for async communication.
Multicast and UDP are the alternatives.2. Persistence: After some evaluation
data to be stored in DBMS System.- End of processing data is an aggregated
record for which MySql looks scalable. But on the volume of data is
exponential. Considering HBase as an option.Looking if there are any
alternatives for above</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Agents sends data every 15 Secs may be even 5 secs. [sent-2, score-0.236]
</p><p>2 Working on a service/system to which all agent can post data/tuples with marginal payload. [sent-3, score-0.657]
</p><p>3 Ultimately the data will be segregated and stored into DBMS System (currently we are using MSQL). [sent-5, score-0.462]
</p><p>4 But there is a remote where Agent(s) to be notified if the server side system generates an event based on the data sent. [sent-9, score-0.625]
</p><p>5 - Lot of advices from internet suggests using Message Bus (ActiveMQ) for async communication. [sent-10, score-0.534]
</p><p>6 Persistence: After some evaluation data to be stored in DBMS System. [sent-13, score-0.344]
</p><p>7 - End of processing data is an aggregated record for which MySql looks scalable. [sent-14, score-0.472]
</p><p>8 Looking if there are any alternatives for above two scenarios and get expert advice. [sent-17, score-0.361]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('agent', 0.395), ('agents', 0.298), ('dbms', 0.246), ('segregated', 0.219), ('advices', 0.219), ('secs', 0.219), ('upto', 0.196), ('marginal', 0.174), ('notified', 0.17), ('activemq', 0.17), ('multicast', 0.156), ('udp', 0.149), ('aggregated', 0.137), ('ultimately', 0.132), ('alternatives', 0.131), ('suggests', 0.13), ('stored', 0.128), ('bus', 0.128), ('async', 0.125), ('expert', 0.121), ('sends', 0.121), ('generates', 0.119), ('data', 0.115), ('persistence', 0.11), ('scenarios', 0.109), ('considering', 0.104), ('hbase', 0.103), ('advice', 0.102), ('evaluation', 0.101), ('drop', 0.1), ('sending', 0.099), ('status', 0.098), ('volume', 0.096), ('record', 0.093), ('remote', 0.092), ('post', 0.088), ('communication', 0.084), ('message', 0.083), ('rate', 0.073), ('looks', 0.071), ('currently', 0.069), ('side', 0.068), ('event', 0.061), ('internet', 0.06), ('written', 0.059), ('working', 0.056), ('processing', 0.056), ('looking', 0.052), ('end', 0.049), ('mysql', 0.048)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1578-tfidf-1" href="../high_scalability-2014/high_scalability-2014-01-14-Ask_HS%3A_Design_and_Implementation_of_scalable_services%3F.html">1578 high scalability-2014-01-14-Ask HS: Design and Implementation of scalable services?</a></p>
<p>Introduction: We have written agents deployed/distributed across the network. Agents sends
data every 15 Secs may be even 5 secs. Working on a service/system to which
all agent can post data/tuples with marginal payload. Upto 5% drop rate is
acceptable. Ultimately the data will be segregated and stored into DBMS System
(currently we are using MSQL).Question(s) I am looking for answer1.
Client/Server Communication: Agent(s) can post data. Status of sending data is
not that important. But there is a remote where Agent(s) to be notified if the
server side system generates an event based on the data sent.- Lot of advices
from internet suggests using Message Bus (ActiveMQ) for async communication.
Multicast and UDP are the alternatives.2. Persistence: After some evaluation
data to be stored in DBMS System.- End of processing data is an aggregated
record for which MySql looks scalable. But on the volume of data is
exponential. Considering HBase as an option.Looking if there are any
alternatives for above</p><p>2 0.12891181 <a title="1578-tfidf-2" href="../high_scalability-2008/high_scalability-2008-10-27-Notify.me_Architecture_-_Synchronicity_Kills.html">431 high scalability-2008-10-27-Notify.me Architecture - Synchronicity Kills</a></p>
<p>Introduction: What's cool about starting a new project is you finally have a chance to do it
right. You of course eventually mess everything up in your own way, but for
that one moment the world has a perfect order, a rightness that feels
satisfying and good. Arne Claassen, the CTO of notify.me, a brand new real
time notification delivery service, is in this honeymoon period now.Arne has
been gracious enough to share with us his philosophy of how to build a
notification service. I think you'll find it fascinating because Arne goes
into a lot of useful detail about how his system works.His main design
philosophy is to minimize the bottlenecks that form around synchronous access,
that is whensome resource is requested and the requestor ties up more
resources, waiting for a response. If the requested resource can't be
delivered in a timely manner, more and more requests pile up until the server
can't accept any new ones. Nobody gets what they want and you have an outage.
Breaking synchronous operations</p><p>3 0.10197268 <a title="1578-tfidf-3" href="../high_scalability-2011/high_scalability-2011-07-18-New_Relic_Architecture_-_Collecting_20%2B_Billion_Metrics_a_Day.html">1082 high scalability-2011-07-18-New Relic Architecture - Collecting 20+ Billion Metrics a Day</a></p>
<p>Introduction: This is a guest post by Brian Doll, Application Performance Engineer at New
Relic.New Relic's multitenant, SaaS web application monitoring service
collects and persists over 100,000 metrics every second on a sustained basis,
while still delivering an average page load time of 1.5 seconds.  We believe
that good architecture and good tools can help you handle an extremely large
amount of data while still providing extremely fast service.  Here we'll show
you how we do it. New Relic is Application Performance Management (APM) as a
Service In-app agent instrumentation (bytecode instrumentation, etc.) Support
for 5 programming languages (Ruby, Java, PHP, .NET, Python) 175,000+ app
processes monitored globally 10,000+ customersThe Stats 20+ Billion
application metrics collected every day 1.7+ Billion web page metrics
collected every week Each "timeslice" metric is about 250 bytes 100k timeslice
records inserted every second 7 Billion new rows of data every day Data
collection handled by 9 sh</p><p>4 0.096413389 <a title="1578-tfidf-4" href="../high_scalability-2008/high_scalability-2008-01-28-Product%3A_ISPMan_Centralized_ISP_Management_System_.html">228 high scalability-2008-01-28-Product: ISPMan Centralized ISP Management System </a></p>
<p>Introduction: FromFRESH Portsand their website:ISPmanis an ISP management software written
in perl, using an LDAPbackend to manage virtual hosts for an ISP. It can be
used to manage,DNS, virtual hosts for apache config, postfix configuration,
cyrusmail boxes, proftpd etc.ISPMan was written as a management tool for the
network at 4unet wherebetween 30 to 50 domains are hosted and the number is
crazily growing.Managing these domains and their users was a little time
consuming,and needed an Administrator who knows linux and these
daemonsfluently. Now the help-desk can easily manage the domains and
users.LDAP data can be easily replicated site wide, and mail box server canbe
scaled from 1 to n as required. An LDAP entry called maildroptells the SMTP
server (postfix) where to deliver the mail. The SMTPservers can be
loadbalanced with one of many load balancingtechniques. The program is written
with scalability and Highavailability in mind.This may not be the right
software for you if you want to run a sm</p><p>5 0.089913845 <a title="1578-tfidf-5" href="../high_scalability-2010/high_scalability-2010-07-13-DbShards_Part_Deux_-_The_Internals.html">857 high scalability-2010-07-13-DbShards Part Deux - The Internals</a></p>
<p>Introduction: This is a follow up article byCory Isaacson to the first article on DbShards,
Product: dbShards - Share Nothing. Shard Everything, describing some of the
details about how DbShards works on the inside.The dbShards architecture is a
true "shared nothing" implementation of Database Sharding. The high-level view
of dbShards is shown here:The above diagram shows how dbShards works for
achieving massive database scalability across multiple database servers, using
native DBMS engines and our dbShards components. The important components
are:dbS/Client: A design goal of dbShards is to make database sharding as
seamless as possible to an application, so that application developers can
write the same type of code they always have. A key component to making this
possible is the dbShards Client. The dbShards Client is our intelligent driver
that is an exact API emulation of a given vendor's database driver. For
example, with MySQL we have full support for JDBC, and the the MySQL C driver
(used in</p><p>6 0.086451098 <a title="1578-tfidf-6" href="../high_scalability-2009/high_scalability-2009-04-03-Collectl_interface_to_Ganglia_-_any_interest%3F.html">553 high scalability-2009-04-03-Collectl interface to Ganglia - any interest?</a></p>
<p>7 0.08354383 <a title="1578-tfidf-7" href="../high_scalability-2010/high_scalability-2010-03-16-1_Billion_Reasons_Why_Adobe_Chose_HBase_.html">795 high scalability-2010-03-16-1 Billion Reasons Why Adobe Chose HBase </a></p>
<p>8 0.08210218 <a title="1578-tfidf-8" href="../high_scalability-2013/high_scalability-2013-02-19-Puppet_monitoring%3A_how_to_monitor_the_success_or_failure_of_Puppet_runs__.html">1408 high scalability-2013-02-19-Puppet monitoring: how to monitor the success or failure of Puppet runs  </a></p>
<p>9 0.079426266 <a title="1578-tfidf-9" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>10 0.079332843 <a title="1578-tfidf-10" href="../high_scalability-2010/high_scalability-2010-11-16-Facebook%27s_New_Real-time_Messaging_System%3A_HBase_to_Store_135%2B_Billion_Messages_a_Month.html">943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</a></p>
<p>11 0.076539382 <a title="1578-tfidf-11" href="../high_scalability-2012/high_scalability-2012-06-25-StubHub_Architecture%3A_The_Surprising_Complexity_Behind_the_World%E2%80%99s_Largest_Ticket_Marketplace.html">1271 high scalability-2012-06-25-StubHub Architecture: The Surprising Complexity Behind the World’s Largest Ticket Marketplace</a></p>
<p>12 0.076399848 <a title="1578-tfidf-12" href="../high_scalability-2007/high_scalability-2007-10-14-Product%3A_The_Spread_Toolkit.html">122 high scalability-2007-10-14-Product: The Spread Toolkit</a></p>
<p>13 0.07242161 <a title="1578-tfidf-13" href="../high_scalability-2009/high_scalability-2009-03-19-Product%3A_Redis_-_Not_Just_Another_Key-Value_Store.html">545 high scalability-2009-03-19-Product: Redis - Not Just Another Key-Value Store</a></p>
<p>14 0.069352254 <a title="1578-tfidf-14" href="../high_scalability-2007/high_scalability-2007-12-10-Future_of_EJB3_%21%21_%3F%3F.html">179 high scalability-2007-12-10-Future of EJB3 !! ??</a></p>
<p>15 0.067593969 <a title="1578-tfidf-15" href="../high_scalability-2007/high_scalability-2007-11-12-a8cjdbc_-_Database_Clustering_via_JDBC.html">151 high scalability-2007-11-12-a8cjdbc - Database Clustering via JDBC</a></p>
<p>16 0.064930722 <a title="1578-tfidf-16" href="../high_scalability-2007/high_scalability-2007-07-25-Product%3A_3_PAR_REMOTE_COPY.html">27 high scalability-2007-07-25-Product: 3 PAR REMOTE COPY</a></p>
<p>17 0.064762495 <a title="1578-tfidf-17" href="../high_scalability-2010/high_scalability-2010-11-09-Facebook_Uses_Non-Stored_Procedures_to_Update_Social_Graphs.html">936 high scalability-2010-11-09-Facebook Uses Non-Stored Procedures to Update Social Graphs</a></p>
<p>18 0.064753123 <a title="1578-tfidf-18" href="../high_scalability-2010/high_scalability-2010-11-01-Hot_Trend%3A__Move_Behavior_to_Data_for_a_New_Interactive_Application_Architecture.html">933 high scalability-2010-11-01-Hot Trend:  Move Behavior to Data for a New Interactive Application Architecture</a></p>
<p>19 0.064723998 <a title="1578-tfidf-19" href="../high_scalability-2008/high_scalability-2008-10-04-Is_MapReduce_going_mainstream%3F.html">401 high scalability-2008-10-04-Is MapReduce going mainstream?</a></p>
<p>20 0.064662397 <a title="1578-tfidf-20" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.093), (1, 0.035), (2, -0.013), (3, -0.01), (4, 0.016), (5, 0.057), (6, 0.038), (7, -0.003), (8, 0.012), (9, 0.008), (10, -0.004), (11, 0.041), (12, 0.032), (13, -0.043), (14, 0.02), (15, 0.039), (16, 0.002), (17, -0.006), (18, -0.022), (19, -0.011), (20, -0.007), (21, -0.001), (22, -0.011), (23, 0.02), (24, 0.041), (25, -0.0), (26, -0.003), (27, 0.007), (28, -0.008), (29, 0.012), (30, -0.021), (31, 0.002), (32, -0.003), (33, 0.018), (34, 0.014), (35, 0.025), (36, 0.028), (37, -0.002), (38, 0.01), (39, 0.002), (40, 0.051), (41, 0.02), (42, 0.023), (43, 0.015), (44, 0.028), (45, 0.001), (46, -0.012), (47, -0.001), (48, -0.043), (49, -0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.89543068 <a title="1578-lsi-1" href="../high_scalability-2014/high_scalability-2014-01-14-Ask_HS%3A_Design_and_Implementation_of_scalable_services%3F.html">1578 high scalability-2014-01-14-Ask HS: Design and Implementation of scalable services?</a></p>
<p>Introduction: We have written agents deployed/distributed across the network. Agents sends
data every 15 Secs may be even 5 secs. Working on a service/system to which
all agent can post data/tuples with marginal payload. Upto 5% drop rate is
acceptable. Ultimately the data will be segregated and stored into DBMS System
(currently we are using MSQL).Question(s) I am looking for answer1.
Client/Server Communication: Agent(s) can post data. Status of sending data is
not that important. But there is a remote where Agent(s) to be notified if the
server side system generates an event based on the data sent.- Lot of advices
from internet suggests using Message Bus (ActiveMQ) for async communication.
Multicast and UDP are the alternatives.2. Persistence: After some evaluation
data to be stored in DBMS System.- End of processing data is an aggregated
record for which MySql looks scalable. But on the volume of data is
exponential. Considering HBase as an option.Looking if there are any
alternatives for above</p><p>2 0.73841256 <a title="1578-lsi-2" href="../high_scalability-2012/high_scalability-2012-03-19-LinkedIn%3A_Creating_a_Low_Latency_Change_Data_Capture_System_with_Databus.html">1211 high scalability-2012-03-19-LinkedIn: Creating a Low Latency Change Data Capture System with Databus</a></p>
<p>Introduction: This is a guest post bySiddharth Anand, a senior member of LinkedIn's
Distributed Data Systems team.Over the past 3 years, I've had the good fortune
to work with many emerging NoSQL products in the context of supporting the
needs of a high-traffic, customer facing web site.In 2010, I helped Netflix to
successfullytransition its web scale use-cases from Oracle to SimpleDB, AWS'
hosted database service. On completion of that migration, we started a second
migration, this time from SimpleDB to Cassandra. The first transition was key
to our move from our own data center to AWS' cloud. The second was key to our
expansion from one AWS Region to multiple geographically-distributed Regions
-- today Netflix serves traffic out of two AWS Regions, one in Virginia, the
other in Ireland (F1). Both of these transitions have been successful, but
have involved integration pain points such as the creation of database
replication technology.In December 2011, I moved to LinkedIn's Distributed
Data System</p><p>3 0.73676717 <a title="1578-lsi-3" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>Introduction: Mobile developers have a huge scaling problem ahead: doing something useful
with massive continuous streams of telemetry data from millions and millions
of devices. This is a really good problem to have. It means smartphone sales
are finally fulfilling their destiny: slaughtering PCsin the sales arena. And
it also means mobile devices aren't just containers for simple standalone apps
anymore, they are becoming the dominant interface to giant backend
systems.While developers are now rocking mobile development on the client
side, their next challenge is how to code those tricky backend bits. A company
facing those same exact problems right now isMedialets, a mobile rich media ad
platform. What they do is help publishers create high quality interactive ads,
though for our purposes their ad stuff isn't that interesting. What I did find
really interesting about their system is how they are tackling the problem of
defeating the mobile device data deluge.Each day Medialets munches on billions</p><p>4 0.73593748 <a title="1578-lsi-4" href="../high_scalability-2012/high_scalability-2012-11-26-BigData_using_Erlang%2C_C_and_Lisp_to_Fight_the_Tsunami_of_Mobile_Data.html">1362 high scalability-2012-11-26-BigData using Erlang, C and Lisp to Fight the Tsunami of Mobile Data</a></p>
<p>Introduction: This is a guest post byJon Vlachogiannis. Jon is the founder and CTO
ofBugSense.BugSense, is an error-reporting and quality metrics service that
tracks thousand of apps every day. When mobile apps crash, BugSense helps
developers pinpoint and fix the problem. The startup delivers first-class
service to its customers, which include VMWare, Samsung, Skype and thousands
of independent app developers. Tracking more than 200M devices requires fast,
fault tolerant and cheap infrastructure.The last six months, we've decided to
use our BigData infrastructure, to provide the users with metrics about their
apps performance and stability and let them know how the errors affect their
user base and revenues.We knew that our solution should be scalable from day
one, because more than 4% of the smartphones out there, will start DDOSing us
with data.We wanted to be able to:Abstract the application logic and feed
browsers with JSONRun complex algorithms on the flyExperiment with data,
without the need</p><p>5 0.72250277 <a title="1578-lsi-5" href="../high_scalability-2014/high_scalability-2014-03-24-Big%2C_Small%2C_Hot_or_Cold_-_Examples_of_Robust_Data_Pipelines_from_Stripe%2C_Tapad%2C_Etsy_and_Square.html">1618 high scalability-2014-03-24-Big, Small, Hot or Cold - Examples of Robust Data Pipelines from Stripe, Tapad, Etsy and Square</a></p>
<p>Introduction: This is a guest repost byPete Soderling, Founder at Hakka Labs, creating a
community where software engineers come to grow.In response to a recent post
from MongoHQ entitled "You don't have big data," I would generally agree with
many of the author's points.However, regardless of whether you call it big
data, small data, hot data or cold data - we are all in a position to admit
that *more* data is here to stay - and that's due to many different
factors.Perhaps primarily, as the article mentions, this is due to the
decreasing cost of storage over time. Other factors include access to open
APIs, the sheer volume of ever-increasing consumer activity online, as well as
a plethora of other incentives that are developing (mostly) behind the scenes
as companies "share" data with each other. (You know they do this, right?)But
one of the most important things I've learned over the past couple of years is
that it's crucial for forward thinking companies to start to design more
robust data pipeli</p><p>6 0.71602374 <a title="1578-lsi-6" href="../high_scalability-2011/high_scalability-2011-04-12-Caching_and_Processing_2TB_Mozilla_Crash_Reports_in_memory_with_Hazelcast.html">1020 high scalability-2011-04-12-Caching and Processing 2TB Mozilla Crash Reports in memory with Hazelcast</a></p>
<p>7 0.70818347 <a title="1578-lsi-7" href="../high_scalability-2008/high_scalability-2008-01-30-How_Rackspace_Now_Uses_MapReduce_and_Hadoop_to_Query_Terabytes_of_Data.html">233 high scalability-2008-01-30-How Rackspace Now Uses MapReduce and Hadoop to Query Terabytes of Data</a></p>
<p>8 0.7025103 <a title="1578-lsi-8" href="../high_scalability-2013/high_scalability-2013-01-07-Analyzing_billions_of_credit_card_transactions_and_serving_low-latency_insights_in_the_cloud.html">1382 high scalability-2013-01-07-Analyzing billions of credit card transactions and serving low-latency insights in the cloud</a></p>
<p>9 0.69876629 <a title="1578-lsi-9" href="../high_scalability-2010/high_scalability-2010-12-08-How_To_Get_Experience_Working_With_Large_Datasets.html">956 high scalability-2010-12-08-How To Get Experience Working With Large Datasets</a></p>
<p>10 0.69187337 <a title="1578-lsi-10" href="../high_scalability-2009/high_scalability-2009-04-06-How_do_you_monitor_the_performance_of_your_cluster%3F.html">558 high scalability-2009-04-06-How do you monitor the performance of your cluster?</a></p>
<p>11 0.69116259 <a title="1578-lsi-11" href="../high_scalability-2009/high_scalability-2009-04-03-Collectl_interface_to_Ganglia_-_any_interest%3F.html">553 high scalability-2009-04-03-Collectl interface to Ganglia - any interest?</a></p>
<p>12 0.68711072 <a title="1578-lsi-12" href="../high_scalability-2010/high_scalability-2010-09-23-Working_With_Large_Data_Sets.html">907 high scalability-2010-09-23-Working With Large Data Sets</a></p>
<p>13 0.68369162 <a title="1578-lsi-13" href="../high_scalability-2009/high_scalability-2009-10-06-Building_a_Unique_Data_Warehouse.html">716 high scalability-2009-10-06-Building a Unique Data Warehouse</a></p>
<p>14 0.66943884 <a title="1578-lsi-14" href="../high_scalability-2010/high_scalability-2010-08-18-Misco%3A_A_MapReduce_Framework_for_Mobile_Systems_-_Start_of_the_Ambient_Cloud%3F.html">882 high scalability-2010-08-18-Misco: A MapReduce Framework for Mobile Systems - Start of the Ambient Cloud?</a></p>
<p>15 0.66526723 <a title="1578-lsi-15" href="../high_scalability-2014/high_scalability-2014-01-28-How_Next_Big_Sound_Tracks_Over_a_Trillion_Song_Plays%2C_Likes%2C_and_More_Using_a_Version_Control_System_for_Hadoop_Data.html">1586 high scalability-2014-01-28-How Next Big Sound Tracks Over a Trillion Song Plays, Likes, and More Using a Version Control System for Hadoop Data</a></p>
<p>16 0.66455668 <a title="1578-lsi-16" href="../high_scalability-2010/high_scalability-2010-04-13-Strategy%3A_Saving_Your_Butt_With_Deferred_Deletes.html">809 high scalability-2010-04-13-Strategy: Saving Your Butt With Deferred Deletes</a></p>
<p>17 0.66347367 <a title="1578-lsi-17" href="../high_scalability-2007/high_scalability-2007-10-10-WAN_Accelerate_Your_Way_to_Lightening_Fast_Transfers_Between_Data_Centers.html">119 high scalability-2007-10-10-WAN Accelerate Your Way to Lightening Fast Transfers Between Data Centers</a></p>
<p>18 0.66314822 <a title="1578-lsi-18" href="../high_scalability-2008/high_scalability-2008-11-24-Product%3A_Scribe_-_Facebook%27s_Scalable_Logging_System.html">449 high scalability-2008-11-24-Product: Scribe - Facebook's Scalable Logging System</a></p>
<p>19 0.66302633 <a title="1578-lsi-19" href="../high_scalability-2011/high_scalability-2011-12-22-Architecting_Massively-Scalable_Near-Real-Time_Risk_Analysis_Solutions.html">1161 high scalability-2011-12-22-Architecting Massively-Scalable Near-Real-Time Risk Analysis Solutions</a></p>
<p>20 0.66176689 <a title="1578-lsi-20" href="../high_scalability-2009/high_scalability-2009-05-01-FastBit%3A_An_Efficient_Compressed_Bitmap_Index_Technology.html">587 high scalability-2009-05-01-FastBit: An Efficient Compressed Bitmap Index Technology</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.128), (2, 0.242), (16, 0.285), (30, 0.063), (61, 0.054), (79, 0.015), (85, 0.09)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.8581174 <a title="1578-lda-1" href="../high_scalability-2014/high_scalability-2014-01-14-Ask_HS%3A_Design_and_Implementation_of_scalable_services%3F.html">1578 high scalability-2014-01-14-Ask HS: Design and Implementation of scalable services?</a></p>
<p>Introduction: We have written agents deployed/distributed across the network. Agents sends
data every 15 Secs may be even 5 secs. Working on a service/system to which
all agent can post data/tuples with marginal payload. Upto 5% drop rate is
acceptable. Ultimately the data will be segregated and stored into DBMS System
(currently we are using MSQL).Question(s) I am looking for answer1.
Client/Server Communication: Agent(s) can post data. Status of sending data is
not that important. But there is a remote where Agent(s) to be notified if the
server side system generates an event based on the data sent.- Lot of advices
from internet suggests using Message Bus (ActiveMQ) for async communication.
Multicast and UDP are the alternatives.2. Persistence: After some evaluation
data to be stored in DBMS System.- End of processing data is an aggregated
record for which MySql looks scalable. But on the volume of data is
exponential. Considering HBase as an option.Looking if there are any
alternatives for above</p><p>2 0.85064834 <a title="1578-lda-2" href="../high_scalability-2007/high_scalability-2007-10-03-Why_most_large-scale_Web_sites_are_not_written_in_Java.html">110 high scalability-2007-10-03-Why most large-scale Web sites are not written in Java</a></p>
<p>Introduction: Thereis alot ofinformation in the blogosphere describing the architecture of
many popular sites, such as Google, Amazon, eBay, LinkedIn, TypePad, WikiPedia
and others.I've summarized this issue in a blog posthereI would really
appreciate your opinion on this matter.</p><p>3 0.82564914 <a title="1578-lda-3" href="../high_scalability-2011/high_scalability-2011-07-20-Netflix%3A_Harden_Systems_Using_a_Barrel_of_Problem_Causing_Monkeys_-_Latency%2C_Conformity%2C_Doctor%2C_Janitor%2C_Security%2C_Internationalization%2C_Chaos.html">1083 high scalability-2011-07-20-Netflix: Harden Systems Using a Barrel of Problem Causing Monkeys - Latency, Conformity, Doctor, Janitor, Security, Internationalization, Chaos</a></p>
<p>Introduction: With a new Planet of the Apes coming out, this may be a touchy subject with
our new overlords, but Netflix is using a whole lot more trouble injecting
monkeys to test and iteratively harden their systems. We learned previously
how Netflix used Chaos Monkey, a tool to test failover handling by
continuously failing EC2 nodes. That was just a start. More monkeys have been
added to the barrel. Node failure is just one problem in a system. Imagine a
problem and you can imagine creating a monkey to test if your system is
handling that problem properly. Yury Izrailevsky talks about just this
approach in this very interesting post: The Netflix Simian Army.I know what
you are thinking, if monkeys are so great then why has Netflix been down
lately. Dmuino addressedthis potential embarrassment, putting all fears of
cloud inferiority to rest:Unfortunately we're not running 100% on the cloud
today. We're working on it, and we could use more help. The latest outage was
caused by a component that sti</p><p>4 0.7642529 <a title="1578-lda-4" href="../high_scalability-2008/high_scalability-2008-09-23-Event%3A_CloudCamp_Silicon_Valley_Unconference_on_30th_September.html">388 high scalability-2008-09-23-Event: CloudCamp Silicon Valley Unconference on 30th September</a></p>
<p>Introduction: CloudCampis an interesting unconference where early adapters of Cloud
Computing technologies exchange ideas. With the rapid change occurring in the
industry, we need a place we can meet to share our experiences, challenges and
solutions. At CloudCamp, you are encouraged you to share your thoughts in
several open discussions, as we strive for the advancement of Cloud Computing.
End users, IT professionals and vendors are all encouraged to
participate.CloudCamp Silicon Valley 08is scheduled for Tuesday, September 30,
2008 from 06:00 PM - 10:00 PM in Sun Microsystems' EBC Briefing Center15
Network CircleMenlo Park, CA 94025CloudCamp follows an interactive, unscripted
unconference format. You can propose your own session or you can attend a
session proposed by someone else. Either way, you are encouraged to engage in
the discussion and “Vote with your feet”, which means … “find another session
if you don’t find the session helpful”. Pick and choose from the
conversations; rant and rave, or</p><p>5 0.76186478 <a title="1578-lda-5" href="../high_scalability-2014/high_scalability-2014-04-30-10_Tips_for_Optimizing_NGINX_and_PHP-fpm_for_High_Traffic_Sites.html">1640 high scalability-2014-04-30-10 Tips for Optimizing NGINX and PHP-fpm for High Traffic Sites</a></p>
<p>Introduction: Adrian Singer has boiled down 7 years of experience to a set of 10 very useful
tips on how to bestoptimize NGINX and PHP-fpm for high traffic sites:Switch
from TCP to UNIX domain sockets. When communicating to processes on the same
machine UNIX sockets have better performance the TCP because there's less
copying and fewer context switches.Adjust Worker Processes. Set the
worker_processes in your nginx.conf file to the number of cores your machine
has and  increase the number of worker_connections.Setup upstream load
balancing. Multiple upstream backends on the same machine produce higher
throughout than a single one.Disable access log files. Log files on high
traffic sites involve a lot of I/O that has to be synchronized across all
threads. Can have a big impact.Enable GZip. Cache information about frequently
accessed files. Adjust client timeouts.Adjust output buffers./etc/sysctl.conf
tuning.Monitor. Continually monitor the number of open connections, free
memory and number of waiting</p><p>6 0.75980002 <a title="1578-lda-6" href="../high_scalability-2013/high_scalability-2013-12-04-How_Can_Batching_Requests_Actually_Reduce_Latency%3F.html">1558 high scalability-2013-12-04-How Can Batching Requests Actually Reduce Latency?</a></p>
<p>7 0.75977951 <a title="1578-lda-7" href="../high_scalability-2011/high_scalability-2011-07-01-Stuff_The_Internet_Says_On_Scalability_For_July_1%2C_2011.html">1071 high scalability-2011-07-01-Stuff The Internet Says On Scalability For July 1, 2011</a></p>
<p>8 0.74215609 <a title="1578-lda-8" href="../high_scalability-2009/high_scalability-2009-01-05-Lessons_Learned_at_208K%3A_Towards_Debugging_Millions_of_Cores.html">484 high scalability-2009-01-05-Lessons Learned at 208K: Towards Debugging Millions of Cores</a></p>
<p>9 0.71976948 <a title="1578-lda-9" href="../high_scalability-2011/high_scalability-2011-03-14-Twitter_by_the_Numbers_-_460%2C000_New_Accounts_and_140_Million_Tweets_Per_Day.html">1004 high scalability-2011-03-14-Twitter by the Numbers - 460,000 New Accounts and 140 Million Tweets Per Day</a></p>
<p>10 0.71230996 <a title="1578-lda-10" href="../high_scalability-2010/high_scalability-2010-03-09-Applications_as_Virtual_States.html">790 high scalability-2010-03-09-Applications as Virtual States</a></p>
<p>11 0.70884413 <a title="1578-lda-11" href="../high_scalability-2014/high_scalability-2014-05-21-9_Principles_of_High_Performance_Programs.html">1652 high scalability-2014-05-21-9 Principles of High Performance Programs</a></p>
<p>12 0.70199192 <a title="1578-lda-12" href="../high_scalability-2014/high_scalability-2014-02-21-Stuff_The_Internet_Says_On_Scalability_For_February_21st%2C_2014.html">1600 high scalability-2014-02-21-Stuff The Internet Says On Scalability For February 21st, 2014</a></p>
<p>13 0.70165062 <a title="1578-lda-13" href="../high_scalability-2012/high_scalability-2012-10-29-Gone_Fishin%27%3A_Welcome_to_High_Scalability.html">1349 high scalability-2012-10-29-Gone Fishin': Welcome to High Scalability</a></p>
<p>14 0.69733882 <a title="1578-lda-14" href="../high_scalability-2007/high_scalability-2007-08-01-Product%3A_Memcached.html">52 high scalability-2007-08-01-Product: Memcached</a></p>
<p>15 0.69144803 <a title="1578-lda-15" href="../high_scalability-2008/high_scalability-2008-02-03-Product%3A_Collectl_-_Performance_Data_Collector.html">237 high scalability-2008-02-03-Product: Collectl - Performance Data Collector</a></p>
<p>16 0.69091791 <a title="1578-lda-16" href="../high_scalability-2013/high_scalability-2013-06-10-The_10_Deadly_Sins_Against_Scalability.html">1473 high scalability-2013-06-10-The 10 Deadly Sins Against Scalability</a></p>
<p>17 0.68652898 <a title="1578-lda-17" href="../high_scalability-2010/high_scalability-2010-11-15-Strategy%3A_Biggest_Performance_Impact_is_to_Reduce_the_Number_of_HTTP_Requests.html">942 high scalability-2010-11-15-Strategy: Biggest Performance Impact is to Reduce the Number of HTTP Requests</a></p>
<p>18 0.68596292 <a title="1578-lda-18" href="../high_scalability-2009/high_scalability-2009-09-10-How_to_handle_so_many_socket_connection.html">699 high scalability-2009-09-10-How to handle so many socket connection</a></p>
<p>19 0.68522847 <a title="1578-lda-19" href="../high_scalability-2009/high_scalability-2009-06-26-PlentyOfFish_Architecture.html">638 high scalability-2009-06-26-PlentyOfFish Architecture</a></p>
<p>20 0.6851446 <a title="1578-lda-20" href="../high_scalability-2008/high_scalability-2008-05-10-Hitting_300_SimbleDB_Requests_Per_Second_on_a_Small_EC2_Instance.html">317 high scalability-2008-05-10-Hitting 300 SimbleDB Requests Per Second on a Small EC2 Instance</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
