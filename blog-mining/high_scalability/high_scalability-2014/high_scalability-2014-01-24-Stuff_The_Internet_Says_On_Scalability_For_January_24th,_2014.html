<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1585 high scalability-2014-01-24-Stuff The Internet Says On Scalability For January 24th, 2014</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2014" href="../home/high_scalability-2014_home.html">high_scalability-2014</a> <a title="high_scalability-2014-1585" href="#">high_scalability-2014-1585</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1585 high scalability-2014-01-24-Stuff The Internet Says On Scalability For January 24th, 2014</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2014-1585-html" href="http://highscalability.com//blog/2014/1/24/stuff-the-internet-says-on-scalability-for-january-24th-2014.html">html</a></p><p>Introduction: Hey, it's HighScalability time:
     Gorgeous image from Scientific American's  Your Brain by the Numbers    
 Quotable Quotes:                           
 
  @jezhumble : Google does everything off trunk despite 10k devs across 40 offices.  
  @KentLangley : "in 2016. When it goes online, the SKA is expected to produce 700 terabytes of data each day"  
  Jonathan Marks : It's actually a talk about how NOT to be creative. And what he [John Cleese] describes is the way most international broadcasters operated for most of their existence. They were content factories, slave to an artificial transmission schedule. Because they didn't take time to be creative, then ended up sounding like a tape machine. They were run by a computer algorithm. Not a human soul. There was never room for a creative pause. Routine was the solution. And that's creativities biggest enemy. 
 
 
 
  40% better single-threaded performance in MariaDB . Using perf, cache misses were found and the fix was using the righ</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 When it goes online, the SKA is expected to produce 700 terabytes of data each day"     Jonathan Marks : It's actually a talk about how NOT to be creative. [sent-3, score-0.076]
</p><p>2 And what he [John Cleese] describes is the way most international broadcasters operated for most of their existence. [sent-4, score-0.081]
</p><p>3 Using perf, cache misses were found and the fix was using the right gcc flags. [sent-13, score-0.358]
</p><p>4 When Socrates asks you a question, it's probably a question worth thinking about. [sent-18, score-0.082]
</p><p>5 88 million trips by air, 235 million trips by rail, and 2. [sent-23, score-0.398]
</p><p>6 85 billion road trips  during the peak of China’s Spring Festival  holiday period. [sent-24, score-0.111]
</p><p>7 The GemFire in-memory data grid was tasked to handle the load: Seventy two UNIX systems and a relational database were replaced with 10 primary and 10 back up x86 servers, a much more cost-effective model that holds 2 terabytes or one month of ticket data in memory. [sent-25, score-0.076]
</p><p>8 Holiday travel periods create peaks of  10 million tickets sold per day, 20 million passengers to visit the web site, 1. [sent-26, score-0.379]
</p><p>9 4 billion page views per day, and 40,000 visits per second driving up to 5 million tickets sold online per day at peak. [sent-27, score-0.382]
</p><p>10 Reining in the Cost of Connectivity : It is abundantly clear that the United States’ collective broadband experience does not measure up to that of other countries. [sent-33, score-0.154]
</p><p>11 The fix is more checks, which are of course themselves a future source of potential error. [sent-39, score-0.082]
</p><p>12 The fix is a tool that parallelizes the replay of binary logs. [sent-41, score-0.158]
</p><p>13 I liked poetic finality of this advice from Sonar: "We focused on engagement, which we improved by orders of magnitude. [sent-44, score-0.074]
</p><p>14 If we use the cache optimally, we can store 32,768 items. [sent-59, score-0.074]
</p><p>15 But, since we’re accessing things that are page (4k) aligned, we effectively lose the bottom log₂(4k) = 12 bits, which means that every access falls into the same set, and we can only loop through 8 things before our working set is too large to fit in the L1! [sent-60, score-0.089]
</p><p>16 But if we’d misaligned our data to different cache lines, we’d be able to use 8 * 64 = 512 locations effectively. [sent-61, score-0.074]
</p><p>17 PayPal with a good article on  Building infinite scrolling in the PayPal mobile web app : The core of the infinite scroll is the ability to reuse cells that are no longer visible. [sent-62, score-0.259]
</p><p>18 Lots of love for DTrace as an ace investigative tool. [sent-65, score-0.152]
</p><p>19 While many of you can project what a supercomputer of that magnitude might cost, the duration of their run to sort compounds cost them around $33,000—and ran in less than a day distributed across 16,788 instances. [sent-69, score-0.254]
</p><p>20 Akka ran a  large test on Google Compute engine  and were able to reach 2400 nodes as well as starting up a 1000 node cluster in just over four minutes. [sent-70, score-0.082]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('outgrown', 0.162), ('misses', 0.126), ('paypal', 0.119), ('china', 0.115), ('trips', 0.111), ('xen', 0.107), ('tickets', 0.106), ('home', 0.101), ('sold', 0.097), ('vms', 0.092), ('day', 0.091), ('accessing', 0.089), ('infinite', 0.089), ('zones', 0.088), ('million', 0.088), ('creative', 0.084), ('fix', 0.082), ('ran', 0.082), ('question', 0.082), ('bookscaling', 0.081), ('compounds', 0.081), ('abundantly', 0.081), ('seagate', 0.081), ('scroll', 0.081), ('ska', 0.081), ('jezhumble', 0.081), ('onbuilding', 0.081), ('numbersquotable', 0.081), ('kentlangley', 0.081), ('broadcasters', 0.081), ('serviceworkers', 0.081), ('compute', 0.078), ('terabytes', 0.076), ('gorgeous', 0.076), ('ace', 0.076), ('parallelizes', 0.076), ('gcc', 0.076), ('alarge', 0.076), ('investigative', 0.076), ('cache', 0.074), ('persistent', 0.074), ('focused', 0.074), ('rail', 0.073), ('trunk', 0.073), ('aligned', 0.073), ('respective', 0.073), ('factories', 0.073), ('americans', 0.073), ('broadband', 0.073), ('harish', 0.073)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="1585-tfidf-1" href="../high_scalability-2014/high_scalability-2014-01-24-Stuff_The_Internet_Says_On_Scalability_For_January_24th%2C_2014.html">1585 high scalability-2014-01-24-Stuff The Internet Says On Scalability For January 24th, 2014</a></p>
<p>Introduction: Hey, it's HighScalability time:
     Gorgeous image from Scientific American's  Your Brain by the Numbers    
 Quotable Quotes:                           
 
  @jezhumble : Google does everything off trunk despite 10k devs across 40 offices.  
  @KentLangley : "in 2016. When it goes online, the SKA is expected to produce 700 terabytes of data each day"  
  Jonathan Marks : It's actually a talk about how NOT to be creative. And what he [John Cleese] describes is the way most international broadcasters operated for most of their existence. They were content factories, slave to an artificial transmission schedule. Because they didn't take time to be creative, then ended up sounding like a tape machine. They were run by a computer algorithm. Not a human soul. There was never room for a creative pause. Routine was the solution. And that's creativities biggest enemy. 
 
 
 
  40% better single-threaded performance in MariaDB . Using perf, cache misses were found and the fix was using the righ</p><p>2 0.16501985 <a title="1585-tfidf-2" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>Introduction: "But it is not complicated. [There's] just a lot of it." \--Richard Feynmanon
how the immense variety of the world arises from simple rules.Contents:Have We
Reached the End of Scaling?Applications Become Black Boxes Using Markets to
Scale and Control CostsLet's Welcome our Neo-Feudal OverlordsThe Economic
Argument for the Ambient CloudWhat Will Kill the Cloud?The Amazing Collective
Compute Power of the Ambient CloudUsing the Ambient Cloud as an Application
RuntimeApplications as Virtual StatesConclusionWe have not yet begun to scale.
The world is still fundamentally disconnected and for all our wisdom we are
still in the earliest days of learning how to build truly large planet-scaling
applications.Today 350 million users on Facebook is a lot of users and five
million followers on Twitter is a lot of followers. This may seem like a lot
now, but consider we have no planet wide applications yet. None.Tomorrow the
numbers foreshadow a newCambrian explosionof connectivity that will look as</p><p>3 0.16493799 <a title="1585-tfidf-3" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>Introduction: All in all this is still my favorite post and I still think it's an accurate
vision of a future. Not everyone agrees, but I guess we'll see..."But it is
not complicated. [There's] just a lot of it." \--Richard Feynmanon how the
immense variety of the world arises from simple rules.Contents:Have We Reached
the End of Scaling?Applications Become Black Boxes Using Markets to Scale and
Control CostsLet's Welcome our Neo-Feudal OverlordsThe Economic Argument for
the Ambient CloudWhat Will Kill the Cloud?The Amazing Collective Compute Power
of the Ambient CloudUsing the Ambient Cloud as an Application
RuntimeApplications as Virtual StatesConclusionWe have not yet begun to scale.
The world is still fundamentally disconnected and for all our wisdom we are
still in the earliest days of learning how to build truly large planet-scaling
applications.Today 350 million users on Facebook is a lot of users and five
million followers on Twitter is a lot of followers. This may seem like a lot
now, but c</p><p>4 0.14786649 <a title="1585-tfidf-4" href="../high_scalability-2013/high_scalability-2013-12-13-Stuff_The_Internet_Says_On_Scalability_For_December_13th%2C_2013.html">1564 high scalability-2013-12-13-Stuff The Internet Says On Scalability For December 13th, 2013</a></p>
<p>Introduction: Hey, it's HighScalability time:
   

Test your sense of scale. Is this image of something microscopic or macroscopic?  Find out .

   
  80 billion : Netflix logging events per day;  10 petabytes : Ancestry.com data;  six million : Foursquare checkins per day;  
 Quotable Quotes:                                              
 
  George Lakoff : What can't all your thoughts be conscious? Because consciousness is linear and your brain is parallel. The linear structure of consciousness could never keep up. 
  @peakscale : "Engineers like to solve problems. If there are no problems handily available, they will create their own problems" - Scott Adams 
  @kiwipom :  “Immutability is magic pixie dust that makes distributed systems work” - Adrian Cockcroft  
  @LachM : Netflix: SPEED at SCALE = breaks EVERYTHING. #yow13 
  Joe Landman : … you get really annoyed at the performance of grep on file IO (seriously folks? 32k or page size sized IO? What is this … 1992?) so you rewrite it in 20 minu</p><p>5 0.13410705 <a title="1585-tfidf-5" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>Introduction: We are on the edge of two potent technological changes: Clouds and Memory Based Architectures. This evolution will rip open a chasm where new players can enter and prosper. Google is the master of disk. You can't beat them at a game they perfected. Disk based databases like SimpleDB and BigTable are complicated beasts, typical last gasp products of any aging technology before a change. The next era is the age of Memory and Cloud which will allow for new players to succeed. The tipping point will be soon.   Let's take a short trip down web architecture lane:
  It's 1993: Yahoo runs on FreeBSD, Apache, Perl scripts and a SQL database   It's 1995: Scale-up the database.   It's 1998: LAMP   It's 1999: Stateless + Load Balanced + Database + SAN   It's 2001: In-memory data-grid.   It's 2003: Add a caching layer.   It's 2004: Add scale-out and partitioning.   It's 2005: Add asynchronous job scheduling and maybe a distributed file system.   It's 2007: Move it all into the cloud.   It's 2008: C</p><p>6 0.13224575 <a title="1585-tfidf-6" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>7 0.13038446 <a title="1585-tfidf-7" href="../high_scalability-2012/high_scalability-2012-07-02-C_is_for_Compute_-_Google_Compute_Engine_%28GCE%29.html">1275 high scalability-2012-07-02-C is for Compute - Google Compute Engine (GCE)</a></p>
<p>8 0.13031754 <a title="1585-tfidf-8" href="../high_scalability-2007/high_scalability-2007-11-26-Scale_to_China.html">165 high scalability-2007-11-26-Scale to China</a></p>
<p>9 0.13031711 <a title="1585-tfidf-9" href="../high_scalability-2008/high_scalability-2008-03-12-YouTube_Architecture.html">274 high scalability-2008-03-12-YouTube Architecture</a></p>
<p>10 0.12961709 <a title="1585-tfidf-10" href="../high_scalability-2009/high_scalability-2009-06-26-PlentyOfFish_Architecture.html">638 high scalability-2009-06-26-PlentyOfFish Architecture</a></p>
<p>11 0.12904701 <a title="1585-tfidf-11" href="../high_scalability-2012/high_scalability-2012-11-22-Gone_Fishin%27%3A_PlentyOfFish_Architecture.html">1361 high scalability-2012-11-22-Gone Fishin': PlentyOfFish Architecture</a></p>
<p>12 0.12842523 <a title="1585-tfidf-12" href="../high_scalability-2008/high_scalability-2008-05-02-Friends_for_Sale_Architecture_-_A_300_Million_Page_View-Month_Facebook_RoR_App.html">313 high scalability-2008-05-02-Friends for Sale Architecture - A 300 Million Page View-Month Facebook RoR App</a></p>
<p>13 0.12828796 <a title="1585-tfidf-13" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>14 0.12792356 <a title="1585-tfidf-14" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>15 0.12618329 <a title="1585-tfidf-15" href="../high_scalability-2010/high_scalability-2010-05-03-MocoSpace_Architecture_-_3_Billion_Mobile_Page_Views_a_Month.html">821 high scalability-2010-05-03-MocoSpace Architecture - 3 Billion Mobile Page Views a Month</a></p>
<p>16 0.12566379 <a title="1585-tfidf-16" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>17 0.12562835 <a title="1585-tfidf-17" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>18 0.1253458 <a title="1585-tfidf-18" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>19 0.12465726 <a title="1585-tfidf-19" href="../high_scalability-2012/high_scalability-2012-06-26-Sponsored_Post%3A_New_Relic%2C_Digital_Ocean%2C_NetDNA%2C_Torbit%2C_Reality_Check_Network%2C_Gigaspaces%2C_AiCache%2C_Logic_Monitor%2C_AppDynamics%2C_CloudSigma%2C_ManageEnine%2C_Site24x7.html">1272 high scalability-2012-06-26-Sponsored Post: New Relic, Digital Ocean, NetDNA, Torbit, Reality Check Network, Gigaspaces, AiCache, Logic Monitor, AppDynamics, CloudSigma, ManageEnine, Site24x7</a></p>
<p>20 0.12403383 <a title="1585-tfidf-20" href="../high_scalability-2008/high_scalability-2008-03-27-Amazon_Announces_Static_IP_Addresses_and_Multiple_Datacenter_Operation.html">289 high scalability-2008-03-27-Amazon Announces Static IP Addresses and Multiple Datacenter Operation</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.282), (1, 0.123), (2, -0.004), (3, -0.01), (4, -0.058), (5, -0.017), (6, 0.001), (7, 0.012), (8, 0.055), (9, 0.006), (10, -0.008), (11, -0.104), (12, 0.049), (13, 0.0), (14, -0.038), (15, 0.041), (16, -0.033), (17, -0.044), (18, -0.024), (19, 0.002), (20, -0.011), (21, 0.0), (22, 0.021), (23, 0.021), (24, -0.018), (25, -0.006), (26, -0.066), (27, 0.033), (28, -0.012), (29, 0.004), (30, -0.014), (31, 0.011), (32, 0.014), (33, -0.012), (34, 0.005), (35, 0.033), (36, 0.019), (37, 0.031), (38, -0.005), (39, -0.003), (40, -0.04), (41, -0.018), (42, -0.002), (43, 0.012), (44, 0.028), (45, 0.045), (46, 0.013), (47, 0.028), (48, -0.009), (49, -0.029)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96535897 <a title="1585-lsi-1" href="../high_scalability-2014/high_scalability-2014-01-24-Stuff_The_Internet_Says_On_Scalability_For_January_24th%2C_2014.html">1585 high scalability-2014-01-24-Stuff The Internet Says On Scalability For January 24th, 2014</a></p>
<p>Introduction: Hey, it's HighScalability time:
     Gorgeous image from Scientific American's  Your Brain by the Numbers    
 Quotable Quotes:                           
 
  @jezhumble : Google does everything off trunk despite 10k devs across 40 offices.  
  @KentLangley : "in 2016. When it goes online, the SKA is expected to produce 700 terabytes of data each day"  
  Jonathan Marks : It's actually a talk about how NOT to be creative. And what he [John Cleese] describes is the way most international broadcasters operated for most of their existence. They were content factories, slave to an artificial transmission schedule. Because they didn't take time to be creative, then ended up sounding like a tape machine. They were run by a computer algorithm. Not a human soul. There was never room for a creative pause. Routine was the solution. And that's creativities biggest enemy. 
 
 
 
  40% better single-threaded performance in MariaDB . Using perf, cache misses were found and the fix was using the righ</p><p>2 0.86363047 <a title="1585-lsi-2" href="../high_scalability-2012/high_scalability-2012-07-06-Stuff_The_Internet_Says_On_Scalability_For_July_6%2C_2012.html">1278 high scalability-2012-07-06-Stuff The Internet Says On Scalability For July 6, 2012</a></p>
<p>Introduction: It's HighScalability Time ( with 33% more goodness  for the same NoPrice):
  
 2.5 terabits per second :  Infinite-capacity wireless vortex beams ; One Trillion Tons :  Carbon Pollution ; 1 Megawatt:  more power due to leap second ; 100,000 terabytes:  information storage capability of one gram of human stool ; 2.8B social interactions per day :  Zynga ;  2 trillion requests a day :  Akamai   
  Hugh E. Williams on eBay by the numbers : 10 petabytes of data, 300 million items for sale, 250 million user queries per day, 100 million active users,  2 billion pages served per day, $68 billion in merchandise sold in 2011, 75 billion database calls each day. 
  @adrianco : At best you are only a few one-line code changes away from an outage. Experiences find those bugs, then there is a big dose of random luck. 
 With strangely little reaction to  Amazon's post-mortem  it was nice to see Dmitriy Samovskiy's take in  Applying 5 Whys to Amazon EC2 Outage : AWS effectively lost its control plane</p><p>3 0.83179247 <a title="1585-lsi-3" href="../high_scalability-2012/high_scalability-2012-09-07-Stuff_The_Internet_Says_On_Scalability_For_September_7%2C_2012.html">1318 high scalability-2012-09-07-Stuff The Internet Says On Scalability For September 7, 2012</a></p>
<p>Introduction: It's HighScalability Time:
  
 Quotable Quotes:                    
 
  Where did all the supercomputers go?  Inside Intel. 
  @Jacattell : I love the smell of high scalability in the morning :-) 
  @nkohari : Post on HN about GitHub scalability. Top comment? “…someone wasted valuable time making the dashboard look so pretty”  
 
 
  Evolution of SoundCloud’s Architecture : The way we develop SoundCloud is to identify the points of scale then isolate and optimize the read and write paths individually, in anticipation of the next magnitude of growth. 
  How We Build Our 60-Node (Almost Distributed Web Crawler .  Semantics3 crawls 1-3 million pages a day at a cost of ~$3 a day (excluding storage costs) using micro-instances, Grearman, redis, perl, chef, and capistrano. 
 Werner Vogels continues his 50 Shades of Programming book club with  Back-to-Basics Weekend Reading - Granularity of locks . Highlight is a touching remembrance of Jim Gray. 
 Speaking of locks and stories, the MySQL Per</p><p>4 0.83100581 <a title="1585-lsi-4" href="../high_scalability-2013/high_scalability-2013-12-13-Stuff_The_Internet_Says_On_Scalability_For_December_13th%2C_2013.html">1564 high scalability-2013-12-13-Stuff The Internet Says On Scalability For December 13th, 2013</a></p>
<p>Introduction: Hey, it's HighScalability time:
   

Test your sense of scale. Is this image of something microscopic or macroscopic?  Find out .

   
  80 billion : Netflix logging events per day;  10 petabytes : Ancestry.com data;  six million : Foursquare checkins per day;  
 Quotable Quotes:                                              
 
  George Lakoff : What can't all your thoughts be conscious? Because consciousness is linear and your brain is parallel. The linear structure of consciousness could never keep up. 
  @peakscale : "Engineers like to solve problems. If there are no problems handily available, they will create their own problems" - Scott Adams 
  @kiwipom :  “Immutability is magic pixie dust that makes distributed systems work” - Adrian Cockcroft  
  @LachM : Netflix: SPEED at SCALE = breaks EVERYTHING. #yow13 
  Joe Landman : … you get really annoyed at the performance of grep on file IO (seriously folks? 32k or page size sized IO? What is this … 1992?) so you rewrite it in 20 minu</p><p>5 0.83099449 <a title="1585-lsi-5" href="../high_scalability-2013/high_scalability-2013-06-07-Stuff_The_Internet_Says_On_Scalability_For_June_7%2C_2013.html">1472 high scalability-2013-06-07-Stuff The Internet Says On Scalability For June 7, 2013</a></p>
<p>Introduction: Hey, it's HighScalability time:
    ( Ever feel like everyone has already climbed your Everest?)    
 Trillion Particles, 120,000 cores, and 350 TBs:  Lessons Learned From a Hero I/O Run on Hopper  
 Quotable Quotes:                                   
 
  @PenLlawen : @spolsky In my time as a scalability engineer, I’ve seen plenty of cases where optimisation was left too late. Even harder to fix. 
  @davidlubar : Whoever said you can't fold a piece of paper in half more than 7 times probably forget to unfold it each time. I'm up to 6,000. 
  deno :  A quick comparison of App Engine vs. Compute Engine prices shows that App Engine is at best 10x more expensive per unit of RAM. 
  Fred Wilson : strategy is figuring out what part of the market the company wants to play in, how it goes to market, and how it differentiates itself in the market it is about what you are going to do and importantly what you are not going to do 
  Elon Musk : SpaceX was able to achieve orders of magnitude saving</p><p>6 0.82826233 <a title="1585-lsi-6" href="../high_scalability-2014/high_scalability-2014-01-10-Stuff_The_Internet_Says_On_Scalability_For_January_10th%2C_2014.html">1576 high scalability-2014-01-10-Stuff The Internet Says On Scalability For January 10th, 2014</a></p>
<p>7 0.82707888 <a title="1585-lsi-7" href="../high_scalability-2012/high_scalability-2012-03-23-Stuff_The_Internet_Says_On_Scalability_For_March_23%2C_2012.html">1214 high scalability-2012-03-23-Stuff The Internet Says On Scalability For March 23, 2012</a></p>
<p>8 0.82466984 <a title="1585-lsi-8" href="../high_scalability-2013/high_scalability-2013-07-19-Stuff_The_Internet_Says_On_Scalability_For_July_19%2C_2013.html">1494 high scalability-2013-07-19-Stuff The Internet Says On Scalability For July 19, 2013</a></p>
<p>9 0.82401484 <a title="1585-lsi-9" href="../high_scalability-2012/high_scalability-2012-02-10-Stuff_The_Internet_Says_On_Scalability_For_February_10%2C_2012.html">1190 high scalability-2012-02-10-Stuff The Internet Says On Scalability For February 10, 2012</a></p>
<p>10 0.82157981 <a title="1585-lsi-10" href="../high_scalability-2014/high_scalability-2014-05-16-Stuff_The_Internet_Says_On_Scalability_For_May_16th%2C_2014.html">1649 high scalability-2014-05-16-Stuff The Internet Says On Scalability For May 16th, 2014</a></p>
<p>11 0.82127559 <a title="1585-lsi-11" href="../high_scalability-2013/high_scalability-2013-11-22-Stuff_The_Internet_Says_On_Scalability_For_November_22th%2C_2013.html">1552 high scalability-2013-11-22-Stuff The Internet Says On Scalability For November 22th, 2013</a></p>
<p>12 0.82059538 <a title="1585-lsi-12" href="../high_scalability-2011/high_scalability-2011-09-23-Stuff_The_Internet_Says_On_Scalability_For_September_23%2C_2011.html">1122 high scalability-2011-09-23-Stuff The Internet Says On Scalability For September 23, 2011</a></p>
<p>13 0.81482846 <a title="1585-lsi-13" href="../high_scalability-2012/high_scalability-2012-12-28-Stuff_The_Internet_Says_On_Scalability_For_December_28%2C_2012.html">1378 high scalability-2012-12-28-Stuff The Internet Says On Scalability For December 28, 2012</a></p>
<p>14 0.81337106 <a title="1585-lsi-14" href="../high_scalability-2013/high_scalability-2013-09-13-Stuff_The_Internet_Says_On_Scalability_For_September_13%2C_2013.html">1516 high scalability-2013-09-13-Stuff The Internet Says On Scalability For September 13, 2013</a></p>
<p>15 0.81291461 <a title="1585-lsi-15" href="../high_scalability-2012/high_scalability-2012-10-04-Stuff_The_Internet_Says_On_Scalability_For_October_5%2C_2012.html">1334 high scalability-2012-10-04-Stuff The Internet Says On Scalability For October 5, 2012</a></p>
<p>16 0.81028867 <a title="1585-lsi-16" href="../high_scalability-2013/high_scalability-2013-06-28-Stuff_The_Internet_Says_On_Scalability_For_June_28%2C_2013.html">1484 high scalability-2013-06-28-Stuff The Internet Says On Scalability For June 28, 2013</a></p>
<p>17 0.80901039 <a title="1585-lsi-17" href="../high_scalability-2014/high_scalability-2014-02-21-Stuff_The_Internet_Says_On_Scalability_For_February_21st%2C_2014.html">1600 high scalability-2014-02-21-Stuff The Internet Says On Scalability For February 21st, 2014</a></p>
<p>18 0.80630827 <a title="1585-lsi-18" href="../high_scalability-2014/high_scalability-2014-02-14-Stuff_The_Internet_Says_On_Scalability_For_February_14th%2C_2014.html">1596 high scalability-2014-02-14-Stuff The Internet Says On Scalability For February 14th, 2014</a></p>
<p>19 0.80392104 <a title="1585-lsi-19" href="../high_scalability-2014/high_scalability-2014-04-25-Stuff_The_Internet_Says_On_Scalability_For_April_25th%2C_2014.html">1637 high scalability-2014-04-25-Stuff The Internet Says On Scalability For April 25th, 2014</a></p>
<p>20 0.80261672 <a title="1585-lsi-20" href="../high_scalability-2013/high_scalability-2013-08-09-Stuff_The_Internet_Says_On_Scalability_For_August_9%2C_2013.html">1499 high scalability-2013-08-09-Stuff The Internet Says On Scalability For August 9, 2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.099), (2, 0.179), (10, 0.369), (30, 0.023), (61, 0.075), (79, 0.085), (85, 0.012), (94, 0.057)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97842664 <a title="1585-lda-1" href="../high_scalability-2011/high_scalability-2011-06-22-It%27s_the_Fraking_IOPS_-_1_SSD_is_44%2C000_IOPS%2C_Hard_Drive_is_180.html">1066 high scalability-2011-06-22-It's the Fraking IOPS - 1 SSD is 44,000 IOPS, Hard Drive is 180</a></p>
<p>Introduction: Planning your next buildout and thinking SSDs are still far in the future? Still too expensive, too low density. Hard disks are cheap, familiar, and store lots of stuff. In this short and entertaining video Wikia's  Artur Bergman  wants to change your mind about SSDs. SSDs are for today, get with the math already.
 
Here's Artur's logic:
  
 Wikia is all SSD in production. The new Wikia file servers have a theoretical read rate of ~10GB/sec sequential, 6GB/sec random and 1.2 million IOPs. If you can't do math or love the past, you love spinning rust. If you are awesome you love SSDs. 
 SSDs are cheaper than drives using the most relevant metric: $/GB/IOPS. 1 SSD is 44,000 IOPS and one hard drive is 180 IOPS. Need 1 SSD instead of 50 hard drives. 
 With 8 million files there's a 9 minute fsck. Full backup in 12 minutes (X-25M based). 
 4 GB/sec random read average latency 1 msec. 
 2.2 GB/sec random write average latency 1 msec. 
 50TBs of SSDs in one machine for $80,000. With the densi</p><p>2 0.97622794 <a title="1585-lda-2" href="../high_scalability-2013/high_scalability-2013-06-24-Update_on_How_29_Cloud_Price_Drops_Changed_the_Bottom_Line_of_TripAdvisor_and_Pinterest_-_Results_Mixed.html">1480 high scalability-2013-06-24-Update on How 29 Cloud Price Drops Changed the Bottom Line of TripAdvisor and Pinterest - Results Mixed</a></p>
<p>Introduction: This is a guest post by  Ali Khajeh-Hosseini , Technical Lead at  PlanForCloud . The original article was published  on their site . With 29 cloud price reductions I thought it would be interesting to see how the bottom line would change compared to an article  we published last year . The result is surprisingly little for TripAdvisor because prices for On Demand instances have  not dropped as fast  as for other other instances types. 
 
Over the last year and a half,  we counted 29 price reductions  in cloud services provided by AWS, Google Compute Engine, Windows Azure, and Rackspace Cloud. Price reductions have a direct effect on cloud users, but given the usual tiny reductions, how significant is that effect on the bottom line?
 
Last year I wrote about  cloud cost forecasts for TripAdvisor and Pinterest .  TripAdvisor was experimenting with AWS  and attempted to process 700K HTTP requests per minute on a replica of its live site, and  Pinterest was growing massively on AWS . In th</p><p>3 0.97294152 <a title="1585-lda-3" href="../high_scalability-2008/high_scalability-2008-10-26-Should_you_use_a_SAN_to_scale_your_architecture%3F_.html">430 high scalability-2008-10-26-Should you use a SAN to scale your architecture? </a></p>
<p>Introduction: This is a question everyone must struggle with when building out their datacenter. Storage choices are always the ones I have the least confidence in.  David Marks in his blog  You Can Change It Later!  asks the question   Should I get a SAN to scale my site architecture?   and answers no. A better solution is to use commodity hardware, directly attach storage on servers, and partition across servers to scale and for greater availability.  David's reasoning is interesting:
  A SAN creates a SPOF (single point of failure) that is dependent on a vendor to fly and fix when there's a problem. This can lead to long down times during this outage you have no access to your data at all.   Using easily available commodity hardware minimizes risks to your company, it's not just about saving money. Zooming over to Fry's to buy emergency equipment provides the kind of agility startups need in order to respond quickly to ever changing situations.  It's hard to beat the power and flexibility (backup</p><p>4 0.96704721 <a title="1585-lda-4" href="../high_scalability-2012/high_scalability-2012-08-06-Paper%3A_High-Performance_Concurrency_Control_Mechanisms_for_Main-Memory_Databases.html">1299 high scalability-2012-08-06-Paper: High-Performance Concurrency Control Mechanisms for Main-Memory Databases</a></p>
<p>Introduction: If you stayed up all night watching the life reaffirming  Curiosity landing on Mars , then this paper,  High-Performance Concurrency Control Mechanisms for Main-Memory Databases , has nothing to do with that at all, but it is an excellent look at how to use optimistic MVCC schemes to reduce lock overhead on in-memory datastructures:
  A database system optimized for in-memory storage can support  much higher transaction rates than current systems.  However,  standard concurrency control methods used today do not scale to  the high transaction rates achievable by such systems. In this paper we introduce two efficient concurrency control methods specifically designed for main-memory databases. Both use multiversioning to isolate read-only transactions from updates but differ in  how atomicity is ensured: one is optimistic and one is pessimistic. To avoid expensive context switching, transactions  never block  during normal processing but they may have to wait before commit to ensure corr</p><p>5 0.96276522 <a title="1585-lda-5" href="../high_scalability-2014/high_scalability-2014-04-21-This_is_why_Microsoft_won._And_why_they_lost..html">1635 high scalability-2014-04-21-This is why Microsoft won. And why they lost.</a></p>
<p>Introduction: My favorite kind of histories are those told from an insider's perspective. The story of Richard the Lionheart is full of great battles and dynastic intrigue. The story of one of his soldiers, not so much. Yet the soldiers' story, as someone who has experienced the real consequences of decisions made and actions taken, is more revealing.
 
We get such a history in  Chat Wars , a wonderful article written by David Auerbach, who in 1998 worked at Microsoft on MSN Messenger Service, Microsoft’s instant messaging app (for a related story see  The Rise and Fall of AIM, the Breakthrough AOL Never Wanted ).
 
It's as if Herodotus visited Microsoft and wrote down his experiences. It has that same sort of conversational tone, insightful on-the-ground observations, and facts no outsider might ever believe.
 
Much of the article is a play-by-play account of the cat and mouse game David plays changing Messenger to track AOL's Instant Messenger protocol changes. AOL repeatedly tried to make it so M</p><p>6 0.94975734 <a title="1585-lda-6" href="../high_scalability-2010/high_scalability-2010-08-07-ArchCamp%3A_Scalable_Databases_%28NoSQL%29.html">874 high scalability-2010-08-07-ArchCamp: Scalable Databases (NoSQL)</a></p>
<p>7 0.94636995 <a title="1585-lda-7" href="../high_scalability-2010/high_scalability-2010-01-27-Hot_Scalability_Links_for_January_28_2010.html">767 high scalability-2010-01-27-Hot Scalability Links for January 28 2010</a></p>
<p>8 0.93889195 <a title="1585-lda-8" href="../high_scalability-2011/high_scalability-2011-05-23-Evernote_Architecture_-_9_Million_Users_and_150_Million_Requests_a_Day.html">1046 high scalability-2011-05-23-Evernote Architecture - 9 Million Users and 150 Million Requests a Day</a></p>
<p>9 0.93449509 <a title="1585-lda-9" href="../high_scalability-2007/high_scalability-2007-12-10-1_Master%2C_N_Slaves.html">178 high scalability-2007-12-10-1 Master, N Slaves</a></p>
<p>10 0.92153484 <a title="1585-lda-10" href="../high_scalability-2010/high_scalability-2010-03-10-How_FarmVille_Scales_-_The_Follow-up.html">792 high scalability-2010-03-10-How FarmVille Scales - The Follow-up</a></p>
<p>11 0.91733623 <a title="1585-lda-11" href="../high_scalability-2009/high_scalability-2009-04-27-Some_Questions_from_a_newbie.html">584 high scalability-2009-04-27-Some Questions from a newbie</a></p>
<p>12 0.91702169 <a title="1585-lda-12" href="../high_scalability-2014/high_scalability-2014-04-14-How_do_you_even_do_anything_without_using_EBS%3F.html">1631 high scalability-2014-04-14-How do you even do anything without using EBS?</a></p>
<p>same-blog 13 0.91577429 <a title="1585-lda-13" href="../high_scalability-2014/high_scalability-2014-01-24-Stuff_The_Internet_Says_On_Scalability_For_January_24th%2C_2014.html">1585 high scalability-2014-01-24-Stuff The Internet Says On Scalability For January 24th, 2014</a></p>
<p>14 0.91100812 <a title="1585-lda-14" href="../high_scalability-2009/high_scalability-2009-08-28-Strategy%3A_Solve_Only_80_Percent_of_the_Problem.html">689 high scalability-2009-08-28-Strategy: Solve Only 80 Percent of the Problem</a></p>
<p>15 0.90569067 <a title="1585-lda-15" href="../high_scalability-2007/high_scalability-2007-12-02-a8cjdbc_-_update_verision_1.3.html">171 high scalability-2007-12-02-a8cjdbc - update verision 1.3</a></p>
<p>16 0.9056735 <a title="1585-lda-16" href="../high_scalability-2007/high_scalability-2007-12-02-Database-Clustering%3A_a8cjdbc_-_update%3A_version_1.3.html">170 high scalability-2007-12-02-Database-Clustering: a8cjdbc - update: version 1.3</a></p>
<p>17 0.87786102 <a title="1585-lda-17" href="../high_scalability-2007/high_scalability-2007-11-05-Strategy%3A_Diagonal_Scaling_-_Don%27t_Forget_to_Scale_Out_AND_Up.html">142 high scalability-2007-11-05-Strategy: Diagonal Scaling - Don't Forget to Scale Out AND Up</a></p>
<p>18 0.85636878 <a title="1585-lda-18" href="../high_scalability-2012/high_scalability-2012-11-01-Cost_Analysis%3A_TripAdvisor_and_Pinterest_costs_on_the_AWS_cloud.html">1353 high scalability-2012-11-01-Cost Analysis: TripAdvisor and Pinterest costs on the AWS cloud</a></p>
<p>19 0.85473549 <a title="1585-lda-19" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>20 0.85077769 <a title="1585-lda-20" href="../high_scalability-2008/high_scalability-2008-02-22-Kevin%27s_Great_Adventures_in_SSDland.html">257 high scalability-2008-02-22-Kevin's Great Adventures in SSDland</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
