<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1604 high scalability-2014-03-03-The “Four Hamiltons” Framework for Mitigating Faults in the Cloud: Avoid it, Mask it, Bound it, Fix it Fast</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2014" href="../home/high_scalability-2014_home.html">high_scalability-2014</a> <a title="high_scalability-2014-1604" href="#">high_scalability-2014-1604</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1604 high scalability-2014-03-03-The “Four Hamiltons” Framework for Mitigating Faults in the Cloud: Avoid it, Mask it, Bound it, Fix it Fast</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2014-1604-html" href="http://highscalability.com//blog/2014/3/3/the-four-hamiltons-framework-for-mitigating-faults-in-the-cl.html">html</a></p><p>Introduction: This is a guest post by  Patrick Eaton , Software Engineer and Distributed Systems Architect at Stackdriver. 
 
Stackdriver provides intelligent monitoring-as-a-service for cloud hosted applications.  Behind this easy-to-use service is a large distributed system for collecting and storing metrics and events, monitoring and alerting on them, analyzing them, and serving up all the results in a web UI.  Because we ourselves run in the cloud (mostly on AWS), we spend a lot of time thinking about how to deal with faults in the cloud.  We have developed a framework for thinking about fault mitigation for large, cloud-hosted systems.  We endearingly call this framework the “Four Hamiltons” because it is inspired by an article from James Hamilton, the Vice President and Distinguished Engineer at Amazon Web Services.
   The article that led to this framework is called “   The Power Failure Seen Around the World   ”  .  Hamilton analyzes the causes of the power outage that affected Super Bowl XL</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 )     Combining the fault domains and the techniques for addressing faults in those domains, we can produce a grid, as shown below, to guide us as we consider how to survive faults in cloud-hosted applications. [sent-18, score-0.835]
</p><p>2 An application builder cannot generally avoid faults in the bigger fault domains (regions and zones) because they have no control over those domains. [sent-34, score-0.842]
</p><p>3 Some cloud providers offer hosted services that claim to protect against zone or region outages. [sent-36, score-0.738]
</p><p>4 It offers a multi-AZ (zone) deployment option that includes a synchronous replica with automatic failover that can mask zone failures, making it appear to be a reliable database to the application builder. [sent-40, score-0.65]
</p><p>5 Documentation suggests that it stores copies of all messages across data centers (in a single region), and so, from the perspective of the system builder, it is reliable in the presence of instance and zone failures. [sent-42, score-0.719]
</p><p>6 As for the largest fault domain, AWS’s Route 53 hosted DNS service supports failover between regions to provide the appearance of reliable name resolution, even in the presence of region failures. [sent-43, score-0.838]
</p><p>7 To avoid errors at the zone and region level, we make heavy use of hosted services that provide reliable service despite component failures in the hosted service. [sent-52, score-1.38]
</p><p>8 For relational databases, we use AWS RDS with multi-zone replication to avoid instance and zone failures. [sent-53, score-0.712]
</p><p>9 For reliable load balancing, we use AWS ELB to protect against instance and zone failures. [sent-54, score-0.652]
</p><p>10 Finally, for much of our low-volume messaging, we use AWS SQS as a reliable queueing service that is not affected by instance of zone failures. [sent-55, score-0.726]
</p><p>11 Mask It    If you cannot avoid a fault, the next best alternative is to mask the fault with redundancy. [sent-56, score-0.65]
</p><p>12 Similarly, handling the failure of a region requires that all services be distributed across more than one region and that capacity is sufficient to handle the load when one region is unavailable. [sent-66, score-0.726]
</p><p>13 For masking both instance and zone failures, some services use multiple workers consuming messages from a single AWS SQS queue. [sent-68, score-0.766]
</p><p>14 Other services mask instance and zone failures by deploying multiple workers behind a AWS Elastic Load Balancer (ELB). [sent-71, score-1.06]
</p><p>15 When an instance hosting a worker fails or becomes unavailable due to a zone failure, the load balancer removes the worker and continues distributing load among the remaining workers. [sent-72, score-0.91]
</p><p>16 The aggregation function can fall behind due to reduced capacity because of instance or zone failure. [sent-107, score-0.697]
</p><p>17 To handle zone and region failures, replicas must, obviously, be located in outside the impacted fault domain. [sent-144, score-0.968]
</p><p>18 Evaluate your system by iterating through the system components and compare your fault mitigation strategy against the Four Hamiltons. [sent-169, score-0.714]
</p><p>19 James Hamilton gives us a list of fault mitigation strategies: 1) avoid the fault (avoid it! [sent-178, score-0.974]
</p><p>20 ) 3) minimize the fault impact with small fault zones (bound it! [sent-180, score-0.892]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('zone', 0.365), ('fault', 0.305), ('faults', 0.226), ('mitigation', 0.205), ('failures', 0.189), ('instance', 0.188), ('mask', 0.186), ('region', 0.179), ('avoid', 0.159), ('recovery', 0.138), ('zones', 0.124), ('hosted', 0.121), ('failure', 0.116), ('incident', 0.105), ('reliable', 0.099), ('impact', 0.097), ('provision', 0.096), ('delayed', 0.089), ('aws', 0.088), ('due', 0.085), ('pipeline', 0.081), ('masking', 0.081), ('hamilton', 0.078), ('domains', 0.078), ('customers', 0.077), ('builder', 0.074), ('service', 0.074), ('services', 0.073), ('sqs', 0.073), ('fails', 0.072), ('strategy', 0.07), ('worker', 0.069), ('cassandra', 0.068), ('system', 0.067), ('rollbar', 0.063), ('unavailable', 0.062), ('prioritize', 0.062), ('minimize', 0.061), ('outage', 0.061), ('regions', 0.06), ('impacted', 0.06), ('multiple', 0.059), ('aggregation', 0.059), ('replicas', 0.059), ('alerting', 0.058), ('mitigate', 0.058), ('elb', 0.058), ('fix', 0.058), ('failed', 0.057), ('probes', 0.057)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="1604-tfidf-1" href="../high_scalability-2014/high_scalability-2014-03-03-The_%E2%80%9CFour_Hamiltons%E2%80%9D_Framework_for_Mitigating_Faults_in_the_Cloud%3A_Avoid_it%2C_Mask_it%2C_Bound_it%2C_Fix_it_Fast.html">1604 high scalability-2014-03-03-The “Four Hamiltons” Framework for Mitigating Faults in the Cloud: Avoid it, Mask it, Bound it, Fix it Fast</a></p>
<p>Introduction: This is a guest post by  Patrick Eaton , Software Engineer and Distributed Systems Architect at Stackdriver. 
 
Stackdriver provides intelligent monitoring-as-a-service for cloud hosted applications.  Behind this easy-to-use service is a large distributed system for collecting and storing metrics and events, monitoring and alerting on them, analyzing them, and serving up all the results in a web UI.  Because we ourselves run in the cloud (mostly on AWS), we spend a lot of time thinking about how to deal with faults in the cloud.  We have developed a framework for thinking about fault mitigation for large, cloud-hosted systems.  We endearingly call this framework the “Four Hamiltons” because it is inspired by an article from James Hamilton, the Vice President and Distinguished Engineer at Amazon Web Services.
   The article that led to this framework is called “   The Power Failure Seen Around the World   ”  .  Hamilton analyzes the causes of the power outage that affected Super Bowl XL</p><p>2 0.23499638 <a title="1604-tfidf-2" href="../high_scalability-2011/high_scalability-2011-12-28-Strategy%3A_Guaranteed_Availability_Requires_Reserving_Instances_in_Specific_Zones.html">1165 high scalability-2011-12-28-Strategy: Guaranteed Availability Requires Reserving Instances in Specific Zones</a></p>
<p>Introduction: When EC2 first started the mental model was of a magic Pez dispenser supplying an infinite stream of instances in any desired flavor. If you needed an instance, because of a either a failure or traffic spike, it would be there. As amazing as EC2 is, this model turned out to be optimistic.  
 
From a  thread on the Amazon discussion forum  we learn any dispenser has limits:
  

As Availability Zones grow over time, our ability to continue to expand them can become constrained. In these scenarios, we will prevent customers from launching in the constrained zone if they do not yet have existing resources in that zone. We also might remove the constrained zone entirely from the list of options for new customers. This means that occasionally, different customers will see a different number of Availability Zones in a particular Region. Both approaches aim to help customers avoid accidentally starting to build up their infrastructure in an Availability Zone where they might have less ability</p><p>3 0.16428469 <a title="1604-tfidf-3" href="../high_scalability-2011/high_scalability-2011-08-15-Should_any_cloud_be_considered_one_availability_zone%3F_The_Amazon_experience_says_yes..html">1098 high scalability-2011-08-15-Should any cloud be considered one availability zone? The Amazon experience says yes.</a></p>
<p>Introduction: Amazon has a very will written account of their 8/8/2011 downtime:  Summary of the Amazon EC2, Amazon EBS, and Amazon RDS Service Event in the EU West Region . Power failed, backup generators failed to kick in, there weren't enough resources for EBS volumes to recover, API servers where overwhelmed, a DNS failure caused failovers to alternate availability zones to fail, a double fault occurred as the power event interrupted the repair of a different bug. All kind of typical stuff that just seems to happen.
 
Considering the  previous outage , the big question for programmers is: what does this mean? What does it mean for how systems should be structured? Have we learned something that can't be unlearned?
 
The Amazon post has lots of good insights into how EBS and RDS work, plus lessons learned. The short of the problem is large + complex = high probability of failure. The immediate fixes are adding more resources, more redundancy, more isolation between components, more automation, re</p><p>4 0.16114816 <a title="1604-tfidf-4" href="../high_scalability-2008/high_scalability-2008-03-27-Amazon_Announces_Static_IP_Addresses_and_Multiple_Datacenter_Operation.html">289 high scalability-2008-03-27-Amazon Announces Static IP Addresses and Multiple Datacenter Operation</a></p>
<p>Introduction: Amazon is fixing two of their major problems: no static IP addresses and single datacenter operation. By adding these two new features developers can finally build a no apology system on Amazon. Before you always had to throw in an apology or two. No, we don't have low failover times because of the silly DNS games and unexceptionable DNS update and propagation times and no, we don't operate in more than one datacenter. No more. Now Amazon is adding   Elastic IP Addresses   and   Availability Zones  .     Elastic IP addresses are far better than normal IP addresses because they are both in tight with   Jessica Alba   and they are:        Static IP addresses designed for dynamic cloud computing. An Elastic IP address is associated with your account, not a particular instance, and you control that address until you choose to explicitly release it. Unlike traditional static IP addresses, however, Elastic IP addresses allow you to mask instance or availability zone failures by programmatica</p><p>5 0.16098161 <a title="1604-tfidf-5" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>Introduction: This is a guest post by  Frédéric Faure   (architect at  Ysance )  on the differences between using a cloud infrastructure and building your own. Frédéric was kind enough to translate the original French version of this article into English. 
 
I’ve been noticing many questions about the differences inherent in choosing between a Cloud infrastructure such as  AWS  (Amazon Web Services) and a traditional physical infrastructure. Firstly, there are a certain number of preconceived notions on this subject that I will attempt to decode for you. Then, it must be understood that each infrastructure has its advantages and disadvantages: a Cloud-type infrastructure does not necessarily fulfill your requirements in every case, however, it can satisfy some of them by optimizing or facilitating the features offered by a traditional physical infrastructure. I will therefore demonstrate the differences between the two that I have noticed, in order to help you make up your own mind.
 
 
 
  The Fram</p><p>6 0.15658776 <a title="1604-tfidf-6" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>7 0.15581825 <a title="1604-tfidf-7" href="../high_scalability-2011/high_scalability-2011-10-27-Strategy%3A_Survive_a_Comet_Strike_in_the_East_With_Reserved_Instances_in_the_West.html">1133 high scalability-2011-10-27-Strategy: Survive a Comet Strike in the East With Reserved Instances in the West</a></p>
<p>8 0.15317462 <a title="1604-tfidf-8" href="../high_scalability-2011/high_scalability-2011-04-25-The_Big_List_of_Articles_on_the_Amazon_Outage.html">1029 high scalability-2011-04-25-The Big List of Articles on the Amazon Outage</a></p>
<p>9 0.14929067 <a title="1604-tfidf-9" href="../high_scalability-2012/high_scalability-2012-10-08-How_UltraDNS_Handles_Hundreds_of_Thousands_of_Zones_and_Tens_of_Millions_of_Records.html">1335 high scalability-2012-10-08-How UltraDNS Handles Hundreds of Thousands of Zones and Tens of Millions of Records</a></p>
<p>10 0.14849588 <a title="1604-tfidf-10" href="../high_scalability-2012/high_scalability-2012-07-06-Stuff_The_Internet_Says_On_Scalability_For_July_6%2C_2012.html">1278 high scalability-2012-07-06-Stuff The Internet Says On Scalability For July 6, 2012</a></p>
<p>11 0.14789931 <a title="1604-tfidf-11" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>12 0.14420253 <a title="1604-tfidf-12" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>13 0.14306149 <a title="1604-tfidf-13" href="../high_scalability-2012/high_scalability-2012-10-25-Not_All_Regions_are_Created_Equal_-_South_America_Es_Bueno.html">1347 high scalability-2012-10-25-Not All Regions are Created Equal - South America Es Bueno</a></p>
<p>14 0.1399439 <a title="1604-tfidf-14" href="../high_scalability-2007/high_scalability-2007-07-30-Build_an_Infinitely_Scalable_Infrastructure_for_%24100_Using_Amazon_Services.html">38 high scalability-2007-07-30-Build an Infinitely Scalable Infrastructure for $100 Using Amazon Services</a></p>
<p>15 0.1390063 <a title="1604-tfidf-15" href="../high_scalability-2010/high_scalability-2010-08-16-Scaling_an_AWS_infrastructure_-_Tools_and_Patterns.html">881 high scalability-2010-08-16-Scaling an AWS infrastructure - Tools and Patterns</a></p>
<p>16 0.13718058 <a title="1604-tfidf-16" href="../high_scalability-2011/high_scalability-2011-06-13-Automation_on_AWS_with_Ruby_and_Puppet.html">1058 high scalability-2011-06-13-Automation on AWS with Ruby and Puppet</a></p>
<p>17 0.13608019 <a title="1604-tfidf-17" href="../high_scalability-2009/high_scalability-2009-08-07-The_Canonical_Cloud_Architecture_.html">674 high scalability-2009-08-07-The Canonical Cloud Architecture </a></p>
<p>18 0.13564606 <a title="1604-tfidf-18" href="../high_scalability-2014/high_scalability-2014-02-05-Little%E2%80%99s_Law%2C_Scalability_and_Fault_Tolerance%3A_The_OS_is_your_bottleneck._What_you_can_do%3F.html">1591 high scalability-2014-02-05-Little’s Law, Scalability and Fault Tolerance: The OS is your bottleneck. What you can do?</a></p>
<p>19 0.13449861 <a title="1604-tfidf-19" href="../high_scalability-2007/high_scalability-2007-09-18-Amazon_Architecture.html">96 high scalability-2007-09-18-Amazon Architecture</a></p>
<p>20 0.13357328 <a title="1604-tfidf-20" href="../high_scalability-2013/high_scalability-2013-02-08-Stuff_The_Internet_Says_On_Scalability_For_February_8%2C_2013.html">1403 high scalability-2013-02-08-Stuff The Internet Says On Scalability For February 8, 2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.253), (1, 0.087), (2, -0.036), (3, 0.063), (4, -0.064), (5, -0.042), (6, 0.107), (7, -0.135), (8, -0.025), (9, -0.12), (10, 0.005), (11, 0.052), (12, 0.017), (13, -0.116), (14, 0.007), (15, 0.01), (16, 0.053), (17, 0.006), (18, 0.022), (19, 0.017), (20, 0.035), (21, 0.038), (22, 0.034), (23, -0.007), (24, -0.07), (25, 0.013), (26, -0.035), (27, 0.037), (28, -0.004), (29, 0.017), (30, -0.018), (31, 0.021), (32, 0.03), (33, -0.013), (34, -0.019), (35, -0.022), (36, 0.004), (37, -0.008), (38, -0.021), (39, 0.022), (40, 0.022), (41, -0.045), (42, -0.027), (43, 0.022), (44, 0.009), (45, -0.021), (46, -0.022), (47, 0.033), (48, -0.001), (49, -0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96524692 <a title="1604-lsi-1" href="../high_scalability-2014/high_scalability-2014-03-03-The_%E2%80%9CFour_Hamiltons%E2%80%9D_Framework_for_Mitigating_Faults_in_the_Cloud%3A_Avoid_it%2C_Mask_it%2C_Bound_it%2C_Fix_it_Fast.html">1604 high scalability-2014-03-03-The “Four Hamiltons” Framework for Mitigating Faults in the Cloud: Avoid it, Mask it, Bound it, Fix it Fast</a></p>
<p>Introduction: This is a guest post by  Patrick Eaton , Software Engineer and Distributed Systems Architect at Stackdriver. 
 
Stackdriver provides intelligent monitoring-as-a-service for cloud hosted applications.  Behind this easy-to-use service is a large distributed system for collecting and storing metrics and events, monitoring and alerting on them, analyzing them, and serving up all the results in a web UI.  Because we ourselves run in the cloud (mostly on AWS), we spend a lot of time thinking about how to deal with faults in the cloud.  We have developed a framework for thinking about fault mitigation for large, cloud-hosted systems.  We endearingly call this framework the “Four Hamiltons” because it is inspired by an article from James Hamilton, the Vice President and Distinguished Engineer at Amazon Web Services.
   The article that led to this framework is called “   The Power Failure Seen Around the World   ”  .  Hamilton analyzes the causes of the power outage that affected Super Bowl XL</p><p>2 0.82710898 <a title="1604-lsi-2" href="../high_scalability-2011/high_scalability-2011-07-20-Netflix%3A_Harden_Systems_Using_a_Barrel_of_Problem_Causing_Monkeys_-_Latency%2C_Conformity%2C_Doctor%2C_Janitor%2C_Security%2C_Internationalization%2C_Chaos.html">1083 high scalability-2011-07-20-Netflix: Harden Systems Using a Barrel of Problem Causing Monkeys - Latency, Conformity, Doctor, Janitor, Security, Internationalization, Chaos</a></p>
<p>Introduction: With a new Planet of the Apes coming out, this may be a touchy subject with our new overlords, but Netflix is using a whole lot more trouble injecting monkeys to test and iteratively harden their systems. We learned previously how Netflix used  Chaos Monkey , a tool to test failover handling by continuously failing EC2 nodes. That was just a start. More monkeys have been added to the barrel. Node failure is just one problem in a system. Imagine a problem and you can imagine creating a monkey to test if your system is handling that problem properly. Yury Izrailevsky talks about just this approach in this very interesting post:  The Netflix Simian Army .
 
I know what you are thinking, if monkeys are so great then why has Netflix been down lately.  Dmuino addressed  this potential embarrassment, putting all fears of cloud inferiority to rest:
  

Unfortunately we're not running 100% on the cloud today. We're working on it, and we could use more help. The latest outage was caused by a com</p><p>3 0.79516059 <a title="1604-lsi-3" href="../high_scalability-2010/high_scalability-2010-08-16-Scaling_an_AWS_infrastructure_-_Tools_and_Patterns.html">881 high scalability-2010-08-16-Scaling an AWS infrastructure - Tools and Patterns</a></p>
<p>Introduction: This is a guest post by    Frédéric Faure    (architect at    Ysance   ), you can follow him on    twitter   . 
 
How do you scale an  AWS  (Amazon Web Services) infrastructure? This article will give you a detailed reply in two parts: the tools you can use to make the most of Amazon’s dynamic approach, and the architectural model you should adopt for a scalable infrastructure.
 
I base my report on my experience gained in several AWS production projects in casual gaming (Facebook), e-commerce infrastructures and within the mainstream GIS (Geographic Information System). It’s true that my experience in gaming ( IsCool, The Game ) is currently the most representative in terms of scalability, due to the number of users (over 800 thousand DAU – daily active users – at peak usage and over 20 million page views every day), however my experiences in e-commerce and GIS (currently underway) provide a different view of scalability, taking into account the various problems of availability and da</p><p>4 0.77161515 <a title="1604-lsi-4" href="../high_scalability-2011/high_scalability-2011-06-13-Automation_on_AWS_with_Ruby_and_Puppet.html">1058 high scalability-2011-06-13-Automation on AWS with Ruby and Puppet</a></p>
<p>Introduction: This is a guest post by   Frédéric Faure    (architect at  Ysance ), you can follow him on  twitter .  
 
 
 
 Urbandive  is an immersive view service launched by the  French YellowPages  which allows you to travel in cities in France thanks to a 360° view. Urbandive focuses on providing high definition pictures and accurate professional and social content. One of the biggest jobs was to enable a fast scalable architecture, because it was really difficult to forecast the traffic load at production time. Traffic load may be influenced if the service receives attention from users as a result of advertising.
 
Below you will find a summary of the goals we achieve by using a Ruby scheduler built on top of  Puppet  on  AWS  to create a complete infrastructure.
    Workflow & XTR-Lucid    
Our scalability combo is : a home-made Ruby scheduler ( XTR-Lucid ) to deal with AWS APIs + the Puppet Master to install services and configure EC2 instances and keep them up-to-date during all the product</p><p>5 0.76864827 <a title="1604-lsi-5" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>Introduction: This is a guest post by  Frédéric Faure   (architect at  Ysance )  on the differences between using a cloud infrastructure and building your own. Frédéric was kind enough to translate the original French version of this article into English. 
 
I’ve been noticing many questions about the differences inherent in choosing between a Cloud infrastructure such as  AWS  (Amazon Web Services) and a traditional physical infrastructure. Firstly, there are a certain number of preconceived notions on this subject that I will attempt to decode for you. Then, it must be understood that each infrastructure has its advantages and disadvantages: a Cloud-type infrastructure does not necessarily fulfill your requirements in every case, however, it can satisfy some of them by optimizing or facilitating the features offered by a traditional physical infrastructure. I will therefore demonstrate the differences between the two that I have noticed, in order to help you make up your own mind.
 
 
 
  The Fram</p><p>6 0.76183051 <a title="1604-lsi-6" href="../high_scalability-2010/high_scalability-2010-12-28-Netflix%3A_Continually_Test_by_Failing_Servers_with_Chaos_Monkey.html">964 high scalability-2010-12-28-Netflix: Continually Test by Failing Servers with Chaos Monkey</a></p>
<p>7 0.76141953 <a title="1604-lsi-7" href="../high_scalability-2013/high_scalability-2013-12-02-Evolution_of_Bazaarvoice%E2%80%99s_Architecture_to_500M_Unique_Users_Per_Month.html">1557 high scalability-2013-12-02-Evolution of Bazaarvoice’s Architecture to 500M Unique Users Per Month</a></p>
<p>8 0.75741768 <a title="1604-lsi-8" href="../high_scalability-2011/high_scalability-2011-12-28-Strategy%3A_Guaranteed_Availability_Requires_Reserving_Instances_in_Specific_Zones.html">1165 high scalability-2011-12-28-Strategy: Guaranteed Availability Requires Reserving Instances in Specific Zones</a></p>
<p>9 0.75452113 <a title="1604-lsi-9" href="../high_scalability-2011/high_scalability-2011-08-01-Peecho_Architecture_-_scalability_on_a_shoestring.html">1090 high scalability-2011-08-01-Peecho Architecture - scalability on a shoestring</a></p>
<p>10 0.75390619 <a title="1604-lsi-10" href="../high_scalability-2011/high_scalability-2011-08-15-Should_any_cloud_be_considered_one_availability_zone%3F_The_Amazon_experience_says_yes..html">1098 high scalability-2011-08-15-Should any cloud be considered one availability zone? The Amazon experience says yes.</a></p>
<p>11 0.75249183 <a title="1604-lsi-11" href="../high_scalability-2014/high_scalability-2014-04-14-How_do_you_even_do_anything_without_using_EBS%3F.html">1631 high scalability-2014-04-14-How do you even do anything without using EBS?</a></p>
<p>12 0.75141627 <a title="1604-lsi-12" href="../high_scalability-2010/high_scalability-2010-04-28-Elasticity_for_the_Enterprise_--_Ensuring_Continuous_High_Availability_in_a_Disaster_Failure_Scenario.html">816 high scalability-2010-04-28-Elasticity for the Enterprise -- Ensuring Continuous High Availability in a Disaster Failure Scenario</a></p>
<p>13 0.74852985 <a title="1604-lsi-13" href="../high_scalability-2014/high_scalability-2014-04-08-Microservices_-_Not_a_free_lunch%21.html">1628 high scalability-2014-04-08-Microservices - Not a free lunch!</a></p>
<p>14 0.74630409 <a title="1604-lsi-14" href="../high_scalability-2010/high_scalability-2010-03-22-7_Secrets_to_Successfully_Scaling_with_Scalr_%28on_Amazon%29_by_Sebastian_Stadil.html">798 high scalability-2010-03-22-7 Secrets to Successfully Scaling with Scalr (on Amazon) by Sebastian Stadil</a></p>
<p>15 0.74462426 <a title="1604-lsi-15" href="../high_scalability-2013/high_scalability-2013-11-15-Stuff_The_Internet_Says_On_Scalability_For_November_15th%2C_2013.html">1549 high scalability-2013-11-15-Stuff The Internet Says On Scalability For November 15th, 2013</a></p>
<p>16 0.74364847 <a title="1604-lsi-16" href="../high_scalability-2013/high_scalability-2013-11-05-10_Things_You_Should_Know_About_AWS.html">1543 high scalability-2013-11-05-10 Things You Should Know About AWS</a></p>
<p>17 0.73737431 <a title="1604-lsi-17" href="../high_scalability-2011/high_scalability-2011-07-11-ATMCash_Exploits_Virtualization_for_Security_-_Immutability_and_Reversion.html">1077 high scalability-2011-07-11-ATMCash Exploits Virtualization for Security - Immutability and Reversion</a></p>
<p>18 0.72718811 <a title="1604-lsi-18" href="../high_scalability-2007/high_scalability-2007-09-18-Amazon_Architecture.html">96 high scalability-2007-09-18-Amazon Architecture</a></p>
<p>19 0.72625721 <a title="1604-lsi-19" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>20 0.72190487 <a title="1604-lsi-20" href="../high_scalability-2011/high_scalability-2011-12-12-Netflix%3A_Developing%2C_Deploying%2C_and_Supporting_Software_According_to_the_Way_of_the_Cloud.html">1155 high scalability-2011-12-12-Netflix: Developing, Deploying, and Supporting Software According to the Way of the Cloud</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.142), (2, 0.24), (10, 0.091), (30, 0.022), (47, 0.018), (52, 0.108), (61, 0.066), (77, 0.015), (79, 0.126), (85, 0.035), (94, 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96526504 <a title="1604-lda-1" href="../high_scalability-2014/high_scalability-2014-03-03-The_%E2%80%9CFour_Hamiltons%E2%80%9D_Framework_for_Mitigating_Faults_in_the_Cloud%3A_Avoid_it%2C_Mask_it%2C_Bound_it%2C_Fix_it_Fast.html">1604 high scalability-2014-03-03-The “Four Hamiltons” Framework for Mitigating Faults in the Cloud: Avoid it, Mask it, Bound it, Fix it Fast</a></p>
<p>Introduction: This is a guest post by  Patrick Eaton , Software Engineer and Distributed Systems Architect at Stackdriver. 
 
Stackdriver provides intelligent monitoring-as-a-service for cloud hosted applications.  Behind this easy-to-use service is a large distributed system for collecting and storing metrics and events, monitoring and alerting on them, analyzing them, and serving up all the results in a web UI.  Because we ourselves run in the cloud (mostly on AWS), we spend a lot of time thinking about how to deal with faults in the cloud.  We have developed a framework for thinking about fault mitigation for large, cloud-hosted systems.  We endearingly call this framework the “Four Hamiltons” because it is inspired by an article from James Hamilton, the Vice President and Distinguished Engineer at Amazon Web Services.
   The article that led to this framework is called “   The Power Failure Seen Around the World   ”  .  Hamilton analyzes the causes of the power outage that affected Super Bowl XL</p><p>2 0.96428055 <a title="1604-lda-2" href="../high_scalability-2013/high_scalability-2013-01-07-Analyzing_billions_of_credit_card_transactions_and_serving_low-latency_insights_in_the_cloud.html">1382 high scalability-2013-01-07-Analyzing billions of credit card transactions and serving low-latency insights in the cloud</a></p>
<p>Introduction: This is a guest post by  Ivan de Prado  and  Pere Ferrera , founders of  Datasalt , the company behind  Pangool  and  Splout SQL  Big Data open-source projects.  
 
The amount of payments performed using credit cards is huge. It is clear that there is inherent value in the data that can be derived from analyzing all the transactions. Client fidelity, demographics, heat maps of activity, shop recommendations, and many other statistics are useful to both clients and shops for improving their relationship with the market. At  Datasalt  we have developed a system in collaboration with the  BBVA bank  that is able to analyze years of data and serve insights and statistics to different low-latency web and mobile applications.
 
The main challenge we faced besides processing Big Data input is that  the output was also Big Data, and even bigger than the input . And this output needed to be served quickly, under high load.
 
The solution we developed has an infrastructure cost of just a few tho</p><p>3 0.96081787 <a title="1604-lda-3" href="../high_scalability-2011/high_scalability-2011-09-16-Stuff_The_Internet_Says_On_Scalability_For_September_16%2C_2011.html">1117 high scalability-2011-09-16-Stuff The Internet Says On Scalability For September 16, 2011</a></p>
<p>Introduction: Between love and madness lies  HighScalability : 
  
  Google now 10x better : MapReduce sorts 1 petabyte of data using 8000 computers in 33 minutes;  1 Billion on Social Networks ;  Tumblr at 10 Billion Posts ;  Twitter at 100 Million Users ;  Testing at Google Scale : 1800 builds, 120 million test suites, 60 million tests run daily. 
 From the  Dash Memo  on Google's Plan:  Go is a very promising systems-programming language in the vein of C++. We fully hope and expect that Go becomes the standard back-end language at Google over the next few years.  On GAE  Go can load from  a cold start in 100ms and the typical instance size is 4MB. Is it any wonder Go is a go? Should we expect to see Java and Python deprecated because Go is so much cheaper to run at scale? 
 Potent Quotables:               
 
  @caciufo  : 30x more scalability w/ many-core. So perf doesn't have to level out or vex programmers. #IDF2011 
  @joerglew  : Evaluating divide&conquer; vs. master-slave architecture for wor</p><p>4 0.95989543 <a title="1604-lda-4" href="../high_scalability-2013/high_scalability-2013-05-03-Stuff_The_Internet_Says_On_Scalability_For_May_3%2C_2013.html">1451 high scalability-2013-05-03-Stuff The Internet Says On Scalability For May 3, 2013</a></p>
<p>Introduction: Hey, it's HighScalability time:
    ( Giant Hurricane on Saturn , here's one  in New Orleans )  
 
  
  1,966,080 cores : Time Warp synchronization protocol using up to 7.8M MPI tasks on 1,966,080 cores of the {Sequoia} Blue Gene/Q supercomputer system. 33 trillion events processed in 65 seconds yielding a peak event-rate in excess of 504 billion events/second using 120 racks of Sequoia. 
 Quotable Quotes:                             
 
  Thad Starner : the longer accessing a device exceeds 2s, the more its actually usage would decrease exponentially. Thus, he made a claim that wrist watch interface always sitting on one's wrist ready to use should be more successful than mobile phones which have to pulled out of the pocket.  
  @joedevon : We came for scalability but we stayed for agility #NoSQL 
  @jahmailay : "Our user base is exploding. I really wish we spent more time on scalability instead of features customers don't use." - Everybody, always. 
  @bsletten : I don’t think it is a</p><p>5 0.95311445 <a title="1604-lda-5" href="../high_scalability-2007/high_scalability-2007-11-16-Mogulus_Doesn%27t_Own_a_Single_Server_and_has_%241.2_million_in_funding%2C_15%2C000_People_Creating_Channels.html">156 high scalability-2007-11-16-Mogulus Doesn't Own a Single Server and has $1.2 million in funding, 15,000 People Creating Channels</a></p>
<p>Introduction: Scoble   the Ubiquitous has a fascinating post on how Mogulus, a live video channel startup, uses S3/EC2 and doesn't own a single server. The trends that have been happening for a while now are going mainstream. To do great things you no longer need to start by creating a huge war chest. You can forage off the land, like any good mobile, light weight fighting unit.     For a strategy hit he mentions the same needed change in perspective as Beau Lebens talked about when making   FeedBlendr  :     One tip he gave us is that when using Amazon’s services you have to design your systems with the assumption that they will never be up and running. What he means by that is services are “volatile” and can go up and down without notice. So, he’s designed his systems to survive that. He told me that it meant his engineering teams had to be quite disciplined in designing their architecture.</p><p>6 0.95094246 <a title="1604-lda-6" href="../high_scalability-2013/high_scalability-2013-02-14-When_all_the_Program%27s_a_Graph_-_Prismatic%27s_Plumbing_Library.html">1406 high scalability-2013-02-14-When all the Program's a Graph - Prismatic's Plumbing Library</a></p>
<p>7 0.95025146 <a title="1604-lda-7" href="../high_scalability-2008/high_scalability-2008-02-11-Yahoo_Live%27s_Scaling_Problems_Prove%3A_Release_Early_and_Often_-_Just_Don%27t_Screw_Up.html">244 high scalability-2008-02-11-Yahoo Live's Scaling Problems Prove: Release Early and Often - Just Don't Screw Up</a></p>
<p>8 0.9497503 <a title="1604-lda-8" href="../high_scalability-2008/high_scalability-2008-04-05-Skype_Plans_for_PostgreSQL_to_Scale_to_1_Billion_Users.html">297 high scalability-2008-04-05-Skype Plans for PostgreSQL to Scale to 1 Billion Users</a></p>
<p>9 0.94902432 <a title="1604-lda-9" href="../high_scalability-2010/high_scalability-2010-08-18-Misco%3A_A_MapReduce_Framework_for_Mobile_Systems_-_Start_of_the_Ambient_Cloud%3F.html">882 high scalability-2010-08-18-Misco: A MapReduce Framework for Mobile Systems - Start of the Ambient Cloud?</a></p>
<p>10 0.94432592 <a title="1604-lda-10" href="../high_scalability-2013/high_scalability-2013-04-01-Khan_Academy_Checkbook_Scaling_to_6_Million_Users_a_Month_on_GAE.html">1432 high scalability-2013-04-01-Khan Academy Checkbook Scaling to 6 Million Users a Month on GAE</a></p>
<p>11 0.94407654 <a title="1604-lda-11" href="../high_scalability-2007/high_scalability-2007-07-30-Product%3A_Yslow_to_speed_up_your_web_pages.html">47 high scalability-2007-07-30-Product: Yslow to speed up your web pages</a></p>
<p>12 0.94198823 <a title="1604-lda-12" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>13 0.94191992 <a title="1604-lda-13" href="../high_scalability-2014/high_scalability-2014-01-06-How_HipChat_Stores_and_Indexes_Billions_of_Messages_Using_ElasticSearch_and_Redis.html">1573 high scalability-2014-01-06-How HipChat Stores and Indexes Billions of Messages Using ElasticSearch and Redis</a></p>
<p>14 0.94066817 <a title="1604-lda-14" href="../high_scalability-2009/high_scalability-2009-10-06-Building_a_Unique_Data_Warehouse.html">716 high scalability-2009-10-06-Building a Unique Data Warehouse</a></p>
<p>15 0.94019687 <a title="1604-lda-15" href="../high_scalability-2009/high_scalability-2009-01-20-Product%3A_Amazon%27s_SimpleDB.html">498 high scalability-2009-01-20-Product: Amazon's SimpleDB</a></p>
<p>16 0.93972456 <a title="1604-lda-16" href="../high_scalability-2008/high_scalability-2008-03-12-YouTube_Architecture.html">274 high scalability-2008-03-12-YouTube Architecture</a></p>
<p>17 0.93938941 <a title="1604-lda-17" href="../high_scalability-2007/high_scalability-2007-08-22-Wikimedia_architecture.html">72 high scalability-2007-08-22-Wikimedia architecture</a></p>
<p>18 0.93915111 <a title="1604-lda-18" href="../high_scalability-2012/high_scalability-2012-12-10-Switch_your_databases_to_Flash_storage._Now._Or_you%27re_doing_it_wrong..html">1369 high scalability-2012-12-10-Switch your databases to Flash storage. Now. Or you're doing it wrong.</a></p>
<p>19 0.93876117 <a title="1604-lda-19" href="../high_scalability-2012/high_scalability-2012-07-30-Prismatic_Architecture_-_Using_Machine_Learning_on_Social_Networks_to_Figure_Out_What_You_Should_Read_on_the_Web_.html">1293 high scalability-2012-07-30-Prismatic Architecture - Using Machine Learning on Social Networks to Figure Out What You Should Read on the Web </a></p>
<p>20 0.93673307 <a title="1604-lda-20" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
