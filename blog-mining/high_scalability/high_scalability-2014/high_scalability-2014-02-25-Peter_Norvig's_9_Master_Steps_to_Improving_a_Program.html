<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1601 high scalability-2014-02-25-Peter Norvig's 9 Master Steps to Improving a Program</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2014" href="../home/high_scalability-2014_home.html">high_scalability-2014</a> <a title="high_scalability-2014-1601" href="#">high_scalability-2014-1601</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1601 high scalability-2014-02-25-Peter Norvig's 9 Master Steps to Improving a Program</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2014-1601-html" href="http://highscalability.com//blog/2014/2/25/peter-norvigs-9-master-steps-to-improving-a-program.html">html</a></p><p>Introduction: Inspired by axkcd comic,Peter Norvig,Director of Research at Google and all
around interesting and nice guy, has created an above par code kata involving
a regex program that demonstrates the core inner loop of many successful
systems profiled on HighScalability.The original code is atxkcd 1313: Regex
Golf, which comes up with an algorithm to find a short regex that matches the
winners and not the losers from two arbitrary lists. The Python code is
readable, the process is TDDish, and the problem, which sounds simple, but
soon explodes into regex weirdness, as does most regex code. If you find
regular expressions confusing you'll definitely benefit from Peter's
deliberate strategy for finding a regex.The post demonstrating the iterated
improvement of the program is atxkcd 1313: Regex Golf (Part 2: Infinite
Problems). As with most first solutions it wasn't optimal. To improve the
program Peter recommends the following steps: Profiling: Figure out where the
program spends its time. Speed</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('regex', 0.62), ('atxkcd', 0.243), ('program', 0.238), ('golf', 0.22), ('search', 0.146), ('components', 0.135), ('peter', 0.122), ('arbitrary', 0.12), ('weirdness', 0.11), ('deliberate', 0.11), ('greedy', 0.11), ('explodes', 0.11), ('glorious', 0.099), ('exhaustive', 0.099), ('iterated', 0.095), ('studying', 0.092), ('readable', 0.092), ('expressions', 0.092), ('profiled', 0.09), ('demonstrating', 0.09)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1601-tfidf-1" href="../high_scalability-2014/high_scalability-2014-02-25-Peter_Norvig%27s_9_Master_Steps_to_Improving_a_Program.html">1601 high scalability-2014-02-25-Peter Norvig's 9 Master Steps to Improving a Program</a></p>
<p>Introduction: Inspired by axkcd comic,Peter Norvig,Director of Research at Google and all
around interesting and nice guy, has created an above par code kata involving
a regex program that demonstrates the core inner loop of many successful
systems profiled on HighScalability.The original code is atxkcd 1313: Regex
Golf, which comes up with an algorithm to find a short regex that matches the
winners and not the losers from two arbitrary lists. The Python code is
readable, the process is TDDish, and the problem, which sounds simple, but
soon explodes into regex weirdness, as does most regex code. If you find
regular expressions confusing you'll definitely benefit from Peter's
deliberate strategy for finding a regex.The post demonstrating the iterated
improvement of the program is atxkcd 1313: Regex Golf (Part 2: Infinite
Problems). As with most first solutions it wasn't optimal. To improve the
program Peter recommends the following steps: Profiling: Figure out where the
program spends its time. Speed</p><p>2 0.089207292 <a title="1601-tfidf-2" href="../high_scalability-2008/high_scalability-2008-05-28-Job_queue_and_search_engine.html">332 high scalability-2008-05-28-Job queue and search engine</a></p>
<p>Introduction: Hi,I want to implement a search engine with lucene.To be scalable, I would
like to execute search jobs asynchronously (with a job queuing system).But i
don't know if it is a good design... Why ?Search results can be large ! (eg:
100+ pages with 25 documents per page)With asynchronous sytem, I need to store
results for each search job.I can set a short expiration time (~5 min) for
each search result, but it's still large.What do you think about it ?Which
design would you use for that ?ThanksMat</p><p>3 0.079265036 <a title="1601-tfidf-3" href="../high_scalability-2009/high_scalability-2009-11-26-Kngine_Snippet_Search_New_Indexing_Technology.html">746 high scalability-2009-11-26-Kngine Snippet Search New Indexing Technology</a></p>
<p>Introduction: WhileKnginejust announcesome improvement and new features, I would like you
take you in small trip in Snippet Search research project at Kngine. What is
Kngine?Kngine is startup company working in Searching technologies, We in
Kngine aims to organize the human beingsSystematic KnowledgeandExperiencesand
make it accessible to everyone. We aim to collect and organize all objective
data, and make it possible and easy to access. Our goal is to buildWeb 3.0 Web
Search Engineon the advances of Web Search Engine, Semantic Web, Data
Representation technologies a new form of Web Search Engine that will unleash
a revolution of new possibilities. Introduction to Snippet SearchToday, The
Web Search Engine's is the Web getaway, especially to get specific
information. But unfortunately the search engines didn't changed mush as the
Web changed from 90's.Since the 90's the Web search engine still provide the
same kind of results: Links to documents. We in Kngine think that it's the
time to rethink abo</p><p>4 0.078890495 <a title="1601-tfidf-4" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>Introduction: This is an interview with Gabriel Weinberg, founder of Duck Duck Go and
general all around startup guru, on what DDG's architecture looks like in
2012.Innovative search engine upstart DuckDuckGo had30 million searchesin
February 2012 and averages over 1 million searches a day. It's being
positioned bysuper investor Fred Wilsonas a clean, private, impartial and fast
search engine. After talking with Gabriel I like what Fred Wilson said
earlier, it seems closer to the heart of the matter:We invested in DuckDuckGo
for the Reddit, Hacker News anarchists.                  Choosing DuckDuckGo
can be thought of as not just a technical choice, but a vote for revolution.
In an age when knowing your essence is not about about love or friendship, but
about more effectively selling you to advertisers, DDG is positioning
themselves as thedo not track alternative, keepers of theprivacy flame. You
will still be monetized of course, but in a more civilized and anonymous way.
Pushing privacy is a good</p><p>5 0.077025376 <a title="1601-tfidf-5" href="../high_scalability-2009/high_scalability-2009-07-08-Servers_Component_-_How_to_choice_and_build_perfect_server.html">653 high scalability-2009-07-08-Servers Component - How to choice and build perfect server</a></p>
<p>Introduction: There are a lot of questions about how the server components, and how to build
perfect server with consider the power consumption. TodayI will discussthe
Server components, and how we can choice better server components with
consider the power consumption, efficacy, performance, and price.Key
points:What kind of components the servers needs?The Green Computing and the
Servers componentsHow much power the server consumeChoice the right
components:ProcessorHard Disk DriveMemoryOperating systemBuild Server, or buy?</p><p>6 0.067457646 <a title="1601-tfidf-6" href="../high_scalability-2010/high_scalability-2010-05-10-Sify.com_Architecture_-_A_Portal_at_3900_Requests_Per_Second.html">825 high scalability-2010-05-10-Sify.com Architecture - A Portal at 3900 Requests Per Second</a></p>
<p>7 0.066285551 <a title="1601-tfidf-7" href="../high_scalability-2012/high_scalability-2012-03-26-7_Years_of_YouTube_Scalability_Lessons_in_30_Minutes.html">1215 high scalability-2012-03-26-7 Years of YouTube Scalability Lessons in 30 Minutes</a></p>
<p>8 0.065603934 <a title="1601-tfidf-8" href="../high_scalability-2013/high_scalability-2013-08-30-Stuff_The_Internet_Says_On_Scalability_For_August_30%2C_2013.html">1509 high scalability-2013-08-30-Stuff The Internet Says On Scalability For August 30, 2013</a></p>
<p>9 0.064825267 <a title="1601-tfidf-9" href="../high_scalability-2010/high_scalability-2010-03-30-Running_Large_Graph_Algorithms_-_Evaluation_of_Current_State-of-the-Art_and_Lessons_Learned.html">801 high scalability-2010-03-30-Running Large Graph Algorithms - Evaluation of Current State-of-the-Art and Lessons Learned</a></p>
<p>10 0.063749842 <a title="1601-tfidf-10" href="../high_scalability-2009/high_scalability-2009-04-29-How_to_choice_and_build_perfect_server.html">585 high scalability-2009-04-29-How to choice and build perfect server</a></p>
<p>11 0.059578039 <a title="1601-tfidf-11" href="../high_scalability-2013/high_scalability-2013-08-16-Stuff_The_Internet_Says_On_Scalability_For_August_16%2C_2013.html">1502 high scalability-2013-08-16-Stuff The Internet Says On Scalability For August 16, 2013</a></p>
<p>12 0.058279462 <a title="1601-tfidf-12" href="../high_scalability-2009/high_scalability-2009-06-23-Learn_How_to_Exploit_Multiple_Cores_for_Better_Performance_and_Scalability.html">636 high scalability-2009-06-23-Learn How to Exploit Multiple Cores for Better Performance and Scalability</a></p>
<p>13 0.057259601 <a title="1601-tfidf-13" href="../high_scalability-2009/high_scalability-2009-03-12-Paper%3A_Understanding_and_Designing_New_Server_Architectures_for_Emerging_Warehouse-Computing_Environments.html">535 high scalability-2009-03-12-Paper: Understanding and Designing New Server Architectures for Emerging Warehouse-Computing Environments</a></p>
<p>14 0.05664305 <a title="1601-tfidf-14" href="../high_scalability-2013/high_scalability-2013-12-06-Stuff_The_Internet_Says_On_Scalability_For_December_6th%2C_2013.html">1559 high scalability-2013-12-06-Stuff The Internet Says On Scalability For December 6th, 2013</a></p>
<p>15 0.054901138 <a title="1601-tfidf-15" href="../high_scalability-2013/high_scalability-2013-07-12-Stuff_The_Internet_Says_On_Scalability_For_July_12%2C_2013.html">1490 high scalability-2013-07-12-Stuff The Internet Says On Scalability For July 12, 2013</a></p>
<p>16 0.054615024 <a title="1601-tfidf-16" href="../high_scalability-2013/high_scalability-2013-02-14-When_all_the_Program%27s_a_Graph_-_Prismatic%27s_Plumbing_Library.html">1406 high scalability-2013-02-14-When all the Program's a Graph - Prismatic's Plumbing Library</a></p>
<p>17 0.054350935 <a title="1601-tfidf-17" href="../high_scalability-2009/high_scalability-2009-08-07-The_Canonical_Cloud_Architecture_.html">674 high scalability-2009-08-07-The Canonical Cloud Architecture </a></p>
<p>18 0.0540975 <a title="1601-tfidf-18" href="../high_scalability-2013/high_scalability-2013-05-22-Strategy%3A_Stop_Using_Linked-Lists.html">1462 high scalability-2013-05-22-Strategy: Stop Using Linked-Lists</a></p>
<p>19 0.052541051 <a title="1601-tfidf-19" href="../high_scalability-2009/high_scalability-2009-08-28-Strategy%3A_Solve_Only_80_Percent_of_the_Problem.html">689 high scalability-2009-08-28-Strategy: Solve Only 80 Percent of the Problem</a></p>
<p>20 0.052091144 <a title="1601-tfidf-20" href="../high_scalability-2009/high_scalability-2009-02-21-Google_AppEngine_-_A_Second_Look.html">517 high scalability-2009-02-21-Google AppEngine - A Second Look</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.092), (1, 0.046), (2, -0.008), (3, 0.025), (4, 0.019), (5, -0.0), (6, -0.015), (7, 0.038), (8, -0.0), (9, 0.012), (10, -0.005), (11, -0.013), (12, 0.001), (13, -0.025), (14, 0.004), (15, -0.015), (16, -0.002), (17, 0.005), (18, 0.034), (19, 0.008), (20, 0.019), (21, -0.062), (22, -0.018), (23, 0.018), (24, -0.037), (25, -0.001), (26, -0.009), (27, -0.003), (28, -0.004), (29, 0.05), (30, -0.046), (31, 0.033), (32, -0.036), (33, 0.033), (34, 0.026), (35, -0.003), (36, -0.0), (37, -0.01), (38, -0.012), (39, -0.008), (40, 0.043), (41, -0.024), (42, -0.029), (43, 0.007), (44, -0.029), (45, 0.034), (46, 0.018), (47, 0.024), (48, 0.037), (49, -0.009)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97933239 <a title="1601-lsi-1" href="../high_scalability-2014/high_scalability-2014-02-25-Peter_Norvig%27s_9_Master_Steps_to_Improving_a_Program.html">1601 high scalability-2014-02-25-Peter Norvig's 9 Master Steps to Improving a Program</a></p>
<p>Introduction: Inspired by axkcd comic,Peter Norvig,Director of Research at Google and all
around interesting and nice guy, has created an above par code kata involving
a regex program that demonstrates the core inner loop of many successful
systems profiled on HighScalability.The original code is atxkcd 1313: Regex
Golf, which comes up with an algorithm to find a short regex that matches the
winners and not the losers from two arbitrary lists. The Python code is
readable, the process is TDDish, and the problem, which sounds simple, but
soon explodes into regex weirdness, as does most regex code. If you find
regular expressions confusing you'll definitely benefit from Peter's
deliberate strategy for finding a regex.The post demonstrating the iterated
improvement of the program is atxkcd 1313: Regex Golf (Part 2: Infinite
Problems). As with most first solutions it wasn't optimal. To improve the
program Peter recommends the following steps: Profiling: Figure out where the
program spends its time. Speed</p><p>2 0.76129776 <a title="1601-lsi-2" href="../high_scalability-2008/high_scalability-2008-06-08-Search_fast_in_million_rows.html">342 high scalability-2008-06-08-Search fast in million rows</a></p>
<p>Introduction: I have a table .This table has many columns but search performed based on 1
columns ,this table can have more than million rows.The data in these columns
is something like funny,new york,hollywoodUser can search with parameters as
funny hollywood .I need to take this 2 words and then search on column whether
that column contain this words and how many times .It is not possible to index
here .If the results return say 1200 results then without comparing each and
every column i can't determine no of results.I need to compare for each and
every column.This query is very frequent .How can i approach for this
problem.What type of architecture,tools is helpful.I just know that this can
be accomplished with distributed system but how can i make this system. I also
see in this website that LinkedIn uses Lucene for search .Is Lucene is helpful
in my case.My table has also lots of insertion ,however updation in not very
frequent.</p><p>3 0.75418687 <a title="1601-lsi-3" href="../high_scalability-2010/high_scalability-2010-04-14-Parallel_Information_Retrieval_and_Other_Search_Engine_Goodness.html">810 high scalability-2010-04-14-Parallel Information Retrieval and Other Search Engine Goodness</a></p>
<p>Introduction: Parallel Information Retrievalis a sample chapter in what appears to be a
book-in-progress titledInformation Retrieval Implementing and Evaluation
Search EnginesbyStefan Buttcher, Google Inc andCharles L. A. Clarke,Gordon V.
Cormack, both of the University of Waterloo. The full table of contents is on-
line and looks to be really interesting:Information retrieval is the
foundation for modern search engines. This text offers an introduction to the
core topics underlying modern search technologies, including algorithms, data
structures, indexing, retrieval, and evaluation. The emphasis is on
implementation and experimentation; each chapter includes exercises and
suggestions for student projects.Currently available is the full text of
chapters: Introduction, Basic Techniques, Static Inverted Indices, Index
Compression, and Parallel Information Retrieval. Parallel Information
Retrieval is really meaty:Information retrieval systems often have to deal
with very large amounts of data. They mu</p><p>4 0.74765629 <a title="1601-lsi-4" href="../high_scalability-2008/high_scalability-2008-05-28-Job_queue_and_search_engine.html">332 high scalability-2008-05-28-Job queue and search engine</a></p>
<p>Introduction: Hi,I want to implement a search engine with lucene.To be scalable, I would
like to execute search jobs asynchronously (with a job queuing system).But i
don't know if it is a good design... Why ?Search results can be large ! (eg:
100+ pages with 25 documents per page)With asynchronous sytem, I need to store
results for each search job.I can set a short expiration time (~5 min) for
each search result, but it's still large.What do you think about it ?Which
design would you use for that ?ThanksMat</p><p>5 0.73869687 <a title="1601-lsi-5" href="../high_scalability-2009/high_scalability-2009-11-26-Kngine_Snippet_Search_New_Indexing_Technology.html">746 high scalability-2009-11-26-Kngine Snippet Search New Indexing Technology</a></p>
<p>Introduction: WhileKnginejust announcesome improvement and new features, I would like you
take you in small trip in Snippet Search research project at Kngine. What is
Kngine?Kngine is startup company working in Searching technologies, We in
Kngine aims to organize the human beingsSystematic KnowledgeandExperiencesand
make it accessible to everyone. We aim to collect and organize all objective
data, and make it possible and easy to access. Our goal is to buildWeb 3.0 Web
Search Engineon the advances of Web Search Engine, Semantic Web, Data
Representation technologies a new form of Web Search Engine that will unleash
a revolution of new possibilities. Introduction to Snippet SearchToday, The
Web Search Engine's is the Web getaway, especially to get specific
information. But unfortunately the search engines didn't changed mush as the
Web changed from 90's.Since the 90's the Web search engine still provide the
same kind of results: Links to documents. We in Kngine think that it's the
time to rethink abo</p><p>6 0.72807515 <a title="1601-lsi-6" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>7 0.71521294 <a title="1601-lsi-7" href="../high_scalability-2013/high_scalability-2013-04-26-Stuff_The_Internet_Says_On_Scalability_For_April_26%2C_2013.html">1447 high scalability-2013-04-26-Stuff The Internet Says On Scalability For April 26, 2013</a></p>
<p>8 0.70045 <a title="1601-lsi-8" href="../high_scalability-2009/high_scalability-2009-08-28-Strategy%3A_Solve_Only_80_Percent_of_the_Problem.html">689 high scalability-2009-08-28-Strategy: Solve Only 80 Percent of the Problem</a></p>
<p>9 0.69557947 <a title="1601-lsi-9" href="../high_scalability-2012/high_scalability-2012-08-02-Ask_DuckDuckGo%3A_Is_there_Anything_you_Want_to_Know_About_DDG%3F.html">1295 high scalability-2012-08-02-Ask DuckDuckGo: Is there Anything you Want to Know About DDG?</a></p>
<p>10 0.68616652 <a title="1601-lsi-10" href="../high_scalability-2008/high_scalability-2008-02-24-Yandex_Architecture.html">258 high scalability-2008-02-24-Yandex Architecture</a></p>
<p>11 0.6852814 <a title="1601-lsi-11" href="../high_scalability-2009/high_scalability-2009-06-14-kngine_%27Knowledge_Engine%27_milestone_2.html">630 high scalability-2009-06-14-kngine 'Knowledge Engine' milestone 2</a></p>
<p>12 0.67306608 <a title="1601-lsi-12" href="../high_scalability-2014/high_scalability-2014-04-03-Leslie_Lamport_to_Programmers%3A_You%27re_Doing_it_Wrong.html">1625 high scalability-2014-04-03-Leslie Lamport to Programmers: You're Doing it Wrong</a></p>
<p>13 0.67199528 <a title="1601-lsi-13" href="../high_scalability-2012/high_scalability-2012-05-28-The_Anatomy_of_Search_Technology%3A_Crawling_using_Combinators.html">1253 high scalability-2012-05-28-The Anatomy of Search Technology: Crawling using Combinators</a></p>
<p>14 0.66176981 <a title="1601-lsi-14" href="../high_scalability-2012/high_scalability-2012-05-04-Stuff_The_Internet_Says_On_Scalability_For_May_4%2C_2012.html">1239 high scalability-2012-05-04-Stuff The Internet Says On Scalability For May 4, 2012</a></p>
<p>15 0.65278661 <a title="1601-lsi-15" href="../high_scalability-2008/high_scalability-2008-05-30-Is_%22Scaling_Engineer%22_a_new_job_title%3F.html">335 high scalability-2008-05-30-Is "Scaling Engineer" a new job title?</a></p>
<p>16 0.64381766 <a title="1601-lsi-16" href="../high_scalability-2014/high_scalability-2014-03-11-Douglas_Adams_-_3_Rules_that_Describe_Our_Reactions_to_Technologies.html">1610 high scalability-2014-03-11-Douglas Adams - 3 Rules that Describe Our Reactions to Technologies</a></p>
<p>17 0.6334303 <a title="1601-lsi-17" href="../high_scalability-2011/high_scalability-2011-09-26-17_Techniques_Used_to_Scale_Turntable.fm_and_Labmeeting_to_Millions_of_Users.html">1124 high scalability-2011-09-26-17 Techniques Used to Scale Turntable.fm and Labmeeting to Millions of Users</a></p>
<p>18 0.62062901 <a title="1601-lsi-18" href="../high_scalability-2012/high_scalability-2012-04-25-The_Anatomy_of_Search_Technology%3A_blekko%E2%80%99s_NoSQL_database.html">1233 high scalability-2012-04-25-The Anatomy of Search Technology: blekko’s NoSQL database</a></p>
<p>19 0.61904603 <a title="1601-lsi-19" href="../high_scalability-2012/high_scalability-2012-06-01-Stuff_The_Internet_Says_On_Scalability_For_June_1%2C_2012.html">1255 high scalability-2012-06-01-Stuff The Internet Says On Scalability For June 1, 2012</a></p>
<p>20 0.61739594 <a title="1601-lsi-20" href="../high_scalability-2013/high_scalability-2013-08-16-Stuff_The_Internet_Says_On_Scalability_For_August_16%2C_2013.html">1502 high scalability-2013-08-16-Stuff The Internet Says On Scalability For August 16, 2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.056), (2, 0.148), (10, 0.02), (61, 0.039), (79, 0.06), (85, 0.015), (94, 0.559)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98136425 <a title="1601-lda-1" href="../high_scalability-2009/high_scalability-2009-04-07-Six_Lessons_Learned_Deploying_a_Large-scale_Infrastructure_in_Amazon_EC2_.html">559 high scalability-2009-04-07-Six Lessons Learned Deploying a Large-scale Infrastructure in Amazon EC2 </a></p>
<p>Introduction: Lessons learned fromOpenX's large-scale deploymentto Amazon EC2:Expect
failures; what's more, embrace themFully automate your infrastructure
deploymentsDesign your infrastructure so that it scales horizontallyEstablish
clear measurable goalsBe prepared to quickly identify and eliminate
bottlenecksPlay wack-a-mole for a while, until things get stable</p><p>2 0.9613927 <a title="1601-lda-2" href="../high_scalability-2009/high_scalability-2009-05-22-Distributed_content_system_with_bandwidth_balancing.html">605 high scalability-2009-05-22-Distributed content system with bandwidth balancing</a></p>
<p>Introduction: I am looking for a way to distribute files over servers in different physical
locations. My main concern is that I have bandwidth limitations on each
location, and wish to spread the bandwidth load evenly. Atm. I just have 1:1
copies of the files on all servers, and have the application pick a random
server to serve the file as a temp fix...It's a small video streaming service.
I want to spoonfeed the stream to the client with a max bandwidth output, and
support seek. At present I use php to limit the network stream, and read the
file at a given offset sendt as a get parameter from the player for seek. It's
psuedo streaming, but it works.I have been looking at MogileFS, which would
solve the storage part. With MogileFS I can make use of my current php
solution as it supports lighttpd and apache (with mod_rewrite or similar).
However I don't see how I can apply MogileFS to check for bandwidth %
usage?Any reccomendations for how I can solve this?</p><p>3 0.95991957 <a title="1601-lda-3" href="../high_scalability-2008/high_scalability-2008-10-15-Sun_Customer_Ready_HPC_Cluster%3A_Reference_Configurations_with_Sun_Fire_X2200_M2_and_X2100_M2_Servers.html">418 high scalability-2008-10-15-Sun Customer Ready HPC Cluster: Reference Configurations with Sun Fire X2200 M2 and X2100 M2 Servers</a></p>
<p>Introduction: The reference configurations described in this blueprint are starting points
for building Sun Customer Ready HPC Clusters configured with Sun Fire X2100 M2
and X2200 M2 servers. The configurations define how Sun Systems Group products
can be configured in a typical grid rack deployment. This document describes
configurations in detail using Sun Fire X2100 M2 and X2200 M2 servers with a
Gigabit Ethernet data fabric, as well as configurations using Sun Fire X2200
M2 servers with a high-speed InfiniBand fabric. These configurations focus on
single rack solutions, with external connections through uplink ports of the
switches.These reference configurations have been architected using Sun's
expertise gained in actual, real-world installations. Within certain
constraints, as described in the later sections, the system can be tailored to
the customer needs. Certain system components described in this document are
only available through Sun's factory integration. Although the information
conta</p><p>same-blog 4 0.94270706 <a title="1601-lda-4" href="../high_scalability-2014/high_scalability-2014-02-25-Peter_Norvig%27s_9_Master_Steps_to_Improving_a_Program.html">1601 high scalability-2014-02-25-Peter Norvig's 9 Master Steps to Improving a Program</a></p>
<p>Introduction: Inspired by axkcd comic,Peter Norvig,Director of Research at Google and all
around interesting and nice guy, has created an above par code kata involving
a regex program that demonstrates the core inner loop of many successful
systems profiled on HighScalability.The original code is atxkcd 1313: Regex
Golf, which comes up with an algorithm to find a short regex that matches the
winners and not the losers from two arbitrary lists. The Python code is
readable, the process is TDDish, and the problem, which sounds simple, but
soon explodes into regex weirdness, as does most regex code. If you find
regular expressions confusing you'll definitely benefit from Peter's
deliberate strategy for finding a regex.The post demonstrating the iterated
improvement of the program is atxkcd 1313: Regex Golf (Part 2: Infinite
Problems). As with most first solutions it wasn't optimal. To improve the
program Peter recommends the following steps: Profiling: Figure out where the
program spends its time. Speed</p><p>5 0.93617785 <a title="1601-lda-5" href="../high_scalability-2007/high_scalability-2007-10-07-Using_ThreadLocal_to_pass_context_information_around_in_web_applications.html">115 high scalability-2007-10-07-Using ThreadLocal to pass context information around in web applications</a></p>
<p>Introduction: Hi,In java web servers, each http request is handled by a thread in thread
pool. So for a Servlet handling the request, a thread is assigned. It is
tempting (and very convinient) to keep context information in the threadlocal
variable. I recently had a requirement where we need to assign logged in user
id and timestamp to request sent to web services. Because we already had the
code in place, it was extremely difficult to change the method signatures to
pass user id everywhere. The solution I thought isclass ReferenceIdGenerator
{public static setReferenceId(String login) {threadLocal.set(login +
System.currentMillis());}public static String getReferenceId() {return
threadLocal.get();}private static ThreadLocal threadLocal =new
ThreadLocal();}class MySevlet {void service(.....) {HttpSession session =
request.getSession(false);String userId =
session.get("userId");ReferenceIdGenerator.setRefernceId(userId);try
{doSomething();}finally {ReferenceIdGenerator.remove();}}This method is also</p><p>6 0.91369307 <a title="1601-lda-6" href="../high_scalability-2012/high_scalability-2012-08-16-Paper%3A_A_Provably_Correct_Scalable_Concurrent_Skip_List.html">1305 high scalability-2012-08-16-Paper: A Provably Correct Scalable Concurrent Skip List</a></p>
<p>7 0.91202813 <a title="1601-lda-7" href="../high_scalability-2007/high_scalability-2007-09-13-Design_Preparations_for_Scaling.html">91 high scalability-2007-09-13-Design Preparations for Scaling</a></p>
<p>8 0.84747428 <a title="1601-lda-8" href="../high_scalability-2012/high_scalability-2012-04-05-Big_Data_Counting%3A_How_to_count_a_billion_distinct_objects_using_only_1.5KB_of_Memory.html">1222 high scalability-2012-04-05-Big Data Counting: How to count a billion distinct objects using only 1.5KB of Memory</a></p>
<p>9 0.83648527 <a title="1601-lda-9" href="../high_scalability-2010/high_scalability-2010-06-01-Web_Speed_Can_Push_You_Off_of_Google_Search_Rankings%21_What_Can_You_Do%3F.html">834 high scalability-2010-06-01-Web Speed Can Push You Off of Google Search Rankings! What Can You Do?</a></p>
<p>10 0.77422321 <a title="1601-lda-10" href="../high_scalability-2011/high_scalability-2011-04-16-The_NewSQL_Market_Breakdown.html">1025 high scalability-2011-04-16-The NewSQL Market Breakdown</a></p>
<p>11 0.77086103 <a title="1601-lda-11" href="../high_scalability-2008/high_scalability-2008-02-05-SLA_monitoring.html">241 high scalability-2008-02-05-SLA monitoring</a></p>
<p>12 0.76751965 <a title="1601-lda-12" href="../high_scalability-2011/high_scalability-2011-01-06-BankSimple_Mini-Architecture_-_Using_a_Next_Generation_Toolchain.html">970 high scalability-2011-01-06-BankSimple Mini-Architecture - Using a Next Generation Toolchain</a></p>
<p>13 0.75821519 <a title="1601-lda-13" href="../high_scalability-2012/high_scalability-2012-04-06-Stuff_The_Internet_Says_On_Scalability_For_April_6%2C_2012.html">1223 high scalability-2012-04-06-Stuff The Internet Says On Scalability For April 6, 2012</a></p>
<p>14 0.75786835 <a title="1601-lda-14" href="../high_scalability-2013/high_scalability-2013-02-25-SongPop_Scales_to_1_Million_Active_Users_on_GAE%2C_Showing_PaaS_is_not_Pass%C3%A9.html">1412 high scalability-2013-02-25-SongPop Scales to 1 Million Active Users on GAE, Showing PaaS is not Passé</a></p>
<p>15 0.75321192 <a title="1601-lda-15" href="../high_scalability-2011/high_scalability-2011-07-22-Stuff_The_Internet_Says_On_Scalability_For_July_22%2C_2011.html">1084 high scalability-2011-07-22-Stuff The Internet Says On Scalability For July 22, 2011</a></p>
<p>16 0.74752003 <a title="1601-lda-16" href="../high_scalability-2007/high_scalability-2007-09-01-2_tier_switch_selection_for_colocation.html">78 high scalability-2007-09-01-2 tier switch selection for colocation</a></p>
<p>17 0.73826939 <a title="1601-lda-17" href="../high_scalability-2010/high_scalability-2010-05-14-Hot_Scalability_Links_for_May_14%2C_2010.html">827 high scalability-2010-05-14-Hot Scalability Links for May 14, 2010</a></p>
<p>18 0.73174739 <a title="1601-lda-18" href="../high_scalability-2011/high_scalability-2011-04-14-Strategy%3A_Cache_Application_Start_State_to_Reduce_Spin-up_Times.html">1023 high scalability-2011-04-14-Strategy: Cache Application Start State to Reduce Spin-up Times</a></p>
<p>19 0.70829737 <a title="1601-lda-19" href="../high_scalability-2012/high_scalability-2012-01-13-Stuff_The_Internet_Says_On_Scalability_For_January_13%2C_2012.html">1174 high scalability-2012-01-13-Stuff The Internet Says On Scalability For January 13, 2012</a></p>
<p>20 0.70414662 <a title="1601-lda-20" href="../high_scalability-2008/high_scalability-2008-03-04-Manage_Downtime_Risk_by_Connecting_Multiple_Data_Centers_into_a_Secure_Virtual_LAN.html">266 high scalability-2008-03-04-Manage Downtime Risk by Connecting Multiple Data Centers into a Secure Virtual LAN</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
