<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>912 high scalability-2010-10-01-Google Paper: Large-scale Incremental Processing Using Distributed Transactions and Notifications</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2010" href="../home/high_scalability-2010_home.html">high_scalability-2010</a> <a title="high_scalability-2010-912" href="#">high_scalability-2010-912</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>912 high scalability-2010-10-01-Google Paper: Large-scale Incremental Processing Using Distributed Transactions and Notifications</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2010-912-html" href="http://highscalability.com//blog/2010/10/1/google-paper-large-scale-incremental-processing-using-distri.html">html</a></p><p>Introduction: This paper, Large-scale Incremental Processing Using Distributed Transactions
and Notifications by Daniel Peng and Frank Dabek, is Google's much anticipated
description of Percolator, their new real-time indexing system.The
abstract:Updating an index of the web as documents are crawled requires
continuously transforming a large repository of existing documents as new
documents arrive. This task is one example of a class of data processing tasks
that transform a large repository of data via small, independent mutations.
These tasks lie in a gap between the capabilities of existing infrastructure.
Databases do not meet the storage or throughput requirements of these tasks:
Google's indexing system stores tens of petabytes of data and processes
billions of updates per day on thousands of machines. MapReduce and other
batch-processing systems cannot process small updates individually as they
rely on creating large batches for efďŹ ciency. We have built Percolator, a
system for incrementally</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This paper, Large-scale Incremental Processing Using Distributed Transactions and Notifications by Daniel Peng and Frank Dabek, is Google's much anticipated description of Percolator, their new real-time indexing system. [sent-1, score-0.491]
</p><p>2 The abstract:Updating an index of the web as documents are crawled requires continuously transforming a large repository of existing documents as new documents arrive. [sent-2, score-1.96]
</p><p>3 This task is one example of a class of data processing tasks that transform a large repository of data via small, independent mutations. [sent-3, score-0.969]
</p><p>4 These tasks lie in a gap between the capabilities of existing infrastructure. [sent-4, score-0.586]
</p><p>5 Databases do not meet the storage or throughput requirements of these tasks: Google's indexing system stores tens of petabytes of data and processes billions of updates per day on thousands of machines. [sent-5, score-1.042]
</p><p>6 MapReduce and other batch-processing systems cannot process small updates individually as they rely on creating large batches for efďŹ ciency. [sent-6, score-0.727]
</p><p>7 We have built Percolator, a system for incrementally processing updates to a large data set, and deployed it to create the Google web search index. [sent-7, score-0.772]
</p><p>8 By replacing a batch-based indexing system with an indexing system based on incremental processing using Percolator, we process the same number of documents per day, while reducing the average age of documents in Google search results by 50%. [sent-8, score-2.237]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('percolator', 0.445), ('documents', 0.387), ('indexing', 0.294), ('repository', 0.21), ('tasks', 0.186), ('updates', 0.18), ('incremental', 0.17), ('processing', 0.169), ('google', 0.14), ('anticipated', 0.138), ('frank', 0.131), ('crawled', 0.131), ('lie', 0.123), ('individually', 0.119), ('ef', 0.119), ('transforming', 0.111), ('batches', 0.11), ('gap', 0.109), ('daniel', 0.106), ('large', 0.102), ('existing', 0.102), ('transform', 0.099), ('incrementally', 0.096), ('replacing', 0.092), ('updating', 0.09), ('notifications', 0.089), ('search', 0.088), ('tens', 0.086), ('petabytes', 0.085), ('age', 0.083), ('abstract', 0.081), ('continuously', 0.08), ('rely', 0.078), ('day', 0.074), ('billions', 0.073), ('reducing', 0.072), ('small', 0.071), ('deployed', 0.07), ('independent', 0.07), ('task', 0.067), ('system', 0.067), ('process', 0.067), ('capabilities', 0.066), ('class', 0.066), ('meet', 0.063), ('index', 0.063), ('stores', 0.061), ('mapreduce', 0.061), ('requirements', 0.059), ('description', 0.059)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="912-tfidf-1" href="../high_scalability-2010/high_scalability-2010-10-01-Google_Paper%3A_Large-scale_Incremental_Processing_Using_Distributed_Transactions_and_Notifications.html">912 high scalability-2010-10-01-Google Paper: Large-scale Incremental Processing Using Distributed Transactions and Notifications</a></p>
<p>Introduction: This paper, Large-scale Incremental Processing Using Distributed Transactions
and Notifications by Daniel Peng and Frank Dabek, is Google's much anticipated
description of Percolator, their new real-time indexing system.The
abstract:Updating an index of the web as documents are crawled requires
continuously transforming a large repository of existing documents as new
documents arrive. This task is one example of a class of data processing tasks
that transform a large repository of data via small, independent mutations.
These tasks lie in a gap between the capabilities of existing infrastructure.
Databases do not meet the storage or throughput requirements of these tasks:
Google's indexing system stores tens of petabytes of data and processes
billions of updates per day on thousands of machines. MapReduce and other
batch-processing systems cannot process small updates individually as they
rely on creating large batches for efďŹ ciency. We have built Percolator, a
system for incrementally</p><p>2 0.14400998 <a title="912-tfidf-2" href="../high_scalability-2008/high_scalability-2008-05-28-Job_queue_and_search_engine.html">332 high scalability-2008-05-28-Job queue and search engine</a></p>
<p>Introduction: Hi,I want to implement a search engine with lucene.To be scalable, I would
like to execute search jobs asynchronously (with a job queuing system).But i
don't know if it is a good design... Why ?Search results can be large ! (eg:
100+ pages with 25 documents per page)With asynchronous sytem, I need to store
results for each search job.I can set a short expiration time (~5 min) for
each search result, but it's still large.What do you think about it ?Which
design would you use for that ?ThanksMat</p><p>3 0.12286037 <a title="912-tfidf-3" href="../high_scalability-2012/high_scalability-2012-04-25-The_Anatomy_of_Search_Technology%3A_blekko%E2%80%99s_NoSQL_database.html">1233 high scalability-2012-04-25-The Anatomy of Search Technology: blekko’s NoSQL database</a></p>
<p>Introduction: This is a guest post (part 2,part 3) by Greg Lindahl, CTO of blekko, the spam
free search engine that had over 3.5 million unique visitors in March. Greg
Lindahl was Founder and Distinguished Engineer at PathScale, at which he was
the architect of the InfiniPath low-latency InfiniBand HCA, used to build
tightly-coupled supercomputing clusters.Imagine that you're crazy enough to
think about building a search engine.  It's a huge task: the minimum index
size needed to answer most queries is a few billion webpages. Crawling and
indexing a few billion webpages requires a cluster with several petabytes of
usable disk -- that's several thousand 1 terabyte disks -- and produces an
index that's about 100 terabytes in size.Serving query results quickly
involves having most of the index in RAM or on solid state (flash) disk. If
you can buy a server with 100 gigabytes of RAM for about $3,000, that's 1,000
servers at a capital cost of $3 million, plus about $1 million per year of
server co-locatio</p><p>4 0.11841808 <a title="912-tfidf-4" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>Introduction: Update 2:Sorting 1 PB with MapReduce. PB is not peanut-butter-and-jelly
misspelled. It's 1 petabyte or 1000 terabytes or 1,000,000 gigabytes.It took
six hours and two minutes to sort 1PB (10 trillion 100-byte records) on 4,000
computersand the results were replicated thrice on 48,000 disks.Update:Greg
Lindenpoints to a new Google articleMapReduce: simplified data processing on
large clusters. Some interesting stats: 100k MapReduce jobs are executed each
day; more than 20 petabytes of data are processed per day; more than 10k
MapReduce programs have been implemented; machines are dual processor with
gigabit ethernet and 4-8 GB of memory.Google is the King of scalability.
Everyone knows Google for their large, sophisticated, and fast searching, but
they don't just shine in search. Their platform approach to building scalable
applications allows them to roll out internet scale applications at an
alarmingly high competition crushing rate. Their goal is always to build a
higher performing h</p><p>5 0.11676371 <a title="912-tfidf-5" href="../high_scalability-2013/high_scalability-2013-09-09-Need_Help_with_Database_Scalability%3F_Understand_I-O.html">1514 high scalability-2013-09-09-Need Help with Database Scalability? Understand I-O</a></p>
<p>Introduction: This is a guest post byZardosht Kasheff, Software Developer atTokutek, a
storage engine company that delivers 21st-Century capabilities to the leading
open source data management platforms.As software developers, we value
abstraction. The simpler the API, the more attractive it becomes. Arguably,
MongoDB's greatest strengths are its elegant API and itsagility, which let
developers simply code.But whenMongoDBruns into scalability problems onbig
data, developers need to peek underneath the covers to understand the
underlying issues and how to fix them. Without understanding, one may end up
with an inefficient solution that costs time and money. For example, one may
shard prematurely, increasing hardware and management costs, when a simpler
replication setup would do. Or, one may increase the size of a replica set
when upgrading to SSDs would suffice.This article showshow to reason about
some big data scalability problemsin an effort to find efficient
solutions.Defining the IssuesFirst, l</p><p>6 0.1166568 <a title="912-tfidf-6" href="../high_scalability-2008/high_scalability-2008-01-13-Google_Reveals_New_MapReduce_Stats.html">211 high scalability-2008-01-13-Google Reveals New MapReduce Stats</a></p>
<p>7 0.11646044 <a title="912-tfidf-7" href="../high_scalability-2012/high_scalability-2012-08-28-Making_Hadoop_Run_Faster.html">1313 high scalability-2012-08-28-Making Hadoop Run Faster</a></p>
<p>8 0.11640717 <a title="912-tfidf-8" href="../high_scalability-2014/high_scalability-2014-03-07-Stuff_The_Internet_Says_On_Scalability_For_March_7th%2C_2014.html">1607 high scalability-2014-03-07-Stuff The Internet Says On Scalability For March 7th, 2014</a></p>
<p>9 0.11486196 <a title="912-tfidf-9" href="../high_scalability-2009/high_scalability-2009-11-26-Kngine_Snippet_Search_New_Indexing_Technology.html">746 high scalability-2009-11-26-Kngine Snippet Search New Indexing Technology</a></p>
<p>10 0.11006317 <a title="912-tfidf-10" href="../high_scalability-2011/high_scalability-2011-08-29-The_Three_Ages_of_Google_-_Batch%2C_Warehouse%2C_Instant.html">1107 high scalability-2011-08-29-The Three Ages of Google - Batch, Warehouse, Instant</a></p>
<p>11 0.10079539 <a title="912-tfidf-11" href="../high_scalability-2009/high_scalability-2009-01-04-Paper%3A_MapReduce%3A_Simplified_Data_Processing_on_Large_Clusters.html">483 high scalability-2009-01-04-Paper: MapReduce: Simplified Data Processing on Large Clusters</a></p>
<p>12 0.10052456 <a title="912-tfidf-12" href="../high_scalability-2010/high_scalability-2010-04-14-Parallel_Information_Retrieval_and_Other_Search_Engine_Goodness.html">810 high scalability-2010-04-14-Parallel Information Retrieval and Other Search Engine Goodness</a></p>
<p>13 0.099742539 <a title="912-tfidf-13" href="../high_scalability-2011/high_scalability-2011-07-11-ATMCash_Exploits_Virtualization_for_Security_-_Immutability_and_Reversion.html">1077 high scalability-2011-07-11-ATMCash Exploits Virtualization for Security - Immutability and Reversion</a></p>
<p>14 0.096281633 <a title="912-tfidf-14" href="../high_scalability-2010/high_scalability-2010-09-09-How_did_Google_Instant_become_Faster_with_5-7X_More_Results_Pages%3F.html">899 high scalability-2010-09-09-How did Google Instant become Faster with 5-7X More Results Pages?</a></p>
<p>15 0.096071929 <a title="912-tfidf-15" href="../high_scalability-2009/high_scalability-2009-07-30-Learn_How_to_Think_at_Scale.html">666 high scalability-2009-07-30-Learn How to Think at Scale</a></p>
<p>16 0.092745222 <a title="912-tfidf-16" href="../high_scalability-2009/high_scalability-2009-12-22-Incremental_deployment.html">754 high scalability-2009-12-22-Incremental deployment</a></p>
<p>17 0.09141735 <a title="912-tfidf-17" href="../high_scalability-2010/high_scalability-2010-02-10-ElasticSearch_-_Open_Source%2C_Distributed%2C_RESTful_Search_Engine.html">775 high scalability-2010-02-10-ElasticSearch - Open Source, Distributed, RESTful Search Engine</a></p>
<p>18 0.090135723 <a title="912-tfidf-18" href="../high_scalability-2009/high_scalability-2009-12-30-Terrastore_-_Scalable%2C_elastic%2C_consistent_document_store..html">756 high scalability-2009-12-30-Terrastore - Scalable, elastic, consistent document store.</a></p>
<p>19 0.089357562 <a title="912-tfidf-19" href="../high_scalability-2009/high_scalability-2009-08-07-The_Canonical_Cloud_Architecture_.html">674 high scalability-2009-08-07-The Canonical Cloud Architecture </a></p>
<p>20 0.082233839 <a title="912-tfidf-20" href="../high_scalability-2010/high_scalability-2010-08-18-Misco%3A_A_MapReduce_Framework_for_Mobile_Systems_-_Start_of_the_Ambient_Cloud%3F.html">882 high scalability-2010-08-18-Misco: A MapReduce Framework for Mobile Systems - Start of the Ambient Cloud?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.118), (1, 0.072), (2, 0.004), (3, 0.04), (4, 0.006), (5, 0.062), (6, 0.044), (7, 0.031), (8, 0.018), (9, 0.08), (10, 0.015), (11, -0.018), (12, 0.016), (13, -0.06), (14, 0.049), (15, 0.05), (16, -0.11), (17, -0.059), (18, 0.094), (19, -0.003), (20, 0.085), (21, -0.023), (22, 0.019), (23, -0.046), (24, 0.001), (25, -0.013), (26, -0.063), (27, 0.046), (28, -0.035), (29, 0.093), (30, 0.025), (31, 0.055), (32, -0.031), (33, 0.005), (34, 0.013), (35, -0.009), (36, 0.008), (37, -0.025), (38, -0.011), (39, 0.015), (40, 0.051), (41, -0.023), (42, 0.004), (43, 0.002), (44, -0.034), (45, 0.033), (46, -0.053), (47, -0.049), (48, 0.044), (49, -0.092)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96440238 <a title="912-lsi-1" href="../high_scalability-2010/high_scalability-2010-10-01-Google_Paper%3A_Large-scale_Incremental_Processing_Using_Distributed_Transactions_and_Notifications.html">912 high scalability-2010-10-01-Google Paper: Large-scale Incremental Processing Using Distributed Transactions and Notifications</a></p>
<p>Introduction: This paper, Large-scale Incremental Processing Using Distributed Transactions
and Notifications by Daniel Peng and Frank Dabek, is Google's much anticipated
description of Percolator, their new real-time indexing system.The
abstract:Updating an index of the web as documents are crawled requires
continuously transforming a large repository of existing documents as new
documents arrive. This task is one example of a class of data processing tasks
that transform a large repository of data via small, independent mutations.
These tasks lie in a gap between the capabilities of existing infrastructure.
Databases do not meet the storage or throughput requirements of these tasks:
Google's indexing system stores tens of petabytes of data and processes
billions of updates per day on thousands of machines. MapReduce and other
batch-processing systems cannot process small updates individually as they
rely on creating large batches for efďŹ ciency. We have built Percolator, a
system for incrementally</p><p>2 0.8011114 <a title="912-lsi-2" href="../high_scalability-2010/high_scalability-2010-04-14-Parallel_Information_Retrieval_and_Other_Search_Engine_Goodness.html">810 high scalability-2010-04-14-Parallel Information Retrieval and Other Search Engine Goodness</a></p>
<p>Introduction: Parallel Information Retrievalis a sample chapter in what appears to be a
book-in-progress titledInformation Retrieval Implementing and Evaluation
Search EnginesbyStefan Buttcher, Google Inc andCharles L. A. Clarke,Gordon V.
Cormack, both of the University of Waterloo. The full table of contents is on-
line and looks to be really interesting:Information retrieval is the
foundation for modern search engines. This text offers an introduction to the
core topics underlying modern search technologies, including algorithms, data
structures, indexing, retrieval, and evaluation. The emphasis is on
implementation and experimentation; each chapter includes exercises and
suggestions for student projects.Currently available is the full text of
chapters: Introduction, Basic Techniques, Static Inverted Indices, Index
Compression, and Parallel Information Retrieval. Parallel Information
Retrieval is really meaty:Information retrieval systems often have to deal
with very large amounts of data. They mu</p><p>3 0.78468513 <a title="912-lsi-3" href="../high_scalability-2009/high_scalability-2009-01-04-Paper%3A_MapReduce%3A_Simplified_Data_Processing_on_Large_Clusters.html">483 high scalability-2009-01-04-Paper: MapReduce: Simplified Data Processing on Large Clusters</a></p>
<p>Introduction: Update:MapReduce and PageRank Notes from Remzi Arpaci-Dusseau's Fall 2008
class. Collects interesting facts about MapReduce and PageRank. For example,
the history of the solution to searching for the term "flu" is traced through
multiple generations of technology.With Google entering the cloud space
withGoogle AppEngineand a maturingHadoopproduct, the MapReduce scaling
approach might finally become a standard programmer practice. This is the best
paper on the subject and is an excellent primer on a content-addressable
memory future.Some interesting stats from the paper: Google executes 100k
MapReduce jobs each day; more than 20 petabytes of data are processed per day;
more than 10k MapReduce programs have been implemented; machines are dual
processor with gigabit ethernet and 4-8 GB of memory.One common criticism ex-
Googlers have is that it takes months to get up and be productive in the
Google environment. Hopefully a way will be found to lower the learning curve
and make programmers</p><p>4 0.77259326 <a title="912-lsi-4" href="../high_scalability-2010/high_scalability-2010-09-09-How_did_Google_Instant_become_Faster_with_5-7X_More_Results_Pages%3F.html">899 high scalability-2010-09-09-How did Google Instant become Faster with 5-7X More Results Pages?</a></p>
<p>Introduction: We don't have a lot of details on how Google pulled off their technically very
impressive Google Instant release, but inGoogle Instant behind the scenes,
they did share some interesting facts:Google was serving more than a billion
searches per day.With Google Instant they served 5-7X more results pages than
previously.Typical search results were returned in less than a quarter of
second.A team of 50+ worked on the project for an extended period of
time.AlthoughGoogleis associated with muscular data centers, they just didn't
throw more server capacity at the problem, they worked smarter too. What were
their general strategies?Increase backend server capacity.Add new caches to
handle high request rates while keeping results fresh while the web is
continuously crawled and re-indexed.Add User-state data to the back-ends to
keep track of the results pages already shown to a given user, preventing the
same results from being re-fetched repeatedly.Optimize page-rendering
JavaScript code to he</p><p>5 0.74593282 <a title="912-lsi-5" href="../high_scalability-2010/high_scalability-2010-08-04-Dremel%3A_Interactive_Analysis_of_Web-Scale_Datasets_-_Data_as_a_Programming_Paradigm.html">871 high scalability-2010-08-04-Dremel: Interactive Analysis of Web-Scale Datasets - Data as a Programming Paradigm</a></p>
<p>Introduction: If Google was a boxer then MapReduce would be a probing right hand that sets
up the massive left hook that is Dremel, Google's--scalable (thousands of
CPUs, petabytes of data, trillions of rows), SQL based, columnar, interactive
(results returned in seconds), ad-hoc--analytics system. If Google was a
magician then MapReduce would be the shiny thing that distracts the mind while
the trick goes unnoticed. I say that because even though Dremel has been
around internally at Google since 2006, we have not heard a whisper about it.
All we've heard about is MapReduce, clones of which have inspired entire new
industries.Tricky.Dremel, according to Brian Bershad, Director of Engineering
at Google, is targeted at solvingBigData class problems:While we all know that
systems are huge and will get even huger, the implications of this size on
programmability, manageability, power, etc. is hard to comprehend. Alfred
noted that the Internet is predicted to be carrying a zetta-byte (1021bytes)
per year</p><p>6 0.69571126 <a title="912-lsi-6" href="../high_scalability-2008/high_scalability-2008-01-13-Google_Reveals_New_MapReduce_Stats.html">211 high scalability-2008-01-13-Google Reveals New MapReduce Stats</a></p>
<p>7 0.67455691 <a title="912-lsi-7" href="../high_scalability-2009/high_scalability-2009-06-14-kngine_%27Knowledge_Engine%27_milestone_2.html">630 high scalability-2009-06-14-kngine 'Knowledge Engine' milestone 2</a></p>
<p>8 0.67215908 <a title="912-lsi-8" href="../high_scalability-2013/high_scalability-2013-10-21-Google%27s_Sanjay_Ghemawat_on_What_Made_Google_Google_and_Great_Big_Data_Career_Advice.html">1535 high scalability-2013-10-21-Google's Sanjay Ghemawat on What Made Google Google and Great Big Data Career Advice</a></p>
<p>9 0.67034137 <a title="912-lsi-9" href="../high_scalability-2008/high_scalability-2008-05-28-Job_queue_and_search_engine.html">332 high scalability-2008-05-28-Job queue and search engine</a></p>
<p>10 0.65663582 <a title="912-lsi-10" href="../high_scalability-2011/high_scalability-2011-08-29-The_Three_Ages_of_Google_-_Batch%2C_Warehouse%2C_Instant.html">1107 high scalability-2011-08-29-The Three Ages of Google - Batch, Warehouse, Instant</a></p>
<p>11 0.64480096 <a title="912-lsi-11" href="../high_scalability-2010/high_scalability-2010-09-11-Google%27s_Colossus_Makes_Search_Real-time_by_Dumping_MapReduce.html">900 high scalability-2010-09-11-Google's Colossus Makes Search Real-time by Dumping MapReduce</a></p>
<p>12 0.63372546 <a title="912-lsi-12" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>13 0.63168555 <a title="912-lsi-13" href="../high_scalability-2010/high_scalability-2010-04-27-Paper%3A__Dapper%2C_Google%27s_Large-Scale_Distributed_Systems_Tracing_Infrastructure.html">815 high scalability-2010-04-27-Paper:  Dapper, Google's Large-Scale Distributed Systems Tracing Infrastructure</a></p>
<p>14 0.61897755 <a title="912-lsi-14" href="../high_scalability-2009/high_scalability-2009-11-26-Kngine_Snippet_Search_New_Indexing_Technology.html">746 high scalability-2009-11-26-Kngine Snippet Search New Indexing Technology</a></p>
<p>15 0.61834639 <a title="912-lsi-15" href="../high_scalability-2008/high_scalability-2008-09-03-MapReduce_framework_Disco.html">376 high scalability-2008-09-03-MapReduce framework Disco</a></p>
<p>16 0.60741544 <a title="912-lsi-16" href="../high_scalability-2013/high_scalability-2013-09-05-Paper%3A_MillWheel%3A_Fault-Tolerant_Stream_Processing_at_Internet_Scale.html">1512 high scalability-2013-09-05-Paper: MillWheel: Fault-Tolerant Stream Processing at Internet Scale</a></p>
<p>17 0.60531193 <a title="912-lsi-17" href="../high_scalability-2007/high_scalability-2007-08-28-Google_Utilities_%3A_An_online_google_guide%2Ctools_and_Utilities..html">75 high scalability-2007-08-28-Google Utilities : An online google guide,tools and Utilities.</a></p>
<p>18 0.60221231 <a title="912-lsi-18" href="../high_scalability-2009/high_scalability-2009-06-20-Building_a_data_cycle_at_LinkedIn_with_Hadoop_and_Project_Voldemort.html">634 high scalability-2009-06-20-Building a data cycle at LinkedIn with Hadoop and Project Voldemort</a></p>
<p>19 0.60093904 <a title="912-lsi-19" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>20 0.59985662 <a title="912-lsi-20" href="../high_scalability-2012/high_scalability-2012-04-25-The_Anatomy_of_Search_Technology%3A_blekko%E2%80%99s_NoSQL_database.html">1233 high scalability-2012-04-25-The Anatomy of Search Technology: blekko’s NoSQL database</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.079), (2, 0.148), (9, 0.153), (10, 0.026), (61, 0.187), (76, 0.034), (79, 0.181), (85, 0.065)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.91949171 <a title="912-lda-1" href="../high_scalability-2010/high_scalability-2010-10-01-Google_Paper%3A_Large-scale_Incremental_Processing_Using_Distributed_Transactions_and_Notifications.html">912 high scalability-2010-10-01-Google Paper: Large-scale Incremental Processing Using Distributed Transactions and Notifications</a></p>
<p>Introduction: This paper, Large-scale Incremental Processing Using Distributed Transactions
and Notifications by Daniel Peng and Frank Dabek, is Google's much anticipated
description of Percolator, their new real-time indexing system.The
abstract:Updating an index of the web as documents are crawled requires
continuously transforming a large repository of existing documents as new
documents arrive. This task is one example of a class of data processing tasks
that transform a large repository of data via small, independent mutations.
These tasks lie in a gap between the capabilities of existing infrastructure.
Databases do not meet the storage or throughput requirements of these tasks:
Google's indexing system stores tens of petabytes of data and processes
billions of updates per day on thousands of machines. MapReduce and other
batch-processing systems cannot process small updates individually as they
rely on creating large batches for efďŹ ciency. We have built Percolator, a
system for incrementally</p><p>2 0.85949183 <a title="912-lda-2" href="../high_scalability-2013/high_scalability-2013-05-22-Strategy%3A_Stop_Using_Linked-Lists.html">1462 high scalability-2013-05-22-Strategy: Stop Using Linked-Lists</a></p>
<p>Introduction: What data structure is more sacred than the link list? If we get rid of it
what silly interview questions would we use instead? But not using linked-
lists is exactly what Aater Suleman recommends inShould you ever use Linked-
Lists?InThe Secret To 10 Million Concurrent Connectionsone of the important
strategies is not scribbling data all over memory via pointers because
following pointers increases cache misses whichreduces performance. And
there's nothing more iconic of pointers than the link list.Here are Aeter's
reasons to be anti-linked-list:They reduce the benefit of out-of-order
execution.They throw off hardware prefetching.They reduce DRAM and TLB
locality.They cannot leverage SIMD.They are harder to send to GPUs.He also
demolishes the pros of linked-lists, finding arrays a better option in almost
every case. Good discussion in the comment section as not everyone
agrees.Patrick Wyatt detailshow a linked-list threading bugrepeatedly crashed
Starcraft. Also a good comment discuss</p><p>3 0.84690529 <a title="912-lda-3" href="../high_scalability-2009/high_scalability-2009-11-09-10_NoSQL_Systems_Reviewed.html">739 high scalability-2009-11-09-10 NoSQL Systems Reviewed</a></p>
<p>Introduction: Jonathan Ellis reviews in theNoSQL Ecosystem the origin of the NoSQL movement
and 10 different NoSQL products and how their 1) support for multiple
datacenters,  2) the ability to add new machines to a live cluster
transparently to the your applications, 3) Data Model, 4) Query API, 5)
Persistence Design. The 10 systems reviewed are: Cassandra, CouchDB, HBase,
MongoDB, Neo4J, Redis, Riak, Scalaris, Tokyo Cabinet, Voldemort.A very
thorough and thoughtful article on the entire NoSQL space. It's clear from the
article that NoSQL is not monolithic, there is a very wide variety of
approaches to not being a relational database.Related ArticlesNOSQL = Not Only
SQL?. Google Groups thread on talking about the appropriateness of NoSQL as a
label.The "NoSQL" Discussion has Nothing to Do With SQL by Michael
Stonebraker.HBase vs. Cassandra: NoSQL Battle! by Bradford.Predictions on the
future of NoSQL by Aleksander Kmetec.</p><p>4 0.84490991 <a title="912-lda-4" href="../high_scalability-2012/high_scalability-2012-05-09-Cell_Architectures.html">1242 high scalability-2012-05-09-Cell Architectures</a></p>
<p>Introduction: A consequence of Service Oriented Architectures is the burning need to provide
services at scale. The architecture that has evolved to satisfy these
requirements is a little known technique called the Cell Architecture.A Cell
Architecture is based on the idea that massive scale requires parallelization
and parallelization requires components be isolated from each other. These
islands of isolation are called cells. A cell is a self-contained installation
that can satisfy all the operations for a shard. A shard is a subset of a much
larger dataset, typically a range of users, for example. Cell Architectures
have several advantages:Cells provide a unit of parallelization that can be
adjusted to any size as the user base grows.Cell are added in an incremental
fashion as more capacity is required.Cells isolate failures. One cell failure
does not impact other cells.Cells provide isolation as the storage and
application horsepower to process requests is independent of other cells.Cells
enable</p><p>5 0.84149891 <a title="912-lda-5" href="../high_scalability-2009/high_scalability-2009-04-08-N%2B1%2Bcaching_is_ok%3F.html">561 high scalability-2009-04-08-N+1+caching is ok?</a></p>
<p>Introduction: Hibernate and iBATIS and other similar tools have documentation with
recommendations for avoiding the "N+1 select" problem. The problem being that
if you wanted to retrieve a set of widgets from a table, one query would be
used to to retrieve all the ids of the matching widgets (select widget_id from
widget where ...) and then for each id, another select is used to retrieve the
details of that widget (select * from widget where widget_id = ?). If you have
100 widgets, it requires 101 queries to get the details of them all.I can see
why this is bad, but what if you're doing entity caching? i.e. If you run the
first query to get your list of ids, and then for each widget you retrive it
from the cache. Surely in that case, N+1(+caching) is good? Assuming of course
that there is a high probability of all of the matching entities being in the
cache.I may be asking a daft question here - one whose answer is obviously
implied by the large scalable mechanisms for storing data that are in use
t</p><p>6 0.8336516 <a title="912-lda-6" href="../high_scalability-2013/high_scalability-2013-10-21-Google%27s_Sanjay_Ghemawat_on_What_Made_Google_Google_and_Great_Big_Data_Career_Advice.html">1535 high scalability-2013-10-21-Google's Sanjay Ghemawat on What Made Google Google and Great Big Data Career Advice</a></p>
<p>7 0.82688189 <a title="912-lda-7" href="../high_scalability-2011/high_scalability-2011-11-14-Using_Gossip_Protocols_for_Failure_Detection%2C_Monitoring%2C_Messaging_and_Other_Good_Things.html">1142 high scalability-2011-11-14-Using Gossip Protocols for Failure Detection, Monitoring, Messaging and Other Good Things</a></p>
<p>8 0.82652867 <a title="912-lda-8" href="../high_scalability-2008/high_scalability-2008-03-03-Two_data_streams_for_a_happy_website.html">265 high scalability-2008-03-03-Two data streams for a happy website</a></p>
<p>9 0.82590806 <a title="912-lda-9" href="../high_scalability-2011/high_scalability-2011-12-08-Update_on_Scalable_Causal_Consistency_For_Wide-Area_Storage_With_COPS.html">1153 high scalability-2011-12-08-Update on Scalable Causal Consistency For Wide-Area Storage With COPS</a></p>
<p>10 0.82388335 <a title="912-lda-10" href="../high_scalability-2008/high_scalability-2008-03-18-Shared_filesystem_on_EC2.html">283 high scalability-2008-03-18-Shared filesystem on EC2</a></p>
<p>11 0.82380021 <a title="912-lda-11" href="../high_scalability-2012/high_scalability-2012-05-21-Pinterest_Architecture_Update_-_18_Million_Visitors%2C_10x_Growth%2C12_Employees%2C_410_TB_of_Data.html">1248 high scalability-2012-05-21-Pinterest Architecture Update - 18 Million Visitors, 10x Growth,12 Employees, 410 TB of Data</a></p>
<p>12 0.82253832 <a title="912-lda-12" href="../high_scalability-2012/high_scalability-2012-10-10-Antirez%3A_You_Need_to_Think_in_Terms_of_Organizing_Your_Data_for_Fetching.html">1337 high scalability-2012-10-10-Antirez: You Need to Think in Terms of Organizing Your Data for Fetching</a></p>
<p>13 0.82062799 <a title="912-lda-13" href="../high_scalability-2008/high_scalability-2008-01-25-Application_Database_and_DAL_Architecture.html">222 high scalability-2008-01-25-Application Database and DAL Architecture</a></p>
<p>14 0.81925219 <a title="912-lda-14" href="../high_scalability-2009/high_scalability-2009-05-20-Paper%3A_Flux%3A_An_Adaptive_Partitioning_Operator_for_Continuous_Query_Systems.html">604 high scalability-2009-05-20-Paper: Flux: An Adaptive Partitioning Operator for Continuous Query Systems</a></p>
<p>15 0.8175844 <a title="912-lda-15" href="../high_scalability-2007/high_scalability-2007-12-01-many_website%2C_one_setup%2C_many_databases.html">169 high scalability-2007-12-01-many website, one setup, many databases</a></p>
<p>16 0.81540561 <a title="912-lda-16" href="../high_scalability-2013/high_scalability-2013-05-20-The_Tumblr_Architecture_Yahoo_Bought_for_a_Cool_Billion_Dollars.html">1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</a></p>
<p>17 0.81519949 <a title="912-lda-17" href="../high_scalability-2013/high_scalability-2013-01-16-What_if_Cars_Were_Rented_Like_We_Hire_Programmers%3F.html">1388 high scalability-2013-01-16-What if Cars Were Rented Like We Hire Programmers?</a></p>
<p>18 0.81485355 <a title="912-lda-18" href="../high_scalability-2012/high_scalability-2012-02-13-Tumblr_Architecture_-_15_Billion_Page_Views_a_Month_and_Harder_to_Scale_than_Twitter.html">1191 high scalability-2012-02-13-Tumblr Architecture - 15 Billion Page Views a Month and Harder to Scale than Twitter</a></p>
<p>19 0.81485301 <a title="912-lda-19" href="../high_scalability-2012/high_scalability-2012-11-19-Gone_Fishin%27%3A_Tumblr_Architecture_-_15_Billion_Page_Views_A_Month_And_Harder_To_Scale_Than_Twitter.html">1360 high scalability-2012-11-19-Gone Fishin': Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a></p>
<p>20 0.80983126 <a title="912-lda-20" href="../high_scalability-2013/high_scalability-2013-02-22-Stuff_The_Internet_Says_On_Scalability_For_February_22%2C_2013.html">1411 high scalability-2013-02-22-Stuff The Internet Says On Scalability For February 22, 2013</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
