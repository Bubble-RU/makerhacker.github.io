<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2010" href="../home/high_scalability-2010_home.html">high_scalability-2010</a> <a title="high_scalability-2010-943" href="#">high_scalability-2010-943</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2010-943-html" href="http://highscalability.com//blog/2010/11/16/facebooks-new-real-time-messaging-system-hbase-to-store-135.html">html</a></p><p>Introduction: You may have read somewhere that Facebook has introduced a newSocial Inbox
integrating email, IM, SMS,  text messages, on-site Facebook messages. All-in-
all they need to store over 135 billion messages a month. Where do they store
all that stuff? Facebook's Kannan Muthukkaruppan gives the surprise answer
inThe Underlying Technology of Messages:HBase. HBase beat out MySQL,
Cassandra, and a few others.Why a surprise? Facebook created Cassandra and it
was purpose built for an inbox type application, but they found Cassandra's
eventual consistency model wasn't a good match for their new real-time
Messages product. Facebook also has an extensiveMySQL infrastructure, but they
found performance suffered as data set and indexes grew larger. And they could
have built their own, but they chose HBase.HBase is ascaleout table store
supporting very high rates of row-level updates over massive amounts of data.
Exactly what is needed for a Messaging system. HBase is also a column based
key-value sto</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hbase', 0.536), ('facebook', 0.257), ('inbox', 0.197), ('messages', 0.175), ('hdfs', 0.167), ('chose', 0.151), ('lars', 0.148), ('sms', 0.145), ('cassandra', 0.129), ('surprise', 0.124), ('store', 0.114), ('hive', 0.11), ('rarely', 0.106), ('chat', 0.1), ('hadoop', 0.096), ('carl', 0.09), ('standardize', 0.09), ('hbaseby', 0.09), ('rows', 0.089), ('decisions', 0.084)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="943-tfidf-1" href="../high_scalability-2010/high_scalability-2010-11-16-Facebook%27s_New_Real-time_Messaging_System%3A_HBase_to_Store_135%2B_Billion_Messages_a_Month.html">943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</a></p>
<p>Introduction: You may have read somewhere that Facebook has introduced a newSocial Inbox
integrating email, IM, SMS,  text messages, on-site Facebook messages. All-in-
all they need to store over 135 billion messages a month. Where do they store
all that stuff? Facebook's Kannan Muthukkaruppan gives the surprise answer
inThe Underlying Technology of Messages:HBase. HBase beat out MySQL,
Cassandra, and a few others.Why a surprise? Facebook created Cassandra and it
was purpose built for an inbox type application, but they found Cassandra's
eventual consistency model wasn't a good match for their new real-time
Messages product. Facebook also has an extensiveMySQL infrastructure, but they
found performance suffered as data set and indexes grew larger. And they could
have built their own, but they chose HBase.HBase is ascaleout table store
supporting very high rates of row-level updates over massive amounts of data.
Exactly what is needed for a Messaging system. HBase is also a column based
key-value sto</p><p>2 0.38925591 <a title="943-tfidf-2" href="../high_scalability-2010/high_scalability-2010-03-16-1_Billion_Reasons_Why_Adobe_Chose_HBase_.html">795 high scalability-2010-03-16-1 Billion Reasons Why Adobe Chose HBase </a></p>
<p>Introduction: Cosmin Lehene ďťżwrote two excellent articles on Adobe's experiences with
HBase:Why we're using HBase: Part 1andWhy we're using HBase: Part 2. Adobe
needed ageneric,real-time, structured data storage and processing system that
could handle any data volume, with access times under 50ms, with no downtime
andno data loss. The article goes into great detail about their experiences
with HBase and their evaluation process, providing a "well reasoned impartial
use case from a commercial user". It talks about failure handling,
availability, write performance, read performance, random reads, sequential
scans, and consistency. One of the knocks against HBase has been it's
complexity, as it has many parts that need installation and configuration. All
is not lost according to the Adobe team:HBase is more complex than other
systems (you need Hadoop, Zookeeper, cluster machines have multiple roles). We
believe that for HBase, this is not accidental complexity and that the
argument that "HBase is not a</p><p>3 0.26904881 <a title="943-tfidf-3" href="../high_scalability-2012/high_scalability-2012-02-07-Hypertable_Routs_HBase_in_Performance_Test_--_HBase_Overwhelmed_by_Garbage_Collection.html">1189 high scalability-2012-02-07-Hypertable Routs HBase in Performance Test -- HBase Overwhelmed by Garbage Collection</a></p>
<p>Introduction: This is a guest post byDoug Judd, original creator of Hypertable and the CEO
of Hypertable, Inc.Hypertable delivers 2X better throughput in most tests --
HBase fails 41 and 167 billion record insert tests, overwhelmed by garbage
collection -- Both systems deliver similar results for random read uniform
testWe recently conducted a test comparing the performance of Hypertable
(@hypertable) version 0.9.5.5 to that of HBase (@HBase) version 0.90.4
(CDH3u2) running Zookeeper 3.3.4.  In this post, we summarize the results and
offer explanations for the discrepancies. For the full test report,
seeHypertable vs. HBase II.IntroductionHypertable and HBase are both open
source, scalable databases modeled after Google's proprietary Bigtable
database.  The primary difference between the two systems is that Hypertable
is written in C++, while HBase is written in Java.  We modeled this test after
the one described in section 7 of theBigtable paperand tuned both systems for
maximum performance.  The t</p><p>4 0.26240724 <a title="943-tfidf-4" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>Introduction: Facebook did it again. They've built another system capable of doing something
useful with ginormous streams of realtime data. Last time we saw Facebook
release their New Real-Time Messaging System: HBase To Store 135+ Billion
Messages A Month. This time it's a realtime analytics system handlingover 20
billion events per day (200,000 events per second) with a lag of less than 30
seconds. Alex Himel, Engineering Manager at Facebook, explains what they've
built (video) and the scale required:Social plugins have become an important
and growing source of traffic for millions of websites over the past year. We
released a new version of Insights for Websites last week to give site owners
better analytics on how people interact with their content and to help them
optimize their websites in real time. To accomplish this, we had to engineer a
system that could process over 20 billion events per day (200,000 events per
second) with a lag of less than 30 seconds. Alex does an excellent job with
t</p><p>5 0.22516283 <a title="943-tfidf-5" href="../high_scalability-2011/high_scalability-2011-09-02-Stuff_The_Internet_Says_On_Scalability_For_September_2%2C_2011.html">1109 high scalability-2011-09-02-Stuff The Internet Says On Scalability For September 2, 2011</a></p>
<p>Introduction: Scale the modern way / No brush / No lather / No rub-in / Big tube 35 cents -
Drug stores / HighScalability:8868 Tweets per second during VMAs;Facebook: 250
million photos uploaded each day;Earth: 7 Billion People StrongPotent
quotables:@kevinweil: Wow, 8868 Tweets per second last night during the #VMAs.
And that's just the writes -- imagine how many reads we were
doing!@tristanbergh: #NoSQL isn't cool, it's a working kludge of existing
architectures, bowing to the current tech limits, not transcending
them@krishnan: I would love to switch the backend infra to Amazon anytime but
our top 20 customers will not allow us @ianozsvald: Learning about all the
horrible things that happen when you don't plan (@socialtiesapp) for
scalability. Trying to be creative now...After a particularly difficult
Jeopardy match, Watson asked IBM to make him a new cognitive chip so he could
continue to kick human butt. The result, a newish chip design collocates data
and computation. RAM and CPU are interconn</p><p>6 0.21896197 <a title="943-tfidf-6" href="../high_scalability-2009/high_scalability-2009-07-02-Product%3A_Hbase.html">650 high scalability-2009-07-02-Product: Hbase</a></p>
<p>7 0.21411526 <a title="943-tfidf-7" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>8 0.20003738 <a title="943-tfidf-8" href="../high_scalability-2009/high_scalability-2009-06-10-Hive_-_A_Petabyte_Scale_Data_Warehouse_using_Hadoop.html">624 high scalability-2009-06-10-Hive - A Petabyte Scale Data Warehouse using Hadoop</a></p>
<p>9 0.19521129 <a title="943-tfidf-9" href="../high_scalability-2013/high_scalability-2013-05-20-The_Tumblr_Architecture_Yahoo_Bought_for_a_Cool_Billion_Dollars.html">1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</a></p>
<p>10 0.19500536 <a title="943-tfidf-10" href="../high_scalability-2012/high_scalability-2012-02-13-Tumblr_Architecture_-_15_Billion_Page_Views_a_Month_and_Harder_to_Scale_than_Twitter.html">1191 high scalability-2012-02-13-Tumblr Architecture - 15 Billion Page Views a Month and Harder to Scale than Twitter</a></p>
<p>11 0.19500536 <a title="943-tfidf-11" href="../high_scalability-2012/high_scalability-2012-11-19-Gone_Fishin%27%3A_Tumblr_Architecture_-_15_Billion_Page_Views_A_Month_And_Harder_To_Scale_Than_Twitter.html">1360 high scalability-2012-11-19-Gone Fishin': Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a></p>
<p>12 0.18051405 <a title="943-tfidf-12" href="../high_scalability-2011/high_scalability-2011-05-17-Facebook%3A_An_Example_Canonical_Architecture_for_Scaling_Billions_of_Messages.html">1042 high scalability-2011-05-17-Facebook: An Example Canonical Architecture for Scaling Billions of Messages</a></p>
<p>13 0.17281818 <a title="943-tfidf-13" href="../high_scalability-2014/high_scalability-2014-01-28-How_Next_Big_Sound_Tracks_Over_a_Trillion_Song_Plays%2C_Likes%2C_and_More_Using_a_Version_Control_System_for_Hadoop_Data.html">1586 high scalability-2014-01-28-How Next Big Sound Tracks Over a Trillion Song Plays, Likes, and More Using a Version Control System for Hadoop Data</a></p>
<p>14 0.15743332 <a title="943-tfidf-14" href="../high_scalability-2010/high_scalability-2010-06-22-Exploring_the_software_behind_Facebook%2C_the_world%E2%80%99s_largest_site.html">845 high scalability-2010-06-22-Exploring the software behind Facebook, the world’s largest site</a></p>
<p>15 0.15545161 <a title="943-tfidf-15" href="../high_scalability-2011/high_scalability-2011-07-25-Is_NoSQL_a_Premature_Optimization_that%27s_Worse_than_Death%3F_Or_the_Lady_Gaga_of_the_Database_World%3F.html">1085 high scalability-2011-07-25-Is NoSQL a Premature Optimization that's Worse than Death? Or the Lady Gaga of the Database World?</a></p>
<p>16 0.1536413 <a title="943-tfidf-16" href="../high_scalability-2009/high_scalability-2009-10-12-High_Performance_at_Massive_Scale_%E2%80%93__Lessons_learned_at_Facebook.html">720 high scalability-2009-10-12-High Performance at Massive Scale –  Lessons learned at Facebook</a></p>
<p>17 0.15106127 <a title="943-tfidf-17" href="../high_scalability-2011/high_scalability-2011-09-23-The_Real_News_is_Not_that_Facebook_Serves_Up_1_Trillion_Pages_a_Month%E2%80%A6.html">1123 high scalability-2011-09-23-The Real News is Not that Facebook Serves Up 1 Trillion Pages a Month…</a></p>
<p>18 0.14699101 <a title="943-tfidf-18" href="../high_scalability-2011/high_scalability-2011-06-15-101_Questions_to_Ask_When_Considering_a_NoSQL_Database.html">1062 high scalability-2011-06-15-101 Questions to Ask When Considering a NoSQL Database</a></p>
<p>19 0.14609858 <a title="943-tfidf-19" href="../high_scalability-2009/high_scalability-2009-07-02-Product%3A_Facebook%27s_Cassandra_-_A_Massive_Distributed_Store.html">649 high scalability-2009-07-02-Product: Facebook's Cassandra - A Massive Distributed Store</a></p>
<p>20 0.1445719 <a title="943-tfidf-20" href="../high_scalability-2014/high_scalability-2014-02-26-The_WhatsApp_Architecture_Facebook_Bought_For_%2419_Billion.html">1602 high scalability-2014-02-26-The WhatsApp Architecture Facebook Bought For $19 Billion</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.209), (1, 0.122), (2, 0.003), (3, 0.016), (4, 0.108), (5, 0.067), (6, -0.047), (7, 0.01), (8, 0.129), (9, 0.077), (10, 0.096), (11, 0.155), (12, 0.092), (13, -0.082), (14, -0.063), (15, 0.112), (16, -0.005), (17, -0.084), (18, -0.047), (19, -0.04), (20, 0.061), (21, 0.126), (22, 0.052), (23, -0.047), (24, 0.055), (25, -0.103), (26, 0.115), (27, -0.008), (28, 0.044), (29, -0.03), (30, -0.112), (31, 0.083), (32, 0.077), (33, -0.089), (34, 0.028), (35, 0.103), (36, 0.006), (37, -0.009), (38, -0.03), (39, -0.061), (40, 0.008), (41, 0.062), (42, 0.081), (43, 0.063), (44, -0.031), (45, 0.039), (46, -0.013), (47, 0.066), (48, 0.012), (49, -0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96930867 <a title="943-lsi-1" href="../high_scalability-2010/high_scalability-2010-11-16-Facebook%27s_New_Real-time_Messaging_System%3A_HBase_to_Store_135%2B_Billion_Messages_a_Month.html">943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</a></p>
<p>Introduction: You may have read somewhere that Facebook has introduced a newSocial Inbox
integrating email, IM, SMS,  text messages, on-site Facebook messages. All-in-
all they need to store over 135 billion messages a month. Where do they store
all that stuff? Facebook's Kannan Muthukkaruppan gives the surprise answer
inThe Underlying Technology of Messages:HBase. HBase beat out MySQL,
Cassandra, and a few others.Why a surprise? Facebook created Cassandra and it
was purpose built for an inbox type application, but they found Cassandra's
eventual consistency model wasn't a good match for their new real-time
Messages product. Facebook also has an extensiveMySQL infrastructure, but they
found performance suffered as data set and indexes grew larger. And they could
have built their own, but they chose HBase.HBase is ascaleout table store
supporting very high rates of row-level updates over massive amounts of data.
Exactly what is needed for a Messaging system. HBase is also a column based
key-value sto</p><p>2 0.78091061 <a title="943-lsi-2" href="../high_scalability-2009/high_scalability-2009-07-02-Product%3A_Facebook%27s_Cassandra_-_A_Massive_Distributed_Store.html">649 high scalability-2009-07-02-Product: Facebook's Cassandra - A Massive Distributed Store</a></p>
<p>Introduction: Update 2:Presentation from theNoSQL conference:slides,video.Update:Why you
won't be building your killer app on a distributed hash tableby Jonathan
Ellis.Why I think Cassandra is the most promising of the open-source
distributed databases --you get a relatively rich data model and a
distribution model that supports efficient range queries. These are not things
that can be grafted on top of a simpler DHT foundation, so Cassandra will be
useful for a wider variety of applications.James Hamilton has published a
thorough summary of Facebook's Cassandra, another scalable key-value store for
your perusal. It's open source and is described as a "BigTable data model
running on a Dynamo-like infrastructure." Cassandra is used in Facebook as an
email search system containing 25TB and over 100m mailboxes.Google Code for
Cassandra- A Structured Storage System on a P2P NetworkSIGMOD 2008
Presentation.Video Presentation at FacebookFacebook Engineering Blog for
CassandraAnti-RDBMS: A list of distribu</p><p>3 0.75263298 <a title="943-lsi-3" href="../high_scalability-2010/high_scalability-2010-03-16-1_Billion_Reasons_Why_Adobe_Chose_HBase_.html">795 high scalability-2010-03-16-1 Billion Reasons Why Adobe Chose HBase </a></p>
<p>Introduction: Cosmin Lehene ďťżwrote two excellent articles on Adobe's experiences with
HBase:Why we're using HBase: Part 1andWhy we're using HBase: Part 2. Adobe
needed ageneric,real-time, structured data storage and processing system that
could handle any data volume, with access times under 50ms, with no downtime
andno data loss. The article goes into great detail about their experiences
with HBase and their evaluation process, providing a "well reasoned impartial
use case from a commercial user". It talks about failure handling,
availability, write performance, read performance, random reads, sequential
scans, and consistency. One of the knocks against HBase has been it's
complexity, as it has many parts that need installation and configuration. All
is not lost according to the Adobe team:HBase is more complex than other
systems (you need Hadoop, Zookeeper, cluster machines have multiple roles). We
believe that for HBase, this is not accidental complexity and that the
argument that "HBase is not a</p><p>4 0.71340102 <a title="943-lsi-4" href="../high_scalability-2009/high_scalability-2009-06-10-Hive_-_A_Petabyte_Scale_Data_Warehouse_using_Hadoop.html">624 high scalability-2009-06-10-Hive - A Petabyte Scale Data Warehouse using Hadoop</a></p>
<p>Introduction: This post about using Hive and Hadoop for analytics comes straight from
Facebook engineers.Scalable analysis on large data sets has been core to the
functions of a number of teams at Facebook - both engineering and non-
engineering. Apart from ad hoc analysis and business intelligence applications
used by analysts across the company, a number of Facebook products are also
based on analytics.These products range from simple reporting applications
like Insights for the Facebook Ad Network, to more advanced kind such as
Facebook's Lexicon product.As a result a flexible infrastructure that caters
to the needs of these diverse applications and users and that also scales up
in a cost effective manner with the ever increasing amounts of data being
generated on Facebook, is critical. Hive and Hadoop are the technologies that
we have used to address these requirements at Facebook.Read the rest of the
article on Engineering @ Facebook's Notes page</p><p>5 0.65683413 <a title="943-lsi-5" href="../high_scalability-2009/high_scalability-2009-07-01-Podcast_about_Facebook%27s_Cassandra_Project_and_the_New_Wave_of_Distributed_Databases.html">646 high scalability-2009-07-01-Podcast about Facebook's Cassandra Project and the New Wave of Distributed Databases</a></p>
<p>Introduction: In thispodcast, we interviewJonathan Ellisabout how Facebook's open
sourcedCassandra Projecttook lessons learned from Amazon'sDynamoand
Google'sBigTableto tackle the difficult problem of building a highly scalable,
always available, distributed data store.</p><p>6 0.65230721 <a title="943-lsi-6" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>7 0.63993055 <a title="943-lsi-7" href="../high_scalability-2009/high_scalability-2009-07-02-Hypertable_is_a_New_BigTable_Clone_that_Runs_on_HDFS_or_KFS.html">647 high scalability-2009-07-02-Hypertable is a New BigTable Clone that Runs on HDFS or KFS</a></p>
<p>8 0.63016844 <a title="943-lsi-8" href="../high_scalability-2010/high_scalability-2010-06-22-Exploring_the_software_behind_Facebook%2C_the_world%E2%80%99s_largest_site.html">845 high scalability-2010-06-22-Exploring the software behind Facebook, the world’s largest site</a></p>
<p>9 0.62483597 <a title="943-lsi-9" href="../high_scalability-2008/high_scalability-2008-03-03-Read_This_Site_and_Ace_Your_Next_Interview%21.html">264 high scalability-2008-03-03-Read This Site and Ace Your Next Interview!</a></p>
<p>10 0.61833346 <a title="943-lsi-10" href="../high_scalability-2011/high_scalability-2011-05-17-Facebook%3A_An_Example_Canonical_Architecture_for_Scaling_Billions_of_Messages.html">1042 high scalability-2011-05-17-Facebook: An Example Canonical Architecture for Scaling Billions of Messages</a></p>
<p>11 0.61258906 <a title="943-lsi-11" href="../high_scalability-2011/high_scalability-2011-12-30-Stuff_The_Internet_Says_On_Scalability_For_December_30%2C_2011.html">1166 high scalability-2011-12-30-Stuff The Internet Says On Scalability For December 30, 2011</a></p>
<p>12 0.60659587 <a title="943-lsi-12" href="../high_scalability-2009/high_scalability-2009-10-12-High_Performance_at_Massive_Scale_%E2%80%93__Lessons_learned_at_Facebook.html">720 high scalability-2009-10-12-High Performance at Massive Scale –  Lessons learned at Facebook</a></p>
<p>13 0.60138535 <a title="943-lsi-13" href="../high_scalability-2011/high_scalability-2011-09-02-Stuff_The_Internet_Says_On_Scalability_For_September_2%2C_2011.html">1109 high scalability-2011-09-02-Stuff The Internet Says On Scalability For September 2, 2011</a></p>
<p>14 0.59840471 <a title="943-lsi-14" href="../high_scalability-2012/high_scalability-2012-09-15-4_Reasons_Facebook_Dumped_HTML5_and_Went_Native.html">1323 high scalability-2012-09-15-4 Reasons Facebook Dumped HTML5 and Went Native</a></p>
<p>15 0.59818763 <a title="943-lsi-15" href="../high_scalability-2011/high_scalability-2011-07-18-Building_your_own_Facebook_Realtime_Analytics_System__.html">1081 high scalability-2011-07-18-Building your own Facebook Realtime Analytics System  </a></p>
<p>16 0.59145504 <a title="943-lsi-16" href="../high_scalability-2012/high_scalability-2012-04-06-Stuff_The_Internet_Says_On_Scalability_For_April_6%2C_2012.html">1223 high scalability-2012-04-06-Stuff The Internet Says On Scalability For April 6, 2012</a></p>
<p>17 0.58641881 <a title="943-lsi-17" href="../high_scalability-2014/high_scalability-2014-02-26-The_WhatsApp_Architecture_Facebook_Bought_For_%2419_Billion.html">1602 high scalability-2014-02-26-The WhatsApp Architecture Facebook Bought For $19 Billion</a></p>
<p>18 0.58590567 <a title="943-lsi-18" href="../high_scalability-2011/high_scalability-2011-04-12-Caching_and_Processing_2TB_Mozilla_Crash_Reports_in_memory_with_Hazelcast.html">1020 high scalability-2011-04-12-Caching and Processing 2TB Mozilla Crash Reports in memory with Hazelcast</a></p>
<p>19 0.58377433 <a title="943-lsi-19" href="../high_scalability-2010/high_scalability-2010-12-31-Facebook_in_20_Minutes%3A_2.7M_Photos%2C_10.2M_Comments%2C_4.6M_Messages.html">966 high scalability-2010-12-31-Facebook in 20 Minutes: 2.7M Photos, 10.2M Comments, 4.6M Messages</a></p>
<p>20 0.58067715 <a title="943-lsi-20" href="../high_scalability-2011/high_scalability-2011-07-08-Stuff_The_Internet_Says_On_Scalability_For_July_8%2C_2011.html">1076 high scalability-2011-07-08-Stuff The Internet Says On Scalability For July 8, 2011</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.081), (2, 0.243), (10, 0.053), (26, 0.033), (30, 0.03), (40, 0.039), (47, 0.017), (61, 0.171), (77, 0.014), (79, 0.072), (85, 0.062), (94, 0.078)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97722256 <a title="943-lda-1" href="../high_scalability-2010/high_scalability-2010-11-16-Facebook%27s_New_Real-time_Messaging_System%3A_HBase_to_Store_135%2B_Billion_Messages_a_Month.html">943 high scalability-2010-11-16-Facebook's New Real-time Messaging System: HBase to Store 135+ Billion Messages a Month</a></p>
<p>Introduction: You may have read somewhere that Facebook has introduced a newSocial Inbox
integrating email, IM, SMS,  text messages, on-site Facebook messages. All-in-
all they need to store over 135 billion messages a month. Where do they store
all that stuff? Facebook's Kannan Muthukkaruppan gives the surprise answer
inThe Underlying Technology of Messages:HBase. HBase beat out MySQL,
Cassandra, and a few others.Why a surprise? Facebook created Cassandra and it
was purpose built for an inbox type application, but they found Cassandra's
eventual consistency model wasn't a good match for their new real-time
Messages product. Facebook also has an extensiveMySQL infrastructure, but they
found performance suffered as data set and indexes grew larger. And they could
have built their own, but they chose HBase.HBase is ascaleout table store
supporting very high rates of row-level updates over massive amounts of data.
Exactly what is needed for a Messaging system. HBase is also a column based
key-value sto</p><p>2 0.96561879 <a title="943-lda-2" href="../high_scalability-2009/high_scalability-2009-09-12-How_Google_Taught_Me_to_Cache_and_Cash-In.html">703 high scalability-2009-09-12-How Google Taught Me to Cache and Cash-In</a></p>
<p>Introduction: A user named Apathyon how Reddit scales some of their features, shares some
advice he learned while working at Google and other major companies.To be
fair, I [Apathy] was working at Google at the time, and every job I held
between 1995 and 2005 involved at least one of the largest websites on the
planet. I didn't come up with any of these ideas, just watched other smart
people I worked with who knew what they were doing and found (or wrote) tools
that did the same things. But the theme is always the same:Cache everything
you can and store the rest in some sort of database (not necessarily
relational and not necessarily centralized).Cache everything that doesn't
change rapidly. Most of the time you don't have to hit the database for
anything other than checking whether the users' new message count has
transitioned from 0 to (1 or more).Cache everything--templates, user message
status, the front page components--and hit the database once a minute or so to
update the front page, forums, e</p><p>3 0.96122116 <a title="943-lda-3" href="../high_scalability-2011/high_scalability-2011-07-06-11_Common_Web_Use_Cases_Solved_in_Redis.html">1074 high scalability-2011-07-06-11 Common Web Use Cases Solved in Redis</a></p>
<p>Introduction: In How to take advantage of Redis just adding it to your stack Salvatore
'antirez' Sanfilippo shows how to solve some common problems in Redis by
taking advantage of its unique data structure handling capabilities. Common
Redis primitives like LPUSH, and LTRIM, and LREM are used to accomplish tasks
programmers need to get done, but that can be hard or slow in more traditional
stores. A very useful and practical article. How would you accomplish these
tasks in your framework?Show latest items listings in your home page. This is
a live in-memory cache and is very fast.LPUSHis used to insert a content ID at
the head of the list stored at a key.LTRIMis used to limit the number of items
in the list to 5000. If the user needs to page beyond this cache only then are
they sent to the database.Deletion and filtering. If a cached article is
deleted it can be removed from the cache using LREM.Leaderboards and related
problems. A leader board is a set sorted by score. TheZADDcommands implements
th</p><p>4 0.95647627 <a title="943-lda-4" href="../high_scalability-2011/high_scalability-2011-11-14-Using_Gossip_Protocols_for_Failure_Detection%2C_Monitoring%2C_Messaging_and_Other_Good_Things.html">1142 high scalability-2011-11-14-Using Gossip Protocols for Failure Detection, Monitoring, Messaging and Other Good Things</a></p>
<p>Introduction: When building a system on top of a set of wildly uncooperative and unruly
computers you have knowledge problems: knowing when other nodes are dead;
knowing when nodes become alive; getting information about other nodes so you
can make local decisions, like knowing which node should handle a request
based on a scheme for assigning nodes to a certain range of users; learning
about new configuration data; agreeing on data values; and so on.How do you
solve these problems? A common centralized approach is to use a database and
all nodes query it for information. Obvious availability and performance
issues for large distributed clusters. Another approach is to use Paxos, a
protocol for solving consensus in a network to maintain strict consistency
requirements for small groups of unreliable processes. Not practical when
larger number of nodes are involved.So what's the super cool decentralized way
to bring order to large clusters?Gossip protocols, which maintain relaxed
consistency requireme</p><p>5 0.95585304 <a title="943-lda-5" href="../high_scalability-2013/high_scalability-2013-10-28-Design_Decisions_for_Scaling_Your_High_Traffic_Feeds.html">1538 high scalability-2013-10-28-Design Decisions for Scaling Your High Traffic Feeds</a></p>
<p>Introduction: Guest post by Thierry Schellenbach, Founder/CTO of Fashiolista.com, follow
@tschellenbach on Twitter and GithubFashiolistastarted out as a hobby project
which we built on the side. We had absolutely no idea it would grow into one
of the largest online fashion communities. The entire first version took about
two weeks to develop and our feed implementation was dead simple. We've come a
long way since then and I'd like to share our experience with scaling feed
systems.Feeds are a core component of many large startups such as Pinterest,
Instagram, Wanelo and Fashiolista. At Fashiolista the feed system powers
theflat feed,aggregated feedand thenotification system. This article will
explain the troubles we ran into when scaling our feeds and the design
decisions involved with building your own solution. Understanding the basics
of how these feed systems work is essential as more and more applications rely
on them.Furthermore we've open sourcedFeedly, the Python module powering our
feeds. Wh</p><p>6 0.95417523 <a title="943-lda-6" href="../high_scalability-2007/high_scalability-2007-07-11-Friendster_Architecture.html">6 high scalability-2007-07-11-Friendster Architecture</a></p>
<p>7 0.95348084 <a title="943-lda-7" href="../high_scalability-2011/high_scalability-2011-07-29-Stuff_The_Internet_Says_On_Scalability_For_July_29%2C_2011.html">1089 high scalability-2011-07-29-Stuff The Internet Says On Scalability For July 29, 2011</a></p>
<p>8 0.95232308 <a title="943-lda-8" href="../high_scalability-2011/high_scalability-2011-10-31-15_Ways_to_Make_Your_Application_Feel_More_Responsive_under_Google_App_Engine.html">1135 high scalability-2011-10-31-15 Ways to Make Your Application Feel More Responsive under Google App Engine</a></p>
<p>9 0.95179927 <a title="943-lda-9" href="../high_scalability-2013/high_scalability-2013-05-20-The_Tumblr_Architecture_Yahoo_Bought_for_a_Cool_Billion_Dollars.html">1461 high scalability-2013-05-20-The Tumblr Architecture Yahoo Bought for a Cool Billion Dollars</a></p>
<p>10 0.95146561 <a title="943-lda-10" href="../high_scalability-2012/high_scalability-2012-11-19-Gone_Fishin%27%3A_Tumblr_Architecture_-_15_Billion_Page_Views_A_Month_And_Harder_To_Scale_Than_Twitter.html">1360 high scalability-2012-11-19-Gone Fishin': Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a></p>
<p>11 0.95146537 <a title="943-lda-11" href="../high_scalability-2012/high_scalability-2012-02-13-Tumblr_Architecture_-_15_Billion_Page_Views_a_Month_and_Harder_to_Scale_than_Twitter.html">1191 high scalability-2012-02-13-Tumblr Architecture - 15 Billion Page Views a Month and Harder to Scale than Twitter</a></p>
<p>12 0.94912821 <a title="943-lda-12" href="../high_scalability-2009/high_scalability-2009-03-19-Product%3A_Redis_-_Not_Just_Another_Key-Value_Store.html">545 high scalability-2009-03-19-Product: Redis - Not Just Another Key-Value Store</a></p>
<p>13 0.94910914 <a title="943-lda-13" href="../high_scalability-2010/high_scalability-2010-07-12-Creating_Scalable_Digital_Libraries.html">856 high scalability-2010-07-12-Creating Scalable Digital Libraries</a></p>
<p>14 0.94829941 <a title="943-lda-14" href="../high_scalability-2012/high_scalability-2012-06-01-Stuff_The_Internet_Says_On_Scalability_For_June_1%2C_2012.html">1255 high scalability-2012-06-01-Stuff The Internet Says On Scalability For June 1, 2012</a></p>
<p>15 0.94223177 <a title="943-lda-15" href="../high_scalability-2009/high_scalability-2009-10-02-HighScalability_has_Moved_to_Squarespace.com%21_.html">714 high scalability-2009-10-02-HighScalability has Moved to Squarespace.com! </a></p>
<p>16 0.94189745 <a title="943-lda-16" href="../high_scalability-2008/high_scalability-2008-04-21-The_Search_for_the_Source_of_Data_-_How_SimpleDB_Differs_from_a_RDBMS.html">306 high scalability-2008-04-21-The Search for the Source of Data - How SimpleDB Differs from a RDBMS</a></p>
<p>17 0.94140929 <a title="943-lda-17" href="../high_scalability-2014/high_scalability-2014-01-06-How_HipChat_Stores_and_Indexes_Billions_of_Messages_Using_ElasticSearch_and_Redis.html">1573 high scalability-2014-01-06-How HipChat Stores and Indexes Billions of Messages Using ElasticSearch and Redis</a></p>
<p>18 0.94112301 <a title="943-lda-18" href="../high_scalability-2012/high_scalability-2012-10-10-Antirez%3A_You_Need_to_Think_in_Terms_of_Organizing_Your_Data_for_Fetching.html">1337 high scalability-2012-10-10-Antirez: You Need to Think in Terms of Organizing Your Data for Fetching</a></p>
<p>19 0.93952912 <a title="943-lda-19" href="../high_scalability-2009/high_scalability-2009-06-10-Paper%3A_Graph_Databases_and_the_Future_of_Large-Scale_Knowledge_Management.html">626 high scalability-2009-06-10-Paper: Graph Databases and the Future of Large-Scale Knowledge Management</a></p>
<p>20 0.93843919 <a title="943-lda-20" href="../high_scalability-2012/high_scalability-2012-01-30-37signals_Still_Happily_Scaling_on_Moore_RAM_and_SSDs.html">1183 high scalability-2012-01-30-37signals Still Happily Scaling on Moore RAM and SSDs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
