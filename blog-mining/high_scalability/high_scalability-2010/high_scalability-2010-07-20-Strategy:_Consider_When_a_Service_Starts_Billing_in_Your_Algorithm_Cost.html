<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>862 high scalability-2010-07-20-Strategy: Consider When a Service Starts Billing in Your Algorithm Cost</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2010" href="../home/high_scalability-2010_home.html">high_scalability-2010</a> <a title="high_scalability-2010-862" href="#">high_scalability-2010-862</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>862 high scalability-2010-07-20-Strategy: Consider When a Service Starts Billing in Your Algorithm Cost</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2010-862-html" href="http://highscalability.com//blog/2010/7/20/strategy-consider-when-a-service-starts-billing-in-your-algo.html">html</a></p><p>Introduction: At Monday'sCloud Computing Meetup,Paco Nathangave an excellentGetting Started
on Hadooptalk (slides). I found one of Paco's strategies particularly
interesting: consider when a service starts charging in cost calculations.
Depending on your use case it may be cheaper to go with a more expensive
service that charges only for work accomplished rather than charging for both
work + startup time.The example is comparing the cost of running Hadoop on AWS
yourself versus using Amazon's prepackaged Hadoop service,Elastic
MapReduce(EMR). The thought may have gone through your mind as it did mine
that it doesn't necessarily make sense to use Amazon's Hadoop service. Why pay
a premium for EMR when Hadoop will run directly on AWS?One reason is that
Amazon has made significant changes to Hadoop to make it run more efficiently
and easily on AWS. The other more surprising reason is cost.When starting a
500 node Hadoop cluster, for example, you have to wait for all the nodes to
start and join the clus</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('emr', 0.451), ('hadoop', 0.292), ('charged', 0.217), ('charging', 0.203), ('node', 0.177), ('startup', 0.163), ('cost', 0.156), ('starts', 0.147), ('surprising', 0.141), ('funds', 0.136), ('paco', 0.136), ('percentages', 0.136), ('aws', 0.134), ('depending', 0.133), ('run', 0.125), ('prepackaged', 0.121), ('digit', 0.121), ('starting', 0.111), ('charges', 0.108), ('reason', 0.101)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="862-tfidf-1" href="../high_scalability-2010/high_scalability-2010-07-20-Strategy%3A_Consider_When_a_Service_Starts_Billing_in_Your_Algorithm_Cost.html">862 high scalability-2010-07-20-Strategy: Consider When a Service Starts Billing in Your Algorithm Cost</a></p>
<p>Introduction: At Monday'sCloud Computing Meetup,Paco Nathangave an excellentGetting Started
on Hadooptalk (slides). I found one of Paco's strategies particularly
interesting: consider when a service starts charging in cost calculations.
Depending on your use case it may be cheaper to go with a more expensive
service that charges only for work accomplished rather than charging for both
work + startup time.The example is comparing the cost of running Hadoop on AWS
yourself versus using Amazon's prepackaged Hadoop service,Elastic
MapReduce(EMR). The thought may have gone through your mind as it did mine
that it doesn't necessarily make sense to use Amazon's Hadoop service. Why pay
a premium for EMR when Hadoop will run directly on AWS?One reason is that
Amazon has made significant changes to Hadoop to make it run more efficiently
and easily on AWS. The other more surprising reason is cost.When starting a
500 node Hadoop cluster, for example, you have to wait for all the nodes to
start and join the clus</p><p>2 0.1817843 <a title="862-tfidf-2" href="../high_scalability-2009/high_scalability-2009-05-17-Product%3A_Hadoop.html">601 high scalability-2009-05-17-Product: Hadoop</a></p>
<p>Introduction: Update 5:Hadoop Sorts a Petabyte in 16.25 Hours and a Terabyte in 62
Secondsand has itsgreen cred questionedbecause it took 40 times the number of
machines Greenplum used to do the same work.Update 4:Introduction to Pig. Pig
allows you to skip programming Hadoop at the low map-reduce level. You don't
have to know Java. Using the Pig Latin language, which is a scripting data
flow language, you can think about your problem as a data flow program. 10
lines of Pig Latin = 200 lines of Java.Update 3: Scaling Hadoop to4000 nodes
at Yahoo!. 30,000 cores with nearly 16PB of raw disk; sorted 6TB of data
completed in 37 minutes; 14,000 map tasks writes (reads) 360 MB (about 3
blocks) of data into a single file with a total of 5.04 TB for the whole
job.Update 2: HadoopSummit and Data-Intensive Computing Symposium Videos and
Slides. Topics include: Pig, JAQL, Hbase, Hive, Data-Intensive Scalable
Computing, Clouds and ManyCore: The Revolution, Simplicity and Complexity in
Data Systems at Scale, Han</p><p>3 0.17794096 <a title="862-tfidf-3" href="../high_scalability-2008/high_scalability-2008-09-28-Product%3A_Happy_%3D_Hadoop_%2B_Python.html">397 high scalability-2008-09-28-Product: Happy = Hadoop + Python</a></p>
<p>Introduction: Has a Java only Hadoop been getting you down? Now you can beHappy. Happy is
aframework for writing map-reduce programs for Hadoop using Jython. It files
off the sharp edges on Hadoop and makes writing map-reduce programs a breeze.
There's really no history yet on Happy, but I'm delighted at the idea of being
able to map-reduce inother languages. The more ways the better.From the
website:Happy is a framework that allows Hadoop jobs to be written and run in
Python 2.2 using Jython. It is aneasy way to write map-reduce programs for
Hadoop, and includes some new useful features as well.The current release
supports Hadoop 0.17.2.Map-reduce jobs in Happy are defined by sub-classing
happy.HappyJob and implementing amap(records, task) and reduce(key, values,
task) function. Then you create an instance of theclass, set the job
parameters (such as inputs and outputs) and call run().When you call run(),
Happy serializes your job instance and copies it and all accompanyinglibraries
out to the Hado</p><p>4 0.16812748 <a title="862-tfidf-4" href="../high_scalability-2009/high_scalability-2009-06-11-Yahoo%21_Distribution_of_Hadoop.html">627 high scalability-2009-06-11-Yahoo! Distribution of Hadoop</a></p>
<p>Introduction: Many people in the Apache Hadoop community have asked Yahoo! to publish the
version of Apache Hadoop they test and deploy across their large Hadoop
clusters. As a service to the Hadoop community, Yahoo is releasing the Yahoo!
Distribution of Hadoop -- a source code distribution that is based entirely on
code found in the Apache Hadoop project.This source distribution includes code
patches that they have added to improve the stability and performance of their
clusters. In all cases, these patches have already been contributed back to
Apache, but they may not yet be available in an Apache release of Hadoop.Read
more and get the Hadoop distribution from Yahoo</p><p>5 0.15698224 <a title="862-tfidf-5" href="../high_scalability-2011/high_scalability-2011-01-04-Map-Reduce_With_Ruby_Using_Hadoop.html">968 high scalability-2011-01-04-Map-Reduce With Ruby Using Hadoop</a></p>
<p>Introduction: A demonstration, with repeatable steps, of how to quickly fire-up a Hadoop
cluster on Amazon EC2, load data onto the HDFS (Hadoop Distributed File-
System), write map-reduce scripts in Ruby and use them to run a map-reduce job
on your Hadoop cluster. You willnotneed to ssh into the cluster, as all tasks
are run from your local machine. Below I am using my MacBook Pro as my local
machine, but the steps I have provided should be reproducible on other
platforms running bash and Java.Fire-Up Your Hadoop ClusterI choose
theCloudera distribution of Hadoopwhich is still 100% Apache licensed, but has
some additional benefits. One of these benefits is that it is released byDoug
Cutting, who started Hadoop and drove it’s development at Yahoo! He also
startedLucene, which is another of my favourite Apache Projects, so I have
good faith that he knows what he is doing. Another benefit, as you will see,
is that it is simple to fire-up a Hadoop cluster.I am going to use
Cloudera’sWhirr script, which</p><p>6 0.13722414 <a title="862-tfidf-6" href="../high_scalability-2008/high_scalability-2008-10-15-Hadoop_-_A_Primer.html">414 high scalability-2008-10-15-Hadoop - A Primer</a></p>
<p>7 0.12924436 <a title="862-tfidf-7" href="../high_scalability-2012/high_scalability-2012-02-16-A_Short_on_the_Pinterest_Stack_for_Handling_3%2B_Million_Users.html">1193 high scalability-2012-02-16-A Short on the Pinterest Stack for Handling 3+ Million Users</a></p>
<p>8 0.12796348 <a title="862-tfidf-8" href="../high_scalability-2013/high_scalability-2013-06-26-Leveraging_Cloud_Computing_at_Yelp_-_102_Million_Monthly_Vistors_and_39_Million_Reviews.html">1482 high scalability-2013-06-26-Leveraging Cloud Computing at Yelp - 102 Million Monthly Vistors and 39 Million Reviews</a></p>
<p>9 0.12482732 <a title="862-tfidf-9" href="../high_scalability-2011/high_scalability-2011-07-27-Making_Hadoop_1000x_Faster_for_Graph_Problems.html">1088 high scalability-2011-07-27-Making Hadoop 1000x Faster for Graph Problems</a></p>
<p>10 0.12347555 <a title="862-tfidf-10" href="../high_scalability-2007/high_scalability-2007-07-30-Build_an_Infinitely_Scalable_Infrastructure_for_%24100_Using_Amazon_Services.html">38 high scalability-2007-07-30-Build an Infinitely Scalable Infrastructure for $100 Using Amazon Services</a></p>
<p>11 0.12100685 <a title="862-tfidf-11" href="../high_scalability-2012/high_scalability-2012-08-28-Making_Hadoop_Run_Faster.html">1313 high scalability-2012-08-28-Making Hadoop Run Faster</a></p>
<p>12 0.11846381 <a title="862-tfidf-12" href="../high_scalability-2013/high_scalability-2013-01-07-Analyzing_billions_of_credit_card_transactions_and_serving_low-latency_insights_in_the_cloud.html">1382 high scalability-2013-01-07-Analyzing billions of credit card transactions and serving low-latency insights in the cloud</a></p>
<p>13 0.1178479 <a title="862-tfidf-13" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>14 0.11735549 <a title="862-tfidf-14" href="../high_scalability-2011/high_scalability-2011-09-07-What_Google_App_Engine_Price_Changes_Say_About_the_Future_of_Web_Architecture.html">1112 high scalability-2011-09-07-What Google App Engine Price Changes Say About the Future of Web Architecture</a></p>
<p>15 0.11298979 <a title="862-tfidf-15" href="../high_scalability-2008/high_scalability-2008-02-19-Hadoop_Getting_Closer_to_1.0_Release.html">254 high scalability-2008-02-19-Hadoop Getting Closer to 1.0 Release</a></p>
<p>16 0.11292066 <a title="862-tfidf-16" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>17 0.10543574 <a title="862-tfidf-17" href="../high_scalability-2007/high_scalability-2007-08-03-Running_Hadoop_MapReduce_on_Amazon_EC2_and_Amazon_S3.html">56 high scalability-2007-08-03-Running Hadoop MapReduce on Amazon EC2 and Amazon S3</a></p>
<p>18 0.10487552 <a title="862-tfidf-18" href="../high_scalability-2013/high_scalability-2013-04-24-Strategy%3A_Using_Lots_of_RAM_Often_Cheaper_than_Using_a_Hadoop_Cluster.html">1445 high scalability-2013-04-24-Strategy: Using Lots of RAM Often Cheaper than Using a Hadoop Cluster</a></p>
<p>19 0.1042505 <a title="862-tfidf-19" href="../high_scalability-2011/high_scalability-2011-11-14-Using_Gossip_Protocols_for_Failure_Detection%2C_Monitoring%2C_Messaging_and_Other_Good_Things.html">1142 high scalability-2011-11-14-Using Gossip Protocols for Failure Detection, Monitoring, Messaging and Other Good Things</a></p>
<p>20 0.10018626 <a title="862-tfidf-20" href="../high_scalability-2009/high_scalability-2009-07-30-Learn_How_to_Think_at_Scale.html">666 high scalability-2009-07-30-Learn How to Think at Scale</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.157), (1, 0.076), (2, 0.035), (3, 0.068), (4, -0.041), (5, -0.024), (6, 0.106), (7, -0.019), (8, 0.122), (9, -0.017), (10, 0.057), (11, -0.043), (12, 0.097), (13, -0.107), (14, 0.042), (15, -0.051), (16, -0.037), (17, -0.013), (18, -0.02), (19, 0.04), (20, -0.025), (21, 0.05), (22, 0.092), (23, -0.004), (24, -0.024), (25, 0.049), (26, 0.086), (27, 0.015), (28, 0.046), (29, 0.043), (30, 0.076), (31, 0.112), (32, -0.006), (33, 0.018), (34, -0.011), (35, 0.017), (36, -0.056), (37, 0.01), (38, -0.014), (39, -0.04), (40, 0.04), (41, 0.046), (42, -0.043), (43, -0.032), (44, 0.015), (45, 0.016), (46, 0.02), (47, 0.019), (48, -0.037), (49, -0.0)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98143017 <a title="862-lsi-1" href="../high_scalability-2010/high_scalability-2010-07-20-Strategy%3A_Consider_When_a_Service_Starts_Billing_in_Your_Algorithm_Cost.html">862 high scalability-2010-07-20-Strategy: Consider When a Service Starts Billing in Your Algorithm Cost</a></p>
<p>Introduction: At Monday'sCloud Computing Meetup,Paco Nathangave an excellentGetting Started
on Hadooptalk (slides). I found one of Paco's strategies particularly
interesting: consider when a service starts charging in cost calculations.
Depending on your use case it may be cheaper to go with a more expensive
service that charges only for work accomplished rather than charging for both
work + startup time.The example is comparing the cost of running Hadoop on AWS
yourself versus using Amazon's prepackaged Hadoop service,Elastic
MapReduce(EMR). The thought may have gone through your mind as it did mine
that it doesn't necessarily make sense to use Amazon's Hadoop service. Why pay
a premium for EMR when Hadoop will run directly on AWS?One reason is that
Amazon has made significant changes to Hadoop to make it run more efficiently
and easily on AWS. The other more surprising reason is cost.When starting a
500 node Hadoop cluster, for example, you have to wait for all the nodes to
start and join the clus</p><p>2 0.8637867 <a title="862-lsi-2" href="../high_scalability-2011/high_scalability-2011-01-04-Map-Reduce_With_Ruby_Using_Hadoop.html">968 high scalability-2011-01-04-Map-Reduce With Ruby Using Hadoop</a></p>
<p>Introduction: A demonstration, with repeatable steps, of how to quickly fire-up a Hadoop
cluster on Amazon EC2, load data onto the HDFS (Hadoop Distributed File-
System), write map-reduce scripts in Ruby and use them to run a map-reduce job
on your Hadoop cluster. You willnotneed to ssh into the cluster, as all tasks
are run from your local machine. Below I am using my MacBook Pro as my local
machine, but the steps I have provided should be reproducible on other
platforms running bash and Java.Fire-Up Your Hadoop ClusterI choose
theCloudera distribution of Hadoopwhich is still 100% Apache licensed, but has
some additional benefits. One of these benefits is that it is released byDoug
Cutting, who started Hadoop and drove it’s development at Yahoo! He also
startedLucene, which is another of my favourite Apache Projects, so I have
good faith that he knows what he is doing. Another benefit, as you will see,
is that it is simple to fire-up a Hadoop cluster.I am going to use
Cloudera’sWhirr script, which</p><p>3 0.8509165 <a title="862-lsi-3" href="../high_scalability-2008/high_scalability-2008-09-28-Product%3A_Happy_%3D_Hadoop_%2B_Python.html">397 high scalability-2008-09-28-Product: Happy = Hadoop + Python</a></p>
<p>Introduction: Has a Java only Hadoop been getting you down? Now you can beHappy. Happy is
aframework for writing map-reduce programs for Hadoop using Jython. It files
off the sharp edges on Hadoop and makes writing map-reduce programs a breeze.
There's really no history yet on Happy, but I'm delighted at the idea of being
able to map-reduce inother languages. The more ways the better.From the
website:Happy is a framework that allows Hadoop jobs to be written and run in
Python 2.2 using Jython. It is aneasy way to write map-reduce programs for
Hadoop, and includes some new useful features as well.The current release
supports Hadoop 0.17.2.Map-reduce jobs in Happy are defined by sub-classing
happy.HappyJob and implementing amap(records, task) and reduce(key, values,
task) function. Then you create an instance of theclass, set the job
parameters (such as inputs and outputs) and call run().When you call run(),
Happy serializes your job instance and copies it and all accompanyinglibraries
out to the Hado</p><p>4 0.77493793 <a title="862-lsi-4" href="../high_scalability-2013/high_scalability-2013-04-24-Strategy%3A_Using_Lots_of_RAM_Often_Cheaper_than_Using_a_Hadoop_Cluster.html">1445 high scalability-2013-04-24-Strategy: Using Lots of RAM Often Cheaper than Using a Hadoop Cluster</a></p>
<p>Introduction: Solving problems while saving money is always a problem. In Nobody ever got
ďŹ red for using Hadoop on a cluster they give some counter-intuitive advice by
showing a big-memory server may  provide better performance per dollar than a
cluster:For jobs where the input data is multi-terabyte or larger a Hadoop
cluster is the right solution.For smaller problems memory has reached a GB/$
ratio where it is technically and financially feasible to use a single server
with 100s of GB of DRAM rather than a cluster. Given the majority of analytics
jobs do not process huge data sets, a cluster doesn't need to be your first
option. Scaling up RAM saves on programmer time, reduces programmer effort,
improved accuracy, and reduces hardware costs.</p><p>5 0.76892871 <a title="862-lsi-5" href="../high_scalability-2009/high_scalability-2009-05-17-Product%3A_Hadoop.html">601 high scalability-2009-05-17-Product: Hadoop</a></p>
<p>Introduction: Update 5:Hadoop Sorts a Petabyte in 16.25 Hours and a Terabyte in 62
Secondsand has itsgreen cred questionedbecause it took 40 times the number of
machines Greenplum used to do the same work.Update 4:Introduction to Pig. Pig
allows you to skip programming Hadoop at the low map-reduce level. You don't
have to know Java. Using the Pig Latin language, which is a scripting data
flow language, you can think about your problem as a data flow program. 10
lines of Pig Latin = 200 lines of Java.Update 3: Scaling Hadoop to4000 nodes
at Yahoo!. 30,000 cores with nearly 16PB of raw disk; sorted 6TB of data
completed in 37 minutes; 14,000 map tasks writes (reads) 360 MB (about 3
blocks) of data into a single file with a total of 5.04 TB for the whole
job.Update 2: HadoopSummit and Data-Intensive Computing Symposium Videos and
Slides. Topics include: Pig, JAQL, Hbase, Hive, Data-Intensive Scalable
Computing, Clouds and ManyCore: The Revolution, Simplicity and Complexity in
Data Systems at Scale, Han</p><p>6 0.7674244 <a title="862-lsi-6" href="../high_scalability-2008/high_scalability-2008-11-14-Paper%3A_Pig_Latin%3A_A_Not-So-Foreign_Language_for_Data_Processing.html">443 high scalability-2008-11-14-Paper: Pig Latin: A Not-So-Foreign Language for Data Processing</a></p>
<p>7 0.76009345 <a title="862-lsi-7" href="../high_scalability-2009/high_scalability-2009-06-11-Yahoo%21_Distribution_of_Hadoop.html">627 high scalability-2009-06-11-Yahoo! Distribution of Hadoop</a></p>
<p>8 0.74953544 <a title="862-lsi-8" href="../high_scalability-2009/high_scalability-2009-08-03-Building_a_Data_Intensive_Web_Application_with_Cloudera%2C_Hadoop%2C_Hive%2C_Pig%2C_and_EC2.html">669 high scalability-2009-08-03-Building a Data Intensive Web Application with Cloudera, Hadoop, Hive, Pig, and EC2</a></p>
<p>9 0.72255337 <a title="862-lsi-9" href="../high_scalability-2012/high_scalability-2012-06-15-Stuff_The_Internet_Says_On_Scalability_For_June_15%2C_2012.html">1265 high scalability-2012-06-15-Stuff The Internet Says On Scalability For June 15, 2012</a></p>
<p>10 0.70904553 <a title="862-lsi-10" href="../high_scalability-2012/high_scalability-2012-08-28-Making_Hadoop_Run_Faster.html">1313 high scalability-2012-08-28-Making Hadoop Run Faster</a></p>
<p>11 0.6940316 <a title="862-lsi-11" href="../high_scalability-2013/high_scalability-2013-06-26-Leveraging_Cloud_Computing_at_Yelp_-_102_Million_Monthly_Vistors_and_39_Million_Reviews.html">1482 high scalability-2013-06-26-Leveraging Cloud Computing at Yelp - 102 Million Monthly Vistors and 39 Million Reviews</a></p>
<p>12 0.68926817 <a title="862-lsi-12" href="../high_scalability-2012/high_scalability-2012-01-12-Peregrine_-_A_Map_Reduce_Framework_for_Iterative_and_Pipelined_Jobs.html">1173 high scalability-2012-01-12-Peregrine - A Map Reduce Framework for Iterative and Pipelined Jobs</a></p>
<p>13 0.68127912 <a title="862-lsi-13" href="../high_scalability-2007/high_scalability-2007-08-03-Running_Hadoop_MapReduce_on_Amazon_EC2_and_Amazon_S3.html">56 high scalability-2007-08-03-Running Hadoop MapReduce on Amazon EC2 and Amazon S3</a></p>
<p>14 0.6805681 <a title="862-lsi-14" href="../high_scalability-2008/high_scalability-2008-02-19-Hadoop_Getting_Closer_to_1.0_Release.html">254 high scalability-2008-02-19-Hadoop Getting Closer to 1.0 Release</a></p>
<p>15 0.66655308 <a title="862-lsi-15" href="../high_scalability-2008/high_scalability-2008-10-15-Hadoop_-_A_Primer.html">414 high scalability-2008-10-15-Hadoop - A Primer</a></p>
<p>16 0.65302616 <a title="862-lsi-16" href="../high_scalability-2010/high_scalability-2010-07-02-Hot_Scalability_Links_for_July_2%2C_2010.html">851 high scalability-2010-07-02-Hot Scalability Links for July 2, 2010</a></p>
<p>17 0.63369638 <a title="862-lsi-17" href="../high_scalability-2013/high_scalability-2013-01-07-Analyzing_billions_of_credit_card_transactions_and_serving_low-latency_insights_in_the_cloud.html">1382 high scalability-2013-01-07-Analyzing billions of credit card transactions and serving low-latency insights in the cloud</a></p>
<p>18 0.63158792 <a title="862-lsi-18" href="../high_scalability-2009/high_scalability-2009-07-02-Product%3A_Hbase.html">650 high scalability-2009-07-02-Product: Hbase</a></p>
<p>19 0.59169436 <a title="862-lsi-19" href="../high_scalability-2013/high_scalability-2013-05-06-7_Not_So_Sexy_Tips_for_Saving_Money_On_Amazon.html">1452 high scalability-2013-05-06-7 Not So Sexy Tips for Saving Money On Amazon</a></p>
<p>20 0.57440215 <a title="862-lsi-20" href="../high_scalability-2013/high_scalability-2013-03-01-Stuff_The_Internet_Says_On_Scalability_For_February_29%2C_2013.html">1414 high scalability-2013-03-01-Stuff The Internet Says On Scalability For February 29, 2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.039), (2, 0.255), (10, 0.078), (30, 0.046), (40, 0.044), (61, 0.075), (62, 0.146), (77, 0.024), (79, 0.175), (94, 0.021)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95253587 <a title="862-lda-1" href="../high_scalability-2010/high_scalability-2010-07-20-Strategy%3A_Consider_When_a_Service_Starts_Billing_in_Your_Algorithm_Cost.html">862 high scalability-2010-07-20-Strategy: Consider When a Service Starts Billing in Your Algorithm Cost</a></p>
<p>Introduction: At Monday'sCloud Computing Meetup,Paco Nathangave an excellentGetting Started
on Hadooptalk (slides). I found one of Paco's strategies particularly
interesting: consider when a service starts charging in cost calculations.
Depending on your use case it may be cheaper to go with a more expensive
service that charges only for work accomplished rather than charging for both
work + startup time.The example is comparing the cost of running Hadoop on AWS
yourself versus using Amazon's prepackaged Hadoop service,Elastic
MapReduce(EMR). The thought may have gone through your mind as it did mine
that it doesn't necessarily make sense to use Amazon's Hadoop service. Why pay
a premium for EMR when Hadoop will run directly on AWS?One reason is that
Amazon has made significant changes to Hadoop to make it run more efficiently
and easily on AWS. The other more surprising reason is cost.When starting a
500 node Hadoop cluster, for example, you have to wait for all the nodes to
start and join the clus</p><p>2 0.8912586 <a title="862-lda-2" href="../high_scalability-2009/high_scalability-2009-03-05-Strategy%3A__In_Cloud_Computing_Systematically_Drive_Load_to_the_CPU.html">526 high scalability-2009-03-05-Strategy:  In Cloud Computing Systematically Drive Load to the CPU</a></p>
<p>Introduction: Update 2:Linear Bloom Filtersby Edward Kmett. A Bloom filter is a novel data
structure for approximating membership in a set. A Bloom join conserves
network bandwith by exchanging cheaper, more plentiful local CPU utilization
and disk IO.Update:What are Amazon EC2 Compute Units?. Cloud providers charge
for CPU time in voodoo units like "compute units" and "core hours." Geva Perry
takes on the quest of figuring out what these mean in real life.breakI
attended Sebastian Stadil'sAWS Training CampSaturday and during the class
Sebastian brought up a wonderfully counter-intuitive idea:CPU (EC2) costs a
lot less than storage (S3, SDB) so you should systematically move as much work
as you can to the CPU. This is said to be theClient-Cloud Paradigm. It
leverages the well pummeled trend that CPU power follows Moore's Law while
storage followsThe Great Plains' Law(flat). And what sane computing
professional would do battle with Sir Moore and histrusty battle swordof a
law?Embedded systems often m</p><p>3 0.88988298 <a title="862-lda-3" href="../high_scalability-2007/high_scalability-2007-10-20-Strategy%3A_Send_XHR_Request_on_Lost_Focus_Instead_of_For_Every_Character.html">127 high scalability-2007-10-20-Strategy: Send XHR Request on Lost Focus Instead of For Every Character</a></p>
<p>Introduction: Robert Stewart shared this useful Ajax related scalability strategy:We avoided
XMLHttpRequests for individual keystrokes, choosing to go back to the server
only when a field lost focus. Google can afford all the servers to handle the
load for that, but we didn't want to.Do you have a scalability strategy to
share? Thenshare it!.</p><p>4 0.88880038 <a title="862-lda-4" href="../high_scalability-2013/high_scalability-2013-07-15-Ask_HS%3A_What%27s_Wrong_with_Twitter%2C_Why_Isn%27t_One_Machine_Enough%3F.html">1491 high scalability-2013-07-15-Ask HS: What's Wrong with Twitter, Why Isn't One Machine Enough?</a></p>
<p>Introduction: Can anyone convincingly explain why properties sporting traffic statistics
that may seem in-line with with the capabilities of a single big-iron machine
need so many machines in their architecture?This is a common reaction to
architecture profiles on High Scalability: I could do all that on a few
machines so they must be doing something really stupid. Lo and behold this
same reaction also occurred to the articleThe Architecture Twitter Uses to
Deal with 150M Active Users. On Hacker Newspapsosouid voiced what a lot of
people may have been thinking:I really question the current trend of creating
big, complex, fragile architectures to "be able to scale". These numbers are a
great example of why, the entire thing could run on a single server, in a very
straight forward setup. When you are creating a cluster for scalability, and
it has less CPU, RAM and IO than a single server, what are you gaining? They
are only doing 6k writes a second for crying out loud.This is a surprisingly
hard react</p><p>5 0.88163042 <a title="862-lda-5" href="../high_scalability-2013/high_scalability-2013-11-13-Google%3A_Multiplex_Multiple_Works_Loads_on_Computers_to_Increase_Machine_Utilization_and_Save_Money.html">1548 high scalability-2013-11-13-Google: Multiplex Multiple Works Loads on Computers to Increase Machine Utilization and Save Money</a></p>
<p>Introduction: Jeff Deangave a talk at SFBay ACMand at about 3 minutes in he goes over how
Google runs jobs on computers, which is different than how most shops
distribute workloads.It's common for machines to be dedicated to one service,
say run a database, run a cache, run this, or run that. The logic is:Better
control over responsiveness as you generally know the traffic loads a machine
will experience and you can over provision a box to be safe.Easier to manage,
load balance, configure, upgrade, create and make highly available. Since you
know what a machine does another machine can be provisioned to do the same
work.The problem is monocropping hardware though conceptually clean for humans
and safe for applications, is hugely wasteful. Machines are woefully
underutilized, even in a virtualized world.What Google does is use ashared
environmentin a datacenter where all kinds of stuff run on each computer.
Batch computation and interactive computations all run together on the same
machine. Each mach</p><p>6 0.87931609 <a title="862-lda-6" href="../high_scalability-2009/high_scalability-2009-03-11-The_Implications_of_Punctuated_Scalabilium_for_Website_Architecture.html">533 high scalability-2009-03-11-The Implications of Punctuated Scalabilium for Website Architecture</a></p>
<p>7 0.87889832 <a title="862-lda-7" href="../high_scalability-2010/high_scalability-2010-02-19-Twitter%E2%80%99s_Plan_to_Analyze_100_Billion_Tweets.html">780 high scalability-2010-02-19-Twitter’s Plan to Analyze 100 Billion Tweets</a></p>
<p>8 0.87876832 <a title="862-lda-8" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>9 0.87629628 <a title="862-lda-9" href="../high_scalability-2008/high_scalability-2008-07-20-Strategy%3A_Front_S3_with_a_Caching_Proxy.html">353 high scalability-2008-07-20-Strategy: Front S3 with a Caching Proxy</a></p>
<p>10 0.87587976 <a title="862-lda-10" href="../high_scalability-2011/high_scalability-2011-08-15-Should_any_cloud_be_considered_one_availability_zone%3F_The_Amazon_experience_says_yes..html">1098 high scalability-2011-08-15-Should any cloud be considered one availability zone? The Amazon experience says yes.</a></p>
<p>11 0.87512684 <a title="862-lda-11" href="../high_scalability-2009/high_scalability-2009-08-24-How_Google_Serves_Data_from_Multiple_Datacenters.html">687 high scalability-2009-08-24-How Google Serves Data from Multiple Datacenters</a></p>
<p>12 0.87509978 <a title="862-lda-12" href="../high_scalability-2013/high_scalability-2013-11-08-Stuff_The_Internet_Says_On_Scalability_For_November_8th%2C_2013.html">1545 high scalability-2013-11-08-Stuff The Internet Says On Scalability For November 8th, 2013</a></p>
<p>13 0.87490296 <a title="862-lda-13" href="../high_scalability-2009/high_scalability-2009-05-17-Product%3A_Hadoop.html">601 high scalability-2009-05-17-Product: Hadoop</a></p>
<p>14 0.87404442 <a title="862-lda-14" href="../high_scalability-2011/high_scalability-2011-12-19-How_Twitter_Stores_250_Million_Tweets_a_Day_Using_MySQL.html">1159 high scalability-2011-12-19-How Twitter Stores 250 Million Tweets a Day Using MySQL</a></p>
<p>15 0.87337542 <a title="862-lda-15" href="../high_scalability-2008/high_scalability-2008-03-31-Read_HighScalability_on_Your_Mobile_Phone_Using_WidSets_Widgets.html">293 high scalability-2008-03-31-Read HighScalability on Your Mobile Phone Using WidSets Widgets</a></p>
<p>16 0.87221563 <a title="862-lda-16" href="../high_scalability-2010/high_scalability-2010-07-27-YeSQL%3A_An_Overview_of_the_Various_Query_Semantics_in_the_Post_Only-SQL_World.html">867 high scalability-2010-07-27-YeSQL: An Overview of the Various Query Semantics in the Post Only-SQL World</a></p>
<p>17 0.87174481 <a title="862-lda-17" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>18 0.86857533 <a title="862-lda-18" href="../high_scalability-2009/high_scalability-2009-06-05-SSL_RPC_API_Scalability.html">620 high scalability-2009-06-05-SSL RPC API Scalability</a></p>
<p>19 0.86848527 <a title="862-lda-19" href="../high_scalability-2008/high_scalability-2008-04-30-Rather_small_site_architecture..html">312 high scalability-2008-04-30-Rather small site architecture.</a></p>
<p>20 0.86789191 <a title="862-lda-20" href="../high_scalability-2011/high_scalability-2011-09-07-What_Google_App_Engine_Price_Changes_Say_About_the_Future_of_Web_Architecture.html">1112 high scalability-2011-09-07-What Google App Engine Price Changes Say About the Future of Web Architecture</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
