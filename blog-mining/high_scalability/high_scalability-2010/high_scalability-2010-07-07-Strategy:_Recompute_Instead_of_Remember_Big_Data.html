<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>852 high scalability-2010-07-07-Strategy: Recompute Instead of Remember Big Data</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2010" href="../home/high_scalability-2010_home.html">high_scalability-2010</a> <a title="high_scalability-2010-852" href="#">high_scalability-2010-852</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>852 high scalability-2010-07-07-Strategy: Recompute Instead of Remember Big Data</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2010-852-html" href="http://highscalability.com//blog/2010/7/7/strategy-recompute-instead-of-remember-big-data.html">html</a></p><p>Introduction: Professor Lance Fortnow, in his blog post Drowning in Data, says complexity
has taught him this lesson:When storage is expensive, it is cheaper to
recompute what you've already computed. And that's the world we now live in:
Storage is pretty cheap but data acquisition and computation are even
cheaper.Jouni, one of the commenters, thinks the opposite is true:storage is
cheap, but computation is expensive. When you are dealing with massive data,
the size of the data set is very often determined by the amount of computing
power available for a certain price.With such data, a linear-time algorithm
takes O(1) seconds to finish, while a quadratic-time algorithm requires O(n)
seconds. But as computing power increases exponentially over time, the
quadratic algorithm gets exponentially slower.For me it's not a matter of
which is true, both positions can be true, but what's interesting is to think
that storage and computation are in some cases fungible. Your architecture can
decide which tradeof</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Professor Lance Fortnow, in his blog post Drowning in Data, says complexity has taught him this lesson:When storage is expensive, it is cheaper to recompute what you've already computed. [sent-1, score-0.831]
</p><p>2 And that's the world we now live in: Storage is pretty cheap but data acquisition and computation are even cheaper. [sent-2, score-0.829]
</p><p>3 Jouni, one of the commenters, thinks the opposite is true:storage is cheap, but computation is expensive. [sent-3, score-0.538]
</p><p>4 When you are dealing with massive data, the size of the data set is very often determined by the amount of computing power available for a certain price. [sent-4, score-0.823]
</p><p>5 With such data, a linear-time algorithm takes O(1) seconds to finish, while a quadratic-time algorithm requires O(n) seconds. [sent-5, score-0.71]
</p><p>6 But as computing power increases exponentially over time, the quadratic algorithm gets exponentially slower. [sent-6, score-1.393]
</p><p>7 For me it's not a matter of which is true, both positions can be true, but what's interesting is to think that storage and computation are in some cases fungible. [sent-7, score-0.724]
</p><p>8 Your architecture can decide which tradeoffs to make based on the cost of resources and the nature of your data. [sent-8, score-0.387]
</p><p>9 I'm not sure, but this seems like a new degree of freedom in the design space. [sent-9, score-0.327]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('computation', 0.285), ('algorithm', 0.279), ('exponentially', 0.271), ('true', 0.244), ('drowning', 0.223), ('lance', 0.223), ('recompute', 0.209), ('quadratic', 0.209), ('commenters', 0.177), ('cheap', 0.168), ('professor', 0.166), ('acquisition', 0.161), ('taught', 0.156), ('storage', 0.146), ('determined', 0.145), ('finish', 0.145), ('freedom', 0.145), ('opposite', 0.142), ('positions', 0.137), ('tradeoffs', 0.135), ('lesson', 0.119), ('degree', 0.114), ('thinks', 0.111), ('computing', 0.105), ('decide', 0.104), ('dealing', 0.103), ('power', 0.099), ('cheaper', 0.094), ('increases', 0.088), ('nature', 0.088), ('seconds', 0.086), ('data', 0.083), ('certain', 0.081), ('complexity', 0.079), ('matter', 0.078), ('cases', 0.078), ('massive', 0.077), ('says', 0.075), ('blog', 0.072), ('expensive', 0.072), ('gets', 0.071), ('pretty', 0.07), ('seems', 0.068), ('space', 0.067), ('requires', 0.066), ('amount', 0.065), ('size', 0.065), ('sure', 0.064), ('live', 0.062), ('resources', 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="852-tfidf-1" href="../high_scalability-2010/high_scalability-2010-07-07-Strategy%3A_Recompute_Instead_of_Remember_Big_Data.html">852 high scalability-2010-07-07-Strategy: Recompute Instead of Remember Big Data</a></p>
<p>Introduction: Professor Lance Fortnow, in his blog post Drowning in Data, says complexity
has taught him this lesson:When storage is expensive, it is cheaper to
recompute what you've already computed. And that's the world we now live in:
Storage is pretty cheap but data acquisition and computation are even
cheaper.Jouni, one of the commenters, thinks the opposite is true:storage is
cheap, but computation is expensive. When you are dealing with massive data,
the size of the data set is very often determined by the amount of computing
power available for a certain price.With such data, a linear-time algorithm
takes O(1) seconds to finish, while a quadratic-time algorithm requires O(n)
seconds. But as computing power increases exponentially over time, the
quadratic algorithm gets exponentially slower.For me it's not a matter of
which is true, both positions can be true, but what's interesting is to think
that storage and computation are in some cases fungible. Your architecture can
decide which tradeof</p><p>2 0.1188164 <a title="852-tfidf-2" href="../high_scalability-2014/high_scalability-2014-01-02-xkcd%3A_How_Standards_Proliferate%3A.html">1571 high scalability-2014-01-02-xkcd: How Standards Proliferate:</a></p>
<p>Introduction: The great thing about standards is there are so many to choose from. What is
it about human nature that makes this so recognizably true?</p><p>3 0.1082279 <a title="852-tfidf-3" href="../high_scalability-2012/high_scalability-2012-08-16-Paper%3A_A_Provably_Correct_Scalable_Concurrent_Skip_List.html">1305 high scalability-2012-08-16-Paper: A Provably Correct Scalable Concurrent Skip List</a></p>
<p>Introduction: InMemSQL Architecture we learned one of the core strategies MemSQL uses to
achieve their need for speed is lock-free skip lists. Skip lists are used to
efficiently handle range queries. Making the skip-lists lock-free helps
eliminate contention and make writes fast. If this all sounds a little pie-in-
the-sky then here's a very good paper on the subject that might help make it
clearer: A Provably Correct Scalable Concurrent Skip List.From the abstract:We
propose a new concurrent skip list algorithm distinguished by a combination of
simplicity and scalability. The algorithm employs optimistic synchronization,
searching without acquiring locks, followed by short lock-based validation
before adding or removing nodes. It also logically removes an item before
physically unlinking it. Unlike some other concurrent skip list algorithms,
this algorithm preserves the skiplist properties at all times, which
facilitates reasoning about its correctness. Experimental evidence shows that
this algorit</p><p>4 0.1070085 <a title="852-tfidf-4" href="../high_scalability-2010/high_scalability-2010-01-17-Applications_Become_Black_Boxes_Using_Markets_to_Scale_and_Control_Costs.html">761 high scalability-2010-01-17-Applications Become Black Boxes Using Markets to Scale and Control Costs</a></p>
<p>Introduction: This is an excerpt from my articleBuilding Super Scalable Systems: Blade
Runner Meets Autonomic Computing in the Ambient Cloud.We tend to think compute
of resources as residing primarily in datacenters. Given the fast pace of
innovation we will likely see compute resources become pervasive. Some will
reside in datacenters, but compute resources can be anywhere, not just in the
datacenter, we'll actually see the bulk of compute resources live outside of
datacenters in the future.Given the diversity of compute resources it's
reasonable to assume they won't be homogeneous or conform to a standard API.
They will specialize by service. Programmers will have to use those
specialized service interfaces to build applications that are adaptive enough
to take advantage of whatever leverage they can find, whenever and wherever
they can find it. Once found the application will have to reorganize on the
fly to use whatever new resources it has found and let go of whatever
resources it doesn't have</p><p>5 0.10330343 <a title="852-tfidf-5" href="../high_scalability-2008/high_scalability-2008-06-06-Economies_of_Non-Scale.html">340 high scalability-2008-06-06-Economies of Non-Scale</a></p>
<p>Introduction: Scalability forces us to think differently. What worked on a small scale
doesn't always work on a large scale -- and costs are no different. If 90% of
our application is free of contention, and only 10% is spent on a shared
resources, we will need to grow our compute resources by a factor of 100 to
scale by a factor of 10! Another important thing to note is that 10x, in this
case, is the limit of our ability to scale, even if more resources are
added.1. The cost of non-linearly scalable applications grows exponentially
with the demand for more scale.2. Non-linearly scalable applications have an
absolute limit of scalability. According to Amdhal's Law, with 10% contention,
the maximum scaling limit is 10. With 40% contention, our maximum scaling
limit is 2.5 - no matter how many hardware resources we will throw at the
problem.This post discuss in further details how to measure the true cost of
non linearly scalable systems and suggest a model for reducing that cost
significantly.</p><p>6 0.10239805 <a title="852-tfidf-6" href="../high_scalability-2009/high_scalability-2009-03-06-Cloud_Programming_Directly_Feeds_Cost_Allocation_Back_into_Software_Design.html">527 high scalability-2009-03-06-Cloud Programming Directly Feeds Cost Allocation Back into Software Design</a></p>
<p>7 0.10110398 <a title="852-tfidf-7" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>8 0.10086495 <a title="852-tfidf-8" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>9 0.091532007 <a title="852-tfidf-9" href="../high_scalability-2009/high_scalability-2009-04-21-Thread_Pool_Engine_in_MS_CLR_4%2C_and_Work-Stealing_scheduling_algorithm.html">575 high scalability-2009-04-21-Thread Pool Engine in MS CLR 4, and Work-Stealing scheduling algorithm</a></p>
<p>10 0.083807364 <a title="852-tfidf-10" href="../high_scalability-2007/high_scalability-2007-08-22-How_many_machines_do_you_need_to_run_your_site%3F.html">70 high scalability-2007-08-22-How many machines do you need to run your site?</a></p>
<p>11 0.083152153 <a title="852-tfidf-11" href="../high_scalability-2008/high_scalability-2008-11-14-Useful_Cloud_Computing_Blogs.html">445 high scalability-2008-11-14-Useful Cloud Computing Blogs</a></p>
<p>12 0.081480846 <a title="852-tfidf-12" href="../high_scalability-2010/high_scalability-2010-09-09-6_Scalability_Lessons.html">898 high scalability-2010-09-09-6 Scalability Lessons</a></p>
<p>13 0.080981314 <a title="852-tfidf-13" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>14 0.080532387 <a title="852-tfidf-14" href="../high_scalability-2010/high_scalability-2010-06-09-Paper%3A_Propagation_Networks%3A_A_Flexible_and_Expressive_Substrate_for_Computation_.html">839 high scalability-2010-06-09-Paper: Propagation Networks: A Flexible and Expressive Substrate for Computation </a></p>
<p>15 0.079101972 <a title="852-tfidf-15" href="../high_scalability-2012/high_scalability-2012-06-01-Stuff_The_Internet_Says_On_Scalability_For_June_1%2C_2012.html">1255 high scalability-2012-06-01-Stuff The Internet Says On Scalability For June 1, 2012</a></p>
<p>16 0.078775749 <a title="852-tfidf-16" href="../high_scalability-2009/high_scalability-2009-09-01-Cheap_storage%3A_how_backblaze_takes_matters_in_hand.html">692 high scalability-2009-09-01-Cheap storage: how backblaze takes matters in hand</a></p>
<p>17 0.076864645 <a title="852-tfidf-17" href="../high_scalability-2014/high_scalability-2014-02-21-Stuff_The_Internet_Says_On_Scalability_For_February_21st%2C_2014.html">1600 high scalability-2014-02-21-Stuff The Internet Says On Scalability For February 21st, 2014</a></p>
<p>18 0.076564036 <a title="852-tfidf-18" href="../high_scalability-2010/high_scalability-2010-05-05-How_will_memristors_change_everything%3F_.html">823 high scalability-2010-05-05-How will memristors change everything? </a></p>
<p>19 0.076519951 <a title="852-tfidf-19" href="../high_scalability-2007/high_scalability-2007-07-15-Coyote_Point_Load_Balancing_Systems.html">11 high scalability-2007-07-15-Coyote Point Load Balancing Systems</a></p>
<p>20 0.074148357 <a title="852-tfidf-20" href="../high_scalability-2014/high_scalability-2014-05-02-Stuff_The_Internet_Says_On_Scalability_For_May_2nd%2C_2014.html">1642 high scalability-2014-05-02-Stuff The Internet Says On Scalability For May 2nd, 2014</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.111), (1, 0.067), (2, 0.031), (3, 0.069), (4, -0.052), (5, 0.003), (6, -0.01), (7, 0.005), (8, -0.024), (9, 0.022), (10, 0.001), (11, -0.034), (12, -0.015), (13, 0.049), (14, 0.047), (15, 0.006), (16, -0.013), (17, -0.019), (18, -0.005), (19, 0.03), (20, -0.038), (21, 0.019), (22, 0.001), (23, -0.001), (24, -0.009), (25, -0.043), (26, 0.032), (27, 0.042), (28, -0.009), (29, 0.02), (30, -0.011), (31, 0.008), (32, 0.001), (33, 0.053), (34, -0.065), (35, -0.011), (36, 0.033), (37, 0.026), (38, 0.036), (39, -0.02), (40, -0.013), (41, -0.033), (42, 0.003), (43, 0.035), (44, 0.062), (45, 0.012), (46, -0.017), (47, 0.012), (48, -0.022), (49, -0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93413085 <a title="852-lsi-1" href="../high_scalability-2010/high_scalability-2010-07-07-Strategy%3A_Recompute_Instead_of_Remember_Big_Data.html">852 high scalability-2010-07-07-Strategy: Recompute Instead of Remember Big Data</a></p>
<p>Introduction: Professor Lance Fortnow, in his blog post Drowning in Data, says complexity
has taught him this lesson:When storage is expensive, it is cheaper to
recompute what you've already computed. And that's the world we now live in:
Storage is pretty cheap but data acquisition and computation are even
cheaper.Jouni, one of the commenters, thinks the opposite is true:storage is
cheap, but computation is expensive. When you are dealing with massive data,
the size of the data set is very often determined by the amount of computing
power available for a certain price.With such data, a linear-time algorithm
takes O(1) seconds to finish, while a quadratic-time algorithm requires O(n)
seconds. But as computing power increases exponentially over time, the
quadratic algorithm gets exponentially slower.For me it's not a matter of
which is true, both positions can be true, but what's interesting is to think
that storage and computation are in some cases fungible. Your architecture can
decide which tradeof</p><p>2 0.72087586 <a title="852-lsi-2" href="../high_scalability-2010/high_scalability-2010-09-16-How_Can_the_Large_Hadron_Collider_Withstand_One_Petabyte_of_Data_a_Second%3F.html">901 high scalability-2010-09-16-How Can the Large Hadron Collider Withstand One Petabyte of Data a Second?</a></p>
<p>Introduction: Why is there something rather than nothing? That's the kind of question
theLarge Hadron Colliderin CERN is hopefully poised to answer. And what is the
output of this beautiful 17-mile long,6 billion dollar wabi-sabishproton
smashing machine? Data. Great heaping torrents of Grand Canyon sized data. 15
million gigabytes every year. That's 1000 times the information printed in
books every year. It's so much data 10,000 scientists will use agridof80,000+
computers, in 300 computer centers , in 50 different countries just to help
make sense of it all.How will all this data be collected, transported, stored,
and analyzed? It turns out, using what amounts to sort of Internet of
Particles instead of an Internet of Things.Two good articles have recently
shed some electro-magnetic energy in the human visible spectrum on the IT
aspects of the collider:LHC computing grid pushes petabytes of data, beats
expectations by John Timmer on Ars Technica and an overview of theBrookhaven's
RHIC/ATLAS Comput</p><p>3 0.70041376 <a title="852-lsi-3" href="../high_scalability-2010/high_scalability-2010-05-05-How_will_memristors_change_everything%3F_.html">823 high scalability-2010-05-05-How will memristors change everything? </a></p>
<p>Introduction: A non-random sample of my tech friends shows that not many have heard
ofmemristors(though I do suspect vote tampering). I'd read a little about
memristors in2008when the initial hubbub about the existence of memristors was
raised. I, however,  immediately filed them into that comforting conceptual
bucket of potentially revolutionary technologies I didn't have to worry about
because like most wondertech, nothing would ever come of it. Wrong. After
watchingFinding the Missing Memristorby R. Stanley Williams I've had to change
my mind. Memristors have gone from "maybe never" to holy cow this could happen
soon and it could change everything.Let's assume for the sake of dreaming
memristors do prove out. How will we design systems when we have access to a
new material that is two orders of magnitude more efficient from a power
perspective than traditional transistor technologies, contains multiple
petabits (1 petabit = 128TB) of persistent storage, and can be reconfigured to
be either memory</p><p>4 0.69370091 <a title="852-lsi-4" href="../high_scalability-2010/high_scalability-2010-06-09-Paper%3A_Propagation_Networks%3A_A_Flexible_and_Expressive_Substrate_for_Computation_.html">839 high scalability-2010-06-09-Paper: Propagation Networks: A Flexible and Expressive Substrate for Computation </a></p>
<p>Introduction: Alexey Radul in his fascinating 174 page dissertation Propagation Networks: A
Flexible and Expressive Substrate for Computation, offers to help us break
free of the tyranny of linear time by arranging computation as a network of
autonomous but interconnected machines.  We can do this byorganizing
computation as a network of interconnected machines of some kind, each of
which is free to run when it pleases, propagating  information around the
network as proves possible. The consequence of this freedom is that the
structure of the aggregate does not impose an order of time.The abstract from
his thesis is:In this dissertation I propose a shift in the foundations of
computation. Modern programming systems are not expressive enough. The
traditional image of a single computer that has global effects on a large
memory is too restrictive. The propagation paradigm replaces this with
computing by networks of local, independent, stateless machines interconnected
with stateful storage cells. In so</p><p>5 0.66783637 <a title="852-lsi-5" href="../high_scalability-2014/high_scalability-2014-02-21-Stuff_The_Internet_Says_On_Scalability_For_February_21st%2C_2014.html">1600 high scalability-2014-02-21-Stuff The Internet Says On Scalability For February 21st, 2014</a></p>
<p>Introduction: Hey, it's HighScalability time (a particularly bountiful week):The Telephone
Wires of Manhattan in 1887(full)$19 billion: you know what it is;$46 billion:
cost of Sochi Olympics;  400 gigabytes: data transmitted during the Sochi
opening ceremony;26.9 million: Stack Overflow community monthly visitors; 93
million: Candy Crush  daily active users;200-400 Gbps: The New Normal in DDoS
AttacksQuotable Quotes:@brianacton: Facebook turned me down. It was a great
opportunity to connect with some fantastic people. Looking forward to life's
next adventure.@BenedictEvans: Flickr: $35m. Youtube: $1.65bn Whatsapp: $19bn.
Mobile is big. And global. And the next computing platform. Paying
attention?@taziden: On the Internet, worst cases will become common cases
#fosdem #postfixBrian Hayes: Any quantum program must have a stovepipe
architecture: Information flows straight through.So you think Verizon is
stealing your Netflix bandwidth? Not so fast says Dan Rayburn,Netflix's
Streaming Quality Is Based</p><p>6 0.66375417 <a title="852-lsi-6" href="../high_scalability-2007/high_scalability-2007-12-19-How_can_I_learn_to_scale_my_project%3F.html">188 high scalability-2007-12-19-How can I learn to scale my project?</a></p>
<p>7 0.66186327 <a title="852-lsi-7" href="../high_scalability-2010/high_scalability-2010-03-02-Using_the_Ambient_Cloud_as_an_Application_Runtime.html">786 high scalability-2010-03-02-Using the Ambient Cloud as an Application Runtime</a></p>
<p>8 0.66023237 <a title="852-lsi-8" href="../high_scalability-2008/high_scalability-2008-10-06-Paper%3A_Scaling_Genome_Sequencing_-_Complete_Genomics_Technology_Overview.html">403 high scalability-2008-10-06-Paper: Scaling Genome Sequencing - Complete Genomics Technology Overview</a></p>
<p>9 0.65969378 <a title="852-lsi-9" href="../high_scalability-2008/high_scalability-2008-12-09-Rules_of_Thumb_in_Data_Engineering.html">463 high scalability-2008-12-09-Rules of Thumb in Data Engineering</a></p>
<p>10 0.65872997 <a title="852-lsi-10" href="../high_scalability-2013/high_scalability-2013-03-27-The_Changing_Face_of_Scale_-_The_Downside_of_Scaling_in_the_Contextual_Age_.html">1430 high scalability-2013-03-27-The Changing Face of Scale - The Downside of Scaling in the Contextual Age </a></p>
<p>11 0.65675735 <a title="852-lsi-11" href="../high_scalability-2008/high_scalability-2008-09-22-Paper%3A_On_Delivering_Embarrassingly_Distributed_Cloud_Services.html">387 high scalability-2008-09-22-Paper: On Delivering Embarrassingly Distributed Cloud Services</a></p>
<p>12 0.65428221 <a title="852-lsi-12" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>13 0.65366465 <a title="852-lsi-13" href="../high_scalability-2011/high_scalability-2011-05-05-Paper%3A_A_Study_of_Practical_Deduplication.html">1035 high scalability-2011-05-05-Paper: A Study of Practical Deduplication</a></p>
<p>14 0.63934171 <a title="852-lsi-14" href="../high_scalability-2009/high_scalability-2009-03-06-Cloud_Programming_Directly_Feeds_Cost_Allocation_Back_into_Software_Design.html">527 high scalability-2009-03-06-Cloud Programming Directly Feeds Cost Allocation Back into Software Design</a></p>
<p>15 0.63810682 <a title="852-lsi-15" href="../high_scalability-2010/high_scalability-2010-10-08-4_Scalability_Themes_from_Surgecon.html">917 high scalability-2010-10-08-4 Scalability Themes from Surgecon</a></p>
<p>16 0.63761944 <a title="852-lsi-16" href="../high_scalability-2010/high_scalability-2010-02-15-Scaling_Ambition_at_StackOverflow.html">777 high scalability-2010-02-15-Scaling Ambition at StackOverflow</a></p>
<p>17 0.63555038 <a title="852-lsi-17" href="../high_scalability-2011/high_scalability-2011-02-18-Stuff_The_Internet_Says_On_Scalability_For_February_18%2C_2011.html">992 high scalability-2011-02-18-Stuff The Internet Says On Scalability For February 18, 2011</a></p>
<p>18 0.63341033 <a title="852-lsi-18" href="../high_scalability-2009/high_scalability-2009-03-05-Strategy%3A__In_Cloud_Computing_Systematically_Drive_Load_to_the_CPU.html">526 high scalability-2009-03-05-Strategy:  In Cloud Computing Systematically Drive Load to the CPU</a></p>
<p>19 0.63246769 <a title="852-lsi-19" href="../high_scalability-2007/high_scalability-2007-08-21-What_does_the_next_generation_data_center_look_like%3F.html">69 high scalability-2007-08-21-What does the next generation data center look like?</a></p>
<p>20 0.63225967 <a title="852-lsi-20" href="../high_scalability-2011/high_scalability-2011-09-28-Pursue_robust_indefinite_scalability_with_the_Movable_Feast_Machine.html">1127 high scalability-2011-09-28-Pursue robust indefinite scalability with the Movable Feast Machine</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.171), (2, 0.174), (10, 0.022), (47, 0.439), (79, 0.074)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.89287519 <a title="852-lda-1" href="../high_scalability-2007/high_scalability-2007-08-03-Scaling_IMAP_and_POP3.html">57 high scalability-2007-08-03-Scaling IMAP and POP3</a></p>
<p>Introduction: Just thought I'd drop a brief suggestion to anyone building a large mail
system. Our solution for scaling mail pickup was to develop a sharded
architecture whereby accounts are spread across a cluster of servers, each
with imap/pop3 capability. Then we use a cluster of reverse proxies
(Perdition) speaking to the backend imap/pop3 servers . The benefit of this
approach is you can use simply use round-robin or HA loadbalancing on the
perdition servers that end users connect to (e.g. admins can easily move
accounts around on the backend storage servers without affecting end users).
Perdition manages routing users to the appropriate backend servers and has
MySQL support. What we also liked about this approach was that it had no
dependency on a distributed or networked filesystem, so less chance of
corruption or data consistency issues. When an individual server reaches
capacity, we just off load users to a less used server. If any server goes
offline, it only affects the fraction of users</p><p>2 0.85637945 <a title="852-lda-2" href="../high_scalability-2007/high_scalability-2007-09-06-Scaling_IMAP_and_POP3.html">81 high scalability-2007-09-06-Scaling IMAP and POP3</a></p>
<p>Introduction: Another scalability strategy brought to you by Erik Osterman:Just thought I'd
drop a brief suggestion to anyone building a large mail system. Our solution
for scaling mail pickup was to develop a sharded architecture whereby accounts
are spread across a cluster of servers, each with imap/pop3 capability. Then
we use a cluster of reverse proxies (Perdition) speaking to the backend
imap/pop3 servers .The benefit of this approach is you can use simply use
round-robin or HA load balancing on the perdition servers that end users
connect to (e.g. admins can easily move accounts around on the backend storage
servers without affecting end users). Perdition manages routing users to the
appropriate backend servers and has MySQL support.What we also liked about
this approach was that it had no dependency on a distributed or networked file
system, so less chance of corruption or data consistency issues. When an
individual server reaches capacity, we just off load users to a less used
server. If an</p><p>3 0.82664132 <a title="852-lda-3" href="../high_scalability-2007/high_scalability-2007-09-17-Blog%3A_Adding_Simplicity_by_Dan_Pritchett.html">94 high scalability-2007-09-17-Blog: Adding Simplicity by Dan Pritchett</a></p>
<p>Introduction: Dan has genuine insight into building software and large scale scalable
systems in particular. You'll always learn something interesting reading his
blog.A Quick Hit of What's InsideInverting the Reliability Stack,In Support of
Non-Stop Software,Chaotic Perspectives,Latency Exists, Cope!,A Real eBay
Architect Analyzes Part 3,Avoiding Two Phase Commit,
ReduxSite:http://www.addsimplicity.com/</p><p>4 0.80283594 <a title="852-lda-4" href="../high_scalability-2009/high_scalability-2009-09-17-Infinispan_narrows_the_gap_between_open_source_and_commercial_data_caches_.html">708 high scalability-2009-09-17-Infinispan narrows the gap between open source and commercial data caches </a></p>
<p>Introduction: Recently I attended a lecture presented by Manik Surtani , JBoss Cache &
Infinispan project lead. The goal of the talk was to provide a technical
overview of both products and outline Infinispan's road-map. Infinispan is the
successor to the open-source JBoss Cache. JBoss Cache was originally targeted
at simple web page caching and Infinispan builds on this to take it into the
Cloud paradigm.Why did I attend? Well, over the past few years I have worked
on projects that have used commercial distributed caching (aka data grid)
technologies such as GemFire, GigaSpaces XAP or Oracle Coherence . These
projects required more functionality than is currently provided by open-source
solutions such as memcached or EHCache. Looking at the road-map for
Infinispan, I was struck by its ambition - will it provide the functionality
that I need?Read more at:http://bigdatamatters.com/bigdatamatters/2009/09
/infinispan-vs-gigaspaces.html</p><p>5 0.79859895 <a title="852-lda-5" href="../high_scalability-2010/high_scalability-2010-01-13-10_Hot_Scalability_Links_for_January_13%2C_2010.html">760 high scalability-2010-01-13-10 Hot Scalability Links for January 13, 2010</a></p>
<p>Introduction: Has Amazon EC2 become over subscribed?by Alan Williamson. Systemic problems
hit AWS as users experience problems across Amazon's infrastructure. It seems
the strange attractor of a cloud may be the same as for a shared hosting
service.Understanding Infrastructure 2.0by James Urquhart.We need to take a
systems view of our entire infrastructure, and build our automation around the
end-to-end architecture of that system.Hey You, Get Off of My Cloud: Exploring
Information Leakage in Third-Party Compute Clouds.We show that it is possible
to map the internal cloud infrastructure.Hadoop World: Building Data Intensive
Apps with Hadoop and EC2 by Pete Skomoroch.Dives into detail about how he
built TrendingTopics.org using Hadoop and EC2.A Crash Course in Modern
Hardwareby Cliff Click. Yes, your mind will hurt after watching this. And no,
you probably don't know what your microprocessor is doing anymore.EVE
Scalability Explainedby James Harrison.This post aims to demystify EVE's
architecture and</p><p>6 0.78670508 <a title="852-lda-6" href="../high_scalability-2007/high_scalability-2007-11-21-n-phase_commit_for_FS_writes%2C_reads_stay_local.html">163 high scalability-2007-11-21-n-phase commit for FS writes, reads stay local</a></p>
<p>7 0.78030574 <a title="852-lda-7" href="../high_scalability-2012/high_scalability-2012-09-20-How_Vimeo_Saves_50%25_on_EC2_by_Playing_a_Smarter_Game.html">1326 high scalability-2012-09-20-How Vimeo Saves 50% on EC2 by Playing a Smarter Game</a></p>
<p>same-blog 8 0.7790181 <a title="852-lda-8" href="../high_scalability-2010/high_scalability-2010-07-07-Strategy%3A_Recompute_Instead_of_Remember_Big_Data.html">852 high scalability-2010-07-07-Strategy: Recompute Instead of Remember Big Data</a></p>
<p>9 0.76901418 <a title="852-lda-9" href="../high_scalability-2009/high_scalability-2009-12-30-Terrastore_-_Scalable%2C_elastic%2C_consistent_document_store..html">756 high scalability-2009-12-30-Terrastore - Scalable, elastic, consistent document store.</a></p>
<p>10 0.7542541 <a title="852-lda-10" href="../high_scalability-2009/high_scalability-2009-08-08-Yahoo%21%27s_PNUTS_Database%3A_Too_Hot%2C_Too_Cold_or_Just_Right%3F.html">676 high scalability-2009-08-08-Yahoo!'s PNUTS Database: Too Hot, Too Cold or Just Right?</a></p>
<p>11 0.72069341 <a title="852-lda-11" href="../high_scalability-2011/high_scalability-2011-12-30-Stuff_The_Internet_Says_On_Scalability_For_December_30%2C_2011.html">1166 high scalability-2011-12-30-Stuff The Internet Says On Scalability For December 30, 2011</a></p>
<p>12 0.6923582 <a title="852-lda-12" href="../high_scalability-2007/high_scalability-2007-11-07-What_CDN_would_you_recommend%3F.html">144 high scalability-2007-11-07-What CDN would you recommend?</a></p>
<p>13 0.69144416 <a title="852-lda-13" href="../high_scalability-2009/high_scalability-2009-03-30-Ebay_history_and_architecture.html">550 high scalability-2009-03-30-Ebay history and architecture</a></p>
<p>14 0.68646097 <a title="852-lda-14" href="../high_scalability-2011/high_scalability-2011-06-15-101_Questions_to_Ask_When_Considering_a_NoSQL_Database.html">1062 high scalability-2011-06-15-101 Questions to Ask When Considering a NoSQL Database</a></p>
<p>15 0.68061906 <a title="852-lda-15" href="../high_scalability-2011/high_scalability-2011-06-06-NoSQL_Pain%3F_Learn_How_to_Read-write_Scale_Without_a_Complete_Re-write.html">1054 high scalability-2011-06-06-NoSQL Pain? Learn How to Read-write Scale Without a Complete Re-write</a></p>
<p>16 0.66358829 <a title="852-lda-16" href="../high_scalability-2013/high_scalability-2013-10-11-Stuff_The_Internet_Says_On_Scalability_For_October_11th%2C_2013.html">1530 high scalability-2013-10-11-Stuff The Internet Says On Scalability For October 11th, 2013</a></p>
<p>17 0.61911583 <a title="852-lda-17" href="../high_scalability-2008/high_scalability-2008-03-15-New_Website_Design_Considerations.html">276 high scalability-2008-03-15-New Website Design Considerations</a></p>
<p>18 0.60772818 <a title="852-lda-18" href="../high_scalability-2009/high_scalability-2009-08-18-Hardware_Architecture_Example_%28geographical_level_mapping_of_servers%29.html">683 high scalability-2009-08-18-Hardware Architecture Example (geographical level mapping of servers)</a></p>
<p>19 0.58895892 <a title="852-lda-19" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>20 0.57954466 <a title="852-lda-20" href="../high_scalability-2009/high_scalability-2009-09-07-Product%3A_Infinispan_-_Open_Source_Data_Grid.html">696 high scalability-2009-09-07-Product: Infinispan - Open Source Data Grid</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
