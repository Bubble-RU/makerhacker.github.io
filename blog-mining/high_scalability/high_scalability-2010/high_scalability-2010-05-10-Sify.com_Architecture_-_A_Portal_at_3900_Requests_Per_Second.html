<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>825 high scalability-2010-05-10-Sify.com Architecture - A Portal at 3900 Requests Per Second</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2010" href="../home/high_scalability-2010_home.html">high_scalability-2010</a> <a title="high_scalability-2010-825" href="#">high_scalability-2010-825</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>825 high scalability-2010-05-10-Sify.com Architecture - A Portal at 3900 Requests Per Second</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2010-825-html" href="http://highscalability.com//blog/2010/5/10/sifycom-architecture-a-portal-at-3900-requests-per-second.html">html</a></p><p>Introduction: Sify.com is one of the leading portals in India. Samachar.com is owned by the same company and is one of the top content aggregation sites in India, primarily targeting Non-resident Indians from around the world. Ramki Subramanian, an Architect at Sify, has been generous enough to describe the common back-end for both these sites. One of the most notable aspects of their architecture is that Sify does not use a traditional database. They query Solr and then retrieve records from a distributed file system. Over the years many people have argued for file systems over databases. Filesystems can work for key-value lookups, but they don't work for queries, using Solr is a good way around that problem. Another interesting aspect of their system is the use of Drools for intelligent cache invalidation. As we have more and more data duplicated in multiple specialized services, the problem of how to keep them  synchronized  is a difficult one. A rules engine is a clever approach.
         Platfo</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com is owned by the same company and is one of the top content aggregation sites in India, primarily targeting Non-resident Indians from around the world. [sent-4, score-0.187]
</p><p>2 They query Solr and then retrieve records from a distributed file system. [sent-7, score-0.224]
</p><p>3 It is currently manual, but in the next version of the system we are planning on automating the whole provisioning, commissioning, de-commissioning, moving around VMs and  also auto-scaling. [sent-20, score-0.301]
</p><p>4 All files are stored in the clustered file system (GFS). [sent-29, score-0.29]
</p><p>5 This approach makes the system completely horizontally scalable and there is zero dependency on a database. [sent-32, score-0.338]
</p><p>6 The logged query will then be parsed and pushed into the Drools system. [sent-49, score-0.208]
</p><p>7 The system would take that input and create rules dynamically into the system if it is not already existing. [sent-50, score-0.271]
</p><p>8 Then our Content Ingestion system will keep pushing all content it is getting into a Drools queue. [sent-52, score-0.196]
</p><p>9 For example, we support "NOW", greater than, less than, NOT, etc in the query, those will really give us big headache. [sent-58, score-0.206]
</p><p>10 Also on analysis, we figured out the queries are mostly constant across many days. [sent-63, score-0.206]
</p><p>11 For example, we have close to 40,000 different queries a day and it will be repeating every day in almost same pattern. [sent-64, score-0.201]
</p><p>12 So, we could setup multiple instances and just replicate the rules in different systems, that way we can scale it horizontally too. [sent-66, score-0.179]
</p><p>13 Synchronous reads, but fewer layers, less PHP intervention and socket connections. [sent-67, score-0.189]
</p><p>14 I'm looking at ways to use that advantage in the system and see how we can build clusters that can process huge amounts of content quickly, in parallel. [sent-78, score-0.256]
</p><p>15 We use to hit the TCP socket limits in less than 5 minutes from a restart. [sent-81, score-0.255]
</p><p>16 We have gone to the extent of automating the restarts by doing a query and if there is no response or time-outs, we restart Solr. [sent-100, score-0.224]
</p><p>17 For complex queries the query response time is really poor. [sent-102, score-0.332]
</p><p>18 We have about 5 million docs and lot of queries do return in less than a second, but when we have a query with a few "NOT"s and many fields and criteria, it takes 100+ secs. [sent-103, score-0.444]
</p><p>19 We worked around this by splitting the query into more simpler ones and merging the results in PHP space. [sent-104, score-0.215]
</p><p>20 Given the industry we are in and the competition, 10 mins late news makes us irrelevant. [sent-108, score-0.225]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('drools', 0.352), ('solr', 0.23), ('vms', 0.18), ('mins', 0.16), ('query', 0.146), ('ramki', 0.141), ('sify', 0.141), ('gfs', 0.134), ('mule', 0.127), ('queries', 0.123), ('lighty', 0.12), ('content', 0.118), ('rules', 0.115), ('socket', 0.111), ('blades', 0.104), ('docs', 0.097), ('php', 0.086), ('figured', 0.083), ('somebody', 0.08), ('issue', 0.079), ('file', 0.078), ('less', 0.078), ('close', 0.078), ('automating', 0.078), ('system', 0.078), ('whole', 0.076), ('dependency', 0.075), ('urls', 0.074), ('ids', 0.074), ('clustered', 0.072), ('varnish', 0.072), ('looked', 0.07), ('around', 0.069), ('serious', 0.068), ('hit', 0.066), ('us', 0.065), ('kaazing', 0.064), ('casually', 0.064), ('disastrous', 0.064), ('mqs', 0.064), ('portals', 0.064), ('horizontally', 0.064), ('really', 0.063), ('files', 0.062), ('pushed', 0.062), ('completely', 0.061), ('looking', 0.06), ('approach', 0.06), ('editorial', 0.06), ('thats', 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999958 <a title="825-tfidf-1" href="../high_scalability-2010/high_scalability-2010-05-10-Sify.com_Architecture_-_A_Portal_at_3900_Requests_Per_Second.html">825 high scalability-2010-05-10-Sify.com Architecture - A Portal at 3900 Requests Per Second</a></p>
<p>Introduction: Sify.com is one of the leading portals in India. Samachar.com is owned by the same company and is one of the top content aggregation sites in India, primarily targeting Non-resident Indians from around the world. Ramki Subramanian, an Architect at Sify, has been generous enough to describe the common back-end for both these sites. One of the most notable aspects of their architecture is that Sify does not use a traditional database. They query Solr and then retrieve records from a distributed file system. Over the years many people have argued for file systems over databases. Filesystems can work for key-value lookups, but they don't work for queries, using Solr is a good way around that problem. Another interesting aspect of their system is the use of Drools for intelligent cache invalidation. As we have more and more data duplicated in multiple specialized services, the problem of how to keep them  synchronized  is a difficult one. A rules engine is a clever approach.
         Platfo</p><p>2 0.16241646 <a title="825-tfidf-2" href="../high_scalability-2014/high_scalability-2014-02-17-How_the_AOL.com_Architecture_Evolved_to_99.999%25_Availability%2C_8_Million_Visitors_Per_Day%2C_and_200%2C000_Requests_Per_Second.html">1597 high scalability-2014-02-17-How the AOL.com Architecture Evolved to 99.999% Availability, 8 Million Visitors Per Day, and 200,000 Requests Per Second</a></p>
<p>Introduction: This is a guest post by  Dave Hagler  Systems Architect at AOL. 
  The AOL homepages receive more than  8 million visitors per day .  That’s more daily viewers than Good Morning America or the Today Show on television.  Over a billion page views are served each month.  AOL.com has been a major internet destination since 1996, and still has a strong following of loyal users.
   The architecture for AOL.com is in it’s 5th generation .  It has essentially been rebuilt from scratch 5 times over two decades.  The current architecture was designed 6 years ago.  Pieces have been upgraded and new components have been added along the way, but the overall design remains largely intact.  The code, tools, development and deployment processes are highly tuned over 6 years of continual improvement, making the AOL.com architecture battle tested and very stable.
  The engineering team is made up of developers, testers, and operations and  totals around 25 people .  The majority are in Dulles, Virginia</p><p>3 0.15216197 <a title="825-tfidf-3" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>Introduction: Update 2:   Sorting 1 PB with MapReduce . PB is not peanut-butter-and-jelly misspelled. It's 1 petabyte or 1000 terabytes or 1,000,000 gigabytes.  It took six hours and two minutes to sort 1PB (10 trillion 100-byte records) on 4,000 computers  and the results were replicated thrice on 48,000 disks.  Update:   Greg Linden  points to a new Google article  MapReduce: simplified data processing on large clusters . Some interesting stats: 100k MapReduce jobs are executed each day; more than 20 petabytes of data are processed per day; more than 10k MapReduce programs have been implemented; machines are dual processor with gigabit ethernet and 4-8 GB of memory.  Google is the King of scalability.  Everyone knows Google for their large,  sophisticated, and fast searching, but they don't just shine in search. Their platform approach to building scalable applications allows them to roll out internet scale applications at an alarmingly high competition crushing rate. Their goal is always to build</p><p>4 0.14827034 <a title="825-tfidf-4" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>Introduction: Facebook did it again. They've built another system capable of doing something useful with ginormous streams of realtime data. Last time we saw Facebook release their  New Real-Time Messaging System: HBase To Store 135+ Billion Messages A Month . This time it's a realtime analytics system handling  over 20 billion events per day (200,000 events per second) with a lag of less than 30 seconds . 
 
Alex Himel, Engineering Manager at Facebook,  explains what they've built  ( video ) and the scale required:
  

Social plugins have become an important and growing source of traffic for millions of websites over the past year. We released a new version of Insights for Websites last week to give site owners better analytics on how people interact with their content and to help them optimize their websites in real time. To accomplish this, we had to engineer a system that could process over 20 billion events per day (200,000 events per second) with a lag of less than 30 seconds. 

  
Alex does a</p><p>5 0.1478067 <a title="825-tfidf-5" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>Introduction: Pinterest has been riding an exponential growth curve, doubling every month
and half. They've gone from 0 to 10s of billions of page views a month in two
years, from 2 founders and one engineer to over 40 engineers, from one little
MySQL server to 180 Web Engines, 240 API Engines, 88 MySQL DBs (cc2.8xlarge) +
1 slave each, 110 Redis Instances, and 200 Memcache Instances.Stunning growth.
So what's Pinterest's story? To tell their story we have our bards,
Pinterest'sYashwanth NelapatiandMarty Weiner, who tell the dramatic story of
Pinterest's architecture evolution in a talk titledScaling Pinterest. This is
the talk they would have liked to hear a year and half ago when they were
scaling fast and there were a lot of options to choose from. And they made a
lot of incorrect choices.This is a great talk. It's full of amazing details.
It's also very practical, down to earth, and it contains strategies adoptable
by nearly anyone. Highly recommended.Two of my favorite lessons from the
talk:Arc</p><p>6 0.14427477 <a title="825-tfidf-6" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>7 0.13979283 <a title="825-tfidf-7" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>8 0.13739805 <a title="825-tfidf-8" href="../high_scalability-2013/high_scalability-2013-09-09-Need_Help_with_Database_Scalability%3F_Understand_I-O.html">1514 high scalability-2013-09-09-Need Help with Database Scalability? Understand I-O</a></p>
<p>9 0.13116337 <a title="825-tfidf-9" href="../high_scalability-2008/high_scalability-2008-03-12-YouTube_Architecture.html">274 high scalability-2008-03-12-YouTube Architecture</a></p>
<p>10 0.1295995 <a title="825-tfidf-10" href="../high_scalability-2010/high_scalability-2010-04-12-Poppen.de_Architecture.html">808 high scalability-2010-04-12-Poppen.de Architecture</a></p>
<p>11 0.12864815 <a title="825-tfidf-11" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>12 0.1266354 <a title="825-tfidf-12" href="../high_scalability-2009/high_scalability-2009-03-11-The_Implications_of_Punctuated_Scalabilium_for_Website_Architecture.html">533 high scalability-2009-03-11-The Implications of Punctuated Scalabilium for Website Architecture</a></p>
<p>13 0.12627044 <a title="825-tfidf-13" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>14 0.12623146 <a title="825-tfidf-14" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>15 0.12613519 <a title="825-tfidf-15" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>16 0.12601757 <a title="825-tfidf-16" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>17 0.1259075 <a title="825-tfidf-17" href="../high_scalability-2007/high_scalability-2007-11-13-Flickr_Architecture.html">152 high scalability-2007-11-13-Flickr Architecture</a></p>
<p>18 0.1257444 <a title="825-tfidf-18" href="../high_scalability-2008/high_scalability-2008-05-02-Friends_for_Sale_Architecture_-_A_300_Million_Page_View-Month_Facebook_RoR_App.html">313 high scalability-2008-05-02-Friends for Sale Architecture - A 300 Million Page View-Month Facebook RoR App</a></p>
<p>19 0.12265053 <a title="825-tfidf-19" href="../high_scalability-2009/high_scalability-2009-08-16-ThePort__Network__Architecture.html">682 high scalability-2009-08-16-ThePort  Network  Architecture</a></p>
<p>20 0.12180614 <a title="825-tfidf-20" href="../high_scalability-2010/high_scalability-2010-07-12-Creating_Scalable_Digital_Libraries.html">856 high scalability-2010-07-12-Creating Scalable Digital Libraries</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.266), (1, 0.143), (2, -0.046), (3, -0.075), (4, 0.034), (5, 0.024), (6, 0.007), (7, -0.002), (8, 0.034), (9, 0.016), (10, -0.024), (11, 0.0), (12, -0.018), (13, -0.05), (14, 0.028), (15, 0.013), (16, -0.036), (17, -0.025), (18, -0.009), (19, -0.052), (20, -0.021), (21, -0.036), (22, 0.03), (23, 0.057), (24, 0.029), (25, 0.025), (26, 0.013), (27, 0.001), (28, -0.043), (29, 0.022), (30, -0.016), (31, 0.027), (32, -0.04), (33, 0.061), (34, 0.022), (35, 0.029), (36, -0.027), (37, -0.022), (38, -0.031), (39, 0.014), (40, -0.047), (41, -0.065), (42, -0.012), (43, 0.029), (44, -0.039), (45, 0.023), (46, -0.037), (47, 0.0), (48, 0.014), (49, 0.02)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96396422 <a title="825-lsi-1" href="../high_scalability-2010/high_scalability-2010-05-10-Sify.com_Architecture_-_A_Portal_at_3900_Requests_Per_Second.html">825 high scalability-2010-05-10-Sify.com Architecture - A Portal at 3900 Requests Per Second</a></p>
<p>Introduction: Sify.com is one of the leading portals in India. Samachar.com is owned by the same company and is one of the top content aggregation sites in India, primarily targeting Non-resident Indians from around the world. Ramki Subramanian, an Architect at Sify, has been generous enough to describe the common back-end for both these sites. One of the most notable aspects of their architecture is that Sify does not use a traditional database. They query Solr and then retrieve records from a distributed file system. Over the years many people have argued for file systems over databases. Filesystems can work for key-value lookups, but they don't work for queries, using Solr is a good way around that problem. Another interesting aspect of their system is the use of Drools for intelligent cache invalidation. As we have more and more data duplicated in multiple specialized services, the problem of how to keep them  synchronized  is a difficult one. A rules engine is a clever approach.
         Platfo</p><p>2 0.86698246 <a title="825-lsi-2" href="../high_scalability-2014/high_scalability-2014-05-19-A_Short_On_How_the_Wayback_Machine_Stores_More_Pages_than_Stars_in_the_Milky_Way.html">1650 high scalability-2014-05-19-A Short On How the Wayback Machine Stores More Pages than Stars in the Milky Way</a></p>
<p>Introduction: How does the  Wayback Machine  work? Now with over  400 billion webpages indexed , allowing the Internet to be browsed all the way back to 1996, it's an even more compelling question. I've looked several times but I've never found a really good answer.
 
Here's some information from a thread on Hacker News. It starts with  mmagin , a former Archive employee:
  
 I can't speak to their current infrastructure (though more of it is open source now - http://archive-access.sourceforge.net/projects/wayback/ ), but as far as the wayback machine, there was no SQL database anywhere in it. 
  
 For the purposes of making the wayback machine go: 
 
 
 Archived data was in ARC file format (predecessor to http://en.wikipedia.org/wiki/Web_ARChive) which is essentially a concatenation of separately gzipped records. That is, you can seek to a particular offset and start decompressing a record. Thus you could get at any archived web page with a triple (server, filename, file-offset) Thus it was spread</p><p>3 0.81407493 <a title="825-lsi-3" href="../high_scalability-2014/high_scalability-2014-02-17-How_the_AOL.com_Architecture_Evolved_to_99.999%25_Availability%2C_8_Million_Visitors_Per_Day%2C_and_200%2C000_Requests_Per_Second.html">1597 high scalability-2014-02-17-How the AOL.com Architecture Evolved to 99.999% Availability, 8 Million Visitors Per Day, and 200,000 Requests Per Second</a></p>
<p>Introduction: This is a guest post by  Dave Hagler  Systems Architect at AOL. 
  The AOL homepages receive more than  8 million visitors per day .  That’s more daily viewers than Good Morning America or the Today Show on television.  Over a billion page views are served each month.  AOL.com has been a major internet destination since 1996, and still has a strong following of loyal users.
   The architecture for AOL.com is in it’s 5th generation .  It has essentially been rebuilt from scratch 5 times over two decades.  The current architecture was designed 6 years ago.  Pieces have been upgraded and new components have been added along the way, but the overall design remains largely intact.  The code, tools, development and deployment processes are highly tuned over 6 years of continual improvement, making the AOL.com architecture battle tested and very stable.
  The engineering team is made up of developers, testers, and operations and  totals around 25 people .  The majority are in Dulles, Virginia</p><p>4 0.81388527 <a title="825-lsi-4" href="../high_scalability-2014/high_scalability-2014-03-11-Building_a_Social_Music_Service_Using_AWS%2C_Scala%2C_Akka%2C_Play%2C_MongoDB%2C_and_Elasticsearch.html">1609 high scalability-2014-03-11-Building a Social Music Service Using AWS, Scala, Akka, Play, MongoDB, and Elasticsearch</a></p>
<p>Introduction: This is a  guest repost  by  Rotem Hermon , former Chief Architect for  serendip.me , on the architecture and scaling considerations behind making a startup music service. 
 
 serendip.me  is a social music service that helps people discover great music shared by their friends, and also introduces them to their “music soulmates” - people outside their immediate social circle that shares a similar taste in music.
 
Serendip is running on AWS and is built on the following stack:  scala  (and some Java),  akka  (for handling concurrency),  Play framework  (for the web and API front-ends),  MongoDB  and  Elasticsearch .
  Choosing the stack  
One of the challenges of building serendip was the need to handle a large amount of data from day one, since a main feature of serendip is that it collects  every piece of music being shared on Twitter  from public music services. So when we approached the question of choosing the language and technologies to use, an important consideration was the ab</p><p>5 0.80722445 <a title="825-lsi-5" href="../high_scalability-2014/high_scalability-2014-01-28-How_Next_Big_Sound_Tracks_Over_a_Trillion_Song_Plays%2C_Likes%2C_and_More_Using_a_Version_Control_System_for_Hadoop_Data.html">1586 high scalability-2014-01-28-How Next Big Sound Tracks Over a Trillion Song Plays, Likes, and More Using a Version Control System for Hadoop Data</a></p>
<p>Introduction: This is a guest post by  Eric Czech  ,  Chief Architect at Next Big Sound, talks about some unique approaches taken to solving scalability challenges in music analytics.  
 
Tracking online activity is hardly a new idea, but doing it for the entire music industry isn't easy.  Half a billion music video streams,  track downloads, and artist page likes occur each day and measuring all of this activity across platforms such as Spotify, iTunes, YouTube,  Facebook, and more, poses some interesting scalability challenges.  Next Big Sound collects this type of data from over a hundred sources,  standardizes everything, and offers that information to record labels, band managers, and artists through a web-based analytics platform.
 
While many of our applications use open-source systems like Hadoop, HBase, Cassandra, Mongo, RabbitMQ, and MySQL, our usage is fairly standard, but there is one aspect of what we do that is pretty unique. We collect or receive information from 100+ sources and we s</p><p>6 0.7974124 <a title="825-lsi-6" href="../high_scalability-2010/high_scalability-2010-04-12-Poppen.de_Architecture.html">808 high scalability-2010-04-12-Poppen.de Architecture</a></p>
<p>7 0.7867915 <a title="825-lsi-7" href="../high_scalability-2013/high_scalability-2013-03-22-Stuff_The_Internet_Says_On_Scalability_For_March_22%2C_2013.html">1428 high scalability-2013-03-22-Stuff The Internet Says On Scalability For March 22, 2013</a></p>
<p>8 0.7845245 <a title="825-lsi-8" href="../high_scalability-2011/high_scalability-2011-09-26-17_Techniques_Used_to_Scale_Turntable.fm_and_Labmeeting_to_Millions_of_Users.html">1124 high scalability-2011-09-26-17 Techniques Used to Scale Turntable.fm and Labmeeting to Millions of Users</a></p>
<p>9 0.77974623 <a title="825-lsi-9" href="../high_scalability-2013/high_scalability-2013-09-13-Stuff_The_Internet_Says_On_Scalability_For_September_13%2C_2013.html">1516 high scalability-2013-09-13-Stuff The Internet Says On Scalability For September 13, 2013</a></p>
<p>10 0.77938908 <a title="825-lsi-10" href="../high_scalability-2012/high_scalability-2012-08-14-MemSQL_Architecture_-_The_Fast_%28MVCC%2C_InMem%2C_LockFree%2C_CodeGen%29_and_Familiar_%28SQL%29.html">1304 high scalability-2012-08-14-MemSQL Architecture - The Fast (MVCC, InMem, LockFree, CodeGen) and Familiar (SQL)</a></p>
<p>11 0.77604693 <a title="825-lsi-11" href="../high_scalability-2012/high_scalability-2012-06-08-Stuff_The_Internet_Says_On_Scalability_For_June_8%2C_2012.html">1261 high scalability-2012-06-08-Stuff The Internet Says On Scalability For June 8, 2012</a></p>
<p>12 0.77446204 <a title="825-lsi-12" href="../high_scalability-2014/high_scalability-2014-05-16-Stuff_The_Internet_Says_On_Scalability_For_May_16th%2C_2014.html">1649 high scalability-2014-05-16-Stuff The Internet Says On Scalability For May 16th, 2014</a></p>
<p>13 0.77375007 <a title="825-lsi-13" href="../high_scalability-2008/high_scalability-2008-07-15-ZooKeeper_-_A_Reliable%2C_Scalable_Distributed_Coordination_System_.html">350 high scalability-2008-07-15-ZooKeeper - A Reliable, Scalable Distributed Coordination System </a></p>
<p>14 0.77268076 <a title="825-lsi-14" href="../high_scalability-2007/high_scalability-2007-07-31-BerkeleyDB_%26_other_distributed_high_performance_key-value_databases.html">50 high scalability-2007-07-31-BerkeleyDB & other distributed high performance key-value databases</a></p>
<p>15 0.77237308 <a title="825-lsi-15" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>16 0.77221566 <a title="825-lsi-16" href="../high_scalability-2012/high_scalability-2012-04-18-Ansible_-__A_Simple_Model-Driven_Configuration_Management_and_Command_Execution_Framework.html">1230 high scalability-2012-04-18-Ansible -  A Simple Model-Driven Configuration Management and Command Execution Framework</a></p>
<p>17 0.7704609 <a title="825-lsi-17" href="../high_scalability-2010/high_scalability-2010-05-17-7_Lessons_Learned_While_Building_Reddit_to_270_Million_Page_Views_a_Month.html">828 high scalability-2010-05-17-7 Lessons Learned While Building Reddit to 270 Million Page Views a Month</a></p>
<p>18 0.76777571 <a title="825-lsi-18" href="../high_scalability-2010/high_scalability-2010-03-26-Strategy%3A_Caching_404s_Saved_the_Onion_66%25_on_Server_Time.html">800 high scalability-2010-03-26-Strategy: Caching 404s Saved the Onion 66% on Server Time</a></p>
<p>19 0.76701587 <a title="825-lsi-19" href="../high_scalability-2014/high_scalability-2014-02-14-Stuff_The_Internet_Says_On_Scalability_For_February_14th%2C_2014.html">1596 high scalability-2014-02-14-Stuff The Internet Says On Scalability For February 14th, 2014</a></p>
<p>20 0.76598287 <a title="825-lsi-20" href="../high_scalability-2012/high_scalability-2012-06-25-StubHub_Architecture%3A_The_Surprising_Complexity_Behind_the_World%E2%80%99s_Largest_Ticket_Marketplace.html">1271 high scalability-2012-06-25-StubHub Architecture: The Surprising Complexity Behind the World’s Largest Ticket Marketplace</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.114), (2, 0.239), (10, 0.085), (19, 0.017), (20, 0.113), (30, 0.019), (40, 0.011), (47, 0.026), (61, 0.106), (73, 0.011), (79, 0.107), (85, 0.038), (94, 0.045)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95273435 <a title="825-lda-1" href="../high_scalability-2013/high_scalability-2013-12-18-How_to_get_started_with_sizing_and_capacity_planning%2C_assuming_you_don%27t_know_the_software_behavior%3F.html">1566 high scalability-2013-12-18-How to get started with sizing and capacity planning, assuming you don't know the software behavior?</a></p>
<p>Introduction: Here's a common situation and question from the  mechanical-sympathy  Google group by Avinash Agrawal on the black art of capacity planning:
  

How to get started with sizing and capacity planning, assuming we don't know the software behavior and its completely new product to deal with?

  
 Gil Tene , Vice President of Technology and CTO & Co-Founder, wrote a very  understandable and useful answer  that is worth highlighting:
  

Start with requirements. I see way too many "capacity planning" exercises that go off spending weeks measuring some irrelevant metrics about a system (like how many widgets per hour can this thing do) without knowing what they actually need it to do.


There are two key sets of metrics to state here: the "how much" set and the "how bad" set:


In the "How Much" part, you need to establish, based on expected business needs, Numbers for things (like connections, users, streams, transactions or messages per second) that you expect to interact with at the peak t</p><p>same-blog 2 0.95096946 <a title="825-lda-2" href="../high_scalability-2010/high_scalability-2010-05-10-Sify.com_Architecture_-_A_Portal_at_3900_Requests_Per_Second.html">825 high scalability-2010-05-10-Sify.com Architecture - A Portal at 3900 Requests Per Second</a></p>
<p>Introduction: Sify.com is one of the leading portals in India. Samachar.com is owned by the same company and is one of the top content aggregation sites in India, primarily targeting Non-resident Indians from around the world. Ramki Subramanian, an Architect at Sify, has been generous enough to describe the common back-end for both these sites. One of the most notable aspects of their architecture is that Sify does not use a traditional database. They query Solr and then retrieve records from a distributed file system. Over the years many people have argued for file systems over databases. Filesystems can work for key-value lookups, but they don't work for queries, using Solr is a good way around that problem. Another interesting aspect of their system is the use of Drools for intelligent cache invalidation. As we have more and more data duplicated in multiple specialized services, the problem of how to keep them  synchronized  is a difficult one. A rules engine is a clever approach.
         Platfo</p><p>3 0.94373834 <a title="825-lda-3" href="../high_scalability-2009/high_scalability-2009-10-02-HighScalability_has_Moved_to_Squarespace.com%21_.html">714 high scalability-2009-10-02-HighScalability has Moved to Squarespace.com! </a></p>
<p>Introduction: You may have noticed something is a little a different when visiting HighScalability today: We've Moved! HighScalability.com has switched hosting services to Squarespace.com. House warming gifts are completely unnecessary. Thanks for the thought though.  It's been a long long long process. Importing a largish Drupal site to Wordpress and then into Squarespace is a bit like dental work without the happy juice, but the results are worth it. While the site is missing a few features I think it looks nicer, feels faster, and I'm betting it will be more scalable and more reliable. All good things. I'll explain more about the move later in this post, but there's some admistrivia that needs to be handled to make the move complete:
  
 If you have a user account and have posted on HighScalability before then you have a user account, but since I don't know your passwords I had to make new passwords up for you. So please  contact  me and I'll give you your password so you can login and change it.</p><p>4 0.94205111 <a title="825-lda-4" href="../high_scalability-2014/high_scalability-2014-03-19-Strategy%3A_Three_Techniques_to_Survive_Traffic_Surges_by_Quickly_Scaling_Your_Site.html">1615 high scalability-2014-03-19-Strategy: Three Techniques to Survive Traffic Surges by Quickly Scaling Your Site</a></p>
<p>Introduction: Matthew Might , as a first responder to a surprise  traffic surge  on his inexpensive linode hosted blog, took emergency steps that you might find useful in a similar situation:
  
  Find the bottleneck.  Reloading the page in firebug showed the first page took 24 seconds to load and after that everything else loaded quickly. In retrospect this burst meant the site was thread limited as the CPU was idle. 
  Cut image sizes in half  with a shell script using ImageMagick's convert. Load time is now 12 seconds. 
  Turn dynamic content into static content  using a static index.html file  copied using the browser's "view source" feature. Load time is now 6 seconds. 
  Added threads  to the Apache configuration file. Load time is now 2 seconds. Crises averted. 
  
Because of this quick thinking and quick action the patient survived to serve pages another day.
 
And in fine post-mortem tradition some of the future changes are: 
  
  Run a cron job to trigger an earlier alert . Email when requ</p><p>5 0.94036025 <a title="825-lda-5" href="../high_scalability-2014/high_scalability-2014-02-14-Stuff_The_Internet_Says_On_Scalability_For_February_14th%2C_2014.html">1596 high scalability-2014-02-14-Stuff The Internet Says On Scalability For February 14th, 2014</a></p>
<p>Introduction: Hey, it's HighScalability time:
     Climbing the World's Second Tallest Building     
  5 billion : Number of phone records NSA collects per day;  Facebook : 1.23 billion users, 201.6 billion friend connections, 400 billion shared photos, and 7.8 trillion messages sent since the start of 2012. 
 Quotable Quotes:                                  
 
  @ShrikanthSS : people repeatedly underestimate the cost of busy waits 
  @mcclure111 : Learning today java․net․URL․equals is a blocking operation that hits the network shook me badly. I don't know if I can trust the world now. 
  @hui_kenneth : @randybias: “3 ways 2 be market leader - be 1st, be best, or be cheapest. #AWS was all 3. Now #googlecloud may be best & is the cheapest.” 
  @thijs : The nice thing about Paper is that we can point out to clients that it took 18 experienced designers and developers two years to build. 
  @neil_conway : My guess is that the split between Spanner and F1 is a great example of Conway's Law. 
 
 
 How F</p><p>6 0.93781376 <a title="825-lda-6" href="../high_scalability-2010/high_scalability-2010-12-21-SQL_%2B_NoSQL_%3D_Yes_%21.html">961 high scalability-2010-12-21-SQL + NoSQL = Yes !</a></p>
<p>7 0.9372409 <a title="825-lda-7" href="../high_scalability-2007/high_scalability-2007-07-24-Major_Websites_Down%3A_Or_Why_You_Want_to_Run_in_Two_or_More_Data_Centers..html">23 high scalability-2007-07-24-Major Websites Down: Or Why You Want to Run in Two or More Data Centers.</a></p>
<p>8 0.93175578 <a title="825-lda-8" href="../high_scalability-2011/high_scalability-2011-08-15-Should_any_cloud_be_considered_one_availability_zone%3F_The_Amazon_experience_says_yes..html">1098 high scalability-2011-08-15-Should any cloud be considered one availability zone? The Amazon experience says yes.</a></p>
<p>9 0.9308058 <a title="825-lda-9" href="../high_scalability-2009/high_scalability-2009-06-05-HotPads_Shows_the_True_Cost_of_Hosting_on_Amazon.html">619 high scalability-2009-06-05-HotPads Shows the True Cost of Hosting on Amazon</a></p>
<p>10 0.93004763 <a title="825-lda-10" href="../high_scalability-2012/high_scalability-2012-07-25-Vertical_Scaling_Ascendant_-_How_are_SSDs_Changing__Architectures%3F.html">1291 high scalability-2012-07-25-Vertical Scaling Ascendant - How are SSDs Changing  Architectures?</a></p>
<p>11 0.92994112 <a title="825-lda-11" href="../high_scalability-2009/high_scalability-2009-01-20-Product%3A_Amazon%27s_SimpleDB.html">498 high scalability-2009-01-20-Product: Amazon's SimpleDB</a></p>
<p>12 0.92989963 <a title="825-lda-12" href="../high_scalability-2007/high_scalability-2007-08-22-Wikimedia_architecture.html">72 high scalability-2007-08-22-Wikimedia architecture</a></p>
<p>13 0.92800808 <a title="825-lda-13" href="../high_scalability-2011/high_scalability-2011-09-07-What_Google_App_Engine_Price_Changes_Say_About_the_Future_of_Web_Architecture.html">1112 high scalability-2011-09-07-What Google App Engine Price Changes Say About the Future of Web Architecture</a></p>
<p>14 0.9248901 <a title="825-lda-14" href="../high_scalability-2009/high_scalability-2009-08-06-An_Unorthodox_Approach_to_Database_Design_%3A_The_Coming_of_the_Shard.html">672 high scalability-2009-08-06-An Unorthodox Approach to Database Design : The Coming of the Shard</a></p>
<p>15 0.92363459 <a title="825-lda-15" href="../high_scalability-2012/high_scalability-2012-03-14-The_Azure_Outage%3A_Time_Is_a_SPOF%2C_Leap_Day_Doubly_So.html">1209 high scalability-2012-03-14-The Azure Outage: Time Is a SPOF, Leap Day Doubly So</a></p>
<p>16 0.92338628 <a title="825-lda-16" href="../high_scalability-2014/high_scalability-2014-05-16-Stuff_The_Internet_Says_On_Scalability_For_May_16th%2C_2014.html">1649 high scalability-2014-05-16-Stuff The Internet Says On Scalability For May 16th, 2014</a></p>
<p>17 0.92337418 <a title="825-lda-17" href="../high_scalability-2011/high_scalability-2011-09-16-Stuff_The_Internet_Says_On_Scalability_For_September_16%2C_2011.html">1117 high scalability-2011-09-16-Stuff The Internet Says On Scalability For September 16, 2011</a></p>
<p>18 0.92302114 <a title="825-lda-18" href="../high_scalability-2010/high_scalability-2010-06-28-VoltDB_Decapitates_Six_SQL_Urban_Myths_and_Delivers_Internet_Scale_OLTP_in_the_Process.html">849 high scalability-2010-06-28-VoltDB Decapitates Six SQL Urban Myths and Delivers Internet Scale OLTP in the Process</a></p>
<p>19 0.92171216 <a title="825-lda-19" href="../high_scalability-2014/high_scalability-2014-04-25-Stuff_The_Internet_Says_On_Scalability_For_April_25th%2C_2014.html">1637 high scalability-2014-04-25-Stuff The Internet Says On Scalability For April 25th, 2014</a></p>
<p>20 0.9215551 <a title="825-lda-20" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
