<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>143 high scalability-2007-11-06-Product: ChironFS</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2007" href="../home/high_scalability-2007_home.html">high_scalability-2007</a> <a title="high_scalability-2007-143" href="#">high_scalability-2007-143</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>143 high scalability-2007-11-06-Product: ChironFS</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2007-143-html" href="http://highscalability.com//blog/2007/11/6/product-chironfs.html">html</a></p><p>Introduction: If you are trying to create highly available file systems, especially across data centers,  then ChironFS is one potential solution. It's relatively new, so there aren't lots of experience reports, but it looks worth considering. What is  ChironFS  and how does it work?
 
Adapted from the ChironFS website:   The Chiron Filesystem is a Fuse based filesystem that frees you from single points of failure. It's main purpose is to guarantee filesystem availability using replication. But it isn't a RAID implementation. RAID replicates DEVICES not FILESYSTEMS.  Why not just use RAID over some network block device? Because it is a block device and if one server mounts that device in RW mode, no other server will be able to mount it in RW mode. Any real network may have many servers and offer a variety of services. Keeping everything running can become a real nightmare!</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 If you are trying to create highly available file systems, especially across data centers,  then ChironFS is one potential solution. [sent-1, score-0.46]
</p><p>2 It's relatively new, so there aren't lots of experience reports, but it looks worth considering. [sent-2, score-0.311]
</p><p>3 Adapted from the ChironFS website:   The Chiron Filesystem is a Fuse based filesystem that frees you from single points of failure. [sent-4, score-0.641]
</p><p>4 It's main purpose is to guarantee filesystem availability using replication. [sent-5, score-0.663]
</p><p>5 Why not just use RAID over some network block device? [sent-8, score-0.242]
</p><p>6 Because it is a block device and if one server mounts that device in RW mode, no other server will be able to mount it in RW mode. [sent-9, score-1.208]
</p><p>7 Any real network may have many servers and offer a variety of services. [sent-10, score-0.338]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('chironfs', 0.448), ('rw', 0.406), ('filesystem', 0.35), ('raid', 0.286), ('device', 0.256), ('fuse', 0.182), ('mounts', 0.182), ('block', 0.177), ('frees', 0.154), ('nightmare', 0.152), ('mount', 0.149), ('adapted', 0.144), ('replicates', 0.133), ('guarantee', 0.104), ('mode', 0.1), ('reports', 0.096), ('purpose', 0.09), ('variety', 0.088), ('real', 0.083), ('devices', 0.082), ('centers', 0.082), ('potential', 0.078), ('relatively', 0.074), ('keeping', 0.073), ('points', 0.069), ('main', 0.069), ('offer', 0.068), ('worth', 0.068), ('looks', 0.066), ('network', 0.065), ('trying', 0.063), ('especially', 0.063), ('lots', 0.057), ('become', 0.055), ('server', 0.054), ('website', 0.053), ('file', 0.05), ('availability', 0.05), ('highly', 0.049), ('everything', 0.046), ('experience', 0.046), ('able', 0.044), ('available', 0.043), ('create', 0.042), ('running', 0.038), ('across', 0.036), ('one', 0.036), ('based', 0.034), ('may', 0.034), ('single', 0.034)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="143-tfidf-1" href="../high_scalability-2007/high_scalability-2007-11-06-Product%3A_ChironFS.html">143 high scalability-2007-11-06-Product: ChironFS</a></p>
<p>Introduction: If you are trying to create highly available file systems, especially across data centers,  then ChironFS is one potential solution. It's relatively new, so there aren't lots of experience reports, but it looks worth considering. What is  ChironFS  and how does it work?
 
Adapted from the ChironFS website:   The Chiron Filesystem is a Fuse based filesystem that frees you from single points of failure. It's main purpose is to guarantee filesystem availability using replication. But it isn't a RAID implementation. RAID replicates DEVICES not FILESYSTEMS.  Why not just use RAID over some network block device? Because it is a block device and if one server mounts that device in RW mode, no other server will be able to mount it in RW mode. Any real network may have many servers and offer a variety of services. Keeping everything running can become a real nightmare!</p><p>2 0.24085411 <a title="143-tfidf-2" href="../high_scalability-2008/high_scalability-2008-03-08-Product%3A_DRBD_-_Distributed_Replicated_Block_Device.html">271 high scalability-2008-03-08-Product: DRBD - Distributed Replicated Block Device</a></p>
<p>Introduction: From their website:   DRBD  is a block device which is designed to build high availability clusters. This is done by mirroring a whole block device via (a dedicated) network. You could see it as a network raid-1.  DRBD takes over the data, writes it to the local disk and sends it to the other host. On the other host, it takes it to the disk there.  
   
  The other components needed are a cluster membership service, which is supposed to be heartbeat, and some kind of application that works on top of a block device.  Examples: A filesystem & fsck. A journaling FS. A database with recovery capabilities.  Each device (DRBD provides more than one of these devices) has a state, which can be 'primary' or 'secondary'. On the node with the primary device the application is supposed to run and to access the device (/dev/drbdX). Every write is sent to the local 'lower level block device' and to the node with the device in 'secondary' state. The secondary device simply writes the data to its lowe</p><p>3 0.24054761 <a title="143-tfidf-3" href="../high_scalability-2007/high_scalability-2007-08-01-Product%3A_MogileFS.html">53 high scalability-2007-08-01-Product: MogileFS</a></p>
<p>Introduction: MogileFS  is an open source distributed filesystem. Its properties and features include: Application level, No single point of failure, Automatic file replication, Better than RAID, Flat Namespace, Shared-Nothing, No RAID required, Local filesystem agnostic.</p><p>4 0.10226515 <a title="143-tfidf-4" href="../high_scalability-2012/high_scalability-2012-07-09-Data_Replication_in_NoSQL_Databases.html">1279 high scalability-2012-07-09-Data Replication in NoSQL Databases</a></p>
<p>Introduction: This is the third guest post  (  part 1  ,   part 2  ) of a series by Greg Lindahl, CTO of blekko, the spam free search engine. Previously, Greg was Founder and Distinguished Engineer at PathScale, at which he was the architect of the InfiniPath low-latency InfiniBand HCA, used to build tightly-coupled supercomputing clusters. 
 
blekko's home-grown NoSQL database was designed from the start to support a web-scale search engine, with 1,000s of servers and petabytes of disk. Data replication is a very important part of keeping the database up and serving queries.  Like many NoSQL database authors, we decided to keep R=3 copies of each piece of data in the database, and not use RAID to improve reliability. The key goal we were shooting for was a database which degrades gracefully when there are many small failures over time, without needing human intervention.
  Why don't we like RAID for big NoSQL databases?  
Most big storage systems use RAID levels like 3, 4, 5, or 10 to improve relia</p><p>5 0.09983135 <a title="143-tfidf-5" href="../high_scalability-2012/high_scalability-2012-10-26-Stuff_The_Internet_Says_On_Scalability_For_October_26%2C_2012.html">1348 high scalability-2012-10-26-Stuff The Internet Says On Scalability For October 26, 2012</a></p>
<p>Introduction: It's HighScalability Time:
  
  1.5 Billion Pageviews : Etsy in September;  200 dedicated database servers : Tumblr 
 Quotable Quotes:                                  
 
  @rbranson  :  Datadog stays available  where it counts (metrics injest) by using Cassandra, combined with an RDBMS for queries. Nice.  
  @jmhodges  : Few engineers know what modern hw is capable of, in part, because the only people that see the numbers are in orgs that had to care or die. 
  @tinagroves  : Storing the brain in the cloud might cost $38/month asserts Jim Adelius at #strataconf in talk on #bigdata and thought crimes. 
 
 
 
  Why is it hard to scale a database, in layman’s terms?  on Quora. Some really good answers. My answer would involve a cookie jar filled with all different kinds of cookies and a motley crew of kindergartners all trying to get cookies at the same time while keebler elves are trying to fill up the jar, all at the same time. 
 
 Rackspace now has their own  cloud block storage  prod</p><p>6 0.097492114 <a title="143-tfidf-6" href="../high_scalability-2009/high_scalability-2009-04-29-How_to_choice_and_build_perfect_server.html">585 high scalability-2009-04-29-How to choice and build perfect server</a></p>
<p>7 0.083249293 <a title="143-tfidf-7" href="../high_scalability-2012/high_scalability-2012-01-19-Is_it_time_to_get_rid_of_the_Linux_OS_model_in_the_cloud%3F.html">1177 high scalability-2012-01-19-Is it time to get rid of the Linux OS model in the cloud?</a></p>
<p>8 0.082118466 <a title="143-tfidf-8" href="../high_scalability-2008/high_scalability-2008-03-18-Shared_filesystem_on_EC2.html">283 high scalability-2008-03-18-Shared filesystem on EC2</a></p>
<p>9 0.079476759 <a title="143-tfidf-9" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>10 0.076940112 <a title="143-tfidf-10" href="../high_scalability-2013/high_scalability-2013-06-10-The_10_Deadly_Sins_Against_Scalability.html">1473 high scalability-2013-06-10-The 10 Deadly Sins Against Scalability</a></p>
<p>11 0.076669231 <a title="143-tfidf-11" href="../high_scalability-2011/high_scalability-2011-04-06-Netflix%3A_Run_Consistency_Checkers_All_the_time_to_Fixup_Transactions.html">1017 high scalability-2011-04-06-Netflix: Run Consistency Checkers All the time to Fixup Transactions</a></p>
<p>12 0.074977376 <a title="143-tfidf-12" href="../high_scalability-2013/high_scalability-2013-09-04-Wide_Fast_SATA%3A_the_Recipe_for_Hot_Performance.html">1511 high scalability-2013-09-04-Wide Fast SATA: the Recipe for Hot Performance</a></p>
<p>13 0.072691716 <a title="143-tfidf-13" href="../high_scalability-2011/high_scalability-2011-06-06-Apple_iCloud%3A_Syncing_and_Distributed_Storage_Over_Streaming_and_Centralized_Storage.html">1053 high scalability-2011-06-06-Apple iCloud: Syncing and Distributed Storage Over Streaming and Centralized Storage</a></p>
<p>14 0.072502188 <a title="143-tfidf-14" href="../high_scalability-2007/high_scalability-2007-09-18-Sync_data_on_all_servers.html">98 high scalability-2007-09-18-Sync data on all servers</a></p>
<p>15 0.071618535 <a title="143-tfidf-15" href="../high_scalability-2011/high_scalability-2011-09-13-Must_see%3A_5_Steps_to_Scaling_MongoDB_%28Or_Any_DB%29_in_8_Minutes.html">1114 high scalability-2011-09-13-Must see: 5 Steps to Scaling MongoDB (Or Any DB) in 8 Minutes</a></p>
<p>16 0.06631317 <a title="143-tfidf-16" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>17 0.06466525 <a title="143-tfidf-17" href="../high_scalability-2010/high_scalability-2010-05-03-MocoSpace_Architecture_-_3_Billion_Mobile_Page_Views_a_Month.html">821 high scalability-2010-05-03-MocoSpace Architecture - 3 Billion Mobile Page Views a Month</a></p>
<p>18 0.064517781 <a title="143-tfidf-18" href="../high_scalability-2010/high_scalability-2010-08-16-Scaling_an_AWS_infrastructure_-_Tools_and_Patterns.html">881 high scalability-2010-08-16-Scaling an AWS infrastructure - Tools and Patterns</a></p>
<p>19 0.059398532 <a title="143-tfidf-19" href="../high_scalability-2007/high_scalability-2007-08-20-TypePad_Architecture.html">68 high scalability-2007-08-20-TypePad Architecture</a></p>
<p>20 0.059319898 <a title="143-tfidf-20" href="../high_scalability-2010/high_scalability-2010-12-21-SQL_%2B_NoSQL_%3D_Yes_%21.html">961 high scalability-2010-12-21-SQL + NoSQL = Yes !</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.083), (1, 0.037), (2, -0.007), (3, -0.022), (4, -0.036), (5, 0.018), (6, 0.038), (7, -0.012), (8, -0.0), (9, 0.005), (10, -0.015), (11, -0.017), (12, -0.001), (13, -0.02), (14, 0.03), (15, 0.04), (16, 0.009), (17, 0.04), (18, -0.034), (19, 0.007), (20, 0.017), (21, 0.012), (22, -0.034), (23, 0.03), (24, -0.011), (25, -0.01), (26, 0.051), (27, -0.022), (28, -0.068), (29, 0.01), (30, -0.051), (31, -0.005), (32, 0.05), (33, -0.043), (34, 0.01), (35, 0.019), (36, 0.021), (37, 0.006), (38, -0.026), (39, -0.023), (40, -0.022), (41, -0.052), (42, -0.054), (43, 0.033), (44, -0.005), (45, -0.044), (46, -0.002), (47, 0.056), (48, -0.045), (49, 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93650019 <a title="143-lsi-1" href="../high_scalability-2007/high_scalability-2007-11-06-Product%3A_ChironFS.html">143 high scalability-2007-11-06-Product: ChironFS</a></p>
<p>Introduction: If you are trying to create highly available file systems, especially across data centers,  then ChironFS is one potential solution. It's relatively new, so there aren't lots of experience reports, but it looks worth considering. What is  ChironFS  and how does it work?
 
Adapted from the ChironFS website:   The Chiron Filesystem is a Fuse based filesystem that frees you from single points of failure. It's main purpose is to guarantee filesystem availability using replication. But it isn't a RAID implementation. RAID replicates DEVICES not FILESYSTEMS.  Why not just use RAID over some network block device? Because it is a block device and if one server mounts that device in RW mode, no other server will be able to mount it in RW mode. Any real network may have many servers and offer a variety of services. Keeping everything running can become a real nightmare!</p><p>2 0.78874385 <a title="143-lsi-2" href="../high_scalability-2007/high_scalability-2007-08-01-Product%3A_MogileFS.html">53 high scalability-2007-08-01-Product: MogileFS</a></p>
<p>Introduction: MogileFS  is an open source distributed filesystem. Its properties and features include: Application level, No single point of failure, Automatic file replication, Better than RAID, Flat Namespace, Shared-Nothing, No RAID required, Local filesystem agnostic.</p><p>3 0.73362112 <a title="143-lsi-3" href="../high_scalability-2008/high_scalability-2008-03-08-Product%3A_DRBD_-_Distributed_Replicated_Block_Device.html">271 high scalability-2008-03-08-Product: DRBD - Distributed Replicated Block Device</a></p>
<p>Introduction: From their website:   DRBD  is a block device which is designed to build high availability clusters. This is done by mirroring a whole block device via (a dedicated) network. You could see it as a network raid-1.  DRBD takes over the data, writes it to the local disk and sends it to the other host. On the other host, it takes it to the disk there.  
   
  The other components needed are a cluster membership service, which is supposed to be heartbeat, and some kind of application that works on top of a block device.  Examples: A filesystem & fsck. A journaling FS. A database with recovery capabilities.  Each device (DRBD provides more than one of these devices) has a state, which can be 'primary' or 'secondary'. On the node with the primary device the application is supposed to run and to access the device (/dev/drbdX). Every write is sent to the local 'lower level block device' and to the node with the device in 'secondary' state. The secondary device simply writes the data to its lowe</p><p>4 0.68987024 <a title="143-lsi-4" href="../high_scalability-2007/high_scalability-2007-09-18-Sync_data_on_all_servers.html">98 high scalability-2007-09-18-Sync data on all servers</a></p>
<p>Introduction: I have a few apache servers ( arround 11 atm ) serving a small amount of data ( arround 44 gigs right now ).     For some time I have been using rsync to keep all the content equal on all servers, but the amount of data has been growing, and rsync takes a few too much time to "compare" all data from source to destination, and create a lot of I/O.     I have been taking a look at MogileFS, it seems a good and reliable option, but as the fuse module is not finished, we should have to rewrite all our apps, and its not an option atm.     Any ideas?     I just want a "real time, non resource-hungry" solution alternative for rsync. If I get more features on the way, then they are welcome :)     Why I prefer to use a Distributed File System instead of using NAS + NFS?     - I need 2 NAS, if I dont want a point of failure, and NAS hard is expensive.   - Non-shared hardware, all server has their own local disks.   - As files are replicated, I can save a lot of money, RAID is not a MUST.     Thn</p><p>5 0.68389887 <a title="143-lsi-5" href="../high_scalability-2007/high_scalability-2007-09-28-Kosmos_File_System_%28KFS%29_is_a_New_High_End_Google_File_System_Option.html">103 high scalability-2007-09-28-Kosmos File System (KFS) is a New High End Google File System Option</a></p>
<p>Introduction: There's a new clustered file system on the spindle:   Kosmos File System (KFS)  .  Thanks to Rich Skrenta for turning me on to KFS and I think his blog   post   says it all.  KFS is an open source project written in C++ by search startup   Kosmix  . The team members have a good   pedigree   so there's a better than average chance this software will be worth considering.     After you stop trying to turn KFS into "Kentucky Fried File System" in your mind,  take a look at KFS' intriguing feature set:           Incremental scalability: New chunkserver nodes can be added as storage needs increase; the system automatically adapts to the new nodes.  Availability: Replication is used to provide availability due to chunk server failures. Typically, files are replicated 3-way.   Per file degree of replication: The degree of replication is configurable on a per file basis, with a max. limit of 64.   Re-replication: Whenever the degree of replication for a file drops below the configured amount (</p><p>6 0.67803884 <a title="143-lsi-6" href="../high_scalability-2012/high_scalability-2012-07-09-Data_Replication_in_NoSQL_Databases.html">1279 high scalability-2012-07-09-Data Replication in NoSQL Databases</a></p>
<p>7 0.66359466 <a title="143-lsi-7" href="../high_scalability-2007/high_scalability-2007-10-04-You_Can_Now_Store_All_Your_Stuff_on_Your_Own_Google_Like_File_System.html">112 high scalability-2007-10-04-You Can Now Store All Your Stuff on Your Own Google Like File System</a></p>
<p>8 0.64295042 <a title="143-lsi-8" href="../high_scalability-2008/high_scalability-2008-03-16-Product%3A_GlusterFS.html">278 high scalability-2008-03-16-Product: GlusterFS</a></p>
<p>9 0.61561829 <a title="143-lsi-9" href="../high_scalability-2009/high_scalability-2009-01-08-file_synchronization_solutions.html">488 high scalability-2009-01-08-file synchronization solutions</a></p>
<p>10 0.6124779 <a title="143-lsi-10" href="../high_scalability-2010/high_scalability-2010-08-30-Pomegranate_-_Storing_Billions_and_Billions_of_Tiny_Little_Files.html">889 high scalability-2010-08-30-Pomegranate - Storing Billions and Billions of Tiny Little Files</a></p>
<p>11 0.6100651 <a title="143-lsi-11" href="../high_scalability-2008/high_scalability-2008-01-29-Building_scalable_storage_into_application_-_Instead_of_MogileFS_OpenAFS_etc..html">229 high scalability-2008-01-29-Building scalable storage into application - Instead of MogileFS OpenAFS etc.</a></p>
<p>12 0.59580666 <a title="143-lsi-12" href="../high_scalability-2007/high_scalability-2007-10-21-Paper%3A_Standardizing_Storage_Clusters_%28with_pNFS%29.html">128 high scalability-2007-10-21-Paper: Standardizing Storage Clusters (with pNFS)</a></p>
<p>13 0.58506775 <a title="143-lsi-13" href="../high_scalability-2008/high_scalability-2008-10-26-Should_you_use_a_SAN_to_scale_your_architecture%3F_.html">430 high scalability-2008-10-26-Should you use a SAN to scale your architecture? </a></p>
<p>14 0.57657117 <a title="143-lsi-14" href="../high_scalability-2013/high_scalability-2013-04-17-Tachyon__-_Fault_Tolerant_Distributed_File_System_with_300_Times_Higher_Throughput_than_HDFS.html">1442 high scalability-2013-04-17-Tachyon  - Fault Tolerant Distributed File System with 300 Times Higher Throughput than HDFS</a></p>
<p>15 0.57456899 <a title="143-lsi-15" href="../high_scalability-2009/high_scalability-2009-07-08-Servers_Component_-_How_to_choice_and_build_perfect_server.html">653 high scalability-2009-07-08-Servers Component - How to choice and build perfect server</a></p>
<p>16 0.57310098 <a title="143-lsi-16" href="../high_scalability-2007/high_scalability-2007-07-31-BerkeleyDB_%26_other_distributed_high_performance_key-value_databases.html">50 high scalability-2007-07-31-BerkeleyDB & other distributed high performance key-value databases</a></p>
<p>17 0.57213336 <a title="143-lsi-17" href="../high_scalability-2009/high_scalability-2009-04-29-How_to_choice_and_build_perfect_server.html">585 high scalability-2009-04-29-How to choice and build perfect server</a></p>
<p>18 0.56535321 <a title="143-lsi-18" href="../high_scalability-2008/high_scalability-2008-03-18-Shared_filesystem_on_EC2.html">283 high scalability-2008-03-18-Shared filesystem on EC2</a></p>
<p>19 0.56357181 <a title="143-lsi-19" href="../high_scalability-2011/high_scalability-2011-05-05-Paper%3A_A_Study_of_Practical_Deduplication.html">1035 high scalability-2011-05-05-Paper: A Study of Practical Deduplication</a></p>
<p>20 0.56156063 <a title="143-lsi-20" href="../high_scalability-2009/high_scalability-2009-02-05-Beta_testers_wanted_for_ultra_high-scalability-performance_clustered_object_storage_system_designed_for_web_content_delivery.html">508 high scalability-2009-02-05-Beta testers wanted for ultra high-scalability-performance clustered object storage system designed for web content delivery</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.162), (61, 0.043), (79, 0.114), (85, 0.533)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93849874 <a title="143-lda-1" href="../high_scalability-2007/high_scalability-2007-08-04-Try_Squid_as_a_Reverse_Proxy.html">59 high scalability-2007-08-04-Try Squid as a Reverse Proxy</a></p>
<p>Introduction: This scalability strategy is brought to you by Erik Osterman:   My recommendations for anyone dealing with explosive growth on a limited budget with lots of cachable content (e.g. content capable of returning valid expiration headers) is employ a    reverse proxy    as mentioned in this article.   In the last week, we had a site get AP'd, triggering 100K unique visitors to a single IIS server in under 5 hours. It took out the IIS server. Placing a single squid infront of the server handled the entire onslaught with a max server load of 0.10 on a modest Intel IV 3Ghz.  It's trivial to implement for anyone interested...</p><p>2 0.91332507 <a title="143-lda-2" href="../high_scalability-2011/high_scalability-2011-05-31-Awesome_List_of_Advanced_Distributed_Systems_Papers.html">1049 high scalability-2011-05-31-Awesome List of Advanced Distributed Systems Papers</a></p>
<p>Introduction: As part of  Dr. Indranil Gupta 's  CS 525 Spring 2011 Advanced Distributed Systems  class, he has collected an incredible  list of resources on distributed systems . His  research group  is also doing some interesting work.
 
The  various topics  include: Before there Were Clouds, Cloud Computing, P2P Systems, Basic Distributed Computing Concepts, Sensor Networks, Overlays and DHTs, Cloud Programming, Cloud Scheduling, Key-Value Stores, Storage, Sensor Net Routing, Geo-Distribution, P2P Apps, In-network processing, Epidemics, Probabilistic Membership Protocols, Distributed Monitoring and  Management, Publish-Subscribe/CDNs, Measurement Studies, Old Wine: Stale or Vintage?, In Byzantium, Cloud Pricing, Other Industrial Systems, Structure of Networks, Completing the Circle, Green Clouds, Distributed Debugging, Flash!, The Middle or the End?, Availability-Aware Systems, Design Methodologies, Handling Stress, Sources of unreliability in networks, Handling Stress, Selfish algorithms, Securi</p><p>same-blog 3 0.88215566 <a title="143-lda-3" href="../high_scalability-2007/high_scalability-2007-11-06-Product%3A_ChironFS.html">143 high scalability-2007-11-06-Product: ChironFS</a></p>
<p>Introduction: If you are trying to create highly available file systems, especially across data centers,  then ChironFS is one potential solution. It's relatively new, so there aren't lots of experience reports, but it looks worth considering. What is  ChironFS  and how does it work?
 
Adapted from the ChironFS website:   The Chiron Filesystem is a Fuse based filesystem that frees you from single points of failure. It's main purpose is to guarantee filesystem availability using replication. But it isn't a RAID implementation. RAID replicates DEVICES not FILESYSTEMS.  Why not just use RAID over some network block device? Because it is a block device and if one server mounts that device in RW mode, no other server will be able to mount it in RW mode. Any real network may have many servers and offer a variety of services. Keeping everything running can become a real nightmare!</p><p>4 0.87024516 <a title="143-lda-4" href="../high_scalability-2007/high_scalability-2007-12-23-Synchronizing_Memcached_application.html">191 high scalability-2007-12-23-Synchronizing Memcached application</a></p>
<p>Introduction: I have an application with couple of web servers that uses MemcacheD. How can i synchronize concurrent put to the cache? The value of the entry  is list.     Atomic append operation could have been helpful, but unfortunately memcahe doesn't support atomic append.</p><p>5 0.86701465 <a title="143-lda-5" href="../high_scalability-2008/high_scalability-2008-11-19-High_Definition_Video_Delivery_on_the_Web%3F.html">447 high scalability-2008-11-19-High Definition Video Delivery on the Web?</a></p>
<p>Introduction: How would you architect and implement an SD and HD internet video delivery system such as the BBC iPlayer or   Recast Digital's RDV1  . What do you need to consider on top of the Lessons Learned section in the   YouTube Architecture   post?     How is it possible to compete with the big players like Google? Can you just use a CDN and scale efficiently? Would Amazon's cloud services be a viable platform for high-definition video streaming?</p><p>6 0.85284168 <a title="143-lda-6" href="../high_scalability-2010/high_scalability-2010-05-03-100_Node_Hazelcast_cluster_on_Amazon_EC2.html">820 high scalability-2010-05-03-100 Node Hazelcast cluster on Amazon EC2</a></p>
<p>7 0.82039905 <a title="143-lda-7" href="../high_scalability-2007/high_scalability-2007-09-27-Product%3A_Sequoia_Database_Clustering_Technology.html">102 high scalability-2007-09-27-Product: Sequoia Database Clustering Technology</a></p>
<p>8 0.8044765 <a title="143-lda-8" href="../high_scalability-2011/high_scalability-2011-05-12-Paper%3A_Mind_the_Gap%3A_Reconnecting_Architecture_and_OS_Research.html">1039 high scalability-2011-05-12-Paper: Mind the Gap: Reconnecting Architecture and OS Research</a></p>
<p>9 0.77821559 <a title="143-lda-9" href="../high_scalability-2011/high_scalability-2011-05-02-Stack_Overflow_Makes_Slow_Pages_100x_Faster_by_Simple_SQL_Tuning.html">1032 high scalability-2011-05-02-Stack Overflow Makes Slow Pages 100x Faster by Simple SQL Tuning</a></p>
<p>10 0.76461887 <a title="143-lda-10" href="../high_scalability-2011/high_scalability-2011-12-27-PlentyOfFish_Update_-_6_Billion_Pageviews_and_32_Billion_Images_a_Month.html">1164 high scalability-2011-12-27-PlentyOfFish Update - 6 Billion Pageviews and 32 Billion Images a Month</a></p>
<p>11 0.74680495 <a title="143-lda-11" href="../high_scalability-2013/high_scalability-2013-08-12-100_Curse_Free_Lessons_from_Gordon_Ramsay_on_Building_Great_Software.html">1500 high scalability-2013-08-12-100 Curse Free Lessons from Gordon Ramsay on Building Great Software</a></p>
<p>12 0.74671376 <a title="143-lda-12" href="../high_scalability-2014/high_scalability-2014-01-13-NYTimes_Architecture%3A_No_Head%2C_No_Master%2C_No_Single_Point_of_Failure.html">1577 high scalability-2014-01-13-NYTimes Architecture: No Head, No Master, No Single Point of Failure</a></p>
<p>13 0.73875326 <a title="143-lda-13" href="../high_scalability-2012/high_scalability-2012-05-04-Stuff_The_Internet_Says_On_Scalability_For_May_4%2C_2012.html">1239 high scalability-2012-05-04-Stuff The Internet Says On Scalability For May 4, 2012</a></p>
<p>14 0.71202075 <a title="143-lda-14" href="../high_scalability-2009/high_scalability-2009-01-16-Database_Sharding_for_startups.html">492 high scalability-2009-01-16-Database Sharding for startups</a></p>
<p>15 0.6868881 <a title="143-lda-15" href="../high_scalability-2011/high_scalability-2011-04-15-Stuff_The_Internet_Says_On_Scalability_For_April_15%2C_2011.html">1024 high scalability-2011-04-15-Stuff The Internet Says On Scalability For April 15, 2011</a></p>
<p>16 0.68618834 <a title="143-lda-16" href="../high_scalability-2007/high_scalability-2007-10-09-High_Load_on_production_Webservers_after_Sourcecode_sync.html">118 high scalability-2007-10-09-High Load on production Webservers after Sourcecode sync</a></p>
<p>17 0.67310655 <a title="143-lda-17" href="../high_scalability-2014/high_scalability-2014-02-07-Stuff_The_Internet_Says_On_Scalability_For_February_7th%2C_2014.html">1592 high scalability-2014-02-07-Stuff The Internet Says On Scalability For February 7th, 2014</a></p>
<p>18 0.67074096 <a title="143-lda-18" href="../high_scalability-2009/high_scalability-2009-06-26-PlentyOfFish_Architecture.html">638 high scalability-2009-06-26-PlentyOfFish Architecture</a></p>
<p>19 0.66982645 <a title="143-lda-19" href="../high_scalability-2012/high_scalability-2012-11-22-Gone_Fishin%27%3A_PlentyOfFish_Architecture.html">1361 high scalability-2012-11-22-Gone Fishin': PlentyOfFish Architecture</a></p>
<p>20 0.6657185 <a title="143-lda-20" href="../high_scalability-2012/high_scalability-2012-09-21-Stuff_The_Internet_Says_On_Scalability_For_September_21%2C_2012.html">1327 high scalability-2012-09-21-Stuff The Internet Says On Scalability For September 21, 2012</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
