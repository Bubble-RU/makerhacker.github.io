<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>155 high scalability-2007-11-15-Video: Dryad: A general-purpose distributed execution platform</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2007" href="../home/high_scalability-2007_home.html">high_scalability-2007</a> <a title="high_scalability-2007-155" href="#">high_scalability-2007-155</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>155 high scalability-2007-11-15-Video: Dryad: A general-purpose distributed execution platform</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2007-155-html" href="http://highscalability.com//blog/2007/11/15/video-dryad-a-general-purpose-distributed-execution-platform.html">html</a></p><p>Introduction: Dryad is Microsoft's answer to Google'smap-reduce. What's the question: How do
you process really large amounts of data? My initial impression of Dryad is
it's like a giant Unix command line filter on steroids. There are lots of
inputs, outputs, tees, queues, and merge sorts all connected together by a
master exec program. What else does Dryad have to offer the scalable
infrastructure wars?Dryad models programs as the execution of a directed
acyclic graph. Each vertex is a program and edges are typed communication
channels (files, TCP pipes, and shared memory channels within a process). Map-
reduce uses a different model. It's more like a large distributed sort where
the programmer defines functions for mapping, partitioning, and reducing. Each
approach seems to borrow from the spirit of its creating organization. The
graph approach seems a bit too complicated and map-reduce seems a bit too
simple. How ironic, in the Alanis Morissette sense.Dryad is a middleware layer
that executes gra</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dryad', 0.505), ('dag', 0.234), ('outputs', 0.182), ('channels', 0.166), ('graph', 0.165), ('edges', 0.149), ('executes', 0.145), ('inputs', 0.142), ('acyclic', 0.117), ('layer', 0.111), ('manipulated', 0.11), ('porridge', 0.11), ('seems', 0.107), ('abstractly', 0.105), ('borrow', 0.105), ('changeable', 0.105), ('planner', 0.101), ('ironic', 0.098), ('vertex', 0.095), ('programmer', 0.093)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="155-tfidf-1" href="../high_scalability-2007/high_scalability-2007-11-15-Video%3A_Dryad%3A_A_general-purpose_distributed_execution_platform.html">155 high scalability-2007-11-15-Video: Dryad: A general-purpose distributed execution platform</a></p>
<p>Introduction: Dryad is Microsoft's answer to Google'smap-reduce. What's the question: How do
you process really large amounts of data? My initial impression of Dryad is
it's like a giant Unix command line filter on steroids. There are lots of
inputs, outputs, tees, queues, and merge sorts all connected together by a
master exec program. What else does Dryad have to offer the scalable
infrastructure wars?Dryad models programs as the execution of a directed
acyclic graph. Each vertex is a program and edges are typed communication
channels (files, TCP pipes, and shared memory channels within a process). Map-
reduce uses a different model. It's more like a large distributed sort where
the programmer defines functions for mapping, partitioning, and reducing. Each
approach seems to borrow from the spirit of its creating organization. The
graph approach seems a bit too complicated and map-reduce seems a bit too
simple. How ironic, in the Alanis Morissette sense.Dryad is a middleware layer
that executes gra</p><p>2 0.33258381 <a title="155-tfidf-2" href="../high_scalability-2009/high_scalability-2009-05-06-Dyrad.html">591 high scalability-2009-05-06-Dyrad</a></p>
<p>Introduction: The Dryad Project is investigating programming models for writing parallel and
distributed programs to scale from a small cluster to a large data-center.</p><p>3 0.1741959 <a title="155-tfidf-3" href="../high_scalability-2010/high_scalability-2010-03-30-Running_Large_Graph_Algorithms_-_Evaluation_of_Current_State-of-the-Art_and_Lessons_Learned.html">801 high scalability-2010-03-30-Running Large Graph Algorithms - Evaluation of Current State-of-the-Art and Lessons Learned</a></p>
<p>Introduction: On the surface nothing appears more different than soft data and hard raw
materials like iron. Then isn't itironic, in theAlanis Morissettesense, that
in this Age of Information, great wealth still lies hidden deep beneath piles
of stuff? It's so strange how directly digging for dollars in data parallels
the great wealth producing models of the Industrial Revolution.The piles of
stuff is the Internet. It takes lots of prospecting to find the right stuff.
Mighty web crawling machines tirelessly collect stuff, bringing it into their
huge maws, then depositing load after load into rack after rack of distributed
file system machines. Then armies of still other machines take this stuff and
strip out the valuable raw materials, which in the Information Age, are
endless bytes of raw data. Link clicks, likes, page views, content, head
lines, searches, inbound links, outbound links, search clicks, hashtags,
friends, purchases: anything and everything you do on the Internet is a
valuable raw mat</p><p>4 0.17032368 <a title="155-tfidf-4" href="../high_scalability-2009/high_scalability-2009-05-06-DyradLINQ.html">592 high scalability-2009-05-06-DyradLINQ</a></p>
<p>Introduction: The goal of DryadLINQ is to make distributed computing on large compute
cluster simple enough for ordinary programmers. DryadLINQ combines two
important pieces of Microsoft technology: the Dryad distributed execution
engine and the .NET Language Integrated Query (LINQ).</p><p>5 0.1546582 <a title="155-tfidf-5" href="../high_scalability-2011/high_scalability-2011-11-03-Paper%3A_G2_%3A_A_Graph_Processing_System_for_Diagnosing_Distributed_Systems.html">1136 high scalability-2011-11-03-Paper: G2 : A Graph Processing System for Diagnosing Distributed Systems</a></p>
<p>Introduction: One of the problems in building distributed systems is figuring out what the
heck is going on. Usually endless streams of log files are consulted like
ancients usingentrailsto divine the will of the Gods.To rise above these
ancient practices we must rise another level of abstraction and that's the
approach described in a Microsoft research paper: G2: A Graph Processing
System for Diagnosing Distributed Systems, which uses execution graphs that
model runtime events and their correlations in distributed systems.The problem
with these schemes is viewing applications, written by programmers in low
level code, as execution graphs. But we're heading in this direction in any
case. To program a warehouse or an internet sized computer we'll have to write
at higher levels of abstraction so code can be executed transparently at
runtime on these giant distributed computers. There are many advantages to
this approach, fault diagnosis and performance monitoring are just one of the
wins.Abstract from</p><p>6 0.14111575 <a title="155-tfidf-6" href="../high_scalability-2009/high_scalability-2009-06-13-Neo4j_-_a_Graph_Database_that_Kicks_Buttox.html">628 high scalability-2009-06-13-Neo4j - a Graph Database that Kicks Buttox</a></p>
<p>7 0.12733805 <a title="155-tfidf-7" href="../high_scalability-2013/high_scalability-2013-02-14-When_all_the_Program%27s_a_Graph_-_Prismatic%27s_Plumbing_Library.html">1406 high scalability-2013-02-14-When all the Program's a Graph - Prismatic's Plumbing Library</a></p>
<p>8 0.11599361 <a title="155-tfidf-8" href="../high_scalability-2009/high_scalability-2009-08-18-Hardware_Architecture_Example_%28geographical_level_mapping_of_servers%29.html">683 high scalability-2009-08-18-Hardware Architecture Example (geographical level mapping of servers)</a></p>
<p>9 0.11551724 <a title="155-tfidf-9" href="../high_scalability-2010/high_scalability-2010-04-06-Strategy%3A_Make_it_Really_Fast_vs_Do_the_Work_Up_Front.html">805 high scalability-2010-04-06-Strategy: Make it Really Fast vs Do the Work Up Front</a></p>
<p>10 0.11489086 <a title="155-tfidf-10" href="../high_scalability-2010/high_scalability-2010-11-09-Facebook_Uses_Non-Stored_Procedures_to_Update_Social_Graphs.html">936 high scalability-2010-11-09-Facebook Uses Non-Stored Procedures to Update Social Graphs</a></p>
<p>11 0.10718364 <a title="155-tfidf-11" href="../high_scalability-2009/high_scalability-2009-06-10-Paper%3A_Graph_Databases_and_the_Future_of_Large-Scale_Knowledge_Management.html">626 high scalability-2009-06-10-Paper: Graph Databases and the Future of Large-Scale Knowledge Management</a></p>
<p>12 0.10220788 <a title="155-tfidf-12" href="../high_scalability-2009/high_scalability-2009-06-06-Graph_server.html">621 high scalability-2009-06-06-Graph server</a></p>
<p>13 0.10039495 <a title="155-tfidf-13" href="../high_scalability-2011/high_scalability-2011-07-27-Making_Hadoop_1000x_Faster_for_Graph_Problems.html">1088 high scalability-2011-07-27-Making Hadoop 1000x Faster for Graph Problems</a></p>
<p>14 0.095213391 <a title="155-tfidf-14" href="../high_scalability-2008/high_scalability-2008-09-28-Product%3A_Happy_%3D_Hadoop_%2B_Python.html">397 high scalability-2008-09-28-Product: Happy = Hadoop + Python</a></p>
<p>15 0.094639026 <a title="155-tfidf-15" href="../high_scalability-2011/high_scalability-2011-08-05-Stuff_The_Internet_Says_On_Scalability_For_August_5%2C_2011.html">1093 high scalability-2011-08-05-Stuff The Internet Says On Scalability For August 5, 2011</a></p>
<p>16 0.093342878 <a title="155-tfidf-16" href="../high_scalability-2009/high_scalability-2009-06-15-Large-scale_Graph_Computing_at_Google.html">631 high scalability-2009-06-15-Large-scale Graph Computing at Google</a></p>
<p>17 0.093134649 <a title="155-tfidf-17" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>18 0.092561506 <a title="155-tfidf-18" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>19 0.09203206 <a title="155-tfidf-19" href="../high_scalability-2012/high_scalability-2012-07-18-Disks_Ain%27t_Dead_Yet%3A_GraphChi_-_a_disk-based_large-scale_graph_computation.html">1285 high scalability-2012-07-18-Disks Ain't Dead Yet: GraphChi - a disk-based large-scale graph computation</a></p>
<p>20 0.090990283 <a title="155-tfidf-20" href="../high_scalability-2009/high_scalability-2009-07-17-Against_all_the_odds.html">658 high scalability-2009-07-17-Against all the odds</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.134), (1, 0.091), (2, 0.005), (3, 0.033), (4, 0.015), (5, 0.076), (6, -0.004), (7, 0.023), (8, -0.003), (9, 0.045), (10, 0.044), (11, 0.009), (12, -0.038), (13, -0.077), (14, 0.034), (15, -0.043), (16, -0.038), (17, 0.102), (18, 0.032), (19, 0.087), (20, -0.083), (21, -0.066), (22, -0.014), (23, 0.0), (24, 0.008), (25, 0.064), (26, 0.047), (27, 0.016), (28, 0.054), (29, -0.018), (30, -0.019), (31, -0.022), (32, -0.019), (33, 0.03), (34, -0.008), (35, 0.041), (36, 0.027), (37, -0.047), (38, -0.009), (39, 0.055), (40, -0.029), (41, 0.036), (42, 0.003), (43, -0.025), (44, 0.011), (45, -0.007), (46, 0.025), (47, -0.009), (48, 0.051), (49, -0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96206093 <a title="155-lsi-1" href="../high_scalability-2007/high_scalability-2007-11-15-Video%3A_Dryad%3A_A_general-purpose_distributed_execution_platform.html">155 high scalability-2007-11-15-Video: Dryad: A general-purpose distributed execution platform</a></p>
<p>Introduction: Dryad is Microsoft's answer to Google'smap-reduce. What's the question: How do
you process really large amounts of data? My initial impression of Dryad is
it's like a giant Unix command line filter on steroids. There are lots of
inputs, outputs, tees, queues, and merge sorts all connected together by a
master exec program. What else does Dryad have to offer the scalable
infrastructure wars?Dryad models programs as the execution of a directed
acyclic graph. Each vertex is a program and edges are typed communication
channels (files, TCP pipes, and shared memory channels within a process). Map-
reduce uses a different model. It's more like a large distributed sort where
the programmer defines functions for mapping, partitioning, and reducing. Each
approach seems to borrow from the spirit of its creating organization. The
graph approach seems a bit too complicated and map-reduce seems a bit too
simple. How ironic, in the Alanis Morissette sense.Dryad is a middleware layer
that executes gra</p><p>2 0.84892905 <a title="155-lsi-2" href="../high_scalability-2011/high_scalability-2011-11-03-Paper%3A_G2_%3A_A_Graph_Processing_System_for_Diagnosing_Distributed_Systems.html">1136 high scalability-2011-11-03-Paper: G2 : A Graph Processing System for Diagnosing Distributed Systems</a></p>
<p>Introduction: One of the problems in building distributed systems is figuring out what the
heck is going on. Usually endless streams of log files are consulted like
ancients usingentrailsto divine the will of the Gods.To rise above these
ancient practices we must rise another level of abstraction and that's the
approach described in a Microsoft research paper: G2: A Graph Processing
System for Diagnosing Distributed Systems, which uses execution graphs that
model runtime events and their correlations in distributed systems.The problem
with these schemes is viewing applications, written by programmers in low
level code, as execution graphs. But we're heading in this direction in any
case. To program a warehouse or an internet sized computer we'll have to write
at higher levels of abstraction so code can be executed transparently at
runtime on these giant distributed computers. There are many advantages to
this approach, fault diagnosis and performance monitoring are just one of the
wins.Abstract from</p><p>3 0.84862131 <a title="155-lsi-3" href="../high_scalability-2013/high_scalability-2013-02-14-When_all_the_Program%27s_a_Graph_-_Prismatic%27s_Plumbing_Library.html">1406 high scalability-2013-02-14-When all the Program's a Graph - Prismatic's Plumbing Library</a></p>
<p>Introduction: At some point as a programmer you might have the insight/fear that all
programming is just doing stuff to other stuff.Then you may observe after
coding the same stuff over again that stuff in a program often takes the form
of interacting patterns of flows.Then you may think hey, a program isn't only
useful for coding datastructures, but a program is a kind of datastructure and
that with a meta level jump you could program a program in terms of flows over
data and flow over other flows.That's the kind of stuff Prismatic is making
available in the Graph extension to their plumbing package (code examples),
which is described in an excellent post:Graph: Abstractions for Structured
Computation.You may remember Prismatic from previous profile we did on
HighScalability: Prismatic Architecture - Using Machine Learning On Social
Networks To Figure Out What You Should Read On The Web. We learned how
Prismatic, an interest driven content suggestion service, builds programs in
terms of graph stuff</p><p>4 0.80326271 <a title="155-lsi-4" href="../high_scalability-2010/high_scalability-2010-04-06-Strategy%3A_Make_it_Really_Fast_vs_Do_the_Work_Up_Front.html">805 high scalability-2010-04-06-Strategy: Make it Really Fast vs Do the Work Up Front</a></p>
<p>Introduction: InCool spatial algos with Neo4j: Part 1 - Routing with A* in RubyPeter
Neubauer not only does a fantastic job explaining a complicated routing
algorithm using the graph databaseNeo4j, but he surfaces an interesting
architectural conundrum:make it really fast so work can be done on the reads
or do all the work on the writes so the reads are really fast.The money quote
pointing out the competing options is:[Being] able to do these calculations in
sub-second speeds on graphs of millions of roads and waypoints makes it
possible in many cases to abandon the normal approach ofprecomputing indexes
with K/V stores and be able to put routing into the critical path with the
possibility to adapt to the live conditions and build highly personalized and
dynamic spatial services.ďťżThe poster boys for the precompute strategy
isSimpleGeo, a startup that is building a "scaling infrastructure for
geodata." Their strategy forhandling geodata is touse Cassandra and build two
clusters: one for indexes and o</p><p>5 0.80298424 <a title="155-lsi-5" href="../high_scalability-2009/high_scalability-2009-06-15-Large-scale_Graph_Computing_at_Google.html">631 high scalability-2009-06-15-Large-scale Graph Computing at Google</a></p>
<p>Introduction: To continue the graph theme Google has got into the act and released
information onPregel. Pregel does not appear to be a new type of potato chip.
Pregel is instead a scalable infrastructure......to mine a wide range of
graphs. In Pregel, programs are expressed as a sequence of iterations. In each
iteration, a vertex can, independently of other vertices, receive messages
sent to it in the previous iteration, send messages to other vertices, modify
its own and its outgoing edges' states, and mutate the graph's
topology.Currently, Pregel scales to billions of vertices and edges, but this
limit will keep expanding. Pregel's applicability is harder to quantify, but
so far we haven't come across a type of graph or a practical graph computing
problem which is not solvable with Pregel. It computes over large graphs much
faster than alternatives, and the application programming interface is easy to
use. Implementing PageRank, for example, takes only about 15 lines of code.
Developers of dozens</p><p>6 0.79565668 <a title="155-lsi-6" href="../high_scalability-2012/high_scalability-2012-07-18-Disks_Ain%27t_Dead_Yet%3A_GraphChi_-_a_disk-based_large-scale_graph_computation.html">1285 high scalability-2012-07-18-Disks Ain't Dead Yet: GraphChi - a disk-based large-scale graph computation</a></p>
<p>7 0.79031712 <a title="155-lsi-7" href="../high_scalability-2009/high_scalability-2009-06-13-Neo4j_-_a_Graph_Database_that_Kicks_Buttox.html">628 high scalability-2009-06-13-Neo4j - a Graph Database that Kicks Buttox</a></p>
<p>8 0.77766395 <a title="155-lsi-8" href="../high_scalability-2010/high_scalability-2010-01-26-Product%3A_HyperGraphDB_-_A_Graph_Database.html">766 high scalability-2010-01-26-Product: HyperGraphDB - A Graph Database</a></p>
<p>9 0.76982307 <a title="155-lsi-9" href="../high_scalability-2010/high_scalability-2010-03-30-Running_Large_Graph_Algorithms_-_Evaluation_of_Current_State-of-the-Art_and_Lessons_Learned.html">801 high scalability-2010-03-30-Running Large Graph Algorithms - Evaluation of Current State-of-the-Art and Lessons Learned</a></p>
<p>10 0.74608952 <a title="155-lsi-10" href="../high_scalability-2009/high_scalability-2009-06-10-Paper%3A_Graph_Databases_and_the_Future_of_Large-Scale_Knowledge_Management.html">626 high scalability-2009-06-10-Paper: Graph Databases and the Future of Large-Scale Knowledge Management</a></p>
<p>11 0.72305131 <a title="155-lsi-11" href="../high_scalability-2010/high_scalability-2010-06-16-Hot_Scalability_Links_for_June_16%2C_2010.html">842 high scalability-2010-06-16-Hot Scalability Links for June 16, 2010</a></p>
<p>12 0.71455282 <a title="155-lsi-12" href="../high_scalability-2011/high_scalability-2011-07-27-Making_Hadoop_1000x_Faster_for_Graph_Problems.html">1088 high scalability-2011-07-27-Making Hadoop 1000x Faster for Graph Problems</a></p>
<p>13 0.67468297 <a title="155-lsi-13" href="../high_scalability-2012/high_scalability-2012-06-13-Why_My_Soap_Film_is_Better_than_Your_Hadoop_Cluster.html">1263 high scalability-2012-06-13-Why My Soap Film is Better than Your Hadoop Cluster</a></p>
<p>14 0.66130531 <a title="155-lsi-14" href="../high_scalability-2010/high_scalability-2010-05-14-Hot_Scalability_Links_for_May_14%2C_2010.html">827 high scalability-2010-05-14-Hot Scalability Links for May 14, 2010</a></p>
<p>15 0.65252268 <a title="155-lsi-15" href="../high_scalability-2009/high_scalability-2009-06-06-Graph_server.html">621 high scalability-2009-06-06-Graph server</a></p>
<p>16 0.63253403 <a title="155-lsi-16" href="../high_scalability-2007/high_scalability-2007-08-04-Product%3A_Cacti.html">58 high scalability-2007-08-04-Product: Cacti</a></p>
<p>17 0.62367642 <a title="155-lsi-17" href="../high_scalability-2013/high_scalability-2013-09-05-Paper%3A_MillWheel%3A_Fault-Tolerant_Stream_Processing_at_Internet_Scale.html">1512 high scalability-2013-09-05-Paper: MillWheel: Fault-Tolerant Stream Processing at Internet Scale</a></p>
<p>18 0.62364841 <a title="155-lsi-18" href="../high_scalability-2009/high_scalability-2009-10-15-Hot_Scalability_Links_for_Oct_15_2009_.html">722 high scalability-2009-10-15-Hot Scalability Links for Oct 15 2009 </a></p>
<p>19 0.61080229 <a title="155-lsi-19" href="../high_scalability-2012/high_scalability-2012-11-30-Stuff_The_Internet_Says_On_Scalability_For_November_30%2C_2012.html">1365 high scalability-2012-11-30-Stuff The Internet Says On Scalability For November 30, 2012</a></p>
<p>20 0.60143673 <a title="155-lsi-20" href="../high_scalability-2008/high_scalability-2008-01-17-Database_People_Hating_on_MapReduce.html">216 high scalability-2008-01-17-Database People Hating on MapReduce</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.098), (2, 0.184), (8, 0.254), (10, 0.067), (17, 0.03), (61, 0.061), (77, 0.032), (79, 0.142), (85, 0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.89981538 <a title="155-lda-1" href="../high_scalability-2012/high_scalability-2012-05-10-Paper%3A_Paxos_Made_Moderately_Complex.html">1243 high scalability-2012-05-10-Paper: Paxos Made Moderately Complex</a></p>
<p>Introduction: If you are a normal human being and find thePaxos protocolconfusing, then this
paper, Paxos Made Moderately Complex, is a great find. Robbert van Renesse
from Cornell University has written a clear and well written paper with
excellent explanations.The Abstract:For anybody who has ever tried to
implement it, Paxos is by no means a simple protocol, even though it is based
on relatively simple invariants. This paper provides imperative pseudo-code
for the full Paxos (or Multi-Paxos) protocol without shying away from
discussing various implementation details. The initial description avoids
optimizations that complicate comprehension. Next we discuss liveness, and
list various optimizations that make the protocol practical.Related
ArticlesPaxos on HighScalability.com</p><p>2 0.88217551 <a title="155-lda-2" href="../high_scalability-2007/high_scalability-2007-12-13-un-article%3A_the_setup_behind_microsoft.com.html">186 high scalability-2007-12-13-un-article: the setup behind microsoft.com</a></p>
<p>Introduction: On the blogs.technet.com article on microsoft.com's infrastructure:The article
reads like a blatant ad for it's own products, and is light on the technical
side.The juicy bits are here, so you know what the fuss is about:Cytrix
Netscaler (= loadbalancer with various optimizations)W2K8 + IIS7 and antivirus
software on the webservers650GB/day ISS log files8-9GBit/s (unknown if CDN's
are included)Simple network filtering: stateless access lists blocking
unwanted ports on the routers/switches (hence the debated "no firewalls"
claim).Note that this information may not reflect present reality very well;
the spokesman appears to be reciting others words.</p><p>same-blog 3 0.87591648 <a title="155-lda-3" href="../high_scalability-2007/high_scalability-2007-11-15-Video%3A_Dryad%3A_A_general-purpose_distributed_execution_platform.html">155 high scalability-2007-11-15-Video: Dryad: A general-purpose distributed execution platform</a></p>
<p>Introduction: Dryad is Microsoft's answer to Google'smap-reduce. What's the question: How do
you process really large amounts of data? My initial impression of Dryad is
it's like a giant Unix command line filter on steroids. There are lots of
inputs, outputs, tees, queues, and merge sorts all connected together by a
master exec program. What else does Dryad have to offer the scalable
infrastructure wars?Dryad models programs as the execution of a directed
acyclic graph. Each vertex is a program and edges are typed communication
channels (files, TCP pipes, and shared memory channels within a process). Map-
reduce uses a different model. It's more like a large distributed sort where
the programmer defines functions for mapping, partitioning, and reducing. Each
approach seems to borrow from the spirit of its creating organization. The
graph approach seems a bit too complicated and map-reduce seems a bit too
simple. How ironic, in the Alanis Morissette sense.Dryad is a middleware layer
that executes gra</p><p>4 0.85580677 <a title="155-lda-4" href="../high_scalability-2011/high_scalability-2011-08-31-Pud_is_the_Anti-Stack_-_Windows%2C_CFML%2C_Dropbox%2C_Xeround%2C_JungleDisk%2C_ELB.html">1108 high scalability-2011-08-31-Pud is the Anti-Stack - Windows, CFML, Dropbox, Xeround, JungleDisk, ELB</a></p>
<p>Introduction: Pud off*ckedcomany.com (FC) fame, a favorite site of the dot bomb era, and a
site I absolutely loved until my company became featured, has given us a look
at his backend: Why Must You Laugh At My Back End. For those whose don't
remember FC's history, TechCrunch published afitting eulogy:[FC] first went
live in 2000, chronicling failing and troubled companies in its unique and
abrasive style after the dot com bust. Within a year it had a massive audience
and was getting serious mainstream press attention. As the startup economy
became better in 2004, much of the attention the site received went away. But
a large and loyal audience remains at the site, coming back day after day for
its unique slant on the news. At its peak, FC had 4 million unique monthly
visitors.Delightfully, FC was not a real-names kind of site. Hard witty
cynicism ruled and not a single cat picture was in sight. It was a blast of
fun when all around was the enclosing dark.So when I saw Pud's post I was
quite interest</p><p>5 0.85136336 <a title="155-lda-5" href="../high_scalability-2008/high_scalability-2008-03-08-Product%3A_FAI_-_Fully_Automatic_Installation.html">272 high scalability-2008-03-08-Product: FAI - Fully Automatic Installation</a></p>
<p>Introduction: From their website:FAIis an automated installation tool to install or deploy
Debian GNU/Linux and other distributions on a bunch of different hosts or a
Cluster. It's more flexible than other tools like kickstart for Red Hat,
autoyast and alice for SuSE or Jumpstart for SUN Solaris. FAI can also be used
for configuration management of a running system.You can take one or more
virgin PCs, turn on the power and after a few minutes Linux is installed,
configured and running on all your machines, without any interaction
necessary. FAI it's a scalable method for installing and updating all your
computers unattended with little effort involved. It's a centralized
management system for your Linux deployment.breakFAI's target group are system
administrators who have to install Linux onto one or even hundreds of
computers. It's not only a tool for doing a Cluster installation but a general
purpose installation tool. It can be used for installing a Beowulf cluster, a
rendering farm, a web server</p><p>6 0.81308401 <a title="155-lda-6" href="../high_scalability-2012/high_scalability-2012-04-17-YouTube_Strategy%3A_Adding_Jitter_isn%27t_a_Bug.html">1229 high scalability-2012-04-17-YouTube Strategy: Adding Jitter isn't a Bug</a></p>
<p>7 0.77579653 <a title="155-lda-7" href="../high_scalability-2012/high_scalability-2012-01-30-37signals_Still_Happily_Scaling_on_Moore_RAM_and_SSDs.html">1183 high scalability-2012-01-30-37signals Still Happily Scaling on Moore RAM and SSDs</a></p>
<p>8 0.74143058 <a title="155-lda-8" href="../high_scalability-2013/high_scalability-2013-04-03-5_Steps_to_Benchmarking_Managed_NoSQL_-_DynamoDB_vs_Cassandra.html">1434 high scalability-2013-04-03-5 Steps to Benchmarking Managed NoSQL - DynamoDB vs Cassandra</a></p>
<p>9 0.73097879 <a title="155-lda-9" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>10 0.72105044 <a title="155-lda-10" href="../high_scalability-2008/high_scalability-2008-07-15-ZooKeeper_-_A_Reliable%2C_Scalable_Distributed_Coordination_System_.html">350 high scalability-2008-07-15-ZooKeeper - A Reliable, Scalable Distributed Coordination System </a></p>
<p>11 0.7203325 <a title="155-lda-11" href="../high_scalability-2010/high_scalability-2010-10-01-Hot_Scalability_Links_For_Oct_1%2C_2010.html">913 high scalability-2010-10-01-Hot Scalability Links For Oct 1, 2010</a></p>
<p>12 0.7123847 <a title="155-lda-12" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>13 0.71213311 <a title="155-lda-13" href="../high_scalability-2011/high_scalability-2011-12-19-How_Twitter_Stores_250_Million_Tweets_a_Day_Using_MySQL.html">1159 high scalability-2011-12-19-How Twitter Stores 250 Million Tweets a Day Using MySQL</a></p>
<p>14 0.71182632 <a title="155-lda-14" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>15 0.71139884 <a title="155-lda-15" href="../high_scalability-2010/high_scalability-2010-07-13-Sponsored_Post%3A__VoltDB_and_Digg_are_Hiring.html">858 high scalability-2010-07-13-Sponsored Post:  VoltDB and Digg are Hiring</a></p>
<p>16 0.71082729 <a title="155-lda-16" href="../high_scalability-2009/high_scalability-2009-08-24-How_Google_Serves_Data_from_Multiple_Datacenters.html">687 high scalability-2009-08-24-How Google Serves Data from Multiple Datacenters</a></p>
<p>17 0.71028203 <a title="155-lda-17" href="../high_scalability-2011/high_scalability-2011-08-15-Should_any_cloud_be_considered_one_availability_zone%3F_The_Amazon_experience_says_yes..html">1098 high scalability-2011-08-15-Should any cloud be considered one availability zone? The Amazon experience says yes.</a></p>
<p>18 0.70935506 <a title="155-lda-18" href="../high_scalability-2009/high_scalability-2009-07-30-Learn_How_to_Think_at_Scale.html">666 high scalability-2009-07-30-Learn How to Think at Scale</a></p>
<p>19 0.70853859 <a title="155-lda-19" href="../high_scalability-2009/high_scalability-2009-10-30-Hot_Scalabilty_Links_for_October_30_2009.html">734 high scalability-2009-10-30-Hot Scalabilty Links for October 30 2009</a></p>
<p>20 0.70792288 <a title="155-lda-20" href="../high_scalability-2012/high_scalability-2012-09-04-Changing_Architectures%3A_New_Datacenter_Networks_Will_Set_Your_Code_and_Data_Free___.html">1316 high scalability-2012-09-04-Changing Architectures: New Datacenter Networks Will Set Your Code and Data Free   </a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
