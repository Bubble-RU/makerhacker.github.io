<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>152 high scalability-2007-11-13-Flickr Architecture</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2007" href="../home/high_scalability-2007_home.html">high_scalability-2007</a> <a title="high_scalability-2007-152" href="#">high_scalability-2007-152</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>152 high scalability-2007-11-13-Flickr Architecture</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2007-152-html" href="http://highscalability.com//blog/2007/11/13/flickr-architecture.html">html</a></p><p>Introduction: Update:Flickr hits2 Billion photosserved. That's a lot of hamburgers.Flickr is
both my favoritebirdand the web's leading photo sharing site. Flickr has an
amazing challenge, they must handle a vast sea of ever expanding new content,
ever increasing legions of users, and a constant stream of new features, all
while providing excellent performance. How do they do it?Site:
http://www.flickr.comInformation SourcesFlickr and PHP(an early
document)Capacity Planning for LAMPFederation at Flickr: Doing Billions of
Queries a Dayby Dathan Pattishall.Building Scalable Web Sitesby Cal Henderson
from Flickr.Database War Stories #3: Flickrby Tim O'ReillyCal Henderson's
Talks. A lot of useful PowerPoint
presentations.PlatformPHPMySQLShardsMemcached for a caching layer.Squid in
reverse-proxy for html and images.Linux (RedHat)Smarty for templatingPerlPEAR
for XML and Email parsingImageMagick, for image processingJava, for the node
serviceApacheSystemImager for deploymentGanglia for distributed system
m</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ~35M photos in squid cache (total)~2M photos in squid's RAM~470M photos, 4 or 5 sizes of each38k req/sec to memcached (12M objects)2 PB raw storage (consumed about ~1. [sent-17, score-0.765]
</p><p>2 5TB on SundayOver 400,000 photos being added every dayThe ArchitectureA pretty picture of Flickr's architecture can be found on thisslide. [sent-18, score-0.373]
</p><p>3 - The central database includes data like the 'users' table, which includes primary userkeys (a few different IDs) and a pointer to which shard a users' data can be found on. [sent-21, score-0.451]
</p><p>4 Every page view, calculate where your data is, at that moment of time. [sent-39, score-0.256]
</p><p>5 - PHP logic to connect to the shards and keep the data consistent (10 lines of code with comments! [sent-40, score-0.367]
</p><p>6 Clicking a Favorite:- Pulls the Photo owners Account from Cache, to get the shard location (say on shard-5)- Pulls my Information from cache, to get my shard location (say on shard-13)- Starts a "distributed transaction" \- to answer the question: Who favorited the photo? [sent-47, score-0.642]
</p><p>7 To get rid of replication lagâ&euro;Ś\- every page load, the user is assigned to a bucket- if host is down, go to next host in the list; if all hosts are down, display an error page. [sent-51, score-0.272]
</p><p>8 So 1 server in the shard can take the full load if a server of that shard is down or in maintenance mode. [sent-58, score-0.642]
</p><p>9 Over 36,000 queries per second - running within capacity threshold. [sent-67, score-0.264]
</p><p>10 Transactions are used to prevent out of sync data: open transaction 1, write commands, open transaction 2, write commands, commit 1st transaction if all is well, commit 2nd transaction if 1st committed. [sent-74, score-0.578]
</p><p>11 Search:- Two search back- ends: shards 35k qps on a few shards and Yahoo! [sent-76, score-0.464]
</p><p>12 's (proprietary) web search- Owner's single tag search or a batch tag change (say, via Organizr) goes to the Shards due to real-time requirements, everything else goes to Yahoo! [sent-77, score-0.272]
</p><p>13 - Data size is at 12 TB of user metadata (these are not photos, this is just innodb ibdata files - the photos are a lot larger). [sent-79, score-0.441]
</p><p>14 Backup procedure:- ibbackup on a cron job, that runs across various shards at different times. [sent-82, score-0.201]
</p><p>15 - Writing or deleting several huge backup files at once to a replication filestore can wreck performance on that filestore for the next few hours as it replicates the backup files. [sent-85, score-0.473]
</p><p>16 Stick it into a table, or recover data from another copy from other users shards. [sent-94, score-0.206]
</p><p>17 max_connections = 400 connections per shard, or 800 connections per server & shard. [sent-95, score-0.402]
</p><p>18 Create clear levels of abstraction between database work, business logic, page logic, page mark-up and the presentation layer. [sent-121, score-0.244]
</p><p>19 Layering allows developers to create page level logic which designers can use to build the user experience. [sent-124, score-0.223]
</p><p>20 More users means more content, more content means more connections, more connections mean more usage. [sent-150, score-0.201]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('shard', 0.321), ('photos', 0.307), ('shards', 0.201), ('flickr', 0.152), ('squid', 0.151), ('photo', 0.137), ('filestore', 0.128), ('page', 0.122), ('connections', 0.122), ('transaction', 0.113), ('ring', 0.107), ('tag', 0.105), ('henderson', 0.104), ('comment', 0.103), ('stored', 0.102), ('logic', 0.101), ('queries', 0.096), ('favorites', 0.092), ('capacity', 0.089), ('replication', 0.084), ('pulls', 0.08), ('per', 0.079), ('users', 0.079), ('artificial', 0.078), ('shut', 0.077), ('files', 0.075), ('tags', 0.074), ('lag', 0.074), ('uploads', 0.073), ('planning', 0.072), ('calculate', 0.069), ('ids', 0.067), ('every', 0.066), ('data', 0.065), ('email', 0.065), ('active', 0.065), ('commit', 0.063), ('recover', 0.062), ('search', 0.062), ('migration', 0.061), ('metadata', 0.059), ('dual', 0.059), ('php', 0.059), ('backups', 0.059), ('commands', 0.058), ('statsmore', 0.058), ('autoincrement', 0.058), ('powerpoint', 0.058), ('wreck', 0.058), ('double', 0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999976 <a title="152-tfidf-1" href="../high_scalability-2007/high_scalability-2007-11-13-Flickr_Architecture.html">152 high scalability-2007-11-13-Flickr Architecture</a></p>
<p>Introduction: Update:Flickr hits2 Billion photosserved. That's a lot of hamburgers.Flickr is
both my favoritebirdand the web's leading photo sharing site. Flickr has an
amazing challenge, they must handle a vast sea of ever expanding new content,
ever increasing legions of users, and a constant stream of new features, all
while providing excellent performance. How do they do it?Site:
http://www.flickr.comInformation SourcesFlickr and PHP(an early
document)Capacity Planning for LAMPFederation at Flickr: Doing Billions of
Queries a Dayby Dathan Pattishall.Building Scalable Web Sitesby Cal Henderson
from Flickr.Database War Stories #3: Flickrby Tim O'ReillyCal Henderson's
Talks. A lot of useful PowerPoint
presentations.PlatformPHPMySQLShardsMemcached for a caching layer.Squid in
reverse-proxy for html and images.Linux (RedHat)Smarty for templatingPerlPEAR
for XML and Email parsingImageMagick, for image processingJava, for the node
serviceApacheSystemImager for deploymentGanglia for distributed system
m</p><p>2 0.3234604 <a title="152-tfidf-2" href="../high_scalability-2009/high_scalability-2009-08-06-An_Unorthodox_Approach_to_Database_Design_%3A_The_Coming_of_the_Shard.html">672 high scalability-2009-08-06-An Unorthodox Approach to Database Design : The Coming of the Shard</a></p>
<p>Introduction: Update 4:Why you don't want to shard.by Morgon on the MySQL Performance
Blog.Optimize everything else first, and then if performance still isn't good
enough, it's time to take a very bitter medicine.Update 3:Building Scalable
Databases: Pros and Cons of Various Database Sharding Schemesby Dare Obasanjo.
Excellent discussion of why and when you would choose a sharding architecture,
how to shard, and problems with sharding.Update 2:Mr. Moore gets to punt on
shardingby Alan Rimm-Kaufman of 37signals. Insightful article on design
tradeoffs and the evils of premature optimization. With more memory, more CPU,
and new tech like SSD, problems can be avoided before more exotic
architectures like sharding are needed. Add features not infrastructure.Jeremy
Zawodnysays he's wrong wrong wrong. we're running multi-core CPUs at slower
clock speeds. Moore won't save you.Update:Dan Pritchett shares some
excellentSharding Lessons: Size Your Shards, Use Math on Shard Counts,
Carefully Consider the Spread</p><p>3 0.28792381 <a title="152-tfidf-3" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>Introduction: For everything given something seems to be taken. Caching is a great
scalability solution, but caching alsocomes with problems.Shardingis a great
scalability solution, but as Foursquare recently revealed in apost-mortemabout
their 17 hours of downtime, sharding also has problems. MongoDB, the database
Foursquare uses, also contributed theirpost-mortemof what went wrong too.Now
that everyone has shared and resharded, what can we learn to help us skip
these mistakes and quickly move on to a different set of mistakes?First, like
forFacebook, huge props to Foursquare and MongoDB for being upfront and honest
about their problems. This helps everyone get better and is a sign we work in
a pretty cool industry.Second, overall, the fault didn't flow from evil hearts
or gross negligence. As usual the cause was more mundane: a key system, that
could be a little more robust, combined with a very popular application built
by a small group of people, under immense pressure, trying to get a lot of
wo</p><p>4 0.28013095 <a title="152-tfidf-4" href="../high_scalability-2007/high_scalability-2007-10-02-Secrets_to_Fotolog%27s_Scaling_Success.html">106 high scalability-2007-10-02-Secrets to Fotolog's Scaling Success</a></p>
<p>Introduction: Fotolog, a social blogging site centered around photos, grew from about 300
thousand users in 2004 to over 11 million users in 2007. Though they initially
experienced the inevitable pains of rapid growth, they overcame their problems
and now manage over 300 million photos and 800,000 new photos are added each
day. Generating all that fabulous content are 20 million unique monthly
visitors and a volunteer army of 30,000 new users each day. They did so well a
very impressed suitor bought them out for a cool $90 million. That's scale
meets success by anyone standards. How did they do it?Site:
http://www.fotolog.comInformation SourcesScaling the World's Largest Photo
Blogging CommunityCongrats to Fotolog on $90mm sale to Hi-MediaFotolog
overtaking Flickr?Fotolog Hits 11 Million Members and 300 Million Photos
PostedSite of the Week: Fotolog.comby PC MagazineCEO John Borthwick's Blog.DBA
Frank Mash's BlogFotolog, lessons learntby John BorthwickThe
PlatformJavaPHPSunSolaris 10MySQLApacheHiber</p><p>5 0.24442093 <a title="152-tfidf-5" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>Introduction: Pinterest has been riding an exponential growth curve, doubling every month
and half. They've gone from 0 to 10s of billions of page views a month in two
years, from 2 founders and one engineer to over 40 engineers, from one little
MySQL server to 180 Web Engines, 240 API Engines, 88 MySQL DBs (cc2.8xlarge) +
1 slave each, 110 Redis Instances, and 200 Memcache Instances.Stunning growth.
So what's Pinterest's story? To tell their story we have our bards,
Pinterest'sYashwanth NelapatiandMarty Weiner, who tell the dramatic story of
Pinterest's architecture evolution in a talk titledScaling Pinterest. This is
the talk they would have liked to hear a year and half ago when they were
scaling fast and there were a lot of options to choose from. And they made a
lot of incorrect choices.This is a great talk. It's full of amazing details.
It's also very practical, down to earth, and it contains strategies adoptable
by nearly anyone. Highly recommended.Two of my favorite lessons from the
talk:Arc</p><p>6 0.21969399 <a title="152-tfidf-6" href="../high_scalability-2008/high_scalability-2008-07-26-Sharding_the_Hibernate_Way.html">358 high scalability-2008-07-26-Sharding the Hibernate Way</a></p>
<p>7 0.21963686 <a title="152-tfidf-7" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<p>8 0.20677851 <a title="152-tfidf-8" href="../high_scalability-2013/high_scalability-2013-09-09-Need_Help_with_Database_Scalability%3F_Understand_I-O.html">1514 high scalability-2013-09-09-Need Help with Database Scalability? Understand I-O</a></p>
<p>9 0.19533384 <a title="152-tfidf-9" href="../high_scalability-2009/high_scalability-2009-06-29-How_to_Succeed_at_Capacity_Planning_Without_Really_Trying_%3A__An_Interview_with_Flickr%27s_John_Allspaw_on_His_New_Book.html">643 high scalability-2009-06-29-How to Succeed at Capacity Planning Without Really Trying :  An Interview with Flickr's John Allspaw on His New Book</a></p>
<p>10 0.19235559 <a title="152-tfidf-10" href="../high_scalability-2011/high_scalability-2011-12-06-Instagram_Architecture%3A_14_Million_users%2C_Terabytes_of_Photos%2C_100s_of_Instances%2C_Dozens_of_Technologies.html">1152 high scalability-2011-12-06-Instagram Architecture: 14 Million users, Terabytes of Photos, 100s of Instances, Dozens of Technologies</a></p>
<p>11 0.18070039 <a title="152-tfidf-11" href="../high_scalability-2008/high_scalability-2008-08-04-A_Bunch_of_Great_Strategies_for_Using_Memcached_and_MySQL_Better_Together.html">360 high scalability-2008-08-04-A Bunch of Great Strategies for Using Memcached and MySQL Better Together</a></p>
<p>12 0.18004231 <a title="152-tfidf-12" href="../high_scalability-2010/high_scalability-2010-06-10-The_Four_Meta_Secrets_of_Scaling_at_Facebook.html">840 high scalability-2010-06-10-The Four Meta Secrets of Scaling at Facebook</a></p>
<p>13 0.17981161 <a title="152-tfidf-13" href="../high_scalability-2012/high_scalability-2012-04-09-The_Instagram_Architecture_Facebook_Bought_for_a_Cool_Billion_Dollars.html">1224 high scalability-2012-04-09-The Instagram Architecture Facebook Bought for a Cool Billion Dollars</a></p>
<p>14 0.17482808 <a title="152-tfidf-14" href="../high_scalability-2010/high_scalability-2010-06-23-Product%3A_dbShards_-_Share_Nothing._Shard_Everything..html">847 high scalability-2010-06-23-Product: dbShards - Share Nothing. Shard Everything.</a></p>
<p>15 0.17459054 <a title="152-tfidf-15" href="../high_scalability-2008/high_scalability-2008-08-17-Strategy%3A_Drop_Memcached%2C_Add_More_MySQL_Servers.html">367 high scalability-2008-08-17-Strategy: Drop Memcached, Add More MySQL Servers</a></p>
<p>16 0.17154153 <a title="152-tfidf-16" href="../high_scalability-2010/high_scalability-2010-11-09-Facebook_Uses_Non-Stored_Procedures_to_Update_Social_Graphs.html">936 high scalability-2010-11-09-Facebook Uses Non-Stored Procedures to Update Social Graphs</a></p>
<p>17 0.16315025 <a title="152-tfidf-17" href="../high_scalability-2007/high_scalability-2007-08-22-Wikimedia_architecture.html">72 high scalability-2007-08-22-Wikimedia architecture</a></p>
<p>18 0.16239734 <a title="152-tfidf-18" href="../high_scalability-2008/high_scalability-2008-09-10-Shard_servers_--_go_big_or_small%3F.html">383 high scalability-2008-09-10-Shard servers -- go big or small?</a></p>
<p>19 0.16030633 <a title="152-tfidf-19" href="../high_scalability-2012/high_scalability-2012-04-16-Instagram_Architecture_Update%3A_What%E2%80%99s_new_with_Instagram%3F.html">1228 high scalability-2012-04-16-Instagram Architecture Update: What’s new with Instagram?</a></p>
<p>20 0.15938799 <a title="152-tfidf-20" href="../high_scalability-2008/high_scalability-2008-05-02-Friends_for_Sale_Architecture_-_A_300_Million_Page_View-Month_Facebook_RoR_App.html">313 high scalability-2008-05-02-Friends for Sale Architecture - A 300 Million Page View-Month Facebook RoR App</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.304), (1, 0.158), (2, -0.069), (3, -0.2), (4, 0.027), (5, 0.048), (6, 0.0), (7, -0.058), (8, 0.056), (9, -0.015), (10, -0.003), (11, 0.047), (12, -0.036), (13, 0.085), (14, 0.002), (15, 0.061), (16, -0.103), (17, 0.028), (18, 0.01), (19, 0.087), (20, 0.006), (21, 0.019), (22, -0.021), (23, 0.024), (24, -0.087), (25, -0.001), (26, -0.021), (27, -0.03), (28, -0.009), (29, 0.117), (30, 0.01), (31, -0.015), (32, 0.027), (33, -0.011), (34, 0.107), (35, -0.066), (36, 0.042), (37, 0.0), (38, -0.117), (39, 0.019), (40, -0.091), (41, 0.126), (42, -0.01), (43, -0.071), (44, -0.062), (45, 0.013), (46, -0.023), (47, 0.029), (48, -0.056), (49, -0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94935358 <a title="152-lsi-1" href="../high_scalability-2007/high_scalability-2007-11-13-Flickr_Architecture.html">152 high scalability-2007-11-13-Flickr Architecture</a></p>
<p>Introduction: Update:Flickr hits2 Billion photosserved. That's a lot of hamburgers.Flickr is
both my favoritebirdand the web's leading photo sharing site. Flickr has an
amazing challenge, they must handle a vast sea of ever expanding new content,
ever increasing legions of users, and a constant stream of new features, all
while providing excellent performance. How do they do it?Site:
http://www.flickr.comInformation SourcesFlickr and PHP(an early
document)Capacity Planning for LAMPFederation at Flickr: Doing Billions of
Queries a Dayby Dathan Pattishall.Building Scalable Web Sitesby Cal Henderson
from Flickr.Database War Stories #3: Flickrby Tim O'ReillyCal Henderson's
Talks. A lot of useful PowerPoint
presentations.PlatformPHPMySQLShardsMemcached for a caching layer.Squid in
reverse-proxy for html and images.Linux (RedHat)Smarty for templatingPerlPEAR
for XML and Email parsingImageMagick, for image processingJava, for the node
serviceApacheSystemImager for deploymentGanglia for distributed system
m</p><p>2 0.82039398 <a title="152-lsi-2" href="../high_scalability-2009/high_scalability-2009-08-06-An_Unorthodox_Approach_to_Database_Design_%3A_The_Coming_of_the_Shard.html">672 high scalability-2009-08-06-An Unorthodox Approach to Database Design : The Coming of the Shard</a></p>
<p>Introduction: Update 4:Why you don't want to shard.by Morgon on the MySQL Performance
Blog.Optimize everything else first, and then if performance still isn't good
enough, it's time to take a very bitter medicine.Update 3:Building Scalable
Databases: Pros and Cons of Various Database Sharding Schemesby Dare Obasanjo.
Excellent discussion of why and when you would choose a sharding architecture,
how to shard, and problems with sharding.Update 2:Mr. Moore gets to punt on
shardingby Alan Rimm-Kaufman of 37signals. Insightful article on design
tradeoffs and the evils of premature optimization. With more memory, more CPU,
and new tech like SSD, problems can be avoided before more exotic
architectures like sharding are needed. Add features not infrastructure.Jeremy
Zawodnysays he's wrong wrong wrong. we're running multi-core CPUs at slower
clock speeds. Moore won't save you.Update:Dan Pritchett shares some
excellentSharding Lessons: Size Your Shards, Use Math on Shard Counts,
Carefully Consider the Spread</p><p>3 0.80201262 <a title="152-lsi-3" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>Introduction: Pinterest has been riding an exponential growth curve, doubling every month
and half. They've gone from 0 to 10s of billions of page views a month in two
years, from 2 founders and one engineer to over 40 engineers, from one little
MySQL server to 180 Web Engines, 240 API Engines, 88 MySQL DBs (cc2.8xlarge) +
1 slave each, 110 Redis Instances, and 200 Memcache Instances.Stunning growth.
So what's Pinterest's story? To tell their story we have our bards,
Pinterest'sYashwanth NelapatiandMarty Weiner, who tell the dramatic story of
Pinterest's architecture evolution in a talk titledScaling Pinterest. This is
the talk they would have liked to hear a year and half ago when they were
scaling fast and there were a lot of options to choose from. And they made a
lot of incorrect choices.This is a great talk. It's full of amazing details.
It's also very practical, down to earth, and it contains strategies adoptable
by nearly anyone. Highly recommended.Two of my favorite lessons from the
talk:Arc</p><p>4 0.79205406 <a title="152-lsi-4" href="../high_scalability-2008/high_scalability-2008-07-26-Sharding_the_Hibernate_Way.html">358 high scalability-2008-07-26-Sharding the Hibernate Way</a></p>
<p>Introduction: Update:A very nice JavaWorld podcast interview withGoogle engineer Max Ross on
Hibernate Shards. Max defines Hibernate Shards (horizontal partitioning), how
it works (pretty well), virtual shards (don't ask), what they need to do in
the future (query, replication, operational tools), and how it relates to
Google AppEngine (not much).To scale you are supposed to partition your data.
Sounds good, but how do you do it? When you actually sit down to work out all
the details it's not that easy. Hibernate Shards to the rescue! Hibernate
shards is: an extension to the core Hibernate product that adds facilities for
horizontal partitioning. If you know the core Hibernate API you know the
shards API. No learning curve at all. Here is what a few members of the core
group had to say about the Hibernate Shards open source project. Although
there are some limitations, from the sound of it they are doing useful stuff
in the right way and it's very much worth looking at, especially if you use
Hiberna</p><p>5 0.78865081 <a title="152-lsi-5" href="../high_scalability-2008/high_scalability-2008-09-10-Shard_servers_--_go_big_or_small%3F.html">383 high scalability-2008-09-10-Shard servers -- go big or small?</a></p>
<p>Introduction: Hello everyone,I'm designing a website/widget that my business partner and I
expect to serve millions of hits daily. As such we must shard our database
(and we're designing with shards in mind right from the beginning). However,
the one thing I haven't been able to figure out from Googling is the best
hardware to go with for shards. I'm using exclusively InnoDB tables.We'll
(eventually) be running 3 groups of database servers:a) Session servers for
php sessions. These will have a very high write volume.b) ID servers. These
will match a couple primary indices (such as user ID) to a given shard. These
will have an intense read load, plus a moderate amount of writes.c) Shard
servers. These will hold the bulk of the data. These will have a high read
load and a lowish write load.Group A is done as a database instead of using
memcached so users aren't logged out if a memcached server goes down. As the
write load is high, a pair of high performance master-master servers seems
obvious. What's</p><p>6 0.78212327 <a title="152-lsi-6" href="../high_scalability-2012/high_scalability-2012-04-16-Instagram_Architecture_Update%3A_What%E2%80%99s_new_with_Instagram%3F.html">1228 high scalability-2012-04-16-Instagram Architecture Update: What’s new with Instagram?</a></p>
<p>7 0.77922428 <a title="152-lsi-7" href="../high_scalability-2008/high_scalability-2008-06-11-Pyshards_aspires_to_build_sharding_toolkit_for_Python.html">345 high scalability-2008-06-11-Pyshards aspires to build sharding toolkit for Python</a></p>
<p>8 0.75460309 <a title="152-lsi-8" href="../high_scalability-2010/high_scalability-2010-06-23-Product%3A_dbShards_-_Share_Nothing._Shard_Everything..html">847 high scalability-2010-06-23-Product: dbShards - Share Nothing. Shard Everything.</a></p>
<p>9 0.74251819 <a title="152-lsi-9" href="../high_scalability-2008/high_scalability-2008-12-28-How_to_Organize_a_Database_Table%E2%80%99s_Keys_for_Scalability.html">476 high scalability-2008-12-28-How to Organize a Database Table’s Keys for Scalability</a></p>
<p>10 0.73953956 <a title="152-lsi-10" href="../high_scalability-2009/high_scalability-2009-03-20-Alternate_strategy_for_database_sharding.html">546 high scalability-2009-03-20-Alternate strategy for database sharding</a></p>
<p>11 0.7261557 <a title="152-lsi-11" href="../high_scalability-2010/high_scalability-2010-07-13-DbShards_Part_Deux_-_The_Internals.html">857 high scalability-2010-07-13-DbShards Part Deux - The Internals</a></p>
<p>12 0.71265447 <a title="152-lsi-12" href="../high_scalability-2011/high_scalability-2011-05-23-Evernote_Architecture_-_9_Million_Users_and_150_Million_Requests_a_Day.html">1046 high scalability-2011-05-23-Evernote Architecture - 9 Million Users and 150 Million Requests a Day</a></p>
<p>13 0.70581293 <a title="152-lsi-13" href="../high_scalability-2013/high_scalability-2013-09-09-Need_Help_with_Database_Scalability%3F_Understand_I-O.html">1514 high scalability-2013-09-09-Need Help with Database Scalability? Understand I-O</a></p>
<p>14 0.70491779 <a title="152-lsi-14" href="../high_scalability-2007/high_scalability-2007-07-24-Product%3A__Hibernate_Shards.html">24 high scalability-2007-07-24-Product:  Hibernate Shards</a></p>
<p>15 0.70476896 <a title="152-lsi-15" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>16 0.69701207 <a title="152-lsi-16" href="../high_scalability-2010/high_scalability-2010-02-10-ElasticSearch_-_Open_Source%2C_Distributed%2C_RESTful_Search_Engine.html">775 high scalability-2010-02-10-ElasticSearch - Open Source, Distributed, RESTful Search Engine</a></p>
<p>17 0.69100839 <a title="152-lsi-17" href="../high_scalability-2007/high_scalability-2007-07-10-mixi.jp__Architecture.html">5 high scalability-2007-07-10-mixi.jp  Architecture</a></p>
<p>18 0.69069016 <a title="152-lsi-18" href="../high_scalability-2007/high_scalability-2007-10-02-Secrets_to_Fotolog%27s_Scaling_Success.html">106 high scalability-2007-10-02-Secrets to Fotolog's Scaling Success</a></p>
<p>19 0.67780757 <a title="152-lsi-19" href="../high_scalability-2009/high_scalability-2009-05-25-non-sequential%2C_unique_identifier%2C_strategy_question.html">606 high scalability-2009-05-25-non-sequential, unique identifier, strategy question</a></p>
<p>20 0.67422664 <a title="152-lsi-20" href="../high_scalability-2008/high_scalability-2008-01-10-Sharding_with_Cookie-Based_Session_Storage.html">207 high scalability-2008-01-10-Sharding with Cookie-Based Session Storage</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.16), (2, 0.2), (4, 0.017), (10, 0.04), (30, 0.017), (40, 0.011), (47, 0.033), (56, 0.012), (61, 0.139), (77, 0.043), (79, 0.107), (85, 0.034), (89, 0.062), (94, 0.037)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97537482 <a title="152-lda-1" href="../high_scalability-2012/high_scalability-2012-02-03-Stuff_The_Internet_Says_On_Scalability_For_February_3%2C_2012.html">1187 high scalability-2012-02-03-Stuff The Internet Says On Scalability For February 3, 2012</a></p>
<p>Introduction: I'm only here for the HighScalability:762 billion: objects stored on
S3;$1B/Quarter: Google spend on servers;100 Petabytes: Storage for Facebook's
photos and videos.Quotable Quotes:@knorth2: #IPO filing says #Facebook is
"dependent on our ability to maintain and scale our technical
infrastructure"@debuggist: Scalability trumps politics.@cagedether: Hype of
#Hadoop is driving pressure on people to keep everything@nanreh: My MongoDB t
shirt has never helped me get laid. This is typical with #nosql
databases.@lusis: I kenna do it, Capt'n. IO is pegged, disk is saturatedâ&euro;ŚI
lost 3 good young men when the cache blew up!Kenton Varda: Jeff Dean puts his
pants on one leg at a time, but if he had more than two legs, you'd see that
his approach is actually O(log n)One upon a time manufacturing located near
rivers for power. Likewise software will be located next to storage, CPU, and
analytics resources in a small cartel of clouds. That's the contention of Here
Come the Cloud Cartels. This tributa</p><p>same-blog 2 0.97223365 <a title="152-lda-2" href="../high_scalability-2007/high_scalability-2007-11-13-Flickr_Architecture.html">152 high scalability-2007-11-13-Flickr Architecture</a></p>
<p>Introduction: Update:Flickr hits2 Billion photosserved. That's a lot of hamburgers.Flickr is
both my favoritebirdand the web's leading photo sharing site. Flickr has an
amazing challenge, they must handle a vast sea of ever expanding new content,
ever increasing legions of users, and a constant stream of new features, all
while providing excellent performance. How do they do it?Site:
http://www.flickr.comInformation SourcesFlickr and PHP(an early
document)Capacity Planning for LAMPFederation at Flickr: Doing Billions of
Queries a Dayby Dathan Pattishall.Building Scalable Web Sitesby Cal Henderson
from Flickr.Database War Stories #3: Flickrby Tim O'ReillyCal Henderson's
Talks. A lot of useful PowerPoint
presentations.PlatformPHPMySQLShardsMemcached for a caching layer.Squid in
reverse-proxy for html and images.Linux (RedHat)Smarty for templatingPerlPEAR
for XML and Email parsingImageMagick, for image processingJava, for the node
serviceApacheSystemImager for deploymentGanglia for distributed system
m</p><p>3 0.96695894 <a title="152-lda-3" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<p>Introduction: This is a guest post by Alberto Lopez Toledo, PHD, CTO of Pixable, and Julio
Viera, VP of Engineering at Pixable.Pixableaggregates photos from across your
different social networks and finds the best ones so you never miss an
important moment. That means currently processing the metadata of more than 20
million new photos per day: crawling, analyzing, ranking, and sorting them
along with the other 5+ billion that are already stored in our database.
Making sense of all that data has challenges, but two in particular rise above
the rest:How to access millions of photos per day from Facebook, Twitter,
Instagram, and other services in the most efficient manner.How to process,
organize, index, and store all the meta-data related to those photos.Sure,
Pixable's infrastructure is changing continuously, but there are some things
that we have learned over the last year. As a result, we have been able to
build a scalable infrastructure that takes advantage of today's tools,
languages and cloud s</p><p>4 0.96539855 <a title="152-lda-4" href="../high_scalability-2010/high_scalability-2010-10-28-Notes_from_A_NOSQL_Evening_in_Palo_Alto_.html">931 high scalability-2010-10-28-Notes from A NOSQL Evening in Palo Alto </a></p>
<p>Introduction: I along with 180 other people and veritable who's who of NoSQL vendors,
attended the A NoSQL Evening in Palo Alto NoSQL Meetup on Tuesday. The format
was a panel of 10 vendors--10gen, Basho, CouchOne, Cloudant, Cloudera, GoGrid,
InfiniteGraph, Membase, Riptano, Scality--sitting in two rows of chairs in
front of what seemed like a pretty diverse audience. Tim Anglade (founder, A
NOSQL Summer) moderated. Tim kept things moving by asking a few leading
questions and the panel chimed in with answers. Quite a few questions came
from the audience, which was refreshing. Overall a genial evening with some
good discussion. I was pleased that the panel members didn't just
automatically slip into marketing speak. Most of the discussions were on point
rather than just another excuse to hit the talking points. There were some
complaints about the talk not being technical enough, but I don't think that
was really the purpose of this kind of talk. The panel format is excellent at
giving a wide range o</p><p>5 0.96420443 <a title="152-lda-5" href="../high_scalability-2008/high_scalability-2008-05-27-eBay_Architecture.html">331 high scalability-2008-05-27-eBay Architecture</a></p>
<p>Introduction: Update 2:EBay's Randy Shoup spills the secrets of how to service hundreds of
millions of users and over two billion page views a day in ScalabilityBest
Practices: Lessons from eBayon InfoQ. The practices: Partition by Function,
Split Horizontally, Avoid Distributed Transactions, Decouple Functions
Asynchronously, Move Processing To Asynchronous Flows, Virtualize At All
Levels, Cache Appropriately.Update:eBay Serves 5 Billion API Calls Each Month.
Aren't we seeing more and more traffic driven by mashups composed on top of
open APIs? APIs are no longer a bolt on, they are your application.
Architecturally that argues for implementing your own application around the
same APIs developers and users employ.Who hasn't wondered how eBay does their
business? As one of the largest most loaded websites in the world, it can't be
easy. And the subtitle of the presentation hints at how creating such a
monster system requires true engineering: Striking a balance between site
stability, feature veloci</p><p>6 0.96355516 <a title="152-lda-6" href="../high_scalability-2007/high_scalability-2007-10-02-Secrets_to_Fotolog%27s_Scaling_Success.html">106 high scalability-2007-10-02-Secrets to Fotolog's Scaling Success</a></p>
<p>7 0.96304417 <a title="152-lda-7" href="../high_scalability-2012/high_scalability-2012-01-24-The_State_of_NoSQL_in_2012.html">1180 high scalability-2012-01-24-The State of NoSQL in 2012</a></p>
<p>8 0.96279687 <a title="152-lda-8" href="../high_scalability-2012/high_scalability-2012-08-10-Stuff_The_Internet_Says_On_Scalability_For_August_10%2C_2012.html">1302 high scalability-2012-08-10-Stuff The Internet Says On Scalability For August 10, 2012</a></p>
<p>9 0.96210146 <a title="152-lda-9" href="../high_scalability-2012/high_scalability-2012-07-23-State_of_the_CDN%3A_More_Traffic%2C_Stable_Prices%2C_More_Products%2C_Profits_-_Not_So_Much.html">1289 high scalability-2012-07-23-State of the CDN: More Traffic, Stable Prices, More Products, Profits - Not So Much</a></p>
<p>10 0.96201783 <a title="152-lda-10" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>11 0.9618513 <a title="152-lda-11" href="../high_scalability-2011/high_scalability-2011-05-13-Stuff_The_Internet_Says_On_Scalability_For_May_13%2C_2011.html">1040 high scalability-2011-05-13-Stuff The Internet Says On Scalability For May 13, 2011</a></p>
<p>12 0.96168512 <a title="152-lda-12" href="../high_scalability-2007/high_scalability-2007-11-19-Tailrank_Architecture_-_Learn_How_to_Track_Memes_Across_the_Entire_Blogosphere.html">160 high scalability-2007-11-19-Tailrank Architecture - Learn How to Track Memes Across the Entire Blogosphere</a></p>
<p>13 0.96167517 <a title="152-lda-13" href="../high_scalability-2010/high_scalability-2010-07-12-Creating_Scalable_Digital_Libraries.html">856 high scalability-2010-07-12-Creating Scalable Digital Libraries</a></p>
<p>14 0.96032381 <a title="152-lda-14" href="../high_scalability-2008/high_scalability-2008-09-10-Shard_servers_--_go_big_or_small%3F.html">383 high scalability-2008-09-10-Shard servers -- go big or small?</a></p>
<p>15 0.95961291 <a title="152-lda-15" href="../high_scalability-2011/high_scalability-2011-11-25-Stuff_The_Internet_Says_On_Scalability_For_November_25%2C_2011.html">1147 high scalability-2011-11-25-Stuff The Internet Says On Scalability For November 25, 2011</a></p>
<p>16 0.95953995 <a title="152-lda-16" href="../high_scalability-2013/high_scalability-2013-12-06-Stuff_The_Internet_Says_On_Scalability_For_December_6th%2C_2013.html">1559 high scalability-2013-12-06-Stuff The Internet Says On Scalability For December 6th, 2013</a></p>
<p>17 0.95885438 <a title="152-lda-17" href="../high_scalability-2010/high_scalability-2010-03-03-Hot_Scalability_Links_for_March_3%2C_2010.html">787 high scalability-2010-03-03-Hot Scalability Links for March 3, 2010</a></p>
<p>18 0.95844251 <a title="152-lda-18" href="../high_scalability-2011/high_scalability-2011-03-03-Stack_Overflow_Architecture_Update_-_Now_at_95_Million_Page_Views_a_Month.html">998 high scalability-2011-03-03-Stack Overflow Architecture Update - Now at 95 Million Page Views a Month</a></p>
<p>19 0.95735389 <a title="152-lda-19" href="../high_scalability-2011/high_scalability-2011-03-09-Productivity_vs._Control_tradeoffs_in_PaaS.html">1002 high scalability-2011-03-09-Productivity vs. Control tradeoffs in PaaS</a></p>
<p>20 0.95615023 <a title="152-lda-20" href="../high_scalability-2011/high_scalability-2011-09-02-Stuff_The_Internet_Says_On_Scalability_For_September_2%2C_2011.html">1109 high scalability-2011-09-02-Stuff The Internet Says On Scalability For September 2, 2011</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
