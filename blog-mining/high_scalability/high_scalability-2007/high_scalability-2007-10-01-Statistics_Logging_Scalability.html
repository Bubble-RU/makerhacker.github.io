<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>105 high scalability-2007-10-01-Statistics Logging Scalability</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2007" href="../home/high_scalability-2007_home.html">high_scalability-2007</a> <a title="high_scalability-2007-105" href="#">high_scalability-2007-105</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>105 high scalability-2007-10-01-Statistics Logging Scalability</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2007-105-html" href="http://highscalability.com//blog/2007/10/1/statistics-logging-scalability.html">html</a></p><p>Introduction: My company is developing a centralized web platform to service our clients.  We currently use about 3Mb/s on our uplink at our ISP serving web pages for about 100 clients.  We'd like to offer them statistics that mean something to their businesses and have been contemplating writing our own statistics code to handle the task.     All statistics would be gathered at the page view level and we're implementing a HttpModule in ASP.Net 2.0 to handle the gather of the data.  That said, I'm curious to hear comments on writing this data (~500 bytes of log data/page request).  We need to write this data somewhere and then build a process to aggregate the data into a warehouse application used in our reporting system.  Google Analytics is out of the question because we do not want our hosting infrastructure dependant upon a remote server.  Web Trends et al. are too expensive for our clients.     I'm thinking of a couple of options.   1) Writing log data directly to a SQL Server 2000 db and havin</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 My company is developing a centralized web platform to service our clients. [sent-1, score-0.109]
</p><p>2 We currently use about 3Mb/s on our uplink at our ISP serving web pages for about 100 clients. [sent-2, score-0.227]
</p><p>3 We'd like to offer them statistics that mean something to their businesses and have been contemplating writing our own statistics code to handle the task. [sent-3, score-0.922]
</p><p>4 All statistics would be gathered at the page view level and we're implementing a HttpModule in ASP. [sent-4, score-0.461]
</p><p>5 That said, I'm curious to hear comments on writing this data (~500 bytes of log data/page request). [sent-7, score-0.638]
</p><p>6 We need to write this data somewhere and then build a process to aggregate the data into a warehouse application used in our reporting system. [sent-8, score-0.802]
</p><p>7 1) Writing log data directly to a SQL Server 2000 db and having a Windows Service come in periodically to summarize and aggregate the data to the reporting server. [sent-13, score-1.006]
</p><p>8 I'm not sure this will scale with higher load and that the aggregation process will timeout because of the number of inserts being sent to the table. [sent-14, score-0.35]
</p><p>9 2) Write the log data to a structure in memory on the web server and periodically flush the data to the db. [sent-15, score-0.93]
</p><p>10 The fear here is that the web server goes down and we lose all the data in memory. [sent-16, score-0.323]
</p><p>11 Other fears are that the IIS processes and worker threads might mangle one another when contending for the memory system resource. [sent-17, score-0.472]
</p><p>12 3) Don't use memory and write to a file instead. [sent-18, score-0.295]
</p><p>13 Save the file handler as an application variable and use it for all accesses to the file. [sent-19, score-0.389]
</p><p>14 Not sure about threading issues here as well and am reluctant to use anything which might corrupt a log file under load. [sent-20, score-0.818]
</p><p>15 This theoretically should remove the threading issues but leaves me to think that the data would not be terribly useful once its in the IIS logs. [sent-22, score-0.635]
</p><p>16 The major driver here is that we do not want to use any of the web sites and canned reports built into 90% of all statistics platforms. [sent-23, score-0.471]
</p><p>17 Our users shouldn't have to "leave" the customer care portal we're creating just to see stats for their sites. [sent-24, score-0.098]
</p><p>18 I'm looking for a solution that's not entirely complex, nor is it overly expensive and it will give me the access to the data we need to record on page views. [sent-26, score-0.416]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('iis', 0.326), ('statistics', 0.281), ('log', 0.196), ('periodically', 0.179), ('threading', 0.174), ('reporting', 0.158), ('writing', 0.156), ('contending', 0.148), ('fears', 0.148), ('aggregate', 0.14), ('terribly', 0.139), ('reluctant', 0.133), ('contemplating', 0.124), ('data', 0.122), ('corrupt', 0.121), ('overly', 0.121), ('uplink', 0.118), ('flush', 0.115), ('handler', 0.111), ('file', 0.109), ('web', 0.109), ('theoretically', 0.109), ('et', 0.104), ('gathered', 0.102), ('iframes', 0.101), ('write', 0.099), ('isp', 0.099), ('portal', 0.098), ('timeout', 0.096), ('expensive', 0.095), ('inserts', 0.093), ('fear', 0.092), ('leaves', 0.091), ('accesses', 0.09), ('worker', 0.089), ('gather', 0.089), ('summarize', 0.089), ('memory', 0.087), ('curious', 0.086), ('sure', 0.085), ('warehouse', 0.083), ('driver', 0.081), ('thoughts', 0.081), ('businesses', 0.08), ('variable', 0.079), ('page', 0.078), ('bytes', 0.078), ('somewhere', 0.078), ('leave', 0.077), ('aggregation', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="105-tfidf-1" href="../high_scalability-2007/high_scalability-2007-10-01-Statistics_Logging_Scalability.html">105 high scalability-2007-10-01-Statistics Logging Scalability</a></p>
<p>Introduction: My company is developing a centralized web platform to service our clients.  We currently use about 3Mb/s on our uplink at our ISP serving web pages for about 100 clients.  We'd like to offer them statistics that mean something to their businesses and have been contemplating writing our own statistics code to handle the task.     All statistics would be gathered at the page view level and we're implementing a HttpModule in ASP.Net 2.0 to handle the gather of the data.  That said, I'm curious to hear comments on writing this data (~500 bytes of log data/page request).  We need to write this data somewhere and then build a process to aggregate the data into a warehouse application used in our reporting system.  Google Analytics is out of the question because we do not want our hosting infrastructure dependant upon a remote server.  Web Trends et al. are too expensive for our clients.     I'm thinking of a couple of options.   1) Writing log data directly to a SQL Server 2000 db and havin</p><p>2 0.21310468 <a title="105-tfidf-2" href="../high_scalability-2007/high_scalability-2007-07-26-Product%3A_AWStats_a_Log_Analyzer.html">30 high scalability-2007-07-26-Product: AWStats a Log Analyzer</a></p>
<p>Introduction: AWStats  is a free powerful and featureful tool that generates advanced web, streaming, ftp or mail server statistics, graphically. This log analyzer works as a CGI or from command line and shows you all possible information your log contains, in few graphical web pages. It uses a partial information file to be able to process large log files, often and quickly. It can analyze log files from all major server tools like Apache log files (NCSA combined/XLF/ELF log format or common/CLF log format), WebStar, IIS (W3C log format) and a lot of other web, proxy, wap, streaming servers, mail servers and some ftp servers.</p><p>3 0.18810976 <a title="105-tfidf-3" href="../high_scalability-2007/high_scalability-2007-12-05-how_to%3A_Load_Balancing_with_iis.html">175 high scalability-2007-12-05-how to: Load Balancing with iis</a></p>
<p>Introduction: he  l   l  o wor  l  d,   can you te  l   l   me how   i   can   i  mp  l  ement a   l  oad ba  l  anc  i  ng of a web s  i  te runn  i  ng under i  i  s - w  i  ndows server 2003/08</p><p>4 0.16137376 <a title="105-tfidf-4" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_Web_Log_Storming.html">37 high scalability-2007-07-28-Product: Web Log Storming</a></p>
<p>Introduction: Web Log Storming  is an interactive, desktop-based Web Log Analyzer for Windows. The whole new concept of log analysis makes it clearly different from any other web log analyzer. Browse through statistics to get into details - down to individual visitor's session. Check individual visitor behavior pattern and how it fits into your desired scenario.  Web Log Storming does far more than just generate common reports - it displays detailed web site statistics with interactive graphs and reports. Very complete detailed log analysis of activity from every visitor to your web site is only a mouse-click away.  In other words, analyze your web logs like never before!   It's easy to track sessions, hits, page views, downloads, or whatever metric is most important to each user. You can look at referring pages and see which search engines and keywords were used to bring visitors to the site. Web site behavior, from the top entry and exit pages, to the paths that users follow, can be analyzed. You</p><p>5 0.15734568 <a title="105-tfidf-5" href="../high_scalability-2007/high_scalability-2007-08-30-Log_Everything_All_the_Time.html">77 high scalability-2007-08-30-Log Everything All the Time</a></p>
<p>Introduction: This JoelOnSoftware  thread  asks the age old question of what and how to log. The usual trace/error/warning/info advice is totally useless in a large scale distributed system. Instead, you need to  log everything all the time  so you can solve problems that have already happened across a potentially huge range of servers. Yes, it can be done.  To see why the typical logging approach is broken,  imagine this scenario: Your site has been up and running great for weeks. No problems. A foreshadowing beeper goes off at 2AM. It seems some users can no longer add comments to threads. Then you hear the debugging deathknell: it's an intermittent problem and customers are pissed. Fix it. Now.  So how are you going to debug this? The monitoring system doesn't show any obvious problems or errors. You quickly post a comment and it works fine. This won't be easy. So you think. Commenting involves a bunch of servers and networks. There's the load balancer, spam filter,  web server, database server,</p><p>6 0.14305593 <a title="105-tfidf-6" href="../high_scalability-2013/high_scalability-2013-01-21-Processing_100_Million_Pixels_a_Day_-_Small_Amounts_of_Contention_Cause_Big_Problems_at_Scale.html">1390 high scalability-2013-01-21-Processing 100 Million Pixels a Day - Small Amounts of Contention Cause Big Problems at Scale</a></p>
<p>7 0.14071971 <a title="105-tfidf-7" href="../high_scalability-2008/high_scalability-2008-01-30-How_Rackspace_Now_Uses_MapReduce_and_Hadoop_to_Query_Terabytes_of_Data.html">233 high scalability-2008-01-30-How Rackspace Now Uses MapReduce and Hadoop to Query Terabytes of Data</a></p>
<p>8 0.13180101 <a title="105-tfidf-8" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_Web_Log_Expert.html">36 high scalability-2007-07-28-Product: Web Log Expert</a></p>
<p>9 0.12391867 <a title="105-tfidf-9" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_FastStats_Log_Analyzer_.html">35 high scalability-2007-07-28-Product: FastStats Log Analyzer </a></p>
<p>10 0.12095773 <a title="105-tfidf-10" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>11 0.11870206 <a title="105-tfidf-11" href="../high_scalability-2007/high_scalability-2007-08-04-Try_Squid_as_a_Reverse_Proxy.html">59 high scalability-2007-08-04-Try Squid as a Reverse Proxy</a></p>
<p>12 0.10720938 <a title="105-tfidf-12" href="../high_scalability-2007/high_scalability-2007-09-18-Amazon_Architecture.html">96 high scalability-2007-09-18-Amazon Architecture</a></p>
<p>13 0.10460067 <a title="105-tfidf-13" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>14 0.10456994 <a title="105-tfidf-14" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>15 0.10101241 <a title="105-tfidf-15" href="../high_scalability-2013/high_scalability-2013-08-13-In_Memoriam%3A_Lavabit_Architecture_-_Creating_a_Scalable_Email_Service.html">1501 high scalability-2013-08-13-In Memoriam: Lavabit Architecture - Creating a Scalable Email Service</a></p>
<p>16 0.097858004 <a title="105-tfidf-16" href="../high_scalability-2013/high_scalability-2013-01-14-MongoDB_and_GridFS_for_Inter_and_Intra_Datacenter_Data_Replication_.html">1386 high scalability-2013-01-14-MongoDB and GridFS for Inter and Intra Datacenter Data Replication </a></p>
<p>17 0.097607233 <a title="105-tfidf-17" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>18 0.096988499 <a title="105-tfidf-18" href="../high_scalability-2008/high_scalability-2008-02-25-Any_Suggestions_for_the_Architecture_Template%3F.html">259 high scalability-2008-02-25-Any Suggestions for the Architecture Template?</a></p>
<p>19 0.096988499 <a title="105-tfidf-19" href="../high_scalability-2008/high_scalability-2008-02-25-Architecture_Template_Advice_Needed.html">260 high scalability-2008-02-25-Architecture Template Advice Needed</a></p>
<p>20 0.096507072 <a title="105-tfidf-20" href="../high_scalability-2007/high_scalability-2007-08-04-Product%3A_Cacti.html">58 high scalability-2007-08-04-Product: Cacti</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.177), (1, 0.084), (2, -0.021), (3, -0.094), (4, 0.015), (5, 0.013), (6, 0.045), (7, -0.021), (8, 0.009), (9, 0.064), (10, -0.028), (11, -0.023), (12, 0.006), (13, -0.064), (14, 0.075), (15, -0.006), (16, 0.004), (17, 0.004), (18, 0.02), (19, 0.012), (20, 0.025), (21, -0.063), (22, -0.017), (23, 0.105), (24, 0.136), (25, -0.07), (26, -0.049), (27, -0.009), (28, -0.014), (29, -0.008), (30, -0.014), (31, -0.074), (32, 0.077), (33, -0.062), (34, -0.055), (35, 0.043), (36, -0.005), (37, 0.041), (38, 0.075), (39, -0.007), (40, 0.027), (41, 0.052), (42, -0.003), (43, -0.006), (44, 0.009), (45, -0.067), (46, 0.028), (47, -0.057), (48, 0.012), (49, -0.03)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94179064 <a title="105-lsi-1" href="../high_scalability-2007/high_scalability-2007-10-01-Statistics_Logging_Scalability.html">105 high scalability-2007-10-01-Statistics Logging Scalability</a></p>
<p>Introduction: My company is developing a centralized web platform to service our clients.  We currently use about 3Mb/s on our uplink at our ISP serving web pages for about 100 clients.  We'd like to offer them statistics that mean something to their businesses and have been contemplating writing our own statistics code to handle the task.     All statistics would be gathered at the page view level and we're implementing a HttpModule in ASP.Net 2.0 to handle the gather of the data.  That said, I'm curious to hear comments on writing this data (~500 bytes of log data/page request).  We need to write this data somewhere and then build a process to aggregate the data into a warehouse application used in our reporting system.  Google Analytics is out of the question because we do not want our hosting infrastructure dependant upon a remote server.  Web Trends et al. are too expensive for our clients.     I'm thinking of a couple of options.   1) Writing log data directly to a SQL Server 2000 db and havin</p><p>2 0.85899329 <a title="105-lsi-2" href="../high_scalability-2013/high_scalability-2013-01-21-Processing_100_Million_Pixels_a_Day_-_Small_Amounts_of_Contention_Cause_Big_Problems_at_Scale.html">1390 high scalability-2013-01-21-Processing 100 Million Pixels a Day - Small Amounts of Contention Cause Big Problems at Scale</a></p>
<p>Introduction: This is a guest post by  Gordon Worley , a Software Engineer at  Korrelate , where they correlate (see what they did there) online purchases to offline purchases. 
 
Several weeks ago, we came into the office one morning to find every server alarm going off. Pixel log processing was behind by 8 hours and not making headway. Checking the logs, we discovered that a big client had come online during the night and was giving us 10 times more traffic than we were originally told to expect. I wouldn’t say we panicked, but the office was certainly more jittery than usual. Over the next several hours, though, thanks both to foresight and quick thinking, we were able to scale up to handle the added load and clear the backlog to return log processing to a steady state.
 
At Korrelate, we deploy  tracking pixels , also known beacons or web bugs, that our partners use to send us information about their users. These tiny web objects contain no visible content, but may include transparent 1 by 1 gif</p><p>3 0.84574306 <a title="105-lsi-3" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_FastStats_Log_Analyzer_.html">35 high scalability-2007-07-28-Product: FastStats Log Analyzer </a></p>
<p>Introduction: FastStats Log Analyzer  enables you to: 
 
 Determine whether your CPC advertising is profitable: 
 Are you spending $0.75 per click on Google or Overture, but only receiving $0.56 per click in revenue? 
 Tune site traffic patterns: 
 FastStats's Hyperlink Tree View feature lets you visually see how traffic flows through your web site. 
 High-performance solution for even the busiest web sites: 
 Our software has been clocked at over 1000 MB/min. Other popular log file analysis tools (we won't name names), run at 1/40th the speed. 
 We've been in the business for over 6 years, delivering value, quality, and good customer service to our clients. Our products are used for data mining at some of the world's busiest web sites -- why not give FastStats a try at your web site? FastStats log file analysis supports a wide variety of web server log files, including Apache logs and Microsoft IIS logs.</p><p>4 0.83967799 <a title="105-lsi-4" href="../high_scalability-2007/high_scalability-2007-08-30-Log_Everything_All_the_Time.html">77 high scalability-2007-08-30-Log Everything All the Time</a></p>
<p>Introduction: This JoelOnSoftware  thread  asks the age old question of what and how to log. The usual trace/error/warning/info advice is totally useless in a large scale distributed system. Instead, you need to  log everything all the time  so you can solve problems that have already happened across a potentially huge range of servers. Yes, it can be done.  To see why the typical logging approach is broken,  imagine this scenario: Your site has been up and running great for weeks. No problems. A foreshadowing beeper goes off at 2AM. It seems some users can no longer add comments to threads. Then you hear the debugging deathknell: it's an intermittent problem and customers are pissed. Fix it. Now.  So how are you going to debug this? The monitoring system doesn't show any obvious problems or errors. You quickly post a comment and it works fine. This won't be easy. So you think. Commenting involves a bunch of servers and networks. There's the load balancer, spam filter,  web server, database server,</p><p>5 0.83717227 <a title="105-lsi-5" href="../high_scalability-2009/high_scalability-2009-04-15-Implementing_large_scale_web_analytics.html">570 high scalability-2009-04-15-Implementing large scale web analytics</a></p>
<p>Introduction: Does anyone know of any articles or papers that discuss the nuts and bolts of how web analytics is implemented at organizations with large volumes of web traffic and a critcal business need to analyze that data - e.g. places like Amazon.com, eBay, and Google?     Just as a fun project I'm planning to build my own web log analysis app that can effectively index and query large volumes of web log data (i.e. TB range). But first I'd like to learn more about how it's done in the organizations whose lifeblood depends on this stuff. Even just a high level architectural overview of their approaches would be nice to have.</p><p>6 0.82552153 <a title="105-lsi-6" href="../high_scalability-2007/high_scalability-2007-07-26-Product%3A_AWStats_a_Log_Analyzer.html">30 high scalability-2007-07-26-Product: AWStats a Log Analyzer</a></p>
<p>7 0.80936396 <a title="105-lsi-7" href="../high_scalability-2009/high_scalability-2009-03-16-Product%3A_Smart_Inspect.html">541 high scalability-2009-03-16-Product: Smart Inspect</a></p>
<p>8 0.8070839 <a title="105-lsi-8" href="../high_scalability-2008/high_scalability-2008-11-24-Product%3A_Scribe_-_Facebook%27s_Scalable_Logging_System.html">449 high scalability-2008-11-24-Product: Scribe - Facebook's Scalable Logging System</a></p>
<p>9 0.80096805 <a title="105-lsi-9" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_Web_Log_Storming.html">37 high scalability-2007-07-28-Product: Web Log Storming</a></p>
<p>10 0.79047489 <a title="105-lsi-10" href="../high_scalability-2010/high_scalability-2010-11-09-Paper%3A_Hyder_-_Scaling_Out_without_Partitioning_.html">937 high scalability-2010-11-09-Paper: Hyder - Scaling Out without Partitioning </a></p>
<p>11 0.7744925 <a title="105-lsi-11" href="../high_scalability-2008/high_scalability-2008-01-30-How_Rackspace_Now_Uses_MapReduce_and_Hadoop_to_Query_Terabytes_of_Data.html">233 high scalability-2008-01-30-How Rackspace Now Uses MapReduce and Hadoop to Query Terabytes of Data</a></p>
<p>12 0.73828208 <a title="105-lsi-12" href="../high_scalability-2008/high_scalability-2008-04-19-How_to_build_a_real-time_analytics_system%3F.html">304 high scalability-2008-04-19-How to build a real-time analytics system?</a></p>
<p>13 0.73731858 <a title="105-lsi-13" href="../high_scalability-2009/high_scalability-2009-04-03-Collectl_interface_to_Ganglia_-_any_interest%3F.html">553 high scalability-2009-04-03-Collectl interface to Ganglia - any interest?</a></p>
<p>14 0.70123339 <a title="105-lsi-14" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_Web_Log_Expert.html">36 high scalability-2007-07-28-Product: Web Log Expert</a></p>
<p>15 0.69490147 <a title="105-lsi-15" href="../high_scalability-2012/high_scalability-2012-02-20-Berkeley_DB_Architecture_-_NoSQL_Before_NoSQL_was_Cool.html">1196 high scalability-2012-02-20-Berkeley DB Architecture - NoSQL Before NoSQL was Cool</a></p>
<p>16 0.69328225 <a title="105-lsi-16" href="../high_scalability-2011/high_scalability-2011-08-10-LevelDB_-_Fast_and_Lightweight_Key-Value_Database_From_the_Authors_of_MapReduce_and_BigTable.html">1096 high scalability-2011-08-10-LevelDB - Fast and Lightweight Key-Value Database From the Authors of MapReduce and BigTable</a></p>
<p>17 0.64607948 <a title="105-lsi-17" href="../high_scalability-2007/high_scalability-2007-07-30-Product%3A_SmarterStats.html">45 high scalability-2007-07-30-Product: SmarterStats</a></p>
<p>18 0.63468355 <a title="105-lsi-18" href="../high_scalability-2009/high_scalability-2009-07-28-37signals_Architecture.html">663 high scalability-2009-07-28-37signals Architecture</a></p>
<p>19 0.63205361 <a title="105-lsi-19" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>20 0.63068569 <a title="105-lsi-20" href="../high_scalability-2007/high_scalability-2007-11-30-Strategy%3A_Efficiently_Geo-referencing_IPs.html">168 high scalability-2007-11-30-Strategy: Efficiently Geo-referencing IPs</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.151), (2, 0.223), (10, 0.033), (11, 0.208), (17, 0.027), (56, 0.032), (61, 0.083), (79, 0.094), (85, 0.018), (94, 0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94041252 <a title="105-lda-1" href="../high_scalability-2007/high_scalability-2007-10-26-Paper%3A_Wikipedia%27s_Site_Internals%2C_Configuration%2C_Code_Examples_and_Management_Issues.html">134 high scalability-2007-10-26-Paper: Wikipedia's Site Internals, Configuration, Code Examples and Management Issues</a></p>
<p>Introduction: Wikipedia and  Wikimedia  have some of the best, most complete real-world documentation on how to build highly scalable systems. This paper by Domas Mituzas covers a lot of details about how Wikipedia works, including: an overview of the different packages used (Linux, PowerDNS, LVS, Squid, lighttpd, Apache, PHP5, Lucene, Mono, Memcached), how they use their CDN,   how caching works, how they profile their code, how they store their media, how they structure their database access, how they handle search, how they handle load balancing and administration. All with real code examples and examples of configuration files. This is a really useful resource.
  Related Articles     Wikimedia Architecture      Domas Mituzas' Blog</p><p>2 0.92486912 <a title="105-lda-2" href="../high_scalability-2007/high_scalability-2007-07-25-Paper%3A_Designing_Disaster_Tolerant_High_Availability_Clusters.html">25 high scalability-2007-07-25-Paper: Designing Disaster Tolerant High Availability Clusters</a></p>
<p>Introduction: A very detailed (339 pages) paper on how to use HP products to create a highly available cluster. It's somewhat dated and obviously concentrates on HP products, but it is still good information.  Table of contents:  1. Disaster Tolerance and Recovery in a Serviceguard Cluster 2. Building an Extended Distance Cluster Using ServiceGuard 3. Designing a Metropolitan Cluster 4. Designing a Continental Cluster 5. Building Disaster-Tolerant Serviceguard Solutions Using Metrocluster with Continuous Access XP 6. Building Disaster Tolerant Serviceguard Solutions Using Metrocluster with EMC SRDF 7. Cascading Failover in a Continental Cluster 
   
    Evaluating the Need for Disaster Tolerance  What is a Disaster Tolerant Architecture?  Types of Disaster Tolerant Clusters   Extended Distance Clusters  Metropolitan Cluster  Continental Cluster  Continental Cluster With Cascading Failover   Disaster Tolerant Architecture Guidelines   Protecting Nodes through Geographic Dispersion  Protecting Data th</p><p>3 0.92153889 <a title="105-lda-3" href="../high_scalability-2009/high_scalability-2009-08-01-15_Scalability_and_Performance_Best_Practices.html">668 high scalability-2009-08-01-15 Scalability and Performance Best Practices</a></p>
<p>Introduction: These are from  Laura Thomson of OmniTi :  
  Profile early, profile often.  Pick a profiling tool and learn it in and out.  
  Dev-ops cooperation is essential.  The most critical difference in organizations that handles crises well. 
  Test on production data.  Code behavior (especially performance) is often data driven. 
  Track and trend.  Understanding your historical performance characteristics is essential for spotting emerging problems. 
  Assumptions will burn you.  Systems are complex and often break in unexpected ways. 
  Decouple.  Isolate performance failures. 
  Cache.  Caching is the core of most optimizations. 
  Federate.  Data federation is taking a single data set and spreading it across multiple database/application servers. 
  Replicate.  Replication is making synchronized copies of data available in more than one place. 
  Avoid straining hard-to-scale resources.  Some resources are inherently hard to scale: Uncacheable’ data, Data with a very high read+write rate</p><p>4 0.90769428 <a title="105-lda-4" href="../high_scalability-2012/high_scalability-2012-05-03-Snooze_-_Open-source%2C_Scalable%2C_Autonomic%2C_and_Energy-efficient_VM_Management_for_Private_Clouds.html">1238 high scalability-2012-05-03-Snooze - Open-source, Scalable, Autonomic, and Energy-efficient VM Management for Private Clouds</a></p>
<p>Introduction: Snooze   is an open-source, scalable, autonomic, and energy-efficient  virtual machine (VM) management framework for private clouds. Similarly  to other VM management frameworks such as Nimbus, OpenNebula,  Eucalyptus, and OpenStack it allows to build compute infrastructures  from virtualized resources. Particularly, once installed and configured  users can submit and control the life-cycle of a large number of VMs.  However, contrary to existing frameworks for scalability and fault  tolerance, Snooze employs a self-organizing and healing (based on Apache ZooKeeper) hierarchical  architecture. Moreover, it performs distributed VM management and is  designed to be energy efficient. Therefore, it implements features to  monitor and estimate VM resource (CPU, memory, network Rx, network Tx)  demands, detect and resolve overload/underload situations, perform  dynamic VM consolidation through live migration, and finally power  management to save energy. Last but not least, it integrates a g</p><p>5 0.89812922 <a title="105-lda-5" href="../high_scalability-2010/high_scalability-2010-02-04-Hot_Scalability_Links_for_February_4%2C_2010.html">771 high scalability-2010-02-04-Hot Scalability Links for February 4, 2010</a></p>
<p>Introduction: Lots of cool stuff happening this week...
  
  Voldemort gets rebalancing.  It's one thing to shard data to scale, it's a completely different level of functionality to manage those shards intelligently. Voldemort has stepped up by adding advanced rebalancing functionality: Dynamic addition of new nodes to the cluster; Deletion of nodes from cluster; Load balancing of data inside a cluster. 
  Microsoft Finally Opens Azure for Business.   Out of the blue Microsoft opens up their platform as a service service. Good to have more competition and we'll keep an eye out for experience reports. 
  New details on LinkedIn architecture  by Greg Linden.  LinkedIn appears to only use caching minimally, preferring to spend their efforts and machine resources on making sure they can recompute computations quickly than on hiding poor performance behind caching layers . 
  The end of SQL and relational databases?   by  David Intersimone .  For new projects, I believe, we have genuine non-relational a</p><p>6 0.89033574 <a title="105-lda-6" href="../high_scalability-2011/high_scalability-2011-06-08-Stuff_to_Watch_from_Google_IO_2011.html">1055 high scalability-2011-06-08-Stuff to Watch from Google IO 2011</a></p>
<p>same-blog 7 0.88819963 <a title="105-lda-7" href="../high_scalability-2007/high_scalability-2007-10-01-Statistics_Logging_Scalability.html">105 high scalability-2007-10-01-Statistics Logging Scalability</a></p>
<p>8 0.8850655 <a title="105-lda-8" href="../high_scalability-2012/high_scalability-2012-04-30-Masstree_-_Much_Faster_than_MongoDB%2C_VoltDB%2C_Redis%2C_and_Competitive_with_Memcached.html">1236 high scalability-2012-04-30-Masstree - Much Faster than MongoDB, VoltDB, Redis, and Competitive with Memcached</a></p>
<p>9 0.87082136 <a title="105-lda-9" href="../high_scalability-2010/high_scalability-2010-09-28-6_Strategies_for_Scaling_BBC_iPlayer.html">908 high scalability-2010-09-28-6 Strategies for Scaling BBC iPlayer</a></p>
<p>10 0.86398345 <a title="105-lda-10" href="../high_scalability-2007/high_scalability-2007-10-28-Scaling_Early_Stage_Startups.html">136 high scalability-2007-10-28-Scaling Early Stage Startups</a></p>
<p>11 0.84702992 <a title="105-lda-11" href="../high_scalability-2008/high_scalability-2008-12-01-Sun_FireTM_X4540_Server_as_Backup_Server_for_Zmanda%27s_Amanda_Enterprise_2.6_Software_.html">457 high scalability-2008-12-01-Sun FireTM X4540 Server as Backup Server for Zmanda's Amanda Enterprise 2.6 Software </a></p>
<p>12 0.83424938 <a title="105-lda-12" href="../high_scalability-2010/high_scalability-2010-01-25-Let%27s_Welcome_our_Neo-Feudal_Overlords.html">765 high scalability-2010-01-25-Let's Welcome our Neo-Feudal Overlords</a></p>
<p>13 0.83279192 <a title="105-lda-13" href="../high_scalability-2008/high_scalability-2008-11-13-Plenty_of_Fish_Says_Scaling_for_Free_Doesn%27t_Pay.html">442 high scalability-2008-11-13-Plenty of Fish Says Scaling for Free Doesn't Pay</a></p>
<p>14 0.83024555 <a title="105-lda-14" href="../high_scalability-2007/high_scalability-2007-08-22-Wikimedia_architecture.html">72 high scalability-2007-08-22-Wikimedia architecture</a></p>
<p>15 0.82450438 <a title="105-lda-15" href="../high_scalability-2007/high_scalability-2007-07-10-mixi.jp__Architecture.html">5 high scalability-2007-07-10-mixi.jp  Architecture</a></p>
<p>16 0.82013893 <a title="105-lda-16" href="../high_scalability-2012/high_scalability-2012-10-04-Stuff_The_Internet_Says_On_Scalability_For_October_5%2C_2012.html">1334 high scalability-2012-10-04-Stuff The Internet Says On Scalability For October 5, 2012</a></p>
<p>17 0.81956339 <a title="105-lda-17" href="../high_scalability-2008/high_scalability-2008-04-18-Scaling_Mania_at_MySQL_Conference_2008.html">303 high scalability-2008-04-18-Scaling Mania at MySQL Conference 2008</a></p>
<p>18 0.81563091 <a title="105-lda-18" href="../high_scalability-2009/high_scalability-2009-04-24-Heroku_-_Simultaneously_Develop_and_Deploy_Automatically_Scalable_Rails_Applications_in_the_Cloud.html">579 high scalability-2009-04-24-Heroku - Simultaneously Develop and Deploy Automatically Scalable Rails Applications in the Cloud</a></p>
<p>19 0.81562269 <a title="105-lda-19" href="../high_scalability-2013/high_scalability-2013-12-16-22_Recommendations_for_Building_Effective_High_Traffic_Web_Software.html">1565 high scalability-2013-12-16-22 Recommendations for Building Effective High Traffic Web Software</a></p>
<p>20 0.81442583 <a title="105-lda-20" href="../high_scalability-2011/high_scalability-2011-05-17-Facebook%3A_An_Example_Canonical_Architecture_for_Scaling_Billions_of_Messages.html">1042 high scalability-2011-05-17-Facebook: An Example Canonical Architecture for Scaling Billions of Messages</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
