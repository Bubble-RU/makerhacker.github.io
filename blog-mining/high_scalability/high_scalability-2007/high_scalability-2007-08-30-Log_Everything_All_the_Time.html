<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>77 high scalability-2007-08-30-Log Everything All the Time</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2007" href="../home/high_scalability-2007_home.html">high_scalability-2007</a> <a title="high_scalability-2007-77" href="#">high_scalability-2007-77</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>77 high scalability-2007-08-30-Log Everything All the Time</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2007-77-html" href="http://highscalability.com//blog/2007/8/30/log-everything-all-the-time.html">html</a></p><p>Introduction: This JoelOnSoftware  thread  asks the age old question of what and how to log. The usual trace/error/warning/info advice is totally useless in a large scale distributed system. Instead, you need to  log everything all the time  so you can solve problems that have already happened across a potentially huge range of servers. Yes, it can be done.  To see why the typical logging approach is broken,  imagine this scenario: Your site has been up and running great for weeks. No problems. A foreshadowing beeper goes off at 2AM. It seems some users can no longer add comments to threads. Then you hear the debugging deathknell: it's an intermittent problem and customers are pissed. Fix it. Now.  So how are you going to debug this? The monitoring system doesn't show any obvious problems or errors. You quickly post a comment and it works fine. This won't be easy. So you think. Commenting involves a bunch of servers and networks. There's the load balancer, spam filter,  web server, database server,</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Instead, you need to  log everything all the time  so you can solve problems that have already happened across a potentially huge range of servers. [sent-3, score-0.7]
</p><p>2 You can't deploy a new build with more logging because that build has not been tested and you have no idea when the problem will happen again anyway. [sent-24, score-0.587]
</p><p>3 You need to log everything that will help you diagnose any future problem. [sent-35, score-0.618]
</p><p>4 Over time systems usually evolve to the point of logging everything. [sent-43, score-0.651]
</p><p>5 But the problem is the logging isn't systematic or well thought out, which leads to poor coverage and poor performance. [sent-46, score-0.627]
</p><p>6 Every  hop a request takes should log meta information  about how long the request took to process, how big the request was, what the status of the request was. [sent-59, score-1.073]
</p><p>7 System is logging everything you need to log to debug the system. [sent-64, score-1.321]
</p><p>8 Developers can add more detailed log levels for their code that can be turned on and off on a module by module basis. [sent-68, score-0.783]
</p><p>9 But then I make each process have a command port hosting a simple embedded web server and telnet processor so you can change debug levels and other setting on the fly through the web or telnet interface. [sent-74, score-0.718]
</p><p>10 There are lots of tricks you can use to make logging fast enough that you can do it all the time:    Make logging efficient from the start so you aren't afraid to use it. [sent-86, score-1.111]
</p><p>11 Create a dead simple to use log library that makes logging trivial for developers. [sent-87, score-1.068]
</p><p>12 Log to a separate task and let the task push out log data when it can. [sent-91, score-0.592]
</p><p>13 Use a preallocated buffer pool for log messages so  memory allocation is just pop and push. [sent-92, score-0.796]
</p><p>14 When it's not you can use reference counted data structures and do the formatting in the logging thread. [sent-95, score-0.665]
</p><p>15 Don't do any formatting before it is determined the log is needed. [sent-98, score-0.55]
</p><p>16 Make the log message directly queueable to the log task so queuing doesn't take more memory allocations. [sent-104, score-0.97]
</p><p>17 Tie your logging system into your monitoring system so all the logging data from every process on every host winds its way to your centralized monitoring system. [sent-112, score-1.257]
</p><p>18 Add a command ports to processes that make it easy to set program behaviors at run-time and view important statistics and logging information. [sent-117, score-0.58]
</p><p>19 In large scale distributed systems logging data is all you have to debug most problems. [sent-119, score-0.775]
</p><p>20 So log everything all the time and you may still get that call at 2AM, but at least you'll know you'll have a fighting chance to fix any problems that do come up. [sent-120, score-0.576]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('logging', 0.529), ('log', 0.414), ('debug', 0.246), ('request', 0.148), ('formatting', 0.136), ('preallocated', 0.12), ('trace', 0.118), ('levels', 0.108), ('telnet', 0.102), ('module', 0.094), ('allocation', 0.092), ('task', 0.089), ('debugging', 0.088), ('mutex', 0.076), ('usually', 0.073), ('add', 0.073), ('diagnose', 0.072), ('system', 0.072), ('trivial', 0.07), ('sensitive', 0.07), ('need', 0.07), ('meta', 0.067), ('everything', 0.062), ('messages', 0.06), ('passed', 0.059), ('counts', 0.059), ('happen', 0.058), ('buffer', 0.057), ('dead', 0.055), ('process', 0.055), ('embedded', 0.054), ('beeper', 0.054), ('controllable', 0.054), ('foreshadowing', 0.054), ('timeso', 0.054), ('relevant', 0.054), ('happened', 0.054), ('afraid', 0.053), ('memory', 0.053), ('format', 0.051), ('hear', 0.051), ('problems', 0.051), ('command', 0.051), ('debugger', 0.051), ('drop', 0.05), ('time', 0.049), ('poor', 0.049), ('dear', 0.049), ('outliers', 0.049), ('unavoidable', 0.049)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000005 <a title="77-tfidf-1" href="../high_scalability-2007/high_scalability-2007-08-30-Log_Everything_All_the_Time.html">77 high scalability-2007-08-30-Log Everything All the Time</a></p>
<p>Introduction: This JoelOnSoftware  thread  asks the age old question of what and how to log. The usual trace/error/warning/info advice is totally useless in a large scale distributed system. Instead, you need to  log everything all the time  so you can solve problems that have already happened across a potentially huge range of servers. Yes, it can be done.  To see why the typical logging approach is broken,  imagine this scenario: Your site has been up and running great for weeks. No problems. A foreshadowing beeper goes off at 2AM. It seems some users can no longer add comments to threads. Then you hear the debugging deathknell: it's an intermittent problem and customers are pissed. Fix it. Now.  So how are you going to debug this? The monitoring system doesn't show any obvious problems or errors. You quickly post a comment and it works fine. This won't be easy. So you think. Commenting involves a bunch of servers and networks. There's the load balancer, spam filter,  web server, database server,</p><p>2 0.29765046 <a title="77-tfidf-2" href="../high_scalability-2008/high_scalability-2008-01-30-How_Rackspace_Now_Uses_MapReduce_and_Hadoop_to_Query_Terabytes_of_Data.html">233 high scalability-2008-01-30-How Rackspace Now Uses MapReduce and Hadoop to Query Terabytes of Data</a></p>
<p>Introduction: How do you query hundreds of gigabytes of new data each day streaming in from over 600 hyperactive servers? If you think this sounds like the perfect battle ground for a head-to-head skirmish in the great  MapReduce Versus Database War , you would be correct.   Bill Boebel, CTO of Mailtrust (Rackspace's mail division), has generously provided a fascinating account of how they evolved their log processing system from an early amoeba'ic text file stored on each machine approach,  to a Neandertholic relational database solution that just couldn't compete, and finally to a Homo sapien'ic Hadoop based solution that works wisely for them and has virtually unlimited scalability potential.
 
Rackspace faced a now familiar problem. Lots and lots of data streaming in. Where do you store all that data? How do you do anything useful with it? In the first version of their system logs were stored in flat text files and had to be manually searched by engineers logging into each individual machine.  T</p><p>3 0.27551544 <a title="77-tfidf-3" href="../high_scalability-2013/high_scalability-2013-01-21-Processing_100_Million_Pixels_a_Day_-_Small_Amounts_of_Contention_Cause_Big_Problems_at_Scale.html">1390 high scalability-2013-01-21-Processing 100 Million Pixels a Day - Small Amounts of Contention Cause Big Problems at Scale</a></p>
<p>Introduction: This is a guest post by  Gordon Worley , a Software Engineer at  Korrelate , where they correlate (see what they did there) online purchases to offline purchases. 
 
Several weeks ago, we came into the office one morning to find every server alarm going off. Pixel log processing was behind by 8 hours and not making headway. Checking the logs, we discovered that a big client had come online during the night and was giving us 10 times more traffic than we were originally told to expect. I wouldnâ€™t say we panicked, but the office was certainly more jittery than usual. Over the next several hours, though, thanks both to foresight and quick thinking, we were able to scale up to handle the added load and clear the backlog to return log processing to a steady state.
 
At Korrelate, we deploy  tracking pixels , also known beacons or web bugs, that our partners use to send us information about their users. These tiny web objects contain no visible content, but may include transparent 1 by 1 gif</p><p>4 0.27000982 <a title="77-tfidf-4" href="../high_scalability-2007/high_scalability-2007-07-26-Product%3A_AWStats_a_Log_Analyzer.html">30 high scalability-2007-07-26-Product: AWStats a Log Analyzer</a></p>
<p>Introduction: AWStats  is a free powerful and featureful tool that generates advanced web, streaming, ftp or mail server statistics, graphically. This log analyzer works as a CGI or from command line and shows you all possible information your log contains, in few graphical web pages. It uses a partial information file to be able to process large log files, often and quickly. It can analyze log files from all major server tools like Apache log files (NCSA combined/XLF/ELF log format or common/CLF log format), WebStar, IIS (W3C log format) and a lot of other web, proxy, wap, streaming servers, mail servers and some ftp servers.</p><p>5 0.26049584 <a title="77-tfidf-5" href="../high_scalability-2009/high_scalability-2009-03-16-Product%3A_Smart_Inspect.html">541 high scalability-2009-03-16-Product: Smart Inspect</a></p>
<p>Introduction: Smart Inspect  has added quite a few features specifically tailored to high scalability and high performance environments to our tool over the years. This includes the ability to log to memory and dump log files on demand (when a crash occurs for example), special backlog queue features, a log service application for central log storage and a lot more. Additionally, our SmartInspect Console (the viewer application) makes viewing, filtering and inspecting large amounts of logging data a lot easier/practical.</p><p>6 0.23185658 <a title="77-tfidf-6" href="../high_scalability-2008/high_scalability-2008-11-24-Product%3A_Scribe_-_Facebook%27s_Scalable_Logging_System.html">449 high scalability-2008-11-24-Product: Scribe - Facebook's Scalable Logging System</a></p>
<p>7 0.21996391 <a title="77-tfidf-7" href="../high_scalability-2010/high_scalability-2010-04-27-Paper%3A__Dapper%2C_Google%27s_Large-Scale_Distributed_Systems_Tracing_Infrastructure.html">815 high scalability-2010-04-27-Paper:  Dapper, Google's Large-Scale Distributed Systems Tracing Infrastructure</a></p>
<p>8 0.18829516 <a title="77-tfidf-8" href="../high_scalability-2009/high_scalability-2009-04-03-Collectl_interface_to_Ganglia_-_any_interest%3F.html">553 high scalability-2009-04-03-Collectl interface to Ganglia - any interest?</a></p>
<p>9 0.18279076 <a title="77-tfidf-9" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_Web_Log_Storming.html">37 high scalability-2007-07-28-Product: Web Log Storming</a></p>
<p>10 0.15734568 <a title="77-tfidf-10" href="../high_scalability-2007/high_scalability-2007-10-01-Statistics_Logging_Scalability.html">105 high scalability-2007-10-01-Statistics Logging Scalability</a></p>
<p>11 0.15357697 <a title="77-tfidf-11" href="../high_scalability-2012/high_scalability-2012-12-07-Stuff_The_Internet_Says_On_Scalability_For_December_7%2C_2012.html">1368 high scalability-2012-12-07-Stuff The Internet Says On Scalability For December 7, 2012</a></p>
<p>12 0.15191118 <a title="77-tfidf-12" href="../high_scalability-2010/high_scalability-2010-11-09-Paper%3A_Hyder_-_Scaling_Out_without_Partitioning_.html">937 high scalability-2010-11-09-Paper: Hyder - Scaling Out without Partitioning </a></p>
<p>13 0.14899439 <a title="77-tfidf-13" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>14 0.14660503 <a title="77-tfidf-14" href="../high_scalability-2012/high_scalability-2012-02-20-Berkeley_DB_Architecture_-_NoSQL_Before_NoSQL_was_Cool.html">1196 high scalability-2012-02-20-Berkeley DB Architecture - NoSQL Before NoSQL was Cool</a></p>
<p>15 0.14114611 <a title="77-tfidf-15" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>16 0.14053091 <a title="77-tfidf-16" href="../high_scalability-2008/high_scalability-2008-04-19-How_to_build_a_real-time_analytics_system%3F.html">304 high scalability-2008-04-19-How to build a real-time analytics system?</a></p>
<p>17 0.13378 <a title="77-tfidf-17" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>18 0.13234335 <a title="77-tfidf-18" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>19 0.13102201 <a title="77-tfidf-19" href="../high_scalability-2013/high_scalability-2013-03-18-Beyond_Threads_and_Callbacks_-_Application_Architecture_Pros_and_Cons.html">1425 high scalability-2013-03-18-Beyond Threads and Callbacks - Application Architecture Pros and Cons</a></p>
<p>20 0.12577944 <a title="77-tfidf-20" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.218), (1, 0.112), (2, -0.047), (3, -0.047), (4, 0.02), (5, -0.0), (6, 0.118), (7, 0.097), (8, -0.02), (9, -0.021), (10, -0.012), (11, 0.036), (12, 0.036), (13, -0.067), (14, 0.077), (15, -0.012), (16, 0.043), (17, -0.001), (18, -0.037), (19, 0.04), (20, 0.049), (21, -0.13), (22, -0.053), (23, 0.196), (24, 0.155), (25, -0.053), (26, -0.088), (27, 0.081), (28, -0.002), (29, -0.028), (30, -0.052), (31, -0.133), (32, 0.077), (33, -0.027), (34, -0.041), (35, 0.02), (36, -0.084), (37, 0.031), (38, 0.107), (39, -0.022), (40, 0.015), (41, 0.076), (42, 0.029), (43, -0.022), (44, -0.061), (45, -0.107), (46, 0.039), (47, 0.019), (48, -0.02), (49, -0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96659505 <a title="77-lsi-1" href="../high_scalability-2007/high_scalability-2007-08-30-Log_Everything_All_the_Time.html">77 high scalability-2007-08-30-Log Everything All the Time</a></p>
<p>Introduction: This JoelOnSoftware  thread  asks the age old question of what and how to log. The usual trace/error/warning/info advice is totally useless in a large scale distributed system. Instead, you need to  log everything all the time  so you can solve problems that have already happened across a potentially huge range of servers. Yes, it can be done.  To see why the typical logging approach is broken,  imagine this scenario: Your site has been up and running great for weeks. No problems. A foreshadowing beeper goes off at 2AM. It seems some users can no longer add comments to threads. Then you hear the debugging deathknell: it's an intermittent problem and customers are pissed. Fix it. Now.  So how are you going to debug this? The monitoring system doesn't show any obvious problems or errors. You quickly post a comment and it works fine. This won't be easy. So you think. Commenting involves a bunch of servers and networks. There's the load balancer, spam filter,  web server, database server,</p><p>2 0.90861583 <a title="77-lsi-2" href="../high_scalability-2013/high_scalability-2013-01-21-Processing_100_Million_Pixels_a_Day_-_Small_Amounts_of_Contention_Cause_Big_Problems_at_Scale.html">1390 high scalability-2013-01-21-Processing 100 Million Pixels a Day - Small Amounts of Contention Cause Big Problems at Scale</a></p>
<p>Introduction: This is a guest post by  Gordon Worley , a Software Engineer at  Korrelate , where they correlate (see what they did there) online purchases to offline purchases. 
 
Several weeks ago, we came into the office one morning to find every server alarm going off. Pixel log processing was behind by 8 hours and not making headway. Checking the logs, we discovered that a big client had come online during the night and was giving us 10 times more traffic than we were originally told to expect. I wouldnâ€™t say we panicked, but the office was certainly more jittery than usual. Over the next several hours, though, thanks both to foresight and quick thinking, we were able to scale up to handle the added load and clear the backlog to return log processing to a steady state.
 
At Korrelate, we deploy  tracking pixels , also known beacons or web bugs, that our partners use to send us information about their users. These tiny web objects contain no visible content, but may include transparent 1 by 1 gif</p><p>3 0.87434757 <a title="77-lsi-3" href="../high_scalability-2009/high_scalability-2009-03-16-Product%3A_Smart_Inspect.html">541 high scalability-2009-03-16-Product: Smart Inspect</a></p>
<p>Introduction: Smart Inspect  has added quite a few features specifically tailored to high scalability and high performance environments to our tool over the years. This includes the ability to log to memory and dump log files on demand (when a crash occurs for example), special backlog queue features, a log service application for central log storage and a lot more. Additionally, our SmartInspect Console (the viewer application) makes viewing, filtering and inspecting large amounts of logging data a lot easier/practical.</p><p>4 0.86263132 <a title="77-lsi-4" href="../high_scalability-2008/high_scalability-2008-11-24-Product%3A_Scribe_-_Facebook%27s_Scalable_Logging_System.html">449 high scalability-2008-11-24-Product: Scribe - Facebook's Scalable Logging System</a></p>
<p>Introduction: In  Log Everything All the Time  I advocate applications shouldn't bother logging at all. Why waste all that time and code? No, wait, that's not right. I preach logging everything all the time. Doh. Facebook obviously feels similarly which is why they opened sourced  Scribe , their internal logging system, capable of logging 10s of billions of messages per day. These messages include access logs, performance statistics, actions that went to News Feed, and many others.   Imagine hundreds of thousands of machines across many geographical dispersed datacenters just aching to send their precious log payload to the central repository off all knowledge. Because really, when you combine all the meta data with all the events you pretty much have a complete picture of your operations. Once in the central repository logs can be scanned, indexed, summarized, aggregated, refactored, diced, data cubed, and mined for every scrap of potentially useful information.   Just imagine the log stream from a</p><p>5 0.82279605 <a title="77-lsi-5" href="../high_scalability-2007/high_scalability-2007-07-26-Product%3A_AWStats_a_Log_Analyzer.html">30 high scalability-2007-07-26-Product: AWStats a Log Analyzer</a></p>
<p>Introduction: AWStats  is a free powerful and featureful tool that generates advanced web, streaming, ftp or mail server statistics, graphically. This log analyzer works as a CGI or from command line and shows you all possible information your log contains, in few graphical web pages. It uses a partial information file to be able to process large log files, often and quickly. It can analyze log files from all major server tools like Apache log files (NCSA combined/XLF/ELF log format or common/CLF log format), WebStar, IIS (W3C log format) and a lot of other web, proxy, wap, streaming servers, mail servers and some ftp servers.</p><p>6 0.77646357 <a title="77-lsi-6" href="../high_scalability-2010/high_scalability-2010-11-09-Paper%3A_Hyder_-_Scaling_Out_without_Partitioning_.html">937 high scalability-2010-11-09-Paper: Hyder - Scaling Out without Partitioning </a></p>
<p>7 0.75480205 <a title="77-lsi-7" href="../high_scalability-2009/high_scalability-2009-04-03-Collectl_interface_to_Ganglia_-_any_interest%3F.html">553 high scalability-2009-04-03-Collectl interface to Ganglia - any interest?</a></p>
<p>8 0.74327964 <a title="77-lsi-8" href="../high_scalability-2008/high_scalability-2008-01-30-How_Rackspace_Now_Uses_MapReduce_and_Hadoop_to_Query_Terabytes_of_Data.html">233 high scalability-2008-01-30-How Rackspace Now Uses MapReduce and Hadoop to Query Terabytes of Data</a></p>
<p>9 0.71722317 <a title="77-lsi-9" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_Web_Log_Storming.html">37 high scalability-2007-07-28-Product: Web Log Storming</a></p>
<p>10 0.6938237 <a title="77-lsi-10" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_FastStats_Log_Analyzer_.html">35 high scalability-2007-07-28-Product: FastStats Log Analyzer </a></p>
<p>11 0.68894386 <a title="77-lsi-11" href="../high_scalability-2007/high_scalability-2007-10-01-Statistics_Logging_Scalability.html">105 high scalability-2007-10-01-Statistics Logging Scalability</a></p>
<p>12 0.67608166 <a title="77-lsi-12" href="../high_scalability-2014/high_scalability-2014-04-30-10_Tips_for_Optimizing_NGINX_and_PHP-fpm_for_High_Traffic_Sites.html">1640 high scalability-2014-04-30-10 Tips for Optimizing NGINX and PHP-fpm for High Traffic Sites</a></p>
<p>13 0.6482079 <a title="77-lsi-13" href="../high_scalability-2008/high_scalability-2008-04-19-How_to_build_a_real-time_analytics_system%3F.html">304 high scalability-2008-04-19-How to build a real-time analytics system?</a></p>
<p>14 0.64425051 <a title="77-lsi-14" href="../high_scalability-2007/high_scalability-2007-07-28-Product%3A_Web_Log_Expert.html">36 high scalability-2007-07-28-Product: Web Log Expert</a></p>
<p>15 0.63627845 <a title="77-lsi-15" href="../high_scalability-2012/high_scalability-2012-08-08-3_Tips_and_Tools_for_Creating_Reliable_Billion_Page_View_Web_Services.html">1301 high scalability-2012-08-08-3 Tips and Tools for Creating Reliable Billion Page View Web Services</a></p>
<p>16 0.62576574 <a title="77-lsi-16" href="../high_scalability-2009/high_scalability-2009-04-15-Implementing_large_scale_web_analytics.html">570 high scalability-2009-04-15-Implementing large scale web analytics</a></p>
<p>17 0.60885936 <a title="77-lsi-17" href="../high_scalability-2011/high_scalability-2011-08-10-LevelDB_-_Fast_and_Lightweight_Key-Value_Database_From_the_Authors_of_MapReduce_and_BigTable.html">1096 high scalability-2011-08-10-LevelDB - Fast and Lightweight Key-Value Database From the Authors of MapReduce and BigTable</a></p>
<p>18 0.60692006 <a title="77-lsi-18" href="../high_scalability-2013/high_scalability-2013-08-07-RAFT_-_In_Search_of_an_Understandable_Consensus_Algorithm.html">1498 high scalability-2013-08-07-RAFT - In Search of an Understandable Consensus Algorithm</a></p>
<p>19 0.57701337 <a title="77-lsi-19" href="../high_scalability-2007/high_scalability-2007-07-30-Product%3A_SmarterStats.html">45 high scalability-2007-07-30-Product: SmarterStats</a></p>
<p>20 0.57198966 <a title="77-lsi-20" href="../high_scalability-2012/high_scalability-2012-02-20-Berkeley_DB_Architecture_-_NoSQL_Before_NoSQL_was_Cool.html">1196 high scalability-2012-02-20-Berkeley DB Architecture - NoSQL Before NoSQL was Cool</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.212), (2, 0.281), (10, 0.06), (13, 0.072), (18, 0.019), (26, 0.012), (30, 0.02), (47, 0.021), (56, 0.012), (61, 0.055), (77, 0.011), (79, 0.069), (85, 0.027), (94, 0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98408943 <a title="77-lda-1" href="../high_scalability-2008/high_scalability-2008-09-23-The_7_Stages_of_Scaling_Web_Apps.html">391 high scalability-2008-09-23-The 7 Stages of Scaling Web Apps</a></p>
<p>Introduction: By John Engales CTO, Rackspace. Good presentation of the stages a typical successful website goes through: 
 
 Stage 1 - The Beginning: Simple architecture, low complexity. no redundancy. Firewall, load balancer, a pair of web servers, database server, and internal storage. 
 Stage 2 - More of the same, just bigger. 
 Stage 3 - The Pain Begins: publicity hits. Use reverse proxy, cache static content, load balancers, more databases, re-coding. 
 Stage 4 - The Pain Intensifies: caching with memcached, writes overload and replication takes too long, start database partitioning, shared storage makes sense for content, significant re-architecting for DB. 
 Stage 5 - This Really Hurts!: rethink entire application, partition on geography user ID, etc, create user clusters, using hashing scheme for locating which user belongs to which cluster. 
 Stage 6 - Getting a little less painful: scalable application and database architecture, acceptable performance, starting to add ne features again, op</p><p>same-blog 2 0.97709274 <a title="77-lda-2" href="../high_scalability-2007/high_scalability-2007-08-30-Log_Everything_All_the_Time.html">77 high scalability-2007-08-30-Log Everything All the Time</a></p>
<p>Introduction: This JoelOnSoftware  thread  asks the age old question of what and how to log. The usual trace/error/warning/info advice is totally useless in a large scale distributed system. Instead, you need to  log everything all the time  so you can solve problems that have already happened across a potentially huge range of servers. Yes, it can be done.  To see why the typical logging approach is broken,  imagine this scenario: Your site has been up and running great for weeks. No problems. A foreshadowing beeper goes off at 2AM. It seems some users can no longer add comments to threads. Then you hear the debugging deathknell: it's an intermittent problem and customers are pissed. Fix it. Now.  So how are you going to debug this? The monitoring system doesn't show any obvious problems or errors. You quickly post a comment and it works fine. This won't be easy. So you think. Commenting involves a bunch of servers and networks. There's the load balancer, spam filter,  web server, database server,</p><p>3 0.97054529 <a title="77-lda-3" href="../high_scalability-2009/high_scalability-2009-07-29-Strategy%3A_Devirtualize_for_More_Vroom.html">664 high scalability-2009-07-29-Strategy: Devirtualize for More Vroom</a></p>
<p>Introduction: Virtualization offers a lot of benefits, but it also comes with a  cost  (memory, CPU, network, IO, licensing). If you are in or running a cloud then some form of virtualization may not even be an option. But if you are running your own string of servers you can choose to go without. Free will and all that. Should you or shouldn't you?  In a detailed comparison the folks at  37signals  found that  running their Rails application servers without virtualization  resulted in  A 66% reduction in the response time while handling multiples of the traffic is beyond what I expected .   As is common 37signals runs their big database servers without virtualization. They use a scale-up approach at the database tier so extracting every bit of performance out of those servers is key. Application servers typically use a scale-out approach for scalability, which is virtualization friendly, but that says nothing about performance.   Finding performance increases, especially when you are running on a d</p><p>4 0.97042894 <a title="77-lda-4" href="../high_scalability-2010/high_scalability-2010-01-11-Have_We_Reached_the_End_of_Scaling%3F.html">758 high scalability-2010-01-11-Have We Reached the End of Scaling?</a></p>
<p>Introduction: This is an excerpt from my article  Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud.  
 
Have we reached the end of scaling? That's what I asked myself one day after noticing a bunch of "The End of" headlines. We've reached  The End of History  because the Western liberal democracy is the "end point of humanity's sociocultural evolution and the final form of human government."  We've reached  The End of Science  because of the "fact that there aren't going to be any obvious, cataclysmic revolutions." We've even reached  The End of Theory  because all answers can be found in the continuous stream of data we're collecting. And doesn't always seem like we're at  The End of the World ?
 
Motivated by the prospect of everything ending, I began to wonder: have we really reached The End of Scaling?
 
For a while I thought this might be true. The reason I thought the End of Scaling might be near is because of the slow down of potential articles at m</p><p>5 0.97028589 <a title="77-lda-5" href="../high_scalability-2008/high_scalability-2008-01-30-How_Rackspace_Now_Uses_MapReduce_and_Hadoop_to_Query_Terabytes_of_Data.html">233 high scalability-2008-01-30-How Rackspace Now Uses MapReduce and Hadoop to Query Terabytes of Data</a></p>
<p>Introduction: How do you query hundreds of gigabytes of new data each day streaming in from over 600 hyperactive servers? If you think this sounds like the perfect battle ground for a head-to-head skirmish in the great  MapReduce Versus Database War , you would be correct.   Bill Boebel, CTO of Mailtrust (Rackspace's mail division), has generously provided a fascinating account of how they evolved their log processing system from an early amoeba'ic text file stored on each machine approach,  to a Neandertholic relational database solution that just couldn't compete, and finally to a Homo sapien'ic Hadoop based solution that works wisely for them and has virtually unlimited scalability potential.
 
Rackspace faced a now familiar problem. Lots and lots of data streaming in. Where do you store all that data? How do you do anything useful with it? In the first version of their system logs were stored in flat text files and had to be manually searched by engineers logging into each individual machine.  T</p><p>6 0.96977907 <a title="77-lda-6" href="../high_scalability-2012/high_scalability-2012-12-07-Stuff_The_Internet_Says_On_Scalability_For_December_7%2C_2012.html">1368 high scalability-2012-12-07-Stuff The Internet Says On Scalability For December 7, 2012</a></p>
<p>7 0.96831703 <a title="77-lda-7" href="../high_scalability-2010/high_scalability-2010-08-16-Scaling_an_AWS_infrastructure_-_Tools_and_Patterns.html">881 high scalability-2010-08-16-Scaling an AWS infrastructure - Tools and Patterns</a></p>
<p>8 0.96723974 <a title="77-lda-8" href="../high_scalability-2009/high_scalability-2009-02-12-MySpace_Architecture.html">511 high scalability-2009-02-12-MySpace Architecture</a></p>
<p>9 0.96718669 <a title="77-lda-9" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>10 0.96665442 <a title="77-lda-10" href="../high_scalability-2014/high_scalability-2014-02-17-How_the_AOL.com_Architecture_Evolved_to_99.999%25_Availability%2C_8_Million_Visitors_Per_Day%2C_and_200%2C000_Requests_Per_Second.html">1597 high scalability-2014-02-17-How the AOL.com Architecture Evolved to 99.999% Availability, 8 Million Visitors Per Day, and 200,000 Requests Per Second</a></p>
<p>11 0.96649927 <a title="77-lda-11" href="../high_scalability-2014/high_scalability-2014-05-12-4_Architecture_Issues_When_Scaling_Web_Applications%3A_Bottlenecks%2C_Database%2C_CPU%2C_IO.html">1646 high scalability-2014-05-12-4 Architecture Issues When Scaling Web Applications: Bottlenecks, Database, CPU, IO</a></p>
<p>12 0.96633482 <a title="77-lda-12" href="../high_scalability-2012/high_scalability-2012-04-02-YouPorn_-_Targeting_200_Million_Views_a_Day_and_Beyond.html">1220 high scalability-2012-04-02-YouPorn - Targeting 200 Million Views a Day and Beyond</a></p>
<p>13 0.9663291 <a title="77-lda-13" href="../high_scalability-2009/high_scalability-2009-06-29-How_to_Succeed_at_Capacity_Planning_Without_Really_Trying_%3A__An_Interview_with_Flickr%27s_John_Allspaw_on_His_New_Book.html">643 high scalability-2009-06-29-How to Succeed at Capacity Planning Without Really Trying :  An Interview with Flickr's John Allspaw on His New Book</a></p>
<p>14 0.96595562 <a title="77-lda-14" href="../high_scalability-2009/high_scalability-2009-04-06-How_do_you_monitor_the_performance_of_your_cluster%3F.html">558 high scalability-2009-04-06-How do you monitor the performance of your cluster?</a></p>
<p>15 0.96570128 <a title="77-lda-15" href="../high_scalability-2012/high_scalability-2012-11-29-Performance_data_for_LevelDB%2C_Berkley_DB_and_BangDB_for_Random_Operations.html">1364 high scalability-2012-11-29-Performance data for LevelDB, Berkley DB and BangDB for Random Operations</a></p>
<p>16 0.96547651 <a title="77-lda-16" href="../high_scalability-2008/high_scalability-2008-05-02-Friends_for_Sale_Architecture_-_A_300_Million_Page_View-Month_Facebook_RoR_App.html">313 high scalability-2008-05-02-Friends for Sale Architecture - A 300 Million Page View-Month Facebook RoR App</a></p>
<p>17 0.96535349 <a title="77-lda-17" href="../high_scalability-2012/high_scalability-2012-01-23-Facebook_Timeline%3A_Brought_to_You_by_the_Power_of_Denormalization.html">1179 high scalability-2012-01-23-Facebook Timeline: Brought to You by the Power of Denormalization</a></p>
<p>18 0.96447355 <a title="77-lda-18" href="../high_scalability-2010/high_scalability-2010-09-21-Playfish%27s_Social_Gaming_Architecture_-_50_Million_Monthly_Users_and_Growing.html">904 high scalability-2010-09-21-Playfish's Social Gaming Architecture - 50 Million Monthly Users and Growing</a></p>
<p>19 0.96396756 <a title="77-lda-19" href="../high_scalability-2013/high_scalability-2013-08-13-In_Memoriam%3A_Lavabit_Architecture_-_Creating_a_Scalable_Email_Service.html">1501 high scalability-2013-08-13-In Memoriam: Lavabit Architecture - Creating a Scalable Email Service</a></p>
<p>20 0.96374786 <a title="77-lda-20" href="../high_scalability-2013/high_scalability-2013-12-16-22_Recommendations_for_Building_Effective_High_Traffic_Web_Software.html">1565 high scalability-2013-12-16-22 Recommendations for Building Effective High Traffic Web Software</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
