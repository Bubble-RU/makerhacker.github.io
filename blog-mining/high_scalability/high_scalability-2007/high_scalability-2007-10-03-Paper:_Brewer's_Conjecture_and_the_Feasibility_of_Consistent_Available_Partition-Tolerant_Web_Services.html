<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>108 high scalability-2007-10-03-Paper: Brewer's Conjecture and the Feasibility of Consistent Available Partition-Tolerant Web Services</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2007" href="../home/high_scalability-2007_home.html">high_scalability-2007</a> <a title="high_scalability-2007-108" href="#">high_scalability-2007-108</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>108 high scalability-2007-10-03-Paper: Brewer's Conjecture and the Feasibility of Consistent Available Partition-Tolerant Web Services</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2007-108-html" href="http://highscalability.com//blog/2007/10/3/paper-brewers-conjecture-and-the-feasibility-of-consistent-a.html">html</a></p><p>Introduction: Abstract: When designing distributed web services, there are three properties that are commonly desired: consistency, availability, and partition tolerance. It is impossible to achieve all three. In this note, we prove this conjecture in the asynchronous network model, and then discuss solutions to this dilemma in the partially synchronous model.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract: When designing distributed web services, there are three properties that are commonly desired: consistency, availability, and partition tolerance. [sent-1, score-1.028]
</p><p>2 In this note, we prove this conjecture in the asynchronous network model, and then discuss solutions to this dilemma in the partially synchronous model. [sent-3, score-2.035]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('conjecture', 0.343), ('partially', 0.343), ('dilemma', 0.315), ('desired', 0.266), ('prove', 0.256), ('commonly', 0.25), ('synchronous', 0.228), ('abstract', 0.206), ('properties', 0.203), ('discuss', 0.196), ('model', 0.189), ('impossible', 0.189), ('note', 0.185), ('partition', 0.177), ('asynchronous', 0.164), ('designing', 0.163), ('achieve', 0.162), ('consistency', 0.139), ('solutions', 0.122), ('three', 0.119), ('availability', 0.103), ('services', 0.083), ('network', 0.068), ('distributed', 0.064), ('web', 0.052)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="108-tfidf-1" href="../high_scalability-2007/high_scalability-2007-10-03-Paper%3A_Brewer%27s_Conjecture_and_the_Feasibility_of_Consistent_Available_Partition-Tolerant_Web_Services.html">108 high scalability-2007-10-03-Paper: Brewer's Conjecture and the Feasibility of Consistent Available Partition-Tolerant Web Services</a></p>
<p>Introduction: Abstract: When designing distributed web services, there are three properties that are commonly desired: consistency, availability, and partition tolerance. It is impossible to achieve all three. In this note, we prove this conjecture in the asynchronous network model, and then discuss solutions to this dilemma in the partially synchronous model.</p><p>2 0.13906446 <a title="108-tfidf-2" href="../high_scalability-2009/high_scalability-2009-06-10-Managing_cross_partition_transactions_in_a_distributed_KV_system.html">625 high scalability-2009-06-10-Managing cross partition transactions in a distributed KV system</a></p>
<p>Introduction: I spend a  blog entry  discussing single partition and every partition transactions when using distributed KV systems and solutions for some common problems</p><p>3 0.11720533 <a title="108-tfidf-3" href="../high_scalability-2010/high_scalability-2010-11-30-NoCAP_%E2%80%93_Part_III_%E2%80%93_GigaSpaces_clustering_explained...html">950 high scalability-2010-11-30-NoCAP – Part III – GigaSpaces clustering explained..</a></p>
<p>Introduction: In many of the recent discussions on the design of large scale systems (a.k.a. Web Scale) it was argued that the right set of tradeoffs for building large scale systems would be to give away  C onsistency for  A vailability and  P artition tolerance. Those arguments relied on the foundation of the CAP theorem developed in early 2000-2002. One of the core principals behind the CAP theorem is that you must choose two out of the three CAP properties. In many of the transactional systems giving away consistency is either impossible or yields a huge complexity in the design of those systems. In this series of posts, I've tried to suggest a different set of tradeoffs in which we could achieve scalability without compromising on consistency. I also argued that rather than choosing only two out of the three CAP properties we could choose various degrees of all three. The degrees would be determined by the most likely availability and partition tolerance scenarios in our specific application.</p><p>4 0.098293558 <a title="108-tfidf-4" href="../high_scalability-2013/high_scalability-2013-05-01-Myth%3A_Eric_Brewer_on_Why_Banks_are_BASE_Not_ACID_-_Availability_Is_Revenue_.html">1450 high scalability-2013-05-01-Myth: Eric Brewer on Why Banks are BASE Not ACID - Availability Is Revenue </a></p>
<p>Introduction: In   NoSQL: Past, Present, Future    Eric Brewer  has a particularly fine section on explaining the often hard to understand ideas of   BASE   (Basically Available, Soft State, Eventually Consistent),   ACID   (Atomicity, Consistency, Isolation, Durability),   CAP   (Consistency Availability, Partition Tolerance), in terms of a pernicious long standing myth about the sanctity of consistency in banking.
    Myth   : Money is important, so banks   must   use transactions to keep money safe and consistent, right? 
    Reality   : Banking transactions are inconsistent, particularly for ATMs. ATMs are designed to have a normal case behaviour and a partition mode behaviour. In partition mode Availability is chosen over Consistency. 
   Why?   1)  Availability correlates with revenue and consistency generally does not.  2)  Historically there was never an idea of perfect communication so everything was partitioned.
   Your ATM transaction must go through so Availability is more important than</p><p>5 0.095543548 <a title="108-tfidf-5" href="../high_scalability-2012/high_scalability-2012-12-18-Georeplication%3A_When_Bad_Things_Happen_to_Good_Systems.html">1374 high scalability-2012-12-18-Georeplication: When Bad Things Happen to Good Systems</a></p>
<p>Introduction: Georeplication is one of the standard techniques for dealing when bad things--failure and latency--happen to good systems. The problem is always: how do you do that?  Murat Demirbas , Associate Professor at SUNY Buffalo, has a couple of really good posts that can help:  MDCC: Multi-Data Center Consistency  and  Making Geo-Replicated Systems Fast as Possible, Consistent when Necessary . 
 
In  MDCC: Multi-Data Center Consistency  Murat discusses a paper that says synchronous wide-area replication can be feasible. There's a quick and clear explanation of Paxos and various optimizations that is worth the price of admission. We find that strong consistency doesn't have to be lost across a WAN:
  

The good thing about using Paxos over the WAN is you /almost/ get the full CAP  (all three properties: consistency, availability, and partition-freedom). As we discussed earlier (Paxos taught), Paxos is CP, that is, in the presence of a partition, Paxos keeps consistency over availability. But, P</p><p>6 0.093181625 <a title="108-tfidf-6" href="../high_scalability-2010/high_scalability-2010-03-03-Hot_Scalability_Links_for_March_3%2C_2010.html">787 high scalability-2010-03-03-Hot Scalability Links for March 3, 2010</a></p>
<p>7 0.08453688 <a title="108-tfidf-7" href="../high_scalability-2007/high_scalability-2007-07-23-Weblink_Template.html">22 high scalability-2007-07-23-Weblink Template</a></p>
<p>8 0.084494948 <a title="108-tfidf-8" href="../high_scalability-2011/high_scalability-2011-07-08-Stuff_The_Internet_Says_On_Scalability_For_July_8%2C_2011.html">1076 high scalability-2011-07-08-Stuff The Internet Says On Scalability For July 8, 2011</a></p>
<p>9 0.081432253 <a title="108-tfidf-9" href="../high_scalability-2010/high_scalability-2010-08-12-Think_of_Latency_as_a_Pseudo-permanent_Network_Partition.html">879 high scalability-2010-08-12-Think of Latency as a Pseudo-permanent Network Partition</a></p>
<p>10 0.081252731 <a title="108-tfidf-10" href="../high_scalability-2011/high_scalability-2011-11-23-Paper%3A_Don%E2%80%99t_Settle_for_Eventual%3A_Scalable_Causal_Consistency_for_Wide-Area_Storage_with_COPS.html">1146 high scalability-2011-11-23-Paper: Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</a></p>
<p>11 0.078918874 <a title="108-tfidf-11" href="../high_scalability-2011/high_scalability-2011-12-08-Update_on_Scalable_Causal_Consistency_For_Wide-Area_Storage_With_COPS.html">1153 high scalability-2011-12-08-Update on Scalable Causal Consistency For Wide-Area Storage With COPS</a></p>
<p>12 0.071283393 <a title="108-tfidf-12" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>13 0.07027553 <a title="108-tfidf-13" href="../high_scalability-2009/high_scalability-2009-05-06-Art_of_Distributed.html">590 high scalability-2009-05-06-Art of Distributed</a></p>
<p>14 0.068645634 <a title="108-tfidf-14" href="../high_scalability-2007/high_scalability-2007-09-18-Amazon_Architecture.html">96 high scalability-2007-09-18-Amazon Architecture</a></p>
<p>15 0.068371773 <a title="108-tfidf-15" href="../high_scalability-2009/high_scalability-2009-06-10-Dealing_with_multi-partition_transactions_in_a_distributed_KV_solution.html">623 high scalability-2009-06-10-Dealing with multi-partition transactions in a distributed KV solution</a></p>
<p>16 0.06568905 <a title="108-tfidf-16" href="../high_scalability-2010/high_scalability-2010-01-04-11_Strategies_to_Rock_Your_Startup%E2%80%99s_Scalability_in_2010.html">757 high scalability-2010-01-04-11 Strategies to Rock Your Startup’s Scalability in 2010</a></p>
<p>17 0.063416205 <a title="108-tfidf-17" href="../high_scalability-2011/high_scalability-2011-01-11-Google_Megastore_-_3_Billion_Writes_and_20_Billion_Read_Transactions_Daily.html">972 high scalability-2011-01-11-Google Megastore - 3 Billion Writes and 20 Billion Read Transactions Daily</a></p>
<p>18 0.062613562 <a title="108-tfidf-18" href="../high_scalability-2009/high_scalability-2009-10-12-High_Performance_at_Massive_Scale_%E2%80%93__Lessons_learned_at_Facebook.html">720 high scalability-2009-10-12-High Performance at Massive Scale –  Lessons learned at Facebook</a></p>
<p>19 0.062199462 <a title="108-tfidf-19" href="../high_scalability-2011/high_scalability-2011-11-16-Google%2B_Infrastructure_Update_-_the_JavaScript_Story.html">1143 high scalability-2011-11-16-Google+ Infrastructure Update - the JavaScript Story</a></p>
<p>20 0.059880722 <a title="108-tfidf-20" href="../high_scalability-2012/high_scalability-2012-10-22-Spanner_-_It%27s_About_Programmers_Building_Apps_Using_SQL_Semantics_at_NoSQL_Scale.html">1345 high scalability-2012-10-22-Spanner - It's About Programmers Building Apps Using SQL Semantics at NoSQL Scale</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.063), (1, 0.028), (2, 0.022), (3, 0.043), (4, -0.003), (5, 0.053), (6, -0.005), (7, -0.034), (8, -0.035), (9, 0.012), (10, 0.02), (11, 0.047), (12, -0.071), (13, -0.036), (14, -0.004), (15, 0.024), (16, 0.045), (17, 0.021), (18, 0.055), (19, -0.056), (20, 0.073), (21, 0.058), (22, -0.031), (23, -0.025), (24, -0.047), (25, -0.05), (26, 0.005), (27, -0.007), (28, 0.034), (29, -0.041), (30, 0.037), (31, -0.019), (32, -0.003), (33, 0.034), (34, -0.035), (35, -0.025), (36, -0.015), (37, 0.013), (38, -0.007), (39, 0.002), (40, 0.011), (41, 0.002), (42, -0.005), (43, -0.031), (44, -0.002), (45, -0.024), (46, 0.022), (47, 0.02), (48, -0.03), (49, -0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97768271 <a title="108-lsi-1" href="../high_scalability-2007/high_scalability-2007-10-03-Paper%3A_Brewer%27s_Conjecture_and_the_Feasibility_of_Consistent_Available_Partition-Tolerant_Web_Services.html">108 high scalability-2007-10-03-Paper: Brewer's Conjecture and the Feasibility of Consistent Available Partition-Tolerant Web Services</a></p>
<p>Introduction: Abstract: When designing distributed web services, there are three properties that are commonly desired: consistency, availability, and partition tolerance. It is impossible to achieve all three. In this note, we prove this conjecture in the asynchronous network model, and then discuss solutions to this dilemma in the partially synchronous model.</p><p>2 0.80502284 <a title="108-lsi-2" href="../high_scalability-2012/high_scalability-2012-12-18-Georeplication%3A_When_Bad_Things_Happen_to_Good_Systems.html">1374 high scalability-2012-12-18-Georeplication: When Bad Things Happen to Good Systems</a></p>
<p>Introduction: Georeplication is one of the standard techniques for dealing when bad things--failure and latency--happen to good systems. The problem is always: how do you do that?  Murat Demirbas , Associate Professor at SUNY Buffalo, has a couple of really good posts that can help:  MDCC: Multi-Data Center Consistency  and  Making Geo-Replicated Systems Fast as Possible, Consistent when Necessary . 
 
In  MDCC: Multi-Data Center Consistency  Murat discusses a paper that says synchronous wide-area replication can be feasible. There's a quick and clear explanation of Paxos and various optimizations that is worth the price of admission. We find that strong consistency doesn't have to be lost across a WAN:
  

The good thing about using Paxos over the WAN is you /almost/ get the full CAP  (all three properties: consistency, availability, and partition-freedom). As we discussed earlier (Paxos taught), Paxos is CP, that is, in the presence of a partition, Paxos keeps consistency over availability. But, P</p><p>3 0.73820388 <a title="108-lsi-3" href="../high_scalability-2012/high_scalability-2012-06-27-Paper%3A_Logic_and_Lattices_for_Distributed_Programming.html">1273 high scalability-2012-06-27-Paper: Logic and Lattices for Distributed Programming</a></p>
<p>Introduction: Neil Conway  from Berkeley CS is giving an advanced level talk at  a meetup today  in San Francisco on a new paper:  Logic and Lattices for Distributed Programming  - extending set logic to support CRDT-style lattices. 
 
The description of the meetup is probably the clearest introduction to the paper:
  Developers are increasingly choosing datastores that sacrifice strong consistency guarantees in exchange for improved performance and availability. Unfortunately, writing reliable distributed programs without the benefit of strong consistency can be very challenging.

 


In this talk, I'll discuss work from our group at UC Berkeley that aims to make it easier to write distributed programs without relying on strong consistency. Bloom is a declarative programming language for distributed computing, while CALM is an analysis technique that identifies programs that are guaranteed to be eventually consistent. I'll then discuss our recent work on extending CALM to support a broader range of</p><p>4 0.73053735 <a title="108-lsi-4" href="../high_scalability-2009/high_scalability-2009-06-10-Managing_cross_partition_transactions_in_a_distributed_KV_system.html">625 high scalability-2009-06-10-Managing cross partition transactions in a distributed KV system</a></p>
<p>Introduction: I spend a  blog entry  discussing single partition and every partition transactions when using distributed KV systems and solutions for some common problems</p><p>5 0.72819233 <a title="108-lsi-5" href="../high_scalability-2013/high_scalability-2013-05-01-Myth%3A_Eric_Brewer_on_Why_Banks_are_BASE_Not_ACID_-_Availability_Is_Revenue_.html">1450 high scalability-2013-05-01-Myth: Eric Brewer on Why Banks are BASE Not ACID - Availability Is Revenue </a></p>
<p>Introduction: In   NoSQL: Past, Present, Future    Eric Brewer  has a particularly fine section on explaining the often hard to understand ideas of   BASE   (Basically Available, Soft State, Eventually Consistent),   ACID   (Atomicity, Consistency, Isolation, Durability),   CAP   (Consistency Availability, Partition Tolerance), in terms of a pernicious long standing myth about the sanctity of consistency in banking.
    Myth   : Money is important, so banks   must   use transactions to keep money safe and consistent, right? 
    Reality   : Banking transactions are inconsistent, particularly for ATMs. ATMs are designed to have a normal case behaviour and a partition mode behaviour. In partition mode Availability is chosen over Consistency. 
   Why?   1)  Availability correlates with revenue and consistency generally does not.  2)  Historically there was never an idea of perfect communication so everything was partitioned.
   Your ATM transaction must go through so Availability is more important than</p><p>6 0.72640866 <a title="108-lsi-6" href="../high_scalability-2011/high_scalability-2011-11-23-Paper%3A_Don%E2%80%99t_Settle_for_Eventual%3A_Scalable_Causal_Consistency_for_Wide-Area_Storage_with_COPS.html">1146 high scalability-2011-11-23-Paper: Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</a></p>
<p>7 0.72187722 <a title="108-lsi-7" href="../high_scalability-2013/high_scalability-2013-05-16-Paper%3A_Warp%3A_Multi-Key_Transactions_for_Key-Value_Stores.html">1459 high scalability-2013-05-16-Paper: Warp: Multi-Key Transactions for Key-Value Stores</a></p>
<p>8 0.71997786 <a title="108-lsi-8" href="../high_scalability-2011/high_scalability-2011-12-08-Update_on_Scalable_Causal_Consistency_For_Wide-Area_Storage_With_COPS.html">1153 high scalability-2011-12-08-Update on Scalable Causal Consistency For Wide-Area Storage With COPS</a></p>
<p>9 0.71360868 <a title="108-lsi-9" href="../high_scalability-2014/high_scalability-2014-04-10-Paper%3A_Scalable_Atomic_Visibility_with_RAMP_Transactions_-_Scale_Linearly_to_100_Servers.html">1629 high scalability-2014-04-10-Paper: Scalable Atomic Visibility with RAMP Transactions - Scale Linearly to 100 Servers</a></p>
<p>10 0.71240109 <a title="108-lsi-10" href="../high_scalability-2010/high_scalability-2010-12-23-Paper%3A_CRDTs%3A_Consistency_without_concurrency_control.html">963 high scalability-2010-12-23-Paper: CRDTs: Consistency without concurrency control</a></p>
<p>11 0.70691472 <a title="108-lsi-11" href="../high_scalability-2009/high_scalability-2009-08-08-Yahoo%21%27s_PNUTS_Database%3A_Too_Hot%2C_Too_Cold_or_Just_Right%3F.html">676 high scalability-2009-08-08-Yahoo!'s PNUTS Database: Too Hot, Too Cold or Just Right?</a></p>
<p>12 0.68967962 <a title="108-lsi-12" href="../high_scalability-2010/high_scalability-2010-11-30-NoCAP_%E2%80%93_Part_III_%E2%80%93_GigaSpaces_clustering_explained...html">950 high scalability-2010-11-30-NoCAP – Part III – GigaSpaces clustering explained..</a></p>
<p>13 0.68370843 <a title="108-lsi-13" href="../high_scalability-2010/high_scalability-2010-09-01-Paper%3A_The_Case_for_Determinism_in_Database_Systems__.html">890 high scalability-2010-09-01-Paper: The Case for Determinism in Database Systems  </a></p>
<p>14 0.68062007 <a title="108-lsi-14" href="../high_scalability-2010/high_scalability-2010-08-12-Think_of_Latency_as_a_Pseudo-permanent_Network_Partition.html">879 high scalability-2010-08-12-Think of Latency as a Pseudo-permanent Network Partition</a></p>
<p>15 0.67425984 <a title="108-lsi-15" href="../high_scalability-2009/high_scalability-2009-02-03-Paper%3A_Optimistic_Replication.html">507 high scalability-2009-02-03-Paper: Optimistic Replication</a></p>
<p>16 0.66726279 <a title="108-lsi-16" href="../high_scalability-2013/high_scalability-2013-11-07-Paper%3A_Tempest%3A_Scalable_Time-Critical_Web_Services_Platform.html">1544 high scalability-2013-11-07-Paper: Tempest: Scalable Time-Critical Web Services Platform</a></p>
<p>17 0.6668579 <a title="108-lsi-17" href="../high_scalability-2013/high_scalability-2013-05-23-Paper%3A_Calvin%3A_Fast_Distributed_Transactions_for_Partitioned_Database_Systems.html">1463 high scalability-2013-05-23-Paper: Calvin: Fast Distributed Transactions for Partitioned Database Systems</a></p>
<p>18 0.6210779 <a title="108-lsi-18" href="../high_scalability-2009/high_scalability-2009-03-10-Paper%3A_Consensus_Protocols%3A_Paxos___.html">529 high scalability-2009-03-10-Paper: Consensus Protocols: Paxos   </a></p>
<p>19 0.61376232 <a title="108-lsi-19" href="../high_scalability-2014/high_scalability-2014-03-12-Paper%3A_Scalable_Eventually_Consistent_Counters_over_Unreliable_Networks.html">1611 high scalability-2014-03-12-Paper: Scalable Eventually Consistent Counters over Unreliable Networks</a></p>
<p>20 0.60972756 <a title="108-lsi-20" href="../high_scalability-2010/high_scalability-2010-03-03-Hot_Scalability_Links_for_March_3%2C_2010.html">787 high scalability-2010-03-03-Hot Scalability Links for March 3, 2010</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.106), (27, 0.486), (61, 0.234)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.87065458 <a title="108-lda-1" href="../high_scalability-2007/high_scalability-2007-10-03-Paper%3A_Brewer%27s_Conjecture_and_the_Feasibility_of_Consistent_Available_Partition-Tolerant_Web_Services.html">108 high scalability-2007-10-03-Paper: Brewer's Conjecture and the Feasibility of Consistent Available Partition-Tolerant Web Services</a></p>
<p>Introduction: Abstract: When designing distributed web services, there are three properties that are commonly desired: consistency, availability, and partition tolerance. It is impossible to achieve all three. In this note, we prove this conjecture in the asynchronous network model, and then discuss solutions to this dilemma in the partially synchronous model.</p><p>2 0.76933622 <a title="108-lda-2" href="../high_scalability-2009/high_scalability-2009-04-04-Performance_Anti-Pattern.html">555 high scalability-2009-04-04-Performance Anti-Pattern</a></p>
<p>Introduction: Want your apps to run faster? Here’s what not to do. By: Bart Smaalders, Sun Microsystems.     Performance Anti-Patterns:    - Fixing Performance at the End of the Project    - Measuring and Comparing the Wrong Things    - Algorithmic Antipathy    - Reusing Software    - Iterating Because That’s What Computers Do Well    - Premature Optimization    - Focusing on What You Can See Rather Than on the Problem    - Software Layering    - Excessive Numbers of Threads    - Asymmetric Hardware Utilization    - Not Optimizing for the Common Case    - Needless Swapping of Cache Lines Between CPUs     For more detail   go there</p><p>3 0.53673112 <a title="108-lda-3" href="../high_scalability-2008/high_scalability-2008-03-03-Two_data_streams_for_a_happy_website.html">265 high scalability-2008-03-03-Two data streams for a happy website</a></p>
<p>Introduction: One of the most important architectural decisions that must be done early on in a scalable web site project is  splitting the data flow into two streams : one that is user specific and one that is generic. If this is done properly, the system will be able to grow easily. On the other hand, if the data streams are not separated from the start, then the growth options will be severely limited. Trying to make such a web site scale will be just painting the corpse, and this change will cost a whole lot more when you need to introduce it later (and it is "when" in this case, not "if").</p><p>4 0.49134701 <a title="108-lda-4" href="../high_scalability-2013/high_scalability-2013-06-27-Paper%3A_XORing_Elephants%3A_Novel_Erasure_Codes_for_Big_Data.html">1483 high scalability-2013-06-27-Paper: XORing Elephants: Novel Erasure Codes for Big Data</a></p>
<p>Introduction: Erasure codes  are one of those seemingly magical mathematical creations that with the developments described in the paper  XORing Elephants: Novel Erasure Codes for Big Data , are set to replace triple replication as the data storage protection mechanism of choice.
 
The result says Robin Harris (StorageMojo) in an excellent article,  Facebook’s advanced erasure codes : "WebCos will be able to store massive amounts of data more efficiently than ever before. Bad news: so will anyone else."
 
Robin says with cheap disks triple replication made sense and was economical. With ever bigger BigData the overhead has become costly. But erasure codes have always suffered from unacceptably long time to repair times. This paper describes new Locally Repairable Codes (LRCs) that are efficiently repairable in disk I/O and bandwidth requirements:
  

These systems are now designed to survive the loss of up to four storage elements – disks, servers, nodes or even entire data centers – without losing</p><p>5 0.48487973 <a title="108-lda-5" href="../high_scalability-2011/high_scalability-2011-08-12-Stuff_The_Internet_Says_On_Scalability_For_August_12%2C_2011.html">1097 high scalability-2011-08-12-Stuff The Internet Says On Scalability For August 12, 2011</a></p>
<p>Introduction: Submitted for your scaling pleasure, you may not  scale often, but when you scale, please drink us:
  
 Quotably quotable quotes:            
 
  @mardix  : There is no single point of truth in #NoSQL . #Consistency is no longer global, it's relative to the one accessing it. #Scalability 
  @kekline  : RT @CurtMonash: "...from industry figures, Basho/Riak is our third-biggest competitor." How often do you encounter them? "Never have" #nosql 
  @dave_jacobs  : Love being in a city where I can overhear a convo about Heroku scalability while doing deadlifts. #ahsanfrancisco 
  @satheeshilu  : Doctor at #hospital in india says #ge #healthcare software is slow to handle 100K X-rays an year.Scalability is critical 4 Indian #software 
  @sufw  : How can it be possible that Tagged has 80m users and I have *never* heard of it!?! 
  @EventCloudPro  : One of my vacation realizations? Whole #bigdata thing has turned into a lotta #bighype - many distinct issues & nothing to do w/ #bigdata  
 
 
 No</p><p>6 0.45296589 <a title="108-lda-6" href="../high_scalability-2007/high_scalability-2007-07-25-Product%3A_NetApp_MetroCluster_Software.html">28 high scalability-2007-07-25-Product: NetApp MetroCluster Software</a></p>
<p>7 0.44920594 <a title="108-lda-7" href="../high_scalability-2009/high_scalability-2009-04-24-INFOSCALE_2009_in_June_in_Hong_Kong.html">580 high scalability-2009-04-24-INFOSCALE 2009 in June in Hong Kong</a></p>
<p>8 0.44738227 <a title="108-lda-8" href="../high_scalability-2009/high_scalability-2009-03-18-QCon_London_2009%3A_Upgrading_Twitter_without_service_disruptions.html">544 high scalability-2009-03-18-QCon London 2009: Upgrading Twitter without service disruptions</a></p>
<p>9 0.43609706 <a title="108-lda-9" href="../high_scalability-2009/high_scalability-2009-01-16-Just-In-Time_Scalability%3A_Agile_Methods_to_Support_Massive_Growth_%28IMVU_case_study%29.html">493 high scalability-2009-01-16-Just-In-Time Scalability: Agile Methods to Support Massive Growth (IMVU case study)</a></p>
<p>10 0.43205267 <a title="108-lda-10" href="../high_scalability-2010/high_scalability-2010-03-10-Saying_Yes_to_NoSQL%3B_Going_Steady_with_Cassandra_at_Digg.html">793 high scalability-2010-03-10-Saying Yes to NoSQL; Going Steady with Cassandra at Digg</a></p>
<p>11 0.42546722 <a title="108-lda-11" href="../high_scalability-2008/high_scalability-2008-03-06-Announce%3A_First_Meeting_of_Boston_Scalability_User_Group.html">268 high scalability-2008-03-06-Announce: First Meeting of Boston Scalability User Group</a></p>
<p>12 0.4225235 <a title="108-lda-12" href="../high_scalability-2008/high_scalability-2008-01-28-DR-BC_for_web-DB_servers.html">226 high scalability-2008-01-28-DR-BC for web-DB servers</a></p>
<p>13 0.42105809 <a title="108-lda-13" href="../high_scalability-2009/high_scalability-2009-08-08-1dbase_vs._many_and_cloud_hosting_vs._dedicated_server%28s%29%3F.html">675 high scalability-2009-08-08-1dbase vs. many and cloud hosting vs. dedicated server(s)?</a></p>
<p>14 0.41679335 <a title="108-lda-14" href="../high_scalability-2007/high_scalability-2007-12-05-Easier_Production_Releases_.html">173 high scalability-2007-12-05-Easier Production Releases </a></p>
<p>15 0.41357672 <a title="108-lda-15" href="../high_scalability-2012/high_scalability-2012-08-13-Ask_HighScalability%3A_Facing_scaling_issues_with_news_feeds_on_Redis.__Any_advice%3F.html">1303 high scalability-2012-08-13-Ask HighScalability: Facing scaling issues with news feeds on Redis.  Any advice?</a></p>
<p>16 0.41318974 <a title="108-lda-16" href="../high_scalability-2008/high_scalability-2008-05-19-UK_Based_CDN.html">324 high scalability-2008-05-19-UK Based CDN</a></p>
<p>17 0.41259655 <a title="108-lda-17" href="../high_scalability-2010/high_scalability-2010-10-28-NoSQL_Took_Away_the_Relational_Model_and_Gave_Nothing_Back.html">930 high scalability-2010-10-28-NoSQL Took Away the Relational Model and Gave Nothing Back</a></p>
<p>18 0.41144079 <a title="108-lda-18" href="../high_scalability-2009/high_scalability-2009-11-26-Kngine_Snippet_Search_New_Indexing_Technology.html">746 high scalability-2009-11-26-Kngine Snippet Search New Indexing Technology</a></p>
<p>19 0.41030291 <a title="108-lda-19" href="../high_scalability-2009/high_scalability-2009-03-26-Performance_-_When_do_I_start_worrying%3F.html">549 high scalability-2009-03-26-Performance - When do I start worrying?</a></p>
<p>20 0.40960974 <a title="108-lda-20" href="../high_scalability-2008/high_scalability-2008-07-07-Five_Ways_to_Stop_Framework_Fixation_from_Crashing_Your_Scaling_Strategy.html">347 high scalability-2008-07-07-Five Ways to Stop Framework Fixation from Crashing Your Scaling Strategy</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
