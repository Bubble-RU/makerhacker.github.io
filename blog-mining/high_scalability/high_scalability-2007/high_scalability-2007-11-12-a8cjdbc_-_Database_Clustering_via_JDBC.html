<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>151 high scalability-2007-11-12-a8cjdbc - Database Clustering via JDBC</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2007" href="../home/high_scalability-2007_home.html">high_scalability-2007</a> <a title="high_scalability-2007-151" href="#">high_scalability-2007-151</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>151 high scalability-2007-11-12-a8cjdbc - Database Clustering via JDBC</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2007-151-html" href="http://highscalability.com//blog/2007/11/12/a8cjdbc-database-clustering-via-jdbc.html">html</a></p><p>Introduction: Practically any software project nowadays could not survive without a database
(DBMS) backend storing all the business data that is vital to you and/or your
customers. When projects grow larger, the amount of data usually grows larger
exponentially. So you start moving the DBMS to a separate server to gain more
speed and capacity. Which is all good and healthy but you do not gain any
extra safety for this business data. You might be backing up your database
once a day so in case the database server crashes you don't lose EVERYTHING,
but how much can you really afford to lose? Well clearly this depends on what
kind of data you are storing. In our case the users of our solutions use our
software products to do their everyday (all day) work. They have "everything"
they need for their business stored in the database we are providing. So is 24
hours of data loss acceptable? No, not really. One hour? Maybe. But what we
really want is a second database running with the EXACT same data. We mos</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('jdbc', 0.261), ('database', 0.239), ('safety', 0.211), ('dbms', 0.2), ('gain', 0.163), ('lose', 0.163), ('sequoia', 0.154), ('nowadays', 0.149), ('transparent', 0.146), ('afterwards', 0.145), ('multiply', 0.141), ('vital', 0.133), ('business', 0.132), ('practically', 0.131), ('everyday', 0.126), ('structure', 0.126), ('statements', 0.123), ('healthy', 0.12), ('larger', 0.118), ('triggers', 0.118)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="151-tfidf-1" href="../high_scalability-2007/high_scalability-2007-11-12-a8cjdbc_-_Database_Clustering_via_JDBC.html">151 high scalability-2007-11-12-a8cjdbc - Database Clustering via JDBC</a></p>
<p>Introduction: Practically any software project nowadays could not survive without a database
(DBMS) backend storing all the business data that is vital to you and/or your
customers. When projects grow larger, the amount of data usually grows larger
exponentially. So you start moving the DBMS to a separate server to gain more
speed and capacity. Which is all good and healthy but you do not gain any
extra safety for this business data. You might be backing up your database
once a day so in case the database server crashes you don't lose EVERYTHING,
but how much can you really afford to lose? Well clearly this depends on what
kind of data you are storing. In our case the users of our solutions use our
software products to do their everyday (all day) work. They have "everything"
they need for their business stored in the database we are providing. So is 24
hours of data loss acceptable? No, not really. One hour? Maybe. But what we
really want is a second database running with the EXACT same data. We mos</p><p>2 0.18666673 <a title="151-tfidf-2" href="../high_scalability-2007/high_scalability-2007-09-27-Product%3A_Sequoia_Database_Clustering_Technology.html">102 high scalability-2007-09-27-Product: Sequoia Database Clustering Technology</a></p>
<p>Introduction: Sequoiais a transparent middleware solution offering clustering, load
balancing and failover services for any database. Sequoia is the continuation
of the C-JDBC project. The database is distributed and replicated among
several nodes and Sequoia balances the queries among these nodes. Sequoia
handles node and network failures with transparent failover. It also provides
support for hot recovery, online maintenance operations and online
upgrades.Features in a nutshellNo modification of existing applications or
databases.Operational with any database providing a JDBC driver.High
availability provided by advanced RAIDb technology.Transparent failover and
recovery capabilities.Performance scalability with unique load balancing and
query result caching features.Integrated JMX-based administration and
monitoring.100% Java implementation allowing portability across platforms with
a JRE 1.4 or greater.Open source licensed under Apache v2 license.Professional
support, training and consulting pro</p><p>3 0.14072196 <a title="151-tfidf-3" href="../high_scalability-2010/high_scalability-2010-09-11-Google%27s_Colossus_Makes_Search_Real-time_by_Dumping_MapReduce.html">900 high scalability-2010-09-11-Google's Colossus Makes Search Real-time by Dumping MapReduce</a></p>
<p>Introduction: As the Kings of scaling, when Google changes its search infrastructure over to
do something completely different, it's news. InGoogle search index splits
with MapReduce, an exclusive interview by Cade Metz with Eisar Lipkovitz, a
senior director of engineering at Google, we learn a bit more of the secret
scaling sauce behindGoogle Instant, Google's new faster, real-time search
system.The challenge for Google has been how to support a real-time world when
the core of their search technology, the famous MapReduce, is batch oriented.
Simple, they got rid of MapReduce. At least they got rid of MapReduce as the
backbone for calculating search indexes. MapReduce still excels as a general
query mechanism against masses of data, but real-time search requires a very
specialized tool, and Google built one. Internally the successor to Google's
famed Google File System, was code named Colossus.Details are slowly coming
out about their new goals and approach:Goal is to update the search index
conti</p><p>4 0.1388111 <a title="151-tfidf-4" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>Introduction: The AWS East Region outage showed all of us the importance of running our apps
and databases across multiple Amazon regions (or multiple cloud providers). In
this post, I'll try to explain how to build a MySQL (or Amazon RDS) redundant
site.For simplicity, we create a passive redundant site. This means that the
site is not used during normal operation and only comes into action when the
primary site crashes. There are many reasons for choosing such an architecture
- it's easy to configure, simple to understand, and minimizes the risk of data
collision. The downside is that you have hardware just sitting around doing
nothing.Still, it's a common enough scenario. So what do we need to do to make
it work?DATA SYNCHRONIZATIONWe need to synchronize the database. This is done
by means of database replication. Now, there are two options for database
replication: synchronous and a-synchronous. Synchronous replication is great;
it ensures that the backup database is identical to the primary dat</p><p>5 0.1330044 <a title="151-tfidf-5" href="../high_scalability-2008/high_scalability-2008-04-10-Mysql_scalability_and_failover....html">302 high scalability-2008-04-10-Mysql scalability and failover...</a></p>
<p>Introduction: Hi,I am an owner of an large community website and currently we are having
problems with our database architecture. We are using 2 database servers and
spread tables across them to divide read/writes. We have about 90% reads and
10% writes. We use Memcached on all our webservers to cache as much as we can,
traffic is load balanced between webservers. We have 2 extra servers ready to
put to use!We have looked into a couple of solution so far:Continuent
Uni/Cluster aka Sequoia -> Commercial version way too expensive and Java isn't
as fast as it suppose to be.MySQL Proxy -> We couldn't find any good example
on how to create a master - master with failover scenario.MySQL Clustering ->
Seems to be not mature enough, had a lot of performance issues when we tried
to go online with it.MySQL DRDB HA -> Only good for failover, cannot be
scaled!MySQL Replication -> Well don't get me started ;)So now I turn to you
guys to help me out, I am with my hands in my hair and see the site still
growning a</p><p>6 0.12806454 <a title="151-tfidf-6" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>7 0.1231285 <a title="151-tfidf-7" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>8 0.12108021 <a title="151-tfidf-8" href="../high_scalability-2010/high_scalability-2010-07-13-DbShards_Part_Deux_-_The_Internals.html">857 high scalability-2010-07-13-DbShards Part Deux - The Internals</a></p>
<p>9 0.11185152 <a title="151-tfidf-9" href="../high_scalability-2011/high_scalability-2011-06-21-Running_TPC-C_on_MySQL-RDS.html">1065 high scalability-2011-06-21-Running TPC-C on MySQL-RDS</a></p>
<p>10 0.11158547 <a title="151-tfidf-10" href="../high_scalability-2012/high_scalability-2012-07-04-Top_Features_of_a_Scalable_Database.html">1276 high scalability-2012-07-04-Top Features of a Scalable Database</a></p>
<p>11 0.10953024 <a title="151-tfidf-11" href="../high_scalability-2011/high_scalability-2011-06-20-35%2B_Use_Cases_for_Choosing_Your_Next_NoSQL_Database.html">1064 high scalability-2011-06-20-35+ Use Cases for Choosing Your Next NoSQL Database</a></p>
<p>12 0.10898114 <a title="151-tfidf-12" href="../high_scalability-2009/high_scalability-2009-05-05-Drop_ACID_and_Think_About_Data.html">589 high scalability-2009-05-05-Drop ACID and Think About Data</a></p>
<p>13 0.10790969 <a title="151-tfidf-13" href="../high_scalability-2014/high_scalability-2014-02-03-How_Google_Backs_Up_the_Internet_Along_With_Exabytes_of_Other_Data.html">1589 high scalability-2014-02-03-How Google Backs Up the Internet Along With Exabytes of Other Data</a></p>
<p>14 0.10775528 <a title="151-tfidf-14" href="../high_scalability-2008/high_scalability-2008-04-05-Skype_Plans_for_PostgreSQL_to_Scale_to_1_Billion_Users.html">297 high scalability-2008-04-05-Skype Plans for PostgreSQL to Scale to 1 Billion Users</a></p>
<p>15 0.10650861 <a title="151-tfidf-15" href="../high_scalability-2008/high_scalability-2008-05-27-eBay_Architecture.html">331 high scalability-2008-05-27-eBay Architecture</a></p>
<p>16 0.10322217 <a title="151-tfidf-16" href="../high_scalability-2012/high_scalability-2012-07-23-Ask_HighScalability%3A_How_Do_I_Build_My_MegaUpload_%2B_Itunes_%2B_YouTube_Startup%3F.html">1288 high scalability-2012-07-23-Ask HighScalability: How Do I Build My MegaUpload + Itunes + YouTube Startup?</a></p>
<p>17 0.10310515 <a title="151-tfidf-17" href="../high_scalability-2007/high_scalability-2007-08-22-How_many_machines_do_you_need_to_run_your_site%3F.html">70 high scalability-2007-08-22-How many machines do you need to run your site?</a></p>
<p>18 0.10163869 <a title="151-tfidf-18" href="../high_scalability-2009/high_scalability-2009-07-17-Against_all_the_odds.html">658 high scalability-2009-07-17-Against all the odds</a></p>
<p>19 0.10156133 <a title="151-tfidf-19" href="../high_scalability-2008/high_scalability-2008-05-02-Friends_for_Sale_Architecture_-_A_300_Million_Page_View-Month_Facebook_RoR_App.html">313 high scalability-2008-05-02-Friends for Sale Architecture - A 300 Million Page View-Month Facebook RoR App</a></p>
<p>20 0.1009879 <a title="151-tfidf-20" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.202), (1, 0.077), (2, -0.021), (3, -0.067), (4, 0.018), (5, 0.068), (6, 0.022), (7, -0.08), (8, 0.037), (9, -0.032), (10, -0.039), (11, 0.022), (12, -0.049), (13, 0.035), (14, 0.062), (15, 0.028), (16, 0.012), (17, 0.001), (18, -0.004), (19, 0.043), (20, 0.008), (21, -0.003), (22, -0.002), (23, 0.007), (24, 0.015), (25, 0.035), (26, -0.04), (27, -0.049), (28, 0.016), (29, 0.043), (30, -0.034), (31, 0.029), (32, -0.044), (33, -0.011), (34, -0.032), (35, 0.03), (36, -0.007), (37, 0.011), (38, 0.058), (39, 0.015), (40, 0.009), (41, -0.061), (42, -0.004), (43, 0.007), (44, 0.012), (45, -0.016), (46, 0.089), (47, 0.005), (48, -0.009), (49, 0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97255254 <a title="151-lsi-1" href="../high_scalability-2007/high_scalability-2007-11-12-a8cjdbc_-_Database_Clustering_via_JDBC.html">151 high scalability-2007-11-12-a8cjdbc - Database Clustering via JDBC</a></p>
<p>Introduction: Practically any software project nowadays could not survive without a database
(DBMS) backend storing all the business data that is vital to you and/or your
customers. When projects grow larger, the amount of data usually grows larger
exponentially. So you start moving the DBMS to a separate server to gain more
speed and capacity. Which is all good and healthy but you do not gain any
extra safety for this business data. You might be backing up your database
once a day so in case the database server crashes you don't lose EVERYTHING,
but how much can you really afford to lose? Well clearly this depends on what
kind of data you are storing. In our case the users of our solutions use our
software products to do their everyday (all day) work. They have "everything"
they need for their business stored in the database we are providing. So is 24
hours of data loss acceptable? No, not really. One hour? Maybe. But what we
really want is a second database running with the EXACT same data. We mos</p><p>2 0.83635849 <a title="151-lsi-2" href="../high_scalability-2008/high_scalability-2008-04-05-Skype_Plans_for_PostgreSQL_to_Scale_to_1_Billion_Users.html">297 high scalability-2008-04-05-Skype Plans for PostgreSQL to Scale to 1 Billion Users</a></p>
<p>Introduction: Skypeuses PostgreSQL as their backend database. PostgreSQL doesn't get enough
run in the database world so I was excited to see how PostgreSQL is used "as
the main DB for most of [Skype's] business needs." Their approach is to use a
traditional stored procedure interface for accessing data and on top of that
layer proxy servers which hash SQL requests to a set of database servers that
actually carry out queries. The result is a horizontally partitioned system
that they think will scale to handle 1 billion users.Skype's goal is an
architecture that can handle 1 billion plus users. This level of scale isn't
practically solvable with one really big computer, so our masked superhero
horizontal scaling comes to the rescue.Hardware is dual or quad Opterons with
SCSI RAID.Followed common database progression: Start with one DB. Add new
databases partitioned by functionality. Replicate read-mostly data for better
read access. Then horizontally partition data across multiple nodes..In a
first f</p><p>3 0.82195133 <a title="151-lsi-3" href="../high_scalability-2010/high_scalability-2010-02-23-When_to_migrate_your_database%3F.html">782 high scalability-2010-02-23-When to migrate your database?</a></p>
<p>Introduction: Why migrate your database? Efficiency and availability problems are harming
your business - reports are out of date, your batch processing window is
nearing its limits, outages (unplanned/planned) frequently halt work. Database
consolidation - remove the costs that result from a heterogeneous database
environment (DBAs time, database vendor pricing, database versions, hardware,
OSs, patches, upgrades etc.). OK, so the driving forces for migration are
clear,  what now?ďťżRead more onBigDataMatters.com</p><p>4 0.81921685 <a title="151-lsi-4" href="../high_scalability-2008/high_scalability-2008-09-05-Product%3A_Tungsten_Replicator.html">380 high scalability-2008-09-05-Product: Tungsten Replicator</a></p>
<p>Introduction: WithTungsten ReplicatorContinuent is trying to deliver a better master/slave
replication system. Their goal: scalability, reliability with seamless
failover, no performance loss.From their website:The Tungsten Replicator
implements open source database-neutral master/slave replication. Master/slave
replication is a highly flexible technology that can solve a wide variety of
problems including the following:* Availability - Failing over to a slave
database if your master database dies* Performance Scaling - Spreading reads
across many copies of data* Cross-Site Clustering - Maintaining active
database replicas across WANs* Change Data Capture - Extracting changes to
load data warehouses or update other systems* Zero Downtime Upgrade -
Performing upgrades on a slave server which then becomes the masterThe
Tungsten Replicator architecture is flexible and designed to support addition
of new databases easily. It includes pluggable extractor and applier modules
to help transfer data from mas</p><p>5 0.79536659 <a title="151-lsi-5" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>Introduction: This article is a lightly edited version of 20 Obstacles to Scalability bySean
Hull (with permission) from the always excellent and thought provoking ACM
Queue.1. TWO-PHASE COMMITNormally when data is changed in a database, it is
written both to memory and to disk. When a commit happens, a relational
database makes a commitment to freeze the data somewhere on real storage
media. Remember, memory doesn't survive a crash or reboot. Even if the data is
cached in memory, the database still has to write it to disk. MySQL binary
logs or Oracle redo logs fit the bill.With a MySQL cluster or distributed file
system such as DRBD (Distributed Replicated Block Device) or Amazon Multi-AZ
(Multi-Availability Zone), a commit occurs not only locally, but also at the
remote end. A two-phase commit means waiting for an acknowledgment from the
far end. Because of network and other latency, those commits can be slowed
down by milliseconds, as though all the cars on a highway were slowed down by
heavy loa</p><p>6 0.78890598 <a title="151-lsi-6" href="../high_scalability-2008/high_scalability-2008-07-16-The_Mother_of_All_Database_Normalization_Debates_on_Coding_Horror.html">351 high scalability-2008-07-16-The Mother of All Database Normalization Debates on Coding Horror</a></p>
<p>7 0.78249943 <a title="151-lsi-7" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>8 0.77158278 <a title="151-lsi-8" href="../high_scalability-2007/high_scalability-2007-08-16-Scaling_Secret_%232%3A_Denormalizing_Your_Way_to_Speed_and_Profit.html">65 high scalability-2007-08-16-Scaling Secret #2: Denormalizing Your Way to Speed and Profit</a></p>
<p>9 0.76888567 <a title="151-lsi-9" href="../high_scalability-2010/high_scalability-2010-06-23-Product%3A_dbShards_-_Share_Nothing._Shard_Everything..html">847 high scalability-2010-06-23-Product: dbShards - Share Nothing. Shard Everything.</a></p>
<p>10 0.76853991 <a title="151-lsi-10" href="../high_scalability-2011/high_scalability-2011-06-21-Running_TPC-C_on_MySQL-RDS.html">1065 high scalability-2011-06-21-Running TPC-C on MySQL-RDS</a></p>
<p>11 0.76709759 <a title="151-lsi-11" href="../high_scalability-2010/high_scalability-2010-06-28-VoltDB_Decapitates_Six_SQL_Urban_Myths_and_Delivers_Internet_Scale_OLTP_in_the_Process.html">849 high scalability-2010-06-28-VoltDB Decapitates Six SQL Urban Myths and Delivers Internet Scale OLTP in the Process</a></p>
<p>12 0.76167148 <a title="151-lsi-12" href="../high_scalability-2009/high_scalability-2009-08-05-Stack_Overflow_Architecture.html">671 high scalability-2009-08-05-Stack Overflow Architecture</a></p>
<p>13 0.75423133 <a title="151-lsi-13" href="../high_scalability-2010/high_scalability-2010-04-29-Product%3A_SciDB_-_A_Science-Oriented_DBMS_at_100_Petabytes.html">817 high scalability-2010-04-29-Product: SciDB - A Science-Oriented DBMS at 100 Petabytes</a></p>
<p>14 0.75247777 <a title="151-lsi-14" href="../high_scalability-2009/high_scalability-2009-08-08-1dbase_vs._many_and_cloud_hosting_vs._dedicated_server%28s%29%3F.html">675 high scalability-2009-08-08-1dbase vs. many and cloud hosting vs. dedicated server(s)?</a></p>
<p>15 0.75177217 <a title="151-lsi-15" href="../high_scalability-2012/high_scalability-2012-08-14-MemSQL_Architecture_-_The_Fast_%28MVCC%2C_InMem%2C_LockFree%2C_CodeGen%29_and_Familiar_%28SQL%29.html">1304 high scalability-2012-08-14-MemSQL Architecture - The Fast (MVCC, InMem, LockFree, CodeGen) and Familiar (SQL)</a></p>
<p>16 0.75130218 <a title="151-lsi-16" href="../high_scalability-2010/high_scalability-2010-03-23-Digg%3A_4000%25_Performance_Increase_by_Sorting_in_PHP_Rather_than_MySQL.html">799 high scalability-2010-03-23-Digg: 4000% Performance Increase by Sorting in PHP Rather than MySQL</a></p>
<p>17 0.75033206 <a title="151-lsi-17" href="../high_scalability-2014/high_scalability-2014-02-17-How_the_AOL.com_Architecture_Evolved_to_99.999%25_Availability%2C_8_Million_Visitors_Per_Day%2C_and_200%2C000_Requests_Per_Second.html">1597 high scalability-2014-02-17-How the AOL.com Architecture Evolved to 99.999% Availability, 8 Million Visitors Per Day, and 200,000 Requests Per Second</a></p>
<p>18 0.75016719 <a title="151-lsi-18" href="../high_scalability-2008/high_scalability-2008-12-20-Second_Life_Architecture_-_The_Grid.html">473 high scalability-2008-12-20-Second Life Architecture - The Grid</a></p>
<p>19 0.74861193 <a title="151-lsi-19" href="../high_scalability-2009/high_scalability-2009-02-12-MySpace_Architecture.html">511 high scalability-2009-02-12-MySpace Architecture</a></p>
<p>20 0.74764633 <a title="151-lsi-20" href="../high_scalability-2008/high_scalability-2008-02-02-The_case_against_ORM_Frameworks_in_High_Scalability_Architectures.html">235 high scalability-2008-02-02-The case against ORM Frameworks in High Scalability Architectures</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.18), (2, 0.267), (10, 0.063), (27, 0.012), (38, 0.098), (40, 0.026), (61, 0.086), (79, 0.12), (85, 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98121786 <a title="151-lda-1" href="../high_scalability-2013/high_scalability-2013-05-06-7_Not_So_Sexy_Tips_for_Saving_Money_On_Amazon.html">1452 high scalability-2013-05-06-7 Not So Sexy Tips for Saving Money On Amazon</a></p>
<p>Introduction: Harish Ganesan CTO of8KMiles has a very helpful blog, Cloud, Big Data and
Mobile, where he shows a nice analytical bent which leads to a lot of
practical advice and cost saving tips:Use SQS Batch Requests to reduce the
number of requests hitting SQS which saves costs. Sending 10 messages in a
single batch request which in the example save $30/month.Use SQS Long Polling
to reduce extra polling requests, cutting down empty receives, which in the
example saves ~$600 in empty receive leakage costs.Choose the right search
technology choice to save costs in AWS by matching your activity pattern to
the technology. For a small application with constant load or a heavily
utilized search tier or seasonal loads Amazon Cloud Search looks like the cost
efficient play. Use Amazon CloudFront Price Class to minimize costs by
selecting the right Price Class for your audience to potentially reduce
delivery costs by excluding Amazon CloudFront's more expensive edge
locations.Optimize ElastiCache Cluster</p><p>same-blog 2 0.97034836 <a title="151-lda-2" href="../high_scalability-2007/high_scalability-2007-11-12-a8cjdbc_-_Database_Clustering_via_JDBC.html">151 high scalability-2007-11-12-a8cjdbc - Database Clustering via JDBC</a></p>
<p>Introduction: Practically any software project nowadays could not survive without a database
(DBMS) backend storing all the business data that is vital to you and/or your
customers. When projects grow larger, the amount of data usually grows larger
exponentially. So you start moving the DBMS to a separate server to gain more
speed and capacity. Which is all good and healthy but you do not gain any
extra safety for this business data. You might be backing up your database
once a day so in case the database server crashes you don't lose EVERYTHING,
but how much can you really afford to lose? Well clearly this depends on what
kind of data you are storing. In our case the users of our solutions use our
software products to do their everyday (all day) work. They have "everything"
they need for their business stored in the database we are providing. So is 24
hours of data loss acceptable? No, not really. One hour? Maybe. But what we
really want is a second database running with the EXACT same data. We mos</p><p>3 0.9670738 <a title="151-lda-3" href="../high_scalability-2011/high_scalability-2011-09-21-5_Scalability_Poisons_and_3_Cloud_Scalability_Antidotes.html">1121 high scalability-2011-09-21-5 Scalability Poisons and 3 Cloud Scalability Antidotes</a></p>
<p>Introduction: Sean Hullwith two helpful posts:5 Things That are Toxic to Scalability:Object
Relational Mappers.Create complex queries that hard to optimize and
tweak.Synchronous, Serial, Coupled or Locking Processes.Locks are like stop
signs, traffic circles keep the traffic flowing. Row level locking is better
than table level locking. Use async replication. Use eventual consistency for
clusters.One Copy of Your Database.A single database server is a choke point.
Create parallel databases and let a driver select between them.Having No
Metrics.Visualize what's happening to your system using one of the many
monitoring packages.Lack of Feature Flags.Be able to turn off features via a
flag so when a spike hits features can be turned off to reduce load.3 Ways to
Boost Cloud Scalability:Use Auto-scaling.Spin-up new instances when a
threshold is passed and back down again when traffic drops.Horizontally Scale
the Database Tier.MySQL in a master-master active passive cluster
configuration. As load grows ro</p><p>4 0.96323919 <a title="151-lda-4" href="../high_scalability-2011/high_scalability-2011-02-23-This_stuff_isn%27t_taught%2C_you_learn_it_bit_by_bit_as_you_solve_each_problem..html">994 high scalability-2011-02-23-This stuff isn't taught, you learn it bit by bit as you solve each problem.</a></p>
<p>Introduction: "For the things we have to learn before we can do them, we learn by doing
them." -- AristotleA really nice Internet moment happened in the HackerNews
thread Disqus: Scaling the World's Largest Django Application, when David
Kitchen crafted an awesome responseto a questionabout how you learn to build
scalable systems. It's so good I thought I would reproduce it
here.Question:asked by grovulent:Not like this is a problem I have to worry
about. But where on earth does one learn this stuff? The talk is useful - as
an overview of what they use - but I know nothing of how to implement a single
step.Answer: answered by David Kitchenofburo9:It's called experience. Which
perhaps sounds rude, but it's not meant to be.This stuff isn't taught per se,
you learn it bit by bit as you solve each problem that you face.I learned
about HAProxy when my site load exceeded that which a single web server could
manage.I learned about heartbeat when I had to update my HAProxy and it
knocked the site offline.I</p><p>5 0.95871323 <a title="151-lda-5" href="../high_scalability-2008/high_scalability-2008-06-06-Economies_of_Non-Scale.html">340 high scalability-2008-06-06-Economies of Non-Scale</a></p>
<p>Introduction: Scalability forces us to think differently. What worked on a small scale
doesn't always work on a large scale -- and costs are no different. If 90% of
our application is free of contention, and only 10% is spent on a shared
resources, we will need to grow our compute resources by a factor of 100 to
scale by a factor of 10! Another important thing to note is that 10x, in this
case, is the limit of our ability to scale, even if more resources are
added.1. The cost of non-linearly scalable applications grows exponentially
with the demand for more scale.2. Non-linearly scalable applications have an
absolute limit of scalability. According to Amdhal's Law, with 10% contention,
the maximum scaling limit is 10. With 40% contention, our maximum scaling
limit is 2.5 - no matter how many hardware resources we will throw at the
problem.This post discuss in further details how to measure the true cost of
non linearly scalable systems and suggest a model for reducing that cost
significantly.</p><p>6 0.95809305 <a title="151-lda-6" href="../high_scalability-2013/high_scalability-2013-02-06-Super_Bowl_Advertisers_Ready_for_the_Traffic%3F_Nope..It%27s_Lights_Out..html">1401 high scalability-2013-02-06-Super Bowl Advertisers Ready for the Traffic? Nope..It's Lights Out.</a></p>
<p>7 0.95528787 <a title="151-lda-7" href="../high_scalability-2008/high_scalability-2008-03-12-YouTube_Architecture.html">274 high scalability-2008-03-12-YouTube Architecture</a></p>
<p>8 0.95478362 <a title="151-lda-8" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>9 0.95464873 <a title="151-lda-9" href="../high_scalability-2009/high_scalability-2009-08-05-Stack_Overflow_Architecture.html">671 high scalability-2009-08-05-Stack Overflow Architecture</a></p>
<p>10 0.95456958 <a title="151-lda-10" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>11 0.95456034 <a title="151-lda-11" href="../high_scalability-2011/high_scalability-2011-09-19-Big_Iron_Returns_with_BigMemory.html">1118 high scalability-2011-09-19-Big Iron Returns with BigMemory</a></p>
<p>12 0.9543196 <a title="151-lda-12" href="../high_scalability-2013/high_scalability-2013-09-04-Wide_Fast_SATA%3A_the_Recipe_for_Hot_Performance.html">1511 high scalability-2013-09-04-Wide Fast SATA: the Recipe for Hot Performance</a></p>
<p>13 0.95425993 <a title="151-lda-13" href="../high_scalability-2011/high_scalability-2011-03-22-Facebook%27s_New_Realtime_Analytics_System%3A_HBase_to_Process_20_Billion_Events_Per_Day.html">1008 high scalability-2011-03-22-Facebook's New Realtime Analytics System: HBase to Process 20 Billion Events Per Day</a></p>
<p>14 0.95407796 <a title="151-lda-14" href="../high_scalability-2013/high_scalability-2013-06-05-A_Simple_6_Step_Transition_Guide_for_Moving_Away_from_X_to_AWS_.html">1470 high scalability-2013-06-05-A Simple 6 Step Transition Guide for Moving Away from X to AWS </a></p>
<p>15 0.95387262 <a title="151-lda-15" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>16 0.9535324 <a title="151-lda-16" href="../high_scalability-2013/high_scalability-2013-04-23-Facebook_Secrets_of_Web_Performance.html">1444 high scalability-2013-04-23-Facebook Secrets of Web Performance</a></p>
<p>17 0.95339912 <a title="151-lda-17" href="../high_scalability-2007/high_scalability-2007-11-19-Tailrank_Architecture_-_Learn_How_to_Track_Memes_Across_the_Entire_Blogosphere.html">160 high scalability-2007-11-19-Tailrank Architecture - Learn How to Track Memes Across the Entire Blogosphere</a></p>
<p>18 0.95323312 <a title="151-lda-18" href="../high_scalability-2012/high_scalability-2012-01-19-Is_it_time_to_get_rid_of_the_Linux_OS_model_in_the_cloud%3F.html">1177 high scalability-2012-01-19-Is it time to get rid of the Linux OS model in the cloud?</a></p>
<p>19 0.95275784 <a title="151-lda-19" href="../high_scalability-2013/high_scalability-2013-09-18-If_You%27re_Programming_a_Cell_Phone_Like_a_Server_You%27re_Doing_it_Wrong.html">1519 high scalability-2013-09-18-If You're Programming a Cell Phone Like a Server You're Doing it Wrong</a></p>
<p>20 0.95204407 <a title="151-lda-20" href="../high_scalability-2011/high_scalability-2011-07-07-Myth%3A_Google_Uses_Server_Farms_So_You_Should_Too_-_Resurrection_of_the_Big-Ass_Machines.html">1075 high scalability-2011-07-07-Myth: Google Uses Server Farms So You Should Too - Resurrection of the Big-Ass Machines</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
