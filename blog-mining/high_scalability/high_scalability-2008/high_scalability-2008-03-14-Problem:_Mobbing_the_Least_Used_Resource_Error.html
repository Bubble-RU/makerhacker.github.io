<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>275 high scalability-2008-03-14-Problem: Mobbing the Least Used Resource Error</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2008" href="../home/high_scalability-2008_home.html">high_scalability-2008</a> <a title="high_scalability-2008-275" href="#">high_scalability-2008-275</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>275 high scalability-2008-03-14-Problem: Mobbing the Least Used Resource Error</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2008-275-html" href="http://highscalability.com//blog/2008/3/14/problem-mobbing-the-least-used-resource-error.html">html</a></p><p>Introduction: A thoughtful reader recently suggested creating a series of posts based on
real-life problems people have experienced and the solutions they've created
to slay the little beasties. It's a great idea. Often we learn best from great
trials and tribulations. I'll start off the new "Problem Report"feature with a
diabolical little problem I dubbed the "Mobbing the Least Used Resource
Error." Please post your own. And if you know someone with an interesting
problem report, please tag them too. It could be a lot of fun. Of course, feel
free to scrub your posts of all embarrassing details, but be sure to keep the
heroic parts in :-)The ProblemThere's an unexpected and frequently fatal type
of error that can happen when new resources are added to a horizontally scaled
architecture. Because the new resource has the least of something, load or
connections or whatever, a load balancer configured with a least metric will
instantaneously direct all new traffic to that new resource. And bam! Your
sys</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A thoughtful reader recently suggested creating a series of posts based on real-life problems people have experienced and the solutions they've created to slay the little beasties. [sent-1, score-0.189]
</p><p>2 Often we learn best from great trials and tribulations. [sent-3, score-0.112]
</p><p>3 I'll start off the new "Problem Report"feature with a diabolical little problem I dubbed the "Mobbing the Least Used Resource Error. [sent-4, score-0.391]
</p><p>4 And if you know someone with an interesting problem report, please tag them too. [sent-6, score-0.132]
</p><p>5 Of course, feel free to scrub your posts of all embarrassing details, but be sure to keep the heroic parts in :-)The ProblemThere's an unexpected and frequently fatal type of error that can happen when new resources are added to a horizontally scaled architecture. [sent-8, score-0.774]
</p><p>6 Because the new resource has the least of something, load or connections or whatever, a load balancer configured with a least metric will instantaneously direct all new traffic to that new resource. [sent-9, score-1.442]
</p><p>7 All the traffic that was meant to be spread across your entire cluster is now directed like a laser beam to one small part of it. [sent-12, score-0.294]
</p><p>8 Everyone is screaming for more storage space so you bring up a new filer. [sent-14, score-0.463]
</p><p>9 All new data streams flow to the new filer and it crumbles and crawls because it can't handle the load for the entire system. [sent-15, score-0.719]
</p><p>10 It's in the very act of turning up more storage you bring your system down. [sent-16, score-0.191]
</p><p>11 Your load balancer redirects traffic to the new slaves, but the slaves are trying to sync, yet they can't sink because they are getting hammered by the new traffic. [sent-19, score-1.179]
</p><p>12 Unless your system is very flexible you can't scale anymore by adding resources because you can't repartition the data. [sent-24, score-0.205]
</p><p>13 If you want a different organization you would have to redistribute data across all the clusters. [sent-26, score-0.112]
</p><p>14 The SolutionThe solution depends of course on the resource in question. [sent-28, score-0.191]
</p><p>15 Butting knowing a potential problem is present gives you the heads up you need to avoid destruction. [sent-29, score-0.229]
</p><p>16 For filers migrate storage from existing filers to the new filers so storage is evened out. [sent-30, score-1.404]
</p><p>17 Then new storage will be allocated evenly across all the filers. [sent-31, score-0.336]
</p><p>18 Consistent Hashingto assign resources to a pool of servers in a scalable fashion. [sent-34, score-0.207]
</p><p>19 For servers use random or round-robin balancing when the load balancer can receive incorrect feedback from pool servers. [sent-35, score-0.476]
</p><p>20 TheThundering Herd Problemis supposedly the same problem described here, but it doesn't seem the same to me. [sent-36, score-0.249]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('filers', 0.351), ('slaves', 0.198), ('balancer', 0.178), ('new', 0.147), ('problem', 0.132), ('ca', 0.13), ('breaklet', 0.125), ('bam', 0.125), ('problemthere', 0.125), ('screaming', 0.125), ('least', 0.12), ('problemis', 0.117), ('supposedly', 0.117), ('report', 0.116), ('filer', 0.112), ('trials', 0.112), ('dubbed', 0.112), ('redistribute', 0.112), ('scrub', 0.112), ('posts', 0.108), ('handle', 0.108), ('resource', 0.108), ('fatal', 0.108), ('sink', 0.108), ('pool', 0.106), ('repartition', 0.104), ('herd', 0.104), ('crawls', 0.104), ('cruel', 0.104), ('hammered', 0.104), ('hates', 0.104), ('redirects', 0.104), ('storage', 0.102), ('beam', 0.101), ('instantaneously', 0.101), ('laser', 0.101), ('load', 0.101), ('resources', 0.101), ('heroic', 0.099), ('embarrassing', 0.099), ('heads', 0.097), ('indicating', 0.095), ('traffic', 0.092), ('incorrect', 0.091), ('bring', 0.089), ('evenly', 0.087), ('course', 0.083), ('alive', 0.081), ('suggested', 0.081), ('metric', 0.08)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999976 <a title="275-tfidf-1" href="../high_scalability-2008/high_scalability-2008-03-14-Problem%3A_Mobbing_the_Least_Used_Resource_Error.html">275 high scalability-2008-03-14-Problem: Mobbing the Least Used Resource Error</a></p>
<p>Introduction: A thoughtful reader recently suggested creating a series of posts based on
real-life problems people have experienced and the solutions they've created
to slay the little beasties. It's a great idea. Often we learn best from great
trials and tribulations. I'll start off the new "Problem Report"feature with a
diabolical little problem I dubbed the "Mobbing the Least Used Resource
Error." Please post your own. And if you know someone with an interesting
problem report, please tag them too. It could be a lot of fun. Of course, feel
free to scrub your posts of all embarrassing details, but be sure to keep the
heroic parts in :-)The ProblemThere's an unexpected and frequently fatal type
of error that can happen when new resources are added to a horizontally scaled
architecture. Because the new resource has the least of something, load or
connections or whatever, a load balancer configured with a least metric will
instantaneously direct all new traffic to that new resource. And bam! Your
sys</p><p>2 0.12184534 <a title="275-tfidf-2" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>Introduction: For everything given something seems to be taken. Caching is a great
scalability solution, but caching alsocomes with problems.Shardingis a great
scalability solution, but as Foursquare recently revealed in apost-mortemabout
their 17 hours of downtime, sharding also has problems. MongoDB, the database
Foursquare uses, also contributed theirpost-mortemof what went wrong too.Now
that everyone has shared and resharded, what can we learn to help us skip
these mistakes and quickly move on to a different set of mistakes?First, like
forFacebook, huge props to Foursquare and MongoDB for being upfront and honest
about their problems. This helps everyone get better and is a sign we work in
a pretty cool industry.Second, overall, the fault didn't flow from evil hearts
or gross negligence. As usual the cause was more mundane: a key system, that
could be a little more robust, combined with a very popular application built
by a small group of people, under immense pressure, trying to get a lot of
wo</p><p>3 0.12030613 <a title="275-tfidf-3" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>Introduction: Pinterest has been riding an exponential growth curve, doubling every month
and half. They've gone from 0 to 10s of billions of page views a month in two
years, from 2 founders and one engineer to over 40 engineers, from one little
MySQL server to 180 Web Engines, 240 API Engines, 88 MySQL DBs (cc2.8xlarge) +
1 slave each, 110 Redis Instances, and 200 Memcache Instances.Stunning growth.
So what's Pinterest's story? To tell their story we have our bards,
Pinterest'sYashwanth NelapatiandMarty Weiner, who tell the dramatic story of
Pinterest's architecture evolution in a talk titledScaling Pinterest. This is
the talk they would have liked to hear a year and half ago when they were
scaling fast and there were a lot of options to choose from. And they made a
lot of incorrect choices.This is a great talk. It's full of amazing details.
It's also very practical, down to earth, and it contains strategies adoptable
by nearly anyone. Highly recommended.Two of my favorite lessons from the
talk:Arc</p><p>4 0.11266242 <a title="275-tfidf-4" href="../high_scalability-2011/high_scalability-2011-12-12-Netflix%3A_Developing%2C_Deploying%2C_and_Supporting_Software_According_to_the_Way_of_the_Cloud.html">1155 high scalability-2011-12-12-Netflix: Developing, Deploying, and Supporting Software According to the Way of the Cloud</a></p>
<p>Introduction: At a Cloud Computing Meetup, Siddharth "Sid" Anand of Netflix, backed by a
merry band of Netflixians, gave an interesting talk:Keeping Movies Running
Amid Thunderstorms. While the talk gave a good overview of their move to the
cloud, issues with capacity planning,thundering herds, latency problems,
andsimian armageddon, I found myself most taken with how they handlesoftware
deployment in the cloud.I've worked on half a dozen or more build and
deployment systems, some small, some quite large, but never for a large
organization like Netflix in the cloud. The cloud has this amazing capability
that has never existed before that enables a novel approach to fault-tolerant
software deployments:the ability to spin up huge numbers of instances to
completely run a new release while running the old release at the same
time.The process goes something like: Acanary machineis launched first with
the new software load running real traffic to sanity test the load in a
production environment. If the ca</p><p>5 0.11034157 <a title="275-tfidf-5" href="../high_scalability-2010/high_scalability-2010-01-17-Applications_Become_Black_Boxes_Using_Markets_to_Scale_and_Control_Costs.html">761 high scalability-2010-01-17-Applications Become Black Boxes Using Markets to Scale and Control Costs</a></p>
<p>Introduction: This is an excerpt from my articleBuilding Super Scalable Systems: Blade
Runner Meets Autonomic Computing in the Ambient Cloud.We tend to think compute
of resources as residing primarily in datacenters. Given the fast pace of
innovation we will likely see compute resources become pervasive. Some will
reside in datacenters, but compute resources can be anywhere, not just in the
datacenter, we'll actually see the bulk of compute resources live outside of
datacenters in the future.Given the diversity of compute resources it's
reasonable to assume they won't be homogeneous or conform to a standard API.
They will specialize by service. Programmers will have to use those
specialized service interfaces to build applications that are adaptive enough
to take advantage of whatever leverage they can find, whenever and wherever
they can find it. Once found the application will have to reorganize on the
fly to use whatever new resources it has found and let go of whatever
resources it doesn't have</p><p>6 0.10786953 <a title="275-tfidf-6" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>7 0.10784862 <a title="275-tfidf-7" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>8 0.10749171 <a title="275-tfidf-8" href="../high_scalability-2013/high_scalability-2013-08-13-In_Memoriam%3A_Lavabit_Architecture_-_Creating_a_Scalable_Email_Service.html">1501 high scalability-2013-08-13-In Memoriam: Lavabit Architecture - Creating a Scalable Email Service</a></p>
<p>9 0.10405953 <a title="275-tfidf-9" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>10 0.1039672 <a title="275-tfidf-10" href="../high_scalability-2007/high_scalability-2007-08-09-Lots_of_questions_for_high_scalability_-_high_availability.html">63 high scalability-2007-08-09-Lots of questions for high scalability - high availability</a></p>
<p>11 0.10072256 <a title="275-tfidf-11" href="../high_scalability-2012/high_scalability-2012-11-15-Gone_Fishin%27%3A_Justin.Tv%27s_Live_Video_Broadcasting_Architecture.html">1359 high scalability-2012-11-15-Gone Fishin': Justin.Tv's Live Video Broadcasting Architecture</a></p>
<p>12 0.099445239 <a title="275-tfidf-12" href="../high_scalability-2010/high_scalability-2010-03-16-Justin.tv%27s_Live_Video_Broadcasting_Architecture.html">796 high scalability-2010-03-16-Justin.tv's Live Video Broadcasting Architecture</a></p>
<p>13 0.098724313 <a title="275-tfidf-13" href="../high_scalability-2010/high_scalability-2010-09-22-Applying_Scalability_Patterns_to_Infrastructure_Architecture.html">906 high scalability-2010-09-22-Applying Scalability Patterns to Infrastructure Architecture</a></p>
<p>14 0.095009625 <a title="275-tfidf-14" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>15 0.094564289 <a title="275-tfidf-15" href="../high_scalability-2007/high_scalability-2007-11-13-Flickr_Architecture.html">152 high scalability-2007-11-13-Flickr Architecture</a></p>
<p>16 0.093270719 <a title="275-tfidf-16" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>17 0.091796987 <a title="275-tfidf-17" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>18 0.09104529 <a title="275-tfidf-18" href="../high_scalability-2007/high_scalability-2007-08-20-TypePad_Architecture.html">68 high scalability-2007-08-20-TypePad Architecture</a></p>
<p>19 0.090243936 <a title="275-tfidf-19" href="../high_scalability-2007/high_scalability-2007-11-16-Product%3A_lbpool_-_Load_Balancing_JDBC_Pool.html">157 high scalability-2007-11-16-Product: lbpool - Load Balancing JDBC Pool</a></p>
<p>20 0.088107646 <a title="275-tfidf-20" href="../high_scalability-2007/high_scalability-2007-07-10-mixi.jp__Architecture.html">5 high scalability-2007-07-10-mixi.jp  Architecture</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.182), (1, 0.084), (2, -0.003), (3, -0.067), (4, -0.015), (5, -0.048), (6, 0.024), (7, -0.01), (8, -0.02), (9, -0.036), (10, -0.024), (11, 0.032), (12, -0.007), (13, 0.004), (14, 0.052), (15, 0.016), (16, 0.048), (17, 0.001), (18, -0.034), (19, 0.06), (20, -0.014), (21, 0.028), (22, -0.014), (23, -0.037), (24, -0.011), (25, -0.024), (26, 0.026), (27, 0.065), (28, -0.022), (29, 0.014), (30, 0.036), (31, -0.028), (32, 0.01), (33, 0.045), (34, -0.02), (35, -0.016), (36, -0.008), (37, -0.025), (38, 0.017), (39, -0.007), (40, -0.012), (41, -0.008), (42, 0.028), (43, 0.031), (44, -0.032), (45, 0.058), (46, 0.002), (47, 0.002), (48, 0.025), (49, -0.032)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97630489 <a title="275-lsi-1" href="../high_scalability-2008/high_scalability-2008-03-14-Problem%3A_Mobbing_the_Least_Used_Resource_Error.html">275 high scalability-2008-03-14-Problem: Mobbing the Least Used Resource Error</a></p>
<p>Introduction: A thoughtful reader recently suggested creating a series of posts based on
real-life problems people have experienced and the solutions they've created
to slay the little beasties. It's a great idea. Often we learn best from great
trials and tribulations. I'll start off the new "Problem Report"feature with a
diabolical little problem I dubbed the "Mobbing the Least Used Resource
Error." Please post your own. And if you know someone with an interesting
problem report, please tag them too. It could be a lot of fun. Of course, feel
free to scrub your posts of all embarrassing details, but be sure to keep the
heroic parts in :-)The ProblemThere's an unexpected and frequently fatal type
of error that can happen when new resources are added to a horizontally scaled
architecture. Because the new resource has the least of something, load or
connections or whatever, a load balancer configured with a least metric will
instantaneously direct all new traffic to that new resource. And bam! Your
sys</p><p>2 0.83792901 <a title="275-lsi-2" href="../high_scalability-2007/high_scalability-2007-08-29-Skype_Failed_the_Boot_Scalability_Test%3A_Is_P2P_fundamentally_flawed%3F.html">76 high scalability-2007-08-29-Skype Failed the Boot Scalability Test: Is P2P fundamentally flawed?</a></p>
<p>Introduction: Skype's 220 millions users lost service for a stunning two days. The primary
cause for Skype's nightmare (can you imagine the beeper storm that went off?)
was a massive global roll-out of aWindow's patchtriggering the simultaneous
reboot of millions of machines across the globe. The secondary cause was a bug
in Skype's software that prevented "self-healing" in the face of such attacks.
The flood of log-in requests and a lack of "peer-to-peer resources" melted
their system.breakWho's fault is it? Is Skype to blame? Is Microsoft to blame?
Or is the peer-to-peer model itself fundamentally flawed in some way?Let's be
real, how could Skype possibly test booting 220 million servers over a random
configuration of resources? Answer: they can't. Yes, it's Skype's
responsibility, but they are in a bit of a pickle on this one.The boot
scenario is one of the most basic and one of the most difficult scalability
scenarios to plan for and test. You can't simulate the viciousness of real-
life conditi</p><p>3 0.80053866 <a title="275-lsi-3" href="../high_scalability-2009/high_scalability-2009-03-11-The_Implications_of_Punctuated_Scalabilium_for_Website_Architecture.html">533 high scalability-2009-03-11-The Implications of Punctuated Scalabilium for Website Architecture</a></p>
<p>Introduction: Update:How do you design and handle peak load on the Cloud?by Cloudiquity.
Gives a formula to try and predict and plan for peak load and talks about how
GigaSpaces XAP, Scalr, RightScale and FreedomOSS can be used to handle peak
load within EC2.Theo Schlossnagle, with his usual insight, talks about
inDissecting today's surgeshow the nature of internet traffic has evolved over
time. Traffic now spikes like a heart attack, larger and more quickly than
ever from traffic inflow sources like Digg and The New York Times. Theo
relates howAt least eight times in the past month, we've experienced from 100%
to 1000% sudden increases in traffic across many of our clientsand those spike
can happen as quickly as 60 seconds. To me this sounds a lot likePunctuated
equilibriumin evolution, a force that accounts for much creative growth in
species...breakVMs don't spin up in less than 60 seconds so your ability to
respond to such massive quick spikes is limited. This assumes of course that
you've creat</p><p>4 0.78813493 <a title="275-lsi-4" href="../high_scalability-2007/high_scalability-2007-12-13-Is_premature_scalation_a_real_disease%3F.html">185 high scalability-2007-12-13-Is premature scalation a real disease?</a></p>
<p>Introduction: Update 3: InfoQ'sBig Architecture Up Front - A Case of Premature
Scalaculation?twines several different threads on the topic together into a
fine noose.Update 2: Kevin says thebiggest problems he sees with startups is
they need to scaletheir backend (no, the other one).Update: My bad.It's hard
to sell scalabilityso just forget it.The premise ofStartups and The Problem Of
Premature ScalaculationandDonâ&euro;&trade;t scale: 99.999% uptime is for Wal-Martis that
you shouldn't spend precious limited resources worrying about scaling before
you've first implemented the functionality that will make you successful
enough to have scaling problems in the first place. It's kind of an embodied
life force model of system creation. Energy is scarce so any parasites
siphoning off energy must be hunted down and destroyed so the body has its
best chance of survival. Is this really how it works?If I ever believed this I
certainly don't believe it anymore. The world has changed, even since
2005.Thanks to many books a</p><p>5 0.78240293 <a title="275-lsi-5" href="../high_scalability-2009/high_scalability-2009-08-31-Squarespace_Architecture_-_A_Grid_Handles_Hundreds_of_Millions_of_Requests_a_Month_.html">691 high scalability-2009-08-31-Squarespace Architecture - A Grid Handles Hundreds of Millions of Requests a Month </a></p>
<p>Introduction: I first heard an enthusiastic endorsement ofSquarespacestreaming from the
ubiquitousLeo Laporteon one of his many Twit Live shows. Squarespace as afully
hosted, completely managed environment for creating and maintaining a website,
blog or portfoliowas of interest to me because they promise scalability and
this site doesn't have enough of that. But sadly, since they don't offer a
link preserving Drupal import our relationship was not meant to be.When a fine
reader of High Scalability, Brian Egge, (and all my readers are thrifty,
brave, and strong) asked me how Squarespace scaled I said I didn't know, but I
would try and find out. I emailed Squarespace a few questions and founder
Anthony Casalena and Director of Technical Operations Rolando Berrios were
kind enough to reply in some detail. The questions were both from Brian and
myself. Answers can be found below.Two things struck me most about
Squarespace's approach:They based their system on a memory grid, in this case
Oracle Coherence</p><p>6 0.76921266 <a title="275-lsi-6" href="../high_scalability-2014/high_scalability-2014-03-31-How_WhatsApp_Grew_to_Nearly_500_Million_Users%2C_11%2C000_cores%2C_and_70_Million_Messages_a_Second.html">1622 high scalability-2014-03-31-How WhatsApp Grew to Nearly 500 Million Users, 11,000 cores, and 70 Million Messages a Second</a></p>
<p>7 0.76774919 <a title="275-lsi-7" href="../high_scalability-2014/high_scalability-2014-03-17-Intuitively_Showing_How_To_Scale_a_Web_Application_Using_a_Coffee_Shop_as_an_Example.html">1613 high scalability-2014-03-17-Intuitively Showing How To Scale a Web Application Using a Coffee Shop as an Example</a></p>
<p>8 0.76394367 <a title="275-lsi-8" href="../high_scalability-2009/high_scalability-2009-06-29-How_to_Succeed_at_Capacity_Planning_Without_Really_Trying_%3A__An_Interview_with_Flickr%27s_John_Allspaw_on_His_New_Book.html">643 high scalability-2009-06-29-How to Succeed at Capacity Planning Without Really Trying :  An Interview with Flickr's John Allspaw on His New Book</a></p>
<p>9 0.76119077 <a title="275-lsi-9" href="../high_scalability-2012/high_scalability-2012-07-12-4_Strategies_for_Punching_Down_Traffic_Spikes.html">1282 high scalability-2012-07-12-4 Strategies for Punching Down Traffic Spikes</a></p>
<p>10 0.75652295 <a title="275-lsi-10" href="../high_scalability-2010/high_scalability-2010-03-04-How_MySpace_Tested_Their_Live_Site_with_1_Million_Concurrent_Users.html">788 high scalability-2010-03-04-How MySpace Tested Their Live Site with 1 Million Concurrent Users</a></p>
<p>11 0.75587314 <a title="275-lsi-11" href="../high_scalability-2008/high_scalability-2008-02-16-S3_Failed_Because_of_Authentication_Overload.html">249 high scalability-2008-02-16-S3 Failed Because of Authentication Overload</a></p>
<p>12 0.75018555 <a title="275-lsi-12" href="../high_scalability-2011/high_scalability-2011-07-11-ATMCash_Exploits_Virtualization_for_Security_-_Immutability_and_Reversion.html">1077 high scalability-2011-07-11-ATMCash Exploits Virtualization for Security - Immutability and Reversion</a></p>
<p>13 0.73921651 <a title="275-lsi-13" href="../high_scalability-2007/high_scalability-2007-10-24-Scaling_Operations_Saves_Money_and_Scales_Faster.html">130 high scalability-2007-10-24-Scaling Operations Saves Money and Scales Faster</a></p>
<p>14 0.73870218 <a title="275-lsi-14" href="../high_scalability-2011/high_scalability-2011-02-08-Mollom_Architecture_-_Killing_Over_373_Million_Spams_at_100_Requests_Per_Second.html">985 high scalability-2011-02-08-Mollom Architecture - Killing Over 373 Million Spams at 100 Requests Per Second</a></p>
<p>15 0.73553854 <a title="275-lsi-15" href="../high_scalability-2013/high_scalability-2013-03-11-Low_Level_Scalability_Solutions_-_The_Conditioning_Collection.html">1421 high scalability-2013-03-11-Low Level Scalability Solutions - The Conditioning Collection</a></p>
<p>16 0.73498082 <a title="275-lsi-16" href="../high_scalability-2008/high_scalability-2008-06-09-FaceStat%27s_Rousing_Tale_of_Scaling_Woe_and_Wisdom_Won.html">344 high scalability-2008-06-09-FaceStat's Rousing Tale of Scaling Woe and Wisdom Won</a></p>
<p>17 0.73471487 <a title="275-lsi-17" href="../high_scalability-2012/high_scalability-2012-06-07-Case_Study_on_Scaling_PaaS_infrastructure_.html">1260 high scalability-2012-06-07-Case Study on Scaling PaaS infrastructure </a></p>
<p>18 0.73169065 <a title="275-lsi-18" href="../high_scalability-2013/high_scalability-2013-12-18-How_to_get_started_with_sizing_and_capacity_planning%2C_assuming_you_don%27t_know_the_software_behavior%3F.html">1566 high scalability-2013-12-18-How to get started with sizing and capacity planning, assuming you don't know the software behavior?</a></p>
<p>19 0.72972429 <a title="275-lsi-19" href="../high_scalability-2013/high_scalability-2013-08-13-In_Memoriam%3A_Lavabit_Architecture_-_Creating_a_Scalable_Email_Service.html">1501 high scalability-2013-08-13-In Memoriam: Lavabit Architecture - Creating a Scalable Email Service</a></p>
<p>20 0.72888738 <a title="275-lsi-20" href="../high_scalability-2013/high_scalability-2013-04-10-Check_Yourself_Before_You_Wreck_Yourself_-_Avocado%27s_5_Early_Stages_of_Architecture_Evolution.html">1438 high scalability-2013-04-10-Check Yourself Before You Wreck Yourself - Avocado's 5 Early Stages of Architecture Evolution</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.106), (2, 0.232), (10, 0.081), (61, 0.033), (77, 0.012), (79, 0.155), (80, 0.258), (85, 0.01), (94, 0.029)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9259541 <a title="275-lda-1" href="../high_scalability-2011/high_scalability-2011-03-28-Aztec_Empire_Strategy%3A_Use_Dual_Pipes_in_Your_Aqueduct_for_High_Availability.html">1012 high scalability-2011-03-28-Aztec Empire Strategy: Use Dual Pipes in Your Aqueduct for High Availability</a></p>
<p>Introduction: With the Chapultepec aqueduct, also namedthe great aqueduct, theAztecsbuilt a
novel uninterruptible water supply for providing fresh water to Tenochtitlan,
their fast growing jewel of a capital city. A section of the aqueduct is still
around today: It's fun to think about how even 600 years ago how it was built
with high availability in mind. We findengineers being engineers, no matter
the age:It consisted of a twin pipe distribution system made in part of
compacted soil and in part of wood for the crossings of the aqueduct over the
bridges built to allow the passage of the canoes. It was finished around 1466
AD, and the main purpose was to supply fresh water to Mexico-Tenochtitlan, to
mitigate its thirst.The main source for the aqueduct was the spring of
Chapultepec and the purpose of the twin pipes was to ease the maintenance of
the system, because the water was conveyed through one pipe, and when it got
dirty, the water was diverted to the other pipe while the dirty pipe was
cleaned</p><p>same-blog 2 0.88493794 <a title="275-lda-2" href="../high_scalability-2008/high_scalability-2008-03-14-Problem%3A_Mobbing_the_Least_Used_Resource_Error.html">275 high scalability-2008-03-14-Problem: Mobbing the Least Used Resource Error</a></p>
<p>Introduction: A thoughtful reader recently suggested creating a series of posts based on
real-life problems people have experienced and the solutions they've created
to slay the little beasties. It's a great idea. Often we learn best from great
trials and tribulations. I'll start off the new "Problem Report"feature with a
diabolical little problem I dubbed the "Mobbing the Least Used Resource
Error." Please post your own. And if you know someone with an interesting
problem report, please tag them too. It could be a lot of fun. Of course, feel
free to scrub your posts of all embarrassing details, but be sure to keep the
heroic parts in :-)The ProblemThere's an unexpected and frequently fatal type
of error that can happen when new resources are added to a horizontally scaled
architecture. Because the new resource has the least of something, load or
connections or whatever, a load balancer configured with a least metric will
instantaneously direct all new traffic to that new resource. And bam! Your
sys</p><p>3 0.86582482 <a title="275-lda-3" href="../high_scalability-2012/high_scalability-2012-06-29-Stuff_The_Internet_Says_On_Scalability_For_June_29%2C_2012_-_The_Velocity_Edition.html">1274 high scalability-2012-06-29-Stuff The Internet Says On Scalability For June 29, 2012 - The Velocity Edition</a></p>
<p>Introduction: Judging from the tweet flow, Velocitylooked like a riotous good time. In this
video on themain themes at Velocity, after a little microphone enhanced
violence, John Allspaw and Steve Souders identifyresilienceandautomationas two
of the big ideas behind building a faster and stronger web.John says
resiliency is the idea that we we don't live in a perfect world so trying to
build perfect systems is counter productive. We have to accept failure as a
baseline and think in terms of degrees of availability. All abstraction layers
leak so every part of a system must be monitorable and open to introspection.A
focus on resilience means the web is growing up. Resilience has long been a
requirement for "real" systems, it's great to see the web thinking in terms of
the complex systems they've always been. For the Alpha and Omega on resilience
you'll want to watchDr. Richard Cook'sinspiring talk on How Complex Systems
Fail. Here are some of the most enjoyable Quotable Quotes from
Velocity:@guypod:</p><p>4 0.83208072 <a title="275-lda-4" href="../high_scalability-2012/high_scalability-2012-01-06-Stuff_The_Internet_Says_On_Scalability_For_January_6%2C_2012.html">1170 high scalability-2012-01-06-Stuff The Internet Says On Scalability For January 6, 2012</a></p>
<p>Introduction: OMG, it's 2012:Harry Bombarda Twilight;200 Million: Chinese online shoppers;
Quantum 150 qubit computer: all the power of today's supercomputers;  Sperm:
two aspirins worth could repopulate the world;1 Billion: the number of iOS and
Android apps downloaded in a week;Watson: 250 Servers, 2,880 cores, 10 racks,
16 Terabytes RAM, 80 TeraďŹ&sbquo;ops; Reddit:2 Billion PageviewsQuotable
Quotes:Robert Martin: The hallmark of a really good architecture is that it
allows major decisions to be deferred. Building Memory-efficient Java
Applications: Practices and Challenges : More abstractions = less awareness of
costs.Ian Muir: When we do something that Microsoft did not anticipate, it's
nothing but pain.@kekline: Want to know a secret - NoSQL's rapid growth is
really about NoNormalizationJeremy Zawodny: The fact that I can look back on
code I wrote a few years ago and identify ways that I'd do it better is good.
It means I'm still learning. But the fact that I can successfully resist the
urge to change</p><p>5 0.80489594 <a title="275-lda-5" href="../high_scalability-2008/high_scalability-2008-01-10-MONO_ASP.NET._Will_it_make_the_web%3F%3F%3F.html">206 high scalability-2008-01-10-MONO ASP.NET. Will it make the web???</a></p>
<p>Introduction: I was wondering if it is already possible to scale a MONO's .NET website. I
cannot see any real websites (with the term real I mean "a highly visited
website") running mono. What do you think?Will MONO ASP.NET scale???Is it
worth planning a site to run with Mono asp.net? Or should we leave it to the
future?What do you think?</p><p>6 0.79771388 <a title="275-lda-6" href="../high_scalability-2011/high_scalability-2011-04-22-Stuff_The_Internet_Says_On_Scalability_For_April_22%2C_2011.html">1028 high scalability-2011-04-22-Stuff The Internet Says On Scalability For April 22, 2011</a></p>
<p>7 0.78448147 <a title="275-lda-7" href="../high_scalability-2010/high_scalability-2010-07-02-Hot_Scalability_Links_for_July_2%2C_2010.html">851 high scalability-2010-07-02-Hot Scalability Links for July 2, 2010</a></p>
<p>8 0.7835955 <a title="275-lda-8" href="../high_scalability-2012/high_scalability-2012-12-03-Resiliency_is_the_New_Normal_-_A_Deep_Look_at_What_It_Means_and_How_to_Build_It.html">1366 high scalability-2012-12-03-Resiliency is the New Normal - A Deep Look at What It Means and How to Build It</a></p>
<p>9 0.77959645 <a title="275-lda-9" href="../high_scalability-2011/high_scalability-2011-08-26-Stuff_The_Internet_Says_On_Scalability_For_August_26%2C_2011.html">1106 high scalability-2011-08-26-Stuff The Internet Says On Scalability For August 26, 2011</a></p>
<p>10 0.76456016 <a title="275-lda-10" href="../high_scalability-2009/high_scalability-2009-03-17-IBM_WebSphere_eXtreme_Scale_%28IMDG%29.html">542 high scalability-2009-03-17-IBM WebSphere eXtreme Scale (IMDG)</a></p>
<p>11 0.75720721 <a title="275-lda-11" href="../high_scalability-2011/high_scalability-2011-12-19-How_Twitter_Stores_250_Million_Tweets_a_Day_Using_MySQL.html">1159 high scalability-2011-12-19-How Twitter Stores 250 Million Tweets a Day Using MySQL</a></p>
<p>12 0.75631362 <a title="275-lda-12" href="../high_scalability-2012/high_scalability-2012-04-02-YouPorn_-_Targeting_200_Million_Views_a_Day_and_Beyond.html">1220 high scalability-2012-04-02-YouPorn - Targeting 200 Million Views a Day and Beyond</a></p>
<p>13 0.75616485 <a title="275-lda-13" href="../high_scalability-2014/high_scalability-2014-02-03-How_Google_Backs_Up_the_Internet_Along_With_Exabytes_of_Other_Data.html">1589 high scalability-2014-02-03-How Google Backs Up the Internet Along With Exabytes of Other Data</a></p>
<p>14 0.75412285 <a title="275-lda-14" href="../high_scalability-2013/high_scalability-2013-11-08-Stuff_The_Internet_Says_On_Scalability_For_November_8th%2C_2013.html">1545 high scalability-2013-11-08-Stuff The Internet Says On Scalability For November 8th, 2013</a></p>
<p>15 0.75389832 <a title="275-lda-15" href="../high_scalability-2009/high_scalability-2009-05-17-Product%3A_Hadoop.html">601 high scalability-2009-05-17-Product: Hadoop</a></p>
<p>16 0.75319159 <a title="275-lda-16" href="../high_scalability-2012/high_scalability-2012-09-04-Changing_Architectures%3A_New_Datacenter_Networks_Will_Set_Your_Code_and_Data_Free___.html">1316 high scalability-2012-09-04-Changing Architectures: New Datacenter Networks Will Set Your Code and Data Free   </a></p>
<p>17 0.75306827 <a title="275-lda-17" href="../high_scalability-2011/high_scalability-2011-04-20-Packet_Pushers%3A_How_to_Build_a_Low_Cost_Data_Center.html">1027 high scalability-2011-04-20-Packet Pushers: How to Build a Low Cost Data Center</a></p>
<p>18 0.7530039 <a title="275-lda-18" href="../high_scalability-2013/high_scalability-2013-07-15-Ask_HS%3A_What%27s_Wrong_with_Twitter%2C_Why_Isn%27t_One_Machine_Enough%3F.html">1491 high scalability-2013-07-15-Ask HS: What's Wrong with Twitter, Why Isn't One Machine Enough?</a></p>
<p>19 0.75234574 <a title="275-lda-19" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>20 0.75194347 <a title="275-lda-20" href="../high_scalability-2008/high_scalability-2008-03-27-Amazon_Announces_Static_IP_Addresses_and_Multiple_Datacenter_Operation.html">289 high scalability-2008-03-27-Amazon Announces Static IP Addresses and Multiple Datacenter Operation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
