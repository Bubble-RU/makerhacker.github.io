<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>396 high scalability-2008-09-26-Lucasfilm: The Real Magic is in the Data Center</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2008" href="../home/high_scalability-2008_home.html">high_scalability-2008</a> <a title="high_scalability-2008-396" href="#">high_scalability-2008-396</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>396 high scalability-2008-09-26-Lucasfilm: The Real Magic is in the Data Center</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2008-396-html" href="http://highscalability.com//blog/2008/9/26/lucasfilm-the-real-magic-is-in-the-data-center.html">html</a></p><p>Introduction: Kevin Clark, director of IT operations for Lucasfilm, discusses how their data
center works:* Linux-based platform, SUSE (looking to change), and a lot of
proprietary open source applications for content creation.* 4,500-processor
render farm in the datacenter. Workstations are used off hours.* Developed
their own proprietary scheduler to schedule their 5,500 available processors.*
Render nodes, the blade racks (from Verari), run dual-core dual Opteron chips
with 32GB of memory on board, but are expanding those to quad-core. Are an AMD
shop.* 400TB of storage online for production.* Every night they write out
10-20TB of new data on a render. A project will use up to a hundred-plus
terabytes of storage.* Incremental backups are a challenge because the data
changes up to 50 percent over a week.* NetApps used for storage. They like the
global namespace in the virtual file system.* Foundry Networks architecture
shop. One of the larger 10-GbE-backbone facilities on the West coast. 350-plus</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Kevin Clark, director of IT operations for Lucasfilm, discusses how their data center works:* Linux-based platform, SUSE (looking to change), and a lot of proprietary open source applications for content creation. [sent-1, score-0.384]
</p><p>2 * Developed their own proprietary scheduler to schedule their 5,500 available processors. [sent-4, score-0.372]
</p><p>3 * Render nodes, the blade racks (from Verari), run dual-core dual Opteron chips with 32GB of memory on board, but are expanding those to quad-core. [sent-5, score-0.595]
</p><p>4 * Every night they write out 10-20TB of new data on a render. [sent-8, score-0.085]
</p><p>5 A project will use up to a hundred-plus terabytes of storage. [sent-9, score-0.081]
</p><p>6 * Incremental backups are a challenge because the data changes up to 50 percent over a week. [sent-10, score-0.303]
</p><p>7 They like the global namespace in the virtual file system. [sent-12, score-0.133]
</p><p>8 One of the larger 10-GbE-backbone facilities on the West coast. [sent-14, score-0.225]
</p><p>9 350-plus 10 GbE ports that used for distribution throughout the facility and the backend. [sent-15, score-0.439]
</p><p>10 * A 10-Gig dark fiber connection connects San Rafael and their home office. [sent-17, score-0.384]
</p><p>11 Enables them to co- render and co-storage between the two facilities. [sent-18, score-0.302]
</p><p>12 No difference in performance in terms of where they went to look for their data and their shots. [sent-19, score-0.071]
</p><p>13 * Artists get server class machines: HP 9400 workstations with dual-core dual Opteron processors and 16GB of memory. [sent-20, score-0.571]
</p><p>14 * Challenge now is to better segment storage to not continue to sink costs into high-cost disks. [sent-21, score-0.345]
</p><p>15 * VMware used to host a lot of development environments. [sent-22, score-0.121]
</p><p>16 Allows the quick turn up of testing as the tests can be allocated across VMs. [sent-23, score-0.098]
</p><p>17 * Provides PoE (power-over-ethernet) out from the switch to all of our Web farms. [sent-24, score-0.07]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('workstations', 0.322), ('render', 0.302), ('opteron', 0.266), ('facilities', 0.225), ('proprietary', 0.191), ('dual', 0.174), ('foundry', 0.161), ('suse', 0.161), ('sink', 0.148), ('clark', 0.148), ('namespace', 0.133), ('artists', 0.133), ('challenge', 0.129), ('amd', 0.125), ('facility', 0.122), ('used', 0.121), ('segment', 0.12), ('board', 0.111), ('racks', 0.11), ('ports', 0.11), ('fiber', 0.109), ('blade', 0.108), ('connects', 0.106), ('expanding', 0.105), ('west', 0.104), ('vmware', 0.104), ('kevin', 0.101), ('discusses', 0.099), ('dark', 0.098), ('scheduler', 0.098), ('hp', 0.098), ('allocated', 0.098), ('chips', 0.098), ('director', 0.094), ('incremental', 0.088), ('percent', 0.087), ('backups', 0.087), ('throughout', 0.086), ('night', 0.085), ('utilization', 0.084), ('schedule', 0.083), ('terabytes', 0.081), ('farm', 0.077), ('continue', 0.077), ('processors', 0.075), ('enables', 0.074), ('difference', 0.071), ('home', 0.071), ('san', 0.071), ('switch', 0.07)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="396-tfidf-1" href="../high_scalability-2008/high_scalability-2008-09-26-Lucasfilm%3A_The_Real_Magic_is_in_the_Data_Center.html">396 high scalability-2008-09-26-Lucasfilm: The Real Magic is in the Data Center</a></p>
<p>Introduction: Kevin Clark, director of IT operations for Lucasfilm, discusses how their data
center works:* Linux-based platform, SUSE (looking to change), and a lot of
proprietary open source applications for content creation.* 4,500-processor
render farm in the datacenter. Workstations are used off hours.* Developed
their own proprietary scheduler to schedule their 5,500 available processors.*
Render nodes, the blade racks (from Verari), run dual-core dual Opteron chips
with 32GB of memory on board, but are expanding those to quad-core. Are an AMD
shop.* 400TB of storage online for production.* Every night they write out
10-20TB of new data on a render. A project will use up to a hundred-plus
terabytes of storage.* Incremental backups are a challenge because the data
changes up to 50 percent over a week.* NetApps used for storage. They like the
global namespace in the virtual file system.* Foundry Networks architecture
shop. One of the larger 10-GbE-backbone facilities on the West coast. 350-plus</p><p>2 0.10053932 <a title="396-tfidf-2" href="../high_scalability-2014/high_scalability-2014-01-28-How_Next_Big_Sound_Tracks_Over_a_Trillion_Song_Plays%2C_Likes%2C_and_More_Using_a_Version_Control_System_for_Hadoop_Data.html">1586 high scalability-2014-01-28-How Next Big Sound Tracks Over a Trillion Song Plays, Likes, and More Using a Version Control System for Hadoop Data</a></p>
<p>Introduction: This is a guest post by Eric Czech, Chief Architect at Next Big Sound, talks
about some unique approaches taken to solving scalability challenges in music
analytics.Tracking online activity is hardly a new idea, but doing it for the
entire music industry isn't easy. Half a billion music video streams, track
downloads, and artist page likes occur each day and measuring all of this
activity across platforms such as Spotify, iTunes, YouTube, Facebook, and
more, poses some interesting scalability challenges. Next Big Sound collects
this type of data from over a hundred sources, standardizes everything, and
offers that information to record labels, band managers, and artists through a
web-based analytics platform.While many of our applications use open-source
systems like Hadoop, HBase, Cassandra, Mongo, RabbitMQ, and MySQL, our usage
is fairly standard, but there is one aspect of what we do that is pretty
unique. We collect or receive information from 100+ sources and we struggled
early on</p><p>3 0.097317711 <a title="396-tfidf-3" href="../high_scalability-2009/high_scalability-2009-05-31-Need_help_on_Site_loading_%26_database_optimization_-_URGENT.html">611 high scalability-2009-05-31-Need help on Site loading & database optimization - URGENT</a></p>
<p>Introduction: Hi Friends,I need some help in making site access fast. On an average my site
has the traffic 2500 hits per day and on 16th May it had 60,000 hits. On this
day site was loading very slow even it was getting time out. I also check out
the processes running by using "top" command it was indicating mysql was
taking too much load.There are around 166 tables (Including PHPBB forum) in my
database. All contents on site are displayed by fetching it from database. I
have also added indexing to respective tables where it is required. Plain
PHP/HTML coding is used.Technology:PHP -- 5.2MYSQL -- 5.0Apache --
2.0LinuxFollowing is all the server details of my site:CPU : Single Socket
Dual Core AMD Opteron 1212HEMemory: 2GB DDR RAMHard Drive: 250GB SATAEthernet:
100Mb Primary Ethernet Card(/var/log) # uname -aLinux 2.6.9-67.0.15.ELsmp #1
SMP Tue Apr 22 13:50:33 EDT 2008 i686 athlon i386 GNU/Linuxkernel
version:2.6.9-67.0.15.ELsmp(/var/log) # free -mtotal used free shared buffers
cachedMem: 2026 1976</p><p>4 0.095227174 <a title="396-tfidf-4" href="../high_scalability-2009/high_scalability-2009-04-24-INFOSCALE_2009_in_June_in_Hong_Kong.html">580 high scalability-2009-04-24-INFOSCALE 2009 in June in Hong Kong</a></p>
<p>Introduction: In case you are interested here's the info:INFOSCALE 2009: The 4th
International ICST Conference on Scalable Information Systems. 10-12 June
2009, Hong Kong, China.In the last few years, we have seen the proliferation
of the use of heterogeneous distributed systems, ranging from simple Networks
of Workstations, to highly complex grid computing environments. Such
computational paradigms have been preferred due to their reduced costs and
inherent scalability, which pose many challenges to scalable systems and
applications in terms of information access, storage and retrieval.Grid
computing, P2P technology, data and knowledge bases, distributed information
retrieval technology and networking technology should all converge to address
the scalability concern. Furthermore, with the advent of emerging computing
architectures - e.g. SMTs, GPUs, Multicores. - the importance of designing
techniques explicitly targeting these systems is becoming more and more
important.INFOSCALE 2009 will focus o</p><p>5 0.082802862 <a title="396-tfidf-5" href="../high_scalability-2011/high_scalability-2011-10-31-15_Ways_to_Make_Your_Application_Feel_More_Responsive_under_Google_App_Engine.html">1135 high scalability-2011-10-31-15 Ways to Make Your Application Feel More Responsive under Google App Engine</a></p>
<p>Introduction: Small Imrovements, makers of a hosted, lightweight feedback platform, have
written an excellent article on Performance issues on GAE, and how we resolved
them. They show how they trimmed most of their requests to between 300ms and
800ms, some still take 2 seconds when memcache is stale, and others clock in
at 150ms. Notzippy overall, but acceptable, especially if you really like
GAE's PaaS promise.What's tricky with PaaS is if your performance is poor,
there's often not a lot you can do about it. But the folks at Small
Improvements have been clever and diligent, giving many specific details and
timings. Though their advice is specifically for GAE, it will apply to a lot
of different situations as well.Here are the 15 ways they made small
performance improvements: Understand App Engine has bad days. App Engine can
have bad days where performance can degrade. Your design needs to take this
potential for high latency variability into account. Don't always assume the
best case.Always prefe</p><p>6 0.081823938 <a title="396-tfidf-6" href="../high_scalability-2008/high_scalability-2008-02-04-IPS-IDS_for_heavy_content_site.html">238 high scalability-2008-02-04-IPS-IDS for heavy content site</a></p>
<p>7 0.080903947 <a title="396-tfidf-7" href="../high_scalability-2007/high_scalability-2007-09-23-HA_for_switches.html">99 high scalability-2007-09-23-HA for switches</a></p>
<p>8 0.080573454 <a title="396-tfidf-8" href="../high_scalability-2008/high_scalability-2008-03-19-Serving_JavaScript_Fast.html">285 high scalability-2008-03-19-Serving JavaScript Fast</a></p>
<p>9 0.078476951 <a title="396-tfidf-9" href="../high_scalability-2009/high_scalability-2009-08-09-NoSQL%3A_If_Only_It_Was_That_Easy.html">677 high scalability-2009-08-09-NoSQL: If Only It Was That Easy</a></p>
<p>10 0.077558629 <a title="396-tfidf-10" href="../high_scalability-2007/high_scalability-2007-10-25-Should_JSPs_be_avoided_for_high_scalability%3F.html">131 high scalability-2007-10-25-Should JSPs be avoided for high scalability?</a></p>
<p>11 0.075665027 <a title="396-tfidf-11" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>12 0.075658791 <a title="396-tfidf-12" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>13 0.075135343 <a title="396-tfidf-13" href="../high_scalability-2007/high_scalability-2007-10-20-Should_you_build_your_next_website_using_3tera%27s_grid_OS%3F.html">126 high scalability-2007-10-20-Should you build your next website using 3tera's grid OS?</a></p>
<p>14 0.073751993 <a title="396-tfidf-14" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>15 0.073695116 <a title="396-tfidf-15" href="../high_scalability-2013/high_scalability-2013-04-10-Check_Yourself_Before_You_Wreck_Yourself_-_Avocado%27s_5_Early_Stages_of_Architecture_Evolution.html">1438 high scalability-2013-04-10-Check Yourself Before You Wreck Yourself - Avocado's 5 Early Stages of Architecture Evolution</a></p>
<p>16 0.072980493 <a title="396-tfidf-16" href="../high_scalability-2013/high_scalability-2013-07-17-Steve_Ballmer_Says_Microsoft_has_Over_1_Million_Servers_-_What_Does_that_Really_Mean%3F.html">1493 high scalability-2013-07-17-Steve Ballmer Says Microsoft has Over 1 Million Servers - What Does that Really Mean?</a></p>
<p>17 0.072829574 <a title="396-tfidf-17" href="../high_scalability-2013/high_scalability-2013-08-13-In_Memoriam%3A_Lavabit_Architecture_-_Creating_a_Scalable_Email_Service.html">1501 high scalability-2013-08-13-In Memoriam: Lavabit Architecture - Creating a Scalable Email Service</a></p>
<p>18 0.072184183 <a title="396-tfidf-18" href="../high_scalability-2011/high_scalability-2011-06-14-Sponsored_Post%3A_Aconex%2C_Hadapt%2C_Mathworks%2C_AppDynamics%2C__ScaleOut%2C_Membase%2C_CloudSigma%2C_ManageEngine%2C_Site24x7.html">1061 high scalability-2011-06-14-Sponsored Post: Aconex, Hadapt, Mathworks, AppDynamics,  ScaleOut, Membase, CloudSigma, ManageEngine, Site24x7</a></p>
<p>19 0.072131604 <a title="396-tfidf-19" href="../high_scalability-2007/high_scalability-2007-11-12-Slashdot_Architecture_-_How_the_Old_Man_of_the_Internet_Learned_to_Scale.html">150 high scalability-2007-11-12-Slashdot Architecture - How the Old Man of the Internet Learned to Scale</a></p>
<p>20 0.071833789 <a title="396-tfidf-20" href="../high_scalability-2008/high_scalability-2008-03-12-YouTube_Architecture.html">274 high scalability-2008-03-12-YouTube Architecture</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.135), (1, 0.025), (2, 0.035), (3, -0.012), (4, -0.029), (5, -0.001), (6, 0.03), (7, -0.031), (8, -0.037), (9, 0.066), (10, -0.001), (11, -0.021), (12, 0.038), (13, -0.015), (14, 0.005), (15, 0.038), (16, -0.019), (17, -0.001), (18, -0.022), (19, 0.004), (20, -0.028), (21, 0.009), (22, 0.007), (23, -0.005), (24, -0.022), (25, -0.018), (26, 0.001), (27, 0.009), (28, -0.054), (29, 0.011), (30, -0.008), (31, 0.011), (32, -0.007), (33, -0.024), (34, 0.0), (35, -0.025), (36, 0.013), (37, 0.005), (38, 0.007), (39, 0.041), (40, 0.026), (41, -0.017), (42, 0.036), (43, 0.045), (44, 0.04), (45, -0.013), (46, -0.003), (47, 0.005), (48, -0.037), (49, 0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94773483 <a title="396-lsi-1" href="../high_scalability-2008/high_scalability-2008-09-26-Lucasfilm%3A_The_Real_Magic_is_in_the_Data_Center.html">396 high scalability-2008-09-26-Lucasfilm: The Real Magic is in the Data Center</a></p>
<p>Introduction: Kevin Clark, director of IT operations for Lucasfilm, discusses how their data
center works:* Linux-based platform, SUSE (looking to change), and a lot of
proprietary open source applications for content creation.* 4,500-processor
render farm in the datacenter. Workstations are used off hours.* Developed
their own proprietary scheduler to schedule their 5,500 available processors.*
Render nodes, the blade racks (from Verari), run dual-core dual Opteron chips
with 32GB of memory on board, but are expanding those to quad-core. Are an AMD
shop.* 400TB of storage online for production.* Every night they write out
10-20TB of new data on a render. A project will use up to a hundred-plus
terabytes of storage.* Incremental backups are a challenge because the data
changes up to 50 percent over a week.* NetApps used for storage. They like the
global namespace in the virtual file system.* Foundry Networks architecture
shop. One of the larger 10-GbE-backbone facilities on the West coast. 350-plus</p><p>2 0.71245986 <a title="396-lsi-2" href="../high_scalability-2010/high_scalability-2010-09-16-How_Can_the_Large_Hadron_Collider_Withstand_One_Petabyte_of_Data_a_Second%3F.html">901 high scalability-2010-09-16-How Can the Large Hadron Collider Withstand One Petabyte of Data a Second?</a></p>
<p>Introduction: Why is there something rather than nothing? That's the kind of question
theLarge Hadron Colliderin CERN is hopefully poised to answer. And what is the
output of this beautiful 17-mile long,6 billion dollar wabi-sabishproton
smashing machine? Data. Great heaping torrents of Grand Canyon sized data. 15
million gigabytes every year. That's 1000 times the information printed in
books every year. It's so much data 10,000 scientists will use agridof80,000+
computers, in 300 computer centers , in 50 different countries just to help
make sense of it all.How will all this data be collected, transported, stored,
and analyzed? It turns out, using what amounts to sort of Internet of
Particles instead of an Internet of Things.Two good articles have recently
shed some electro-magnetic energy in the human visible spectrum on the IT
aspects of the collider:LHC computing grid pushes petabytes of data, beats
expectations by John Timmer on Ars Technica and an overview of theBrookhaven's
RHIC/ATLAS Comput</p><p>3 0.70531195 <a title="396-lsi-3" href="../high_scalability-2011/high_scalability-2011-12-21-In_Memory_Data_Grid_Technologies.html">1160 high scalability-2011-12-21-In Memory Data Grid Technologies</a></p>
<p>Introduction: After winning a CSC Leading Edge Forum (LEF) research grant, I (Paul Colmer)
wanted to publish some of the highlights of my research to share with the
wider technology community.What is an In Memory Data Grid?It is not an in-
memory relational database, a NOSQL database or a relational database.  It is
a different breed of software datastore.In summary an IMDG is an 'off the
shelf' software product that exhibits the following characteristics:The data
model is distributed across many servers in a single location or across
multiple locations.  This distribution is known as a data fabric.  This
distributed model is known as a 'shared nothing' architecture.All servers can
be active in each site.All data is stored in the RAM of the servers.Servers
can be added or removed non-disruptively, to increase the amount of RAM
available.The data model is non-relational and is object-based. Distributed
applications written on the .NET and Java application platforms are
supported.The data fabric is re</p><p>4 0.70086271 <a title="396-lsi-4" href="../high_scalability-2008/high_scalability-2008-08-17-Wuala_-_P2P_Online_Storage_Cloud.html">368 high scalability-2008-08-17-Wuala - P2P Online Storage Cloud</a></p>
<p>Introduction: How do you design a reliable distributed file system when the expected
availability of the individual nodes are only ~1/5? That is the case for P2P
systems. Dominik Grolimund, the founder of a Swiss startup Caleido will show
you how! They havelaunched Wuala, the social online storage service which
scales as new nodes join the P2P network.The goal ofWua.lais to provide
distributed online storage that is:largescalablereliablesecureby harnessing
the idle resources of participating computers.This challenge is an old dream
of computer science. In fact asAndrew Tanenbaumwrote in 1995:"The design of a
world-wide, fully transparent distributed filesystem fot simultaneous use by
millions of mobile and frequently disconnected users is left as an exercise
for the reader"After three years of research and development at at ETH Zurich,
the Swiss Federal Institute of Technology on a distributed storage system,
Caleido is ready to unveil the result: Wuala. Wuala is a new way of storing,
sharing, and p</p><p>5 0.6997686 <a title="396-lsi-5" href="../high_scalability-2010/high_scalability-2010-08-18-Misco%3A_A_MapReduce_Framework_for_Mobile_Systems_-_Start_of_the_Ambient_Cloud%3F.html">882 high scalability-2010-08-18-Misco: A MapReduce Framework for Mobile Systems - Start of the Ambient Cloud?</a></p>
<p>Introduction: Misco: A MapReduce Framework for Mobile Systems is a very exciting paper to me
because it's really one of the first explorations of some of the ideas in
Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the
Ambient Cloud. What they are trying to do is efficiently distribute work
across a set cellphones using a now familiar MapReduce interface. Usually we
think of MapReduce as working across large data center hosted clusters. Here,
the cluster nodes are cellphones not contained in any data center, but compute
nodes potentially distributed everywhere.I talked withAdam Dou, one of the
paper's authors, and he said they don't see cellphone clusters replacing
dedicated computer clusters, primarily because of thepower requiredfor both
network communication and the map-reduce computations. Large multi-terabyte
jobs aren't in the cards...yet. Adam estimates computationally that cellphones
are performing similarly to desktops of ten years ago. Instead, they want to
focus</p><p>6 0.69302446 <a title="396-lsi-6" href="../high_scalability-2007/high_scalability-2007-09-27-Product%3A_Ganglia_Monitoring_System.html">101 high scalability-2007-09-27-Product: Ganglia Monitoring System</a></p>
<p>7 0.68995839 <a title="396-lsi-7" href="../high_scalability-2014/high_scalability-2014-05-09-Stuff_The_Internet_Says_On_Scalability_For_May_9th%2C_2014.html">1645 high scalability-2014-05-09-Stuff The Internet Says On Scalability For May 9th, 2014</a></p>
<p>8 0.67326635 <a title="396-lsi-8" href="../high_scalability-2012/high_scalability-2012-09-04-Changing_Architectures%3A_New_Datacenter_Networks_Will_Set_Your_Code_and_Data_Free___.html">1316 high scalability-2012-09-04-Changing Architectures: New Datacenter Networks Will Set Your Code and Data Free   </a></p>
<p>9 0.67177844 <a title="396-lsi-9" href="../high_scalability-2008/high_scalability-2008-12-20-Second_Life_Architecture_-_The_Grid.html">473 high scalability-2008-12-20-Second Life Architecture - The Grid</a></p>
<p>10 0.67143148 <a title="396-lsi-10" href="../high_scalability-2011/high_scalability-2011-05-23-Evernote_Architecture_-_9_Million_Users_and_150_Million_Requests_a_Day.html">1046 high scalability-2011-05-23-Evernote Architecture - 9 Million Users and 150 Million Requests a Day</a></p>
<p>11 0.67113185 <a title="396-lsi-11" href="../high_scalability-2014/high_scalability-2014-01-17-Stuff_The_Internet_Says_On_Scalability_For_January_17th%2C_2014.html">1581 high scalability-2014-01-17-Stuff The Internet Says On Scalability For January 17th, 2014</a></p>
<p>12 0.67055631 <a title="396-lsi-12" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>13 0.66582292 <a title="396-lsi-13" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>14 0.66579843 <a title="396-lsi-14" href="../high_scalability-2007/high_scalability-2007-08-20-TypePad_Architecture.html">68 high scalability-2007-08-20-TypePad Architecture</a></p>
<p>15 0.65840459 <a title="396-lsi-15" href="../high_scalability-2007/high_scalability-2007-10-20-Should_you_build_your_next_website_using_3tera%27s_grid_OS%3F.html">126 high scalability-2007-10-20-Should you build your next website using 3tera's grid OS?</a></p>
<p>16 0.65834802 <a title="396-lsi-16" href="../high_scalability-2012/high_scalability-2012-06-04-OpenFlow-SDN_is_Not_a_Silver_Bullet_for_Network_Scalability.html">1256 high scalability-2012-06-04-OpenFlow-SDN is Not a Silver Bullet for Network Scalability</a></p>
<p>17 0.65384454 <a title="396-lsi-17" href="../high_scalability-2009/high_scalability-2009-05-12-GemStone_Unveils_GemFire_Enterprise_6.0.html">597 high scalability-2009-05-12-GemStone Unveils GemFire Enterprise 6.0</a></p>
<p>18 0.65338445 <a title="396-lsi-18" href="../high_scalability-2013/high_scalability-2013-06-21-Stuff_The_Internet_Says_On_Scalability_For_June_21%2C_2013.html">1479 high scalability-2013-06-21-Stuff The Internet Says On Scalability For June 21, 2013</a></p>
<p>19 0.65275329 <a title="396-lsi-19" href="../high_scalability-2011/high_scalability-2011-06-29-Second_Hand_Seizure_%3A_A_New_Cause_of_Site_Death.html">1070 high scalability-2011-06-29-Second Hand Seizure : A New Cause of Site Death</a></p>
<p>20 0.65136993 <a title="396-lsi-20" href="../high_scalability-2008/high_scalability-2008-09-25-GridGain%3A__One_Compute_Grid%2C_Many_Data_Grids.html">393 high scalability-2008-09-25-GridGain:  One Compute Grid, Many Data Grids</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.158), (2, 0.153), (10, 0.019), (24, 0.287), (40, 0.018), (56, 0.049), (61, 0.142), (79, 0.059), (85, 0.021)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.86071068 <a title="396-lda-1" href="../high_scalability-2008/high_scalability-2008-09-16-Product%3A_Func_-_Fedora_Unified_Network_Controller.html">385 high scalability-2008-09-16-Product: Func - Fedora Unified Network Controller</a></p>
<p>Introduction: Funcis used to manage a large network using bash or Python scripts. It targets
easy and simple remote scripting and one-off tasks over SSH by creating a
secure (SSL certifications) XMLRPC API for communication. Any kind of
application can be written on top of it. Other configuration management tools
specialize in mass configuration. They say here's what the machine should look
like and keep it that way. Func allows you to program your cluster. If you've
ever tried to securely remote script a gang of machines using SSH keys you
know what a total nightmare that can be.Some example commands:Using the
command line:func "*.example.org" call yumcmd updateUsing the Pthon API:import
func.overlord.client as fcclient = fc.Client("*.example.org;*.example.com")cli
ent.yumcmd.update()client.service.start("acme-server")print
client.hardware.info()Func may certainly overlap in functionality with other
tools like Puppet and cfengine, but as programmers we always need more than
one way to do it and def</p><p>2 0.85617769 <a title="396-lda-2" href="../high_scalability-2007/high_scalability-2007-08-07-Can_you_profit_from_the_coming_Content_Delivery_Network_wars%3F.html">60 high scalability-2007-08-07-Can you profit from the coming Content Delivery Network wars?</a></p>
<p>Introduction: Playing like the big boys may be getting cheaper. The big boys, likeYouTube,
farm the serving of their most popular videos to a third party CDN. A lot of
people were surprised YouTube didn't serve all their content themselves, but
it makes sense. It allows them to keep up with demand without a large hit for
infrastructure build out, much like leasing computers instead of buying
them.breakThe problem has been CDNs are expensive. Om Malik reports inAkamai &
the CDN Price Warsthat may be changing. CDN service could be becoming
affordable enough that you might consider using them as part of your scaling
strategy.Akamai, once the clear leader in the CDN field, is facing strong
competition from the likes of Limelight Networks, Level 3, Internap,
CDNetworks, Panther Express and EdgeCast Networks.Thiscommoditizationmay be
bad for their stock prices, but it's good for website builders looking for new
scaling strategies. EdgeCast, for example, passes on the cost savings when
when their bandwidth</p><p>same-blog 3 0.81282943 <a title="396-lda-3" href="../high_scalability-2008/high_scalability-2008-09-26-Lucasfilm%3A_The_Real_Magic_is_in_the_Data_Center.html">396 high scalability-2008-09-26-Lucasfilm: The Real Magic is in the Data Center</a></p>
<p>Introduction: Kevin Clark, director of IT operations for Lucasfilm, discusses how their data
center works:* Linux-based platform, SUSE (looking to change), and a lot of
proprietary open source applications for content creation.* 4,500-processor
render farm in the datacenter. Workstations are used off hours.* Developed
their own proprietary scheduler to schedule their 5,500 available processors.*
Render nodes, the blade racks (from Verari), run dual-core dual Opteron chips
with 32GB of memory on board, but are expanding those to quad-core. Are an AMD
shop.* 400TB of storage online for production.* Every night they write out
10-20TB of new data on a render. A project will use up to a hundred-plus
terabytes of storage.* Incremental backups are a challenge because the data
changes up to 50 percent over a week.* NetApps used for storage. They like the
global namespace in the virtual file system.* Foundry Networks architecture
shop. One of the larger 10-GbE-backbone facilities on the West coast. 350-plus</p><p>4 0.81203574 <a title="396-lda-4" href="../high_scalability-2013/high_scalability-2013-05-15-Lesson_from_Airbnb%3A_Give_Yourself_Permission_to_Experiment_with_Non-scalable_Changes.html">1458 high scalability-2013-05-15-Lesson from Airbnb: Give Yourself Permission to Experiment with Non-scalable Changes</a></p>
<p>Introduction: If you are stuck drowning in too much data and too many options and are
dazzled by all the possibilities of code, here's a helpful bit of advice from
Airbnb's rags to richesorigin story:it's okay to do things that don't scale. A
corollary is the idea of paying attention to and learning from what your users
are actually doing and let that lead you without out that annoying voice in
your head second guessing you, yelling but that will never scale! Worry about
building something good, then worry about making it scale.In Airbnb's case
they noticed people weren't booking rooms because the pictures sucked. So they
flew to New York and shot some beautiful images. This is a very non-scalable
and non-technical solution. Yet it was the turning point for Airbnb and
sparked their climb out of the "trough of sorrow." Previously they had been
limited by the Silicon Valley idea that every feature had to be scalable. Not
every solution can be found behind a computer screen.For the full story please
re</p><p>5 0.76382858 <a title="396-lda-5" href="../high_scalability-2011/high_scalability-2011-08-02-How_Will_DIDO_Wireless_Networking_Change_Everything%3F.html">1091 high scalability-2011-08-02-How Will DIDO Wireless Networking Change Everything?</a></p>
<p>Introduction: A conjunction of a few new technologies may trigger disruptive changes in the
future. This observation was prompted by a talkSteve Perlmangave at the
Columbia Engineering School: Benjamin Button, Cloud Everything and Why
Shannon's Law Isn't. In it he covers a set of technologies that at first may
seem unrelated, but turn out to be deeply related after all, culminating in a
realization of the long talked about vision of an application utility, where
all applications are hosted and run out of the cloud. First Perlman talks
about the realistic human rendering technology developed at Rearden, his
research incubator company. This technology was developed over many years and
is the secret behind the wonderful effects found in movies likeBenjamin
Button. It is now being used in many other films, and promises to
revolutionize film making, possibly even replacing actors with computers, in
real-time.The next invention at Rearden isOnLive, a cloud based gaming
technology for playing video games o</p><p>6 0.76077682 <a title="396-lda-6" href="../high_scalability-2011/high_scalability-2011-06-13-Automation_on_AWS_with_Ruby_and_Puppet.html">1058 high scalability-2011-06-13-Automation on AWS with Ruby and Puppet</a></p>
<p>7 0.71161711 <a title="396-lda-7" href="../high_scalability-2011/high_scalability-2011-04-01-Stuff_The_Internet_Says_On_Scalability_For_April_1%2C_2011.html">1015 high scalability-2011-04-01-Stuff The Internet Says On Scalability For April 1, 2011</a></p>
<p>8 0.69557828 <a title="396-lda-8" href="../high_scalability-2012/high_scalability-2012-08-10-Stuff_The_Internet_Says_On_Scalability_For_August_10%2C_2012.html">1302 high scalability-2012-08-10-Stuff The Internet Says On Scalability For August 10, 2012</a></p>
<p>9 0.68688649 <a title="396-lda-9" href="../high_scalability-2010/high_scalability-2010-12-16-7_Design_Patterns_for_Almost-infinite_Scalability.html">958 high scalability-2010-12-16-7 Design Patterns for Almost-infinite Scalability</a></p>
<p>10 0.67313248 <a title="396-lda-10" href="../high_scalability-2010/high_scalability-2010-10-28-Notes_from_A_NOSQL_Evening_in_Palo_Alto_.html">931 high scalability-2010-10-28-Notes from A NOSQL Evening in Palo Alto </a></p>
<p>11 0.67193341 <a title="396-lda-11" href="../high_scalability-2009/high_scalability-2009-07-28-37signals_Architecture.html">663 high scalability-2009-07-28-37signals Architecture</a></p>
<p>12 0.67048705 <a title="396-lda-12" href="../high_scalability-2011/high_scalability-2011-04-28-PaaS_on_OpenStack_-_Run_Applications_on_Any_Cloud%2C_Any_Time_Using_Any_Thing.html">1031 high scalability-2011-04-28-PaaS on OpenStack - Run Applications on Any Cloud, Any Time Using Any Thing</a></p>
<p>13 0.66933668 <a title="396-lda-13" href="../high_scalability-2008/high_scalability-2008-10-19-Alternatives_to_Google_App_Engine.html">423 high scalability-2008-10-19-Alternatives to Google App Engine</a></p>
<p>14 0.66667819 <a title="396-lda-14" href="../high_scalability-2012/high_scalability-2012-07-23-State_of_the_CDN%3A_More_Traffic%2C_Stable_Prices%2C_More_Products%2C_Profits_-_Not_So_Much.html">1289 high scalability-2012-07-23-State of the CDN: More Traffic, Stable Prices, More Products, Profits - Not So Much</a></p>
<p>15 0.66663945 <a title="396-lda-15" href="../high_scalability-2010/high_scalability-2010-07-09-Hot_Scalability_Links_for_July_9%2C_2010.html">854 high scalability-2010-07-09-Hot Scalability Links for July 9, 2010</a></p>
<p>16 0.66656852 <a title="396-lda-16" href="../high_scalability-2008/high_scalability-2008-09-10-Shard_servers_--_go_big_or_small%3F.html">383 high scalability-2008-09-10-Shard servers -- go big or small?</a></p>
<p>17 0.66438657 <a title="396-lda-17" href="../high_scalability-2010/high_scalability-2010-11-30-NoCAP_%E2%80%93_Part_III_%E2%80%93_GigaSpaces_clustering_explained...html">950 high scalability-2010-11-30-NoCAP – Part III – GigaSpaces clustering explained..</a></p>
<p>18 0.66399753 <a title="396-lda-18" href="../high_scalability-2009/high_scalability-2009-11-06-Product%3A_Resque_-_GitHub%27s_Distrubuted_Job_Queue.html">738 high scalability-2009-11-06-Product: Resque - GitHub's Distrubuted Job Queue</a></p>
<p>19 0.66393328 <a title="396-lda-19" href="../high_scalability-2011/high_scalability-2011-07-29-Stuff_The_Internet_Says_On_Scalability_For_July_29%2C_2011.html">1089 high scalability-2011-07-29-Stuff The Internet Says On Scalability For July 29, 2011</a></p>
<p>20 0.66382611 <a title="396-lda-20" href="../high_scalability-2010/high_scalability-2010-03-03-Hot_Scalability_Links_for_March_3%2C_2010.html">787 high scalability-2010-03-03-Hot Scalability Links for March 3, 2010</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
