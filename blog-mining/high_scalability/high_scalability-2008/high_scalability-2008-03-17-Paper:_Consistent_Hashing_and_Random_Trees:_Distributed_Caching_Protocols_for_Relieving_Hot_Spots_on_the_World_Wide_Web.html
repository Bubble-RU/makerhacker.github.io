<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>280 high scalability-2008-03-17-Paper: Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2008" href="../home/high_scalability-2008_home.html">high_scalability-2008</a> <a title="high_scalability-2008-280" href="#">high_scalability-2008-280</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>280 high scalability-2008-03-17-Paper: Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2008-280-html" href="http://highscalability.com//blog/2008/3/17/paper-consistent-hashing-and-random-trees-distributed-cachin.html">html</a></p><p>Introduction: Consistent hashing is one of those ideas that really puts the science in
computer science and reminds us why all those really smart people spend years
slaving over algorithms. Consistent hashing is "a scheme that provides hash
table functionality in a way that the addition or removal of one slot does not
significantly change the mapping of keys to slots" and was originally a way of
distributing requests among a changing population of web servers. My first
reaction to the idea was "wow, that's really smart" and I sadly realized I
would never come up with something so elegant. I then immediately saw
applications for it everywhere. And consistent hashing is used everywhere:
distributed hash tables, overlay networks, P2P, IM, caching, and CDNs. Here's
the abstract from the original paper and after the abstract are some links to
a few very good articles with accessible explanations of consistent hashing
and its applications in the real world.breakAbstract:We describe a family of
caching pro</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('consistent', 0.415), ('hashing', 0.397), ('protocols', 0.317), ('hash', 0.244), ('spots', 0.188), ('hashingby', 0.179), ('caching', 0.146), ('distribution', 0.131), ('tom', 0.129), ('hot', 0.11), ('networks', 0.105), ('family', 0.104), ('distributed', 0.096), ('coral', 0.09), ('abstract', 0.088), ('relieving', 0.084), ('minimally', 0.08), ('slot', 0.08), ('science', 0.078), ('anycast', 0.077)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="280-tfidf-1" href="../high_scalability-2008/high_scalability-2008-03-17-Paper%3A_Consistent_Hashing_and_Random_Trees%3A_Distributed_Caching_Protocols_for_Relieving_Hot_Spots_on_the_World_Wide_Web.html">280 high scalability-2008-03-17-Paper: Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web</a></p>
<p>Introduction: Consistent hashing is one of those ideas that really puts the science in
computer science and reminds us why all those really smart people spend years
slaving over algorithms. Consistent hashing is "a scheme that provides hash
table functionality in a way that the addition or removal of one slot does not
significantly change the mapping of keys to slots" and was originally a way of
distributing requests among a changing population of web servers. My first
reaction to the idea was "wow, that's really smart" and I sadly realized I
would never come up with something so elegant. I then immediately saw
applications for it everywhere. And consistent hashing is used everywhere:
distributed hash tables, overlay networks, P2P, IM, caching, and CDNs. Here's
the abstract from the original paper and after the abstract are some links to
a few very good articles with accessible explanations of consistent hashing
and its applications in the real world.breakAbstract:We describe a family of
caching pro</p><p>2 0.35645604 <a title="280-tfidf-2" href="../high_scalability-2010/high_scalability-2010-09-02-Distributed_Hashing_Algorithms_by_Example%3A_Consistent_Hashing.html">892 high scalability-2010-09-02-Distributed Hashing Algorithms by Example: Consistent Hashing</a></p>
<p>Introduction: Consistent Hashing is a specific implementation of hashing that is well suited
for many of today's web-scale load balancing problems. Specifically, it can be
seen in use in various caching solutions like Memcached and is applicable to
NoSQL solutions as well. Consistent Hashing is used particularly because it
provides a solution for the typical "hashcode mod n" method of distributing
keys across a series of servers. It does this by allowing servers to be added
or removed without significantly upsetting the distribution of keys, nor does
it require that all keys be rehashed to accommodate the change in the number
of servers.ďťżYou can read the full storehere.</p><p>3 0.16569948 <a title="280-tfidf-3" href="../high_scalability-2009/high_scalability-2009-05-05-Drop_ACID_and_Think_About_Data.html">589 high scalability-2009-05-05-Drop ACID and Think About Data</a></p>
<p>Introduction: The abstract for the talk given by Bob Ippolito, co-founder and CTO of Mochi
Media, Inc:Building large systems on top of a traditional single-master RDBMS
data storage layer is no longer good enough. This talk explores the landscape
of new technologies available today to augment your data layer to improve
performance and reliability. Is your application a good fit for caches, bloom
filters, bitmap indexes, column stores, distributed key/value stores, or
document databases? Learn how they work (in theory and practice) and decide
for yourself.Bob does an excellent job highlighting different products and the
key concepts to understand when pondering the wide variety of new database
offerings. It's unlikely you'll be able to say oh, this is the database for me
after watching the presentation, but you will be much better informed on your
options. And I imagine slightly confused as to what to do :-)An interesting
observation in the talk is that the more robust products are internal to large</p><p>4 0.16185749 <a title="280-tfidf-4" href="../high_scalability-2010/high_scalability-2010-08-30-Pomegranate_-_Storing_Billions_and_Billions_of_Tiny_Little_Files.html">889 high scalability-2010-08-30-Pomegranate - Storing Billions and Billions of Tiny Little Files</a></p>
<p>Introduction: Pomegranateis a novel distributed file system built over distributed tabular
storage that acts an awful lot like a NoSQL system. It's targeted at
increasing the performance of tiny object access in order to support
applications like online photo and micro-blog services, which require high
concurrency, high throughput, and low latency. Their tests seem to indicate it
works:We have demonstrate that file system over tabular storage performs well
for highly concurrent access. In our test cluster, we observedlinearly
increased more than100,000aggregate read and write requests served per second
(RPS). Rather than sitting atop the file system like almost every other K-V
store, Pomegranate is baked into file system. The idea is that the file system
API is common to every platform so it wouldn't require a separate API to use.
Every application could use it out of the box.The features of Pomegranate
are:It handles billions of small files efficiently, even in one directory;It
provide separate and</p><p>5 0.15151589 <a title="280-tfidf-5" href="../high_scalability-2007/high_scalability-2007-07-16-Paper%3A_Replication_Under_Scalable_Hashing.html">19 high scalability-2007-07-16-Paper: Replication Under Scalable Hashing</a></p>
<p>Introduction: Replication Under Scalable Hashing: A Family of Algorithms for
ScalableDecentralized Data DistributionFrom the abstract:Typical algorithms
for decentralized data distributionwork best in a system that is fully built
before it first used;adding or removing components results in either
extensivereorganization of data or load imbalance in the system.We have
developed a family of decentralized algorithms,RUSH (Replication Under
Scalable Hashing), thatmaps replicated objects to a scalable collection of
storageservers or disks. RUSH algorithms distribute objects toservers
according to user-specified server weighting. Whileall RUSH variants support
addition of servers to the system,different variants have different
characteristics withrespect to lookup time in petabyte-scale systems,
performancewith mirroring (as opposed to redundancy codes),and storage server
removal. All RUSH variants redistributeas few objects as possible when new
servers areadded or existing servers are removed, and all v</p><p>6 0.12605447 <a title="280-tfidf-6" href="../high_scalability-2012/high_scalability-2012-03-07-Scale_Indefinitely_on_S3_With_These_Secrets_of_the_S3_Masters.html">1205 high scalability-2012-03-07-Scale Indefinitely on S3 With These Secrets of the S3 Masters</a></p>
<p>7 0.11994835 <a title="280-tfidf-7" href="../high_scalability-2009/high_scalability-2009-07-02-Product%3A_Project_Voldemort_-_A_Distributed_Database.html">651 high scalability-2009-07-02-Product: Project Voldemort - A Distributed Database</a></p>
<p>8 0.11945918 <a title="280-tfidf-8" href="../high_scalability-2012/high_scalability-2012-10-04-Stuff_The_Internet_Says_On_Scalability_For_October_5%2C_2012.html">1334 high scalability-2012-10-04-Stuff The Internet Says On Scalability For October 5, 2012</a></p>
<p>9 0.11042538 <a title="280-tfidf-9" href="../high_scalability-2008/high_scalability-2008-05-05-HSCALE_-__Handling_200_Million_Transactions_Per_Month_Using_Transparent_Partitioning_With_MySQL_Proxy.html">315 high scalability-2008-05-05-HSCALE -  Handling 200 Million Transactions Per Month Using Transparent Partitioning With MySQL Proxy</a></p>
<p>10 0.10830554 <a title="280-tfidf-10" href="../high_scalability-2011/high_scalability-2011-11-14-Using_Gossip_Protocols_for_Failure_Detection%2C_Monitoring%2C_Messaging_and_Other_Good_Things.html">1142 high scalability-2011-11-14-Using Gossip Protocols for Failure Detection, Monitoring, Messaging and Other Good Things</a></p>
<p>11 0.10012133 <a title="280-tfidf-11" href="../high_scalability-2011/high_scalability-2011-11-23-Paper%3A_Don%E2%80%99t_Settle_for_Eventual%3A_Scalable_Causal_Consistency_for_Wide-Area_Storage_with_COPS.html">1146 high scalability-2011-11-23-Paper: Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</a></p>
<p>12 0.099210858 <a title="280-tfidf-12" href="../high_scalability-2010/high_scalability-2010-03-03-Hot_Scalability_Links_for_March_3%2C_2010.html">787 high scalability-2010-03-03-Hot Scalability Links for March 3, 2010</a></p>
<p>13 0.099203609 <a title="280-tfidf-13" href="../high_scalability-2011/high_scalability-2011-06-17-Stuff_The_Internet_Says_On_Scalability_For_June_17%2C_2011.html">1063 high scalability-2011-06-17-Stuff The Internet Says On Scalability For June 17, 2011</a></p>
<p>14 0.098510452 <a title="280-tfidf-14" href="../high_scalability-2010/high_scalability-2010-08-20-Hot_Scalability_Links_For_Aug_20%2C_2010.html">883 high scalability-2010-08-20-Hot Scalability Links For Aug 20, 2010</a></p>
<p>15 0.097852699 <a title="280-tfidf-15" href="../high_scalability-2008/high_scalability-2008-12-17-Ringo_-_Distributed_key-value_storage_for_immutable_data.html">468 high scalability-2008-12-17-Ringo - Distributed key-value storage for immutable data</a></p>
<p>16 0.096480846 <a title="280-tfidf-16" href="../high_scalability-2011/high_scalability-2011-01-14-Stuff_The_Internet_Says_On_Scalability_For_January_14%2C_2011.html">973 high scalability-2011-01-14-Stuff The Internet Says On Scalability For January 14, 2011</a></p>
<p>17 0.096388973 <a title="280-tfidf-17" href="../high_scalability-2011/high_scalability-2011-04-06-Netflix%3A_Run_Consistency_Checkers_All_the_time_to_Fixup_Transactions.html">1017 high scalability-2011-04-06-Netflix: Run Consistency Checkers All the time to Fixup Transactions</a></p>
<p>18 0.095913641 <a title="280-tfidf-18" href="../high_scalability-2011/high_scalability-2011-04-13-Paper%3A_NoSQL_Databases_-_NoSQL_Introduction_and_Overview.html">1022 high scalability-2011-04-13-Paper: NoSQL Databases - NoSQL Introduction and Overview</a></p>
<p>19 0.093729451 <a title="280-tfidf-19" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>20 0.093654372 <a title="280-tfidf-20" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.16), (1, 0.072), (2, -0.021), (3, 0.024), (4, 0.004), (5, 0.052), (6, 0.021), (7, -0.015), (8, -0.079), (9, 0.055), (10, 0.022), (11, 0.018), (12, -0.083), (13, -0.03), (14, 0.006), (15, 0.026), (16, 0.046), (17, 0.01), (18, 0.022), (19, -0.088), (20, -0.001), (21, 0.113), (22, -0.029), (23, 0.061), (24, -0.066), (25, -0.031), (26, 0.038), (27, 0.029), (28, 0.016), (29, -0.051), (30, -0.02), (31, -0.03), (32, -0.026), (33, -0.007), (34, -0.017), (35, -0.05), (36, -0.01), (37, -0.017), (38, 0.034), (39, -0.044), (40, 0.003), (41, 0.03), (42, 0.04), (43, -0.022), (44, -0.048), (45, 0.062), (46, -0.017), (47, 0.044), (48, 0.008), (49, 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96579409 <a title="280-lsi-1" href="../high_scalability-2008/high_scalability-2008-03-17-Paper%3A_Consistent_Hashing_and_Random_Trees%3A_Distributed_Caching_Protocols_for_Relieving_Hot_Spots_on_the_World_Wide_Web.html">280 high scalability-2008-03-17-Paper: Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web</a></p>
<p>Introduction: Consistent hashing is one of those ideas that really puts the science in
computer science and reminds us why all those really smart people spend years
slaving over algorithms. Consistent hashing is "a scheme that provides hash
table functionality in a way that the addition or removal of one slot does not
significantly change the mapping of keys to slots" and was originally a way of
distributing requests among a changing population of web servers. My first
reaction to the idea was "wow, that's really smart" and I sadly realized I
would never come up with something so elegant. I then immediately saw
applications for it everywhere. And consistent hashing is used everywhere:
distributed hash tables, overlay networks, P2P, IM, caching, and CDNs. Here's
the abstract from the original paper and after the abstract are some links to
a few very good articles with accessible explanations of consistent hashing
and its applications in the real world.breakAbstract:We describe a family of
caching pro</p><p>2 0.72891897 <a title="280-lsi-2" href="../high_scalability-2009/high_scalability-2009-09-16-Paper%3A_A_practical_scalable_distributed_B-tree.html">705 high scalability-2009-09-16-Paper: A practical scalable distributed B-tree</a></p>
<p>Introduction: We've seen a lot ofNoSQLaction lately built around distributed hash tables.
Btrees are getting jealous. Btrees, once the king of the database world, want
their throne back.Paul Buchheitsurfaced a paper:A practical scalable
distributed B-treeby Marcos K. Aguilera and Wojciech Golab, that might help
spark a revolution.From the Abstract:We propose a new algorithm for a
practical, fault tolerant, and scalable B-tree distributed over a set of
servers. Our algorithm supports practical features not present in prior work:
transactions that allow atomic execution of multiple operations over multiple
B-trees, online migration of B-tree nodes between servers, and dynamic
addition and removal of servers. Moreover, our algorithm is conceptually
simple: we use transactions to manipulate B-tree nodes so that clients need
not use complicated concurrency and locking protocols used in prior work. To
execute these transactions quickly, we rely on three techniques: (1) We use
optimistic concurrency contro</p><p>3 0.72736925 <a title="280-lsi-3" href="../high_scalability-2009/high_scalability-2009-03-10-Paper%3A_Consensus_Protocols%3A_Paxos___.html">529 high scalability-2009-03-10-Paper: Consensus Protocols: Paxos   </a></p>
<p>Introduction: Update: Barbara Liskov's Turing Award, and Byzantine Fault Tolerance.Henry
Robinson has created an excellent series of articles on consensus protocols.
We already covered his2 Phase Commitarticle and he also has a3 Phase
Commitarticle showing how to handle 2PC under single node failures.But that is
not enough! 3PC works well under node failures, but fails for network
failures. So another consensus mechanism is needed that handles both network
and node failures. And that'sPaxos.Paxos correctly handles both types of
failures, but it does this by becoming inaccessible if too many components
fail. This is the "liveness" property of protocols. Paxos waits until the
faults are fixed. Read queries can be handled, but updates will be blocked
until the protocol thinks it can make forward progress.The liveness of Paxos
is primarily dependent on network stability. In a distributed heterogeneous
environment you are at risk of losing the ability to make updates. Users hate
that.breakSo when compani</p><p>4 0.72622234 <a title="280-lsi-4" href="../high_scalability-2014/high_scalability-2014-03-12-Paper%3A_Scalable_Eventually_Consistent_Counters_over_Unreliable_Networks.html">1611 high scalability-2014-03-12-Paper: Scalable Eventually Consistent Counters over Unreliable Networks</a></p>
<p>Introduction: Counting at scale in a distributed environment issurprisingly hard. And it's a
subject we've covered before in various ways:Big Data Counting: How to count a
billion distinct objects using only 1.5KB of Memory,How to update video views
count effectively?,Numbers Everyone Should Know (sharded
counters).Kellabyte(which is an excellent blog) inScalable Eventually
Consistent Counterstalks about how the Cassandra counter implementation scores
well on the scalability and high availability front, but in so doing has "over
and under counting problem in partitioned environments."Which is often fine.
But if you want more accuracy there's a PN-counter, which is aCRDT (convergent
replicated data type)where "all the changes made to a counter on each node
rather than storing and modifying a single value so that you can merge all the
values into the proper final value. Of course the trade-off here is additional
storage and processing but there are ways to optimize this."And there's a
paper you can co</p><p>5 0.70429397 <a title="280-lsi-5" href="../high_scalability-2009/high_scalability-2009-08-08-Yahoo%21%27s_PNUTS_Database%3A_Too_Hot%2C_Too_Cold_or_Just_Right%3F.html">676 high scalability-2009-08-08-Yahoo!'s PNUTS Database: Too Hot, Too Cold or Just Right?</a></p>
<p>Introduction: So far every massively scalable database is a bundle of compromises. For some
the weak guarantees of Amazon'seventual consistencymodel are too cold. For
many the strong guarantees of standard RDBMSdistributed transactionsare too
hot. Google App Engine tries to get it just right withentity groups. Yahoo! is
also trying to get is just right by offering per-record timeline consistency,
which hopes to serve up a heaping bowl ofrich database functionality and low
latency at massive scale:We describe PNUTS [Platform for Nimble Universal
Table Storage], a massively parallel and geographically distributed database
system for Yahoo!'s web applications. PNUTS provides data storage organized as
hashed or ordered tables, low latency for large numbers of con-current
requests including updates and queries, and novel per-record consistency
guarantees. It is a hosted, centrally managed, and geographically distributed
service, and utilizes automated load-balancing and failover to reduce
operational com</p><p>6 0.68580782 <a title="280-lsi-6" href="../high_scalability-2011/high_scalability-2011-11-14-Using_Gossip_Protocols_for_Failure_Detection%2C_Monitoring%2C_Messaging_and_Other_Good_Things.html">1142 high scalability-2011-11-14-Using Gossip Protocols for Failure Detection, Monitoring, Messaging and Other Good Things</a></p>
<p>7 0.67406124 <a title="280-lsi-7" href="../high_scalability-2011/high_scalability-2011-11-23-Paper%3A_Don%E2%80%99t_Settle_for_Eventual%3A_Scalable_Causal_Consistency_for_Wide-Area_Storage_with_COPS.html">1146 high scalability-2011-11-23-Paper: Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</a></p>
<p>8 0.67396069 <a title="280-lsi-8" href="../high_scalability-2010/high_scalability-2010-09-02-Distributed_Hashing_Algorithms_by_Example%3A_Consistent_Hashing.html">892 high scalability-2010-09-02-Distributed Hashing Algorithms by Example: Consistent Hashing</a></p>
<p>9 0.67113018 <a title="280-lsi-9" href="../high_scalability-2010/high_scalability-2010-09-01-Paper%3A_The_Case_for_Determinism_in_Database_Systems__.html">890 high scalability-2010-09-01-Paper: The Case for Determinism in Database Systems  </a></p>
<p>10 0.66477799 <a title="280-lsi-10" href="../high_scalability-2014/high_scalability-2014-04-10-Paper%3A_Scalable_Atomic_Visibility_with_RAMP_Transactions_-_Scale_Linearly_to_100_Servers.html">1629 high scalability-2014-04-10-Paper: Scalable Atomic Visibility with RAMP Transactions - Scale Linearly to 100 Servers</a></p>
<p>11 0.66437292 <a title="280-lsi-11" href="../high_scalability-2010/high_scalability-2010-08-30-Pomegranate_-_Storing_Billions_and_Billions_of_Tiny_Little_Files.html">889 high scalability-2010-08-30-Pomegranate - Storing Billions and Billions of Tiny Little Files</a></p>
<p>12 0.66350585 <a title="280-lsi-12" href="../high_scalability-2013/high_scalability-2013-05-23-Paper%3A_Calvin%3A_Fast_Distributed_Transactions_for_Partitioned_Database_Systems.html">1463 high scalability-2013-05-23-Paper: Calvin: Fast Distributed Transactions for Partitioned Database Systems</a></p>
<p>13 0.66233027 <a title="280-lsi-13" href="../high_scalability-2007/high_scalability-2007-10-14-Product%3A_The_Spread_Toolkit.html">122 high scalability-2007-10-14-Product: The Spread Toolkit</a></p>
<p>14 0.66214222 <a title="280-lsi-14" href="../high_scalability-2012/high_scalability-2012-12-18-Georeplication%3A_When_Bad_Things_Happen_to_Good_Systems.html">1374 high scalability-2012-12-18-Georeplication: When Bad Things Happen to Good Systems</a></p>
<p>15 0.65741324 <a title="280-lsi-15" href="../high_scalability-2009/high_scalability-2009-02-03-Paper%3A_Optimistic_Replication.html">507 high scalability-2009-02-03-Paper: Optimistic Replication</a></p>
<p>16 0.65507042 <a title="280-lsi-16" href="../high_scalability-2013/high_scalability-2013-05-16-Paper%3A_Warp%3A_Multi-Key_Transactions_for_Key-Value_Stores.html">1459 high scalability-2013-05-16-Paper: Warp: Multi-Key Transactions for Key-Value Stores</a></p>
<p>17 0.6531055 <a title="280-lsi-17" href="../high_scalability-2011/high_scalability-2011-01-27-Comet_-_An_Example_of_the_New_Key-Code_Databases.html">979 high scalability-2011-01-27-Comet - An Example of the New Key-Code Databases</a></p>
<p>18 0.64269823 <a title="280-lsi-18" href="../high_scalability-2012/high_scalability-2012-04-30-Masstree_-_Much_Faster_than_MongoDB%2C_VoltDB%2C_Redis%2C_and_Competitive_with_Memcached.html">1236 high scalability-2012-04-30-Masstree - Much Faster than MongoDB, VoltDB, Redis, and Competitive with Memcached</a></p>
<p>19 0.63539743 <a title="280-lsi-19" href="../high_scalability-2011/high_scalability-2011-02-02-Piccolo_-_Building_Distributed_Programs_that_are_11x_Faster_than_Hadoop.html">983 high scalability-2011-02-02-Piccolo - Building Distributed Programs that are 11x Faster than Hadoop</a></p>
<p>20 0.63367015 <a title="280-lsi-20" href="../high_scalability-2009/high_scalability-2009-01-19-Papers%3A_Readings_in_Distributed_Systems.html">497 high scalability-2009-01-19-Papers: Readings in Distributed Systems</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.184), (2, 0.202), (10, 0.015), (40, 0.315), (47, 0.011), (56, 0.013), (61, 0.109), (79, 0.051)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.94167167 <a title="280-lda-1" href="../high_scalability-2010/high_scalability-2010-07-17-Hot_Scalability_Links_for_July_17%2C_2010.html">860 high scalability-2010-07-17-Hot Scalability Links for July 17, 2010</a></p>
<p>Introduction: And by hot I also mean temperature. Summer has arrived. It's sizzling here in
Silicon Valley. Thank you air conditioning!Scale the web by appointing a
Crawler Czar? Tom Foremski has the idea thatGoogle should open up their
indexso sites wouldn't have to endure the constant pounding by ravenous
crawler bots. Don MacAskill of SmugMug estimates50% of our web server CPU
resourcesare spent serving crawlers. What a waste. How this would all work
with real-time feeds, paid  feeds (Twitter, movies, ...), etc. is unknown, but
does it make sense for all that money to be spent on extracting the same data
over and over again?Tweets of Gold:jamesurquhart:Key to applications is
architecture. Key for infrastructure supporting archs is configurability.
Configurability==features.tjake:  People who choose their datastore based oh
hearsay and not their own evaluation are doomed.b6n:No global lock ever goes
unpunished.MichaelSurtees:scalability, systems & process feed each other
right?jamesgolick: Stateme</p><p>2 0.93582821 <a title="280-lda-2" href="../high_scalability-2013/high_scalability-2013-03-07-It%27s_a_VM_Wasteland_-_A_Near_Optimal_Packing_of_VMs_to_Machines_Reduces_TCO_by_22%25.html">1419 high scalability-2013-03-07-It's a VM Wasteland - A Near Optimal Packing of VMs to Machines Reduces TCO by 22%</a></p>
<p>Introduction: In Algorithm Design for Performance Aware VM Consolidation we learn some
shocking facts (gambling in Casablanca?):Average server utilization in many
data centers is low, estimated between 5% and 15%. This is wasteful because an
idle server often consumes more than 50% of peak power.Surely that's just for
old style datacenters? Nope. In Google data centers, workloads that are
consolidated use only 50% of the processor cores. Every other processor core
is left unused simply to ensure that performance does not degrade.It's a VM
wasteland. The goal is to reduce waste by packing VMs onto machines without
hurting performance or wasting resources. The idea is to select VMs that
interfere the least with each other and places them together on the same
server.It's a NP-Complete problem, but this paper describes a practical method
that performs provably close to the optimal. Interestingly they can optimize
for performance or power efficiency, so you can use different algorithms for
different work</p><p>3 0.93432933 <a title="280-lda-3" href="../high_scalability-2007/high_scalability-2007-07-25-Product%3A_3_PAR_REMOTE_COPY.html">27 high scalability-2007-07-25-Product: 3 PAR REMOTE COPY</a></p>
<p>Introduction: 3PAR Remote Copyis a uniquely simple and efficient replication technology that
allows customers to protect and share any application data affordably. Built
upon 3PAR Thin Copy technology, Remote Copy lowers the total cost of storage
by addressing the cost and complexity of remote replication.Common Uses of
3PAR Remote Copy:Affordable Disaster Recovery: Mirror data cost-effectively
across town or across the world.Centralized Archive: Replicate data from
multiple 3PAR InServs located in multiple data centers to a centralized data
archive location.Resilient Pod Architecture: Mutually replicate tier 1 or 2
data to tier 3 capacity between two InServs (application pods).Remote Data
Access: Replicate data to a remote location for sharing of data with remote
users.</p><p>4 0.92486399 <a title="280-lda-4" href="../high_scalability-2009/high_scalability-2009-01-04-Alternative_Memcache_Usage%3A_A_Highly_Scalable%2C_Highly_Available%2C_In-Memory_Shard_Index.html">482 high scalability-2009-01-04-Alternative Memcache Usage: A Highly Scalable, Highly Available, In-Memory Shard Index</a></p>
<p>Introduction: While working with Memcache the other night, it dawned on me that it’s usage
as a distributed caching mechanism was really just one of many ways to use it.
That there are in fact many alternative usages that one could find for
Memcache if they could just realize what Memcache really is at its core – a
simple distributed hash-table – is an important point worthy of further
discussion.To be clear, when I say “simple”, by no means am I implying that
Memcache’s implementation is simple, just that the ideas behind it are such.
Think about that for a minute. What else could we use a simple distributed
hash-table for, besides caching? How about using it as an alternative to the
traditional shard lookup method we used in our Master Index Lookup scalability
strategy, discussed previously here.</p><p>5 0.91756505 <a title="280-lda-5" href="../high_scalability-2008/high_scalability-2008-10-05-Paper%3A_Scalability_Design_Patterns.html">402 high scalability-2008-10-05-Paper: Scalability Design Patterns</a></p>
<p>Introduction: I have introduced pattern languages in my earlier post onThe Pattern Bible for
Distributed Computing.Achieving highest possible scalability is a complex
combination of many factors. This PLoP 2007paperpresents a pattern language
that can be used to make a system highly scalable.The Scalability Pattern
Language introduced by Kanwardeep Singh Ahluwalia includes patterns
to:Introduce ScalabilityOptimize AlgorithmAdd HardwareAdd ParallelismAdd
Intra-Process ParallelismAdd Inter-Porcess ParallelismAdd Hybrid
ParallelismOptimize DecentralizationControl Shared ResourcesAutomate
Scalability</p><p>6 0.91219944 <a title="280-lda-6" href="../high_scalability-2013/high_scalability-2013-05-29-Amazon%3A_Creating_a_Customer_Utopia_One_Culture_Hack_at_a_Time.html">1466 high scalability-2013-05-29-Amazon: Creating a Customer Utopia One Culture Hack at a Time</a></p>
<p>same-blog 7 0.90128672 <a title="280-lda-7" href="../high_scalability-2008/high_scalability-2008-03-17-Paper%3A_Consistent_Hashing_and_Random_Trees%3A_Distributed_Caching_Protocols_for_Relieving_Hot_Spots_on_the_World_Wide_Web.html">280 high scalability-2008-03-17-Paper: Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web</a></p>
<p>8 0.90104252 <a title="280-lda-8" href="../high_scalability-2013/high_scalability-2013-03-01-Stuff_The_Internet_Says_On_Scalability_For_February_29%2C_2013.html">1414 high scalability-2013-03-01-Stuff The Internet Says On Scalability For February 29, 2013</a></p>
<p>9 0.90029657 <a title="280-lda-9" href="../high_scalability-2010/high_scalability-2010-06-25-Hot_Scalability_Links_for_June_25%2C_2010.html">848 high scalability-2010-06-25-Hot Scalability Links for June 25, 2010</a></p>
<p>10 0.88411289 <a title="280-lda-10" href="../high_scalability-2010/high_scalability-2010-02-15-The_Amazing_Collective_Compute_Power_of_the_Ambient_Cloud.html">778 high scalability-2010-02-15-The Amazing Collective Compute Power of the Ambient Cloud</a></p>
<p>11 0.87958544 <a title="280-lda-11" href="../high_scalability-2008/high_scalability-2008-05-27-Should_Twitter_be_an_All-You-Can-Eat_Buffet_or_a_Vending_Machine%3F.html">330 high scalability-2008-05-27-Should Twitter be an All-You-Can-Eat Buffet or a Vending Machine?</a></p>
<p>12 0.8769471 <a title="280-lda-12" href="../high_scalability-2013/high_scalability-2013-06-06-Paper%3A_Memory_Barriers%3A_a_Hardware_View_for_Software_Hackers.html">1471 high scalability-2013-06-06-Paper: Memory Barriers: a Hardware View for Software Hackers</a></p>
<p>13 0.86945575 <a title="280-lda-13" href="../high_scalability-2008/high_scalability-2008-04-07-Scalr_-_Open_Source_Auto-scaling_Hosting_on_Amazon_EC2.html">300 high scalability-2008-04-07-Scalr - Open Source Auto-scaling Hosting on Amazon EC2</a></p>
<p>14 0.86464608 <a title="280-lda-14" href="../high_scalability-2008/high_scalability-2008-06-02-Total_Cost_of_Ownership_for_different_web_development_frameworks.html">338 high scalability-2008-06-02-Total Cost of Ownership for different web development frameworks</a></p>
<p>15 0.85037494 <a title="280-lda-15" href="../high_scalability-2010/high_scalability-2010-01-04-11_Strategies_to_Rock_Your_Startup%E2%80%99s_Scalability_in_2010.html">757 high scalability-2010-01-04-11 Strategies to Rock Your Startup’s Scalability in 2010</a></p>
<p>16 0.83297688 <a title="280-lda-16" href="../high_scalability-2010/high_scalability-2010-02-01-What_Will_Kill_the_Cloud%3F.html">768 high scalability-2010-02-01-What Will Kill the Cloud?</a></p>
<p>17 0.8265512 <a title="280-lda-17" href="../high_scalability-2010/high_scalability-2010-08-12-Think_of_Latency_as_a_Pseudo-permanent_Network_Partition.html">879 high scalability-2010-08-12-Think of Latency as a Pseudo-permanent Network Partition</a></p>
<p>18 0.81167001 <a title="280-lda-18" href="../high_scalability-2013/high_scalability-2013-07-17-How_do_you_create_a_100th_Monkey_software_development_culture%3F.html">1492 high scalability-2013-07-17-How do you create a 100th Monkey software development culture?</a></p>
<p>19 0.80384868 <a title="280-lda-19" href="../high_scalability-2007/high_scalability-2007-09-18-Session_management_in_highly_scalable_web_sites.html">97 high scalability-2007-09-18-Session management in highly scalable web sites</a></p>
<p>20 0.77835107 <a title="280-lda-20" href="../high_scalability-2009/high_scalability-2009-04-10-counting_%23_of_views%2C_calculating_most-least_viewed.html">564 high scalability-2009-04-10-counting # of views, calculating most-least viewed</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
