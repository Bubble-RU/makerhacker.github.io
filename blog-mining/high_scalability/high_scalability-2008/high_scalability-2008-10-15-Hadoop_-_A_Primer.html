<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>414 high scalability-2008-10-15-Hadoop - A Primer</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2008" href="../home/high_scalability-2008_home.html">high_scalability-2008</a> <a title="high_scalability-2008-414" href="#">high_scalability-2008-414</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>414 high scalability-2008-10-15-Hadoop - A Primer</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2008-414-html" href="http://highscalability.com//blog/2008/10/15/hadoop-a-primer.html">html</a></p><p>Introduction: Hadoop is a distributed computing platform written in Java. It incorporates
features similar to those of theGoogle File System and of MapReduce to process
vast amounts of data"Hadoop is a Free Java software framework that supports
data intensive distributed applications running on large clusters of commodity
computers. It enables applications to easily scale out to thousands of nodes
and petabytes of data" (Wikipedia)* What platform does Hadoop run on?* Java
1.5.x or higher, preferably from Sun* Linux* Windows for development* Solaris</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Hadoop is a distributed computing platform written in Java. [sent-1, score-0.476]
</p><p>2 It incorporates features similar to those of theGoogle File System and of MapReduce to process vast amounts of data"Hadoop is a Free Java software framework that supports data intensive distributed applications running on large clusters of commodity computers. [sent-2, score-2.043]
</p><p>3 It enables applications to easily scale out to thousands of nodes and petabytes of data" (Wikipedia)* What platform does Hadoop run on? [sent-3, score-1.061]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hadoop', 0.355), ('incorporates', 0.295), ('thegoogle', 0.287), ('preferably', 0.28), ('solaris', 0.259), ('wikipedia', 0.224), ('platform', 0.19), ('sun', 0.185), ('petabytes', 0.181), ('java', 0.177), ('vast', 0.169), ('intensive', 0.168), ('enables', 0.153), ('amounts', 0.149), ('windows', 0.148), ('commodity', 0.148), ('clusters', 0.133), ('mapreduce', 0.13), ('supports', 0.127), ('applications', 0.118), ('framework', 0.114), ('similar', 0.11), ('thousands', 0.109), ('linux', 0.108), ('distributed', 0.108), ('higher', 0.106), ('easily', 0.101), ('nodes', 0.098), ('written', 0.095), ('file', 0.087), ('free', 0.085), ('computing', 0.083), ('development', 0.082), ('data', 0.079), ('features', 0.077), ('process', 0.071), ('running', 0.066), ('run', 0.061), ('software', 0.057), ('large', 0.054), ('scale', 0.05), ('system', 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="414-tfidf-1" href="../high_scalability-2008/high_scalability-2008-10-15-Hadoop_-_A_Primer.html">414 high scalability-2008-10-15-Hadoop - A Primer</a></p>
<p>Introduction: Hadoop is a distributed computing platform written in Java. It incorporates
features similar to those of theGoogle File System and of MapReduce to process
vast amounts of data"Hadoop is a Free Java software framework that supports
data intensive distributed applications running on large clusters of commodity
computers. It enables applications to easily scale out to thousands of nodes
and petabytes of data" (Wikipedia)* What platform does Hadoop run on?* Java
1.5.x or higher, preferably from Sun* Linux* Windows for development* Solaris</p><p>2 0.25217238 <a title="414-tfidf-2" href="../high_scalability-2009/high_scalability-2009-05-17-Product%3A_Hadoop.html">601 high scalability-2009-05-17-Product: Hadoop</a></p>
<p>Introduction: Update 5:Hadoop Sorts a Petabyte in 16.25 Hours and a Terabyte in 62
Secondsand has itsgreen cred questionedbecause it took 40 times the number of
machines Greenplum used to do the same work.Update 4:Introduction to Pig. Pig
allows you to skip programming Hadoop at the low map-reduce level. You don't
have to know Java. Using the Pig Latin language, which is a scripting data
flow language, you can think about your problem as a data flow program. 10
lines of Pig Latin = 200 lines of Java.Update 3: Scaling Hadoop to4000 nodes
at Yahoo!. 30,000 cores with nearly 16PB of raw disk; sorted 6TB of data
completed in 37 minutes; 14,000 map tasks writes (reads) 360 MB (about 3
blocks) of data into a single file with a total of 5.04 TB for the whole
job.Update 2: HadoopSummit and Data-Intensive Computing Symposium Videos and
Slides. Topics include: Pig, JAQL, Hbase, Hive, Data-Intensive Scalable
Computing, Clouds and ManyCore: The Revolution, Simplicity and Complexity in
Data Systems at Scale, Han</p><p>3 0.22988829 <a title="414-tfidf-3" href="../high_scalability-2009/high_scalability-2009-05-11-Facebook%2C_Hadoop%2C_and_Hive.html">596 high scalability-2009-05-11-Facebook, Hadoop, and Hive</a></p>
<p>Introduction: Facebook has the second largest installation of Hadoop (a software platform
that lets one easily write and run applications that process vast amounts of
data), Yahoo being the first.Learn how they do it and what are the challenges
on DBMS2 blog, which is a blog for people who care about database and analytic
technologies.</p><p>4 0.21996839 <a title="414-tfidf-4" href="../high_scalability-2008/high_scalability-2008-12-01-Deploying_MySQL_Database_in_Solaris_Cluster_Environments.html">454 high scalability-2008-12-01-Deploying MySQL Database in Solaris Cluster Environments</a></p>
<p>Introduction: MySQL™ database, an open source database, delivers high performance and
reliability while keeping costs low by eliminating licensing fees. The
Solaris™ Cluster product is an integrated hardware and software environment
that can be used to create highly-available data services. This article
explains how to deploy the MySQL database in a Solaris Cluster environment.
The article addresses the following topics:* "Advantages of Deploying MySQL
Database with Solaris Cluster" on page 1 discusses the benefits provided by a
Solaris Cluster deployment of the MySQL database.* "Overview of Solaris
Cluster" on page 2 provides a high-level description of the hardware and
software components of the Solaris Cluster.* "Installation and Configuration"
on page 8 explains the procedure for deploying the MySQL database on a Solaris
Cluster.This article assumes that readers have a basic understanding of
Solaris Cluster and MySQL database installation and administration.</p><p>5 0.19859016 <a title="414-tfidf-5" href="../high_scalability-2008/high_scalability-2008-09-28-Product%3A_Happy_%3D_Hadoop_%2B_Python.html">397 high scalability-2008-09-28-Product: Happy = Hadoop + Python</a></p>
<p>Introduction: Has a Java only Hadoop been getting you down? Now you can beHappy. Happy is
aframework for writing map-reduce programs for Hadoop using Jython. It files
off the sharp edges on Hadoop and makes writing map-reduce programs a breeze.
There's really no history yet on Happy, but I'm delighted at the idea of being
able to map-reduce inother languages. The more ways the better.From the
website:Happy is a framework that allows Hadoop jobs to be written and run in
Python 2.2 using Jython. It is aneasy way to write map-reduce programs for
Hadoop, and includes some new useful features as well.The current release
supports Hadoop 0.17.2.Map-reduce jobs in Happy are defined by sub-classing
happy.HappyJob and implementing amap(records, task) and reduce(key, values,
task) function. Then you create an instance of theclass, set the job
parameters (such as inputs and outputs) and call run().When you call run(),
Happy serializes your job instance and copies it and all accompanyinglibraries
out to the Hado</p><p>6 0.18673001 <a title="414-tfidf-6" href="../high_scalability-2009/high_scalability-2009-06-11-Yahoo%21_Distribution_of_Hadoop.html">627 high scalability-2009-06-11-Yahoo! Distribution of Hadoop</a></p>
<p>7 0.16344121 <a title="414-tfidf-7" href="../high_scalability-2011/high_scalability-2011-01-04-Map-Reduce_With_Ruby_Using_Hadoop.html">968 high scalability-2011-01-04-Map-Reduce With Ruby Using Hadoop</a></p>
<p>8 0.16295172 <a title="414-tfidf-8" href="../high_scalability-2008/high_scalability-2008-12-01-Web_Consolidation_on_the_Sun_Fire_T1000_using_Solaris_Containers__.html">458 high scalability-2008-12-01-Web Consolidation on the Sun Fire T1000 using Solaris Containers  </a></p>
<p>9 0.15679941 <a title="414-tfidf-9" href="../high_scalability-2011/high_scalability-2011-07-27-Making_Hadoop_1000x_Faster_for_Graph_Problems.html">1088 high scalability-2011-07-27-Making Hadoop 1000x Faster for Graph Problems</a></p>
<p>10 0.15031062 <a title="414-tfidf-10" href="../high_scalability-2008/high_scalability-2008-10-15-Need_help_with_your_Hadoop_deployment%3F_This_company_may_help%21.html">415 high scalability-2008-10-15-Need help with your Hadoop deployment? This company may help!</a></p>
<p>11 0.14986682 <a title="414-tfidf-11" href="../high_scalability-2008/high_scalability-2008-10-14-Implementing_the_Lustre_File_System_with_Sun_Storage%3A_High_Performance_Storage_for_High_Performance_Computing.html">411 high scalability-2008-10-14-Implementing the Lustre File System with Sun Storage: High Performance Storage for High Performance Computing</a></p>
<p>12 0.14640118 <a title="414-tfidf-12" href="../high_scalability-2009/high_scalability-2009-07-02-Product%3A_Hbase.html">650 high scalability-2009-07-02-Product: Hbase</a></p>
<p>13 0.14415415 <a title="414-tfidf-13" href="../high_scalability-2012/high_scalability-2012-08-28-Making_Hadoop_Run_Faster.html">1313 high scalability-2012-08-28-Making Hadoop Run Faster</a></p>
<p>14 0.13722414 <a title="414-tfidf-14" href="../high_scalability-2010/high_scalability-2010-07-20-Strategy%3A_Consider_When_a_Service_Starts_Billing_in_Your_Algorithm_Cost.html">862 high scalability-2010-07-20-Strategy: Consider When a Service Starts Billing in Your Algorithm Cost</a></p>
<p>15 0.13708298 <a title="414-tfidf-15" href="../high_scalability-2014/high_scalability-2014-01-07-Sponsored_Post%3A_Netflix%2C_Logentries%2C_Host_Color%2C_Booking%2C_Apple%2C_ScaleOut%2C_MongoDB%2C_BlueStripe%2C_AiScaler%2C_Aerospike%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1574 high scalability-2014-01-07-Sponsored Post: Netflix, Logentries, Host Color, Booking, Apple, ScaleOut, MongoDB, BlueStripe, AiScaler, Aerospike, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>16 0.13591669 <a title="414-tfidf-16" href="../high_scalability-2013/high_scalability-2013-12-24-Sponsored_Post%3A_Netflix%2C_Logentries%2C_Host_Color%2C_Booking%2C_Spokeo%2C_Apple%2C_ScaleOut%2C_MongoDB%2C_BlueStripe%2C_AiScaler%2C_Aerospike%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1569 high scalability-2013-12-24-Sponsored Post: Netflix, Logentries, Host Color, Booking, Spokeo, Apple, ScaleOut, MongoDB, BlueStripe, AiScaler, Aerospike, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>17 0.13444638 <a title="414-tfidf-17" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>18 0.13336812 <a title="414-tfidf-18" href="../high_scalability-2008/high_scalability-2008-12-03-Java_World_Interview_on_Scalability_and_Other_Java_Scalability_Secrets.html">459 high scalability-2008-12-03-Java World Interview on Scalability and Other Java Scalability Secrets</a></p>
<p>19 0.13227758 <a title="414-tfidf-19" href="../high_scalability-2008/high_scalability-2008-12-19-Gigaspaces_curbs_latency_outliers_with_Java_Real_Time.html">471 high scalability-2008-12-19-Gigaspaces curbs latency outliers with Java Real Time</a></p>
<p>20 0.12712516 <a title="414-tfidf-20" href="../high_scalability-2013/high_scalability-2013-12-10-Sponsored_Post%3A_Booking%2C_Spokeo%2C_Apple%2C_NuoDB%2C_ScaleOut%2C_MongoDB%2C_BlueStripe%2C_AiScaler%2C_Aerospike%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1562 high scalability-2013-12-10-Sponsored Post: Booking, Spokeo, Apple, NuoDB, ScaleOut, MongoDB, BlueStripe, AiScaler, Aerospike, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.149), (1, -0.014), (2, 0.037), (3, 0.081), (4, -0.009), (5, 0.094), (6, 0.122), (7, -0.062), (8, 0.067), (9, 0.266), (10, 0.039), (11, -0.013), (12, 0.186), (13, -0.046), (14, 0.081), (15, -0.056), (16, -0.06), (17, -0.038), (18, -0.042), (19, 0.049), (20, 0.037), (21, 0.009), (22, 0.126), (23, -0.026), (24, -0.032), (25, 0.047), (26, 0.13), (27, -0.023), (28, 0.033), (29, 0.008), (30, 0.031), (31, 0.123), (32, -0.015), (33, -0.036), (34, 0.006), (35, 0.013), (36, -0.097), (37, 0.02), (38, -0.016), (39, 0.012), (40, 0.028), (41, 0.012), (42, -0.112), (43, 0.017), (44, 0.034), (45, 0.028), (46, 0.063), (47, 0.035), (48, -0.065), (49, 0.03)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96134913 <a title="414-lsi-1" href="../high_scalability-2008/high_scalability-2008-10-15-Hadoop_-_A_Primer.html">414 high scalability-2008-10-15-Hadoop - A Primer</a></p>
<p>Introduction: Hadoop is a distributed computing platform written in Java. It incorporates
features similar to those of theGoogle File System and of MapReduce to process
vast amounts of data"Hadoop is a Free Java software framework that supports
data intensive distributed applications running on large clusters of commodity
computers. It enables applications to easily scale out to thousands of nodes
and petabytes of data" (Wikipedia)* What platform does Hadoop run on?* Java
1.5.x or higher, preferably from Sun* Linux* Windows for development* Solaris</p><p>2 0.7907114 <a title="414-lsi-2" href="../high_scalability-2011/high_scalability-2011-01-04-Map-Reduce_With_Ruby_Using_Hadoop.html">968 high scalability-2011-01-04-Map-Reduce With Ruby Using Hadoop</a></p>
<p>Introduction: A demonstration, with repeatable steps, of how to quickly fire-up a Hadoop
cluster on Amazon EC2, load data onto the HDFS (Hadoop Distributed File-
System), write map-reduce scripts in Ruby and use them to run a map-reduce job
on your Hadoop cluster. You willnotneed to ssh into the cluster, as all tasks
are run from your local machine. Below I am using my MacBook Pro as my local
machine, but the steps I have provided should be reproducible on other
platforms running bash and Java.Fire-Up Your Hadoop ClusterI choose
theCloudera distribution of Hadoopwhich is still 100% Apache licensed, but has
some additional benefits. One of these benefits is that it is released byDoug
Cutting, who started Hadoop and drove it’s development at Yahoo! He also
startedLucene, which is another of my favourite Apache Projects, so I have
good faith that he knows what he is doing. Another benefit, as you will see,
is that it is simple to fire-up a Hadoop cluster.I am going to use
Cloudera’sWhirr script, which</p><p>3 0.76929313 <a title="414-lsi-3" href="../high_scalability-2008/high_scalability-2008-09-28-Product%3A_Happy_%3D_Hadoop_%2B_Python.html">397 high scalability-2008-09-28-Product: Happy = Hadoop + Python</a></p>
<p>Introduction: Has a Java only Hadoop been getting you down? Now you can beHappy. Happy is
aframework for writing map-reduce programs for Hadoop using Jython. It files
off the sharp edges on Hadoop and makes writing map-reduce programs a breeze.
There's really no history yet on Happy, but I'm delighted at the idea of being
able to map-reduce inother languages. The more ways the better.From the
website:Happy is a framework that allows Hadoop jobs to be written and run in
Python 2.2 using Jython. It is aneasy way to write map-reduce programs for
Hadoop, and includes some new useful features as well.The current release
supports Hadoop 0.17.2.Map-reduce jobs in Happy are defined by sub-classing
happy.HappyJob and implementing amap(records, task) and reduce(key, values,
task) function. Then you create an instance of theclass, set the job
parameters (such as inputs and outputs) and call run().When you call run(),
Happy serializes your job instance and copies it and all accompanyinglibraries
out to the Hado</p><p>4 0.74346226 <a title="414-lsi-4" href="../high_scalability-2009/high_scalability-2009-05-17-Product%3A_Hadoop.html">601 high scalability-2009-05-17-Product: Hadoop</a></p>
<p>Introduction: Update 5:Hadoop Sorts a Petabyte in 16.25 Hours and a Terabyte in 62
Secondsand has itsgreen cred questionedbecause it took 40 times the number of
machines Greenplum used to do the same work.Update 4:Introduction to Pig. Pig
allows you to skip programming Hadoop at the low map-reduce level. You don't
have to know Java. Using the Pig Latin language, which is a scripting data
flow language, you can think about your problem as a data flow program. 10
lines of Pig Latin = 200 lines of Java.Update 3: Scaling Hadoop to4000 nodes
at Yahoo!. 30,000 cores with nearly 16PB of raw disk; sorted 6TB of data
completed in 37 minutes; 14,000 map tasks writes (reads) 360 MB (about 3
blocks) of data into a single file with a total of 5.04 TB for the whole
job.Update 2: HadoopSummit and Data-Intensive Computing Symposium Videos and
Slides. Topics include: Pig, JAQL, Hbase, Hive, Data-Intensive Scalable
Computing, Clouds and ManyCore: The Revolution, Simplicity and Complexity in
Data Systems at Scale, Han</p><p>5 0.72525078 <a title="414-lsi-5" href="../high_scalability-2008/high_scalability-2008-11-14-Paper%3A_Pig_Latin%3A_A_Not-So-Foreign_Language_for_Data_Processing.html">443 high scalability-2008-11-14-Paper: Pig Latin: A Not-So-Foreign Language for Data Processing</a></p>
<p>Introduction: Yahoo has developed a new language called Pig Latin that fit in a sweet spot
between high-level declarative querying in the spirit of SQL, and low-level,
procedural programming `a la map-reduce and combines best of both worlds.The
accompanying system, Pig, is fully implemented, and compiles Pig Latin into
physical plans that are executed over Hadoop, an open-source, map-reduce
implementation. Pig has just graduated from the Apache Incubator and joined
Hadoop as a subproject.The paper has a few examples of how engineers at Yahoo!
are using Pig to dramatically reduce the time required for the development and
execution of their data analysis tasks, compared tousing Hadoop
directly.References:Apache Pig Wiki</p><p>6 0.7234717 <a title="414-lsi-6" href="../high_scalability-2009/high_scalability-2009-06-11-Yahoo%21_Distribution_of_Hadoop.html">627 high scalability-2009-06-11-Yahoo! Distribution of Hadoop</a></p>
<p>7 0.66814387 <a title="414-lsi-7" href="../high_scalability-2009/high_scalability-2009-08-03-Building_a_Data_Intensive_Web_Application_with_Cloudera%2C_Hadoop%2C_Hive%2C_Pig%2C_and_EC2.html">669 high scalability-2009-08-03-Building a Data Intensive Web Application with Cloudera, Hadoop, Hive, Pig, and EC2</a></p>
<p>8 0.65090632 <a title="414-lsi-8" href="../high_scalability-2009/high_scalability-2009-07-02-Product%3A_Hbase.html">650 high scalability-2009-07-02-Product: Hbase</a></p>
<p>9 0.63350427 <a title="414-lsi-9" href="../high_scalability-2008/high_scalability-2008-10-15-Need_help_with_your_Hadoop_deployment%3F_This_company_may_help%21.html">415 high scalability-2008-10-15-Need help with your Hadoop deployment? This company may help!</a></p>
<p>10 0.63179624 <a title="414-lsi-10" href="../high_scalability-2013/high_scalability-2013-04-24-Strategy%3A_Using_Lots_of_RAM_Often_Cheaper_than_Using_a_Hadoop_Cluster.html">1445 high scalability-2013-04-24-Strategy: Using Lots of RAM Often Cheaper than Using a Hadoop Cluster</a></p>
<p>11 0.61827755 <a title="414-lsi-11" href="../high_scalability-2010/high_scalability-2010-07-20-Strategy%3A_Consider_When_a_Service_Starts_Billing_in_Your_Algorithm_Cost.html">862 high scalability-2010-07-20-Strategy: Consider When a Service Starts Billing in Your Algorithm Cost</a></p>
<p>12 0.60658288 <a title="414-lsi-12" href="../high_scalability-2008/high_scalability-2008-02-19-Hadoop_Getting_Closer_to_1.0_Release.html">254 high scalability-2008-02-19-Hadoop Getting Closer to 1.0 Release</a></p>
<p>13 0.59758788 <a title="414-lsi-13" href="../high_scalability-2008/high_scalability-2008-09-03-MapReduce_framework_Disco.html">376 high scalability-2008-09-03-MapReduce framework Disco</a></p>
<p>14 0.59249258 <a title="414-lsi-14" href="../high_scalability-2009/high_scalability-2009-05-11-Facebook%2C_Hadoop%2C_and_Hive.html">596 high scalability-2009-05-11-Facebook, Hadoop, and Hive</a></p>
<p>15 0.59160233 <a title="414-lsi-15" href="../high_scalability-2012/high_scalability-2012-08-28-Making_Hadoop_Run_Faster.html">1313 high scalability-2012-08-28-Making Hadoop Run Faster</a></p>
<p>16 0.58993447 <a title="414-lsi-16" href="../high_scalability-2011/high_scalability-2011-07-08-Stuff_The_Internet_Says_On_Scalability_For_July_8%2C_2011.html">1076 high scalability-2011-07-08-Stuff The Internet Says On Scalability For July 8, 2011</a></p>
<p>17 0.57586795 <a title="414-lsi-17" href="../high_scalability-2012/high_scalability-2012-01-12-Peregrine_-_A_Map_Reduce_Framework_for_Iterative_and_Pipelined_Jobs.html">1173 high scalability-2012-01-12-Peregrine - A Map Reduce Framework for Iterative and Pipelined Jobs</a></p>
<p>18 0.56659853 <a title="414-lsi-18" href="../high_scalability-2012/high_scalability-2012-06-15-Stuff_The_Internet_Says_On_Scalability_For_June_15%2C_2012.html">1265 high scalability-2012-06-15-Stuff The Internet Says On Scalability For June 15, 2012</a></p>
<p>19 0.56010032 <a title="414-lsi-19" href="../high_scalability-2008/high_scalability-2008-10-14-Implementing_the_Lustre_File_System_with_Sun_Storage%3A_High_Performance_Storage_for_High_Performance_Computing.html">411 high scalability-2008-10-14-Implementing the Lustre File System with Sun Storage: High Performance Storage for High Performance Computing</a></p>
<p>20 0.55235744 <a title="414-lsi-20" href="../high_scalability-2013/high_scalability-2013-09-05-Paper%3A_MillWheel%3A_Fault-Tolerant_Stream_Processing_at_Internet_Scale.html">1512 high scalability-2013-09-05-Paper: MillWheel: Fault-Tolerant Stream Processing at Internet Scale</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.15), (2, 0.137), (15, 0.215), (61, 0.043), (79, 0.243), (94, 0.072)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.8917678 <a title="414-lda-1" href="../high_scalability-2008/high_scalability-2008-10-15-Hadoop_-_A_Primer.html">414 high scalability-2008-10-15-Hadoop - A Primer</a></p>
<p>Introduction: Hadoop is a distributed computing platform written in Java. It incorporates
features similar to those of theGoogle File System and of MapReduce to process
vast amounts of data"Hadoop is a Free Java software framework that supports
data intensive distributed applications running on large clusters of commodity
computers. It enables applications to easily scale out to thousands of nodes
and petabytes of data" (Wikipedia)* What platform does Hadoop run on?* Java
1.5.x or higher, preferably from Sun* Linux* Windows for development* Solaris</p><p>2 0.85346931 <a title="414-lda-2" href="../high_scalability-2008/high_scalability-2008-08-11-Distributed__Computing_%26_Google_Infrastructure.html">362 high scalability-2008-08-11-Distributed  Computing & Google Infrastructure</a></p>
<p>Introduction: A couple of videos about distributed computing with direct reference on Google
infrastructure.You will get acquainted with:--MapReduce the software framework
implemented by Google to support parallel computations over large (greater
than 100 terabyte) data sets on commodity hardware--GFS and the way it stores
it's data into 64mb chunks--Bigtable which is the simple implementation of a
non-relational database at GoogleCluster Computing and MapReduce Lectures 1-5.</p><p>3 0.81743217 <a title="414-lda-3" href="../high_scalability-2009/high_scalability-2009-08-13-Reconnoiter_-_Large-Scale_Trending_and_Fault-Detection.html">680 high scalability-2009-08-13-Reconnoiter - Large-Scale Trending and Fault-Detection</a></p>
<p>Introduction: One of the top recommendations from the collective wisdom contained inReal
Life Architecturesis to addmonitoringto your system. Now! Loud is the lament
for not adding monitoring early and often. The reason is easy to understand.
Without monitoring you don't know what your system is doing which means you
can't fix it and you can't improve it. Feedback loops require data.Some
popular monitor options are Munin, Nagios, Cacti and Hyperic. A relatively new
entrant is a product called Reconnoiter from Theo Schlossnagle, President and
CEO of OmniTI, leading consultants on solving problems of scalability,
performance, architecture, infrastructure, and data management. Theo's name
might sound familiar. He gives lots of talks and is the author of the very
influentialScalable Internet Architecturesbook.So right away you know
Reconnoiter has a good pedigree. As Theo says, their products are born of
pain, from the fire of solving real-life problems and that's always a
harbinger of good things to co</p><p>4 0.81596202 <a title="414-lda-4" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>Introduction: Update 2:Sorting 1 PB with MapReduce. PB is not peanut-butter-and-jelly
misspelled. It's 1 petabyte or 1000 terabytes or 1,000,000 gigabytes.It took
six hours and two minutes to sort 1PB (10 trillion 100-byte records) on 4,000
computersand the results were replicated thrice on 48,000 disks.Update:Greg
Lindenpoints to a new Google articleMapReduce: simplified data processing on
large clusters. Some interesting stats: 100k MapReduce jobs are executed each
day; more than 20 petabytes of data are processed per day; more than 10k
MapReduce programs have been implemented; machines are dual processor with
gigabit ethernet and 4-8 GB of memory.Google is the King of scalability.
Everyone knows Google for their large, sophisticated, and fast searching, but
they don't just shine in search. Their platform approach to building scalable
applications allows them to roll out internet scale applications at an
alarmingly high competition crushing rate. Their goal is always to build a
higher performing h</p><p>5 0.81482595 <a title="414-lda-5" href="../high_scalability-2013/high_scalability-2013-09-05-Paper%3A_MillWheel%3A_Fault-Tolerant_Stream_Processing_at_Internet_Scale.html">1512 high scalability-2013-09-05-Paper: MillWheel: Fault-Tolerant Stream Processing at Internet Scale</a></p>
<p>Introduction: Ever wonder what powers Google's world spirit sensing Zeitgeist service? No,
it's not a homunculus ofGeorg Wilhelm Friedrich Hegel sitting in each browser.
It's actually a stream processing (think streaming MapReduce on steroids)
system called MillWheel, described in this very well written paper: MillWheel:
Fault-Tolerant Stream Processing at Internet Scale. MillWheel isn't just used
for Zeitgeist at Google, it's also used for streaming joins for a variety of
Ads customers, generalized anomaly-detection service, and network switch and
cluster health monitoring.Abstract:MillWheel is a framework for building low-
latency data-processing applications that is widely used at Google. Users
specify a directed computation graph and application code for individual
nodes, and the system manages persistent state and the continuous ďŹ&sbquo;ow of
records, all within the envelope of the framework's fault-tolerance
guarantees. This paper describes MillWheel's programming model as well as its
implementation.</p><p>6 0.81249958 <a title="414-lda-6" href="../high_scalability-2007/high_scalability-2007-09-08-Making_the_case_for_PHP_at_Yahoo%21_%28Oct_2002%29.html">85 high scalability-2007-09-08-Making the case for PHP at Yahoo! (Oct 2002)</a></p>
<p>7 0.81100661 <a title="414-lda-7" href="../high_scalability-2009/high_scalability-2009-07-02-Product%3A_Hbase.html">650 high scalability-2009-07-02-Product: Hbase</a></p>
<p>8 0.80993593 <a title="414-lda-8" href="../high_scalability-2013/high_scalability-2013-03-08-Stuff_The_Internet_Says_On_Scalability_For_March_8%2C_2013.html">1420 high scalability-2013-03-08-Stuff The Internet Says On Scalability For March 8, 2013</a></p>
<p>9 0.80863452 <a title="414-lda-9" href="../high_scalability-2013/high_scalability-2013-02-08-Stuff_The_Internet_Says_On_Scalability_For_February_8%2C_2013.html">1403 high scalability-2013-02-08-Stuff The Internet Says On Scalability For February 8, 2013</a></p>
<p>10 0.8065691 <a title="414-lda-10" href="../high_scalability-2010/high_scalability-2010-03-02-Using_the_Ambient_Cloud_as_an_Application_Runtime.html">786 high scalability-2010-03-02-Using the Ambient Cloud as an Application Runtime</a></p>
<p>11 0.80587775 <a title="414-lda-11" href="../high_scalability-2010/high_scalability-2010-08-04-Dremel%3A_Interactive_Analysis_of_Web-Scale_Datasets_-_Data_as_a_Programming_Paradigm.html">871 high scalability-2010-08-04-Dremel: Interactive Analysis of Web-Scale Datasets - Data as a Programming Paradigm</a></p>
<p>12 0.80448365 <a title="414-lda-12" href="../high_scalability-2013/high_scalability-2013-07-19-Stuff_The_Internet_Says_On_Scalability_For_July_19%2C_2013.html">1494 high scalability-2013-07-19-Stuff The Internet Says On Scalability For July 19, 2013</a></p>
<p>13 0.80189055 <a title="414-lda-13" href="../high_scalability-2008/high_scalability-2008-09-05-Product%3A_Tungsten_Replicator.html">380 high scalability-2008-09-05-Product: Tungsten Replicator</a></p>
<p>14 0.80049145 <a title="414-lda-14" href="../high_scalability-2010/high_scalability-2010-02-25-Paper%3A_High_Performance_Scalable_Data_Stores_.html">784 high scalability-2010-02-25-Paper: High Performance Scalable Data Stores </a></p>
<p>15 0.79825902 <a title="414-lda-15" href="../high_scalability-2009/high_scalability-2009-09-16-The_VeriScale_Architecture_-_Elasticity_and_efficiency_for_private_clouds.html">706 high scalability-2009-09-16-The VeriScale Architecture - Elasticity and efficiency for private clouds</a></p>
<p>16 0.79497045 <a title="414-lda-16" href="../high_scalability-2013/high_scalability-2013-07-01-PRISM%3A_The_Amazingly_Low_Cost_of_%C2%ADUsing_BigData_to_Know_More_About_You_in_Under_a_Minute.html">1485 high scalability-2013-07-01-PRISM: The Amazingly Low Cost of ­Using BigData to Know More About You in Under a Minute</a></p>
<p>17 0.79458946 <a title="414-lda-17" href="../high_scalability-2009/high_scalability-2009-04-26-Map-Reduce_for_Machine_Learning_on_Multicore.html">581 high scalability-2009-04-26-Map-Reduce for Machine Learning on Multicore</a></p>
<p>18 0.78925186 <a title="414-lda-18" href="../high_scalability-2012/high_scalability-2012-07-05-10_Golden_Principles_For_Building_Successful_Mobile-Web_Applications.html">1277 high scalability-2012-07-05-10 Golden Principles For Building Successful Mobile-Web Applications</a></p>
<p>19 0.78657836 <a title="414-lda-19" href="../high_scalability-2012/high_scalability-2012-10-18-Save_up_to_30%25_by_Selecting_Better_Performing_Amazon_Instances.html">1343 high scalability-2012-10-18-Save up to 30% by Selecting Better Performing Amazon Instances</a></p>
<p>20 0.78432024 <a title="414-lda-20" href="../high_scalability-2011/high_scalability-2011-02-24-Strategy%3A_Eliminate_Unnecessary_SQL.html">995 high scalability-2011-02-24-Strategy: Eliminate Unnecessary SQL</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
