<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>246 high scalability-2008-02-12-Search the tags across all post</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2008" href="../home/high_scalability-2008_home.html">high_scalability-2008</a> <a title="high_scalability-2008-246" href="#">high_scalability-2008-246</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>246 high scalability-2008-02-12-Search the tags across all post</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2008-246-html" href="http://highscalability.com//blog/2008/2/13/search-the-tags-across-all-post.html">html</a></p><p>Introduction: Let suppose i have table which stored tags .Now user can enter keywords and i have to search through all the records in table and find post which contain tags entered by user .user can enter more than 1 keywords.   What strategy ,technique i use to search fast .There maybe more than millions records and many users are firing same query.   Thanks</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Now user can enter keywords and i have to search through all the records in table and find post which contain tags entered by user . [sent-2, score-2.72]
</p><p>2 What strategy ,technique i use to search fast . [sent-4, score-0.39]
</p><p>3 There maybe more than millions records and many users are firing same query. [sent-5, score-0.938]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tags', 0.453), ('enter', 0.41), ('records', 0.31), ('firing', 0.294), ('keywords', 0.286), ('suppose', 0.286), ('entered', 0.246), ('table', 0.243), ('search', 0.187), ('contain', 0.179), ('user', 0.13), ('maybe', 0.126), ('strategy', 0.108), ('stored', 0.103), ('millions', 0.103), ('let', 0.081), ('find', 0.075), ('post', 0.071), ('fast', 0.064), ('users', 0.06), ('many', 0.045), ('use', 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="246-tfidf-1" href="../high_scalability-2008/high_scalability-2008-02-12-Search_the_tags_across_all_post.html">246 high scalability-2008-02-12-Search the tags across all post</a></p>
<p>Introduction: Let suppose i have table which stored tags .Now user can enter keywords and i have to search through all the records in table and find post which contain tags entered by user .user can enter more than 1 keywords.   What strategy ,technique i use to search fast .There maybe more than millions records and many users are firing same query.   Thanks</p><p>2 0.14443873 <a title="246-tfidf-2" href="../high_scalability-2008/high_scalability-2008-06-08-Search_fast_in_million_rows.html">342 high scalability-2008-06-08-Search fast in million rows</a></p>
<p>Introduction: I have a table .This table has many columns but search  performed based on 1 columns ,this table can have more than million rows.   The data in these columns is something like funny,new york,hollywood   User can search with parameters as funny hollywood .I need to take this 2 words and then search on column whether that column contain this words and how many times .It is not possible to index here .If the results return say 1200 results then without comparing each and every column i can't determine no of results.I need to compare for each and every column.This query is very frequent .How can i approach for this problem.What type of architecture,tools is helpful.   I just know that this can be accomplished with distributed system but how can i make this system. I also see in this website that LinkedIn uses Lucene for search .Is Lucene is helpful in my case.My table has also lots of insertion ,however updation in not very frequent.</p><p>3 0.12133002 <a title="246-tfidf-3" href="../high_scalability-2010/high_scalability-2010-07-12-Creating_Scalable_Digital_Libraries.html">856 high scalability-2010-07-12-Creating Scalable Digital Libraries</a></p>
<p>Introduction: Like many other media content providers, libraries and museums are increasingly moving their content onto the Web.  While the move itself is no easy process (with digitization, web development, and training costs), being able to successfully deliver content to a wide audience is an ongoing concern, particularly for large libraries.
 
Much of the concern is financial, as most libraries do not have the internal budget or outside investors that for-profit businesses enjoy.  Even large university libraries will face serious budget constraints that even other university departments, such as science and technology would not face.
 
Creating a scalable infrastructure and also distributing a large digital collection that can handle multiple requests, requires planning that many librarians have not even imagined.  They must stop thinking in terms of "one-item-per-customer" and start thinking in terms of numerous users accessing the same information simultaneously.
 
 Content Delivery Network</p><p>4 0.099591479 <a title="246-tfidf-4" href="../high_scalability-2008/high_scalability-2008-05-28-Job_queue_and_search_engine.html">332 high scalability-2008-05-28-Job queue and search engine</a></p>
<p>Introduction: Hi,     I want to implement a search engine with lucene.   To be scalable, I would like to execute search jobs asynchronously (with a job queuing system).     But i don't know if it is a good design... Why ?     Search results can be large ! (eg: 100+ pages  with 25 documents per page)   With asynchronous sytem, I need to store results for each search job.   I can set a short expiration time (~5 min) for each search result, but it's still large.     What do you think about it ?   Which design would you use for that ?       Thanks   Mat</p><p>5 0.091172457 <a title="246-tfidf-5" href="../high_scalability-2009/high_scalability-2009-09-16-Paper%3A_A_practical_scalable_distributed_B-tree.html">705 high scalability-2009-09-16-Paper: A practical scalable distributed B-tree</a></p>
<p>Introduction: We've seen a lot of  NoSQL  action lately built around distributed hash tables. Btrees are getting jealous. Btrees, once the king of the database world, want their throne back.  Paul Buchheit  surfaced a paper:  A practical scalable distributed B-tree  by Marcos K. Aguilera and Wojciech Golab, that might help spark a revolution.  From the Abstract:
   We propose a new algorithm for a practical, fault tolerant, and scalable B-tree distributed over a set of servers. Our algorithm supports practical features not present in prior work: transactions that allow atomic execution of multiple operations over multiple B-trees, online migration of B-tree nodes between servers, and dynamic addition and removal of servers. Moreover, our algorithm is conceptually simple: we use transactions to manipulate B-tree nodes so that clients need not use complicated concurrency and locking protocols used in prior work. To execute these transactions quickly, we rely on three techniques: (1) We use optimistic</p><p>6 0.088356748 <a title="246-tfidf-6" href="../high_scalability-2009/high_scalability-2009-03-16-Cisco_and_Sun_to_Compete_for_Unified_Computing%3F.html">540 high scalability-2009-03-16-Cisco and Sun to Compete for Unified Computing?</a></p>
<p>7 0.081448749 <a title="246-tfidf-7" href="../high_scalability-2009/high_scalability-2009-11-26-Kngine_Snippet_Search_New_Indexing_Technology.html">746 high scalability-2009-11-26-Kngine Snippet Search New Indexing Technology</a></p>
<p>8 0.076999187 <a title="246-tfidf-8" href="../high_scalability-2007/high_scalability-2007-11-13-Flickr_Architecture.html">152 high scalability-2007-11-13-Flickr Architecture</a></p>
<p>9 0.076405339 <a title="246-tfidf-9" href="../high_scalability-2009/high_scalability-2009-02-14-Scaling_Digg_and_Other_Web_Applications.html">512 high scalability-2009-02-14-Scaling Digg and Other Web Applications</a></p>
<p>10 0.074204817 <a title="246-tfidf-10" href="../high_scalability-2009/high_scalability-2009-08-08-Yahoo%21%27s_PNUTS_Database%3A_Too_Hot%2C_Too_Cold_or_Just_Right%3F.html">676 high scalability-2009-08-08-Yahoo!'s PNUTS Database: Too Hot, Too Cold or Just Right?</a></p>
<p>11 0.071870998 <a title="246-tfidf-11" href="../high_scalability-2008/high_scalability-2008-04-10-Mysql_scalability_and_failover....html">302 high scalability-2008-04-10-Mysql scalability and failover...</a></p>
<p>12 0.071476899 <a title="246-tfidf-12" href="../high_scalability-2010/high_scalability-2010-05-20-Strategy%3A_Scale_Writes_to_734_Million_Records_Per_Day_Using_Time_Partitioning.html">829 high scalability-2010-05-20-Strategy: Scale Writes to 734 Million Records Per Day Using Time Partitioning</a></p>
<p>13 0.066355146 <a title="246-tfidf-13" href="../high_scalability-2009/high_scalability-2009-11-06-Product%3A_Resque_-_GitHub%27s_Distrubuted_Job_Queue.html">738 high scalability-2009-11-06-Product: Resque - GitHub's Distrubuted Job Queue</a></p>
<p>14 0.065617099 <a title="246-tfidf-14" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>15 0.063518718 <a title="246-tfidf-15" href="../high_scalability-2009/high_scalability-2009-10-28-And_the_winner_is%3A_MySQL_or_Memcached_or_Tokyo_Tyrant%3F.html">729 high scalability-2009-10-28-And the winner is: MySQL or Memcached or Tokyo Tyrant?</a></p>
<p>16 0.06328252 <a title="246-tfidf-16" href="../high_scalability-2009/high_scalability-2009-03-19-Product%3A_Redis_-_Not_Just_Another_Key-Value_Store.html">545 high scalability-2009-03-19-Product: Redis - Not Just Another Key-Value Store</a></p>
<p>17 0.062344681 <a title="246-tfidf-17" href="../high_scalability-2009/high_scalability-2009-06-10-Dealing_with_multi-partition_transactions_in_a_distributed_KV_solution.html">623 high scalability-2009-06-10-Dealing with multi-partition transactions in a distributed KV solution</a></p>
<p>18 0.061217405 <a title="246-tfidf-18" href="../high_scalability-2013/high_scalability-2013-04-15-Scaling_Pinterest_-_From_0_to_10s_of_Billions_of_Page_Views_a_Month_in_Two_Years.html">1440 high scalability-2013-04-15-Scaling Pinterest - From 0 to 10s of Billions of Page Views a Month in Two Years</a></p>
<p>19 0.061064567 <a title="246-tfidf-19" href="../high_scalability-2008/high_scalability-2008-09-04-Database_question_for_upcoming_project.html">379 high scalability-2008-09-04-Database question for upcoming project</a></p>
<p>20 0.059167434 <a title="246-tfidf-20" href="../high_scalability-2008/high_scalability-2008-03-08-Audiogalaxy.com_Architecture.html">269 high scalability-2008-03-08-Audiogalaxy.com Architecture</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.056), (1, 0.037), (2, -0.011), (3, -0.054), (4, 0.011), (5, 0.017), (6, -0.009), (7, 0.014), (8, 0.045), (9, -0.001), (10, 0.014), (11, 0.04), (12, -0.036), (13, -0.002), (14, 0.03), (15, 0.029), (16, -0.074), (17, -0.007), (18, 0.045), (19, -0.013), (20, 0.028), (21, -0.06), (22, -0.009), (23, 0.029), (24, -0.027), (25, -0.02), (26, -0.056), (27, 0.004), (28, 0.017), (29, 0.06), (30, -0.03), (31, -0.006), (32, -0.043), (33, 0.031), (34, 0.066), (35, -0.011), (36, 0.008), (37, -0.002), (38, -0.037), (39, -0.052), (40, 0.075), (41, 0.01), (42, -0.033), (43, 0.017), (44, -0.025), (45, 0.037), (46, 0.007), (47, 0.015), (48, 0.004), (49, 0.019)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98063409 <a title="246-lsi-1" href="../high_scalability-2008/high_scalability-2008-02-12-Search_the_tags_across_all_post.html">246 high scalability-2008-02-12-Search the tags across all post</a></p>
<p>Introduction: Let suppose i have table which stored tags .Now user can enter keywords and i have to search through all the records in table and find post which contain tags entered by user .user can enter more than 1 keywords.   What strategy ,technique i use to search fast .There maybe more than millions records and many users are firing same query.   Thanks</p><p>2 0.8757872 <a title="246-lsi-2" href="../high_scalability-2008/high_scalability-2008-06-08-Search_fast_in_million_rows.html">342 high scalability-2008-06-08-Search fast in million rows</a></p>
<p>Introduction: I have a table .This table has many columns but search  performed based on 1 columns ,this table can have more than million rows.   The data in these columns is something like funny,new york,hollywood   User can search with parameters as funny hollywood .I need to take this 2 words and then search on column whether that column contain this words and how many times .It is not possible to index here .If the results return say 1200 results then without comparing each and every column i can't determine no of results.I need to compare for each and every column.This query is very frequent .How can i approach for this problem.What type of architecture,tools is helpful.   I just know that this can be accomplished with distributed system but how can i make this system. I also see in this website that LinkedIn uses Lucene for search .Is Lucene is helpful in my case.My table has also lots of insertion ,however updation in not very frequent.</p><p>3 0.8002941 <a title="246-lsi-3" href="../high_scalability-2008/high_scalability-2008-02-24-Yandex_Architecture.html">258 high scalability-2008-02-24-Yandex Architecture</a></p>
<p>Introduction: Update:   Anatomy of a crash in a new part of Yandex written in Django . Writing to a magic session variable caused an unexpected write into an InnoDB database on every request. Writes took 6-7 seconds because of index rebuilding. Lots of useful details on the sizing of their system, what went wrong, and how they fixed it.   Yandex is a Russian search engine with 3.5 billion pages in their search index. We only know a few fun facts about how they do things, nothing at a detailed architecture level. Hopefully we'll learn more later, but I thought it would still be interesting. From Allen Stern's interview with Yandex's CTO Ilya Segalovich, we learn:
   3.5 billion pages in the search index.    Over several thousand servers.    35 million searches a day.    Several data centers around Russia.    Two-layer architecture.    The database is split in pieces and when a search is requested, it pulls the bits from the different database servers and brings it together for the user.    Languages</p><p>4 0.79970694 <a title="246-lsi-4" href="../high_scalability-2009/high_scalability-2009-06-14-kngine_%27Knowledge_Engine%27_milestone_2.html">630 high scalability-2009-06-14-kngine 'Knowledge Engine' milestone 2</a></p>
<p>Introduction: Kngine is Knowledge Web search engine designed to provide meaningful search results, such as: semantic information about the keywords/concepts, answer the user’s questions, discover the relations between the keywords/concepts, and link the different kind of data together, such as: Movies, Subtitles, Photos, Price at sale store, User reviews, and Influenced story    Goals  
Kngine long-term goal is to make all human beings systematic knowledge and experience accessible to everyone. I aim to collect and organize all objective data, and make it possible and easy to access. Our goal is to build on the advances of Web search engine, semantic web, data representation technologies a new form of Web search engine that will unleash a revolution of new possibilities.  Kngine tries to combine the power of Web search engines with the power of Semantic search and the data representation to provide meaningful search results compromising user needs.
  Status  
Kngine starts as a research project in O</p><p>5 0.79205406 <a title="246-lsi-5" href="../high_scalability-2008/high_scalability-2008-05-28-Job_queue_and_search_engine.html">332 high scalability-2008-05-28-Job queue and search engine</a></p>
<p>Introduction: Hi,     I want to implement a search engine with lucene.   To be scalable, I would like to execute search jobs asynchronously (with a job queuing system).     But i don't know if it is a good design... Why ?     Search results can be large ! (eg: 100+ pages  with 25 documents per page)   With asynchronous sytem, I need to store results for each search job.   I can set a short expiration time (~5 min) for each search result, but it's still large.     What do you think about it ?   Which design would you use for that ?       Thanks   Mat</p><p>6 0.77712184 <a title="246-lsi-6" href="../high_scalability-2009/high_scalability-2009-11-26-Kngine_Snippet_Search_New_Indexing_Technology.html">746 high scalability-2009-11-26-Kngine Snippet Search New Indexing Technology</a></p>
<p>7 0.70870823 <a title="246-lsi-7" href="../high_scalability-2010/high_scalability-2010-02-10-ElasticSearch_-_Open_Source%2C_Distributed%2C_RESTful_Search_Engine.html">775 high scalability-2010-02-10-ElasticSearch - Open Source, Distributed, RESTful Search Engine</a></p>
<p>8 0.68224305 <a title="246-lsi-8" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>9 0.67143917 <a title="246-lsi-9" href="../high_scalability-2007/high_scalability-2007-08-10-How_do_we_make_a_large_real-time_search_engine%3F.html">64 high scalability-2007-08-10-How do we make a large real-time search engine?</a></p>
<p>10 0.65129495 <a title="246-lsi-10" href="../high_scalability-2008/high_scalability-2008-03-08-Audiogalaxy.com_Architecture.html">269 high scalability-2008-03-08-Audiogalaxy.com Architecture</a></p>
<p>11 0.6444 <a title="246-lsi-11" href="../high_scalability-2009/high_scalability-2009-04-23-Which_Key_value_pair_database_to_be_used.html">578 high scalability-2009-04-23-Which Key value pair database to be used</a></p>
<p>12 0.63462478 <a title="246-lsi-12" href="../high_scalability-2014/high_scalability-2014-02-25-Peter_Norvig%27s_9_Master_Steps_to_Improving_a_Program.html">1601 high scalability-2014-02-25-Peter Norvig's 9 Master Steps to Improving a Program</a></p>
<p>13 0.62540179 <a title="246-lsi-13" href="../high_scalability-2010/high_scalability-2010-09-09-How_did_Google_Instant_become_Faster_with_5-7X_More_Results_Pages%3F.html">899 high scalability-2010-09-09-How did Google Instant become Faster with 5-7X More Results Pages?</a></p>
<p>14 0.61558312 <a title="246-lsi-14" href="../high_scalability-2012/high_scalability-2012-05-28-The_Anatomy_of_Search_Technology%3A_Crawling_using_Combinators.html">1253 high scalability-2012-05-28-The Anatomy of Search Technology: Crawling using Combinators</a></p>
<p>15 0.60383517 <a title="246-lsi-15" href="../high_scalability-2010/high_scalability-2010-04-14-Parallel_Information_Retrieval_and_Other_Search_Engine_Goodness.html">810 high scalability-2010-04-14-Parallel Information Retrieval and Other Search Engine Goodness</a></p>
<p>16 0.59253943 <a title="246-lsi-16" href="../high_scalability-2012/high_scalability-2012-04-25-The_Anatomy_of_Search_Technology%3A_blekko%E2%80%99s_NoSQL_database.html">1233 high scalability-2012-04-25-The Anatomy of Search Technology: blekko’s NoSQL database</a></p>
<p>17 0.58805841 <a title="246-lsi-17" href="../high_scalability-2008/high_scalability-2008-03-18-Database_Design_101.html">281 high scalability-2008-03-18-Database Design 101</a></p>
<p>18 0.57780939 <a title="246-lsi-18" href="../high_scalability-2014/high_scalability-2014-05-19-A_Short_On_How_the_Wayback_Machine_Stores_More_Pages_than_Stars_in_the_Milky_Way.html">1650 high scalability-2014-05-19-A Short On How the Wayback Machine Stores More Pages than Stars in the Milky Way</a></p>
<p>19 0.56848872 <a title="246-lsi-19" href="../high_scalability-2012/high_scalability-2012-08-02-Ask_DuckDuckGo%3A_Is_there_Anything_you_Want_to_Know_About_DDG%3F.html">1295 high scalability-2012-08-02-Ask DuckDuckGo: Is there Anything you Want to Know About DDG?</a></p>
<p>20 0.56010443 <a title="246-lsi-20" href="../high_scalability-2010/high_scalability-2010-07-12-Creating_Scalable_Digital_Libraries.html">856 high scalability-2010-07-12-Creating Scalable Digital Libraries</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.171), (2, 0.028), (25, 0.537), (61, 0.068)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.90188724 <a title="246-lda-1" href="../high_scalability-2008/high_scalability-2008-02-12-Search_the_tags_across_all_post.html">246 high scalability-2008-02-12-Search the tags across all post</a></p>
<p>Introduction: Let suppose i have table which stored tags .Now user can enter keywords and i have to search through all the records in table and find post which contain tags entered by user .user can enter more than 1 keywords.   What strategy ,technique i use to search fast .There maybe more than millions records and many users are firing same query.   Thanks</p><p>2 0.66732466 <a title="246-lda-2" href="../high_scalability-2009/high_scalability-2009-03-20-Alternate_strategy_for_database_sharding.html">546 high scalability-2009-03-20-Alternate strategy for database sharding</a></p>
<p>Introduction: An alternate strategy for database sharding which avoids queries across different shards and merging results. A central repository of data is maintained for some tables along with other shards. Can be used in calculating top users, recent users, most read etc.</p><p>3 0.65611303 <a title="246-lda-3" href="../high_scalability-2008/high_scalability-2008-10-10-Useful_Corporate_Blogs_that_Talk_About_Scalability.html">408 high scalability-2008-10-10-Useful Corporate Blogs that Talk About Scalability</a></p>
<p>Introduction: Some intrepid company blogs are posting their technical challenges and how they solve them. I wish more would open up and talk about what they are doing as it helps everyone move forward. Here are a few blogs documenting their encounters with the bleeding edge:     Flickr    Digg    LinkedIn    Facebook    Amazon Web Services blog     Twitter blog     Reddit blog    Photobucket blog     Second Life blog     PlentyofFish blog     Joyent's Blog   Any others that should be added?</p><p>4 0.61535072 <a title="246-lda-4" href="../high_scalability-2008/high_scalability-2008-10-14-Sun_N1_Grid_Engine_Software_and_the_Tokyo_Institute_of_Technology_Super_Computer_Grid.html">412 high scalability-2008-10-14-Sun N1 Grid Engine Software and the Tokyo Institute of Technology Super Computer Grid</a></p>
<p>Introduction: One of the world's leading technical institutes, the Tokyo Institute of Technology (Tokyo Tech) created the fastest supercomputer in Asia, and one of the largest outside of the United States. Using Sun x64 servers and data servers deployed in a grid architecture, Tokyo Tech built a cost-effective, flexible supercomputer that meets the demands of compute- and data-intensive applications. Built in just 35 days, the TSUBAME grid includes hundreds of systems incorporating thousands of processor cores and terabytes of memory, and delivers 47.38 trillion1 floating-point operations per second (TeraFLOPS) of sustained LINPACK benchmark performance and 1.1 petabyte of storage to users running common off-the-shelf applications. Based on the deployment architecture, the grid is expected to reach 100 TeraFLOPS in the future. This Sun BluePrints article provides an overview of the Tokyo Tech grid, named TSUBAME. The third in a series of Sun BluePrints articles on the TSUBAME grid, this document pro</p><p>5 0.61344123 <a title="246-lda-5" href="../high_scalability-2008/high_scalability-2008-01-07-How_Ruby_on_Rails_Survived_a_550k_Pageview_Digging.html">203 high scalability-2008-01-07-How Ruby on Rails Survived a 550k Pageview Digging</a></p>
<p>Introduction: Shanti Braford  details how his Ruby on Rails  based website survived a 24 hour 550,000+ pageview digg attack. His post cleanly lays out all the juicy setup details, so there's not much I can add.   Hosting costs $370 a month for 1 web server, 1 database server, and sufficient bandwidth. The site is built on RoR, nginx, MySQL, and 7 mongrel servers. He thinks Rails 2.0 has improved performance and credits database avoidance and fragment caching for much of the performance boost.    Keep in mind his system is relatively static, but it's a very interesting and useful experience report.</p><p>6 0.6117996 <a title="246-lda-6" href="../high_scalability-2008/high_scalability-2008-10-15-The_Tokyo_Institute_of_Technology_Supercomputer_Grid%3A_Architecture_and_Performance_Overview.html">419 high scalability-2008-10-15-The Tokyo Institute of Technology Supercomputer Grid: Architecture and Performance Overview</a></p>
<p>7 0.45133939 <a title="246-lda-7" href="../high_scalability-2009/high_scalability-2009-04-15-Implementing_large_scale_web_analytics.html">570 high scalability-2009-04-15-Implementing large scale web analytics</a></p>
<p>8 0.38258079 <a title="246-lda-8" href="../high_scalability-2011/high_scalability-2011-02-18-Stuff_The_Internet_Says_On_Scalability_For_February_18%2C_2011.html">992 high scalability-2011-02-18-Stuff The Internet Says On Scalability For February 18, 2011</a></p>
<p>9 0.37210453 <a title="246-lda-9" href="../high_scalability-2008/high_scalability-2008-06-28-ID_generation_schemes.html">346 high scalability-2008-06-28-ID generation schemes</a></p>
<p>10 0.35687202 <a title="246-lda-10" href="../high_scalability-2008/high_scalability-2008-10-15-Tokyo_Tech_Tsubame_Grid_Storage_Implementation.html">420 high scalability-2008-10-15-Tokyo Tech Tsubame Grid Storage Implementation</a></p>
<p>11 0.34908813 <a title="246-lda-11" href="../high_scalability-2011/high_scalability-2011-02-10-Dispelling_the_New_SSL_Myth.html">987 high scalability-2011-02-10-Dispelling the New SSL Myth</a></p>
<p>12 0.34832174 <a title="246-lda-12" href="../high_scalability-2008/high_scalability-2008-02-19-Building_a_email_communication_system.html">253 high scalability-2008-02-19-Building a email communication system</a></p>
<p>13 0.3379617 <a title="246-lda-13" href="../high_scalability-2014/high_scalability-2014-03-07-Stuff_The_Internet_Says_On_Scalability_For_March_7th%2C_2014.html">1607 high scalability-2014-03-07-Stuff The Internet Says On Scalability For March 7th, 2014</a></p>
<p>14 0.32980853 <a title="246-lda-14" href="../high_scalability-2010/high_scalability-2010-02-03-NoSQL_Means_Never_Having_to_Store_Blobs_Again.html">770 high scalability-2010-02-03-NoSQL Means Never Having to Store Blobs Again</a></p>
<p>15 0.32709309 <a title="246-lda-15" href="../high_scalability-2012/high_scalability-2012-07-10-Sponsored_Post%3A_New_Relic%2C_NetDNA%2C_Torbit%2C_GigaSpaces%2C_AiCache%2C_Logic_Monitor%2C_AppDynamics%2C_CloudSigma%2C_ManageEngine%2C_Site24x7.html">1280 high scalability-2012-07-10-Sponsored Post: New Relic, NetDNA, Torbit, GigaSpaces, AiCache, Logic Monitor, AppDynamics, CloudSigma, ManageEngine, Site24x7</a></p>
<p>16 0.32632002 <a title="246-lda-16" href="../high_scalability-2010/high_scalability-2010-08-09-NoSQL_on_the_Microsoft_Platform.html">875 high scalability-2010-08-09-NoSQL on the Microsoft Platform</a></p>
<p>17 0.32346669 <a title="246-lda-17" href="../high_scalability-2012/high_scalability-2012-07-25-Sponsored_Post%3A_ElasticHosts%2C_Atlantic.Net%2C_ScaleOut%2C_ground%28ctrl%29%2C_New_Relic%2C_NetDNA%2C_Torbit%2C_GigaSpaces%2C_AiCache%2C_Logic_Monitor%2C_AppDynamics%2C_CloudSigma%2C_ManageEngine%2C_Site24x7.html">1290 high scalability-2012-07-25-Sponsored Post: ElasticHosts, Atlantic.Net, ScaleOut, ground(ctrl), New Relic, NetDNA, Torbit, GigaSpaces, AiCache, Logic Monitor, AppDynamics, CloudSigma, ManageEngine, Site24x7</a></p>
<p>18 0.32271665 <a title="246-lda-18" href="../high_scalability-2012/high_scalability-2012-10-02-Sponsored_Post%3A_Akiban%2C_Wiredrive%2C_NY_Times%2C_CouchConf%2C_FiftyThree%2C_ROBLOX%2C_Percona%2C_ElasticHosts%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_GigaSpaces%2C__AiCache%2C_Logic_Monitor%2C_AppDynamics%2C_CloudSigma.html">1332 high scalability-2012-10-02-Sponsored Post: Akiban, Wiredrive, NY Times, CouchConf, FiftyThree, ROBLOX, Percona, ElasticHosts, ScaleOut, New Relic, NetDNA, GigaSpaces,  AiCache, Logic Monitor, AppDynamics, CloudSigma</a></p>
<p>19 0.3224209 <a title="246-lda-19" href="../high_scalability-2012/high_scalability-2012-09-18-Sponsored_Post%3A_NY_Times%2C_CouchConf%2C_Surge%2C_FiftyThree%2C_ROBLOX%2C_Percona%2C_ElasticHosts%2C_Atlantic.Net%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_GigaSpaces%2C_AiCache%2C_Logic_Monitor%2C_AppDynamics%2C_CloudSigma%2C_ManageEngine%2C_Site24x7.html">1324 high scalability-2012-09-18-Sponsored Post: NY Times, CouchConf, Surge, FiftyThree, ROBLOX, Percona, ElasticHosts, Atlantic.Net, ScaleOut, New Relic, NetDNA, GigaSpaces, AiCache, Logic Monitor, AppDynamics, CloudSigma, ManageEngine, Site24x7</a></p>
<p>20 0.32235432 <a title="246-lda-20" href="../high_scalability-2012/high_scalability-2012-09-05-Sponsored_Post%3A_Surge%2C_FiftyThree%2C_ROBLOX%2C_Percona%2C_Palantir%2C_ElasticHosts%2C_Atlantic.Net%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_GigaSpaces%2C_AiCache%2C_Logic_Monitor%2C_AppDynamics%2C_CloudSigma%2C_ManageEngine%2C_Site24x7.html">1317 high scalability-2012-09-05-Sponsored Post: Surge, FiftyThree, ROBLOX, Percona, Palantir, ElasticHosts, Atlantic.Net, ScaleOut, New Relic, NetDNA, GigaSpaces, AiCache, Logic Monitor, AppDynamics, CloudSigma, ManageEngine, Site24x7</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
