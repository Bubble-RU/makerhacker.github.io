<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1108 high scalability-2011-08-31-Pud is the Anti-Stack - Windows, CFML, Dropbox, Xeround, JungleDisk, ELB</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2011" href="../home/high_scalability-2011_home.html">high_scalability-2011</a> <a title="high_scalability-2011-1108" href="#">high_scalability-2011-1108</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1108 high scalability-2011-08-31-Pud is the Anti-Stack - Windows, CFML, Dropbox, Xeround, JungleDisk, ELB</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2011-1108-html" href="http://highscalability.com//blog/2011/8/31/pud-is-the-anti-stack-windows-cfml-dropbox-xeround-jungledis.html">html</a></p><p>Introduction: Pud of  f*ckedcomany.com  (FC) fame, a favorite site of the dot bomb era, and a site I absolutely loved until my company became featured, has given us a look at his backend:  Why Must You Laugh At My Back End . For those whose don't remember FC's history, TechCrunch published a  fitting eulogy :
  

[FC] first went live in 2000, chronicling failing and troubled companies in its unique and abrasive style after the dot com bust. Within a year it had a massive audience and was getting serious mainstream press attention. As the startup economy became better in 2004, much of the attention the site received went away. But a large and loyal audience remains at the site, coming back day after day for its unique slant on the news. At its peak, FC had 4 million unique monthly visitors.

  
Delightfully, FC was not a real-names kind of site. Hard witty cynicism ruled and not a single cat picture was in sight. It was a blast of fun when all around was the enclosing dark.
 
So when I saw Pud's post</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  (FC) fame, a favorite site of the dot bomb era, and a site I absolutely loved until my company became featured, has given us a look at his backend:  Why Must You Laugh At My Back End . [sent-2, score-0.549]
</p><p>2 For those whose don't remember FC's history, TechCrunch published a  fitting eulogy :     [FC] first went live in 2000, chronicling failing and troubled companies in its unique and abrasive style after the dot com bust. [sent-3, score-0.557]
</p><p>3 Within a year it had a massive audience and was getting serious mainstream press attention. [sent-4, score-0.183]
</p><p>4 As the startup economy became better in 2004, much of the attention the site received went away. [sent-5, score-0.366]
</p><p>5 But a large and loyal audience remains at the site, coming back day after day for its unique slant on the news. [sent-6, score-0.379]
</p><p>6 At its peak, FC had 4 million unique monthly visitors. [sent-7, score-0.091]
</p><p>7 Hard witty cynicism ruled and not a single cat picture was in sight. [sent-9, score-0.233]
</p><p>8 It was a blast of fun when all around was the enclosing dark. [sent-10, score-0.072]
</p><p>9 It's suitably idiosyncratic:      Windows Server 2008  - likes the GUI, nearly as cheap as Linux on AWS, does all the stuff you need    IIS 7   - does all the stuff you need    ColdFusion Markup Language   - does all the stuff you need    Xeround. [sent-13, score-0.362]
</p><p>10 com for the database  - looks interesting    5 EC2 micro instances  - each server is $20/mo. [sent-14, score-0.166]
</p><p>11 Found that micros performed as well as the xlarge instances for less money. [sent-15, score-0.085]
</p><p>12 Elastic Load Balancing  - used to connect the 5 micro instances together. [sent-18, score-0.089]
</p><p>13 Dropbox  - when a code change is made all servers are synced using Dropbox. [sent-19, score-0.159]
</p><p>14 Backup  - DropBox keeps an offsite backup by default. [sent-23, score-0.089]
</p><p>15 Defiantly, anticipating the antipathy, Pud closes with:     The apps run themselves and are scalable. [sent-25, score-0.168]
</p><p>16 A natural process is clearly at work in Pud's architecture and that shows. [sent-34, score-0.178]
</p><p>17 It wasn't defined using best practices or reference designs, it clearly unfolded based on need and capability. [sent-35, score-0.086]
</p><p>18 Characteristics of the wabi-sabi aesthetic include asymmetry, asperity (roughness or irregularity), simplicity, economy, austerity, modesty, intimacy and appreciation of the ingenuous integrity of natural objects and processes. [sent-37, score-0.254]
</p><p>19 Even if this is all some elaborate joke, the conclusions still apply. [sent-45, score-0.144]
</p><p>20 Pick any stack and you can go through the same discussion, just arguing different points. [sent-46, score-0.072]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fc', 0.524), ('pud', 0.419), ('synced', 0.159), ('dot', 0.147), ('economy', 0.131), ('suck', 0.115), ('audience', 0.114), ('imperfect', 0.095), ('impermanent', 0.095), ('asymmetry', 0.095), ('modesty', 0.095), ('natural', 0.092), ('stuff', 0.091), ('unique', 0.091), ('micro', 0.089), ('brilliance', 0.089), ('slant', 0.089), ('chronicling', 0.089), ('suitably', 0.089), ('offsite', 0.089), ('anticipating', 0.089), ('witty', 0.089), ('became', 0.088), ('clearly', 0.086), ('troubled', 0.085), ('aesthetic', 0.085), ('loyal', 0.085), ('markup', 0.085), ('xlarge', 0.085), ('coincidence', 0.082), ('laugh', 0.079), ('closes', 0.079), ('bomb', 0.079), ('site', 0.079), ('appreciation', 0.077), ('com', 0.077), ('conclusions', 0.075), ('fame', 0.074), ('incomplete', 0.074), ('blast', 0.072), ('ruled', 0.072), ('joke', 0.072), ('cat', 0.072), ('arguing', 0.072), ('techcrunch', 0.07), ('mainstream', 0.069), ('elaborate', 0.069), ('dropbox', 0.069), ('went', 0.068), ('gui', 0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="1108-tfidf-1" href="../high_scalability-2011/high_scalability-2011-08-31-Pud_is_the_Anti-Stack_-_Windows%2C_CFML%2C_Dropbox%2C_Xeround%2C_JungleDisk%2C_ELB.html">1108 high scalability-2011-08-31-Pud is the Anti-Stack - Windows, CFML, Dropbox, Xeround, JungleDisk, ELB</a></p>
<p>Introduction: Pud of  f*ckedcomany.com  (FC) fame, a favorite site of the dot bomb era, and a site I absolutely loved until my company became featured, has given us a look at his backend:  Why Must You Laugh At My Back End . For those whose don't remember FC's history, TechCrunch published a  fitting eulogy :
  

[FC] first went live in 2000, chronicling failing and troubled companies in its unique and abrasive style after the dot com bust. Within a year it had a massive audience and was getting serious mainstream press attention. As the startup economy became better in 2004, much of the attention the site received went away. But a large and loyal audience remains at the site, coming back day after day for its unique slant on the news. At its peak, FC had 4 million unique monthly visitors.

  
Delightfully, FC was not a real-names kind of site. Hard witty cynicism ruled and not a single cat picture was in sight. It was a blast of fun when all around was the enclosing dark.
 
So when I saw Pud's post</p><p>2 0.084997073 <a title="1108-tfidf-2" href="../high_scalability-2013/high_scalability-2013-08-26-Reddit%3A_Lessons_Learned_from_Mistakes_Made_Scaling_to_1_Billion_Pageviews_a_Month.html">1507 high scalability-2013-08-26-Reddit: Lessons Learned from Mistakes Made Scaling to 1 Billion Pageviews a Month</a></p>
<p>Introduction: Jeremy Edberg   , the first paid employee at reddit, teaches us a lot about how to create a successful social site in a really good talk he gave at the RAMP conference. Watch it here at  Scaling Reddit from 1 Million to 1 Billion–Pitfalls and Lessons .  
 
 Jeremy uses a virtue and sin approach. Examples of the mistakes made in scaling reddit are shared and it turns out they did a lot of good stuff too. Somewhat of a shocker is that   Jeremy is now a Reliability Architect at Netflix, so we get a little Netflix perspective thrown in for free. 
 
 Some of the lessons that stood out most for me:  
  
  Think of SSDs as cheap RAM, not expensive disk . When reddit moved from spinning disks to SSDs for the database the number of servers was reduced from 12 to 1 with a ton of headroom. SSDs are 4x more expensive but you get 16x the performance. Worth the cost.  
  Give users a little bit of power, see what they do with it, and turn the good stuff into features . One of the biggest revelations</p><p>3 0.069628313 <a title="1108-tfidf-3" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>Introduction: This is a guest post by  Shawn Hsiao ,  Luke Massa , and  Victor Luu . Shawn runs  TripAdvisor ’s Technical Operations team, Luke and Victor interned on his team this past summer. This post is introduced by  Andy Gelfond , TripAdvisor’s head of engineering.   It's been a little over a year since our last post about the  TripAdvisor architecture . It has been an exciting year. Our business and team continues to grow, we are now an independent public company, and we have continued to keep/scale our development process and culture as we have grown - we still run dozens of independent teams, and each team continues to work across the entire stack. All that has changed are the numbers:
  
 56M visitors per month 
 350M+ pages requests a day 
 120TB+ of warehouse data running on a large Hadoop cluster, and quickly growing 
  
We also had a very successful college intern program that brought on over 60 interns this past summer, all who were quickly on boarded and doing the same kind of work a</p><p>4 0.069173455 <a title="1108-tfidf-4" href="../high_scalability-2012/high_scalability-2012-06-20-iDoneThis_-_Scaling_an_Email-based_App_from_Scratch.html">1269 high scalability-2012-06-20-iDoneThis - Scaling an Email-based App from Scratch</a></p>
<p>Introduction: This is a guest post by Rodrigo Guzman, CTO of  iDoneThis , which makes status reporting happen at your company with the lightest possible touch. 
 
 iDoneThis  is a simple management application that emails your team at the end of every day to ask, "What'd you get done today?"  Just reply with a few lines of what you got done. The following morning everyone on your team gets a digest with what the team accomplished the previous day to keep everyone in the loop and kickstart another awesome day.
 
Before we launched, we built iDoneThis over a weekend in the most rudimentary way possible.  I kid you not, we sent the first few batches of daily emails using the BCC field of a Gmail inbox.  The upshot is that we’ve had users on the site from Day 3 of its existence on.
 
We’ve gone from launch in January 2011 when we sent hundreds of emails out per day by hand to sending out over 1 million emails and handling over 200,000 incoming emails per month.  In total, customers have recorded over 1.</p><p>5 0.061325297 <a title="1108-tfidf-5" href="../high_scalability-2012/high_scalability-2012-11-01-Cost_Analysis%3A_TripAdvisor_and_Pinterest_costs_on_the_AWS_cloud.html">1353 high scalability-2012-11-01-Cost Analysis: TripAdvisor and Pinterest costs on the AWS cloud</a></p>
<p>Introduction: This is a guest post by  Ali Khajeh-Hosseini , Technical Lead at PlanForCloud.com.   
 
 I read a recent blog post about   TripAdvisor's experiment with AWS   where they attempted to process 700K HTTP requests per minute on a replica of their live site. There was also an interesting blog post on   Pinterest's massive growth on AWS  . These blogs highlighted exactly the types of questions we're interested in, mainly: 
    
  How much would it cost to deploy System X on Cloud Y?   e.g. how much would it cost to host TripAdvisor on the AWS US-East cloud?  
  Would it be cheaper to use deployment option X or Y?   e.g. would it be cheaper to use reserved instances, different types of instances, different cloud providers...  
  What happens to costs when the system grows?   e.g. Pinterest has around 410TB of data on S3, what if that keeps growing at a rate of 25% every month, like it has been in the last 10 months?  
      I created a couple of deployments in PlanForCloud to explore these qu</p><p>6 0.06035205 <a title="1108-tfidf-6" href="../high_scalability-2010/high_scalability-2010-10-28-Notes_from_A_NOSQL_Evening_in_Palo_Alto_.html">931 high scalability-2010-10-28-Notes from A NOSQL Evening in Palo Alto </a></p>
<p>7 0.059923489 <a title="1108-tfidf-7" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>8 0.059465505 <a title="1108-tfidf-8" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>9 0.056865271 <a title="1108-tfidf-9" href="../high_scalability-2007/high_scalability-2007-10-02-Secrets_to_Fotolog%27s_Scaling_Success.html">106 high scalability-2007-10-02-Secrets to Fotolog's Scaling Success</a></p>
<p>10 0.055425115 <a title="1108-tfidf-10" href="../high_scalability-2008/high_scalability-2008-02-19-Building_a_email_communication_system.html">253 high scalability-2008-02-19-Building a email communication system</a></p>
<p>11 0.054930054 <a title="1108-tfidf-11" href="../high_scalability-2009/high_scalability-2009-06-26-PlentyOfFish_Architecture.html">638 high scalability-2009-06-26-PlentyOfFish Architecture</a></p>
<p>12 0.054861199 <a title="1108-tfidf-12" href="../high_scalability-2007/high_scalability-2007-09-18-Amazon_Architecture.html">96 high scalability-2007-09-18-Amazon Architecture</a></p>
<p>13 0.054505892 <a title="1108-tfidf-13" href="../high_scalability-2012/high_scalability-2012-11-22-Gone_Fishin%27%3A_PlentyOfFish_Architecture.html">1361 high scalability-2012-11-22-Gone Fishin': PlentyOfFish Architecture</a></p>
<p>14 0.053580284 <a title="1108-tfidf-14" href="../high_scalability-2007/high_scalability-2007-10-16-How_Scalable_are_Single_Page_Ajax_Apps%3F.html">124 high scalability-2007-10-16-How Scalable are Single Page Ajax Apps?</a></p>
<p>15 0.052793901 <a title="1108-tfidf-15" href="../high_scalability-2011/high_scalability-2011-08-22-Strategy%3A_Run_a_Scalable%2C_Available%2C_and_Cheap_Static_Site_on_S3_or_GitHub.html">1102 high scalability-2011-08-22-Strategy: Run a Scalable, Available, and Cheap Static Site on S3 or GitHub</a></p>
<p>16 0.051107578 <a title="1108-tfidf-16" href="../high_scalability-2012/high_scalability-2012-11-27-Sponsored_Post%3A__Akiban%2C_Booking%2C_Teradata_Aster%2C_Hadapt%2C_Zoosk%2C_Aerospike%2C_Server_Stack%2C_Wiredrive%2C_NY_Times%2C_CouchConf%2C_FiftyThree%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_GigaSpaces%2C_AiCache%2C_Logic_Monitor%2C_AppDynamics.html">1363 high scalability-2012-11-27-Sponsored Post:  Akiban, Booking, Teradata Aster, Hadapt, Zoosk, Aerospike, Server Stack, Wiredrive, NY Times, CouchConf, FiftyThree, Percona, ScaleOut, New Relic, NetDNA, GigaSpaces, AiCache, Logic Monitor, AppDynamics</a></p>
<p>17 0.050884165 <a title="1108-tfidf-17" href="../high_scalability-2011/high_scalability-2011-06-06-Apple_iCloud%3A_Syncing_and_Distributed_Storage_Over_Streaming_and_Centralized_Storage.html">1053 high scalability-2011-06-06-Apple iCloud: Syncing and Distributed Storage Over Streaming and Centralized Storage</a></p>
<p>18 0.050559219 <a title="1108-tfidf-18" href="../high_scalability-2008/high_scalability-2008-01-29-When_things_aren%27t_scalable.html">232 high scalability-2008-01-29-When things aren't scalable</a></p>
<p>19 0.049613468 <a title="1108-tfidf-19" href="../high_scalability-2008/high_scalability-2008-03-15-New_Website_Design_Considerations.html">276 high scalability-2008-03-15-New Website Design Considerations</a></p>
<p>20 0.049103629 <a title="1108-tfidf-20" href="../high_scalability-2011/high_scalability-2011-10-24-StackExchange_Architecture_Updates_-_Running_Smoothly%2C_Amazon_4x_More_Expensive.html">1131 high scalability-2011-10-24-StackExchange Architecture Updates - Running Smoothly, Amazon 4x More Expensive</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.102), (1, 0.041), (2, -0.014), (3, -0.016), (4, 0.004), (5, -0.06), (6, -0.021), (7, 0.006), (8, 0.028), (9, -0.031), (10, -0.015), (11, -0.014), (12, 0.003), (13, 0.006), (14, -0.005), (15, -0.017), (16, -0.0), (17, 0.001), (18, -0.005), (19, 0.025), (20, 0.004), (21, -0.031), (22, -0.016), (23, -0.004), (24, -0.007), (25, -0.024), (26, 0.005), (27, 0.012), (28, 0.006), (29, -0.018), (30, 0.012), (31, 0.043), (32, -0.026), (33, -0.021), (34, -0.022), (35, 0.002), (36, -0.013), (37, -0.004), (38, -0.017), (39, 0.027), (40, -0.008), (41, 0.01), (42, -0.005), (43, 0.021), (44, 0.004), (45, -0.026), (46, 0.03), (47, 0.028), (48, -0.005), (49, 0.026)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96743304 <a title="1108-lsi-1" href="../high_scalability-2011/high_scalability-2011-08-31-Pud_is_the_Anti-Stack_-_Windows%2C_CFML%2C_Dropbox%2C_Xeround%2C_JungleDisk%2C_ELB.html">1108 high scalability-2011-08-31-Pud is the Anti-Stack - Windows, CFML, Dropbox, Xeround, JungleDisk, ELB</a></p>
<p>Introduction: Pud of  f*ckedcomany.com  (FC) fame, a favorite site of the dot bomb era, and a site I absolutely loved until my company became featured, has given us a look at his backend:  Why Must You Laugh At My Back End . For those whose don't remember FC's history, TechCrunch published a  fitting eulogy :
  

[FC] first went live in 2000, chronicling failing and troubled companies in its unique and abrasive style after the dot com bust. Within a year it had a massive audience and was getting serious mainstream press attention. As the startup economy became better in 2004, much of the attention the site received went away. But a large and loyal audience remains at the site, coming back day after day for its unique slant on the news. At its peak, FC had 4 million unique monthly visitors.

  
Delightfully, FC was not a real-names kind of site. Hard witty cynicism ruled and not a single cat picture was in sight. It was a blast of fun when all around was the enclosing dark.
 
So when I saw Pud's post</p><p>2 0.80677873 <a title="1108-lsi-2" href="../high_scalability-2009/high_scalability-2009-09-22-How_Ravelry_Scales_to_10_Million_Requests_Using_Rails.html">711 high scalability-2009-09-22-How Ravelry Scales to 10 Million Requests Using Rails</a></p>
<p>Introduction: Tim Bray  has a wonderful  interview with Casey Forbes , creator of Ravelry, a Ruby on Rails site supporting a 400,000+ strong community of dedicated knitters and crocheters.   Casey and his small team have done great things with Ravelry. It is a very focused site that provides a lot of value for users. And users absolutely adore the site. That's obvious from their enthusiastic comments and rocket fast adoption of Ravelry.  Ten years ago a site like Ravelry would have been a multi-million dollar operation. Today Casey is the sole engineer for Ravelry and to run it takes only a few people. He was able to code it in 4 months working nights and weekends. Take a look down below of all the technologies used to make Ravelry and you'll see how it is constructed almost completely from free of the shelf software that Casey has stitched together into a complete system. There's an amazing amount of leverage in today's ecosystem when you combine all the quality tools, languages, storage, bandwidth</p><p>3 0.76001507 <a title="1108-lsi-3" href="../high_scalability-2009/high_scalability-2009-06-01-Guess_How_Many_Users_it_Takes_to_Kill_Your_Site%3F.html">614 high scalability-2009-06-01-Guess How Many Users it Takes to Kill Your Site?</a></p>
<p>Introduction: Update:  Here's the  first result . Good response time until 400 users. At 1,340 users the response time was 6 seconds. And at 2000 users the site was effectively did. An interesting point was that errors that could harm a site's reputation started at 1000 users. Cheers to the company that had the guts to give this a try.  That which doesn't kill your site makes it stronger. Or at least that's the capacity planning strategy John Allspaw recommends (not really, but I'm trying to make a point here) in  The Art of Capacity Planning :
   Using production traffic to define your resources ceilings in a controlled setting allows you to see firsthand what would happen when you run out of capacity in a particular resource. Of course I'm not suggesting that you run your site into the ground, but better to know what your real (not simulated) loads are while you're watching, than find out the hard way. In addition, a lot of unexpected systemic things can happen when load increases in a particular</p><p>4 0.75951761 <a title="1108-lsi-4" href="../high_scalability-2013/high_scalability-2013-08-26-Reddit%3A_Lessons_Learned_from_Mistakes_Made_Scaling_to_1_Billion_Pageviews_a_Month.html">1507 high scalability-2013-08-26-Reddit: Lessons Learned from Mistakes Made Scaling to 1 Billion Pageviews a Month</a></p>
<p>Introduction: Jeremy Edberg   , the first paid employee at reddit, teaches us a lot about how to create a successful social site in a really good talk he gave at the RAMP conference. Watch it here at  Scaling Reddit from 1 Million to 1 Billion–Pitfalls and Lessons .  
 
 Jeremy uses a virtue and sin approach. Examples of the mistakes made in scaling reddit are shared and it turns out they did a lot of good stuff too. Somewhat of a shocker is that   Jeremy is now a Reliability Architect at Netflix, so we get a little Netflix perspective thrown in for free. 
 
 Some of the lessons that stood out most for me:  
  
  Think of SSDs as cheap RAM, not expensive disk . When reddit moved from spinning disks to SSDs for the database the number of servers was reduced from 12 to 1 with a ton of headroom. SSDs are 4x more expensive but you get 16x the performance. Worth the cost.  
  Give users a little bit of power, see what they do with it, and turn the good stuff into features . One of the biggest revelations</p><p>5 0.74371231 <a title="1108-lsi-5" href="../high_scalability-2013/high_scalability-2013-04-10-Check_Yourself_Before_You_Wreck_Yourself_-_Avocado%27s_5_Early_Stages_of_Architecture_Evolution.html">1438 high scalability-2013-04-10-Check Yourself Before You Wreck Yourself - Avocado's 5 Early Stages of Architecture Evolution</a></p>
<p>Introduction: In  Don’t panic! Here’s how to quickly scale your mobile apps   Mike Maelzer  paints a wonderful picture of how  Avocado , a mobile app for connecting couples, evolved to handle 30x traffic within a few weeks. If you are just getting started then this is a great example to learn from.
 
What I liked: it's well written, packing a lot of useful information in a little space; it's failure driven, showing the process of incremental change driven by purposeful testing and production experience; it shows awareness of what's important, in their case, user signup; a replica setup was used for testing, a nice cloud benefit. 
 
Their Biggest lesson learned is a good one:
  It would have been great to start the scaling process much earlier. Due to time pressure we had to make compromises –like dropping four of our media resizer boxes. While throwing more hardware at some scaling problems does work, it’s less than ideal.  
Here's my gloss on the article:
  Evolution One - Make it Work  
When just</p><p>6 0.73650169 <a title="1108-lsi-6" href="../high_scalability-2009/high_scalability-2009-07-20-A_Scalability_Lament.html">659 high scalability-2009-07-20-A Scalability Lament</a></p>
<p>7 0.73640299 <a title="1108-lsi-7" href="../high_scalability-2008/high_scalability-2008-06-09-FaceStat%27s_Rousing_Tale_of_Scaling_Woe_and_Wisdom_Won.html">344 high scalability-2008-06-09-FaceStat's Rousing Tale of Scaling Woe and Wisdom Won</a></p>
<p>8 0.73503566 <a title="1108-lsi-8" href="../high_scalability-2009/high_scalability-2009-01-16-Just-In-Time_Scalability%3A_Agile_Methods_to_Support_Massive_Growth_%28IMVU_case_study%29.html">493 high scalability-2009-01-16-Just-In-Time Scalability: Agile Methods to Support Massive Growth (IMVU case study)</a></p>
<p>9 0.72302383 <a title="1108-lsi-9" href="../high_scalability-2010/high_scalability-2010-12-29-Pinboard.in_Architecture_-_Pay_to_Play_to_Keep_a_System_Small__.html">965 high scalability-2010-12-29-Pinboard.in Architecture - Pay to Play to Keep a System Small  </a></p>
<p>10 0.72292876 <a title="1108-lsi-10" href="../high_scalability-2013/high_scalability-2013-04-01-Khan_Academy_Checkbook_Scaling_to_6_Million_Users_a_Month_on_GAE.html">1432 high scalability-2013-04-01-Khan Academy Checkbook Scaling to 6 Million Users a Month on GAE</a></p>
<p>11 0.72129303 <a title="1108-lsi-11" href="../high_scalability-2008/high_scalability-2008-11-13-Plenty_of_Fish_Says_Scaling_for_Free_Doesn%27t_Pay.html">442 high scalability-2008-11-13-Plenty of Fish Says Scaling for Free Doesn't Pay</a></p>
<p>12 0.70830828 <a title="1108-lsi-12" href="../high_scalability-2012/high_scalability-2012-06-20-iDoneThis_-_Scaling_an_Email-based_App_from_Scratch.html">1269 high scalability-2012-06-20-iDoneThis - Scaling an Email-based App from Scratch</a></p>
<p>13 0.69784129 <a title="1108-lsi-13" href="../high_scalability-2012/high_scalability-2012-01-09-The_Etsy_Saga%3A_From_Silos_to_Happy_to_Billions_of_Pageviews_a_Month.html">1171 high scalability-2012-01-09-The Etsy Saga: From Silos to Happy to Billions of Pageviews a Month</a></p>
<p>14 0.69663829 <a title="1108-lsi-14" href="../high_scalability-2007/high_scalability-2007-10-02-Secrets_to_Fotolog%27s_Scaling_Success.html">106 high scalability-2007-10-02-Secrets to Fotolog's Scaling Success</a></p>
<p>15 0.69634527 <a title="1108-lsi-15" href="../high_scalability-2009/high_scalability-2009-10-02-HighScalability_has_Moved_to_Squarespace.com%21_.html">714 high scalability-2009-10-02-HighScalability has Moved to Squarespace.com! </a></p>
<p>16 0.69108033 <a title="1108-lsi-16" href="../high_scalability-2013/high_scalability-2013-06-18-Scaling_Mailbox_-_From_0_to_One_Million_Users_in_6_Weeks_and_100_Million_Messages_Per_Day.html">1477 high scalability-2013-06-18-Scaling Mailbox - From 0 to One Million Users in 6 Weeks and 100 Million Messages Per Day</a></p>
<p>17 0.69075412 <a title="1108-lsi-17" href="../high_scalability-2007/high_scalability-2007-11-17-Can_How_Bees_Solve_their_Load_Balancing_Problems_Help_Build_More_Scalable_Websites%3F.html">158 high scalability-2007-11-17-Can How Bees Solve their Load Balancing Problems Help Build More Scalable Websites?</a></p>
<p>18 0.6886996 <a title="1108-lsi-18" href="../high_scalability-2007/high_scalability-2007-11-18-Reverse_Proxy.html">159 high scalability-2007-11-18-Reverse Proxy</a></p>
<p>19 0.68157727 <a title="1108-lsi-19" href="../high_scalability-2014/high_scalability-2014-01-06-How_HipChat_Stores_and_Indexes_Billions_of_Messages_Using_ElasticSearch_and_Redis.html">1573 high scalability-2014-01-06-How HipChat Stores and Indexes Billions of Messages Using ElasticSearch and Redis</a></p>
<p>20 0.68102849 <a title="1108-lsi-20" href="../high_scalability-2007/high_scalability-2007-11-08-ID_generator.html">145 high scalability-2007-11-08-ID generator</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.164), (2, 0.132), (8, 0.311), (10, 0.063), (26, 0.029), (40, 0.047), (77, 0.036), (79, 0.086), (94, 0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.84952265 <a title="1108-lda-1" href="../high_scalability-2007/high_scalability-2007-12-13-un-article%3A_the_setup_behind_microsoft.com.html">186 high scalability-2007-12-13-un-article: the setup behind microsoft.com</a></p>
<p>Introduction: On the blogs.technet.com article on microsoft.com's infrastructure:   The article reads like a blatant ad for it's own products, and is light on the technical side.     The juicy bits are here, so you know what the fuss is about:     Cytrix Netscaler (= loadbalancer with various optimizations)   W2K8 + IIS7 and antivirus software on the webservers   650GB/day ISS log files   8-9GBit/s (unknown if CDN's are included)   Simple network filtering: stateless access lists blocking unwanted ports on the routers/switches (hence the debated "no firewalls" claim).       Note that this information may not reflect present reality very well; the spokesman appears to be reciting others words.</p><p>2 0.84633046 <a title="1108-lda-2" href="../high_scalability-2008/high_scalability-2008-07-20-The_clouds_are_coming.html">354 high scalability-2008-07-20-The clouds are coming</a></p>
<p>Introduction: A report from the CloudCamp conference on cloud computing, held in London in July 2008.</p><p>3 0.84098697 <a title="1108-lda-3" href="../high_scalability-2008/high_scalability-2008-03-08-Product%3A_FAI_-_Fully_Automatic_Installation.html">272 high scalability-2008-03-08-Product: FAI - Fully Automatic Installation</a></p>
<p>Introduction: From their website:    FAI  is an automated installation tool to install or deploy Debian GNU/Linux and other distributions on a bunch of different hosts or a Cluster. It's more flexible than other tools like kickstart for Red Hat, autoyast and alice for SuSE or Jumpstart for SUN Solaris. FAI can also be used for configuration management of a running system.  You can take one or more virgin PCs, turn on the power and after a few minutes Linux is installed, configured and running on all your machines, without any interaction necessary. FAI it's a scalable method for installing and updating all your computers unattended with little effort involved. It's a centralized management system for your Linux deployment.  
   
  FAI's target group are system administrators who have to install Linux onto one or even hundreds of computers. It's not only a tool for doing a Cluster installation but a general purpose installation tool. It can be used for installing a Beowulf cluster, a rendering farm,</p><p>same-blog 4 0.81350046 <a title="1108-lda-4" href="../high_scalability-2011/high_scalability-2011-08-31-Pud_is_the_Anti-Stack_-_Windows%2C_CFML%2C_Dropbox%2C_Xeround%2C_JungleDisk%2C_ELB.html">1108 high scalability-2011-08-31-Pud is the Anti-Stack - Windows, CFML, Dropbox, Xeround, JungleDisk, ELB</a></p>
<p>Introduction: Pud of  f*ckedcomany.com  (FC) fame, a favorite site of the dot bomb era, and a site I absolutely loved until my company became featured, has given us a look at his backend:  Why Must You Laugh At My Back End . For those whose don't remember FC's history, TechCrunch published a  fitting eulogy :
  

[FC] first went live in 2000, chronicling failing and troubled companies in its unique and abrasive style after the dot com bust. Within a year it had a massive audience and was getting serious mainstream press attention. As the startup economy became better in 2004, much of the attention the site received went away. But a large and loyal audience remains at the site, coming back day after day for its unique slant on the news. At its peak, FC had 4 million unique monthly visitors.

  
Delightfully, FC was not a real-names kind of site. Hard witty cynicism ruled and not a single cat picture was in sight. It was a blast of fun when all around was the enclosing dark.
 
So when I saw Pud's post</p><p>5 0.77255327 <a title="1108-lda-5" href="../high_scalability-2010/high_scalability-2010-07-13-Sponsored_Post%3A__VoltDB_and_Digg_are_Hiring.html">858 high scalability-2010-07-13-Sponsored Post:  VoltDB and Digg are Hiring</a></p>
<p>Introduction: Who's Hiring?   
  VoltDB is Hiring  
  Get Your High Scalability Fix at Digg  
     VoltDB Field/Community Engineer  
VoltDB is attracting more and more users every day. If you have a strong technical background in SQL and Linux, are experienced with production database deployments, and have a passion for customers and community, you could be just the person we are looking for.  Are you excited about the prospect of working with users to develop and deploy VoltDB applications, and about helping users participate in the thriving VoltDB community? If so, read on at their  job page .
    Get Your High Scalability Fix at Digg     
 Interested in working on cutting-edge high-scale infrastructure at Digg? We're making a big investment in scaling and have committed to the NoSQL (Not only SQL) path with   Cassandra  . We're using other open-source infrastructure to help us scale including Hadoop, RabbitMQ, Zookeeper, Thrift, HDFS and Lucene. We're rewriting Digg from the ground up and we need</p><p>6 0.74158311 <a title="1108-lda-6" href="../high_scalability-2012/high_scalability-2012-05-10-Paper%3A_Paxos_Made_Moderately_Complex.html">1243 high scalability-2012-05-10-Paper: Paxos Made Moderately Complex</a></p>
<p>7 0.71575677 <a title="1108-lda-7" href="../high_scalability-2007/high_scalability-2007-11-15-Video%3A_Dryad%3A_A_general-purpose_distributed_execution_platform.html">155 high scalability-2007-11-15-Video: Dryad: A general-purpose distributed execution platform</a></p>
<p>8 0.70259601 <a title="1108-lda-8" href="../high_scalability-2010/high_scalability-2010-10-01-Hot_Scalability_Links_For_Oct_1%2C_2010.html">913 high scalability-2010-10-01-Hot Scalability Links For Oct 1, 2010</a></p>
<p>9 0.68274915 <a title="1108-lda-9" href="../high_scalability-2013/high_scalability-2013-04-03-5_Steps_to_Benchmarking_Managed_NoSQL_-_DynamoDB_vs_Cassandra.html">1434 high scalability-2013-04-03-5 Steps to Benchmarking Managed NoSQL - DynamoDB vs Cassandra</a></p>
<p>10 0.68026382 <a title="1108-lda-10" href="../high_scalability-2009/high_scalability-2009-05-26-Database_Optimize_patterns.html">607 high scalability-2009-05-26-Database Optimize patterns</a></p>
<p>11 0.6625371 <a title="1108-lda-11" href="../high_scalability-2010/high_scalability-2010-06-01-Sponsored_Post%3A_Get_Your_High_Scalability_Fix_at_Digg.html">833 high scalability-2010-06-01-Sponsored Post: Get Your High Scalability Fix at Digg</a></p>
<p>12 0.63539457 <a title="1108-lda-12" href="../high_scalability-2012/high_scalability-2012-04-17-YouTube_Strategy%3A_Adding_Jitter_isn%27t_a_Bug.html">1229 high scalability-2012-04-17-YouTube Strategy: Adding Jitter isn't a Bug</a></p>
<p>13 0.63354176 <a title="1108-lda-13" href="../high_scalability-2008/high_scalability-2008-09-25-Is_your_cloud_as_scalable_as_you_think_it_is%3F.html">395 high scalability-2008-09-25-Is your cloud as scalable as you think it is?</a></p>
<p>14 0.63132185 <a title="1108-lda-14" href="../high_scalability-2008/high_scalability-2008-12-01-Web_Consolidation_on_the_Sun_Fire_T1000_using_Solaris_Containers__.html">458 high scalability-2008-12-01-Web Consolidation on the Sun Fire T1000 using Solaris Containers  </a></p>
<p>15 0.58998984 <a title="1108-lda-15" href="../high_scalability-2013/high_scalability-2013-11-19-We_Finally_Cracked_the_10K_Problem_-_This_Time_for_Managing_Servers_with_2000x_Servers_Managed_Per_Sysadmin.html">1550 high scalability-2013-11-19-We Finally Cracked the 10K Problem - This Time for Managing Servers with 2000x Servers Managed Per Sysadmin</a></p>
<p>16 0.58882201 <a title="1108-lda-16" href="../high_scalability-2009/high_scalability-2009-08-11-13_Scalability_Best_Practices.html">679 high scalability-2009-08-11-13 Scalability Best Practices</a></p>
<p>17 0.58527172 <a title="1108-lda-17" href="../high_scalability-2013/high_scalability-2013-06-07-Stuff_The_Internet_Says_On_Scalability_For_June_7%2C_2013.html">1472 high scalability-2013-06-07-Stuff The Internet Says On Scalability For June 7, 2013</a></p>
<p>18 0.58465856 <a title="1108-lda-18" href="../high_scalability-2013/high_scalability-2013-06-26-Leveraging_Cloud_Computing_at_Yelp_-_102_Million_Monthly_Vistors_and_39_Million_Reviews.html">1482 high scalability-2013-06-26-Leveraging Cloud Computing at Yelp - 102 Million Monthly Vistors and 39 Million Reviews</a></p>
<p>19 0.58337224 <a title="1108-lda-19" href="../high_scalability-2007/high_scalability-2007-08-02-Product%3A_Mashery.html">55 high scalability-2007-08-02-Product: Mashery</a></p>
<p>20 0.58270013 <a title="1108-lda-20" href="../high_scalability-2008/high_scalability-2008-07-21-Eucalyptus__-__Build_Your_Own_Private_EC2_Cloud.html">355 high scalability-2008-07-21-Eucalyptus  -  Build Your Own Private EC2 Cloud</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
