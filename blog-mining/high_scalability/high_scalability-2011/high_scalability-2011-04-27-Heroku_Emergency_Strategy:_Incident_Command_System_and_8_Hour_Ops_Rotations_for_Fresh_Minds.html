<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1030 high scalability-2011-04-27-Heroku Emergency Strategy: Incident Command System and 8 Hour Ops Rotations for Fresh Minds</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2011" href="../home/high_scalability-2011_home.html">high_scalability-2011</a> <a title="high_scalability-2011-1030" href="#">high_scalability-2011-1030</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1030 high scalability-2011-04-27-Heroku Emergency Strategy: Incident Command System and 8 Hour Ops Rotations for Fresh Minds</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2011-1030-html" href="http://highscalability.com//blog/2011/4/27/heroku-emergency-strategy-incident-command-system-and-8-hour.html">html</a></p><p>Introduction: In Resolved: Widespread Application Outage, Herokutells their story of how
they dealt with theAmazon outage. While taking 100% responsibility for the
downtime, they also shared a number of the strategies they used to bring their
service back to full working order.One ofHeroku'smost interesting strategies
wasn't a technical hack at all, but how they consciously went about deploying
their Ops personnel in response to the emergency. An outline of their strategy
is: Monitoring systems immediately alerted Ops to the problem. An on-call
engineer applied triage logic to the problem and classified it as serious,
which caused the on-callIncident Commanderto be woken out of restful slumber.
TheICcontactedAWS. They were in constant contact with theirAWSrepresentative
and worked closely withAWSto solve problems.TheICalertedHerokuengineers. A
full crew: support, data, and other engineering teams worked around the clock
to bring everything back online.The Ops team instituted an emergency incident
co</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 While taking 100% responsibility for the downtime, they also shared a number of the strategies they used to bring their service back to full working order. [sent-2, score-0.174]
</p><p>2 One ofHeroku'smost interesting strategies wasn't a technical hack at all, but how they consciously went about deploying their Ops personnel in response to the emergency. [sent-3, score-0.362]
</p><p>3 An outline of their strategy is: Monitoring systems immediately alerted Ops to the problem. [sent-4, score-0.183]
</p><p>4 An on-call engineer applied triage logic to the problem and classified it as serious, which caused the on-callIncident Commanderto be woken out of restful slumber. [sent-5, score-0.473]
</p><p>5 A full crew: support, data, and other engineering teams worked around the clock to bring everything back online. [sent-9, score-0.315]
</p><p>6 The Ops team instituted an emergency incident commander rotation of 8 hours per shift, once it became clear the outage was serious, in-order to keep a fresh mind in charge of the situation at all times. [sent-10, score-0.983]
</p><p>7 Incident Command SystemChrishenn in acomment on the Heroku post onHacker News, thinks Heroku was using an emergency response system based on theIncident Command Systemmodel:  a systematic tool used for the command, control, and coordination of emergency response. [sent-12, score-0.808]
</p><p>8 The great thing about it is it's expandability ---it will work for teams of nearly any size. [sent-15, score-0.263]
</p><p>9 I'd be interested in seeing if any other technology companies/backend teams are using it. [sent-16, score-0.147]
</p><p>10 Lessons LearnedHave a monitoring system so you know immediately when there are problems. [sent-17, score-0.099]
</p><p>11 Be a really big customer so Amazon will help you specifically with your problems. [sent-18, score-0.116]
</p><p>12 I noticed in the Amazon developer forums a lot of people forgot to do this and didn't get the personal help they needed. [sent-20, score-0.172]
</p><p>13 Herokuhas an on-call engineer, an ICcoordinator, an escalation process, and the ability to call in all the troops when needed. [sent-22, score-0.109]
</p><p>14 It sounds likeHerokuhandled the incident like a well oiled machine. [sent-23, score-0.255]
</p><p>15 That takes practice, so practice ahead of failures instead of trying to figure out all this stuff when theEBSis falling. [sent-24, score-0.095]
</p><p>16 Recognizing that tired people make bad decisions and putting the coordinator on 8 hour rotation to prevent this type of secondary failure is really genius. [sent-25, score-0.357]
</p><p>17 Heroku'sstatus update policy shows an insightful understanding of customer psychology. [sent-26, score-0.116]
</p><p>18 Managing customer feelings and expectations was a great move. [sent-27, score-0.298]
</p><p>19 Even if the status updates did not contain a lot of details, they did showHerokuwas there and cared. [sent-29, score-0.187]
</p><p>20 Nothing creates resentment faster than lying in these situations. [sent-33, score-0.109]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('emergency', 0.316), ('incident', 0.255), ('heroku', 0.191), ('ops', 0.173), ('rotation', 0.173), ('command', 0.164), ('teams', 0.147), ('outage', 0.123), ('serious', 0.123), ('customer', 0.116), ('theamazon', 0.116), ('reassuring', 0.116), ('learnedhave', 0.116), ('commander', 0.116), ('expandability', 0.116), ('systemmodel', 0.116), ('woken', 0.109), ('classified', 0.109), ('widespread', 0.109), ('lying', 0.109), ('troops', 0.109), ('feelings', 0.104), ('triage', 0.104), ('status', 0.103), ('crew', 0.1), ('immediately', 0.099), ('coordinator', 0.097), ('response', 0.096), ('practice', 0.095), ('forgot', 0.094), ('articleshacker', 0.094), ('strategies', 0.091), ('consciously', 0.09), ('tired', 0.087), ('abandoned', 0.087), ('onhacker', 0.085), ('personnel', 0.085), ('worked', 0.085), ('updates', 0.084), ('outline', 0.084), ('bring', 0.083), ('resolved', 0.082), ('dealt', 0.081), ('systematic', 0.08), ('news', 0.079), ('expectations', 0.078), ('forums', 0.078), ('engineer', 0.076), ('restful', 0.075), ('wikipedia', 0.074)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="1030-tfidf-1" href="../high_scalability-2011/high_scalability-2011-04-27-Heroku_Emergency_Strategy%3A_Incident_Command_System_and_8_Hour_Ops_Rotations_for_Fresh_Minds.html">1030 high scalability-2011-04-27-Heroku Emergency Strategy: Incident Command System and 8 Hour Ops Rotations for Fresh Minds</a></p>
<p>Introduction: In Resolved: Widespread Application Outage, Herokutells their story of how
they dealt with theAmazon outage. While taking 100% responsibility for the
downtime, they also shared a number of the strategies they used to bring their
service back to full working order.One ofHeroku'smost interesting strategies
wasn't a technical hack at all, but how they consciously went about deploying
their Ops personnel in response to the emergency. An outline of their strategy
is: Monitoring systems immediately alerted Ops to the problem. An on-call
engineer applied triage logic to the problem and classified it as serious,
which caused the on-callIncident Commanderto be woken out of restful slumber.
TheICcontactedAWS. They were in constant contact with theirAWSrepresentative
and worked closely withAWSto solve problems.TheICalertedHerokuengineers. A
full crew: support, data, and other engineering teams worked around the clock
to bring everything back online.The Ops team instituted an emergency incident
co</p><p>2 0.16675708 <a title="1030-tfidf-2" href="../high_scalability-2009/high_scalability-2009-04-24-Heroku_-_Simultaneously_Develop_and_Deploy_Automatically_Scalable_Rails_Applications_in_the_Cloud.html">579 high scalability-2009-04-24-Heroku - Simultaneously Develop and Deploy Automatically Scalable Rails Applications in the Cloud</a></p>
<p>Introduction: Update 4: Heroku versus GAE & GAE/JUpdate 3:Heroku has gone live!.
Congratulations to the team. It's difficult right now to get a feeling for the
relative cost and reliability of Heroku, but it's an impressive accomplishment
and a viable option for people looking for a delivery platform.Update 2:Heroku
Architecture. A great interactive presentation of the Heroku stack. Requests
flow into Nginx used as a HTTP Reverse Proxy. Nginx routes requests into a
Varnish based HTTP cache. Then requests are injected into an Erlang based
routing mesh that balances requests across a grid of dynos. Dynos are your
application "VMs" that implement application specific behaviors. Dynos
themselves are a stack of: POSIX, Ruby VM, App Server, Rack, Middleware,
Framework, Your App. Applications can access PostgreSQL. Memcached is used as
an application caching layer.Update: Aaron WorshamInterview with James
Lindenbaum, CEO of Heroku. Aaron nicely sums up their goal: Heroku is looking
to eliminate all the rea</p><p>3 0.13562961 <a title="1030-tfidf-3" href="../high_scalability-2013/high_scalability-2013-06-05-A_Simple_6_Step_Transition_Guide_for_Moving_Away_from_X_to_AWS_.html">1470 high scalability-2013-06-05-A Simple 6 Step Transition Guide for Moving Away from X to AWS </a></p>
<p>Introduction: If you just want to visit Rome and not go full on Cloud Native like Netflix,
thenSoundslice'sAdrian HolovatyinWhy I left Heroku, and notes on my new AWS
setup provides a simple guide for helping make your first trip a good
one.First, let's dispose of why Soundslice left Heroku. The essence is because
of various issues "Heroku lost my trust." YMMV, but once a fact, what do you
do?After a consultation withScott VanDenPlas, former director of dev ops for
the Obama reelection tech team, they came up a simple transition guide that I
think is quite good and generally useful (full details in theoriginal post):
Bake an AMI. Install all the stuff you need on an AMI and use that as your
deployment unit. This works well for Netflix and for users who value a certain
sort of simplicity more than flexibility. There were a lot of comments saying
how it's better to use Chef/Puppet and configure instances on the fly, but
there's a confidence that only a baked image provides.Set up auto-scaling
rules. T</p><p>4 0.13471173 <a title="1030-tfidf-4" href="../high_scalability-2011/high_scalability-2011-05-02-The_Updated_Big_List_of_Articles_on_the_Amazon_Outage.html">1033 high scalability-2011-05-02-The Updated Big List of Articles on the Amazon Outage</a></p>
<p>Introduction: SinceThe Big List Of Articles On The Amazon Outage was published we've a had
few updates that people might not have seen. Amazon of course released their
Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East
Region. Netlix shared theirLessons Learned from the AWS Outage as did Heroku
(How Heroku Survived the Amazon Outage), Smug Mug (How SmugMug survived the
Amazonpocalypse), and SimpleGeo (How SimpleGeo Stayed Up During the AWS
Downtime). The curious thing from my perspective is the general lack of
response to Amazon's explanation. I expected more discussion. There's been
almost none that I've seen. My guess is very few people understand what Amazon
was talking about enough to comment whereas almost everyone feels qualified to
talk about the event itself.Lesson for crisis handlers: deep dive post-mortems
that are timely, long, honestish, and highly technical are the most effective
means of staunching the downward spiral of media attention. Amazon's
Explanation of</p><p>5 0.13416034 <a title="1030-tfidf-5" href="../high_scalability-2010/high_scalability-2010-03-05-Strategy%3A_Planning_for_a_Power_Outage_Google_Style.html">789 high scalability-2010-03-05-Strategy: Planning for a Power Outage Google Style</a></p>
<p>Introduction: We can all learn from problems. The Google App Engine team has created a
teachable moment through a remarkably honest and forthcomingpost-mortem for
February 24th, 2010 outagepost, chronicling in elaborate detail a power outage
that took down Google App Engine for a few hours.The world is ending! The
cloud is unreliable! Jump ship! Not. This is not evidence that the cloud is a
beautiful, powerful and unsinkable ship that goes down on its maiden voyage.
Stuff happens, no matter how well you prepare. If you think private
datacenters don't go down, well, then I have some rearangeable deck chairs to
sell you. The goal is to keep improving and minimizing those failure windows.
From that perspective there is a lot to learn from the problems the Google App
Engine team encountered and how they plan to fix them.Please read the article
for all the juicy details, but here's what struck me as key:Power fails. Plan
for it. This seems to happen with unexpected frequency for such expensive and
well t</p><p>6 0.12651581 <a title="1030-tfidf-6" href="../high_scalability-2007/high_scalability-2007-09-18-Amazon_Architecture.html">96 high scalability-2007-09-18-Amazon Architecture</a></p>
<p>7 0.11867873 <a title="1030-tfidf-7" href="../high_scalability-2011/high_scalability-2011-04-25-The_Big_List_of_Articles_on_the_Amazon_Outage.html">1029 high scalability-2011-04-25-The Big List of Articles on the Amazon Outage</a></p>
<p>8 0.11351755 <a title="1030-tfidf-8" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>9 0.11285459 <a title="1030-tfidf-9" href="../high_scalability-2013/high_scalability-2013-10-15-Sponsored_Post%3A_Apple%2C_ScaleOut%2C_FreeAgent%2C_CloudStats.me%2C_Intechnica%2C_Couchbase%2C_MongoDB%2C_Stackdriver%2C_BlueStripe%2C_Booking%2C_Rackspace%2C_AiCache%2C_Aerospike%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1532 high scalability-2013-10-15-Sponsored Post: Apple, ScaleOut, FreeAgent, CloudStats.me, Intechnica, Couchbase, MongoDB, Stackdriver, BlueStripe, Booking, Rackspace, AiCache, Aerospike, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>10 0.1095762 <a title="1030-tfidf-10" href="../high_scalability-2013/high_scalability-2013-04-23-Facebook_Secrets_of_Web_Performance.html">1444 high scalability-2013-04-23-Facebook Secrets of Web Performance</a></p>
<p>11 0.10780449 <a title="1030-tfidf-11" href="../high_scalability-2014/high_scalability-2014-03-27-Strategy%3A_Cache_Stored_Procedure_Results.html">1620 high scalability-2014-03-27-Strategy: Cache Stored Procedure Results</a></p>
<p>12 0.10778287 <a title="1030-tfidf-12" href="../high_scalability-2013/high_scalability-2013-10-29-Sponsored_Post%3A_Apple%2C_NuoDB%2C_ScaleOut%2C_FreeAgent%2C_CloudStats.me%2C_Intechnica%2C_MongoDB%2C_Stackdriver%2C_BlueStripe%2C_Booking%2C_Rackspace%2C_AiCache%2C_Aerospike%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1539 high scalability-2013-10-29-Sponsored Post: Apple, NuoDB, ScaleOut, FreeAgent, CloudStats.me, Intechnica, MongoDB, Stackdriver, BlueStripe, Booking, Rackspace, AiCache, Aerospike, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>13 0.10712825 <a title="1030-tfidf-13" href="../high_scalability-2014/high_scalability-2014-04-29-Sponsored_Post%3A_Apple%2C_Wargaming.net%2C_PagerDuty%2C_HelloSign%2C_CrowdStrike%2C_Gengo%2C_ScaleOut_Software%2C_Couchbase%2C_Tokutek%2C_MongoDB%2C_BlueStripe%2C_AiScaler%2C_Aerospike%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7__.html">1639 high scalability-2014-04-29-Sponsored Post: Apple, Wargaming.net, PagerDuty, HelloSign, CrowdStrike, Gengo, ScaleOut Software, Couchbase, Tokutek, MongoDB, BlueStripe, AiScaler, Aerospike, LogicMonitor, AppDynamics, ManageEngine, Site24x7  </a></p>
<p>14 0.10569179 <a title="1030-tfidf-14" href="../high_scalability-2013/high_scalability-2013-11-12-Sponsored_Post%3A_Klout%2C_Apple%2C_NuoDB%2C_ScaleOut%2C_FreeAgent%2C_CloudStats.me%2C_Intechnica%2C_MongoDB%2C_Stackdriver%2C_BlueStripe%2C_Booking%2C_AiCache%2C_Aerospike%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1547 high scalability-2013-11-12-Sponsored Post: Klout, Apple, NuoDB, ScaleOut, FreeAgent, CloudStats.me, Intechnica, MongoDB, Stackdriver, BlueStripe, Booking, AiCache, Aerospike, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>15 0.10229644 <a title="1030-tfidf-15" href="../high_scalability-2012/high_scalability-2012-03-14-The_Azure_Outage%3A_Time_Is_a_SPOF%2C_Leap_Day_Doubly_So.html">1209 high scalability-2012-03-14-The Azure Outage: Time Is a SPOF, Leap Day Doubly So</a></p>
<p>16 0.096638575 <a title="1030-tfidf-16" href="../high_scalability-2013/high_scalability-2013-10-01-Sponsored_Post%3A_Apple%2C_Intechnica%2C_Couchbase%2C_MongoDB%2C_Stackdriver%2C_BlueStripe%2C_Surge%2C_Booking%2C_Rackspace%2C_AiCache%2C_Aerospike%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1525 high scalability-2013-10-01-Sponsored Post: Apple, Intechnica, Couchbase, MongoDB, Stackdriver, BlueStripe, Surge, Booking, Rackspace, AiCache, Aerospike, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>17 0.095627934 <a title="1030-tfidf-17" href="../high_scalability-2013/high_scalability-2013-09-03-Sponsored_Post%3A_Apple%2C_Couchbase%2C_Evernote%2C_10gen%2C_Stackdriver%2C_BlueStripe%2C_Surge%2C_Booking%2C_Rackspace%2C_AiCache%2C_Aerospike%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1510 high scalability-2013-09-03-Sponsored Post: Apple, Couchbase, Evernote, 10gen, Stackdriver, BlueStripe, Surge, Booking, Rackspace, AiCache, Aerospike, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>18 0.095463999 <a title="1030-tfidf-18" href="../high_scalability-2013/high_scalability-2013-09-17-Sponsored_Post%3A_Apple%2C_Couchbase%2C_Evernote%2C_MongoDB%2C_Stackdriver%2C_BlueStripe%2C_Surge%2C_Booking%2C_Rackspace%2C_AiCache%2C_Aerospike%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1518 high scalability-2013-09-17-Sponsored Post: Apple, Couchbase, Evernote, MongoDB, Stackdriver, BlueStripe, Surge, Booking, Rackspace, AiCache, Aerospike, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>19 0.093969919 <a title="1030-tfidf-19" href="../high_scalability-2013/high_scalability-2013-04-02-Sponsored_Post%3A_Rackspace%2C_Simple%2C_Fitbit%2C_Amazon%2C_Booking%2C_aiCache%2C_Aerospike%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1433 high scalability-2013-04-02-Sponsored Post: Rackspace, Simple, Fitbit, Amazon, Booking, aiCache, Aerospike, Percona, ScaleOut, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>20 0.09242209 <a title="1030-tfidf-20" href="../high_scalability-2013/high_scalability-2013-04-16-Sponsored_Post%3A_Surge%2C_Rackspace%2C_Simple%2C_Fitbit%2C_Amazon%2C_Booking%2C_aiCache%2C_Aerospike%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_LogicMonitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1441 high scalability-2013-04-16-Sponsored Post: Surge, Rackspace, Simple, Fitbit, Amazon, Booking, aiCache, Aerospike, Percona, ScaleOut, New Relic, LogicMonitor, AppDynamics, ManageEngine, Site24x7</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.166), (1, 0.028), (2, -0.028), (3, 0.03), (4, 0.042), (5, -0.073), (6, -0.0), (7, 0.006), (8, 0.004), (9, -0.073), (10, -0.029), (11, 0.025), (12, 0.006), (13, -0.031), (14, -0.003), (15, -0.017), (16, 0.003), (17, -0.023), (18, -0.032), (19, 0.013), (20, 0.02), (21, -0.03), (22, 0.026), (23, 0.052), (24, -0.047), (25, 0.001), (26, 0.013), (27, 0.021), (28, 0.01), (29, 0.037), (30, -0.035), (31, -0.031), (32, 0.025), (33, 0.005), (34, 0.031), (35, 0.01), (36, -0.009), (37, 0.032), (38, 0.059), (39, 0.005), (40, -0.021), (41, -0.06), (42, -0.024), (43, -0.008), (44, 0.072), (45, 0.006), (46, 0.022), (47, 0.032), (48, -0.009), (49, -0.058)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9630698 <a title="1030-lsi-1" href="../high_scalability-2011/high_scalability-2011-04-27-Heroku_Emergency_Strategy%3A_Incident_Command_System_and_8_Hour_Ops_Rotations_for_Fresh_Minds.html">1030 high scalability-2011-04-27-Heroku Emergency Strategy: Incident Command System and 8 Hour Ops Rotations for Fresh Minds</a></p>
<p>Introduction: In Resolved: Widespread Application Outage, Herokutells their story of how
they dealt with theAmazon outage. While taking 100% responsibility for the
downtime, they also shared a number of the strategies they used to bring their
service back to full working order.One ofHeroku'smost interesting strategies
wasn't a technical hack at all, but how they consciously went about deploying
their Ops personnel in response to the emergency. An outline of their strategy
is: Monitoring systems immediately alerted Ops to the problem. An on-call
engineer applied triage logic to the problem and classified it as serious,
which caused the on-callIncident Commanderto be woken out of restful slumber.
TheICcontactedAWS. They were in constant contact with theirAWSrepresentative
and worked closely withAWSto solve problems.TheICalertedHerokuengineers. A
full crew: support, data, and other engineering teams worked around the clock
to bring everything back online.The Ops team instituted an emergency incident
co</p><p>2 0.80494547 <a title="1030-lsi-2" href="../high_scalability-2012/high_scalability-2012-03-14-The_Azure_Outage%3A_Time_Is_a_SPOF%2C_Leap_Day_Doubly_So.html">1209 high scalability-2012-03-14-The Azure Outage: Time Is a SPOF, Leap Day Doubly So</a></p>
<p>Introduction: This is a guest post by Steve Newman, co-founder of Writely (Google Docs),
tech lead on the Paxos-based synchronous replication in Megastore, and founder
of cloud service providerScalyr.com.Microsoft's Azure service suffered a
widely publicized outage on February 28th / 29th. Microsoft recently published
an excellentpostmortem. For anyone trying to run a high-availability service,
this incident can teach several important lessons.The central lesson is that,
no matter how much work you put into redundancy, problems will arise. Murphy
is strong and, I might say, creative; things go wrong. So preventative
measures are important, but how you react to problems is just as important.
It's interesting to review the Azure incident in this light.The postmortem is
worth reading in its entirety, but here's a quick summary: each time Azure
launches a new VM, it creates a "transfer certificate" to secure
communications with that VM. There was a bug in the code that determines the
certificate expirat</p><p>3 0.73828214 <a title="1030-lsi-3" href="../high_scalability-2011/high_scalability-2011-07-20-Netflix%3A_Harden_Systems_Using_a_Barrel_of_Problem_Causing_Monkeys_-_Latency%2C_Conformity%2C_Doctor%2C_Janitor%2C_Security%2C_Internationalization%2C_Chaos.html">1083 high scalability-2011-07-20-Netflix: Harden Systems Using a Barrel of Problem Causing Monkeys - Latency, Conformity, Doctor, Janitor, Security, Internationalization, Chaos</a></p>
<p>Introduction: With a new Planet of the Apes coming out, this may be a touchy subject with
our new overlords, but Netflix is using a whole lot more trouble injecting
monkeys to test and iteratively harden their systems. We learned previously
how Netflix used Chaos Monkey, a tool to test failover handling by
continuously failing EC2 nodes. That was just a start. More monkeys have been
added to the barrel. Node failure is just one problem in a system. Imagine a
problem and you can imagine creating a monkey to test if your system is
handling that problem properly. Yury Izrailevsky talks about just this
approach in this very interesting post: The Netflix Simian Army.I know what
you are thinking, if monkeys are so great then why has Netflix been down
lately. Dmuino addressedthis potential embarrassment, putting all fears of
cloud inferiority to rest:Unfortunately we're not running 100% on the cloud
today. We're working on it, and we could use more help. The latest outage was
caused by a component that sti</p><p>4 0.73507112 <a title="1030-lsi-4" href="../high_scalability-2013/high_scalability-2013-08-19-What_can_the_Amazing_Race_to_the_South_Pole_Teach_us_About_Startups%3F.html">1503 high scalability-2013-08-19-What can the Amazing Race to the South Pole Teach us About Startups?</a></p>
<p>Introduction: At the heart of every software adventure exists a journey in service of a
quest. Melodramatic much? Sorry, but while wandering dazzled throughRace to
the End of the Earth, a fantastic exhibit at theRoyal BC Museumon the
1911-1912race to the South Polebetween Norwegian explorerRoald Amundsenand
British naval officerRobert Scott, I couldn't help but think of the two
radically different approaches each team took to the race and it shocked me to
see that some of the same principles that lead to success or failure in
software development also seem to lead to success or failure in exploration.I
wish I could reproduce the experience ofwalking through the exhibit. Plaque
after plaque I remember wondering out loud at Scott's choices and then nod in
agreement with Amundsen's approach. The core conflict was straight out of any
ancient Agile (Amundsen) vs Waterfall (Scott) thread you can find on Usenet.
And Waterfall lost.As background here are some sources you may want to read to
understand more</p><p>5 0.72578984 <a title="1030-lsi-5" href="../high_scalability-2013/high_scalability-2013-08-12-100_Curse_Free_Lessons_from_Gordon_Ramsay_on_Building_Great_Software.html">1500 high scalability-2013-08-12-100 Curse Free Lessons from Gordon Ramsay on Building Great Software</a></p>
<p>Introduction: Gordon Ramsayis a world renowned chef with a surprising amount to say on
software development. Well, he says it about cooking and running a restaurant,
but it applies to software development too.You may have seen Gordon Ramsay on
one of his many TV shows. Hell's Kitchen is a competition between chefs trying
to win a dream job: head chef of their own high-end restaurant. On this show
Ramsay is judge, jury, and executioner. And he chops off more than a few
heads. Kitchen Nightmares is a show where Ramsay is called in by restaurant
owners to help turn around their failing restaurants. On this show Ramsay is
there to help.If you just watch Hell's Kitchen you will likely conclude Ramsay
is one of the devil's own helpers ("ram" is the symbol of the devil and "say"
means he speaks for the devil: Ramsay). Ramsay screams, yells, cusses,
belittles, and throws tantrums even a 7 year old could learn from. Then he
does it all over gain just for spite. In Hell's Kitchen there's no evidence at
all of</p><p>6 0.72053057 <a title="1030-lsi-6" href="../high_scalability-2010/high_scalability-2010-03-05-Strategy%3A_Planning_for_a_Power_Outage_Google_Style.html">789 high scalability-2010-03-05-Strategy: Planning for a Power Outage Google Style</a></p>
<p>7 0.70607907 <a title="1030-lsi-7" href="../high_scalability-2013/high_scalability-2013-06-05-A_Simple_6_Step_Transition_Guide_for_Moving_Away_from_X_to_AWS_.html">1470 high scalability-2013-06-05-A Simple 6 Step Transition Guide for Moving Away from X to AWS </a></p>
<p>8 0.70440763 <a title="1030-lsi-8" href="../high_scalability-2008/high_scalability-2008-07-18-Robert_Scoble%27s_Rules_for_Successfully_Scaling_Startups.html">352 high scalability-2008-07-18-Robert Scoble's Rules for Successfully Scaling Startups</a></p>
<p>9 0.69411993 <a title="1030-lsi-9" href="../high_scalability-2008/high_scalability-2008-07-07-Five_Ways_to_Stop_Framework_Fixation_from_Crashing_Your_Scaling_Strategy.html">347 high scalability-2008-07-07-Five Ways to Stop Framework Fixation from Crashing Your Scaling Strategy</a></p>
<p>10 0.69039476 <a title="1030-lsi-10" href="../high_scalability-2011/high_scalability-2011-08-15-Should_any_cloud_be_considered_one_availability_zone%3F_The_Amazon_experience_says_yes..html">1098 high scalability-2011-08-15-Should any cloud be considered one availability zone? The Amazon experience says yes.</a></p>
<p>11 0.6890499 <a title="1030-lsi-11" href="../high_scalability-2007/high_scalability-2007-07-24-Major_Websites_Down%3A_Or_Why_You_Want_to_Run_in_Two_or_More_Data_Centers..html">23 high scalability-2007-07-24-Major Websites Down: Or Why You Want to Run in Two or More Data Centers.</a></p>
<p>12 0.68597484 <a title="1030-lsi-12" href="../high_scalability-2008/high_scalability-2008-03-25-Paper%3A_On_Designing_and_Deploying_Internet-Scale_Services.html">288 high scalability-2008-03-25-Paper: On Designing and Deploying Internet-Scale Services</a></p>
<p>13 0.67915642 <a title="1030-lsi-13" href="../high_scalability-2012/high_scalability-2012-01-09-The_Etsy_Saga%3A_From_Silos_to_Happy_to_Billions_of_Pageviews_a_Month.html">1171 high scalability-2012-01-09-The Etsy Saga: From Silos to Happy to Billions of Pageviews a Month</a></p>
<p>14 0.67751235 <a title="1030-lsi-14" href="../high_scalability-2013/high_scalability-2013-03-08-Stuff_The_Internet_Says_On_Scalability_For_March_8%2C_2013.html">1420 high scalability-2013-03-08-Stuff The Internet Says On Scalability For March 8, 2013</a></p>
<p>15 0.67604113 <a title="1030-lsi-15" href="../high_scalability-2007/high_scalability-2007-09-18-Amazon_Architecture.html">96 high scalability-2007-09-18-Amazon Architecture</a></p>
<p>16 0.67570519 <a title="1030-lsi-16" href="../high_scalability-2013/high_scalability-2013-05-29-Amazon%3A_Creating_a_Customer_Utopia_One_Culture_Hack_at_a_Time.html">1466 high scalability-2013-05-29-Amazon: Creating a Customer Utopia One Culture Hack at a Time</a></p>
<p>17 0.66063666 <a title="1030-lsi-17" href="../high_scalability-2007/high_scalability-2007-11-16-Mogulus_Doesn%27t_Own_a_Single_Server_and_has_%241.2_million_in_funding%2C_15%2C000_People_Creating_Channels.html">156 high scalability-2007-11-16-Mogulus Doesn't Own a Single Server and has $1.2 million in funding, 15,000 People Creating Channels</a></p>
<p>18 0.65972805 <a title="1030-lsi-18" href="../high_scalability-2013/high_scalability-2013-01-16-What_if_Cars_Were_Rented_Like_We_Hire_Programmers%3F.html">1388 high scalability-2013-01-16-What if Cars Were Rented Like We Hire Programmers?</a></p>
<p>19 0.65868515 <a title="1030-lsi-19" href="../high_scalability-2013/high_scalability-2013-07-17-How_do_you_create_a_100th_Monkey_software_development_culture%3F.html">1492 high scalability-2013-07-17-How do you create a 100th Monkey software development culture?</a></p>
<p>20 0.65802544 <a title="1030-lsi-20" href="../high_scalability-2012/high_scalability-2012-12-28-Stuff_The_Internet_Says_On_Scalability_For_December_28%2C_2012.html">1378 high scalability-2012-12-28-Stuff The Internet Says On Scalability For December 28, 2012</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.146), (2, 0.235), (10, 0.024), (28, 0.224), (30, 0.043), (61, 0.09), (77, 0.029), (79, 0.092), (85, 0.012), (94, 0.026)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96019506 <a title="1030-lda-1" href="../high_scalability-2012/high_scalability-2012-08-01-Prismatic_Update%3A_Machine_Learning_on_Documents_and_Users.html">1294 high scalability-2012-08-01-Prismatic Update: Machine Learning on Documents and Users</a></p>
<p>Introduction: In update toPrismatic Architecture - Using Machine Learning on Social Networks
to Figure Out What You Should Read on the Web, Jason Wolfe, even in the face
of deadening fatigue from long nights spent getting their iPhone app out, has
gallantly agreed to talk a little more about Primatic's approach to Machine
Learning.Documents and users are two areas where Prismatic applies ML (machine
learning):ML on DocumentsGiven an HTML document: learn how to extract the main
text of the page (rather than the sidebar, footer, comments, etc), its title,
author, best images, etcdetermine features for relevance (e.g., what the
article is about, topics, etc.)The setup for most of these tasks is pretty
typical. Models are trained using big batch jobs on other machines that read
data from s3, save the learned parameter files to s3, and then read (and
periodically refresh) the models from s3 in the ingest pipeline.All of the
data that flows out of the system can be fed back into this pipeline, which
helps</p><p>2 0.91874409 <a title="1030-lda-2" href="../high_scalability-2009/high_scalability-2009-05-25-non-sequential%2C_unique_identifier%2C_strategy_question.html">606 high scalability-2009-05-25-non-sequential, unique identifier, strategy question</a></p>
<p>Introduction: (Please bare with me, I'm a new, passionate, confident and terrified
programmer :D )Background:I'm pre-launch and 1 year into the development of my
application. My target is to be able to eventually handle millions of
registered users with 5-10% of them concurrent. Up to this point I've used
auto-increment to assign unique identifiers to rows. I am now considering
switching to a non-sequential strategy. Oh, I'm using the LAMP
configuration.My reasons for avoiding auto-increment:1. Complicates
replication when scaling horizontally. Risk of collision is significant (when
running multiple masters). Note: I've read the other entries in this forum
that relate to ID generation and there have been some great suggestions --
including a strategy that uses auto-increment in a way that avoids this
pitfall... That said, I'm still nervous about it.2. Potential bottleneck when
retrieving/assigning IDs -- IDs assigned at the database.My reasons for being
nervous about non-sequential IDs:1. To guarant</p><p>same-blog 3 0.91278678 <a title="1030-lda-3" href="../high_scalability-2011/high_scalability-2011-04-27-Heroku_Emergency_Strategy%3A_Incident_Command_System_and_8_Hour_Ops_Rotations_for_Fresh_Minds.html">1030 high scalability-2011-04-27-Heroku Emergency Strategy: Incident Command System and 8 Hour Ops Rotations for Fresh Minds</a></p>
<p>Introduction: In Resolved: Widespread Application Outage, Herokutells their story of how
they dealt with theAmazon outage. While taking 100% responsibility for the
downtime, they also shared a number of the strategies they used to bring their
service back to full working order.One ofHeroku'smost interesting strategies
wasn't a technical hack at all, but how they consciously went about deploying
their Ops personnel in response to the emergency. An outline of their strategy
is: Monitoring systems immediately alerted Ops to the problem. An on-call
engineer applied triage logic to the problem and classified it as serious,
which caused the on-callIncident Commanderto be woken out of restful slumber.
TheICcontactedAWS. They were in constant contact with theirAWSrepresentative
and worked closely withAWSto solve problems.TheICalertedHerokuengineers. A
full crew: support, data, and other engineering teams worked around the clock
to bring everything back online.The Ops team instituted an emergency incident
co</p><p>4 0.89018619 <a title="1030-lda-4" href="../high_scalability-2010/high_scalability-2010-09-17-Hot_Scalability_Links_For_Sep_17%2C_2010.html">903 high scalability-2010-09-17-Hot Scalability Links For Sep 17, 2010</a></p>
<p>Introduction: Disqus - Scaling the Worlds Largest Django App. Interesting overview of a
commenting system with 75 million comments and 250 million visitors. Lots of
good details on how they partition their database, testing, continuous
integration, feature switches, caching, delayed signals, and more.Things I
learnt tracking a billion events in 24 hours: Know your host, Scaling isn't
just servers, My servers need to talk to me more, Kill switches for users,
What you don't know is the problem, Don't mix server roles, Know your most
important users outside of your site.Tweets of Gold:georgebarnett: I read High
Scalability for useful articles about large scaling. Sadly though, nothing
useful ever shows up. #NoLongerBotheringnorthscale: wow that is fast! :) RT
@cgoldberg: was just running > 100k ops/sec against my 2-node #Membase
cluster... zazooom #nosqlturbofunctor: The root of many (horizontal)
scalability problems is an application level access to a writable filesystem.
(Thus, #appengine.)gwenshap:</p><p>5 0.8861711 <a title="1030-lda-5" href="../high_scalability-2013/high_scalability-2013-08-23-Stuff_The_Internet_Says_On_Scalability_For_August_23%2C_2013.html">1506 high scalability-2013-08-23-Stuff The Internet Says On Scalability For August 23, 2013</a></p>
<p>Introduction: Hey, it's HighScalability time:(Parkour is to terrain as programming is to
frameworks)5x: AWS vs combined size of other cloud vendors;Every Second on The
Internet: Why we need so many servers.Quotable Quotes:@chaliy: Today I learned
that I do not understand how #azure scaling works, instance scale does not
affect requests/sec I can load.@Lariar: Note how crazy this is. An
international launch would have been a huge deal. Now it's just another thing
you do.smacktoward: The problem with relying on donations is that people don't
make donations.@toddhoffious: Programming is a tool built by logical
positivists to solve the problems of idealists and pragmatists. We have a
fundamental mismatch here.@etherealmind: Me: "Weird, my phone data isn't
working" Them: "They turned the 3G off at the tower because it  interferes
with the particle accelerator"John Carmack: In com­puter sci­ence, just about
the only thing that's really sci­ence is when you're talk­ing about
algo­rithms. And opti­miza­tion</p><p>6 0.87142074 <a title="1030-lda-6" href="../high_scalability-2012/high_scalability-2012-06-08-Stuff_The_Internet_Says_On_Scalability_For_June_8%2C_2012.html">1261 high scalability-2012-06-08-Stuff The Internet Says On Scalability For June 8, 2012</a></p>
<p>7 0.86888957 <a title="1030-lda-7" href="../high_scalability-2010/high_scalability-2010-04-08-Hot_Scalability_Links_for_April_8%2C_2010.html">806 high scalability-2010-04-08-Hot Scalability Links for April 8, 2010</a></p>
<p>8 0.86453831 <a title="1030-lda-8" href="../high_scalability-2009/high_scalability-2009-12-17-Oracle_and_IBM_databases%3A_Disk-based_vs_In-memory_databases_.html">752 high scalability-2009-12-17-Oracle and IBM databases: Disk-based vs In-memory databases </a></p>
<p>9 0.86392158 <a title="1030-lda-9" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>10 0.84890223 <a title="1030-lda-10" href="../high_scalability-2014/high_scalability-2014-03-12-Paper%3A_Scalable_Eventually_Consistent_Counters_over_Unreliable_Networks.html">1611 high scalability-2014-03-12-Paper: Scalable Eventually Consistent Counters over Unreliable Networks</a></p>
<p>11 0.83657378 <a title="1030-lda-11" href="../high_scalability-2012/high_scalability-2012-07-30-Prismatic_Architecture_-_Using_Machine_Learning_on_Social_Networks_to_Figure_Out_What_You_Should_Read_on_the_Web_.html">1293 high scalability-2012-07-30-Prismatic Architecture - Using Machine Learning on Social Networks to Figure Out What You Should Read on the Web </a></p>
<p>12 0.83205652 <a title="1030-lda-12" href="../high_scalability-2013/high_scalability-2013-04-12-Stuff_The_Internet_Says_On_Scalability_For_April_12%2C_2013.html">1439 high scalability-2013-04-12-Stuff The Internet Says On Scalability For April 12, 2013</a></p>
<p>13 0.81611395 <a title="1030-lda-13" href="../high_scalability-2013/high_scalability-2013-01-11-Stuff_The_Internet_Says_On_Scalability_For_January_11%2C_2013.html">1385 high scalability-2013-01-11-Stuff The Internet Says On Scalability For January 11, 2013</a></p>
<p>14 0.81461984 <a title="1030-lda-14" href="../high_scalability-2010/high_scalability-2010-06-10-The_Four_Meta_Secrets_of_Scaling_at_Facebook.html">840 high scalability-2010-06-10-The Four Meta Secrets of Scaling at Facebook</a></p>
<p>15 0.81245446 <a title="1030-lda-15" href="../high_scalability-2009/high_scalability-2009-06-14-kngine_%27Knowledge_Engine%27_milestone_2.html">630 high scalability-2009-06-14-kngine 'Knowledge Engine' milestone 2</a></p>
<p>16 0.80826169 <a title="1030-lda-16" href="../high_scalability-2008/high_scalability-2008-01-24-Mailinator_Architecture.html">221 high scalability-2008-01-24-Mailinator Architecture</a></p>
<p>17 0.80783129 <a title="1030-lda-17" href="../high_scalability-2013/high_scalability-2013-04-23-Facebook_Secrets_of_Web_Performance.html">1444 high scalability-2013-04-23-Facebook Secrets of Web Performance</a></p>
<p>18 0.80711401 <a title="1030-lda-18" href="../high_scalability-2008/high_scalability-2008-02-19-Hadoop_Getting_Closer_to_1.0_Release.html">254 high scalability-2008-02-19-Hadoop Getting Closer to 1.0 Release</a></p>
<p>19 0.80667329 <a title="1030-lda-19" href="../high_scalability-2014/high_scalability-2014-03-11-Building_a_Social_Music_Service_Using_AWS%2C_Scala%2C_Akka%2C_Play%2C_MongoDB%2C_and_Elasticsearch.html">1609 high scalability-2014-03-11-Building a Social Music Service Using AWS, Scala, Akka, Play, MongoDB, and Elasticsearch</a></p>
<p>20 0.80628359 <a title="1030-lda-20" href="../high_scalability-2009/high_scalability-2009-04-10-Facebook%27s_Aditya_giving_presentation_on_Facebook_Architecture.html">562 high scalability-2009-04-10-Facebook's Aditya giving presentation on Facebook Architecture</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
