<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1075 high scalability-2011-07-07-Myth: Google Uses Server Farms So You Should Too - Resurrection of the Big-Ass Machines</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2011" href="../home/high_scalability-2011_home.html">high_scalability-2011</a> <a title="high_scalability-2011-1075" href="#">high_scalability-2011-1075</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1075 high scalability-2011-07-07-Myth: Google Uses Server Farms So You Should Too - Resurrection of the Big-Ass Machines</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2011-1075-html" href="http://highscalability.com//blog/2011/7/7/myth-google-uses-server-farms-so-you-should-too-resurrection.html">html</a></p><p>Introduction: For a long epoch there was a strategy of scaling up by making ever bigger
super computers. I had the pleasure of programming on a few large massively
multi-processor machines from SGI and DEC. Beautiful, highly specialized
machines that were very expensive. These met the double-tap extinction event
of Moore's law and a Google inspired era of commodity machine based clusters
and extreme software parallelism. Has the tide turned? Does it now make more
sense to use big machines instead of clusters?InBig-Ass Serversâ&bdquo;˘ and the myths
of clusters in bioinformatics, Jerm makes the case that for bionformatics,
it's more cost effective to buy a Big-Ass Server instead of using a cluster of
machines and a lot of specialized parallel programming techniques. It's a
classic scale-up argument that has been made more attractive by the recent
development of relatively inexpensive large machines.SeaMicrohas developed a
512 core machine. Dell has a new96 core server. Supermicro has48 coremachines.
These ar</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 For a long epoch there was a strategy of scaling up by making ever bigger super computers. [sent-1, score-0.136]
</p><p>2 I had the pleasure of programming on a few large massively multi-processor machines from SGI and DEC. [sent-2, score-0.358]
</p><p>3 These met the double-tap extinction event of Moore's law and a Google inspired era of commodity machine based clusters and extreme software parallelism. [sent-4, score-0.536]
</p><p>4 Does it now make more sense to use big machines instead of clusters? [sent-6, score-0.468]
</p><p>5 InBig-Ass Serversâ&bdquo;˘ and the myths of clusters in bioinformatics, Jerm makes the case that for bionformatics, it's more cost effective to buy a Big-Ass Server instead of using a cluster of machines and a lot of specialized parallel programming techniques. [sent-7, score-1.151]
</p><p>6 It's a classic scale-up argument that has been made more attractive by the recent development of relatively inexpensive large machines. [sent-8, score-0.261]
</p><p>7 These are new options in the scale-up game that have not been available before and could influence your architecture choice. [sent-12, score-0.2]
</p><p>8 Jerm's reasoning for preferring big-ass servers is:The development of multicore/multiprocessor machines and memory capacity has outpaced the speed of networks. [sent-13, score-0.633]
</p><p>9 NGS analyses tends to be more memory-bound and IO-bound rather than CPU-bound, so relying on a cluster of smaller machines can quickly overwhelm a network. [sent-14, score-0.918]
</p><p>10 NGS has forced the number of high-performance applications from BLAST and protein structure prediction to doing dozens of different little analyses, with tools that change on a monthly basis, or are homegrown to deal with special circumstances. [sent-15, score-0.504]
</p><p>11 There isn't time or ability to write each of these for parallel architectures. [sent-16, score-0.082]
</p><p>12 Jerm then goes on to tackle several myths about why a cluster is not necessarily the best solution, well worth reading. [sent-17, score-0.439]
</p><p>13 For Google solving search, investing in a large permanent cluster to do one thing very well makes a lot of sense. [sent-19, score-0.551]
</p><p>14 For someone trying to solve a particular problem and then move on to the next problem, investing a lot of time in writing a parallelized solution doesn't make as much sense. [sent-20, score-0.312]
</p><p>15 It makes more sense to find a big-ass machine, program simply, and let it rip. [sent-21, score-0.187]
</p><p>16 If agility and flexibility are key then clusters may not be right tool for your big data or big computation problem. [sent-22, score-0.735]
</p><p>17 It's interesting how this right tool for the right job idea keeps popping up and how technological innovation brings different options in and out of fashion. [sent-23, score-0.625]
</p><p>18 Now might be an inflection point in tool choice with the rise of the new big machines. [sent-24, score-0.439]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('machines', 0.272), ('investing', 0.22), ('clusters', 0.218), ('myths', 0.216), ('analyses', 0.209), ('outpaced', 0.145), ('sgi', 0.145), ('cluster', 0.14), ('epoch', 0.136), ('tide', 0.136), ('specialized', 0.132), ('extinction', 0.13), ('inflection', 0.13), ('tool', 0.128), ('preferring', 0.125), ('protein', 0.125), ('supermicro', 0.125), ('homegrown', 0.118), ('overwhelm', 0.115), ('popping', 0.112), ('options', 0.11), ('blast', 0.11), ('met', 0.104), ('big', 0.1), ('permanent', 0.1), ('right', 0.097), ('tends', 0.096), ('sense', 0.096), ('inexpensive', 0.093), ('parallelized', 0.092), ('agility', 0.092), ('prediction', 0.092), ('reasoning', 0.091), ('makes', 0.091), ('influence', 0.09), ('classic', 0.088), ('relying', 0.086), ('pleasure', 0.086), ('forced', 0.086), ('moore', 0.086), ('dell', 0.084), ('inspired', 0.084), ('dozens', 0.083), ('tackle', 0.083), ('parallel', 0.082), ('rise', 0.081), ('technological', 0.081), ('argument', 0.08), ('beautiful', 0.079), ('core', 0.078)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1075-tfidf-1" href="../high_scalability-2011/high_scalability-2011-07-07-Myth%3A_Google_Uses_Server_Farms_So_You_Should_Too_-_Resurrection_of_the_Big-Ass_Machines.html">1075 high scalability-2011-07-07-Myth: Google Uses Server Farms So You Should Too - Resurrection of the Big-Ass Machines</a></p>
<p>Introduction: For a long epoch there was a strategy of scaling up by making ever bigger
super computers. I had the pleasure of programming on a few large massively
multi-processor machines from SGI and DEC. Beautiful, highly specialized
machines that were very expensive. These met the double-tap extinction event
of Moore's law and a Google inspired era of commodity machine based clusters
and extreme software parallelism. Has the tide turned? Does it now make more
sense to use big machines instead of clusters?InBig-Ass Serversâ&bdquo;˘ and the myths
of clusters in bioinformatics, Jerm makes the case that for bionformatics,
it's more cost effective to buy a Big-Ass Server instead of using a cluster of
machines and a lot of specialized parallel programming techniques. It's a
classic scale-up argument that has been made more attractive by the recent
development of relatively inexpensive large machines.SeaMicrohas developed a
512 core machine. Dell has a new96 core server. Supermicro has48 coremachines.
These ar</p><p>2 0.11746229 <a title="1075-tfidf-2" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>Introduction: It remains that, from the same principles, I now demonstrate the frame of the
System of the World.-- Isaac NewtonThe practice of IT reminds me a lot of the
practice of science before Isaac Newton. Aristotelianism was dead, but there
was nothing to replace it. Then Newton came along, created a scientific
revolution with hisSystem of the World. And everything changed. That was New
System of the World number one.New System of the World number two was written
about by the incomparable Neal Stephenson in his incredible Baroque Cycle
series. It explores the singular creation of a new way of organizing society
grounded in new modes of thought in business, religion, politics, and science.
Our modern world emerged Enlightened as it could from this roiling cauldron of
forces.In IT we may have had a Leonardo da Vinci or even a Galileo, but we've
never had our Newton. Maybe we don't need a towering genius to make everything
clear? For years startups, like the frenetically inventive age of the 17th</p><p>3 0.11705396 <a title="1075-tfidf-3" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>Introduction: "But it is not complicated. [There's] just a lot of it." \--Richard Feynmanon
how the immense variety of the world arises from simple rules.Contents:Have We
Reached the End of Scaling?Applications Become Black Boxes Using Markets to
Scale and Control CostsLet's Welcome our Neo-Feudal OverlordsThe Economic
Argument for the Ambient CloudWhat Will Kill the Cloud?The Amazing Collective
Compute Power of the Ambient CloudUsing the Ambient Cloud as an Application
RuntimeApplications as Virtual StatesConclusionWe have not yet begun to scale.
The world is still fundamentally disconnected and for all our wisdom we are
still in the earliest days of learning how to build truly large planet-scaling
applications.Today 350 million users on Facebook is a lot of users and five
million followers on Twitter is a lot of followers. This may seem like a lot
now, but consider we have no planet wide applications yet. None.Tomorrow the
numbers foreshadow a newCambrian explosionof connectivity that will look as</p><p>4 0.1169059 <a title="1075-tfidf-4" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>Introduction: All in all this is still my favorite post and I still think it's an accurate
vision of a future. Not everyone agrees, but I guess we'll see..."But it is
not complicated. [There's] just a lot of it." \--Richard Feynmanon how the
immense variety of the world arises from simple rules.Contents:Have We Reached
the End of Scaling?Applications Become Black Boxes Using Markets to Scale and
Control CostsLet's Welcome our Neo-Feudal OverlordsThe Economic Argument for
the Ambient CloudWhat Will Kill the Cloud?The Amazing Collective Compute Power
of the Ambient CloudUsing the Ambient Cloud as an Application
RuntimeApplications as Virtual StatesConclusionWe have not yet begun to scale.
The world is still fundamentally disconnected and for all our wisdom we are
still in the earliest days of learning how to build truly large planet-scaling
applications.Today 350 million users on Facebook is a lot of users and five
million followers on Twitter is a lot of followers. This may seem like a lot
now, but c</p><p>5 0.11361596 <a title="1075-tfidf-5" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>Introduction: Update 2:Sorting 1 PB with MapReduce. PB is not peanut-butter-and-jelly
misspelled. It's 1 petabyte or 1000 terabytes or 1,000,000 gigabytes.It took
six hours and two minutes to sort 1PB (10 trillion 100-byte records) on 4,000
computersand the results were replicated thrice on 48,000 disks.Update:Greg
Lindenpoints to a new Google articleMapReduce: simplified data processing on
large clusters. Some interesting stats: 100k MapReduce jobs are executed each
day; more than 20 petabytes of data are processed per day; more than 10k
MapReduce programs have been implemented; machines are dual processor with
gigabit ethernet and 4-8 GB of memory.Google is the King of scalability.
Everyone knows Google for their large, sophisticated, and fast searching, but
they don't just shine in search. Their platform approach to building scalable
applications allows them to roll out internet scale applications at an
alarmingly high competition crushing rate. Their goal is always to build a
higher performing h</p><p>6 0.1126835 <a title="1075-tfidf-6" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>7 0.1039884 <a title="1075-tfidf-7" href="../high_scalability-2007/high_scalability-2007-11-19-Tailrank_Architecture_-_Learn_How_to_Track_Memes_Across_the_Entire_Blogosphere.html">160 high scalability-2007-11-19-Tailrank Architecture - Learn How to Track Memes Across the Entire Blogosphere</a></p>
<p>8 0.10331453 <a title="1075-tfidf-8" href="../high_scalability-2008/high_scalability-2008-10-13-Challenges_from_large_scale_computing_at_Google.html">409 high scalability-2008-10-13-Challenges from large scale computing at Google</a></p>
<p>9 0.10184406 <a title="1075-tfidf-9" href="../high_scalability-2007/high_scalability-2007-11-05-Strategy%3A_Diagonal_Scaling_-_Don%27t_Forget_to_Scale_Out_AND_Up.html">142 high scalability-2007-11-05-Strategy: Diagonal Scaling - Don't Forget to Scale Out AND Up</a></p>
<p>10 0.09920802 <a title="1075-tfidf-10" href="../high_scalability-2010/high_scalability-2010-04-06-Strategy%3A_Make_it_Really_Fast_vs_Do_the_Work_Up_Front.html">805 high scalability-2010-04-06-Strategy: Make it Really Fast vs Do the Work Up Front</a></p>
<p>11 0.098795086 <a title="1075-tfidf-11" href="../high_scalability-2007/high_scalability-2007-07-15-Lustre_cluster_file_system.html">13 high scalability-2007-07-15-Lustre cluster file system</a></p>
<p>12 0.096788742 <a title="1075-tfidf-12" href="../high_scalability-2010/high_scalability-2010-11-22-Strategy%3A_Google_Sends_Canary_Requests_into_the_Data_Mine.html">946 high scalability-2010-11-22-Strategy: Google Sends Canary Requests into the Data Mine</a></p>
<p>13 0.093609765 <a title="1075-tfidf-13" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>14 0.093112253 <a title="1075-tfidf-14" href="../high_scalability-2009/high_scalability-2009-08-05-Stack_Overflow_Architecture.html">671 high scalability-2009-08-05-Stack Overflow Architecture</a></p>
<p>15 0.093084447 <a title="1075-tfidf-15" href="../high_scalability-2008/high_scalability-2008-02-07-clusteradmin.blogspot.com_-_blog_about_building_and_administering_clusters.html">243 high scalability-2008-02-07-clusteradmin.blogspot.com - blog about building and administering clusters</a></p>
<p>16 0.092903331 <a title="1075-tfidf-16" href="../high_scalability-2012/high_scalability-2012-03-14-The_Azure_Outage%3A_Time_Is_a_SPOF%2C_Leap_Day_Doubly_So.html">1209 high scalability-2012-03-14-The Azure Outage: Time Is a SPOF, Leap Day Doubly So</a></p>
<p>17 0.092280015 <a title="1075-tfidf-17" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>18 0.090007268 <a title="1075-tfidf-18" href="../high_scalability-2007/high_scalability-2007-09-27-Product%3A_Ganglia_Monitoring_System.html">101 high scalability-2007-09-27-Product: Ganglia Monitoring System</a></p>
<p>19 0.089252338 <a title="1075-tfidf-19" href="../high_scalability-2007/high_scalability-2007-09-18-Amazon_Architecture.html">96 high scalability-2007-09-18-Amazon Architecture</a></p>
<p>20 0.088895589 <a title="1075-tfidf-20" href="../high_scalability-2014/high_scalability-2014-02-21-Stuff_The_Internet_Says_On_Scalability_For_February_21st%2C_2014.html">1600 high scalability-2014-02-21-Stuff The Internet Says On Scalability For February 21st, 2014</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.173), (1, 0.094), (2, 0.033), (3, 0.035), (4, -0.006), (5, -0.004), (6, 0.037), (7, 0.026), (8, 0.002), (9, 0.02), (10, 0.017), (11, -0.027), (12, 0.035), (13, 0.016), (14, 0.062), (15, -0.013), (16, -0.013), (17, -0.005), (18, -0.017), (19, 0.053), (20, 0.007), (21, 0.014), (22, -0.023), (23, -0.046), (24, -0.015), (25, 0.056), (26, 0.009), (27, -0.029), (28, -0.057), (29, 0.048), (30, 0.001), (31, 0.068), (32, -0.004), (33, -0.007), (34, -0.018), (35, -0.0), (36, 0.032), (37, -0.078), (38, -0.013), (39, 0.001), (40, 0.025), (41, -0.029), (42, -0.058), (43, -0.009), (44, 0.001), (45, 0.019), (46, 0.031), (47, -0.066), (48, -0.007), (49, -0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97931135 <a title="1075-lsi-1" href="../high_scalability-2011/high_scalability-2011-07-07-Myth%3A_Google_Uses_Server_Farms_So_You_Should_Too_-_Resurrection_of_the_Big-Ass_Machines.html">1075 high scalability-2011-07-07-Myth: Google Uses Server Farms So You Should Too - Resurrection of the Big-Ass Machines</a></p>
<p>Introduction: For a long epoch there was a strategy of scaling up by making ever bigger
super computers. I had the pleasure of programming on a few large massively
multi-processor machines from SGI and DEC. Beautiful, highly specialized
machines that were very expensive. These met the double-tap extinction event
of Moore's law and a Google inspired era of commodity machine based clusters
and extreme software parallelism. Has the tide turned? Does it now make more
sense to use big machines instead of clusters?InBig-Ass Serversâ&bdquo;˘ and the myths
of clusters in bioinformatics, Jerm makes the case that for bionformatics,
it's more cost effective to buy a Big-Ass Server instead of using a cluster of
machines and a lot of specialized parallel programming techniques. It's a
classic scale-up argument that has been made more attractive by the recent
development of relatively inexpensive large machines.SeaMicrohas developed a
512 core machine. Dell has a new96 core server. Supermicro has48 coremachines.
These ar</p><p>2 0.73766768 <a title="1075-lsi-2" href="../high_scalability-2013/high_scalability-2013-11-13-Google%3A_Multiplex_Multiple_Works_Loads_on_Computers_to_Increase_Machine_Utilization_and_Save_Money.html">1548 high scalability-2013-11-13-Google: Multiplex Multiple Works Loads on Computers to Increase Machine Utilization and Save Money</a></p>
<p>Introduction: Jeff Deangave a talk at SFBay ACMand at about 3 minutes in he goes over how
Google runs jobs on computers, which is different than how most shops
distribute workloads.It's common for machines to be dedicated to one service,
say run a database, run a cache, run this, or run that. The logic is:Better
control over responsiveness as you generally know the traffic loads a machine
will experience and you can over provision a box to be safe.Easier to manage,
load balance, configure, upgrade, create and make highly available. Since you
know what a machine does another machine can be provisioned to do the same
work.The problem is monocropping hardware though conceptually clean for humans
and safe for applications, is hugely wasteful. Machines are woefully
underutilized, even in a virtualized world.What Google does is use ashared
environmentin a datacenter where all kinds of stuff run on each computer.
Batch computation and interactive computations all run together on the same
machine. Each mach</p><p>3 0.73584312 <a title="1075-lsi-3" href="../high_scalability-2014/high_scalability-2014-03-07-Stuff_The_Internet_Says_On_Scalability_For_March_7th%2C_2014.html">1607 high scalability-2014-03-07-Stuff The Internet Says On Scalability For March 7th, 2014</a></p>
<p>Introduction: Hey, it's HighScalability time:Twitter valiantlysurvivedan OscarDDoSattack by
non-state actors.Several Billion: Apple iMessages per Day along with 40
billion notifications and 15 to 20 million FaceTime calls. Take that WhatsApp.
Their architecture? Hey, this is Apple, only the Shadow knows.200 bit quantum
computer: more states than atoms in the universe;10 million matches: Tinder's
per day catch;$1 billion: Kickstarter's long tail pledge funding
achievementQuotable Quotes:@cstross: Let me repeat that: 100,000 ARM
processors will cost you a total of $75,000 and probably fit in your jacket
pocket.@openflow: "You can no longer separate compute, storage, and
networking." -- @vkhosla #ONS2014@HackerNewsOnion: New node.js co-working
space has 1 table and everyone takes turns@chrismunns: we're reaching the
point where ease and low cost of doing DDOS attacks means you shouldn't serve
anything directly out of your origin@rilt: Mysql dead, Cassandra now in
production using @DataStax python drive</p><p>4 0.70874488 <a title="1075-lsi-4" href="../high_scalability-2008/high_scalability-2008-02-19-Hadoop_Getting_Closer_to_1.0_Release.html">254 high scalability-2008-02-19-Hadoop Getting Closer to 1.0 Release</a></p>
<p>Introduction: Update:Yahoo! Launches World's Largest Hadoop Production Application. A 10,000
core Hadoop cluster produces data used in every Yahoo! Web search query. Raw
disk is at 5 Petabytes. Their previous 1 petabyte database couldn't handle the
load and couldn't grow larger.Greg Lindenthinks the Google cluster has way
over 133,000 machines.From an InfoQinterviewwith project lead Doug Cutting, it
appearsHadoop, an open source distributed computing platform, is making good
progress towards their 1.0 release. They've successfully reached a 1000 node
cluster size, improved file system integrity, and jacked performance by 20x in
the last year.How they are making progress could be a good model for
anyone:breakThe speedup has been an aggregation of our work in the past few
years, and has been accomplished mostly by trial-and-error. We get things
running smoothly on a cluster of a given size, then double the size of the
cluster and see what breaks. We aim for performance to scale linearly as you
increas</p><p>5 0.70662463 <a title="1075-lsi-5" href="../high_scalability-2014/high_scalability-2014-01-03-Stuff_The_Internet_Says_On_Scalability_For_January_3rd%2C_2014.html">1572 high scalability-2014-01-03-Stuff The Internet Says On Scalability For January 3rd, 2014</a></p>
<p>Introduction: Hey, it's HighScalability time, can you handle the truth?Should software
architecturesinclude parasites? They increase diversity and complexity in the
food web.10 Million: classic hockey stick growth pattern for GitHub
repositoriesQuotable Quotes:Seymour Cray: A supercomputer is a device for
turning compute-bound problems into IO-bound problems.Robert Sapolsky: And why
is self-organization so beautiful to my atheistic self? Because if complex,
adaptive systems don't require a blue print, they don't require a blue print
maker. If they don't require lightning bolts, they don't require Someone
hurtling lightning bolts.@swardley: Asked for a history of PaaS? From memory,
public launch - Zimki ('06), BungeeLabs ('06), Heroku ('07), GAE ('08),
CloudFoundry ('11) ...@neil_conway: If you're designing scalable systems, you
should understand backpressure and build mechanisms to support it.Scott
Aaronson...the brain is not a quantum computer. A quantum computer is good at
factoring integers, disc</p><p>6 0.70341802 <a title="1075-lsi-6" href="../high_scalability-2010/high_scalability-2010-05-05-How_will_memristors_change_everything%3F_.html">823 high scalability-2010-05-05-How will memristors change everything? </a></p>
<p>7 0.69857943 <a title="1075-lsi-7" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>8 0.69799191 <a title="1075-lsi-8" href="../high_scalability-2012/high_scalability-2012-08-30-Stuff_The_Internet_Says_On_Scalability_For_August_31%2C_2012.html">1315 high scalability-2012-08-30-Stuff The Internet Says On Scalability For August 31, 2012</a></p>
<p>9 0.69773823 <a title="1075-lsi-9" href="../high_scalability-2014/high_scalability-2014-03-14-Stuff_The_Internet_Says_On_Scalability_For_March_14th%2C_2014.html">1612 high scalability-2014-03-14-Stuff The Internet Says On Scalability For March 14th, 2014</a></p>
<p>10 0.69583434 <a title="1075-lsi-10" href="../high_scalability-2012/high_scalability-2012-08-23-Economies_of_Scale_in_the_Datacenter%3A_Gmail_is_100x_Cheaper_to_Run_than_Your_Own_Server.html">1310 high scalability-2012-08-23-Economies of Scale in the Datacenter: Gmail is 100x Cheaper to Run than Your Own Server</a></p>
<p>11 0.69121873 <a title="1075-lsi-11" href="../high_scalability-2014/high_scalability-2014-02-21-Stuff_The_Internet_Says_On_Scalability_For_February_21st%2C_2014.html">1600 high scalability-2014-02-21-Stuff The Internet Says On Scalability For February 21st, 2014</a></p>
<p>12 0.69120181 <a title="1075-lsi-12" href="../high_scalability-2007/high_scalability-2007-11-05-Strategy%3A_Diagonal_Scaling_-_Don%27t_Forget_to_Scale_Out_AND_Up.html">142 high scalability-2007-11-05-Strategy: Diagonal Scaling - Don't Forget to Scale Out AND Up</a></p>
<p>13 0.68924177 <a title="1075-lsi-13" href="../high_scalability-2008/high_scalability-2008-01-17-Database_People_Hating_on_MapReduce.html">216 high scalability-2008-01-17-Database People Hating on MapReduce</a></p>
<p>14 0.68827057 <a title="1075-lsi-14" href="../high_scalability-2012/high_scalability-2012-03-23-Stuff_The_Internet_Says_On_Scalability_For_March_23%2C_2012.html">1214 high scalability-2012-03-23-Stuff The Internet Says On Scalability For March 23, 2012</a></p>
<p>15 0.68804532 <a title="1075-lsi-15" href="../high_scalability-2013/high_scalability-2013-08-30-Stuff_The_Internet_Says_On_Scalability_For_August_30%2C_2013.html">1509 high scalability-2013-08-30-Stuff The Internet Says On Scalability For August 30, 2013</a></p>
<p>16 0.67914248 <a title="1075-lsi-16" href="../high_scalability-2013/high_scalability-2013-12-06-Stuff_The_Internet_Says_On_Scalability_For_December_6th%2C_2013.html">1559 high scalability-2013-12-06-Stuff The Internet Says On Scalability For December 6th, 2013</a></p>
<p>17 0.67840058 <a title="1075-lsi-17" href="../high_scalability-2013/high_scalability-2013-11-08-Stuff_The_Internet_Says_On_Scalability_For_November_8th%2C_2013.html">1545 high scalability-2013-11-08-Stuff The Internet Says On Scalability For November 8th, 2013</a></p>
<p>18 0.67356926 <a title="1075-lsi-18" href="../high_scalability-2014/high_scalability-2014-02-19-Planetary-Scale_Computing_Architectures_for_Electronic_Trading_and_How_Algorithms_Shape_Our_World.html">1599 high scalability-2014-02-19-Planetary-Scale Computing Architectures for Electronic Trading and How Algorithms Shape Our World</a></p>
<p>19 0.67140627 <a title="1075-lsi-19" href="../high_scalability-2013/high_scalability-2013-03-15-Stuff_The_Internet_Says_On_Scalability_For_March_15%2C_2013.html">1424 high scalability-2013-03-15-Stuff The Internet Says On Scalability For March 15, 2013</a></p>
<p>20 0.67040694 <a title="1075-lsi-20" href="../high_scalability-2014/high_scalability-2014-04-25-Stuff_The_Internet_Says_On_Scalability_For_April_25th%2C_2014.html">1637 high scalability-2014-04-25-Stuff The Internet Says On Scalability For April 25th, 2014</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.18), (2, 0.149), (10, 0.05), (38, 0.173), (40, 0.027), (61, 0.03), (79, 0.158), (85, 0.088), (94, 0.059)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.92684883 <a title="1075-lda-1" href="../high_scalability-2009/high_scalability-2009-01-19-Papers%3A_Readings_in_Distributed_Systems.html">497 high scalability-2009-01-19-Papers: Readings in Distributed Systems</a></p>
<p>Introduction: Marton Trencseni has collected a wonderful list of different papers on
distributed systems. He's organized them into the following sections: The
Google Papers, Distributed Filesystems, Non-relational Distributed Databases,
The Lamport Papers, and Implementation Issues. Many old favorites on the list
and some that are likely new to you. My new favorite is "Frangipani: A
Scalable Distributed File System." How can you not love "Frangipani" as a
word?</p><p>same-blog 2 0.91731066 <a title="1075-lda-2" href="../high_scalability-2011/high_scalability-2011-07-07-Myth%3A_Google_Uses_Server_Farms_So_You_Should_Too_-_Resurrection_of_the_Big-Ass_Machines.html">1075 high scalability-2011-07-07-Myth: Google Uses Server Farms So You Should Too - Resurrection of the Big-Ass Machines</a></p>
<p>Introduction: For a long epoch there was a strategy of scaling up by making ever bigger
super computers. I had the pleasure of programming on a few large massively
multi-processor machines from SGI and DEC. Beautiful, highly specialized
machines that were very expensive. These met the double-tap extinction event
of Moore's law and a Google inspired era of commodity machine based clusters
and extreme software parallelism. Has the tide turned? Does it now make more
sense to use big machines instead of clusters?InBig-Ass Serversâ&bdquo;˘ and the myths
of clusters in bioinformatics, Jerm makes the case that for bionformatics,
it's more cost effective to buy a Big-Ass Server instead of using a cluster of
machines and a lot of specialized parallel programming techniques. It's a
classic scale-up argument that has been made more attractive by the recent
development of relatively inexpensive large machines.SeaMicrohas developed a
512 core machine. Dell has a new96 core server. Supermicro has48 coremachines.
These ar</p><p>3 0.88559014 <a title="1075-lda-3" href="../high_scalability-2013/high_scalability-2013-05-06-7_Not_So_Sexy_Tips_for_Saving_Money_On_Amazon.html">1452 high scalability-2013-05-06-7 Not So Sexy Tips for Saving Money On Amazon</a></p>
<p>Introduction: Harish Ganesan CTO of8KMiles has a very helpful blog, Cloud, Big Data and
Mobile, where he shows a nice analytical bent which leads to a lot of
practical advice and cost saving tips:Use SQS Batch Requests to reduce the
number of requests hitting SQS which saves costs. Sending 10 messages in a
single batch request which in the example save $30/month.Use SQS Long Polling
to reduce extra polling requests, cutting down empty receives, which in the
example saves ~$600 in empty receive leakage costs.Choose the right search
technology choice to save costs in AWS by matching your activity pattern to
the technology. For a small application with constant load or a heavily
utilized search tier or seasonal loads Amazon Cloud Search looks like the cost
efficient play. Use Amazon CloudFront Price Class to minimize costs by
selecting the right Price Class for your audience to potentially reduce
delivery costs by excluding Amazon CloudFront's more expensive edge
locations.Optimize ElastiCache Cluster</p><p>4 0.87843138 <a title="1075-lda-4" href="../high_scalability-2007/high_scalability-2007-09-10-Is_there_a_difference_between_partitioning_and_federation_and_sharding%3F.html">89 high scalability-2007-09-10-Is there a difference between partitioning and federation and sharding?</a></p>
<p>Introduction: Unlike Theo Schlossnagle, author ofScalable Internet Architectures, I am not a
stickler for semantics because I have an unswerving faith in the ultimate
unknowability of the world as experienced by others. That's why it is Theo who
bravely tackles the differences in his informative blog postPartitioning vs.
Federation vs. Sharding. Royans Tharakan also talks about it on hisblog.Is
there a difference and does it really matter to all our intrepid scalable
website builders?breakGenerally whatever Theo says is probably close to the
truth. Yet, in my mind I think of partitioning as abasic level categoryand
federation and sharding as more specific (subordinate) instances of
partitioning. And partitioning is a more specific instance of the more more
general (superordinate) category divide-and-conquer. Which isn't a useful way
to think about the topic at all.So, let's say federation is like Star Trek.
The Vulcans, Klingons, and Humans live in very separate policy domains, but
they each pledge</p><p>5 0.84269589 <a title="1075-lda-5" href="../high_scalability-2012/high_scalability-2012-07-23-Ask_HighScalability%3A_How_Do_I_Build_My_MegaUpload_%2B_Itunes_%2B_YouTube_Startup%3F.html">1288 high scalability-2012-07-23-Ask HighScalability: How Do I Build My MegaUpload + Itunes + YouTube Startup?</a></p>
<p>Introduction: This question was sent in by Val, who asking for a little help in creating the
next big thing. Any ideas?I'm planning to run my own, first startup website
and have been surfing the webs for relevant info to plan the technology I will
use for it (the frontend and the backend, including the software and the
hardware). The website will be something like a combination of:MegaUpload
(users will upload their files)iTunes (users will be paid for their
uploads)and YouTube (in the future I'm planning to let users watch/listen to
the content online, without downloading).I don't have any investors yet, nor
the budget - I'm still preparing the idea and I'm going to create first
implementation (an "alpha version") before I show it to potential investors.
Hence the initial technologies have to be extremely cheap *but* also highly
scalable in the future so that I don't have to redo anything when the website
grows.Unfortunately I don't have much experience in running big wesites but,
on the other hand</p><p>6 0.83842748 <a title="1075-lda-6" href="../high_scalability-2011/high_scalability-2011-09-21-5_Scalability_Poisons_and_3_Cloud_Scalability_Antidotes.html">1121 high scalability-2011-09-21-5 Scalability Poisons and 3 Cloud Scalability Antidotes</a></p>
<p>7 0.83836442 <a title="1075-lda-7" href="../high_scalability-2013/high_scalability-2013-09-04-Wide_Fast_SATA%3A_the_Recipe_for_Hot_Performance.html">1511 high scalability-2013-09-04-Wide Fast SATA: the Recipe for Hot Performance</a></p>
<p>8 0.83816415 <a title="1075-lda-8" href="../high_scalability-2008/high_scalability-2008-04-19-How_to_build_a_real-time_analytics_system%3F.html">304 high scalability-2008-04-19-How to build a real-time analytics system?</a></p>
<p>9 0.83789003 <a title="1075-lda-9" href="../high_scalability-2009/high_scalability-2009-09-16-The_VeriScale_Architecture_-_Elasticity_and_efficiency_for_private_clouds.html">706 high scalability-2009-09-16-The VeriScale Architecture - Elasticity and efficiency for private clouds</a></p>
<p>10 0.83243781 <a title="1075-lda-10" href="../high_scalability-2008/high_scalability-2008-11-24-Scalability_Perspectives_%233%3A_Marc_Andreessen_%E2%80%93_Internet_Platforms.html">450 high scalability-2008-11-24-Scalability Perspectives #3: Marc Andreessen – Internet Platforms</a></p>
<p>11 0.83187312 <a title="1075-lda-11" href="../high_scalability-2014/high_scalability-2014-01-08-Under_Snowden%27s_Light_Software_Architecture_Choices_Become_Murky.html">1575 high scalability-2014-01-08-Under Snowden's Light Software Architecture Choices Become Murky</a></p>
<p>12 0.83164293 <a title="1075-lda-12" href="../high_scalability-2010/high_scalability-2010-08-27-OpenStack_-_The_Answer_to%3A_How_do_We_Compete_with_Amazon%3F.html">888 high scalability-2010-08-27-OpenStack - The Answer to: How do We Compete with Amazon?</a></p>
<p>13 0.83151889 <a title="1075-lda-13" href="../high_scalability-2008/high_scalability-2008-11-13-Plenty_of_Fish_Says_Scaling_for_Free_Doesn%27t_Pay.html">442 high scalability-2008-11-13-Plenty of Fish Says Scaling for Free Doesn't Pay</a></p>
<p>14 0.83001649 <a title="1075-lda-14" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>15 0.82998061 <a title="1075-lda-15" href="../high_scalability-2012/high_scalability-2012-07-02-C_is_for_Compute_-_Google_Compute_Engine_%28GCE%29.html">1275 high scalability-2012-07-02-C is for Compute - Google Compute Engine (GCE)</a></p>
<p>16 0.82942963 <a title="1075-lda-16" href="../high_scalability-2011/high_scalability-2011-05-19-Zynga%27s_Z_Cloud_-_Scale_Fast_or_Fail_Fast_by_Merging_Private_and_Public_Clouds.html">1044 high scalability-2011-05-19-Zynga's Z Cloud - Scale Fast or Fail Fast by Merging Private and Public Clouds</a></p>
<p>17 0.82788014 <a title="1075-lda-17" href="../high_scalability-2008/high_scalability-2008-09-05-Product%3A_Tungsten_Replicator.html">380 high scalability-2008-09-05-Product: Tungsten Replicator</a></p>
<p>18 0.8265174 <a title="1075-lda-18" href="../high_scalability-2009/high_scalability-2009-10-06-Building_a_Unique_Data_Warehouse.html">716 high scalability-2009-10-06-Building a Unique Data Warehouse</a></p>
<p>19 0.82629049 <a title="1075-lda-19" href="../high_scalability-2013/high_scalability-2013-11-19-We_Finally_Cracked_the_10K_Problem_-_This_Time_for_Managing_Servers_with_2000x_Servers_Managed_Per_Sysadmin.html">1550 high scalability-2013-11-19-We Finally Cracked the 10K Problem - This Time for Managing Servers with 2000x Servers Managed Per Sysadmin</a></p>
<p>20 0.82484674 <a title="1075-lda-20" href="../high_scalability-2009/high_scalability-2009-02-05-Product%3A_HAProxy_-_The_Reliable%2C_High_Performance_TCP-HTTP_Load_Balancer.html">509 high scalability-2009-02-05-Product: HAProxy - The Reliable, High Performance TCP-HTTP Load Balancer</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
