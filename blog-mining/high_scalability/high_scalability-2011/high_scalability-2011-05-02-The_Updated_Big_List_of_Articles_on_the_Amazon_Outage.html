<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1033 high scalability-2011-05-02-The Updated Big List of Articles on the Amazon Outage</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2011" href="../home/high_scalability-2011_home.html">high_scalability-2011</a> <a title="high_scalability-2011-1033" href="#">high_scalability-2011-1033</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1033 high scalability-2011-05-02-The Updated Big List of Articles on the Amazon Outage</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2011-1033-html" href="http://highscalability.com//blog/2011/5/2/the-updated-big-list-of-articles-on-the-amazon-outage.html">html</a></p><p>Introduction: Since  The Big List Of Articles On The Amazon Outage  was published we've a had few updates that people might not have seen. Amazon of course released their  Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region . Netlix shared their  Lessons Learned from the AWS Outage  as did Heroku ( How Heroku Survived the Amazon Outage ), Smug Mug ( How SmugMug survived the Amazonpocalypse ), and SimpleGeo ( How SimpleGeo Stayed Up During the AWS Downtime ). 
 
The curious thing from my perspective is the general lack of response to Amazon's explanation. I expected more discussion. There's been almost none that I've seen. My guess is very few people understand what Amazon was talking about enough to comment whereas almost everyone feels qualified to talk about the event itself.
 
 Lesson for crisis handlers : deep dive post-mortems that are timely, long, honestish, and highly technical are the most effective means of staunching the downward spiral of media attention.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Netlix shared their  Lessons Learned from the AWS Outage  as did Heroku ( How Heroku Survived the Amazon Outage ), Smug Mug ( How SmugMug survived the Amazonpocalypse ), and SimpleGeo ( How SimpleGeo Stayed Up During the AWS Downtime ). [sent-3, score-0.27]
</p><p>2 by Someone at Bizo    Joe Stump's explanation  of how SimpleGeo survived     How Netflix Survived the Outage     Why Twilio Wasn’t Affected by Today’s AWS Issues  on Twilio Engineering's Blog ( Hacker News  thread)    On reddit's outage      What caused the Quora problems/outage in April 2011? [sent-13, score-0.518]
</p><p>3 Availability, redundancy, failover and data backups at LearnBoost     How our small startup survived the Amazon EC2 Cloud-pocalypse  from mobile app developer    Recovering from Amazon cloud outage  by Drew Engelson of PBS. [sent-14, score-0.92]
</p><p>4 PBS was affected for a while primarily because we do use EBS-backed RDS databases. [sent-15, score-0.061]
</p><p>5 From Comment          Amazon Web Services Discussion Forum    A fascinating peek into the experiences of people who were dealing with the outage while they were experiencing it. [sent-18, score-0.518]
</p><p>6 In Summary      Amazon EC2 outage: summary and lessons learned  by RightScale    AWS outage timeline & downtimes by recovery strategy  by Eric Kidd    The Aftermath of Amazon’s Cloud Outage  by Rich Miller      Taking Sides: It's the Customer's Fault      So Your AWS-based Application is Down? [sent-39, score-0.722]
</p><p>7 com’s real problem isn’t the outage, it’s the communication  by Keith Smith     How to work around Amazon EC2 outages  by James Cohen ( Hacker News  thread)    Today’s EC2 / EBS Outage: Lessons learned  on Agile Sysadmin    Amazon EC2 has gone down -what would a prefered hosting platform be? [sent-41, score-0.21]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('outage', 0.518), ('survived', 0.27), ('amazon', 0.23), ('hacker', 0.161), ('aws', 0.15), ('simplegeo', 0.128), ('news', 0.121), ('rds', 0.12), ('ebs', 0.109), ('learned', 0.106), ('east', 0.106), ('lessons', 0.098), ('heroku', 0.098), ('discussion', 0.091), ('amazonpocalypse', 0.089), ('downtimeby', 0.089), ('outageby', 0.089), ('cloud', 0.087), ('disruption', 0.084), ('twilio', 0.08), ('newsthread', 0.077), ('forum', 0.075), ('smugmug', 0.07), ('downtime', 0.069), ('stump', 0.068), ('sky', 0.068), ('falling', 0.064), ('sides', 0.062), ('redundancy', 0.062), ('thread', 0.062), ('affected', 0.061), ('stayed', 0.06), ('outages', 0.054), ('west', 0.054), ('netflix', 0.052), ('fail', 0.051), ('hosting', 0.05), ('zones', 0.048), ('premium', 0.047), ('backups', 0.045), ('jeff', 0.045), ('agile', 0.045), ('smug', 0.044), ('amazonas', 0.044), ('archeology', 0.044), ('architectthe', 0.044), ('avert', 0.044), ('awsany', 0.044), ('azureare', 0.044), ('badlessons', 0.044)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000017 <a title="1033-tfidf-1" href="../high_scalability-2011/high_scalability-2011-05-02-The_Updated_Big_List_of_Articles_on_the_Amazon_Outage.html">1033 high scalability-2011-05-02-The Updated Big List of Articles on the Amazon Outage</a></p>
<p>Introduction: Since  The Big List Of Articles On The Amazon Outage  was published we've a had few updates that people might not have seen. Amazon of course released their  Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region . Netlix shared their  Lessons Learned from the AWS Outage  as did Heroku ( How Heroku Survived the Amazon Outage ), Smug Mug ( How SmugMug survived the Amazonpocalypse ), and SimpleGeo ( How SimpleGeo Stayed Up During the AWS Downtime ). 
 
The curious thing from my perspective is the general lack of response to Amazon's explanation. I expected more discussion. There's been almost none that I've seen. My guess is very few people understand what Amazon was talking about enough to comment whereas almost everyone feels qualified to talk about the event itself.
 
 Lesson for crisis handlers : deep dive post-mortems that are timely, long, honestish, and highly technical are the most effective means of staunching the downward spiral of media attention.</p><p>2 0.90402269 <a title="1033-tfidf-2" href="../high_scalability-2011/high_scalability-2011-04-25-The_Big_List_of_Articles_on_the_Amazon_Outage.html">1029 high scalability-2011-04-25-The Big List of Articles on the Amazon Outage</a></p>
<p>Introduction: Please see  The Updated Big List Of Articles On The Amazon Outage  for a new improved list. 
 
So many great articles have been written on the Amazon Outage. Some aim at being helpful, some chastise developers for being so stupid, some chastise Amazon for being so incompetent, some talk about the pain they and their companies have experienced, and some even predict the downfall of the cloud. Still others say we have seen a sea change in future of the cloud, a prediction that's hard to disagree with, though the shape of the change remains...cloudy.
 
I'll try to keep this list update as more information comes out. There will be a lot for developers to consider going forward. If there's a resource you think should be added, just let me know.
  Amazon's Explanation of What Happened   
  Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region  
  Hackers News thread on AWS Service Disruption Post Mortem   
  Quite Funny Commentary on the Summary  
   Experiences f</p><p>3 0.29000437 <a title="1033-tfidf-3" href="../high_scalability-2011/high_scalability-2011-06-09-Retrospect_on_recent_AWS_outage_and_Resilient_Cloud-Based_Architecture.html">1056 high scalability-2011-06-09-Retrospect on recent AWS outage and Resilient Cloud-Based Architecture</a></p>
<p>Introduction: A bit over a month ago Amazon experienced its infamous AWS outage in the US East Region. As a cloud evangelist, I was intrigued by the history of the outage as it occurred. There were great posts during and after the outage from those who went down. But more interestingly for me as architect were the detailed posts of those who managed to survive the outage relatively unharmed, such as  SimpleGeo ,  Netflix , SmugMug ,  SmugMug’s CTO ,  Twilio ,  Bizo  and others.
 
Reading through the experience of others, I tried to summarize the  patterns, principles and best practices  that emerged from these posts, as I believe we can learn a lot from them on how to design our business applications to truly leverage on the benefits that the cloud offers in high availability and scalability.
 
The main principles, patterns and best practices are:
  
 Design for failure 
 Stateless and autonomous services 
 Redundant hot copies spread across zones 
 Spread across several public cloud vendors and/or</p><p>4 0.21025582 <a title="1033-tfidf-4" href="../high_scalability-2011/high_scalability-2011-08-15-Should_any_cloud_be_considered_one_availability_zone%3F_The_Amazon_experience_says_yes..html">1098 high scalability-2011-08-15-Should any cloud be considered one availability zone? The Amazon experience says yes.</a></p>
<p>Introduction: Amazon has a very will written account of their 8/8/2011 downtime:  Summary of the Amazon EC2, Amazon EBS, and Amazon RDS Service Event in the EU West Region . Power failed, backup generators failed to kick in, there weren't enough resources for EBS volumes to recover, API servers where overwhelmed, a DNS failure caused failovers to alternate availability zones to fail, a double fault occurred as the power event interrupted the repair of a different bug. All kind of typical stuff that just seems to happen.
 
Considering the  previous outage , the big question for programmers is: what does this mean? What does it mean for how systems should be structured? Have we learned something that can't be unlearned?
 
The Amazon post has lots of good insights into how EBS and RDS work, plus lessons learned. The short of the problem is large + complex = high probability of failure. The immediate fixes are adding more resources, more redundancy, more isolation between components, more automation, re</p><p>5 0.18439922 <a title="1033-tfidf-5" href="../high_scalability-2014/high_scalability-2014-04-14-How_do_you_even_do_anything_without_using_EBS%3F.html">1631 high scalability-2014-04-14-How do you even do anything without using EBS?</a></p>
<p>Introduction: In a recent thread on Hacker News discussing  recent AWS price changes ,  seldo  mentioned they use AWS for business, they just never use EBS on AWS. A good question was asked:
  

How do you even do anything without using EBS?

  
Amazon certainly makes using EBS the easiest path. And EBS has a better reliability record as of late, but it's still often recommended to not use EBS. This avoids a single point of failure at the cost of a lot of complexity, though as AWS uses EBS internally, not using EBS may not save you if you use other AWS services like RDS or ELB.
 
If you don't want to use EBS, it's hard to know where to even start. A dilemma to which Kevin Nuckolls  gives a great answer :
  

Well, you break your services out onto stateless and stateful machines. After that, you make sure that each of your stateful services is resilient to individual node failure. I prefer to believe that if you can't roll your entire infrastructure over to new nodes monthly then you're unprepared fo</p><p>6 0.1563386 <a title="1033-tfidf-6" href="../high_scalability-2012/high_scalability-2012-07-06-Stuff_The_Internet_Says_On_Scalability_For_July_6%2C_2012.html">1278 high scalability-2012-07-06-Stuff The Internet Says On Scalability For July 6, 2012</a></p>
<p>7 0.15457736 <a title="1033-tfidf-7" href="../high_scalability-2011/high_scalability-2011-04-22-Stuff_The_Internet_Says_On_Scalability_For_April_22%2C_2011.html">1028 high scalability-2011-04-22-Stuff The Internet Says On Scalability For April 22, 2011</a></p>
<p>8 0.14461385 <a title="1033-tfidf-8" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>9 0.13778597 <a title="1033-tfidf-9" href="../high_scalability-2012/high_scalability-2012-10-26-Stuff_The_Internet_Says_On_Scalability_For_October_26%2C_2012.html">1348 high scalability-2012-10-26-Stuff The Internet Says On Scalability For October 26, 2012</a></p>
<p>10 0.13471173 <a title="1033-tfidf-10" href="../high_scalability-2011/high_scalability-2011-04-27-Heroku_Emergency_Strategy%3A_Incident_Command_System_and_8_Hour_Ops_Rotations_for_Fresh_Minds.html">1030 high scalability-2011-04-27-Heroku Emergency Strategy: Incident Command System and 8 Hour Ops Rotations for Fresh Minds</a></p>
<p>11 0.13434096 <a title="1033-tfidf-11" href="../high_scalability-2013/high_scalability-2013-02-08-Stuff_The_Internet_Says_On_Scalability_For_February_8%2C_2013.html">1403 high scalability-2013-02-08-Stuff The Internet Says On Scalability For February 8, 2013</a></p>
<p>12 0.13394292 <a title="1033-tfidf-12" href="../high_scalability-2012/high_scalability-2012-03-14-The_Azure_Outage%3A_Time_Is_a_SPOF%2C_Leap_Day_Doubly_So.html">1209 high scalability-2012-03-14-The Azure Outage: Time Is a SPOF, Leap Day Doubly So</a></p>
<p>13 0.13190387 <a title="1033-tfidf-13" href="../high_scalability-2008/high_scalability-2008-12-30-Scalability_Perspectives_%235%3A_Werner_Vogels_%E2%80%93_The_Amazon_Technology_Platform.html">480 high scalability-2008-12-30-Scalability Perspectives #5: Werner Vogels – The Amazon Technology Platform</a></p>
<p>14 0.1317061 <a title="1033-tfidf-14" href="../high_scalability-2010/high_scalability-2010-04-28-Elasticity_for_the_Enterprise_--_Ensuring_Continuous_High_Availability_in_a_Disaster_Failure_Scenario.html">816 high scalability-2010-04-28-Elasticity for the Enterprise -- Ensuring Continuous High Availability in a Disaster Failure Scenario</a></p>
<p>15 0.13118134 <a title="1033-tfidf-15" href="../high_scalability-2013/high_scalability-2013-06-05-A_Simple_6_Step_Transition_Guide_for_Moving_Away_from_X_to_AWS_.html">1470 high scalability-2013-06-05-A Simple 6 Step Transition Guide for Moving Away from X to AWS </a></p>
<p>16 0.13099571 <a title="1033-tfidf-16" href="../high_scalability-2007/high_scalability-2007-07-30-Build_an_Infinitely_Scalable_Infrastructure_for_%24100_Using_Amazon_Services.html">38 high scalability-2007-07-30-Build an Infinitely Scalable Infrastructure for $100 Using Amazon Services</a></p>
<p>17 0.12097166 <a title="1033-tfidf-17" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>18 0.11878734 <a title="1033-tfidf-18" href="../high_scalability-2014/high_scalability-2014-03-03-The_%E2%80%9CFour_Hamiltons%E2%80%9D_Framework_for_Mitigating_Faults_in_the_Cloud%3A_Avoid_it%2C_Mask_it%2C_Bound_it%2C_Fix_it_Fast.html">1604 high scalability-2014-03-03-The “Four Hamiltons” Framework for Mitigating Faults in the Cloud: Avoid it, Mask it, Bound it, Fix it Fast</a></p>
<p>19 0.10918207 <a title="1033-tfidf-19" href="../high_scalability-2007/high_scalability-2007-12-13-Amazon_SimpleDB_-_Scalable_Cloud_Database.html">184 high scalability-2007-12-13-Amazon SimpleDB - Scalable Cloud Database</a></p>
<p>20 0.108975 <a title="1033-tfidf-20" href="../high_scalability-2013/high_scalability-2013-11-05-10_Things_You_Should_Know_About_AWS.html">1543 high scalability-2013-11-05-10 Things You Should Know About AWS</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, 0.055), (2, 0.007), (3, 0.138), (4, -0.074), (5, -0.128), (6, -0.036), (7, -0.192), (8, 0.13), (9, -0.159), (10, -0.017), (11, -0.048), (12, 0.03), (13, -0.097), (14, -0.124), (15, -0.04), (16, 0.09), (17, 0.001), (18, 0.012), (19, 0.036), (20, 0.04), (21, -0.007), (22, 0.011), (23, 0.12), (24, -0.137), (25, -0.054), (26, 0.032), (27, 0.048), (28, 0.043), (29, 0.064), (30, -0.066), (31, -0.083), (32, 0.109), (33, -0.128), (34, 0.094), (35, 0.043), (36, 0.086), (37, 0.118), (38, 0.045), (39, 0.04), (40, 0.102), (41, -0.155), (42, -0.117), (43, -0.064), (44, 0.134), (45, -0.052), (46, 0.018), (47, -0.004), (48, 0.001), (49, 0.006)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96673948 <a title="1033-lsi-1" href="../high_scalability-2011/high_scalability-2011-05-02-The_Updated_Big_List_of_Articles_on_the_Amazon_Outage.html">1033 high scalability-2011-05-02-The Updated Big List of Articles on the Amazon Outage</a></p>
<p>Introduction: Since  The Big List Of Articles On The Amazon Outage  was published we've a had few updates that people might not have seen. Amazon of course released their  Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region . Netlix shared their  Lessons Learned from the AWS Outage  as did Heroku ( How Heroku Survived the Amazon Outage ), Smug Mug ( How SmugMug survived the Amazonpocalypse ), and SimpleGeo ( How SimpleGeo Stayed Up During the AWS Downtime ). 
 
The curious thing from my perspective is the general lack of response to Amazon's explanation. I expected more discussion. There's been almost none that I've seen. My guess is very few people understand what Amazon was talking about enough to comment whereas almost everyone feels qualified to talk about the event itself.
 
 Lesson for crisis handlers : deep dive post-mortems that are timely, long, honestish, and highly technical are the most effective means of staunching the downward spiral of media attention.</p><p>2 0.94819707 <a title="1033-lsi-2" href="../high_scalability-2011/high_scalability-2011-04-25-The_Big_List_of_Articles_on_the_Amazon_Outage.html">1029 high scalability-2011-04-25-The Big List of Articles on the Amazon Outage</a></p>
<p>Introduction: Please see  The Updated Big List Of Articles On The Amazon Outage  for a new improved list. 
 
So many great articles have been written on the Amazon Outage. Some aim at being helpful, some chastise developers for being so stupid, some chastise Amazon for being so incompetent, some talk about the pain they and their companies have experienced, and some even predict the downfall of the cloud. Still others say we have seen a sea change in future of the cloud, a prediction that's hard to disagree with, though the shape of the change remains...cloudy.
 
I'll try to keep this list update as more information comes out. There will be a lot for developers to consider going forward. If there's a resource you think should be added, just let me know.
  Amazon's Explanation of What Happened   
  Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region  
  Hackers News thread on AWS Service Disruption Post Mortem   
  Quite Funny Commentary on the Summary  
   Experiences f</p><p>3 0.84103549 <a title="1033-lsi-3" href="../high_scalability-2011/high_scalability-2011-08-15-Should_any_cloud_be_considered_one_availability_zone%3F_The_Amazon_experience_says_yes..html">1098 high scalability-2011-08-15-Should any cloud be considered one availability zone? The Amazon experience says yes.</a></p>
<p>Introduction: Amazon has a very will written account of their 8/8/2011 downtime:  Summary of the Amazon EC2, Amazon EBS, and Amazon RDS Service Event in the EU West Region . Power failed, backup generators failed to kick in, there weren't enough resources for EBS volumes to recover, API servers where overwhelmed, a DNS failure caused failovers to alternate availability zones to fail, a double fault occurred as the power event interrupted the repair of a different bug. All kind of typical stuff that just seems to happen.
 
Considering the  previous outage , the big question for programmers is: what does this mean? What does it mean for how systems should be structured? Have we learned something that can't be unlearned?
 
The Amazon post has lots of good insights into how EBS and RDS work, plus lessons learned. The short of the problem is large + complex = high probability of failure. The immediate fixes are adding more resources, more redundancy, more isolation between components, more automation, re</p><p>4 0.78729993 <a title="1033-lsi-4" href="../high_scalability-2009/high_scalability-2009-04-07-Six_Lessons_Learned_Deploying_a_Large-scale_Infrastructure_in_Amazon_EC2_.html">559 high scalability-2009-04-07-Six Lessons Learned Deploying a Large-scale Infrastructure in Amazon EC2 </a></p>
<p>Introduction: Lessons learned from  OpenX's large-scale deployment  to Amazon EC2:
   Expect failures; what's more, embrace them      Fully automate your infrastructure deployments     Design your infrastructure so that it scales horizontally     Establish clear measurable goals     Be prepared to quickly identify and eliminate bottlenecks     Play wack-a-mole for a while, until things get stable</p><p>5 0.71791899 <a title="1033-lsi-5" href="../high_scalability-2014/high_scalability-2014-04-14-How_do_you_even_do_anything_without_using_EBS%3F.html">1631 high scalability-2014-04-14-How do you even do anything without using EBS?</a></p>
<p>Introduction: In a recent thread on Hacker News discussing  recent AWS price changes ,  seldo  mentioned they use AWS for business, they just never use EBS on AWS. A good question was asked:
  

How do you even do anything without using EBS?

  
Amazon certainly makes using EBS the easiest path. And EBS has a better reliability record as of late, but it's still often recommended to not use EBS. This avoids a single point of failure at the cost of a lot of complexity, though as AWS uses EBS internally, not using EBS may not save you if you use other AWS services like RDS or ELB.
 
If you don't want to use EBS, it's hard to know where to even start. A dilemma to which Kevin Nuckolls  gives a great answer :
  

Well, you break your services out onto stateless and stateful machines. After that, you make sure that each of your stateful services is resilient to individual node failure. I prefer to believe that if you can't roll your entire infrastructure over to new nodes monthly then you're unprepared fo</p><p>6 0.63515478 <a title="1033-lsi-6" href="../high_scalability-2010/high_scalability-2010-04-28-Elasticity_for_the_Enterprise_--_Ensuring_Continuous_High_Availability_in_a_Disaster_Failure_Scenario.html">816 high scalability-2010-04-28-Elasticity for the Enterprise -- Ensuring Continuous High Availability in a Disaster Failure Scenario</a></p>
<p>7 0.62622178 <a title="1033-lsi-7" href="../high_scalability-2008/high_scalability-2008-12-30-Scalability_Perspectives_%235%3A_Werner_Vogels_%E2%80%93_The_Amazon_Technology_Platform.html">480 high scalability-2008-12-30-Scalability Perspectives #5: Werner Vogels – The Amazon Technology Platform</a></p>
<p>8 0.61894643 <a title="1033-lsi-8" href="../high_scalability-2008/high_scalability-2008-12-29-100%25_on_Amazon_Web_Services%3A_Soocial.com_-_a_lesson_of_porting_your_service_to_Amazon.html">477 high scalability-2008-12-29-100% on Amazon Web Services: Soocial.com - a lesson of porting your service to Amazon</a></p>
<p>9 0.61873722 <a title="1033-lsi-9" href="../high_scalability-2013/high_scalability-2013-02-04-Is_Provisioned_IOPS_Better%3F_Yes%2C_it_Delivers_More_Consistent_and_Higher_Performance_IO.html">1398 high scalability-2013-02-04-Is Provisioned IOPS Better? Yes, it Delivers More Consistent and Higher Performance IO</a></p>
<p>10 0.59957021 <a title="1033-lsi-10" href="../high_scalability-2011/high_scalability-2011-10-27-Strategy%3A_Survive_a_Comet_Strike_in_the_East_With_Reserved_Instances_in_the_West.html">1133 high scalability-2011-10-27-Strategy: Survive a Comet Strike in the East With Reserved Instances in the West</a></p>
<p>11 0.57679486 <a title="1033-lsi-11" href="../high_scalability-2007/high_scalability-2007-12-13-Amazon_SimpleDB_-_Scalable_Cloud_Database.html">184 high scalability-2007-12-13-Amazon SimpleDB - Scalable Cloud Database</a></p>
<p>12 0.55257761 <a title="1033-lsi-12" href="../high_scalability-2014/high_scalability-2014-01-08-Under_Snowden%27s_Light_Software_Architecture_Choices_Become_Murky.html">1575 high scalability-2014-01-08-Under Snowden's Light Software Architecture Choices Become Murky</a></p>
<p>13 0.54682773 <a title="1033-lsi-13" href="../high_scalability-2012/high_scalability-2012-10-26-Stuff_The_Internet_Says_On_Scalability_For_October_26%2C_2012.html">1348 high scalability-2012-10-26-Stuff The Internet Says On Scalability For October 26, 2012</a></p>
<p>14 0.53947484 <a title="1033-lsi-14" href="../high_scalability-2011/high_scalability-2011-04-22-Stuff_The_Internet_Says_On_Scalability_For_April_22%2C_2011.html">1028 high scalability-2011-04-22-Stuff The Internet Says On Scalability For April 22, 2011</a></p>
<p>15 0.53619057 <a title="1033-lsi-15" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>16 0.53437036 <a title="1033-lsi-16" href="../high_scalability-2010/high_scalability-2010-12-28-Netflix%3A_Continually_Test_by_Failing_Servers_with_Chaos_Monkey.html">964 high scalability-2010-12-28-Netflix: Continually Test by Failing Servers with Chaos Monkey</a></p>
<p>17 0.53219587 <a title="1033-lsi-17" href="../high_scalability-2008/high_scalability-2008-01-02-WEB_hosting_Select.html">200 high scalability-2008-01-02-WEB hosting Select</a></p>
<p>18 0.52665532 <a title="1033-lsi-18" href="../high_scalability-2007/high_scalability-2007-10-30-Paper%3A_Dynamo%3A_Amazon%E2%80%99s_Highly_Available_Key-value_Store.html">139 high scalability-2007-10-30-Paper: Dynamo: Amazon’s Highly Available Key-value Store</a></p>
<p>19 0.52566546 <a title="1033-lsi-19" href="../high_scalability-2011/high_scalability-2011-06-09-Retrospect_on_recent_AWS_outage_and_Resilient_Cloud-Based_Architecture.html">1056 high scalability-2011-06-09-Retrospect on recent AWS outage and Resilient Cloud-Based Architecture</a></p>
<p>20 0.51975888 <a title="1033-lsi-20" href="../high_scalability-2014/high_scalability-2014-04-01-The_Mullet_Cloud_Selection_Pattern.html">1624 high scalability-2014-04-01-The Mullet Cloud Selection Pattern</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.111), (2, 0.115), (10, 0.076), (27, 0.01), (30, 0.016), (37, 0.379), (43, 0.015), (61, 0.079), (77, 0.024), (79, 0.067), (94, 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.88738674 <a title="1033-lda-1" href="../high_scalability-2011/high_scalability-2011-05-02-The_Updated_Big_List_of_Articles_on_the_Amazon_Outage.html">1033 high scalability-2011-05-02-The Updated Big List of Articles on the Amazon Outage</a></p>
<p>Introduction: Since  The Big List Of Articles On The Amazon Outage  was published we've a had few updates that people might not have seen. Amazon of course released their  Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region . Netlix shared their  Lessons Learned from the AWS Outage  as did Heroku ( How Heroku Survived the Amazon Outage ), Smug Mug ( How SmugMug survived the Amazonpocalypse ), and SimpleGeo ( How SimpleGeo Stayed Up During the AWS Downtime ). 
 
The curious thing from my perspective is the general lack of response to Amazon's explanation. I expected more discussion. There's been almost none that I've seen. My guess is very few people understand what Amazon was talking about enough to comment whereas almost everyone feels qualified to talk about the event itself.
 
 Lesson for crisis handlers : deep dive post-mortems that are timely, long, honestish, and highly technical are the most effective means of staunching the downward spiral of media attention.</p><p>2 0.8220982 <a title="1033-lda-2" href="../high_scalability-2011/high_scalability-2011-04-25-The_Big_List_of_Articles_on_the_Amazon_Outage.html">1029 high scalability-2011-04-25-The Big List of Articles on the Amazon Outage</a></p>
<p>Introduction: Please see  The Updated Big List Of Articles On The Amazon Outage  for a new improved list. 
 
So many great articles have been written on the Amazon Outage. Some aim at being helpful, some chastise developers for being so stupid, some chastise Amazon for being so incompetent, some talk about the pain they and their companies have experienced, and some even predict the downfall of the cloud. Still others say we have seen a sea change in future of the cloud, a prediction that's hard to disagree with, though the shape of the change remains...cloudy.
 
I'll try to keep this list update as more information comes out. There will be a lot for developers to consider going forward. If there's a resource you think should be added, just let me know.
  Amazon's Explanation of What Happened   
  Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region  
  Hackers News thread on AWS Service Disruption Post Mortem   
  Quite Funny Commentary on the Summary  
   Experiences f</p><p>3 0.73017371 <a title="1033-lda-3" href="../high_scalability-2010/high_scalability-2010-09-01-Scale-out_vs_Scale-up.html">891 high scalability-2010-09-01-Scale-out vs Scale-up</a></p>
<p>Introduction: In this post I'll cover the difference between multi-core concurrency that is often referred to as Scale-Up and distributed computing that is often referred to as Scale-Out mode.Â 
 
 more ..</p><p>4 0.72650385 <a title="1033-lda-4" href="../high_scalability-2008/high_scalability-2008-05-05-Put_the_web_server_on_a_diet_and_increase_scalability.html">316 high scalability-2008-05-05-Put the web server on a diet and increase scalability</a></p>
<p>Introduction: Misusing HTTP sessions is probably the number one obstacle to building scalable web sites today. Here are some tips how to consume HTTP sessions responsibly.</p><p>5 0.68843347 <a title="1033-lda-5" href="../high_scalability-2008/high_scalability-2008-05-27-Secure_Remote_Administration_for_Large-Scale_Networks.html">329 high scalability-2008-05-27-Secure Remote Administration for Large-Scale Networks</a></p>
<p>Introduction: This website has been a great resource for helping me to understand the successful (and failed) scalable network designs from organizations that have actually done it, but I haven't seen any explicite explanations about secure remote administration of these systems.     I understand that the *nix people love to SSH, and the windows gang has their RDP, but how does one go about creating a network architecture that both allows one to manage their systems and does its best to avoid hacker interest? As I imagine, no big website will have the SSH/RDP/FTP ports open on the web server, so how is it that they go about remotely administering their geographically diverse groups of servers securely?</p><p>6 0.66274464 <a title="1033-lda-6" href="../high_scalability-2011/high_scalability-2011-10-27-Strategy%3A_Survive_a_Comet_Strike_in_the_East_With_Reserved_Instances_in_the_West.html">1133 high scalability-2011-10-27-Strategy: Survive a Comet Strike in the East With Reserved Instances in the West</a></p>
<p>7 0.65326118 <a title="1033-lda-7" href="../high_scalability-2008/high_scalability-2008-04-29-Strategy%3A_Sample_to_Reduce_Data_Set.html">311 high scalability-2008-04-29-Strategy: Sample to Reduce Data Set</a></p>
<p>8 0.63038313 <a title="1033-lda-8" href="../high_scalability-2008/high_scalability-2008-05-03-Product%3A_nginx.html">314 high scalability-2008-05-03-Product: nginx</a></p>
<p>9 0.62444651 <a title="1033-lda-9" href="../high_scalability-2010/high_scalability-2010-12-29-Pinboard.in_Architecture_-_Pay_to_Play_to_Keep_a_System_Small__.html">965 high scalability-2010-12-29-Pinboard.in Architecture - Pay to Play to Keep a System Small  </a></p>
<p>10 0.61674088 <a title="1033-lda-10" href="../high_scalability-2007/high_scalability-2007-10-07-Paper%3A_Architecture_of_a_Highly_Scalable_NIO-Based_Server.html">113 high scalability-2007-10-07-Paper: Architecture of a Highly Scalable NIO-Based Server</a></p>
<p>11 0.60336345 <a title="1033-lda-11" href="../high_scalability-2007/high_scalability-2007-09-28-Kosmos_File_System_%28KFS%29_is_a_New_High_End_Google_File_System_Option.html">103 high scalability-2007-09-28-Kosmos File System (KFS) is a New High End Google File System Option</a></p>
<p>12 0.5904938 <a title="1033-lda-12" href="../high_scalability-2012/high_scalability-2012-12-31-Designing_for_Resiliency_will_be_so_2013.html">1379 high scalability-2012-12-31-Designing for Resiliency will be so 2013</a></p>
<p>13 0.55673265 <a title="1033-lda-13" href="../high_scalability-2008/high_scalability-2008-03-17-Microsoft%27s_New_Database_Cloud_Ready_to_Rumble_with_Amazon.html">279 high scalability-2008-03-17-Microsoft's New Database Cloud Ready to Rumble with Amazon</a></p>
<p>14 0.53941572 <a title="1033-lda-14" href="../high_scalability-2011/high_scalability-2011-06-28-Sponsored_Post%3A_Surge%2C_BioWare%2C_Tungsten%2C_deviantART%2C_Aconex%2C_Hadapt%2C_Mathworks%2C_AppDynamics%2C__ScaleOut%2C_Membase%2C_CloudSigma%2C_ManageEngine%2C_Site24x7.html">1069 high scalability-2011-06-28-Sponsored Post: Surge, BioWare, Tungsten, deviantART, Aconex, Hadapt, Mathworks, AppDynamics,  ScaleOut, Membase, CloudSigma, ManageEngine, Site24x7</a></p>
<p>15 0.5373947 <a title="1033-lda-15" href="../high_scalability-2013/high_scalability-2013-03-04-7_Life_Saving_Scalability_Defenses_Against_Load_Monster_Attacks.html">1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</a></p>
<p>16 0.52934682 <a title="1033-lda-16" href="../high_scalability-2013/high_scalability-2013-04-23-Facebook_Secrets_of_Web_Performance.html">1444 high scalability-2013-04-23-Facebook Secrets of Web Performance</a></p>
<p>17 0.52919137 <a title="1033-lda-17" href="../high_scalability-2011/high_scalability-2011-08-29-The_Three_Ages_of_Google_-_Batch%2C_Warehouse%2C_Instant.html">1107 high scalability-2011-08-29-The Three Ages of Google - Batch, Warehouse, Instant</a></p>
<p>18 0.52120811 <a title="1033-lda-18" href="../high_scalability-2011/high_scalability-2011-07-05-Sponsored_Post%3A_TripAdvisor%2C_eHarmony%2C_NoSQL_Now%21%2C_Surge%2C_BioWare%2C_Tungsten%2C_deviantART%2C_Aconex%2C_Hadapt%2C_Mathworks%2C_AppDynamics%2C__ScaleOut%2C_Membase%2C_CloudSigma%2C_ManageEngine%2C_Site24x7.html">1073 high scalability-2011-07-05-Sponsored Post: TripAdvisor, eHarmony, NoSQL Now!, Surge, BioWare, Tungsten, deviantART, Aconex, Hadapt, Mathworks, AppDynamics,  ScaleOut, Membase, CloudSigma, ManageEngine, Site24x7</a></p>
<p>19 0.51652366 <a title="1033-lda-19" href="../high_scalability-2011/high_scalability-2011-07-12-Sponsored_Post%3A_New_Relic%2C_eHarmony%2C_TripAdvisor%2C_NoSQL_Now%21%2C_Surge%2C_BioWare%2C_Tungsten%2C_deviantART%2C_Aconex%2C_Hadapt%2C_Mathworks%2C_AppDynamics%2C__ScaleOut%2C_Membase%2C_CloudSigma%2C_ManageEngine%2C_Site24x7.html">1079 high scalability-2011-07-12-Sponsored Post: New Relic, eHarmony, TripAdvisor, NoSQL Now!, Surge, BioWare, Tungsten, deviantART, Aconex, Hadapt, Mathworks, AppDynamics,  ScaleOut, Membase, CloudSigma, ManageEngine, Site24x7</a></p>
<p>20 0.51466936 <a title="1033-lda-20" href="../high_scalability-2012/high_scalability-2012-12-03-Resiliency_is_the_New_Normal_-_A_Deep_Look_at_What_It_Means_and_How_to_Build_It.html">1366 high scalability-2012-12-03-Resiliency is the New Normal - A Deep Look at What It Means and How to Build It</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
