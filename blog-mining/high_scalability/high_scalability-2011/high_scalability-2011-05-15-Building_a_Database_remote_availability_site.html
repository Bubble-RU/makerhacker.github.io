<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1041 high scalability-2011-05-15-Building a Database remote availability site</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2011" href="../home/high_scalability-2011_home.html">high_scalability-2011</a> <a title="high_scalability-2011-1041" href="#">high_scalability-2011-1041</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1041 high scalability-2011-05-15-Building a Database remote availability site</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2011-1041-html" href="http://highscalability.com//blog/2011/5/15/building-a-database-remote-availability-site.html">html</a></p><p>Introduction: The AWS East Region outage showed all of us the importance of running our apps and databases across multiple Amazon regions (or multiple cloud providers). In this post, I’ll try to explain how to build a MySQL (or Amazon RDS) redundant site.
 
For simplicity, we create a passive redundant site. This means that the site is not used during normal operation and only comes into action when the primary site crashes. There are many reasons for choosing such an architecture – it’s easy to configure, simple to understand, and minimizes the risk of data collision. The downside is that you have hardware just sitting around doing nothing.
 
Still, it’s a common enough scenario. So what do we need to do to make it work?
  DATA SYNCHRONIZATION  
We need to synchronize the database. This is done by means of database replication. Now, there are two options for database replication: synchronous and a-synchronous. Synchronous replication is great; it ensures that the backup database is identical to the</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The AWS East Region outage showed all of us the importance of running our apps and databases across multiple Amazon regions (or multiple cloud providers). [sent-1, score-0.321]
</p><p>2 In this post, I’ll try to explain how to build a MySQL (or Amazon RDS) redundant site. [sent-2, score-0.192]
</p><p>3 For simplicity, we create a passive redundant site. [sent-3, score-0.23]
</p><p>4 This means that the site is not used during normal operation and only comes into action when the primary site crashes. [sent-4, score-0.477]
</p><p>5 There are many reasons for choosing such an architecture – it’s easy to configure, simple to understand, and minimizes the risk of data collision. [sent-5, score-0.172]
</p><p>6 The downside is that you have hardware just sitting around doing nothing. [sent-6, score-0.164]
</p><p>7 DATA SYNCHRONIZATION   We need to synchronize the database. [sent-9, score-0.099]
</p><p>8 Now, there are two options for database replication: synchronous and a-synchronous. [sent-11, score-0.455]
</p><p>9 Synchronous replication is great; it ensures that the backup database is identical to the primary database. [sent-12, score-1.223]
</p><p>10 However, it also means that each DML operation on the primary database must be executed on the backup, and the result is sent to the client only after the backup database has completed the operation (at least at commit level). [sent-13, score-1.636]
</p><p>11 This is very slow when the backup database is located in a remote geographical location (as a good friend of mine once said – sometimes the speed of light is just too slow). [sent-14, score-0.99]
</p><p>12 A-synchronous replication is better for remote sites, but can result in data loss, depending on the “lag” between the primary database and the backup database. [sent-15, score-1.25]
</p><p>13 We MySQL customers (RDS customers included) only have a- synchronous replication (and, starting from 5. [sent-16, score-0.783]
</p><p>14 5, semi- synchronous replication, which on most deployments will behave in the same way as a-synchronous replication). [sent-17, score-0.468]
</p><p>15 After the replication is configured, the application needs to be updated to make sure that it recognizes database crashes, and will failover to the backup database. [sent-18, score-1.081]
</p><p>16 DETECTING CRASHES   There are several possibilities for crashes and their detection. [sent-19, score-0.276]
</p><p>17 The first, and simplest, is if the entire region is down, which causes both the application servers and the databases to crash. [sent-20, score-0.22]
</p><p>18 In this case, the CDN, or a DNS load balancing technique, will failover to the backup region. [sent-21, score-0.513]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('backup', 0.387), ('synchronous', 0.313), ('replication', 0.296), ('primary', 0.216), ('crashes', 0.181), ('operation', 0.162), ('rds', 0.157), ('region', 0.151), ('dml', 0.145), ('database', 0.142), ('recognizes', 0.13), ('failover', 0.126), ('remote', 0.122), ('redundant', 0.122), ('passive', 0.108), ('means', 0.099), ('synchronize', 0.099), ('simplest', 0.099), ('minimizes', 0.098), ('identical', 0.096), ('possibilities', 0.095), ('mine', 0.093), ('lag', 0.092), ('slow', 0.089), ('result', 0.087), ('importance', 0.087), ('east', 0.087), ('customers', 0.087), ('ensures', 0.086), ('geographical', 0.084), ('completed', 0.084), ('included', 0.083), ('sitting', 0.082), ('downside', 0.082), ('showed', 0.081), ('commit', 0.079), ('behave', 0.078), ('deployments', 0.077), ('outage', 0.077), ('simplicity', 0.076), ('executed', 0.076), ('regions', 0.076), ('choosing', 0.074), ('friend', 0.073), ('configure', 0.073), ('technique', 0.073), ('loss', 0.071), ('explain', 0.07), ('causes', 0.069), ('providers', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="1041-tfidf-1" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>Introduction: The AWS East Region outage showed all of us the importance of running our apps and databases across multiple Amazon regions (or multiple cloud providers). In this post, I’ll try to explain how to build a MySQL (or Amazon RDS) redundant site.
 
For simplicity, we create a passive redundant site. This means that the site is not used during normal operation and only comes into action when the primary site crashes. There are many reasons for choosing such an architecture – it’s easy to configure, simple to understand, and minimizes the risk of data collision. The downside is that you have hardware just sitting around doing nothing.
 
Still, it’s a common enough scenario. So what do we need to do to make it work?
  DATA SYNCHRONIZATION  
We need to synchronize the database. This is done by means of database replication. Now, there are two options for database replication: synchronous and a-synchronous. Synchronous replication is great; it ensures that the backup database is identical to the</p><p>2 0.19191298 <a title="1041-tfidf-2" href="../high_scalability-2013/high_scalability-2013-01-14-MongoDB_and_GridFS_for_Inter_and_Intra_Datacenter_Data_Replication_.html">1386 high scalability-2013-01-14-MongoDB and GridFS for Inter and Intra Datacenter Data Replication </a></p>
<p>Introduction: This is a guest post by  Jeff Behl , VP Ops @ LogicMonitor.  Jeff  has been a bit herder for the last 20 years, architecting and overseeing the infrastructure for a number of SaaS based companies.   
  Data Replication for Disaster Recovery  
An inevitable part of disaster recovery planning is making sure customer data exists in multiple locations.  In the case of LogicMonitor, a SaaS-based monitoring solution for physical, virtual, and cloud environments, we wanted copies of customer data files both within a data center and outside of it.  The former was to protect against the loss of individual servers within a facility, and the latter for recovery in the event of the complete loss of a data center.
  Where we were:  Rsync  
Like most everyone who starts off in a Linux environment, we used our trusty friend rsync to copy data around.
 
 
 
     
  Rsync is tried, true and tested, and works well when the number of servers, the amount of data, and the number of files is not horrendous.</p><p>3 0.14450173 <a title="1041-tfidf-3" href="../high_scalability-2013/high_scalability-2013-12-02-Evolution_of_Bazaarvoice%E2%80%99s_Architecture_to_500M_Unique_Users_Per_Month.html">1557 high scalability-2013-12-02-Evolution of Bazaarvoice’s Architecture to 500M Unique Users Per Month</a></p>
<p>Introduction: This is a guest post written by    Victor Trac   , Cloud Architect at    Bazaarvoice   .  
   Bazaarvoice is a company that people interact with on a regular basis but have probably never heard of. If you read customer reviews on sites like bestbuy.com, nike.com, or walmart.com, you are using Bazaarvoice services. These sites, along with thousands of others, rely on Bazaarvoice to supply the software and technology to collect and display user conversations about products and services. All of this means that Bazaarvoice processes a lot of sentiment data on most of the products we all use daily. 
     Bazaarvoice helps our clients make better products by using a combination of machine learning and natural language processing to extract useful information and user sentiments from the millions of free-text reviews that go through our platform. This data gets boiled down into reports that clients can use to improve their products and services. We are also starting to look at how to show per</p><p>4 0.1388111 <a title="1041-tfidf-4" href="../high_scalability-2007/high_scalability-2007-11-12-a8cjdbc_-_Database_Clustering_via_JDBC.html">151 high scalability-2007-11-12-a8cjdbc - Database Clustering via JDBC</a></p>
<p>Introduction: Practically any software project nowadays could not survive without a database (DBMS) backend storing all the business data that is vital to you and/or your customers. When projects grow larger, the amount of data usually grows larger exponentially. So you start moving the DBMS to a separate server to gain more speed and capacity. Which is all good and healthy but you do not gain any extra safety for this business data. You might be backing up your database once a day so in case the database server crashes you don't lose EVERYTHING, but how much can you really afford to lose?Â 
 
Well clearly this depends on what kind of data you are storing. In our case the users of our solutions use our software products to do their everyday (all day) work. They have "everything" they need for their business stored in the database we are providing. So is 24 hours of data loss acceptable? No, not really. One hour? Maybe. But what we really want is a second database running with the EXACT same data. We</p><p>5 0.13639967 <a title="1041-tfidf-5" href="../high_scalability-2008/high_scalability-2008-04-22-Simple_NFS_failover_solution_with_symbolic_link%3F.html">308 high scalability-2008-04-22-Simple NFS failover solution with symbolic link?</a></p>
<p>Introduction: I've been trying to find a high availability file storage solution without success. I tried GlusterFS which looks very promising but experienced problems with stability and don't want something I can't easily control and rely on. Other solutions are too complicated or have a SPOF.     So I'm thinking of the following setup:     Two NFS servers, a primary and a warm backup. The primary server will be rsynced with the warm backup every minute or two. I can do it so frequently as a PHP script will know which directories have changed recently from a database and only rsync those. Both servers will be NFS mounted on a cluster of web servers as /mnt/nfs-primary (sym linked as /home/websites) and /mnt/nfs-backup.     I'll then use Ucarp (http://www.ucarp.org/project/ucarp) to monitor both NFS servers availability every couple of seconds and when one goes down, the Ucarp up script will be set to change the symbolic link on all web servers for the /home/websites dir from /mnt/nfs-primary to /mn</p><p>6 0.13473412 <a title="1041-tfidf-6" href="../high_scalability-2011/high_scalability-2011-04-25-The_Big_List_of_Articles_on_the_Amazon_Outage.html">1029 high scalability-2011-04-25-The Big List of Articles on the Amazon Outage</a></p>
<p>7 0.13257959 <a title="1041-tfidf-7" href="../high_scalability-2009/high_scalability-2009-09-01-Cheap_storage%3A_how_backblaze_takes_matters_in_hand.html">692 high scalability-2009-09-01-Cheap storage: how backblaze takes matters in hand</a></p>
<p>8 0.12393268 <a title="1041-tfidf-8" href="../high_scalability-2008/high_scalability-2008-08-17-Strategy%3A_Drop_Memcached%2C_Add_More_MySQL_Servers.html">367 high scalability-2008-08-17-Strategy: Drop Memcached, Add More MySQL Servers</a></p>
<p>9 0.12165171 <a title="1041-tfidf-9" href="../high_scalability-2014/high_scalability-2014-03-03-The_%E2%80%9CFour_Hamiltons%E2%80%9D_Framework_for_Mitigating_Faults_in_the_Cloud%3A_Avoid_it%2C_Mask_it%2C_Bound_it%2C_Fix_it_Fast.html">1604 high scalability-2014-03-03-The “Four Hamiltons” Framework for Mitigating Faults in the Cloud: Avoid it, Mask it, Bound it, Fix it Fast</a></p>
<p>10 0.12097166 <a title="1041-tfidf-10" href="../high_scalability-2011/high_scalability-2011-05-02-The_Updated_Big_List_of_Articles_on_the_Amazon_Outage.html">1033 high scalability-2011-05-02-The Updated Big List of Articles on the Amazon Outage</a></p>
<p>11 0.12062012 <a title="1041-tfidf-11" href="../high_scalability-2014/high_scalability-2014-03-05-10_Things_You_Should_Know_About_Running_MongoDB_at_Scale.html">1606 high scalability-2014-03-05-10 Things You Should Know About Running MongoDB at Scale</a></p>
<p>12 0.11901404 <a title="1041-tfidf-12" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>13 0.11872523 <a title="1041-tfidf-13" href="../high_scalability-2014/high_scalability-2014-04-14-How_do_you_even_do_anything_without_using_EBS%3F.html">1631 high scalability-2014-04-14-How do you even do anything without using EBS?</a></p>
<p>14 0.11657801 <a title="1041-tfidf-14" href="../high_scalability-2012/high_scalability-2012-10-25-Not_All_Regions_are_Created_Equal_-_South_America_Es_Bueno.html">1347 high scalability-2012-10-25-Not All Regions are Created Equal - South America Es Bueno</a></p>
<p>15 0.11517843 <a title="1041-tfidf-15" href="../high_scalability-2012/high_scalability-2012-04-03-Hazelcast_2.0%3A_Big_Data_In-Memory.html">1221 high scalability-2012-04-03-Hazelcast 2.0: Big Data In-Memory</a></p>
<p>16 0.11503372 <a title="1041-tfidf-16" href="../high_scalability-2008/high_scalability-2008-12-01-Sun_FireTM_X4540_Server_as_Backup_Server_for_Zmanda%27s_Amanda_Enterprise_2.6_Software_.html">457 high scalability-2008-12-01-Sun FireTM X4540 Server as Backup Server for Zmanda's Amanda Enterprise 2.6 Software </a></p>
<p>17 0.11444061 <a title="1041-tfidf-17" href="../high_scalability-2009/high_scalability-2009-11-04-Damn%2C_Which_Database_do_I_Use_Now%3F.html">736 high scalability-2009-11-04-Damn, Which Database do I Use Now?</a></p>
<p>18 0.11376993 <a title="1041-tfidf-18" href="../high_scalability-2014/high_scalability-2014-02-03-How_Google_Backs_Up_the_Internet_Along_With_Exabytes_of_Other_Data.html">1589 high scalability-2014-02-03-How Google Backs Up the Internet Along With Exabytes of Other Data</a></p>
<p>19 0.11250859 <a title="1041-tfidf-19" href="../high_scalability-2011/high_scalability-2011-10-27-Strategy%3A_Survive_a_Comet_Strike_in_the_East_With_Reserved_Instances_in_the_West.html">1133 high scalability-2011-10-27-Strategy: Survive a Comet Strike in the East With Reserved Instances in the West</a></p>
<p>20 0.11075656 <a title="1041-tfidf-20" href="../high_scalability-2007/high_scalability-2007-07-16-Book%3A_High_Performance_MySQL.html">16 high scalability-2007-07-16-Book: High Performance MySQL</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.17), (1, 0.064), (2, -0.075), (3, -0.032), (4, -0.02), (5, 0.024), (6, 0.047), (7, -0.155), (8, 0.04), (9, -0.089), (10, -0.037), (11, -0.002), (12, -0.059), (13, -0.02), (14, 0.021), (15, 0.046), (16, 0.053), (17, 0.011), (18, 0.026), (19, 0.031), (20, 0.039), (21, 0.041), (22, 0.011), (23, 0.027), (24, -0.048), (25, 0.063), (26, 0.004), (27, -0.016), (28, 0.057), (29, -0.026), (30, 0.001), (31, -0.008), (32, 0.017), (33, -0.049), (34, -0.019), (35, 0.006), (36, 0.042), (37, 0.023), (38, -0.034), (39, 0.036), (40, 0.053), (41, -0.087), (42, -0.043), (43, 0.051), (44, 0.015), (45, -0.036), (46, 0.019), (47, -0.011), (48, 0.006), (49, -0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95064473 <a title="1041-lsi-1" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>Introduction: The AWS East Region outage showed all of us the importance of running our apps and databases across multiple Amazon regions (or multiple cloud providers). In this post, I’ll try to explain how to build a MySQL (or Amazon RDS) redundant site.
 
For simplicity, we create a passive redundant site. This means that the site is not used during normal operation and only comes into action when the primary site crashes. There are many reasons for choosing such an architecture – it’s easy to configure, simple to understand, and minimizes the risk of data collision. The downside is that you have hardware just sitting around doing nothing.
 
Still, it’s a common enough scenario. So what do we need to do to make it work?
  DATA SYNCHRONIZATION  
We need to synchronize the database. This is done by means of database replication. Now, there are two options for database replication: synchronous and a-synchronous. Synchronous replication is great; it ensures that the backup database is identical to the</p><p>2 0.7040453 <a title="1041-lsi-2" href="../high_scalability-2013/high_scalability-2013-12-02-Evolution_of_Bazaarvoice%E2%80%99s_Architecture_to_500M_Unique_Users_Per_Month.html">1557 high scalability-2013-12-02-Evolution of Bazaarvoice’s Architecture to 500M Unique Users Per Month</a></p>
<p>Introduction: This is a guest post written by    Victor Trac   , Cloud Architect at    Bazaarvoice   .  
   Bazaarvoice is a company that people interact with on a regular basis but have probably never heard of. If you read customer reviews on sites like bestbuy.com, nike.com, or walmart.com, you are using Bazaarvoice services. These sites, along with thousands of others, rely on Bazaarvoice to supply the software and technology to collect and display user conversations about products and services. All of this means that Bazaarvoice processes a lot of sentiment data on most of the products we all use daily. 
     Bazaarvoice helps our clients make better products by using a combination of machine learning and natural language processing to extract useful information and user sentiments from the millions of free-text reviews that go through our platform. This data gets boiled down into reports that clients can use to improve their products and services. We are also starting to look at how to show per</p><p>3 0.69578224 <a title="1041-lsi-3" href="../high_scalability-2014/high_scalability-2014-03-03-The_%E2%80%9CFour_Hamiltons%E2%80%9D_Framework_for_Mitigating_Faults_in_the_Cloud%3A_Avoid_it%2C_Mask_it%2C_Bound_it%2C_Fix_it_Fast.html">1604 high scalability-2014-03-03-The “Four Hamiltons” Framework for Mitigating Faults in the Cloud: Avoid it, Mask it, Bound it, Fix it Fast</a></p>
<p>Introduction: This is a guest post by  Patrick Eaton , Software Engineer and Distributed Systems Architect at Stackdriver. 
 
Stackdriver provides intelligent monitoring-as-a-service for cloud hosted applications.  Behind this easy-to-use service is a large distributed system for collecting and storing metrics and events, monitoring and alerting on them, analyzing them, and serving up all the results in a web UI.  Because we ourselves run in the cloud (mostly on AWS), we spend a lot of time thinking about how to deal with faults in the cloud.  We have developed a framework for thinking about fault mitigation for large, cloud-hosted systems.  We endearingly call this framework the “Four Hamiltons” because it is inspired by an article from James Hamilton, the Vice President and Distinguished Engineer at Amazon Web Services.
   The article that led to this framework is called “   The Power Failure Seen Around the World   ”  .  Hamilton analyzes the causes of the power outage that affected Super Bowl XL</p><p>4 0.68513763 <a title="1041-lsi-4" href="../high_scalability-2010/high_scalability-2010-10-22-Paper%3A_Netflix%E2%80%99s_Transition_to_High-Availability_Storage_Systems_.html">925 high scalability-2010-10-22-Paper: Netflix’s Transition to High-Availability Storage Systems </a></p>
<p>Introduction: In an audacious move for such an established property, Netflix is moving their website out of the comfort of their own datacenter and into the wilds of the Amazon cloud. This paper by Netflix's Siddharth “Sid” Anand,  Netflix’s Transition to High-Availability Storage Systems , gives a detailed look at this transition and does a deep dive on SimpleDB best practices, focussing especially on techniques useful to those who are making the move from a RDBMS.
 
Sid is going to give a talk at QCon based on this paper and he would appreciate your feedback. So if you have any comments or thoughts please comment here or email Sid at  r39132@hotmail.com  or Twitter at @r39132 Here's the introduction from the paper:
  Circa late 2008, Netflix had a single data center. This single data center raised a few concerns. As a single-point-of-failure (a.k.a. SPOF), it represented a liability – data center outages meant interruptions to service and negative customer impact. Additionally, with growth in both</p><p>5 0.67542726 <a title="1041-lsi-5" href="../high_scalability-2011/high_scalability-2011-08-15-Should_any_cloud_be_considered_one_availability_zone%3F_The_Amazon_experience_says_yes..html">1098 high scalability-2011-08-15-Should any cloud be considered one availability zone? The Amazon experience says yes.</a></p>
<p>Introduction: Amazon has a very will written account of their 8/8/2011 downtime:  Summary of the Amazon EC2, Amazon EBS, and Amazon RDS Service Event in the EU West Region . Power failed, backup generators failed to kick in, there weren't enough resources for EBS volumes to recover, API servers where overwhelmed, a DNS failure caused failovers to alternate availability zones to fail, a double fault occurred as the power event interrupted the repair of a different bug. All kind of typical stuff that just seems to happen.
 
Considering the  previous outage , the big question for programmers is: what does this mean? What does it mean for how systems should be structured? Have we learned something that can't be unlearned?
 
The Amazon post has lots of good insights into how EBS and RDS work, plus lessons learned. The short of the problem is large + complex = high probability of failure. The immediate fixes are adding more resources, more redundancy, more isolation between components, more automation, re</p><p>6 0.6662218 <a title="1041-lsi-6" href="../high_scalability-2010/high_scalability-2010-04-28-Elasticity_for_the_Enterprise_--_Ensuring_Continuous_High_Availability_in_a_Disaster_Failure_Scenario.html">816 high scalability-2010-04-28-Elasticity for the Enterprise -- Ensuring Continuous High Availability in a Disaster Failure Scenario</a></p>
<p>7 0.66041541 <a title="1041-lsi-7" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>8 0.64224333 <a title="1041-lsi-8" href="../high_scalability-2014/high_scalability-2014-04-14-How_do_you_even_do_anything_without_using_EBS%3F.html">1631 high scalability-2014-04-14-How do you even do anything without using EBS?</a></p>
<p>9 0.64136904 <a title="1041-lsi-9" href="../high_scalability-2011/high_scalability-2011-06-29-Second_Hand_Seizure_%3A_A_New_Cause_of_Site_Death.html">1070 high scalability-2011-06-29-Second Hand Seizure : A New Cause of Site Death</a></p>
<p>10 0.63630694 <a title="1041-lsi-10" href="../high_scalability-2012/high_scalability-2012-12-05-5_Ways_to_Make_Cloud_Failure_Not_an_Option.html">1367 high scalability-2012-12-05-5 Ways to Make Cloud Failure Not an Option</a></p>
<p>11 0.63610542 <a title="1041-lsi-11" href="../high_scalability-2010/high_scalability-2010-03-10-Saying_Yes_to_NoSQL%3B_Going_Steady_with_Cassandra_at_Digg.html">793 high scalability-2010-03-10-Saying Yes to NoSQL; Going Steady with Cassandra at Digg</a></p>
<p>12 0.63273364 <a title="1041-lsi-12" href="../high_scalability-2007/high_scalability-2007-07-24-Major_Websites_Down%3A_Or_Why_You_Want_to_Run_in_Two_or_More_Data_Centers..html">23 high scalability-2007-07-24-Major Websites Down: Or Why You Want to Run in Two or More Data Centers.</a></p>
<p>13 0.62717652 <a title="1041-lsi-13" href="../high_scalability-2013/high_scalability-2013-01-14-MongoDB_and_GridFS_for_Inter_and_Intra_Datacenter_Data_Replication_.html">1386 high scalability-2013-01-14-MongoDB and GridFS for Inter and Intra Datacenter Data Replication </a></p>
<p>14 0.62265319 <a title="1041-lsi-14" href="../high_scalability-2010/high_scalability-2010-03-22-7_Secrets_to_Successfully_Scaling_with_Scalr_%28on_Amazon%29_by_Sebastian_Stadil.html">798 high scalability-2010-03-22-7 Secrets to Successfully Scaling with Scalr (on Amazon) by Sebastian Stadil</a></p>
<p>15 0.61233437 <a title="1041-lsi-15" href="../high_scalability-2007/high_scalability-2007-08-20-TypePad_Architecture.html">68 high scalability-2007-08-20-TypePad Architecture</a></p>
<p>16 0.60721004 <a title="1041-lsi-16" href="../high_scalability-2007/high_scalability-2007-12-14-The_Current_Pros_and_Cons_List_for_SimpleDB.html">187 high scalability-2007-12-14-The Current Pros and Cons List for SimpleDB</a></p>
<p>17 0.6050455 <a title="1041-lsi-17" href="../high_scalability-2009/high_scalability-2009-11-04-Damn%2C_Which_Database_do_I_Use_Now%3F.html">736 high scalability-2009-11-04-Damn, Which Database do I Use Now?</a></p>
<p>18 0.60456806 <a title="1041-lsi-18" href="../high_scalability-2007/high_scalability-2007-07-25-Product%3A_NetApp_MetroCluster_Software.html">28 high scalability-2007-07-25-Product: NetApp MetroCluster Software</a></p>
<p>19 0.60441935 <a title="1041-lsi-19" href="../high_scalability-2007/high_scalability-2007-10-30-Paper%3A_Dynamo%3A_Amazon%E2%80%99s_Highly_Available_Key-value_Store.html">139 high scalability-2007-10-30-Paper: Dynamo: Amazon’s Highly Available Key-value Store</a></p>
<p>20 0.60379755 <a title="1041-lsi-20" href="../high_scalability-2008/high_scalability-2008-04-10-Mysql_scalability_and_failover....html">302 high scalability-2008-04-10-Mysql scalability and failover...</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.182), (2, 0.229), (10, 0.122), (38, 0.038), (61, 0.069), (79, 0.174), (85, 0.055), (94, 0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9886657 <a title="1041-lda-1" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>Introduction: The AWS East Region outage showed all of us the importance of running our apps and databases across multiple Amazon regions (or multiple cloud providers). In this post, I’ll try to explain how to build a MySQL (or Amazon RDS) redundant site.
 
For simplicity, we create a passive redundant site. This means that the site is not used during normal operation and only comes into action when the primary site crashes. There are many reasons for choosing such an architecture – it’s easy to configure, simple to understand, and minimizes the risk of data collision. The downside is that you have hardware just sitting around doing nothing.
 
Still, it’s a common enough scenario. So what do we need to do to make it work?
  DATA SYNCHRONIZATION  
We need to synchronize the database. This is done by means of database replication. Now, there are two options for database replication: synchronous and a-synchronous. Synchronous replication is great; it ensures that the backup database is identical to the</p><p>2 0.98275483 <a title="1041-lda-2" href="../high_scalability-2009/high_scalability-2009-10-06-Building_a_Unique_Data_Warehouse.html">716 high scalability-2009-10-06-Building a Unique Data Warehouse</a></p>
<p>Introduction: There are many reasons to roll your own  data  storage solution on top of existing technologies. We've seen stories on HighScalability about custom databases for very large sets of individual  data (like Twitter) and large amounts of binary  data  (like Facebook pictures). However, I recently ran into a  unique  type of problem. I was tasked with recording and storing bandwidth information for more than 20,000 servers and their associated networking equipment. This  data  needed to be accessed in real-time, with less than a 5 minute delay between the  data  being recorded and the  data showing up on customer bandwidth graphs on our customer portal.
 
After numerous false starts with off the shelf components and existing database clustering technology, we decided we must roll our own system. The real key to our problem (literally) was the ratio of the size of the key to the size of the actual  data . Because the tracked metric was so small (a 64-bit counter) compared to the  unique  ide</p><p>3 0.97689962 <a title="1041-lda-3" href="../high_scalability-2013/high_scalability-2013-11-25-How_To_Make_an_Infinitely_Scalable_Relational_Database_Management_System_%28RDBMS%29.html">1553 high scalability-2013-11-25-How To Make an Infinitely Scalable Relational Database Management System (RDBMS)</a></p>
<p>Introduction: This is a guest post by  Mark Travis , Founder of  InfiniSQL . 
 
  InfiniSQL is the specific "Infinitely Scalable RDBMS" to which the title refers. It is free software, and instructions for getting, building, running and testing it are available in the  guide .    Benchmarking  shows that an InfiniSQL cluster can handle over 500,000 complex transactions per second with over 100,000 simultaneous connections, all on twelve small servers. The methods used to test are documented, and the code is all available so that any practitioner can achieve similar results. There are two main characteristics which make InfiniSQL extraordinary:
  
 It performs transactions with records on multiple nodes better than any clustered/distributed RDBMS 
 It is free, open source. Not just a teaser "community" version with the good stuff proprietary. The community version of InfiniSQL will also be the enterprise version, when it is ready. 
  
InfiniSQL is still in early stages of development--it already has m</p><p>4 0.97627974 <a title="1041-lda-4" href="../high_scalability-2013/high_scalability-2013-05-06-7_Not_So_Sexy_Tips_for_Saving_Money_On_Amazon.html">1452 high scalability-2013-05-06-7 Not So Sexy Tips for Saving Money On Amazon</a></p>
<p>Introduction: Harish Ganesan  CTO of  8KMiles  has a very helpful blog,  Cloud, Big Data and Mobile , where he shows a nice analytical bent which leads to a lot of practical advice and cost saving tips:       
  Use SQS Batch Requests  to reduce the number of requests hitting SQS which saves costs. Sending 10 messages in a single batch request which in the example save $30/month. 
  Use SQS Long Polling  to reduce extra polling requests, cutting down empty receives, which in the example saves ~$600 in empty receive leakage costs. 
  Choose the right search technology choice to save costs in AWS  by matching your activity pattern to the technology. For a small application with constant load or a heavily utilized search tier or seasonal loads Amazon Cloud Search looks like the cost efficient play.  
  Use Amazon CloudFront Price Class to minimize costs  by selecting the right Price Class for your audience to potentially reduce delivery costs by excluding Amazon CloudFront’s more expensive edge locatio</p><p>5 0.97572607 <a title="1041-lda-5" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>Introduction: “ Data is everywhere, never be at a single location. Not scalable, not maintainable. ”  –Alex Szalay    While Galileo played life and death doctrinal games over the mysteries revealed by the telescope, another revolution went unnoticed, the microscope gave up mystery after mystery and nobody yet understood how subversive would be what it revealed. For the first time these new tools of perceptual augmentation allowed humans to peek behind the veil of appearance. A new new eye driving human invention and discovery for hundreds of years.     Data is another    material    that hides, revealing itself only when we look at different scales and investigate its underlying patterns. If the universe is truly    made of information   , then we are looking into truly primal stuff. A new eye is needed for Data and an ambitious project called    Data-scope    aims to be the lens.     A detailed    paper    on the Data-Scope tells more about what it is:  
  The Data-Scope is a new scientific instrum</p><p>6 0.97137445 <a title="1041-lda-6" href="../high_scalability-2009/high_scalability-2009-01-20-Product%3A_Amazon%27s_SimpleDB.html">498 high scalability-2009-01-20-Product: Amazon's SimpleDB</a></p>
<p>7 0.96961814 <a title="1041-lda-7" href="../high_scalability-2014/high_scalability-2014-06-05-Cloud_Architecture_Revolution.html">1654 high scalability-2014-06-05-Cloud Architecture Revolution</a></p>
<p>8 0.96767068 <a title="1041-lda-8" href="../high_scalability-2014/high_scalability-2014-04-04-Stuff_The_Internet_Says_On_Scalability_For_April_4th%2C_2014.html">1626 high scalability-2014-04-04-Stuff The Internet Says On Scalability For April 4th, 2014</a></p>
<p>9 0.96749246 <a title="1041-lda-9" href="../high_scalability-2011/high_scalability-2011-07-07-Myth%3A_Google_Uses_Server_Farms_So_You_Should_Too_-_Resurrection_of_the_Big-Ass_Machines.html">1075 high scalability-2011-07-07-Myth: Google Uses Server Farms So You Should Too - Resurrection of the Big-Ass Machines</a></p>
<p>10 0.96693361 <a title="1041-lda-10" href="../high_scalability-2010/high_scalability-2010-07-13-DbShards_Part_Deux_-_The_Internals.html">857 high scalability-2010-07-13-DbShards Part Deux - The Internals</a></p>
<p>11 0.9662261 <a title="1041-lda-11" href="../high_scalability-2010/high_scalability-2010-07-08-Cloud_AWS_Infrastructure_vs._Physical_Infrastructure.html">853 high scalability-2010-07-08-Cloud AWS Infrastructure vs. Physical Infrastructure</a></p>
<p>12 0.96348912 <a title="1041-lda-12" href="../high_scalability-2009/high_scalability-2009-04-16-Paper%3A_The_End_of_an_Architectural_Era_%28It%E2%80%99s_Time_for_a_Complete_Rewrite%29.html">572 high scalability-2009-04-16-Paper: The End of an Architectural Era (It’s Time for a Complete Rewrite)</a></p>
<p>13 0.96312708 <a title="1041-lda-13" href="../high_scalability-2008/high_scalability-2008-11-24-Scalability_Perspectives_%233%3A_Marc_Andreessen_%E2%80%93_Internet_Platforms.html">450 high scalability-2008-11-24-Scalability Perspectives #3: Marc Andreessen – Internet Platforms</a></p>
<p>14 0.96284646 <a title="1041-lda-14" href="../high_scalability-2012/high_scalability-2012-12-10-Switch_your_databases_to_Flash_storage._Now._Or_you%27re_doing_it_wrong..html">1369 high scalability-2012-12-10-Switch your databases to Flash storage. Now. Or you're doing it wrong.</a></p>
<p>15 0.96228993 <a title="1041-lda-15" href="../high_scalability-2012/high_scalability-2012-07-02-C_is_for_Compute_-_Google_Compute_Engine_%28GCE%29.html">1275 high scalability-2012-07-02-C is for Compute - Google Compute Engine (GCE)</a></p>
<p>16 0.96220922 <a title="1041-lda-16" href="../high_scalability-2013/high_scalability-2013-06-21-Stuff_The_Internet_Says_On_Scalability_For_June_21%2C_2013.html">1479 high scalability-2013-06-21-Stuff The Internet Says On Scalability For June 21, 2013</a></p>
<p>17 0.96218723 <a title="1041-lda-17" href="../high_scalability-2011/high_scalability-2011-06-27-TripAdvisor_Architecture_-_40M_Visitors%2C_200M_Dynamic_Page_Views%2C_30TB_Data.html">1068 high scalability-2011-06-27-TripAdvisor Architecture - 40M Visitors, 200M Dynamic Page Views, 30TB Data</a></p>
<p>18 0.96208239 <a title="1041-lda-18" href="../high_scalability-2012/high_scalability-2012-11-01-Cost_Analysis%3A_TripAdvisor_and_Pinterest_costs_on_the_AWS_cloud.html">1353 high scalability-2012-11-01-Cost Analysis: TripAdvisor and Pinterest costs on the AWS cloud</a></p>
<p>19 0.96183634 <a title="1041-lda-19" href="../high_scalability-2012/high_scalability-2012-12-12-Pinterest_Cut_Costs_from_%2454_to_%2420_Per_Hour_by_Automatically_Shutting_Down_Systems.html">1371 high scalability-2012-12-12-Pinterest Cut Costs from $54 to $20 Per Hour by Automatically Shutting Down Systems</a></p>
<p>20 0.96183282 <a title="1041-lda-20" href="../high_scalability-2014/high_scalability-2014-05-14-Google_Says_Cloud_Prices_Will_Follow_Moore%E2%80%99s_Law%3A_Are_We_All_Renters_Now%3F.html">1647 high scalability-2014-05-14-Google Says Cloud Prices Will Follow Moore’s Law: Are We All Renters Now?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
