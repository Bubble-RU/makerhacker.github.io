<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1035 high scalability-2011-05-05-Paper: A Study of Practical Deduplication</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2011" href="../home/high_scalability-2011_home.html">high_scalability-2011</a> <a title="high_scalability-2011-1035" href="#">high_scalability-2011-1035</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1035 high scalability-2011-05-05-Paper: A Study of Practical Deduplication</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2011-1035-html" href="http://highscalability.com//blog/2011/5/5/paper-a-study-of-practical-deduplication.html">html</a></p><p>Introduction: With BigData comes BigStorage costs. One way to store less is simply  not to store the same data twice . That's the radically simple and powerful notion behind  data deduplication . If you are one of those who got a good laugh out of the idea of  eliminating SQL queries  as a rather obvious scalability strategy, you'll love this one, but it is a powerful feature and one I don't hear talked about outside the enterprise. A parallel idea in programming is the once-and-only-once principle of never duplicating code.
 
Using deduplication technology, for some upfront CPU usage, which is a plentiful resource in many systems that are IO bound anyway, it's possible to reduce storage requirements by upto 20:1, depending on your data, which saves both money and disk write overhead. 
 
This comes up because of really good article Robin Harris of StorageMojo wrote,  All de-dup works , on a paper,   A Study of Practical Deduplication  by Dutch Meyer and William Bolosky, 
 
For a great  explanation o</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 One way to store less is simply  not to store the same data twice . [sent-2, score-0.217]
</p><p>2 That's the radically simple and powerful notion behind  data deduplication . [sent-3, score-0.847]
</p><p>3 Using deduplication technology, for some upfront CPU usage, which is a plentiful resource in many systems that are IO bound anyway, it's possible to reduce storage requirements by upto 20:1, depending on your data, which saves both money and disk write overhead. [sent-6, score-0.857]
</p><p>4 Chunks of data -- files, blocks, or byte ranges -- are checksummed using some hash function that uniquely identifies data with very high probability. [sent-9, score-0.354]
</p><p>5 When using a secure hash like SHA256, the probability of a hash collision is about 2^-256 = 10^-77 or, in more familiar notation, 0. [sent-10, score-0.236]
</p><p>6 Chunks of data are remembered in a table of some sort that maps the data's checksum to its storage location and reference count. [sent-13, score-0.368]
</p><p>7 When you store another copy of existing data, instead of allocating new space on disk, the dedup code just increments the reference count on the existing data. [sent-14, score-0.521]
</p><p>8 When data is highly replicated, which is typical of backup servers, virtual machine images, and source code repositories, deduplication can reduce space consumption not just by percentages, but by multiples. [sent-15, score-1.024]
</p><p>9 What the paper is saying, for their type of data at least, is that dealing simply with files is nearly as affective as more complex block deduplication schemes. [sent-16, score-1.035]
</p><p>10 From the paper:     We collected file system content data from 857 desktop computers  at  Microsoft over a span of 4 weeks. [sent-17, score-0.22]
</p><p>11 We analyzed the data to determine the relative efficacy of data deduplication, particularly considering whole-file versus block-level elimination of redundancy. [sent-18, score-0.231]
</p><p>12 We found that  whole-file deduplication achieves about three quarters of the space savings of the most aggressive block-level deduplication for storage of live file systems, and  87% of the savings for backup images. [sent-19, score-1.988]
</p><p>13 We also studied file fragmentation finding that it is not prevalent, and updated prior file system metadata studies, finding that the distribution of file sizes continues to skew toward very large unstructured files. [sent-20, score-0.659]
</p><p>14 Indirection and hashing are still the greatest weapons of computer science, which leads to some telling caveats from Robin:     De-duplication trades direct access to save data capacity. [sent-21, score-0.23]
</p><p>15 If it's at the storage layer, in the cloud, that buys you nothing because then all the cost savings simply go to the cloud provider as you will be billed for the size of the data you want to store, not the data actually stored. [sent-25, score-0.479]
</p><p>16 And all these calculations must be applied to non-encrypted data so the implication is it should be in user space somewhere. [sent-26, score-0.206]
</p><p>17 Why shouldn't they just store entire files and let the underlying file system or storage device figure out what's common? [sent-29, score-0.347]
</p><p>18 With the mass of unstructured data rising it seems like there's an opportunity here. [sent-31, score-0.191]
</p><p>19 Related Articles      ZFS Deduplication  by Jeff Bonwick    Cloud Based Deduplication Quick Start Guide     Do any common OS file systems use hashes to avoid storing the same content data more than once? [sent-32, score-0.283]
</p><p>20 Multi-level comparison of data deduplication in a backup scenario  by Dirk Meister and    André Brinkmann. [sent-34, score-0.923]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('deduplication', 0.742), ('dedup', 0.147), ('file', 0.115), ('store', 0.112), ('savings', 0.107), ('data', 0.105), ('space', 0.101), ('reference', 0.098), ('hash', 0.091), ('eliminating', 0.09), ('unstructured', 0.086), ('robin', 0.085), ('backup', 0.076), ('jeff', 0.068), ('weapons', 0.067), ('bigstorage', 0.067), ('revisited', 0.067), ('files', 0.065), ('dutch', 0.063), ('meyer', 0.063), ('bonwick', 0.063), ('efficacy', 0.063), ('diffs', 0.063), ('elimination', 0.063), ('percentages', 0.063), ('undetected', 0.063), ('ecc', 0.063), ('hashes', 0.063), ('increments', 0.063), ('paper', 0.062), ('dealing', 0.061), ('prevalent', 0.06), ('studied', 0.06), ('upto', 0.06), ('caveats', 0.058), ('quarters', 0.058), ('finding', 0.057), ('checksum', 0.056), ('william', 0.056), ('rethinking', 0.056), ('laugh', 0.056), ('storage', 0.055), ('billed', 0.054), ('remembered', 0.054), ('collision', 0.054), ('skew', 0.054), ('duplicating', 0.053), ('identifies', 0.053), ('buys', 0.053), ('zfs', 0.052)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="1035-tfidf-1" href="../high_scalability-2011/high_scalability-2011-05-05-Paper%3A_A_Study_of_Practical_Deduplication.html">1035 high scalability-2011-05-05-Paper: A Study of Practical Deduplication</a></p>
<p>Introduction: With BigData comes BigStorage costs. One way to store less is simply  not to store the same data twice . That's the radically simple and powerful notion behind  data deduplication . If you are one of those who got a good laugh out of the idea of  eliminating SQL queries  as a rather obvious scalability strategy, you'll love this one, but it is a powerful feature and one I don't hear talked about outside the enterprise. A parallel idea in programming is the once-and-only-once principle of never duplicating code.
 
Using deduplication technology, for some upfront CPU usage, which is a plentiful resource in many systems that are IO bound anyway, it's possible to reduce storage requirements by upto 20:1, depending on your data, which saves both money and disk write overhead. 
 
This comes up because of really good article Robin Harris of StorageMojo wrote,  All de-dup works , on a paper,   A Study of Practical Deduplication  by Dutch Meyer and William Bolosky, 
 
For a great  explanation o</p><p>2 0.16025738 <a title="1035-tfidf-2" href="../high_scalability-2014/high_scalability-2014-02-14-Stuff_The_Internet_Says_On_Scalability_For_February_14th%2C_2014.html">1596 high scalability-2014-02-14-Stuff The Internet Says On Scalability For February 14th, 2014</a></p>
<p>Introduction: Hey, it's HighScalability time:
     Climbing the World's Second Tallest Building     
  5 billion : Number of phone records NSA collects per day;  Facebook : 1.23 billion users, 201.6 billion friend connections, 400 billion shared photos, and 7.8 trillion messages sent since the start of 2012. 
 Quotable Quotes:                                  
 
  @ShrikanthSS : people repeatedly underestimate the cost of busy waits 
  @mcclure111 : Learning today java․net․URL․equals is a blocking operation that hits the network shook me badly. I don't know if I can trust the world now. 
  @hui_kenneth : @randybias: “3 ways 2 be market leader - be 1st, be best, or be cheapest. #AWS was all 3. Now #googlecloud may be best & is the cheapest.” 
  @thijs : The nice thing about Paper is that we can point out to clients that it took 18 experienced designers and developers two years to build. 
  @neil_conway : My guess is that the split between Spanner and F1 is a great example of Conway's Law. 
 
 
 How F</p><p>3 0.15682703 <a title="1035-tfidf-3" href="../high_scalability-2011/high_scalability-2011-02-18-Stuff_The_Internet_Says_On_Scalability_For_February_18%2C_2011.html">992 high scalability-2011-02-18-Stuff The Internet Says On Scalability For February 18, 2011</a></p>
<p>Introduction: Submitted for your reading pleasure on this cold and rainy Friday...
  
 Quotable Quotes:        
 
  CarryMillsap : You can't hardware yourself out of a performance problem you softwared yourself into. 
  @juokaz : schema-less databases doesn't mean data should have no structure 
 
 
 Scalability Porn:      
 
  3 Months To The First Million Users, Just 6 Weeks To The Second Million For Instagram  
 S tudy by the USC Annenberg School for Communication & Journalism  estimates:  in 2007, humankind was able to store 2.9 × 1020 optimally compressed bytes, communicate almost 2 × 1021 bytes, and carry out 6.4 × 1018 instructions per second on general-purpose computers. 
 
 
 Hadoop has hit a scalability limit at a whopping 4,000 machines and are looking to create the  next generation architecture . Their target is clusters of 10,000 machines and 200,000 cores.  The fundamental idea of the re-architecture is to divide the two major functions of the Job Tracker, resource management and job sc</p><p>4 0.11292757 <a title="1035-tfidf-4" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>Introduction: Mobile developers have a huge scaling problem ahead: doing something useful with massive continuous streams of telemetry data from millions and millions of devices. This is a really good problem to have. It means smartphone sales are finally fulfilling their destiny:  slaughtering PCs  in the sales arena. And it also means mobile devices aren't just containers for simple standalone apps anymore, they are becoming the dominant interface to giant backend systems.
    
While developers are now rocking mobile development on the client side, their next challenge is how to code those tricky backend bits. A company facing those same exact problems right now is  Medialets , a mobile rich media ad platform. What they do is help publishers create high quality interactive ads, though for our purposes their ad stuff isn't that interesting. What I did find really interesting about their system is how they are tackling the problem of defeating the mobile device data deluge.
 
Each day Medialets munc</p><p>5 0.11049142 <a title="1035-tfidf-5" href="../high_scalability-2009/high_scalability-2009-05-05-Drop_ACID_and_Think_About_Data.html">589 high scalability-2009-05-05-Drop ACID and Think About Data</a></p>
<p>Introduction: The abstract for the talk given by Bob Ippolito, co-founder and CTO of Mochi Media, Inc:
   Building large systems on top of a traditional single-master RDBMS data storage layer is no longer good enough. This talk explores the landscape of new technologies available today to augment your data layer to improve performance and reliability. Is your application a good fit for caches, bloom filters, bitmap indexes, column stores, distributed key/value stores, or document databases? Learn how they work (in theory and practice) and decide for yourself.   
Bob does an excellent job highlighting different products and the key concepts to understand when pondering the wide variety of new database offerings. It's unlikely you'll be able to say oh, this is the database for me after watching the presentation, but you will be much better informed on your options. And I imagine slightly confused as to what to do :-)  An interesting observation in the talk is that the more robust products are internal</p><p>6 0.11045098 <a title="1035-tfidf-6" href="../high_scalability-2010/high_scalability-2010-08-30-Pomegranate_-_Storing_Billions_and_Billions_of_Tiny_Little_Files.html">889 high scalability-2010-08-30-Pomegranate - Storing Billions and Billions of Tiny Little Files</a></p>
<p>7 0.10841254 <a title="1035-tfidf-7" href="../high_scalability-2011/high_scalability-2011-08-25-The_Cloud_and_The_Consumer%3A_The_Impact_on_Bandwidth_and_Broadband.html">1105 high scalability-2011-08-25-The Cloud and The Consumer: The Impact on Bandwidth and Broadband</a></p>
<p>8 0.097911015 <a title="1035-tfidf-8" href="../high_scalability-2012/high_scalability-2012-09-07-Stuff_The_Internet_Says_On_Scalability_For_September_7%2C_2012.html">1318 high scalability-2012-09-07-Stuff The Internet Says On Scalability For September 7, 2012</a></p>
<p>9 0.09545695 <a title="1035-tfidf-9" href="../high_scalability-2011/high_scalability-2011-01-10-Riak%27s_Bitcask_-_A_Log-Structured_Hash_Table_for_Fast_Key-Value_Data.html">971 high scalability-2011-01-10-Riak's Bitcask - A Log-Structured Hash Table for Fast Key-Value Data</a></p>
<p>10 0.092154726 <a title="1035-tfidf-10" href="../high_scalability-2011/high_scalability-2011-09-16-Stuff_The_Internet_Says_On_Scalability_For_September_16%2C_2011.html">1117 high scalability-2011-09-16-Stuff The Internet Says On Scalability For September 16, 2011</a></p>
<p>11 0.08784654 <a title="1035-tfidf-11" href="../high_scalability-2008/high_scalability-2008-11-22-Google_Architecture.html">448 high scalability-2008-11-22-Google Architecture</a></p>
<p>12 0.082277849 <a title="1035-tfidf-12" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>13 0.079569437 <a title="1035-tfidf-13" href="../high_scalability-2012/high_scalability-2012-07-09-Data_Replication_in_NoSQL_Databases.html">1279 high scalability-2012-07-09-Data Replication in NoSQL Databases</a></p>
<p>14 0.078099214 <a title="1035-tfidf-14" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>15 0.078084901 <a title="1035-tfidf-15" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>16 0.077046387 <a title="1035-tfidf-16" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>17 0.076498725 <a title="1035-tfidf-17" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>18 0.07561224 <a title="1035-tfidf-18" href="../high_scalability-2011/high_scalability-2011-03-24-Strategy%3A_Disk_Backup_for_Speed%2C_Tape_Backup_to_Save_Your_Bacon%2C_Just_Ask_Google.html">1010 high scalability-2011-03-24-Strategy: Disk Backup for Speed, Tape Backup to Save Your Bacon, Just Ask Google</a></p>
<p>19 0.074354365 <a title="1035-tfidf-19" href="../high_scalability-2013/high_scalability-2013-01-14-MongoDB_and_GridFS_for_Inter_and_Intra_Datacenter_Data_Replication_.html">1386 high scalability-2013-01-14-MongoDB and GridFS for Inter and Intra Datacenter Data Replication </a></p>
<p>20 0.069611534 <a title="1035-tfidf-20" href="../high_scalability-2008/high_scalability-2008-03-17-Paper%3A_Consistent_Hashing_and_Random_Trees%3A_Distributed_Caching_Protocols_for_Relieving_Hot_Spots_on_the_World_Wide_Web.html">280 high scalability-2008-03-17-Paper: Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.139), (1, 0.079), (2, -0.014), (3, 0.028), (4, -0.026), (5, 0.05), (6, 0.04), (7, -0.005), (8, 0.003), (9, 0.027), (10, 0.012), (11, -0.047), (12, -0.02), (13, -0.007), (14, 0.026), (15, 0.03), (16, -0.007), (17, 0.025), (18, -0.029), (19, -0.011), (20, 0.017), (21, 0.009), (22, 0.002), (23, 0.046), (24, -0.007), (25, -0.033), (26, 0.046), (27, -0.024), (28, -0.041), (29, -0.018), (30, -0.021), (31, -0.002), (32, 0.032), (33, 0.011), (34, -0.059), (35, 0.031), (36, 0.043), (37, 0.029), (38, 0.025), (39, -0.032), (40, -0.041), (41, -0.033), (42, -0.007), (43, 0.032), (44, 0.014), (45, 0.011), (46, -0.016), (47, -0.013), (48, -0.001), (49, 0.012)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93475544 <a title="1035-lsi-1" href="../high_scalability-2011/high_scalability-2011-05-05-Paper%3A_A_Study_of_Practical_Deduplication.html">1035 high scalability-2011-05-05-Paper: A Study of Practical Deduplication</a></p>
<p>Introduction: With BigData comes BigStorage costs. One way to store less is simply  not to store the same data twice . That's the radically simple and powerful notion behind  data deduplication . If you are one of those who got a good laugh out of the idea of  eliminating SQL queries  as a rather obvious scalability strategy, you'll love this one, but it is a powerful feature and one I don't hear talked about outside the enterprise. A parallel idea in programming is the once-and-only-once principle of never duplicating code.
 
Using deduplication technology, for some upfront CPU usage, which is a plentiful resource in many systems that are IO bound anyway, it's possible to reduce storage requirements by upto 20:1, depending on your data, which saves both money and disk write overhead. 
 
This comes up because of really good article Robin Harris of StorageMojo wrote,  All de-dup works , on a paper,   A Study of Practical Deduplication  by Dutch Meyer and William Bolosky, 
 
For a great  explanation o</p><p>2 0.83720487 <a title="1035-lsi-2" href="../high_scalability-2007/high_scalability-2007-07-31-BerkeleyDB_%26_other_distributed_high_performance_key-value_databases.html">50 high scalability-2007-07-31-BerkeleyDB & other distributed high performance key-value databases</a></p>
<p>Introduction: I currently use BerkeleyDB as an embedded database   http://www.oracle.com/database/berkeley-db/   a decision which was initially brought on by learning that Google used BerkeleyDB for their universal sign-on feature.     Lustre looks impressive, but their white paper shows speeds of 800 files created per second, as a good number.  However, BerkeleyDB on my mac mini does 200,000 row creations per second, and can be used as a distributed file system.     I'm having I/O scalability issues with BerkeleyDB on one machine, and about to implement their distributed replication feature (and go multi-machine), which in effect makes it work like a distributed file system, but with local access speeds.  That's why I was looking at Lustre.     The key feature difference between BerkeleyDB and Lustre is that BerkeleyDB has a complete copy of all the data on each computer, making it not a viable solution for massive sized database applications.  However, if you have < 1TB (ie, one disk) of total pos</p><p>3 0.82778114 <a title="1035-lsi-3" href="../high_scalability-2011/high_scalability-2011-01-10-Riak%27s_Bitcask_-_A_Log-Structured_Hash_Table_for_Fast_Key-Value_Data.html">971 high scalability-2011-01-10-Riak's Bitcask - A Log-Structured Hash Table for Fast Key-Value Data</a></p>
<p>Introduction: How would you implement a key-value storage system if you were starting from scratch? The approach Basho settled on with  Bitcask , their new backend for Riak, is an interesting combination of using RAM to store a hash map of file pointers to values and a log-structured file system for efficient writes.  In this excellent  Changelog interview , some folks from Basho describe Bitcask in more detail.
 
The essential Bitcask:
  
 
 Keys are stored in memory for fast lookups. All keys must fit in RAM. 
 Writes are append-only, which means writes are strictly sequential and do not require seeking. Writes are write-through. Every time a value is updated the data file on disk is appended and the in-memory key index is updated with the file pointer. 
 Read queries are satisfied with O(1) random disk seeks. Latency is very predictable if all keys fit in memory because there's no random seeking around through a file. 
 For reads, the file system cache in the kernel is used instead of writing a c</p><p>4 0.81155258 <a title="1035-lsi-4" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>Introduction: “ Data is everywhere, never be at a single location. Not scalable, not maintainable. ”  –Alex Szalay    While Galileo played life and death doctrinal games over the mysteries revealed by the telescope, another revolution went unnoticed, the microscope gave up mystery after mystery and nobody yet understood how subversive would be what it revealed. For the first time these new tools of perceptual augmentation allowed humans to peek behind the veil of appearance. A new new eye driving human invention and discovery for hundreds of years.     Data is another    material    that hides, revealing itself only when we look at different scales and investigate its underlying patterns. If the universe is truly    made of information   , then we are looking into truly primal stuff. A new eye is needed for Data and an ambitious project called    Data-scope    aims to be the lens.     A detailed    paper    on the Data-Scope tells more about what it is:  
  The Data-Scope is a new scientific instrum</p><p>5 0.80968428 <a title="1035-lsi-5" href="../high_scalability-2007/high_scalability-2007-10-21-Paper%3A_Standardizing_Storage_Clusters_%28with_pNFS%29.html">128 high scalability-2007-10-21-Paper: Standardizing Storage Clusters (with pNFS)</a></p>
<p>Introduction: pNFS (parallel NFS) is the next generation of NFS and its main claim to fame is that it's clustered, which "enables clients to directly access file data spread over multiple storage servers in parallel. As a result, each client can leverage the full aggregate bandwidth of a clustered storage service at the granularity of an individual file." About pNFS  StorageMojo  says:  pNFS is going to commoditize parallel data access. In 5 years we wonâ&euro;&trade;t know how we got along without it . Something to watch.</p><p>6 0.79984146 <a title="1035-lsi-6" href="../high_scalability-2007/high_scalability-2007-09-28-Kosmos_File_System_%28KFS%29_is_a_New_High_End_Google_File_System_Option.html">103 high scalability-2007-09-28-Kosmos File System (KFS) is a New High End Google File System Option</a></p>
<p>7 0.79864997 <a title="1035-lsi-7" href="../high_scalability-2007/high_scalability-2007-10-04-You_Can_Now_Store_All_Your_Stuff_on_Your_Own_Google_Like_File_System.html">112 high scalability-2007-10-04-You Can Now Store All Your Stuff on Your Own Google Like File System</a></p>
<p>8 0.7808252 <a title="1035-lsi-8" href="../high_scalability-2009/high_scalability-2009-02-05-Beta_testers_wanted_for_ultra_high-scalability-performance_clustered_object_storage_system_designed_for_web_content_delivery.html">508 high scalability-2009-02-05-Beta testers wanted for ultra high-scalability-performance clustered object storage system designed for web content delivery</a></p>
<p>9 0.77862817 <a title="1035-lsi-9" href="../high_scalability-2010/high_scalability-2010-08-30-Pomegranate_-_Storing_Billions_and_Billions_of_Tiny_Little_Files.html">889 high scalability-2010-08-30-Pomegranate - Storing Billions and Billions of Tiny Little Files</a></p>
<p>10 0.77403331 <a title="1035-lsi-10" href="../high_scalability-2013/high_scalability-2013-06-27-Paper%3A_XORing_Elephants%3A_Novel_Erasure_Codes_for_Big_Data.html">1483 high scalability-2013-06-27-Paper: XORing Elephants: Novel Erasure Codes for Big Data</a></p>
<p>11 0.77110839 <a title="1035-lsi-11" href="../high_scalability-2011/high_scalability-2011-08-10-LevelDB_-_Fast_and_Lightweight_Key-Value_Database_From_the_Authors_of_MapReduce_and_BigTable.html">1096 high scalability-2011-08-10-LevelDB - Fast and Lightweight Key-Value Database From the Authors of MapReduce and BigTable</a></p>
<p>12 0.77015042 <a title="1035-lsi-12" href="../high_scalability-2007/high_scalability-2007-09-18-Sync_data_on_all_servers.html">98 high scalability-2007-09-18-Sync data on all servers</a></p>
<p>13 0.75428921 <a title="1035-lsi-13" href="../high_scalability-2012/high_scalability-2012-07-09-Data_Replication_in_NoSQL_Databases.html">1279 high scalability-2012-07-09-Data Replication in NoSQL Databases</a></p>
<p>14 0.7541014 <a title="1035-lsi-14" href="../high_scalability-2011/high_scalability-2011-12-23-Funny%3A_A_Cautionary_Tale_About_Storage_and_Backup.html">1162 high scalability-2011-12-23-Funny: A Cautionary Tale About Storage and Backup</a></p>
<p>15 0.74965763 <a title="1035-lsi-15" href="../high_scalability-2011/high_scalability-2011-12-23-Stuff_The_Internet_Says_On_Scalability_For_December_23%2C_2011.html">1163 high scalability-2011-12-23-Stuff The Internet Says On Scalability For December 23, 2011</a></p>
<p>16 0.74890929 <a title="1035-lsi-16" href="../high_scalability-2010/high_scalability-2010-07-07-Strategy%3A_Recompute_Instead_of_Remember_Big_Data.html">852 high scalability-2010-07-07-Strategy: Recompute Instead of Remember Big Data</a></p>
<p>17 0.74872124 <a title="1035-lsi-17" href="../high_scalability-2008/high_scalability-2008-03-16-Product%3A_GlusterFS.html">278 high scalability-2008-03-16-Product: GlusterFS</a></p>
<p>18 0.74151498 <a title="1035-lsi-18" href="../high_scalability-2008/high_scalability-2008-08-17-Wuala_-_P2P_Online_Storage_Cloud.html">368 high scalability-2008-08-17-Wuala - P2P Online Storage Cloud</a></p>
<p>19 0.73945236 <a title="1035-lsi-19" href="../high_scalability-2010/high_scalability-2010-12-17-Stuff_the_Internet_Says_on_Scalability_For_December_17th%2C_2010.html">959 high scalability-2010-12-17-Stuff the Internet Says on Scalability For December 17th, 2010</a></p>
<p>20 0.73877156 <a title="1035-lsi-20" href="../high_scalability-2007/high_scalability-2007-10-01-SmugMug_Found_their_Perfect_Storage_Array.html">104 high scalability-2007-10-01-SmugMug Found their Perfect Storage Array</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.089), (2, 0.196), (10, 0.039), (27, 0.014), (30, 0.054), (40, 0.017), (57, 0.013), (61, 0.074), (63, 0.03), (77, 0.01), (79, 0.098), (85, 0.036), (94, 0.054), (96, 0.188)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93072236 <a title="1035-lda-1" href="../high_scalability-2008/high_scalability-2008-03-18-Database_Design_101.html">281 high scalability-2008-03-18-Database Design 101</a></p>
<p>Introduction: I am working on the design for my database and can't seem to come up with a firm schema.  I am torn between normalizing the data and dealing with the overhead of joins and denormalizing it for easy sharding.  The data is essentially music information per user: UserID, Artist, Album, Song.  This lends itself nicely to be normalized and have separate User, Artist, Album and Song databases with a table full of INTs to tie them together.  This will be in a mostly read based environment and with about 80% being searches of data by artist album or song.  By the time I begin the query for artist, album or song I will already have a list of UserID's to limit the search by.  The problem is that the tables can get unmanageably large pretty quickly and my plan was to shard off users once it got too big. Given this simple data relationship what are the pros and cons of normalizing the data vs denormalizing it?  Should I go with 4 separate, normalized tables or one 4 column table?  Perhaps it might</p><p>2 0.90231192 <a title="1035-lda-2" href="../high_scalability-2010/high_scalability-2010-07-30-Basho_Lives_up_to_their_Name_With_Consistent_Smashing.html">868 high scalability-2010-07-30-Basho Lives up to their Name With Consistent Smashing</a></p>
<p>Introduction: For some Friday Fun nerd style, I thought this  demonstration from Basho  on the difference between single master, sharding, and consistent smashing was really clever. I love the use of safety glasses! And it's harder to crash a server with a hammer than you might think...
 
          
 
RecommendedÂ reading:
  
 
  http://labs.google.com/papers/bigtable.html  
  http://research.yahoo.com/project/212</p><p>3 0.88863629 <a title="1035-lda-3" href="../high_scalability-2013/high_scalability-2013-11-15-Stuff_The_Internet_Says_On_Scalability_For_November_15th%2C_2013.html">1549 high scalability-2013-11-15-Stuff The Internet Says On Scalability For November 15th, 2013</a></p>
<p>Introduction: Hey, it's HighScalability time:
    Test your sense of scale. Is this image of something microscopic or macroscopic?  Find out .   
 Quotable Quotes:                           
 
  fidotron : It feels like we've gone in one big circle, where first we move the DB on to a separate machine for performance, yet now more computation will go back to being done nearer the data (like Hadoop) and we'll try to pretend it's all just one giant computer again. 
  @pbailis : Building systems from the ground up with distribution, scale, and availability in mind is much easier than retrofitting single-node systems. 
  @merv : #awsreinvent Jassy: Netflix has 10,000s of EC2 instances. They are the final deployment scenario: All In. And others are coming. 
  Edward Capriolo : YARN... Either it is really complicated or I have brain damage 
  @djspiewak : Eventually, Node.js will reinvent the “IO promise” and realize that flattening your callback effects is actually quite nice. 
  @jimblomo : A Note on Dis</p><p>same-blog 4 0.8828612 <a title="1035-lda-4" href="../high_scalability-2011/high_scalability-2011-05-05-Paper%3A_A_Study_of_Practical_Deduplication.html">1035 high scalability-2011-05-05-Paper: A Study of Practical Deduplication</a></p>
<p>Introduction: With BigData comes BigStorage costs. One way to store less is simply  not to store the same data twice . That's the radically simple and powerful notion behind  data deduplication . If you are one of those who got a good laugh out of the idea of  eliminating SQL queries  as a rather obvious scalability strategy, you'll love this one, but it is a powerful feature and one I don't hear talked about outside the enterprise. A parallel idea in programming is the once-and-only-once principle of never duplicating code.
 
Using deduplication technology, for some upfront CPU usage, which is a plentiful resource in many systems that are IO bound anyway, it's possible to reduce storage requirements by upto 20:1, depending on your data, which saves both money and disk write overhead. 
 
This comes up because of really good article Robin Harris of StorageMojo wrote,  All de-dup works , on a paper,   A Study of Practical Deduplication  by Dutch Meyer and William Bolosky, 
 
For a great  explanation o</p><p>5 0.88054812 <a title="1035-lda-5" href="../high_scalability-2007/high_scalability-2007-11-20-what_is_j2ee_stack.html">162 high scalability-2007-11-20-what is j2ee stack</a></p>
<p>Introduction: I see everyone talk about lamp stack is less than j2ee stack .i m newbie can anyone plz explain what is j2ee stack</p><p>6 0.86943614 <a title="1035-lda-6" href="../high_scalability-2007/high_scalability-2007-10-08-Paper%3A_Understanding_and_Building_High_Availability-Load_Balanced_Clusters.html">117 high scalability-2007-10-08-Paper: Understanding and Building High Availability-Load Balanced Clusters</a></p>
<p>7 0.85973144 <a title="1035-lda-7" href="../high_scalability-2011/high_scalability-2011-06-03-Stuff_The_Internet_Says_On_Scalability_For_June_3%2C_2011.html">1052 high scalability-2011-06-03-Stuff The Internet Says On Scalability For June 3, 2011</a></p>
<p>8 0.84985608 <a title="1035-lda-8" href="../high_scalability-2012/high_scalability-2012-04-16-Instagram_Architecture_Update%3A_What%E2%80%99s_new_with_Instagram%3F.html">1228 high scalability-2012-04-16-Instagram Architecture Update: What’s new with Instagram?</a></p>
<p>9 0.8492685 <a title="1035-lda-9" href="../high_scalability-2008/high_scalability-2008-10-17-Scaling_Spam_Eradication_Using_Purposeful_Games%3A_Die_Spammer_Die%21.html">422 high scalability-2008-10-17-Scaling Spam Eradication Using Purposeful Games: Die Spammer Die!</a></p>
<p>10 0.84745604 <a title="1035-lda-10" href="../high_scalability-2008/high_scalability-2008-07-09-Federation_at_Flickr%3A_Doing_Billions_of_Queries_Per_Day.html">348 high scalability-2008-07-09-Federation at Flickr: Doing Billions of Queries Per Day</a></p>
<p>11 0.84586138 <a title="1035-lda-11" href="../high_scalability-2010/high_scalability-2010-05-17-7_Lessons_Learned_While_Building_Reddit_to_270_Million_Page_Views_a_Month.html">828 high scalability-2010-05-17-7 Lessons Learned While Building Reddit to 270 Million Page Views a Month</a></p>
<p>12 0.84573746 <a title="1035-lda-12" href="../high_scalability-2013/high_scalability-2013-10-07-Ask_HS%3A_Is_Microsoft_the_Right_Technology_for_a_Scalable_Web-based_System%3F.html">1528 high scalability-2013-10-07-Ask HS: Is Microsoft the Right Technology for a Scalable Web-based System?</a></p>
<p>13 0.84301805 <a title="1035-lda-13" href="../high_scalability-2008/high_scalability-2008-09-28-Product%3A_Happy_%3D_Hadoop_%2B_Python.html">397 high scalability-2008-09-28-Product: Happy = Hadoop + Python</a></p>
<p>14 0.83978796 <a title="1035-lda-14" href="../high_scalability-2012/high_scalability-2012-03-21-The_Conspecific_Hybrid_Cloud.html">1212 high scalability-2012-03-21-The Conspecific Hybrid Cloud</a></p>
<p>15 0.83157456 <a title="1035-lda-15" href="../high_scalability-2008/high_scalability-2008-10-30-The_case_for_functional_decomposition.html">435 high scalability-2008-10-30-The case for functional decomposition</a></p>
<p>16 0.82871914 <a title="1035-lda-16" href="../high_scalability-2012/high_scalability-2012-04-03-Hazelcast_2.0%3A_Big_Data_In-Memory.html">1221 high scalability-2012-04-03-Hazelcast 2.0: Big Data In-Memory</a></p>
<p>17 0.80367821 <a title="1035-lda-17" href="../high_scalability-2013/high_scalability-2013-03-06-Low_Level_Scalability_Solutions_-_The_Aggregation_Collection.html">1418 high scalability-2013-03-06-Low Level Scalability Solutions - The Aggregation Collection</a></p>
<p>18 0.80339563 <a title="1035-lda-18" href="../high_scalability-2009/high_scalability-2009-09-12-How_Google_Taught_Me_to_Cache_and_Cash-In.html">703 high scalability-2009-09-12-How Google Taught Me to Cache and Cash-In</a></p>
<p>19 0.7997992 <a title="1035-lda-19" href="../high_scalability-2008/high_scalability-2008-07-16-The_Mother_of_All_Database_Normalization_Debates_on_Coding_Horror.html">351 high scalability-2008-07-16-The Mother of All Database Normalization Debates on Coding Horror</a></p>
<p>20 0.79869878 <a title="1035-lda-20" href="../high_scalability-2013/high_scalability-2013-06-10-The_10_Deadly_Sins_Against_Scalability.html">1473 high scalability-2013-06-10-The 10 Deadly Sins Against Scalability</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
