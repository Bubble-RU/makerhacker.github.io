<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1118 high scalability-2011-09-19-Big Iron Returns with BigMemory</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2011" href="../home/high_scalability-2011_home.html">high_scalability-2011</a> <a title="high_scalability-2011-1118" href="#">high_scalability-2011-1118</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1118 high scalability-2011-09-19-Big Iron Returns with BigMemory</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2011-1118-html" href="http://highscalability.com//blog/2011/9/19/big-iron-returns-with-bigmemory.html">html</a></p><p>Introduction: This is a guest post by Greg Luck Founder and CTO,  Ehcache  Terracotta Inc.  Note: this article contains a bit too much of a product pitch, but the points are still generally valid and useful.
 
The legendary Moore’s Law, which  states that the number of transistors that can be placed inexpensively  on an integrated circuit doubles approximately every two years, has  held true since 1965. It follows that integrated circuits will continue  to get smaller, with chip fabrication currently at a minuscule 22nm  process (1). Users of big iron hardware, or servers that  are dense in terms of CPU power and memory capacity, benefit from this  trend as their hardware becomes cheaper and more powerful over time.  At some point soon, however, density limits imposed by quantum mechanics  will preclude further density increases.
 
At the same time, low-cost commodity  hardware influences enterprise architects to scale their applications  horizontally, where processing is spread across clusters of l</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Users of big iron hardware, or servers that  are dense in terms of CPU power and memory capacity, benefit from this  trend as their hardware becomes cheaper and more powerful over time. [sent-5, score-0.567]
</p><p>2 At the same time, low-cost commodity  hardware influences enterprise architects to scale their applications  horizontally, where processing is spread across clusters of low-cost  commodity servers. [sent-7, score-0.429]
</p><p>3 Although in theory it’s simple to  say, “Use memory instead of disk,” it’s difficult to put this  advice into practice, because the massive growth in available physical  memory is outpacing software technology. [sent-31, score-0.579]
</p><p>4 For instance, when memory management goes wrong, developers  experience memory leaks (lack of memory de-allocation) or memory access  violations due to accessing memory that has already been de-allocated  or attempting to de-allocate memory more than once. [sent-39, score-1.566]
</p><p>5 To relieve developers  of these potential problems, Java implemented automatic memory management  of the Java heap with a garbage collector (GC). [sent-40, score-0.95]
</p><p>6 When a running program  no longer requires specific objects, the Java garbage collector reclaims  its memory within the Java heap. [sent-41, score-0.607]
</p><p>7 Garbage collection works reasonably well, but it becomes increasingly  stressed as the size of the Java heap and numbers of live objects within  it increase. [sent-43, score-0.583]
</p><p>8 Today, GC works well with an occupied Java heap around  3-4GB in size, which also just happens to be the 32-bit memory limit. [sent-44, score-0.613]
</p><p>9 The size limits imposed by Java garbage  collection explain why 64-bit Java use remains a minority despite the  availability of commodity 64-bit CPUs, operating systems and Java for  half a decade. [sent-45, score-0.629]
</p><p>10 Solving the Java Heap/GC Problem   There’s more than one way to try  to resolve the problems associated with garbage collection and very  large Java heaps. [sent-48, score-0.449]
</p><p>11 These JVMs offer garbage collection over large heaps with controlled,  predictable latency; however, they often come with a price tag and require  changes to source code, making them impractical for most applications. [sent-50, score-0.484]
</p><p>12 It creates  a cache store in memory but outside the Java heap using Direct Byte  Buffers. [sent-58, score-0.606]
</p><p>13 This lets you keep the Java heap relatively  small (1-2GB in size), while using the maximum amount of objects within  physical memory. [sent-61, score-0.516]
</p><p>14 As a result, BigMemory can create caches in memory  that match physical RAM limits (i. [sent-62, score-0.415]
</p><p>15 2TB today and more in the future),  without the garbage collection penalties that usually come with a Java  heap of that size. [sent-64, score-0.732]
</p><p>16 By storing your application’s data outside of the  Java heap but within RAM inside your Java process, you get all the benefits  of in-memory storage without the traditional Java costs. [sent-65, score-0.425]
</p><p>17 The Benefits of Vertical Scale   With BigMemory, you can take advantage  of all of your server’s available memory without the compromises and  cost typically associated with enterprise Java applications. [sent-66, score-0.409]
</p><p>18 They do this by running multiple JVM/application  server instances, each with small heap sizes, on a single node configured  across either multiple network ports or virtual guest OS instances using  technology such as VMWare. [sent-68, score-0.518]
</p><p>19 By allowing you to run one JVM/application  server instance with a manageable heap and a very large in-memory Enterprise  Ehcache cache, BigMemory eliminates these direct and hidden costs, along  with the nightmares that come with such complexity. [sent-72, score-0.44]
</p><p>20 Fortunately, with  BigMemory, the top tiers of the pyramid can be sized as large as the  physical memory limits of your server, keeping in mind the limits of  the Java heap that we just discussed. [sent-78, score-0.942]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bigmemory', 0.377), ('heap', 0.302), ('java', 0.296), ('memory', 0.243), ('ehcache', 0.211), ('garbage', 0.202), ('commodity', 0.128), ('iron', 0.128), ('heaps', 0.107), ('collection', 0.105), ('tiered', 0.095), ('collector', 0.095), ('enterprise', 0.094), ('physical', 0.093), ('gc', 0.092), ('instances', 0.084), ('architects', 0.079), ('limits', 0.079), ('pyramid', 0.076), ('associated', 0.072), ('mediums', 0.071), ('servers', 0.071), ('large', 0.07), ('guest', 0.07), ('disk', 0.068), ('instance', 0.068), ('occupied', 0.068), ('penalties', 0.068), ('within', 0.067), ('big', 0.066), ('however', 0.065), ('jvms', 0.063), ('ram', 0.062), ('virtual', 0.062), ('vertical', 0.061), ('cache', 0.061), ('imposed', 0.06), ('trend', 0.059), ('latencies', 0.056), ('developers', 0.056), ('storage', 0.056), ('pauses', 0.056), ('size', 0.055), ('today', 0.055), ('objects', 0.054), ('jvm', 0.053), ('employ', 0.052), ('survey', 0.052), ('management', 0.052), ('gap', 0.05)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="1118-tfidf-1" href="../high_scalability-2011/high_scalability-2011-09-19-Big_Iron_Returns_with_BigMemory.html">1118 high scalability-2011-09-19-Big Iron Returns with BigMemory</a></p>
<p>Introduction: This is a guest post by Greg Luck Founder and CTO,  Ehcache  Terracotta Inc.  Note: this article contains a bit too much of a product pitch, but the points are still generally valid and useful.
 
The legendary Moore’s Law, which  states that the number of transistors that can be placed inexpensively  on an integrated circuit doubles approximately every two years, has  held true since 1965. It follows that integrated circuits will continue  to get smaller, with chip fabrication currently at a minuscule 22nm  process (1). Users of big iron hardware, or servers that  are dense in terms of CPU power and memory capacity, benefit from this  trend as their hardware becomes cheaper and more powerful over time.  At some point soon, however, density limits imposed by quantum mechanics  will preclude further density increases.
 
At the same time, low-cost commodity  hardware influences enterprise architects to scale their applications  horizontally, where processing is spread across clusters of l</p><p>2 0.31202504 <a title="1118-tfidf-2" href="../high_scalability-2008/high_scalability-2008-12-03-Java_World_Interview_on_Scalability_and_Other_Java_Scalability_Secrets.html">459 high scalability-2008-12-03-Java World Interview on Scalability and Other Java Scalability Secrets</a></p>
<p>Introduction: OK, this  interview is with me  on Java scalability issues. I sound like a bigger idiot than I would like, but I suppose it could have been worse. The Java World folks were very nice and did a good job, so there’s no blame on them :-)   The interview went an interesting direction, but there’s more I’d like add and I will do so here. Two major rules regarding Java and scalability have popped out at me:
    Java – It’s the platform stupid .  Java the language isn’t the big win. What is the big win is the ecosystem building up around the JVM, libraries, and toolsets.      Java – It’s the community stupid . A lot of creativity is being expended on leveraging the Java platform to meet scalability challenges. The amazing community that has built up around Java is pushing Java to the next level in almost every direction imaginable.  The fecundity of the Java ecosystem can most readily be seen with the efforts to tame our multi-core future. There’s a multi-core crisis going in case you haven’t</p><p>3 0.24941081 <a title="1118-tfidf-3" href="../high_scalability-2008/high_scalability-2008-08-14-Product%3A_Terracotta_-_Open_Source_Network-Attached_Memory.html">364 high scalability-2008-08-14-Product: Terracotta - Open Source Network-Attached Memory</a></p>
<p>Introduction: Update:     Evaluating Terracotta   by Piotr Woloszyn. Nice writeup that covers resilience, failover, DB persistence, Distributed caching implementation, OS/Platform restrictions, Ease of implementation, Hardware requirements, Performance, Support package, Code stability, partitioning, Transactional, Replication and consistency.      Terracotta   is Network Attached Memory (NAM) for Java VMs. It provides up to a terabyte of virtual heap for Java applications that spans hundreds of connected JVMs.     NAM is best suited for storing what they call scratch data. Scratch data is defined as object oriented data that is critical to the execution of a series of Java operations inside the JVM, but may not be critical once a business transaction is complete.     The Terracotta Architecture has three components:     Client Nodes - Each client node corresponds to a client node in the cluster which runs on a standard JVM   Server Cluster - java process that provides the clustering intelligence. Th</p><p>4 0.23947179 <a title="1118-tfidf-4" href="../high_scalability-2014/high_scalability-2014-01-20-8_Ways_Stardog_Made_its_Database_Insanely_Scalable.html">1582 high scalability-2014-01-20-8 Ways Stardog Made its Database Insanely Scalable</a></p>
<p>Introduction: Stardog  makes a commercial graph database that is a great example of what can be accomplished with a scale-up strategy on BigIron. In a  recent article  StarDog described how they made their new 2.1 release insanely scalable, improving query scalability by about 3 orders of magnitude and it can now handle 50 billion triples on a $10,000 server with 32 cores and 256 GB RAM. It can also load 20B datasets at 300,000 triples per second. 
 
What did they do that you can also do?
  
  Avoid locks by using non-blocking algorithms and data structures . For example, moving from BitSet to ConcurrentLinkedQueue. 
  Use ThreadLocal aggressively to reduce thread contention and avoid synchronization . 
  Batch LRU evictions in a single thread . Triggered by several LRU caches becoming problematic when evictions were being swamped by additions. Downside is batching increases memory pressure and GC times. 
  Move to SHA1 for hashing URIs, bnodes, and literal values . Making hash collisions nearly imp</p><p>5 0.21658246 <a title="1118-tfidf-5" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>Introduction: We are on the edge of two potent technological changes: Clouds and Memory Based Architectures. This evolution will rip open a chasm where new players can enter and prosper. Google is the master of disk. You can't beat them at a game they perfected. Disk based databases like SimpleDB and BigTable are complicated beasts, typical last gasp products of any aging technology before a change. The next era is the age of Memory and Cloud which will allow for new players to succeed. The tipping point will be soon.   Let's take a short trip down web architecture lane:
  It's 1993: Yahoo runs on FreeBSD, Apache, Perl scripts and a SQL database   It's 1995: Scale-up the database.   It's 1998: LAMP   It's 1999: Stateless + Load Balanced + Database + SAN   It's 2001: In-memory data-grid.   It's 2003: Add a caching layer.   It's 2004: Add scale-out and partitioning.   It's 2005: Add asynchronous job scheduling and maybe a distributed file system.   It's 2007: Move it all into the cloud.   It's 2008: C</p><p>6 0.21329007 <a title="1118-tfidf-6" href="../high_scalability-2008/high_scalability-2008-12-19-Gigaspaces_curbs_latency_outliers_with_Java_Real_Time.html">471 high scalability-2008-12-19-Gigaspaces curbs latency outliers with Java Real Time</a></p>
<p>7 0.20665638 <a title="1118-tfidf-7" href="../high_scalability-2012/high_scalability-2012-04-03-Hazelcast_2.0%3A_Big_Data_In-Memory.html">1221 high scalability-2012-04-03-Hazelcast 2.0: Big Data In-Memory</a></p>
<p>8 0.18368509 <a title="1118-tfidf-8" href="../high_scalability-2014/high_scalability-2014-03-20-Paper%3A_Log-structured_Memory_for_DRAM-based_Storage_-_High_Memory_Utilization_Plus_High_Performance.html">1616 high scalability-2014-03-20-Paper: Log-structured Memory for DRAM-based Storage - High Memory Utilization Plus High Performance</a></p>
<p>9 0.18334913 <a title="1118-tfidf-9" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>10 0.1808539 <a title="1118-tfidf-10" href="../high_scalability-2008/high_scalability-2008-07-29-Ehcache_-_A_Java_Distributed_Cache_.html">359 high scalability-2008-07-29-Ehcache - A Java Distributed Cache </a></p>
<p>11 0.17888489 <a title="1118-tfidf-11" href="../high_scalability-2011/high_scalability-2011-05-11-Troubleshooting_response_time_problems_%E2%80%93_why_you_cannot_trust_your_system_metrics.html">1038 high scalability-2011-05-11-Troubleshooting response time problems – why you cannot trust your system metrics</a></p>
<p>12 0.16864108 <a title="1118-tfidf-12" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>13 0.16692796 <a title="1118-tfidf-13" href="../high_scalability-2013/high_scalability-2013-11-20-How_Twitter_Improved_JVM_Performance_by_Reducing_GC_and_Faster_Memory_Allocation.html">1551 high scalability-2013-11-20-How Twitter Improved JVM Performance by Reducing GC and Faster Memory Allocation</a></p>
<p>14 0.1573728 <a title="1118-tfidf-14" href="../high_scalability-2013/high_scalability-2013-12-11-Using_Node.js_PayPal_Doubles_RPS%2C_Lowers_Latency%2C_with_Fewer_Developers%2C_but_Where_Do_the_Improvements_Really_Come_From%3F.html">1563 high scalability-2013-12-11-Using Node.js PayPal Doubles RPS, Lowers Latency, with Fewer Developers, but Where Do the Improvements Really Come From?</a></p>
<p>15 0.15584128 <a title="1118-tfidf-15" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>16 0.15580961 <a title="1118-tfidf-16" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>17 0.1473314 <a title="1118-tfidf-17" href="../high_scalability-2012/high_scalability-2012-05-02-12_Ways_to_Increase_Throughput_by_32X_and_Reduce_Latency_by__20X.html">1237 high scalability-2012-05-02-12 Ways to Increase Throughput by 32X and Reduce Latency by  20X</a></p>
<p>18 0.14632109 <a title="1118-tfidf-18" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>19 0.14628683 <a title="1118-tfidf-19" href="../high_scalability-2011/high_scalability-2011-03-14-6_Lessons_from_Dropbox_-_One_Million_Files_Saved_Every_15_minutes.html">1003 high scalability-2011-03-14-6 Lessons from Dropbox - One Million Files Saved Every 15 minutes</a></p>
<p>20 0.14524524 <a title="1118-tfidf-20" href="../high_scalability-2011/high_scalability-2011-06-17-Stuff_The_Internet_Says_On_Scalability_For_June_17%2C_2011.html">1063 high scalability-2011-06-17-Stuff The Internet Says On Scalability For June 17, 2011</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.287), (1, 0.074), (2, -0.005), (3, 0.018), (4, -0.09), (5, 0.068), (6, 0.123), (7, -0.004), (8, -0.132), (9, 0.025), (10, -0.024), (11, -0.061), (12, 0.076), (13, 0.068), (14, -0.105), (15, -0.05), (16, 0.004), (17, -0.031), (18, 0.001), (19, 0.021), (20, -0.101), (21, -0.01), (22, 0.034), (23, 0.015), (24, -0.034), (25, -0.019), (26, 0.014), (27, -0.23), (28, 0.001), (29, 0.007), (30, 0.035), (31, 0.018), (32, 0.019), (33, -0.097), (34, -0.035), (35, 0.03), (36, -0.056), (37, -0.008), (38, -0.002), (39, 0.044), (40, 0.063), (41, 0.025), (42, 0.016), (43, 0.086), (44, -0.029), (45, -0.029), (46, 0.134), (47, -0.016), (48, 0.02), (49, 0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97932833 <a title="1118-lsi-1" href="../high_scalability-2011/high_scalability-2011-09-19-Big_Iron_Returns_with_BigMemory.html">1118 high scalability-2011-09-19-Big Iron Returns with BigMemory</a></p>
<p>Introduction: This is a guest post by Greg Luck Founder and CTO,  Ehcache  Terracotta Inc.  Note: this article contains a bit too much of a product pitch, but the points are still generally valid and useful.
 
The legendary Moore’s Law, which  states that the number of transistors that can be placed inexpensively  on an integrated circuit doubles approximately every two years, has  held true since 1965. It follows that integrated circuits will continue  to get smaller, with chip fabrication currently at a minuscule 22nm  process (1). Users of big iron hardware, or servers that  are dense in terms of CPU power and memory capacity, benefit from this  trend as their hardware becomes cheaper and more powerful over time.  At some point soon, however, density limits imposed by quantum mechanics  will preclude further density increases.
 
At the same time, low-cost commodity  hardware influences enterprise architects to scale their applications  horizontally, where processing is spread across clusters of l</p><p>2 0.84665179 <a title="1118-lsi-2" href="../high_scalability-2014/high_scalability-2014-01-20-8_Ways_Stardog_Made_its_Database_Insanely_Scalable.html">1582 high scalability-2014-01-20-8 Ways Stardog Made its Database Insanely Scalable</a></p>
<p>Introduction: Stardog  makes a commercial graph database that is a great example of what can be accomplished with a scale-up strategy on BigIron. In a  recent article  StarDog described how they made their new 2.1 release insanely scalable, improving query scalability by about 3 orders of magnitude and it can now handle 50 billion triples on a $10,000 server with 32 cores and 256 GB RAM. It can also load 20B datasets at 300,000 triples per second. 
 
What did they do that you can also do?
  
  Avoid locks by using non-blocking algorithms and data structures . For example, moving from BitSet to ConcurrentLinkedQueue. 
  Use ThreadLocal aggressively to reduce thread contention and avoid synchronization . 
  Batch LRU evictions in a single thread . Triggered by several LRU caches becoming problematic when evictions were being swamped by additions. Downside is batching increases memory pressure and GC times. 
  Move to SHA1 for hashing URIs, bnodes, and literal values . Making hash collisions nearly imp</p><p>3 0.82897449 <a title="1118-lsi-3" href="../high_scalability-2008/high_scalability-2008-08-14-Product%3A_Terracotta_-_Open_Source_Network-Attached_Memory.html">364 high scalability-2008-08-14-Product: Terracotta - Open Source Network-Attached Memory</a></p>
<p>Introduction: Update:     Evaluating Terracotta   by Piotr Woloszyn. Nice writeup that covers resilience, failover, DB persistence, Distributed caching implementation, OS/Platform restrictions, Ease of implementation, Hardware requirements, Performance, Support package, Code stability, partitioning, Transactional, Replication and consistency.      Terracotta   is Network Attached Memory (NAM) for Java VMs. It provides up to a terabyte of virtual heap for Java applications that spans hundreds of connected JVMs.     NAM is best suited for storing what they call scratch data. Scratch data is defined as object oriented data that is critical to the execution of a series of Java operations inside the JVM, but may not be critical once a business transaction is complete.     The Terracotta Architecture has three components:     Client Nodes - Each client node corresponds to a client node in the cluster which runs on a standard JVM   Server Cluster - java process that provides the clustering intelligence. Th</p><p>4 0.82588446 <a title="1118-lsi-4" href="../high_scalability-2008/high_scalability-2008-12-03-Java_World_Interview_on_Scalability_and_Other_Java_Scalability_Secrets.html">459 high scalability-2008-12-03-Java World Interview on Scalability and Other Java Scalability Secrets</a></p>
<p>Introduction: OK, this  interview is with me  on Java scalability issues. I sound like a bigger idiot than I would like, but I suppose it could have been worse. The Java World folks were very nice and did a good job, so there’s no blame on them :-)   The interview went an interesting direction, but there’s more I’d like add and I will do so here. Two major rules regarding Java and scalability have popped out at me:
    Java – It’s the platform stupid .  Java the language isn’t the big win. What is the big win is the ecosystem building up around the JVM, libraries, and toolsets.      Java – It’s the community stupid . A lot of creativity is being expended on leveraging the Java platform to meet scalability challenges. The amazing community that has built up around Java is pushing Java to the next level in almost every direction imaginable.  The fecundity of the Java ecosystem can most readily be seen with the efforts to tame our multi-core future. There’s a multi-core crisis going in case you haven’t</p><p>5 0.80055046 <a title="1118-lsi-5" href="../high_scalability-2014/high_scalability-2014-03-20-Paper%3A_Log-structured_Memory_for_DRAM-based_Storage_-_High_Memory_Utilization_Plus_High_Performance.html">1616 high scalability-2014-03-20-Paper: Log-structured Memory for DRAM-based Storage - High Memory Utilization Plus High Performance</a></p>
<p>Introduction: Most every programmer who gets sucked into deep performance analysis for long running processes eventually realizes memory allocation is the heart of evil at the center of many of their problems. So you replace malloc with something less worse. Or you tune your garbage collector like a fineÂ ukulele. But there's a smarter approach brought to you from the folks at  RAMCloud , a Stanford University production, which is a large scale, distributed, in-memory key-value database.
 
What they've found is that typical memory management approaches don't work and using a log structured approach yields massive benefits:
  

Performance measurements of log-structured memory in RAMCloud show that it enables high client through- put at 80-90% memory utilization, even with artificially stressful workloads. In the most stressful workload, a single RAMCloud server can support 270,000-410,000 durable 100-byte writes per second at 90% memory utilization. The two-level approach to cleaning improves perform</p><p>6 0.76980305 <a title="1118-lsi-6" href="../high_scalability-2013/high_scalability-2013-11-20-How_Twitter_Improved_JVM_Performance_by_Reducing_GC_and_Faster_Memory_Allocation.html">1551 high scalability-2013-11-20-How Twitter Improved JVM Performance by Reducing GC and Faster Memory Allocation</a></p>
<p>7 0.75454313 <a title="1118-lsi-7" href="../high_scalability-2013/high_scalability-2013-06-06-Paper%3A_Memory_Barriers%3A_a_Hardware_View_for_Software_Hackers.html">1471 high scalability-2013-06-06-Paper: Memory Barriers: a Hardware View for Software Hackers</a></p>
<p>8 0.75088096 <a title="1118-lsi-8" href="../high_scalability-2009/high_scalability-2009-09-10-When_optimizing_-_don%27t_forget_the_Java_Virtual_Machine_%28JVM%29_.html">701 high scalability-2009-09-10-When optimizing - don't forget the Java Virtual Machine (JVM) </a></p>
<p>9 0.74857563 <a title="1118-lsi-9" href="../high_scalability-2008/high_scalability-2008-12-19-Gigaspaces_curbs_latency_outliers_with_Java_Real_Time.html">471 high scalability-2008-12-19-Gigaspaces curbs latency outliers with Java Real Time</a></p>
<p>10 0.74099499 <a title="1118-lsi-10" href="../high_scalability-2011/high_scalability-2011-03-14-6_Lessons_from_Dropbox_-_One_Million_Files_Saved_Every_15_minutes.html">1003 high scalability-2011-03-14-6 Lessons from Dropbox - One Million Files Saved Every 15 minutes</a></p>
<p>11 0.73638678 <a title="1118-lsi-11" href="../high_scalability-2012/high_scalability-2012-05-16-Big_List_of_20_Common_Bottlenecks.html">1246 high scalability-2012-05-16-Big List of 20 Common Bottlenecks</a></p>
<p>12 0.72801089 <a title="1118-lsi-12" href="../high_scalability-2012/high_scalability-2012-05-02-12_Ways_to_Increase_Throughput_by_32X_and_Reduce_Latency_by__20X.html">1237 high scalability-2012-05-02-12 Ways to Increase Throughput by 32X and Reduce Latency by  20X</a></p>
<p>13 0.72643304 <a title="1118-lsi-13" href="../high_scalability-2007/high_scalability-2007-09-15-The_Role_of_Memory_within_Web_2.0_Architectures_and_Deployments.html">92 high scalability-2007-09-15-The Role of Memory within Web 2.0 Architectures and Deployments</a></p>
<p>14 0.72481531 <a title="1118-lsi-14" href="../high_scalability-2012/high_scalability-2012-04-03-Hazelcast_2.0%3A_Big_Data_In-Memory.html">1221 high scalability-2012-04-03-Hazelcast 2.0: Big Data In-Memory</a></p>
<p>15 0.72177058 <a title="1118-lsi-15" href="../high_scalability-2014/high_scalability-2014-05-21-9_Principles_of_High_Performance_Programs.html">1652 high scalability-2014-05-21-9 Principles of High Performance Programs</a></p>
<p>16 0.72008622 <a title="1118-lsi-16" href="../high_scalability-2012/high_scalability-2012-12-10-Switch_your_databases_to_Flash_storage._Now._Or_you%27re_doing_it_wrong..html">1369 high scalability-2012-12-10-Switch your databases to Flash storage. Now. Or you're doing it wrong.</a></p>
<p>17 0.71841961 <a title="1118-lsi-17" href="../high_scalability-2011/high_scalability-2011-05-11-Troubleshooting_response_time_problems_%E2%80%93_why_you_cannot_trust_your_system_metrics.html">1038 high scalability-2011-05-11-Troubleshooting response time problems – why you cannot trust your system metrics</a></p>
<p>18 0.71485436 <a title="1118-lsi-18" href="../high_scalability-2013/high_scalability-2013-12-11-Using_Node.js_PayPal_Doubles_RPS%2C_Lowers_Latency%2C_with_Fewer_Developers%2C_but_Where_Do_the_Improvements_Really_Come_From%3F.html">1563 high scalability-2013-12-11-Using Node.js PayPal Doubles RPS, Lowers Latency, with Fewer Developers, but Where Do the Improvements Really Come From?</a></p>
<p>19 0.69235235 <a title="1118-lsi-19" href="../high_scalability-2008/high_scalability-2008-10-19-Alternatives_to_Google_App_Engine.html">423 high scalability-2008-10-19-Alternatives to Google App Engine</a></p>
<p>20 0.68745679 <a title="1118-lsi-20" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.15), (2, 0.206), (10, 0.068), (15, 0.018), (27, 0.015), (40, 0.021), (47, 0.015), (54, 0.093), (59, 0.024), (61, 0.087), (73, 0.01), (79, 0.118), (85, 0.041), (94, 0.037)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.960006 <a title="1118-lda-1" href="../high_scalability-2013/high_scalability-2013-03-27-The_Changing_Face_of_Scale_-_The_Downside_of_Scaling_in_the_Contextual_Age_.html">1430 high scalability-2013-03-27-The Changing Face of Scale - The Downside of Scaling in the Contextual Age </a></p>
<p>Introduction: Robert Scoble  is a kind of Brothers Grimm for the digital age. Instead of inspired romantics walking around the country side collecting the folk tales of past ages, he is an inspired technologist documenting the current mythology of startups.
 
One of the developments Robert is exploring is the rise of the  contextual age . Where every bit of information about you is continually being prodded, pulled, and observed, shoveled into a great learning machine, and turned into a fully actionable  knowledge graph  of context. A digital identity more real to software than your physical body ever was. 
 
Sinner or saviour, the Age of Context has interesting implications for startups. It raises the entrance bar to dizzying heights. Much of the reason companies are tearing down the Golden Age of the Web, one open protocol at a time, is to create a walled garden of monopolized information.
 
To operate in this world you will have to somehow create a walled garden of your own. And it will be a damn</p><p>same-blog 2 0.9535417 <a title="1118-lda-2" href="../high_scalability-2011/high_scalability-2011-09-19-Big_Iron_Returns_with_BigMemory.html">1118 high scalability-2011-09-19-Big Iron Returns with BigMemory</a></p>
<p>Introduction: This is a guest post by Greg Luck Founder and CTO,  Ehcache  Terracotta Inc.  Note: this article contains a bit too much of a product pitch, but the points are still generally valid and useful.
 
The legendary Moore’s Law, which  states that the number of transistors that can be placed inexpensively  on an integrated circuit doubles approximately every two years, has  held true since 1965. It follows that integrated circuits will continue  to get smaller, with chip fabrication currently at a minuscule 22nm  process (1). Users of big iron hardware, or servers that  are dense in terms of CPU power and memory capacity, benefit from this  trend as their hardware becomes cheaper and more powerful over time.  At some point soon, however, density limits imposed by quantum mechanics  will preclude further density increases.
 
At the same time, low-cost commodity  hardware influences enterprise architects to scale their applications  horizontally, where processing is spread across clusters of l</p><p>3 0.94468153 <a title="1118-lda-3" href="../high_scalability-2009/high_scalability-2009-01-20-Product%3A_Amazon%27s_SimpleDB.html">498 high scalability-2009-01-20-Product: Amazon's SimpleDB</a></p>
<p>Introduction: Update 35  :   How and Why Glue is Using Amazon SimpleDB instead of a Relational Database  . Discusses a key design decision that required duplicating data in order to mimic RDBMS joins:   Given the trade off between potential inconsistencies and scalability, social services have to choose the latter.      Update 34  : Apparently Amazon pulled this article. I'm not sure what that means. Maybe time went backwards or something?   Amazon dramatically drops SimpleDB pricing to $0.25 per GB per month from $1.50 per GB  . This puts SimpleDB on par with   Google App Engine  . They also announced  a few new features:   a SQL-like SELECT API as well as a Batch Put operation to streamline uploading of multiple items or attributes  . One of the complaints against SimpleDB is that programmers end up writing too much code to do simple things. These features and a much cheaper price should help considerably. And you can store lots of data now. GAE is still capped.    Update 33  : Amazon announces</p><p>4 0.94379169 <a title="1118-lda-4" href="../high_scalability-2013/high_scalability-2013-02-04-Is_Provisioned_IOPS_Better%3F_Yes%2C_it_Delivers_More_Consistent_and_Higher_Performance_IO.html">1398 high scalability-2013-02-04-Is Provisioned IOPS Better? Yes, it Delivers More Consistent and Higher Performance IO</a></p>
<p>Introduction: Amazon created a whole new class of service with their  Provisioned IOPS  for RDS, EBS, and DynamoDB. The idea is simple. If you want more performance, you turn a dial up. If you want less, you turn a dial down. A beautifully simple model. You pay for the performance you want, which is different than their previous cloud model, where performance varied, but you paid only for what you used. 
 
The question: Do these higher priced services really work better?
 
 Rodrigo Campos  put this question to the test (only for EBS) by running a benchmark he describes in  IOMelt Provisioned IOPS EBS Benchmark Results - December 2012 .
 
The result?  Yes,   AWS Provisioned IOPS Volumes Really Deliver More Consistent and Higher Performance IO :
  

It is clear that the provisioned IOPS EBS volumes offer a huge performance upgrade when compared to the non-optimized EBS volumes, but as data has to be spread among more underlying disks or systems, it seems that the volume is increasingly more susceptibl</p><p>5 0.94174409 <a title="1118-lda-5" href="../high_scalability-2014/high_scalability-2014-04-04-Stuff_The_Internet_Says_On_Scalability_For_April_4th%2C_2014.html">1626 high scalability-2014-04-04-Stuff The Internet Says On Scalability For April 4th, 2014</a></p>
<p>Introduction: Hey, it's HighScalability time:
    The world ends not with a bang, but with  1 exaFLOP of bitcoin  whimpers.   
 Quotable Quotes:                               
 
  @EtienneRoy : Algorithm:  you must encode and leverage your ignorance, not only your knowledge #hadoopsummit - enthralling 
  Chris Brenny : A material is nothing without a process. While the constituent formulation imbues the final product with fundamental properties, the bridge between material and function has a dramatic effect on its perception and use. 
  @gallifreya n: Using AWS c1, m1, m2? @adrianco says don't. c3, m3, r3 are now better and cheaper. #cloudconnect #ccevent 
  @christianhern : Mobile banking in the UK: 1,800 transactions per MINUTE. A "seismic shift" that banks were unprepared for 
 
 
 
 While we are waiting for that epic article deeply comparing Google's Cloud with AWS, we have Adrian Cockcroft's highly hopped  slide comparing the two . Google: no enterprise customers, no reservation options, need m</p><p>6 0.94165111 <a title="1118-lda-6" href="../high_scalability-2011/high_scalability-2011-05-15-Building_a_Database_remote_availability_site.html">1041 high scalability-2011-05-15-Building a Database remote availability site</a></p>
<p>7 0.94080275 <a title="1118-lda-7" href="../high_scalability-2009/high_scalability-2009-10-06-Building_a_Unique_Data_Warehouse.html">716 high scalability-2009-10-06-Building a Unique Data Warehouse</a></p>
<p>8 0.94036394 <a title="1118-lda-8" href="../high_scalability-2012/high_scalability-2012-02-02-The_Data-Scope_Project_-_6PB_storage%2C_500GBytes-sec_sequential_IO%2C_20M_IOPS%2C_130TFlops.html">1186 high scalability-2012-02-02-The Data-Scope Project - 6PB storage, 500GBytes-sec sequential IO, 20M IOPS, 130TFlops</a></p>
<p>9 0.93918949 <a title="1118-lda-9" href="../high_scalability-2012/high_scalability-2012-08-10-Stuff_The_Internet_Says_On_Scalability_For_August_10%2C_2012.html">1302 high scalability-2012-08-10-Stuff The Internet Says On Scalability For August 10, 2012</a></p>
<p>10 0.93908566 <a title="1118-lda-10" href="../high_scalability-2013/high_scalability-2013-03-29-Stuff_The_Internet_Says_On_Scalability_For_March_29%2C_2013.html">1431 high scalability-2013-03-29-Stuff The Internet Says On Scalability For March 29, 2013</a></p>
<p>11 0.93865919 <a title="1118-lda-11" href="../high_scalability-2012/high_scalability-2012-07-04-Top_Features_of_a_Scalable_Database.html">1276 high scalability-2012-07-04-Top Features of a Scalable Database</a></p>
<p>12 0.93858194 <a title="1118-lda-12" href="../high_scalability-2014/high_scalability-2014-05-16-Stuff_The_Internet_Says_On_Scalability_For_May_16th%2C_2014.html">1649 high scalability-2014-05-16-Stuff The Internet Says On Scalability For May 16th, 2014</a></p>
<p>13 0.93780941 <a title="1118-lda-13" href="../high_scalability-2014/high_scalability-2014-02-21-Stuff_The_Internet_Says_On_Scalability_For_February_21st%2C_2014.html">1600 high scalability-2014-02-21-Stuff The Internet Says On Scalability For February 21st, 2014</a></p>
<p>14 0.93753225 <a title="1118-lda-14" href="../high_scalability-2011/high_scalability-2011-03-25-Did_the_Microsoft_Stack_Kill_MySpace%3F.html">1011 high scalability-2011-03-25-Did the Microsoft Stack Kill MySpace?</a></p>
<p>15 0.93732953 <a title="1118-lda-15" href="../high_scalability-2011/high_scalability-2011-11-29-DataSift_Architecture%3A_Realtime_Datamining_at_120%2C000_Tweets_Per_Second.html">1148 high scalability-2011-11-29-DataSift Architecture: Realtime Datamining at 120,000 Tweets Per Second</a></p>
<p>16 0.93726987 <a title="1118-lda-16" href="../high_scalability-2007/high_scalability-2007-08-22-Wikimedia_architecture.html">72 high scalability-2007-08-22-Wikimedia architecture</a></p>
<p>17 0.9370172 <a title="1118-lda-17" href="../high_scalability-2012/high_scalability-2012-03-14-The_Azure_Outage%3A_Time_Is_a_SPOF%2C_Leap_Day_Doubly_So.html">1209 high scalability-2012-03-14-The Azure Outage: Time Is a SPOF, Leap Day Doubly So</a></p>
<p>18 0.9369759 <a title="1118-lda-18" href="../high_scalability-2010/high_scalability-2010-07-13-DbShards_Part_Deux_-_The_Internals.html">857 high scalability-2010-07-13-DbShards Part Deux - The Internals</a></p>
<p>19 0.93601352 <a title="1118-lda-19" href="../high_scalability-2013/high_scalability-2013-06-21-Stuff_The_Internet_Says_On_Scalability_For_June_21%2C_2013.html">1479 high scalability-2013-06-21-Stuff The Internet Says On Scalability For June 21, 2013</a></p>
<p>20 0.935978 <a title="1118-lda-20" href="../high_scalability-2012/high_scalability-2012-01-24-The_State_of_NoSQL_in_2012.html">1180 high scalability-2012-01-24-The State of NoSQL in 2012</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
