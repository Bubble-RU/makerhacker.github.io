<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>636 high scalability-2009-06-23-Learn How to Exploit Multiple Cores for Better Performance and Scalability</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2009" href="../home/high_scalability-2009_home.html">high_scalability-2009</a> <a title="high_scalability-2009-636" href="#">high_scalability-2009-636</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>636 high scalability-2009-06-23-Learn How to Exploit Multiple Cores for Better Performance and Scalability</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2009-636-html" href="http://highscalability.com//blog/2009/6/23/learn-how-to-exploit-multiple-cores-for-better-performance-a.html">html</a></p><p>Introduction: InfoQueue has thisexcellent talk by Brian Goetzon the new features being added
to Java SE 7 that will allow programmers to fully exploit our massively multi-
processor future. While the talk is about Java it's really more general than
that and there's a lot to learn here for everyone.Brian starts with a short,
coherent, and compelling explanation of why programmers can't expect to be
saved by ever faster CPUs and why we must learn to exploit the strengths of
multiple core computers to make our software go faster.Some techniques for
exploiting multiple cores are given in an equally short, coherent, and
compelling explanation of why divide and conquer as the secret to multi-core
bliss, fork-join, how the Java approach differs from map-reduce, and lots of
other juicy topics.The multi-core "problem" is only going to get worse. Tilera
founder Anant Agarwalestimates by 2017embedded processors could have 4,096
cores, server CPUs might have 512 cores and desktop chips could use 128 cores.
Some</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cores', 0.313), ('divide', 0.235), ('faster', 0.168), ('pool', 0.162), ('grain', 0.155), ('parallelism', 0.153), ('chip', 0.137), ('thread', 0.132), ('thinner', 0.127), ('grained', 0.122), ('program', 0.114), ('multicore', 0.113), ('cpus', 0.112), ('parallel', 0.107), ('lunch', 0.106), ('number', 0.105), ('merge', 0.101), ('conquer', 0.101), ('threads', 0.098), ('fork', 0.098)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="636-tfidf-1" href="../high_scalability-2009/high_scalability-2009-06-23-Learn_How_to_Exploit_Multiple_Cores_for_Better_Performance_and_Scalability.html">636 high scalability-2009-06-23-Learn How to Exploit Multiple Cores for Better Performance and Scalability</a></p>
<p>Introduction: InfoQueue has thisexcellent talk by Brian Goetzon the new features being added
to Java SE 7 that will allow programmers to fully exploit our massively multi-
processor future. While the talk is about Java it's really more general than
that and there's a lot to learn here for everyone.Brian starts with a short,
coherent, and compelling explanation of why programmers can't expect to be
saved by ever faster CPUs and why we must learn to exploit the strengths of
multiple core computers to make our software go faster.Some techniques for
exploiting multiple cores are given in an equally short, coherent, and
compelling explanation of why divide and conquer as the secret to multi-core
bliss, fork-join, how the Java approach differs from map-reduce, and lots of
other juicy topics.The multi-core "problem" is only going to get worse. Tilera
founder Anant Agarwalestimates by 2017embedded processors could have 4,096
cores, server CPUs might have 512 cores and desktop chips could use 128 cores.
Some</p><p>2 0.207974 <a title="636-tfidf-2" href="../high_scalability-2008/high_scalability-2008-05-10-Hitting_300_SimbleDB_Requests_Per_Second_on_a_Small_EC2_Instance.html">317 high scalability-2008-05-10-Hitting 300 SimbleDB Requests Per Second on a Small EC2 Instance</a></p>
<p>Introduction: High Performance Multithreaded Access to Amazon SimpleDBis a great follow up
to the idea inHow SimpleDB Differs from a RDBMSthat more programming is the
price paid for performance in SimpleDB. It shows how much work and
infrastructure is required to batter better performance out of
SimpleDB.Remember, in SimpleDB you get keys to records from queries so if you
want to get all the fields for records you need to make separate requests.
Since SimpleDB isn't exactly a speed daemon the obvious strategy is to
parallelize. Even if a job takes a 100 msecs you can get a lot done in a
little time if you can execute enough jobs in parallel.Parallelization is the
approach taken by Haakon@AWS in his Java code example of how to get the most
out of SimpleDB. You can find the code atIndexing and Querying Amazon S3
Metadata with Amazon SimpleDB. We'll also consider how a back-end service
architecture built on Erlang may be a better fit with cloud computing.breakTwo
general mechanisms of parallelism are a</p><p>3 0.2035179 <a title="636-tfidf-3" href="../high_scalability-2009/high_scalability-2009-05-31-Parallel_Programming_for_real-world.html">612 high scalability-2009-05-31-Parallel Programming for real-world</a></p>
<p>Introduction: Multicore computers shift the burden of software performance from chip
designers and architects to software developers.What is the parallel Computing
? and what the different between Multi-Threading and Concurrency and
Parallelism ? and what is differences between task and data parallel ? and how
we can use it ?Fundamental article into Parallel Programming...</p><p>4 0.1983602 <a title="636-tfidf-4" href="../high_scalability-2012/high_scalability-2012-07-04-Top_Features_of_a_Scalable_Database.html">1276 high scalability-2012-07-04-Top Features of a Scalable Database</a></p>
<p>Introduction: This is a guest post by Douglas Wilson, EMEA Field Application Engineer at
Raima, based on insights from biulding theirRaima Database Manager.Scalability
and HardwareScalability is the ability to maintain performance as demands on
the system increase, by adding further resources. Normally those resources
will be in the form of hardware. Since processor speeds are no longer
increasing much, scaling up the hardware normally means adding extra
processors or cores, and more memory.Scalability and SoftwareHowever,
scalability requires software that can utilize the extra hardware effectively.
The software must be designed to allow parallel processing. In the context of
a database engine this means that the server component must be multi-threaded,
to allow the operating system to schedule parallel tasks on all the cores that
are available. Not only that, but the database engine must provide an
efficient way to break its workload into as many parallel tasks as there are
cores. So, for example,</p><p>5 0.18161356 <a title="636-tfidf-5" href="../high_scalability-2009/high_scalability-2009-03-12-Google_TechTalk%3A_Amdahl%27s_Law_in_the_Multicore_Era.html">534 high scalability-2009-03-12-Google TechTalk: Amdahl's Law in the Multicore Era</a></p>
<p>Introduction: Over the last several decades computer architects have been phenomenally
successful turning the transistor bounty provided by Moore's Law into chips
with ever increasing single-threaded performance. During many of these
successful years, however, many researchers paid scant attention to
multiprocessor work. Now as vendors turn to multicore chips, researchers are
reacting with more papers on multi-threaded systems. While this is good, we
are concerned that further work on single-thread performance will be
squashed.To help understand future high-level trade-offs, we develop a
corollary to Amdahl's Law for multicore chips [Hill & Marty, IEEE Computer
2008]. It models fixed chip resources for alternative designs that use
symmetric cores, asymmetric cores, or dynamic techniques that allow cores to
work together on sequential execution. Our results encourage multicore
designers to view performance of the entire chip rather than focus on core
efficiencies. Moreover, we observe that obtaining</p><p>6 0.17761095 <a title="636-tfidf-6" href="../high_scalability-2012/high_scalability-2012-03-06-Ask_For_Forgiveness_Programming_-_Or_How_We%27ll_Program_1000_Cores.html">1204 high scalability-2012-03-06-Ask For Forgiveness Programming - Or How We'll Program 1000 Cores</a></p>
<p>7 0.16749999 <a title="636-tfidf-7" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>8 0.15657867 <a title="636-tfidf-8" href="../high_scalability-2013/high_scalability-2013-03-18-Beyond_Threads_and_Callbacks_-_Application_Architecture_Pros_and_Cons.html">1425 high scalability-2013-03-18-Beyond Threads and Callbacks - Application Architecture Pros and Cons</a></p>
<p>9 0.15603702 <a title="636-tfidf-9" href="../high_scalability-2010/high_scalability-2010-12-03-GPU_vs_CPU_Smackdown_%3A_The_Rise_of_Throughput-Oriented_Architectures.html">953 high scalability-2010-12-03-GPU vs CPU Smackdown : The Rise of Throughput-Oriented Architectures</a></p>
<p>10 0.15467322 <a title="636-tfidf-10" href="../high_scalability-2009/high_scalability-2009-04-21-Thread_Pool_Engine_in_MS_CLR_4%2C_and_Work-Stealing_scheduling_algorithm.html">575 high scalability-2009-04-21-Thread Pool Engine in MS CLR 4, and Work-Stealing scheduling algorithm</a></p>
<p>11 0.15443255 <a title="636-tfidf-11" href="../high_scalability-2010/high_scalability-2010-02-01-What_Will_Kill_the_Cloud%3F.html">768 high scalability-2010-02-01-What Will Kill the Cloud?</a></p>
<p>12 0.15303691 <a title="636-tfidf-12" href="../high_scalability-2008/high_scalability-2008-12-03-Java_World_Interview_on_Scalability_and_Other_Java_Scalability_Secrets.html">459 high scalability-2008-12-03-Java World Interview on Scalability and Other Java Scalability Secrets</a></p>
<p>13 0.15263426 <a title="636-tfidf-13" href="../high_scalability-2012/high_scalability-2012-09-10-Russ%E2%80%99_10_Ingredient_Recipe_for_Making_1_Million_TPS_on_%245K_Hardware.html">1319 high scalability-2012-09-10-Russ’ 10 Ingredient Recipe for Making 1 Million TPS on $5K Hardware</a></p>
<p>14 0.14846334 <a title="636-tfidf-14" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>15 0.14829338 <a title="636-tfidf-15" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>16 0.14738236 <a title="636-tfidf-16" href="../high_scalability-2010/high_scalability-2010-02-15-The_Amazing_Collective_Compute_Power_of_the_Ambient_Cloud.html">778 high scalability-2010-02-15-The Amazing Collective Compute Power of the Ambient Cloud</a></p>
<p>17 0.13923918 <a title="636-tfidf-17" href="../high_scalability-2009/high_scalability-2009-05-27-The_Future_of_the_Parallelism_and_its_Challenges.html">608 high scalability-2009-05-27-The Future of the Parallelism and its Challenges</a></p>
<p>18 0.13878159 <a title="636-tfidf-18" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>19 0.13838528 <a title="636-tfidf-19" href="../high_scalability-2013/high_scalability-2013-10-23-Strategy%3A_Use_Linux_Taskset_to_Pin_Processes_or_Let_the_OS_Schedule_It%3F.html">1536 high scalability-2013-10-23-Strategy: Use Linux Taskset to Pin Processes or Let the OS Schedule It?</a></p>
<p>20 0.1350528 <a title="636-tfidf-20" href="../high_scalability-2013/high_scalability-2013-03-25-AppBackplane_-_A_Framework_for_Supporting_Multiple_Application_Architectures.html">1429 high scalability-2013-03-25-AppBackplane - A Framework for Supporting Multiple Application Architectures</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.223), (1, 0.124), (2, -0.006), (3, 0.055), (4, -0.036), (5, 0.047), (6, 0.058), (7, 0.126), (8, -0.163), (9, -0.014), (10, 0.005), (11, -0.012), (12, 0.068), (13, 0.026), (14, -0.004), (15, -0.058), (16, -0.006), (17, 0.009), (18, -0.026), (19, 0.083), (20, 0.001), (21, -0.083), (22, -0.069), (23, -0.014), (24, 0.028), (25, -0.045), (26, 0.006), (27, 0.009), (28, 0.159), (29, 0.041), (30, 0.036), (31, 0.089), (32, -0.026), (33, -0.029), (34, 0.029), (35, -0.081), (36, 0.058), (37, 0.023), (38, 0.037), (39, 0.033), (40, -0.017), (41, 0.057), (42, -0.09), (43, -0.048), (44, 0.011), (45, -0.006), (46, 0.049), (47, -0.046), (48, 0.032), (49, 0.033)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96407139 <a title="636-lsi-1" href="../high_scalability-2009/high_scalability-2009-06-23-Learn_How_to_Exploit_Multiple_Cores_for_Better_Performance_and_Scalability.html">636 high scalability-2009-06-23-Learn How to Exploit Multiple Cores for Better Performance and Scalability</a></p>
<p>Introduction: InfoQueue has thisexcellent talk by Brian Goetzon the new features being added
to Java SE 7 that will allow programmers to fully exploit our massively multi-
processor future. While the talk is about Java it's really more general than
that and there's a lot to learn here for everyone.Brian starts with a short,
coherent, and compelling explanation of why programmers can't expect to be
saved by ever faster CPUs and why we must learn to exploit the strengths of
multiple core computers to make our software go faster.Some techniques for
exploiting multiple cores are given in an equally short, coherent, and
compelling explanation of why divide and conquer as the secret to multi-core
bliss, fork-join, how the Java approach differs from map-reduce, and lots of
other juicy topics.The multi-core "problem" is only going to get worse. Tilera
founder Anant Agarwalestimates by 2017embedded processors could have 4,096
cores, server CPUs might have 512 cores and desktop chips could use 128 cores.
Some</p><p>2 0.78016955 <a title="636-lsi-2" href="../high_scalability-2012/high_scalability-2012-03-29-Strategy%3A_Exploit_Processor_Affinity_for_High_and_Predictable_Performance.html">1218 high scalability-2012-03-29-Strategy: Exploit Processor Affinity for High and Predictable Performance</a></p>
<p>Introduction: Martin Thompson wrote a really interestingarticleon the beneficial performance
impact of taking advantage of Processor Affinity:The interesting thing I've
observed is that the unpinned test will follow a step function of
unpredictable performance.  Across many runs I've seen different patterns but
all similar in this step function nature.  For the pinned tests I get
consistent throughput with no step pattern and always the greatest
throughput.The idea is by assigning a thread to a particular CPU that when a
thread is rescheduled to run on the same CPU, it can take advantage of the
"accumulated  state in the processor, including instructions and data in the
cache."  With multi-core chips the norm now, you may want to decide for
yourself how to assign work to cores and not let the OS do it for you. The
results are surprisingly strong.</p><p>3 0.7729454 <a title="636-lsi-3" href="../high_scalability-2013/high_scalability-2013-10-23-Strategy%3A_Use_Linux_Taskset_to_Pin_Processes_or_Let_the_OS_Schedule_It%3F.html">1536 high scalability-2013-10-23-Strategy: Use Linux Taskset to Pin Processes or Let the OS Schedule It?</a></p>
<p>Introduction: This question comes from Ulysses on aninteresting threadfrom the Mechanical
Sympathy news group, especially given how multiple processors are now the
norm:Ulysses:On an 8xCPU Linux instance,  is it at all advantageous to use the
Linux taskset command to pin an 8xJVM process set (co-ordinated as a
www.infinispan.org distributed cache/data grid) to a specific CPU affinity set
(i.e. pin JVM0 process to CPU 0, JVM1 process to CPU1, ...., JVM7process to
CPU 7) vs. just letting the Linux OS use its default mechanism for
provisioning the 8xJVM process set to the available CPUs?In effrort to seek an
optimal point (in the full event space), what are the conceptual trade-offs in
considering "searching" each permutation of provisioning an 8xJVM process set
to an 8xCPU set via taskset?Giventaskset is they key to the question, it would
help to have a definition:Used to set or retrieve the CPU affinity of a
running process given its PID or to launch a new COMMAND with a given CPU
affinity.  CPU affi</p><p>4 0.77034289 <a title="636-lsi-4" href="../high_scalability-2008/high_scalability-2008-05-10-Hitting_300_SimbleDB_Requests_Per_Second_on_a_Small_EC2_Instance.html">317 high scalability-2008-05-10-Hitting 300 SimbleDB Requests Per Second on a Small EC2 Instance</a></p>
<p>Introduction: High Performance Multithreaded Access to Amazon SimpleDBis a great follow up
to the idea inHow SimpleDB Differs from a RDBMSthat more programming is the
price paid for performance in SimpleDB. It shows how much work and
infrastructure is required to batter better performance out of
SimpleDB.Remember, in SimpleDB you get keys to records from queries so if you
want to get all the fields for records you need to make separate requests.
Since SimpleDB isn't exactly a speed daemon the obvious strategy is to
parallelize. Even if a job takes a 100 msecs you can get a lot done in a
little time if you can execute enough jobs in parallel.Parallelization is the
approach taken by Haakon@AWS in his Java code example of how to get the most
out of SimpleDB. You can find the code atIndexing and Querying Amazon S3
Metadata with Amazon SimpleDB. We'll also consider how a back-end service
architecture built on Erlang may be a better fit with cloud computing.breakTwo
general mechanisms of parallelism are a</p><p>5 0.76978821 <a title="636-lsi-5" href="../high_scalability-2010/high_scalability-2010-12-03-GPU_vs_CPU_Smackdown_%3A_The_Rise_of_Throughput-Oriented_Architectures.html">953 high scalability-2010-12-03-GPU vs CPU Smackdown : The Rise of Throughput-Oriented Architectures</a></p>
<p>Introduction: In some ways the original Amazon cloud, the one most of us still live in, was
like that really cool house that when you stepped inside and saw the oldgreen
shag carpetin the living room, you knew the house hadn't been updated in a
while. The network is a little slow, the processors are a bit dated, and
virtualization made the house just feel smaller. It has been difficult to run
high bandwidth or low latency workloads in the cloud. Bottlenecks everywhere.
Not a big deal for most applications, but for many high performance
applications (HPC) it was a killer.In a typical house you might just do a
remodel. Upgrade a few rooms. Swap out builder quality appliances with
gleaming stainless steel monsters. But Amazon has a big lot, instead of
remodeling they simply keep adding on entire new wings, kind of like the
Winchester Mystery Houseof computing.The first new wing added was aCPU based
HPC system featuring blazingly fastNehalem chips, virtualization replaced by a
close to metal Hardware Vi</p><p>6 0.75741279 <a title="636-lsi-6" href="../high_scalability-2012/high_scalability-2012-09-10-Russ%E2%80%99_10_Ingredient_Recipe_for_Making_1_Million_TPS_on_%245K_Hardware.html">1319 high scalability-2012-09-10-Russ’ 10 Ingredient Recipe for Making 1 Million TPS on $5K Hardware</a></p>
<p>7 0.7501868 <a title="636-lsi-7" href="../high_scalability-2009/high_scalability-2009-04-21-Thread_Pool_Engine_in_MS_CLR_4%2C_and_Work-Stealing_scheduling_algorithm.html">575 high scalability-2009-04-21-Thread Pool Engine in MS CLR 4, and Work-Stealing scheduling algorithm</a></p>
<p>8 0.75011641 <a title="636-lsi-8" href="../high_scalability-2013/high_scalability-2013-05-08-Typesafe_Interview%3A_Scala_%2B_Akka_is_an_IaaS_for_Your_Process_Architecture.html">1454 high scalability-2013-05-08-Typesafe Interview: Scala + Akka is an IaaS for Your Process Architecture</a></p>
<p>9 0.74936086 <a title="636-lsi-9" href="../high_scalability-2009/high_scalability-2009-11-01-Squeeze_more_performance_from_Parallelism.html">735 high scalability-2009-11-01-Squeeze more performance from Parallelism</a></p>
<p>10 0.74016589 <a title="636-lsi-10" href="../high_scalability-2009/high_scalability-2009-04-26-Map-Reduce_for_Machine_Learning_on_Multicore.html">581 high scalability-2009-04-26-Map-Reduce for Machine Learning on Multicore</a></p>
<p>11 0.73526782 <a title="636-lsi-11" href="../high_scalability-2012/high_scalability-2012-03-06-Ask_For_Forgiveness_Programming_-_Or_How_We%27ll_Program_1000_Cores.html">1204 high scalability-2012-03-06-Ask For Forgiveness Programming - Or How We'll Program 1000 Cores</a></p>
<p>12 0.73098624 <a title="636-lsi-12" href="../high_scalability-2009/high_scalability-2009-03-12-Google_TechTalk%3A_Amdahl%27s_Law_in_the_Multicore_Era.html">534 high scalability-2009-03-12-Google TechTalk: Amdahl's Law in the Multicore Era</a></p>
<p>13 0.72170788 <a title="636-lsi-13" href="../high_scalability-2009/high_scalability-2009-02-01-More_Chips_Means_Less_Salsa.html">505 high scalability-2009-02-01-More Chips Means Less Salsa</a></p>
<p>14 0.71976286 <a title="636-lsi-14" href="../high_scalability-2012/high_scalability-2012-05-02-12_Ways_to_Increase_Throughput_by_32X_and_Reduce_Latency_by__20X.html">1237 high scalability-2012-05-02-12 Ways to Increase Throughput by 32X and Reduce Latency by  20X</a></p>
<p>15 0.71651268 <a title="636-lsi-15" href="../high_scalability-2010/high_scalability-2010-05-12-The_Rise_of_the_Virtual_Cellular_Machines.html">826 high scalability-2010-05-12-The Rise of the Virtual Cellular Machines</a></p>
<p>16 0.71032172 <a title="636-lsi-16" href="../high_scalability-2013/high_scalability-2013-03-18-Beyond_Threads_and_Callbacks_-_Application_Architecture_Pros_and_Cons.html">1425 high scalability-2013-03-18-Beyond Threads and Callbacks - Application Architecture Pros and Cons</a></p>
<p>17 0.69744909 <a title="636-lsi-17" href="../high_scalability-2014/high_scalability-2014-05-01-Paper%3A_Can_Programming_Be_Liberated_From_The_Von_Neumann_Style%3F_.html">1641 high scalability-2014-05-01-Paper: Can Programming Be Liberated From The Von Neumann Style? </a></p>
<p>18 0.69571418 <a title="636-lsi-18" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>19 0.68144077 <a title="636-lsi-19" href="../high_scalability-2014/high_scalability-2014-02-05-Little%E2%80%99s_Law%2C_Scalability_and_Fault_Tolerance%3A_The_OS_is_your_bottleneck._What_you_can_do%3F.html">1591 high scalability-2014-02-05-Little’s Law, Scalability and Fault Tolerance: The OS is your bottleneck. What you can do?</a></p>
<p>20 0.67427838 <a title="636-lsi-20" href="../high_scalability-2013/high_scalability-2013-10-31-Paper%3A_Everything_You_Always_Wanted_to_Know_About_Synchronization_but_Were_Afraid_to_Ask.html">1541 high scalability-2013-10-31-Paper: Everything You Always Wanted to Know About Synchronization but Were Afraid to Ask</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.157), (2, 0.245), (5, 0.014), (10, 0.061), (30, 0.018), (40, 0.029), (44, 0.103), (61, 0.043), (77, 0.039), (79, 0.117), (85, 0.051), (94, 0.037)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.95780373 <a title="636-lda-1" href="../high_scalability-2012/high_scalability-2012-01-19-Is_it_time_to_get_rid_of_the_Linux_OS_model_in_the_cloud%3F.html">1177 high scalability-2012-01-19-Is it time to get rid of the Linux OS model in the cloud?</a></p>
<p>Introduction: You program in a dynamic language, that runs on a JVM, that runs on a OS
designed40 years ago for a completely different purpose, that runs on
virtualized hardware. Does this make sense? We've talked about this idea
before inMachine VM + Cloud API - Rewriting The Cloud From Scratch, where the
vision is to treatcloud virtual hardware as a compiler target, and converting
high-level language source code directly into kernels that run on it.As new
technologies evolve the friction created by our old tool chains and
architecture models becomes ever more obvious. Take, for example, what
ateamatUCSD is releasing: aphase-change memory prototype  -a solid state
storage device that provides performance thousands of times faster than a
conventional hard drive and up to seven times faster than current state-of-
the-art solid-state drives (SSDs).However, PCM has access latencies several
times slower than DRAM.This technology has obvious mind blowing implications,
but an interesting not so obvious im</p><p>same-blog 2 0.95533043 <a title="636-lda-2" href="../high_scalability-2009/high_scalability-2009-06-23-Learn_How_to_Exploit_Multiple_Cores_for_Better_Performance_and_Scalability.html">636 high scalability-2009-06-23-Learn How to Exploit Multiple Cores for Better Performance and Scalability</a></p>
<p>Introduction: InfoQueue has thisexcellent talk by Brian Goetzon the new features being added
to Java SE 7 that will allow programmers to fully exploit our massively multi-
processor future. While the talk is about Java it's really more general than
that and there's a lot to learn here for everyone.Brian starts with a short,
coherent, and compelling explanation of why programmers can't expect to be
saved by ever faster CPUs and why we must learn to exploit the strengths of
multiple core computers to make our software go faster.Some techniques for
exploiting multiple cores are given in an equally short, coherent, and
compelling explanation of why divide and conquer as the secret to multi-core
bliss, fork-join, how the Java approach differs from map-reduce, and lots of
other juicy topics.The multi-core "problem" is only going to get worse. Tilera
founder Anant Agarwalestimates by 2017embedded processors could have 4,096
cores, server CPUs might have 512 cores and desktop chips could use 128 cores.
Some</p><p>3 0.95030963 <a title="636-lda-3" href="../high_scalability-2008/high_scalability-2008-08-17-Many_updates_against_MySQL.html">366 high scalability-2008-08-17-Many updates against MySQL</a></p>
<p>Introduction: Hello! My first post here, so be patient please. I am developing site where I
have lots of static content. But on many pages I have query to update count of
views. I would say this is may cause lots of problems and was interested in
another solution like storing these counts somewhere else. As my knowledge is
bit limited in this way, I am asking you. I can say I understand PHP(OOP ofc)
and MySQL. Nowadays I am getting into servers.Other question I have is:I read
about making lots of things static.(in Flickr Architecture) and am interested
how they do static sites? Lets say they make photo page static? And rebuild
when tagg or comment is added? I am bit interested in it as I want to learn
Smarty better(newbie) and serving content.Moreover, how about PHP? I have read
many books about PHP theoretically but would love to see some RL example of
using objects and exceptions(mainly this as I don't completely understand it)
to learn some good programming habits. So if you can help me with some</p><p>4 0.94809467 <a title="636-lda-4" href="../high_scalability-2010/high_scalability-2010-10-26-Marrying_memcached_and_NoSQL.html">927 high scalability-2010-10-26-Marrying memcached and NoSQL</a></p>
<p>Introduction: Memcached is one of the most common In-Memory cache implementation.  It was
originally developed by Danga Interactive for LiveJournal, but is now used by
many other sites as a side cache to speed up read mostly operations. It gained
popularity in the non-Java world, too, especially since it's a language-
neutral side cache for which few alternatives existed.  As a side-cache,
Memcache clients relies on the database as the system of record, The database
is still used for write,update and complex query operations.  Since the
memcached specification includes no query operations, memcached is not a
database alternative, unlike most of the NoSQL offerings. It also exclude
memcache from being a real solution for write scalability. As a result of that
many of the heavy sites started to move away from Memcache and replace it with
other NoSQL alternatives as noted in a recent highscalability post MySQL And
Memcached: End Of An Era?The transition away from memcached to NoSQL could
represent a la</p><p>5 0.94750053 <a title="636-lda-5" href="../high_scalability-2009/high_scalability-2009-07-21-Paper%3A_Parallelizing_the_Web_Browser.html">660 high scalability-2009-07-21-Paper: Parallelizing the Web Browser</a></p>
<p>Introduction: There have been reports thatsoftware engineering is dead. Maybe, like the
future, software engineering is simply not evenly distributed? When you read
this paper I think you'll agree there is some real engineering going on, it's
just that most of the things we need to build do not require real engineering.
Much like my old childhood tree fort could be patched together and was "good
enough." This brings to mind the old joke: If a software tree falls in the
woods would anyone hear it fall? Only if it tweeted on the way down...What
this paper really showed me is we need not only to change programming
practices and constructs, but we also need to design solutions that allow for
deep parallelism to begin with. Grafting parallelism on later is difficult.
Parallel execution requires knowing precisely how components are dependent on
each other and that level of precision tends to go far beyond the human
attention span.In particular this paper deals with how to parallelize the
browser on cell p</p><p>6 0.94543153 <a title="636-lda-6" href="../high_scalability-2014/high_scalability-2014-02-26-The_WhatsApp_Architecture_Facebook_Bought_For_%2419_Billion.html">1602 high scalability-2014-02-26-The WhatsApp Architecture Facebook Bought For $19 Billion</a></p>
<p>7 0.94291472 <a title="636-lda-7" href="../high_scalability-2010/high_scalability-2010-04-29-Product%3A_SciDB_-_A_Science-Oriented_DBMS_at_100_Petabytes.html">817 high scalability-2010-04-29-Product: SciDB - A Science-Oriented DBMS at 100 Petabytes</a></p>
<p>8 0.94206011 <a title="636-lda-8" href="../high_scalability-2013/high_scalability-2013-10-25-Stuff_The_Internet_Says_On_Scalability_For_October_25th%2C_2013.html">1537 high scalability-2013-10-25-Stuff The Internet Says On Scalability For October 25th, 2013</a></p>
<p>9 0.94203347 <a title="636-lda-9" href="../high_scalability-2009/high_scalability-2009-08-07-The_Canonical_Cloud_Architecture_.html">674 high scalability-2009-08-07-The Canonical Cloud Architecture </a></p>
<p>10 0.94189221 <a title="636-lda-10" href="../high_scalability-2009/high_scalability-2009-02-18-Numbers_Everyone_Should_Know.html">514 high scalability-2009-02-18-Numbers Everyone Should Know</a></p>
<p>11 0.94010544 <a title="636-lda-11" href="../high_scalability-2008/high_scalability-2008-03-12-YouTube_Architecture.html">274 high scalability-2008-03-12-YouTube Architecture</a></p>
<p>12 0.93969971 <a title="636-lda-12" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>13 0.93954277 <a title="636-lda-13" href="../high_scalability-2009/high_scalability-2009-08-05-Stack_Overflow_Architecture.html">671 high scalability-2009-08-05-Stack Overflow Architecture</a></p>
<p>14 0.9394837 <a title="636-lda-14" href="../high_scalability-2010/high_scalability-2010-06-23-Product%3A_dbShards_-_Share_Nothing._Shard_Everything..html">847 high scalability-2010-06-23-Product: dbShards - Share Nothing. Shard Everything.</a></p>
<p>15 0.93936431 <a title="636-lda-15" href="../high_scalability-2014/high_scalability-2014-05-06-The_Quest_for_Database_Scale%3A_the_1_M_TPS_challenge_-_Three_Design_Points_and_Five_common_Bottlenecks_to_avoid.html">1643 high scalability-2014-05-06-The Quest for Database Scale: the 1 M TPS challenge - Three Design Points and Five common Bottlenecks to avoid</a></p>
<p>16 0.93929207 <a title="636-lda-16" href="../high_scalability-2013/high_scalability-2013-04-26-Stuff_The_Internet_Says_On_Scalability_For_April_26%2C_2013.html">1447 high scalability-2013-04-26-Stuff The Internet Says On Scalability For April 26, 2013</a></p>
<p>17 0.93870759 <a title="636-lda-17" href="../high_scalability-2012/high_scalability-2012-10-26-Stuff_The_Internet_Says_On_Scalability_For_October_26%2C_2012.html">1348 high scalability-2012-10-26-Stuff The Internet Says On Scalability For October 26, 2012</a></p>
<p>18 0.93858731 <a title="636-lda-18" href="../high_scalability-2010/high_scalability-2010-07-13-DbShards_Part_Deux_-_The_Internals.html">857 high scalability-2010-07-13-DbShards Part Deux - The Internals</a></p>
<p>19 0.93844312 <a title="636-lda-19" href="../high_scalability-2012/high_scalability-2012-01-09-The_Etsy_Saga%3A_From_Silos_to_Happy_to_Billions_of_Pageviews_a_Month.html">1171 high scalability-2012-01-09-The Etsy Saga: From Silos to Happy to Billions of Pageviews a Month</a></p>
<p>20 0.93836236 <a title="636-lda-20" href="../high_scalability-2008/high_scalability-2008-09-03-Some_Facebook_Secrets_to_Better_Operations.html">378 high scalability-2008-09-03-Some Facebook Secrets to Better Operations</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
