<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>710 high scalability-2009-09-20-PaxosLease: Diskless Paxos for Leases</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2009" href="../home/high_scalability-2009_home.html">high_scalability-2009</a> <a title="high_scalability-2009-710" href="#">high_scalability-2009-710</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>710 high scalability-2009-09-20-PaxosLease: Diskless Paxos for Leases</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2009-710-html" href="http://highscalability.com//blog/2009/9/20/paxoslease-diskless-paxos-for-leases.html">html</a></p><p>Introduction: PaxosLeaseis a distributed algorithm for lease negotiation. It is based on
Paxos, but does not require disk writes or clock synchrony. PaxosLease is used
for master lease negotation in the open-source Keyspace replicated key-value
store.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 It is based on Paxos, but does not require disk writes or clock synchrony. [sent-2, score-0.791]
</p><p>2 PaxosLease is used for master lease negotation in the open-source Keyspace replicated key-value store. [sent-3, score-1.237]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lease', 0.79), ('paxos', 0.3), ('clock', 0.285), ('algorithm', 0.203), ('replicated', 0.202), ('master', 0.176), ('require', 0.153), ('writes', 0.147), ('disk', 0.125), ('store', 0.116), ('based', 0.081), ('distributed', 0.074), ('used', 0.069)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="710-tfidf-1" href="../high_scalability-2009/high_scalability-2009-09-20-PaxosLease%3A_Diskless_Paxos_for_Leases.html">710 high scalability-2009-09-20-PaxosLease: Diskless Paxos for Leases</a></p>
<p>Introduction: PaxosLeaseis a distributed algorithm for lease negotiation. It is based on
Paxos, but does not require disk writes or clock synchrony. PaxosLease is used
for master lease negotation in the open-source Keyspace replicated key-value
store.</p><p>2 0.1733937 <a title="710-tfidf-2" href="../high_scalability-2008/high_scalability-2008-07-26-Google%27s_Paxos_Made_Live_%E2%80%93_An_Engineering_Perspective.html">357 high scalability-2008-07-26-Google's Paxos Made Live – An Engineering Perspective</a></p>
<p>Introduction: This is an unusually well written anduseful paper. It talks in detail about
experiences implementing a complex project, something we don't see very often.
They shockingly even admit that creating a working implementation of Paxos was
more difficult than just translating the pseudo code. Imagine that,
programmers aren't merely typists! I particularly like the explanation of the
Paxos algorithm and why anyone would care about it, working with disk
corruption, using leases to support simultaneous reads, using epoch numbers to
indicate a new master election, using snapshots to prevent unbounded logs,
using MultiOp to implement database transactions, how they tested the system,
and their openness with the various problems they had. A lot to learn
here.From the paper:We describe our experience building a fault-tolerant data-
base using the Paxos consensus algorithm. Despite the existing literature in
the field, building such a database proved to be non-trivial. We describe
selected algorithm</p><p>3 0.13309243 <a title="710-tfidf-3" href="../high_scalability-2012/high_scalability-2012-05-10-Paper%3A_Paxos_Made_Moderately_Complex.html">1243 high scalability-2012-05-10-Paper: Paxos Made Moderately Complex</a></p>
<p>Introduction: If you are a normal human being and find thePaxos protocolconfusing, then this
paper, Paxos Made Moderately Complex, is a great find. Robbert van Renesse
from Cornell University has written a clear and well written paper with
excellent explanations.The Abstract:For anybody who has ever tried to
implement it, Paxos is by no means a simple protocol, even though it is based
on relatively simple invariants. This paper provides imperative pseudo-code
for the full Paxos (or Multi-Paxos) protocol without shying away from
discussing various implementation details. The initial description avoids
optimizations that complicate comprehension. Next we discuss liveness, and
list various optimizations that make the protocol practical.Related
ArticlesPaxos on HighScalability.com</p><p>4 0.11849879 <a title="710-tfidf-4" href="../high_scalability-2012/high_scalability-2012-12-18-Georeplication%3A_When_Bad_Things_Happen_to_Good_Systems.html">1374 high scalability-2012-12-18-Georeplication: When Bad Things Happen to Good Systems</a></p>
<p>Introduction: Georeplication is one of the standard techniques for dealing when bad things--
failure and latency--happen to good systems. The problem is always: how do you
do that? Murat Demirbas, Associate Professor at SUNY Buffalo, has a couple of
really good posts that can help:MDCC: Multi-Data Center Consistency andMaking
Geo-Replicated Systems Fast as Possible, Consistent when Necessary. In MDCC:
Multi-Data Center Consistency Murat discusses a paper that says synchronous
wide-area replication can be feasible. There's a quick and clear explanation
of Paxos and various optimizations that is worth the price of admission. We
find that strong consistency doesn't have to be lost across a WAN:The good
thing about using Paxos over the WAN is you /almost/ get the full CAP  (all
three properties: consistency, availability, and partition-freedom). As we
discussed earlier (Paxos taught), Paxos is CP, that is, in the presence of a
partition, Paxos keeps consistency over availability. But, Paxos can still
pr</p><p>5 0.086175628 <a title="710-tfidf-5" href="../high_scalability-2012/high_scalability-2012-08-16-Paper%3A_A_Provably_Correct_Scalable_Concurrent_Skip_List.html">1305 high scalability-2012-08-16-Paper: A Provably Correct Scalable Concurrent Skip List</a></p>
<p>Introduction: InMemSQL Architecture we learned one of the core strategies MemSQL uses to
achieve their need for speed is lock-free skip lists. Skip lists are used to
efficiently handle range queries. Making the skip-lists lock-free helps
eliminate contention and make writes fast. If this all sounds a little pie-in-
the-sky then here's a very good paper on the subject that might help make it
clearer: A Provably Correct Scalable Concurrent Skip List.From the abstract:We
propose a new concurrent skip list algorithm distinguished by a combination of
simplicity and scalability. The algorithm employs optimistic synchronization,
searching without acquiring locks, followed by short lock-based validation
before adding or removing nodes. It also logically removes an item before
physically unlinking it. Unlike some other concurrent skip list algorithms,
this algorithm preserves the skiplist properties at all times, which
facilitates reasoning about its correctness. Experimental evidence shows that
this algorit</p><p>6 0.086119659 <a title="710-tfidf-6" href="../high_scalability-2009/high_scalability-2009-03-10-Paper%3A_Consensus_Protocols%3A_Paxos___.html">529 high scalability-2009-03-10-Paper: Consensus Protocols: Paxos   </a></p>
<p>7 0.084740289 <a title="710-tfidf-7" href="../high_scalability-2009/high_scalability-2009-08-24-How_Google_Serves_Data_from_Multiple_Datacenters.html">687 high scalability-2009-08-24-How Google Serves Data from Multiple Datacenters</a></p>
<p>8 0.08282648 <a title="710-tfidf-8" href="../high_scalability-2007/high_scalability-2007-12-10-1_Master%2C_N_Slaves.html">178 high scalability-2007-12-10-1 Master, N Slaves</a></p>
<p>9 0.080181353 <a title="710-tfidf-9" href="../high_scalability-2012/high_scalability-2012-10-22-Spanner_-_It%27s_About_Programmers_Building_Apps_Using_SQL_Semantics_at_NoSQL_Scale.html">1345 high scalability-2012-10-22-Spanner - It's About Programmers Building Apps Using SQL Semantics at NoSQL Scale</a></p>
<p>10 0.074257299 <a title="710-tfidf-10" href="../high_scalability-2013/high_scalability-2013-05-16-Paper%3A_Warp%3A_Multi-Key_Transactions_for_Key-Value_Stores.html">1459 high scalability-2013-05-16-Paper: Warp: Multi-Key Transactions for Key-Value Stores</a></p>
<p>11 0.073324963 <a title="710-tfidf-11" href="../high_scalability-2013/high_scalability-2013-05-03-Stuff_The_Internet_Says_On_Scalability_For_May_3%2C_2013.html">1451 high scalability-2013-05-03-Stuff The Internet Says On Scalability For May 3, 2013</a></p>
<p>12 0.067402676 <a title="710-tfidf-12" href="../high_scalability-2013/high_scalability-2013-10-08-F1_and_Spanner_Holistically_Compared.html">1529 high scalability-2013-10-08-F1 and Spanner Holistically Compared</a></p>
<p>13 0.067289934 <a title="710-tfidf-13" href="../high_scalability-2013/high_scalability-2013-06-13-Busting_4_Modern_Hardware_Myths_-_Are_Memory%2C_HDDs%2C_and_SSDs_Really_Random_Access%3F.html">1475 high scalability-2013-06-13-Busting 4 Modern Hardware Myths - Are Memory, HDDs, and SSDs Really Random Access?</a></p>
<p>14 0.066502549 <a title="710-tfidf-14" href="../high_scalability-2009/high_scalability-2009-04-21-Thread_Pool_Engine_in_MS_CLR_4%2C_and_Work-Stealing_scheduling_algorithm.html">575 high scalability-2009-04-21-Thread Pool Engine in MS CLR 4, and Work-Stealing scheduling algorithm</a></p>
<p>15 0.05963422 <a title="710-tfidf-15" href="../high_scalability-2010/high_scalability-2010-07-07-Strategy%3A_Recompute_Instead_of_Remember_Big_Data.html">852 high scalability-2010-07-07-Strategy: Recompute Instead of Remember Big Data</a></p>
<p>16 0.058338888 <a title="710-tfidf-16" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>17 0.057576425 <a title="710-tfidf-17" href="../high_scalability-2009/high_scalability-2009-08-05-Anti-RDBMS%3A_A_list_of_distributed_key-value_stores.html">670 high scalability-2009-08-05-Anti-RDBMS: A list of distributed key-value stores</a></p>
<p>18 0.056950286 <a title="710-tfidf-18" href="../high_scalability-2007/high_scalability-2007-11-21-n-phase_commit_for_FS_writes%2C_reads_stay_local.html">163 high scalability-2007-11-21-n-phase commit for FS writes, reads stay local</a></p>
<p>19 0.056823421 <a title="710-tfidf-19" href="../high_scalability-2009/high_scalability-2009-08-06-An_Unorthodox_Approach_to_Database_Design_%3A_The_Coming_of_the_Shard.html">672 high scalability-2009-08-06-An Unorthodox Approach to Database Design : The Coming of the Shard</a></p>
<p>20 0.056811489 <a title="710-tfidf-20" href="../high_scalability-2007/high_scalability-2007-12-19-How_can_I_learn_to_scale_my_project%3F.html">188 high scalability-2007-12-19-How can I learn to scale my project?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.039), (1, 0.044), (2, -0.012), (3, 0.01), (4, 0.005), (5, 0.064), (6, 0.02), (7, -0.015), (8, -0.031), (9, 0.002), (10, 0.007), (11, -0.014), (12, -0.037), (13, 0.009), (14, 0.034), (15, 0.031), (16, -0.027), (17, -0.002), (18, -0.01), (19, -0.026), (20, 0.029), (21, 0.023), (22, -0.034), (23, 0.028), (24, -0.056), (25, -0.009), (26, 0.039), (27, 0.013), (28, -0.011), (29, -0.022), (30, -0.007), (31, -0.041), (32, -0.053), (33, -0.011), (34, -0.007), (35, -0.057), (36, 0.021), (37, -0.029), (38, 0.017), (39, -0.027), (40, -0.062), (41, 0.006), (42, -0.021), (43, 0.027), (44, 0.053), (45, -0.005), (46, -0.01), (47, -0.003), (48, 0.024), (49, 0.003)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9623282 <a title="710-lsi-1" href="../high_scalability-2009/high_scalability-2009-09-20-PaxosLease%3A_Diskless_Paxos_for_Leases.html">710 high scalability-2009-09-20-PaxosLease: Diskless Paxos for Leases</a></p>
<p>Introduction: PaxosLeaseis a distributed algorithm for lease negotiation. It is based on
Paxos, but does not require disk writes or clock synchrony. PaxosLease is used
for master lease negotation in the open-source Keyspace replicated key-value
store.</p><p>2 0.60223228 <a title="710-lsi-2" href="../high_scalability-2014/high_scalability-2014-03-12-Paper%3A_Scalable_Eventually_Consistent_Counters_over_Unreliable_Networks.html">1611 high scalability-2014-03-12-Paper: Scalable Eventually Consistent Counters over Unreliable Networks</a></p>
<p>Introduction: Counting at scale in a distributed environment issurprisingly hard. And it's a
subject we've covered before in various ways:Big Data Counting: How to count a
billion distinct objects using only 1.5KB of Memory,How to update video views
count effectively?,Numbers Everyone Should Know (sharded
counters).Kellabyte(which is an excellent blog) inScalable Eventually
Consistent Counterstalks about how the Cassandra counter implementation scores
well on the scalability and high availability front, but in so doing has "over
and under counting problem in partitioned environments."Which is often fine.
But if you want more accuracy there's a PN-counter, which is aCRDT (convergent
replicated data type)where "all the changes made to a counter on each node
rather than storing and modifying a single value so that you can merge all the
values into the proper final value. Of course the trade-off here is additional
storage and processing but there are ways to optimize this."And there's a
paper you can co</p><p>3 0.59559786 <a title="710-lsi-3" href="../high_scalability-2011/high_scalability-2011-11-23-Paper%3A_Don%E2%80%99t_Settle_for_Eventual%3A_Scalable_Causal_Consistency_for_Wide-Area_Storage_with_COPS.html">1146 high scalability-2011-11-23-Paper: Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</a></p>
<p>Introduction: Teams fromPrincetonand CMU areworking togetherto solve one of the most
difficult problems in the repertoire: scalable geo-distributed data stores.
Major companies like Google and Facebook have been working on multiple
datacenter database functionality for some time, but there's still a general
lack of available systems that work for complex data scenarios.The ideas in
this paper--Don't Settle for Eventual: Scalable Causal Consistency for Wide-
Area Storage with COPS--are different. It's not another eventually consistent
system, or a traditional transaction oriented system, or a replication based
system, or a system that punts on the issue. It's something new, a causally
consistent system that achievesALPSsystem properties. Move over CAP, NoSQL,
etc, we have another acronym: ALPS - Available (operations always complete
successfully), Low-latency (operations complete quickly (single digit
milliseconds)), Partition-tolerant (operates with a partition), and Scalable
(just add more servers</p><p>4 0.58612889 <a title="710-lsi-4" href="../high_scalability-2009/high_scalability-2009-09-16-Paper%3A_A_practical_scalable_distributed_B-tree.html">705 high scalability-2009-09-16-Paper: A practical scalable distributed B-tree</a></p>
<p>Introduction: We've seen a lot ofNoSQLaction lately built around distributed hash tables.
Btrees are getting jealous. Btrees, once the king of the database world, want
their throne back.Paul Buchheitsurfaced a paper:A practical scalable
distributed B-treeby Marcos K. Aguilera and Wojciech Golab, that might help
spark a revolution.From the Abstract:We propose a new algorithm for a
practical, fault tolerant, and scalable B-tree distributed over a set of
servers. Our algorithm supports practical features not present in prior work:
transactions that allow atomic execution of multiple operations over multiple
B-trees, online migration of B-tree nodes between servers, and dynamic
addition and removal of servers. Moreover, our algorithm is conceptually
simple: we use transactions to manipulate B-tree nodes so that clients need
not use complicated concurrency and locking protocols used in prior work. To
execute these transactions quickly, we rely on three techniques: (1) We use
optimistic concurrency contro</p><p>5 0.57739305 <a title="710-lsi-5" href="../high_scalability-2013/high_scalability-2013-05-23-Paper%3A_Calvin%3A_Fast_Distributed_Transactions_for_Partitioned_Database_Systems.html">1463 high scalability-2013-05-23-Paper: Calvin: Fast Distributed Transactions for Partitioned Database Systems</a></p>
<p>Introduction: Distributed transactions are costly because they useagreement protocols.
Calvin says, surprisingly, that using a deterministic database allows you to
avoid the use of agreement protocols. The approach is to use a deterministic
transaction layer that does all the hard work before acquiring locks and the
beginning of transaction execution.Overview:Many distributed storage systems
achieve high data access throughput via partitioning and replication, each
system with its own advantages and tradeoffs. In order to achieve high
scalability, however, today's systems generally reduce transactional support,
disallowing single transactions from spanning multiple partitions. Calvin is a
practical transaction scheduling and data replication layer that uses a
deterministic ordering guarantee to signiďŹ cantly reduce the normally
prohibitive contention costs associated with distributed transactions. Unlike
previous deterministic database system prototypes, Calvin supports disk-based
storage, scales nea</p><p>6 0.57609797 <a title="710-lsi-6" href="../high_scalability-2009/high_scalability-2009-03-10-Paper%3A_Consensus_Protocols%3A_Paxos___.html">529 high scalability-2009-03-10-Paper: Consensus Protocols: Paxos   </a></p>
<p>7 0.56327951 <a title="710-lsi-7" href="../high_scalability-2012/high_scalability-2012-05-10-Paper%3A_Paxos_Made_Moderately_Complex.html">1243 high scalability-2012-05-10-Paper: Paxos Made Moderately Complex</a></p>
<p>8 0.55744195 <a title="710-lsi-8" href="../high_scalability-2009/high_scalability-2009-08-24-How_Google_Serves_Data_from_Multiple_Datacenters.html">687 high scalability-2009-08-24-How Google Serves Data from Multiple Datacenters</a></p>
<p>9 0.55701393 <a title="710-lsi-9" href="../high_scalability-2014/high_scalability-2014-04-10-Paper%3A_Scalable_Atomic_Visibility_with_RAMP_Transactions_-_Scale_Linearly_to_100_Servers.html">1629 high scalability-2014-04-10-Paper: Scalable Atomic Visibility with RAMP Transactions - Scale Linearly to 100 Servers</a></p>
<p>10 0.5559724 <a title="710-lsi-10" href="../high_scalability-2012/high_scalability-2012-06-27-Paper%3A_Logic_and_Lattices_for_Distributed_Programming.html">1273 high scalability-2012-06-27-Paper: Logic and Lattices for Distributed Programming</a></p>
<p>11 0.55041391 <a title="710-lsi-11" href="../high_scalability-2008/high_scalability-2008-07-26-Google%27s_Paxos_Made_Live_%E2%80%93_An_Engineering_Perspective.html">357 high scalability-2008-07-26-Google's Paxos Made Live – An Engineering Perspective</a></p>
<p>12 0.54817456 <a title="710-lsi-12" href="../high_scalability-2010/high_scalability-2010-12-23-Paper%3A_CRDTs%3A_Consistency_without_concurrency_control.html">963 high scalability-2010-12-23-Paper: CRDTs: Consistency without concurrency control</a></p>
<p>13 0.54701948 <a title="710-lsi-13" href="../high_scalability-2009/high_scalability-2009-02-09-Paper%3A_Consensus_Protocols%3A_Two-Phase_Commit__.html">510 high scalability-2009-02-09-Paper: Consensus Protocols: Two-Phase Commit  </a></p>
<p>14 0.54487783 <a title="710-lsi-14" href="../high_scalability-2009/high_scalability-2009-02-03-Paper%3A_Optimistic_Replication.html">507 high scalability-2009-02-03-Paper: Optimistic Replication</a></p>
<p>15 0.53382593 <a title="710-lsi-15" href="../high_scalability-2011/high_scalability-2011-12-08-Update_on_Scalable_Causal_Consistency_For_Wide-Area_Storage_With_COPS.html">1153 high scalability-2011-12-08-Update on Scalable Causal Consistency For Wide-Area Storage With COPS</a></p>
<p>16 0.53037101 <a title="710-lsi-16" href="../high_scalability-2012/high_scalability-2012-08-16-Paper%3A_A_Provably_Correct_Scalable_Concurrent_Skip_List.html">1305 high scalability-2012-08-16-Paper: A Provably Correct Scalable Concurrent Skip List</a></p>
<p>17 0.52626735 <a title="710-lsi-17" href="../high_scalability-2012/high_scalability-2012-12-18-Georeplication%3A_When_Bad_Things_Happen_to_Good_Systems.html">1374 high scalability-2012-12-18-Georeplication: When Bad Things Happen to Good Systems</a></p>
<p>18 0.52377546 <a title="710-lsi-18" href="../high_scalability-2011/high_scalability-2011-01-27-Comet_-_An_Example_of_the_New_Key-Code_Databases.html">979 high scalability-2011-01-27-Comet - An Example of the New Key-Code Databases</a></p>
<p>19 0.52153462 <a title="710-lsi-19" href="../high_scalability-2009/high_scalability-2009-08-08-Yahoo%21%27s_PNUTS_Database%3A_Too_Hot%2C_Too_Cold_or_Just_Right%3F.html">676 high scalability-2009-08-08-Yahoo!'s PNUTS Database: Too Hot, Too Cold or Just Right?</a></p>
<p>20 0.51942104 <a title="710-lsi-20" href="../high_scalability-2010/high_scalability-2010-08-30-Pomegranate_-_Storing_Billions_and_Billions_of_Tiny_Little_Files.html">889 high scalability-2010-08-30-Pomegranate - Storing Billions and Billions of Tiny Little Files</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.118), (6, 0.368), (10, 0.044), (79, 0.089), (94, 0.125)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.88344926 <a title="710-lda-1" href="../high_scalability-2009/high_scalability-2009-09-20-PaxosLease%3A_Diskless_Paxos_for_Leases.html">710 high scalability-2009-09-20-PaxosLease: Diskless Paxos for Leases</a></p>
<p>Introduction: PaxosLeaseis a distributed algorithm for lease negotiation. It is based on
Paxos, but does not require disk writes or clock synchrony. PaxosLease is used
for master lease negotation in the open-source Keyspace replicated key-value
store.</p><p>2 0.86405283 <a title="710-lda-2" href="../high_scalability-2007/high_scalability-2007-09-16-What_software_runs_on_this_site%3F.html">93 high scalability-2007-09-16-What software runs on this site?</a></p>
<p>Introduction: It's pretty slick! olla</p><p>3 0.68568361 <a title="710-lda-3" href="../high_scalability-2007/high_scalability-2007-10-01-SmugMug_Found_their_Perfect_Storage_Array.html">104 high scalability-2007-10-01-SmugMug Found their Perfect Storage Array</a></p>
<p>Introduction: SmugMug's CEO & Chief Geek Don MacAskill smugly (hard to resist) gushes over
finally finding, after a long and arduous quest, their "best bang-for-the-buck
storage array." It's theDell MD300. His in-depth explanation of why he prefers
the MD3000 should help anyone with their own painful storage deliberations.
His key points are:breakThe price is right; DAS via SAS, 15 spindles at 15K
rpm each, 512MB of mirrored battery-backed write cache; You can disable read
caching; You can disable read-ahead prefetching; The stripe sizes are
configurable up to 512KB; The controller ignores host-based flush commands by
default; They support an ‘Enhanced JBOD’ mode.His reasoning for the
desirability each option is astute and he even gives you the configuration
options for carrying out the configuration. This is not your average CEO.Don
also speculates that a three tier system using flash (system RAM + flash
storage + RAID disks) is a possible future direction. Unfortunately, flash may
not be the dream</p><p>4 0.67647767 <a title="710-lda-4" href="../high_scalability-2010/high_scalability-2010-05-31-Scalable_federated_security_with_Kerberos_.html">832 high scalability-2010-05-31-Scalable federated security with Kerberos </a></p>
<p>Introduction: In my lastpost, I outlined considerations that need to be taken into account
when choosing between a centralized and federated security model. So, how do
we implement the chosen model?Based on a real-world case study, I will outline
a Kerberos architecture that enables cutting-edge collaborative research
through federated sharing of resources.Read more onBigDataMatters.com</p><p>5 0.55269009 <a title="710-lda-5" href="../high_scalability-2009/high_scalability-2009-03-10-Paper%3A_Consensus_Protocols%3A_Paxos___.html">529 high scalability-2009-03-10-Paper: Consensus Protocols: Paxos   </a></p>
<p>Introduction: Update: Barbara Liskov's Turing Award, and Byzantine Fault Tolerance.Henry
Robinson has created an excellent series of articles on consensus protocols.
We already covered his2 Phase Commitarticle and he also has a3 Phase
Commitarticle showing how to handle 2PC under single node failures.But that is
not enough! 3PC works well under node failures, but fails for network
failures. So another consensus mechanism is needed that handles both network
and node failures. And that'sPaxos.Paxos correctly handles both types of
failures, but it does this by becoming inaccessible if too many components
fail. This is the "liveness" property of protocols. Paxos waits until the
faults are fixed. Read queries can be handled, but updates will be blocked
until the protocol thinks it can make forward progress.The liveness of Paxos
is primarily dependent on network stability. In a distributed heterogeneous
environment you are at risk of losing the ability to make updates. Users hate
that.breakSo when compani</p><p>6 0.51911372 <a title="710-lda-6" href="../high_scalability-2008/high_scalability-2008-01-15-Does_Sun_Buying_MySQL_Change_Your_Scaling_Strategy%3F.html">213 high scalability-2008-01-15-Does Sun Buying MySQL Change Your Scaling Strategy?</a></p>
<p>7 0.50119567 <a title="710-lda-7" href="../high_scalability-2010/high_scalability-2010-03-11-What_would_you_like_to_ask_Justin.tv%3F.html">794 high scalability-2010-03-11-What would you like to ask Justin.tv?</a></p>
<p>8 0.46344331 <a title="710-lda-8" href="../high_scalability-2012/high_scalability-2012-08-16-Paper%3A_A_Provably_Correct_Scalable_Concurrent_Skip_List.html">1305 high scalability-2012-08-16-Paper: A Provably Correct Scalable Concurrent Skip List</a></p>
<p>9 0.43287355 <a title="710-lda-9" href="../high_scalability-2014/high_scalability-2014-02-25-Peter_Norvig%27s_9_Master_Steps_to_Improving_a_Program.html">1601 high scalability-2014-02-25-Peter Norvig's 9 Master Steps to Improving a Program</a></p>
<p>10 0.42116556 <a title="710-lda-10" href="../high_scalability-2008/high_scalability-2008-02-07-clusteradmin.blogspot.com_-_blog_about_building_and_administering_clusters.html">243 high scalability-2008-02-07-clusteradmin.blogspot.com - blog about building and administering clusters</a></p>
<p>11 0.42062762 <a title="710-lda-11" href="../high_scalability-2011/high_scalability-2011-04-14-Strategy%3A_Cache_Application_Start_State_to_Reduce_Spin-up_Times.html">1023 high scalability-2011-04-14-Strategy: Cache Application Start State to Reduce Spin-up Times</a></p>
<p>12 0.41793579 <a title="710-lda-12" href="../high_scalability-2009/high_scalability-2009-05-22-Distributed_content_system_with_bandwidth_balancing.html">605 high scalability-2009-05-22-Distributed content system with bandwidth balancing</a></p>
<p>13 0.41686124 <a title="710-lda-13" href="../high_scalability-2013/high_scalability-2013-03-13-Iron.io_Moved_From_Ruby_to_Go%3A_28_Servers_Cut_and_Colossal_Clusterf%2A%2Aks_Prevented.html">1423 high scalability-2013-03-13-Iron.io Moved From Ruby to Go: 28 Servers Cut and Colossal Clusterf**ks Prevented</a></p>
<p>14 0.41601121 <a title="710-lda-14" href="../high_scalability-2007/high_scalability-2007-10-07-Using_ThreadLocal_to_pass_context_information_around_in_web_applications.html">115 high scalability-2007-10-07-Using ThreadLocal to pass context information around in web applications</a></p>
<p>15 0.41299272 <a title="710-lda-15" href="../high_scalability-2012/high_scalability-2012-04-05-Big_Data_Counting%3A_How_to_count_a_billion_distinct_objects_using_only_1.5KB_of_Memory.html">1222 high scalability-2012-04-05-Big Data Counting: How to count a billion distinct objects using only 1.5KB of Memory</a></p>
<p>16 0.40491679 <a title="710-lda-16" href="../high_scalability-2009/high_scalability-2009-04-07-Six_Lessons_Learned_Deploying_a_Large-scale_Infrastructure_in_Amazon_EC2_.html">559 high scalability-2009-04-07-Six Lessons Learned Deploying a Large-scale Infrastructure in Amazon EC2 </a></p>
<p>17 0.39695698 <a title="710-lda-17" href="../high_scalability-2011/high_scalability-2011-07-22-Stuff_The_Internet_Says_On_Scalability_For_July_22%2C_2011.html">1084 high scalability-2011-07-22-Stuff The Internet Says On Scalability For July 22, 2011</a></p>
<p>18 0.39509767 <a title="710-lda-18" href="../high_scalability-2012/high_scalability-2012-04-06-Stuff_The_Internet_Says_On_Scalability_For_April_6%2C_2012.html">1223 high scalability-2012-04-06-Stuff The Internet Says On Scalability For April 6, 2012</a></p>
<p>19 0.39382735 <a title="710-lda-19" href="../high_scalability-2011/high_scalability-2011-01-06-BankSimple_Mini-Architecture_-_Using_a_Next_Generation_Toolchain.html">970 high scalability-2011-01-06-BankSimple Mini-Architecture - Using a Next Generation Toolchain</a></p>
<p>20 0.38626811 <a title="710-lda-20" href="../high_scalability-2009/high_scalability-2009-04-21-Thread_Pool_Engine_in_MS_CLR_4%2C_and_Work-Stealing_scheduling_algorithm.html">575 high scalability-2009-04-21-Thread Pool Engine in MS CLR 4, and Work-Stealing scheduling algorithm</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
