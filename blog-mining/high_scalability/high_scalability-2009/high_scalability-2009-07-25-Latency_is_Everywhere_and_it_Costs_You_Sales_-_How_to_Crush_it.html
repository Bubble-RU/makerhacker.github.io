<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2009" href="../home/high_scalability-2009_home.html">high_scalability-2009</a> <a title="high_scalability-2009-661" href="#">high_scalability-2009-661</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2009-661-html" href="http://highscalability.com//blog/2009/7/25/latency-is-everywhere-and-it-costs-you-sales-how-to-crush-it.html">html</a></p><p>Introduction: Update 8 :  The Cost of Latency  by James Hamilton. James summarizing some latency info from      Steve Souder ,   Greg Linden , and   Marissa Mayer .      Speed [is] an undervalued and under-discussed asset on the web. 
 
 Update 7:   How do you know when you need more memcache servers? . Dathan Pattishall talks about using memcache not to scale, but to reduce latency and reduce I/O spikes, and how to use stats to know when more servers are needed.  Update 6:   Stock Traders Find Speed Pays, in Milliseconds . Goldman Sachs is making record profits off a  500 millisecond  trading advantage. Yes, latency matters. As an interesting aside, Libet found 500 msecs is about the time it takes the brain to weave together an experience of consciousness from all our sensor inputs.  Update 5:   Shopzilla's Site Redo - You Get What You Measure . At the  Velocity  conference Phil Dixon, from Shopzilla, presented data showing a 5 second speed up resulted in a 25% increase in page views, a 10% increas</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Dathan Pattishall talks about using memcache not to scale, but to reduce latency and reduce I/O spikes, and how to use stats to know when more servers are needed. [sent-6, score-0.64]
</p><p>2 And latency is one of those quantifiable qualities that takes real engineering to create. [sent-67, score-0.61]
</p><p>3 Latency Explained   The best explanation of latency I've ever read is still  It's the Latency, Stupid  by admitted network wizard  Stuart Cheshire . [sent-82, score-0.615]
</p><p>4 A wonderful and detailed rant explaining latency as it relates to network communication, but the ideas are applicable everywhere. [sent-83, score-0.615]
</p><p>5 So if we want to increase interactivity we have to address every component in the system that introduces latency and minimize or remove it's contribution. [sent-87, score-0.665]
</p><p>6 If component A calls compont B then the latency is the sum of the latency for each component and overall availability is reduced. [sent-111, score-1.048]
</p><p>7 To reduce latency your only choice is to reduce the distance between endpoints. [sent-116, score-0.712]
</p><p>8 Draw out the list of every hop a client request takes and the potential number of latency gremlins is quite impressive. [sent-126, score-0.732]
</p><p>9 Remove and/or minimize all latency sources that are found. [sent-136, score-0.665]
</p><p>10 With latency variability is the name of the game, but that doesn't mean that variability can't be better controlled and managed. [sent-142, score-0.634]
</p><p>11 As memory is an order of magnitude faster than disk it's hard to argue that latency in such a system wouldn't plummet. [sent-172, score-0.697]
</p><p>12 Use Ajax to minimize perceived latency to the user. [sent-205, score-0.605]
</p><p>13 A high speed  InfiniBand  link can have an end-to end latency of about 1 microsecond. [sent-208, score-0.626]
</p><p>14 One way to minimize the impact of garbage collection on latency is to use more VMs and less memory in each VM instead of VM with a lot of memory. [sent-216, score-0.767]
</p><p>15 Some extra distance is required, based on the availability of fiber routes and interconnects, but much more attention should be given to minimizing latency as we design our network topologies and routing. [sent-228, score-0.687]
</p><p>16 Block for any reason and your performance tanks because not only do you incur the latency of the operation but there's added rescheduling latency as well. [sent-266, score-1.048]
</p><p>17 The number and location of network hops a message has to travel through is a big part of the end-to-end latency of a system. [sent-280, score-0.784]
</p><p>18 If you want to minimize latency then the clear strategy is to colocate your service in the London Stock Exchange. [sent-282, score-0.605]
</p><p>19 ACTIV Financial , for example, uses a custom FGPA for low latency processing of high speed financial data flows. [sent-332, score-0.682]
</p><p>20 end-to-end latency  by Nati Shalom    Low-Latency Delivery Enters Mainstream; But Standard Measurement Remains Elusive  by Andrew Delaney    The three faces of latency  by By Scott Parsons, Chief Scientist at Exegy, Inc. [sent-355, score-1.048]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('latency', 0.524), ('fpgas', 0.18), ('latencyby', 0.178), ('fpga', 0.149), ('dan', 0.102), ('speed', 0.102), ('pritchett', 0.097), ('standard', 0.092), ('network', 0.091), ('memory', 0.089), ('takes', 0.086), ('faster', 0.084), ('minimize', 0.081), ('zero', 0.076), ('less', 0.073), ('cope', 0.072), ('distance', 0.072), ('packet', 0.066), ('hop', 0.063), ('topic', 0.062), ('microprocessor', 0.061), ('sources', 0.06), ('milliseconds', 0.06), ('increase', 0.06), ('asynch', 0.059), ('stupidby', 0.059), ('number', 0.059), ('minimized', 0.059), ('hops', 0.059), ('tcp', 0.059), ('reduce', 0.058), ('objects', 0.057), ('paging', 0.057), ('page', 0.057), ('data', 0.056), ('means', 0.055), ('variability', 0.055), ('respond', 0.054), ('bw', 0.054), ('shopzilla', 0.054), ('stuart', 0.054), ('containing', 0.052), ('graphics', 0.052), ('communication', 0.052), ('bandwidth', 0.052), ('stock', 0.051), ('message', 0.051), ('bcp', 0.051), ('adapters', 0.051), ('loosely', 0.05)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="661-tfidf-1" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>Introduction: Update 8 :  The Cost of Latency  by James Hamilton. James summarizing some latency info from      Steve Souder ,   Greg Linden , and   Marissa Mayer .      Speed [is] an undervalued and under-discussed asset on the web. 
 
 Update 7:   How do you know when you need more memcache servers? . Dathan Pattishall talks about using memcache not to scale, but to reduce latency and reduce I/O spikes, and how to use stats to know when more servers are needed.  Update 6:   Stock Traders Find Speed Pays, in Milliseconds . Goldman Sachs is making record profits off a  500 millisecond  trading advantage. Yes, latency matters. As an interesting aside, Libet found 500 msecs is about the time it takes the brain to weave together an experience of consciousness from all our sensor inputs.  Update 5:   Shopzilla's Site Redo - You Get What You Measure . At the  Velocity  conference Phil Dixon, from Shopzilla, presented data showing a 5 second speed up resulted in a 25% increase in page views, a 10% increas</p><p>2 0.3212871 <a title="661-tfidf-2" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>Introduction: Likewise the current belief that, in the case of artificial machines the very large and the very small are equally feasible and lasting is a manifest error. Thus, for example, a small obelisk or column or other solid figure can certainly be laid down or set up without danger of breaking, while the large ones will go to pieces under the slightest provocation, and that purely on account of their own weight. -- Galileo  
Galileo observed how things broke if they were naively scaled up. Interestingly, Google noticed a similar pattern when building larger software systems using the same techniques used to build smaller systems. 
 
 Luiz André Barroso , Distinguished Engineer at Google, talks about this fundamental property of scaling systems in his fascinating talk,  Warehouse-Scale Computing: Entering the Teenage Decade . Google found the larger the scale the greater the impact of latency variability. When a request is implemented by work done in parallel, as is common with today's service</p><p>3 0.25299981 <a title="661-tfidf-3" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>Introduction: In   Taming The Long Latency Tail   we covered   Luiz Barroso  ’s exploration of the long tail latency (some operations are really slow) problems generated by large fanout architectures (a request is composed of potentially thousands of other requests). You may have noticed there weren’t a lot of solutions. That’s where a talk I attended,   Achieving Rapid Response Times in Large Online Services   (  slide deck  ), by  Jeff Dean , also of Google, comes in:
  
  In this talk, I’ll describe a collection of techniques and practices lowering response times in large distributed systems whose components run on shared clusters of machines, where pieces of these systems are subject to interference by other tasks, and where unpredictable latency hiccups are the norm, not the exception. 

  
 The goal is to use software techniques to reduce variability given the increasing variability in underlying hardware, the need to handle dynamic workloads on a shared infrastructure, and the need to use lar</p><p>4 0.2477233 <a title="661-tfidf-4" href="../high_scalability-2013/high_scalability-2013-01-15-More_Numbers_Every_Awesome_Programmer_Must_Know.html">1387 high scalability-2013-01-15-More Numbers Every Awesome Programmer Must Know</a></p>
<p>Introduction: Colin Scott   , a Berkeley researcher, updated Jeff Dean’s famous    Numbers Everyone Should Know    with his    Latency Numbers Every Programmer Should Know    interactive graphic. The interactive aspect is cool because it has a slider that let’s you see numbers back from as early as 1990 to the far far future of 2020.  
 
Colin explained his  motivation for updating the numbers :
  The other day, a friend mentioned a latency number to me, and I realized that it was an order of magnitude smaller than what I had memorized from Jeff’s talk. The problem, of course, is that hardware performance increases exponentially! After some digging, I actually found that the numbers Jeff quotes are over a decade old  
 Since numbers without interpretation are simply data, take a look at    Google Pro Tip: Use Back-Of-The-Envelope-Calculations To Choose The Best Design . The idea is back-of-the-envelope calculations are estimates you create using a combination of thought experiments and common perfor</p><p>5 0.23715171 <a title="661-tfidf-5" href="../high_scalability-2013/high_scalability-2013-12-04-How_Can_Batching_Requests_Actually_Reduce_Latency%3F.html">1558 high scalability-2013-12-04-How Can Batching Requests Actually Reduce Latency?</a></p>
<p>Introduction: Jeremy Edberg gave a talk on  Scaling Reddit from 1 Million to 1 Billion–Pitfalls and Lessons  and  one of the issues  they had was that they:
  

Did not account for increased latency after moving to EC2. In the datacenter they had submillisecond access between machines so it was possible to make a 1000 calls to memache for one page load. Not so on EC2. Memcache access times increased 10x to a millisecond which made their old approach unusable. Fix was to batch calls to memcache so a large number of gets are in one request.

  
Dave Pacheco had an  interesting question  about batching requests and its impact on latency:
  

 I was confused about the memcached problem after moving to the cloud.  I understand why network latency may have gone from submillisecond to milliseconds, but how could you improve latency by batching requests? Shouldn't that improve efficiency, not latency, at the possible expense of latency (since some requests will wait on the client as they get batched)?</p><p>6 0.23105341 <a title="661-tfidf-6" href="../high_scalability-2009/high_scalability-2009-03-16-Are_Cloud_Based_Memory_Architectures_the_Next_Big_Thing%3F.html">538 high scalability-2009-03-16-Are Cloud Based Memory Architectures the Next Big Thing?</a></p>
<p>7 0.20691717 <a title="661-tfidf-7" href="../high_scalability-2009/high_scalability-2009-08-24-How_Google_Serves_Data_from_Multiple_Datacenters.html">687 high scalability-2009-08-24-How Google Serves Data from Multiple Datacenters</a></p>
<p>8 0.20626104 <a title="661-tfidf-8" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>9 0.20386657 <a title="661-tfidf-9" href="../high_scalability-2009/high_scalability-2009-12-16-Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_in_the_Ambient_Cloud.html">750 high scalability-2009-12-16-Building Super Scalable Systems: Blade Runner Meets Autonomic Computing in the Ambient Cloud</a></p>
<p>10 0.20378365 <a title="661-tfidf-10" href="../high_scalability-2012/high_scalability-2012-11-05-Gone_Fishin%27%3A_Building_Super_Scalable_Systems%3A_Blade_Runner_Meets_Autonomic_Computing_In_The_Ambient_Cloud.html">1355 high scalability-2012-11-05-Gone Fishin': Building Super Scalable Systems: Blade Runner Meets Autonomic Computing In The Ambient Cloud</a></p>
<p>11 0.20347449 <a title="661-tfidf-11" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>12 0.19522001 <a title="661-tfidf-12" href="../high_scalability-2010/high_scalability-2010-08-12-Think_of_Latency_as_a_Pseudo-permanent_Network_Partition.html">879 high scalability-2010-08-12-Think of Latency as a Pseudo-permanent Network Partition</a></p>
<p>13 0.19211929 <a title="661-tfidf-13" href="../high_scalability-2012/high_scalability-2012-01-19-Is_it_time_to_get_rid_of_the_Linux_OS_model_in_the_cloud%3F.html">1177 high scalability-2012-01-19-Is it time to get rid of the Linux OS model in the cloud?</a></p>
<p>14 0.18938738 <a title="661-tfidf-14" href="../high_scalability-2013/high_scalability-2013-08-30-Stuff_The_Internet_Says_On_Scalability_For_August_30%2C_2013.html">1509 high scalability-2013-08-30-Stuff The Internet Says On Scalability For August 30, 2013</a></p>
<p>15 0.18681511 <a title="661-tfidf-15" href="../high_scalability-2010/high_scalability-2010-12-20-Netflix%3A_Use_Less_Chatty_Protocols_in_the_Cloud_-_Plus_26_Fixes.html">960 high scalability-2010-12-20-Netflix: Use Less Chatty Protocols in the Cloud - Plus 26 Fixes</a></p>
<p>16 0.1862184 <a title="661-tfidf-16" href="../high_scalability-2009/high_scalability-2009-06-30-Hot_New_Trend%3A_Linking_Clouds_Through_Cheap_IP_VPNs_Instead_of_Private_Lines_.html">645 high scalability-2009-06-30-Hot New Trend: Linking Clouds Through Cheap IP VPNs Instead of Private Lines </a></p>
<p>17 0.18386333 <a title="661-tfidf-17" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>18 0.18101285 <a title="661-tfidf-18" href="../high_scalability-2012/high_scalability-2012-11-15-Gone_Fishin%27%3A_Justin.Tv%27s_Live_Video_Broadcasting_Architecture.html">1359 high scalability-2012-11-15-Gone Fishin': Justin.Tv's Live Video Broadcasting Architecture</a></p>
<p>19 0.18087372 <a title="661-tfidf-19" href="../high_scalability-2010/high_scalability-2010-03-16-Justin.tv%27s_Live_Video_Broadcasting_Architecture.html">796 high scalability-2010-03-16-Justin.tv's Live Video Broadcasting Architecture</a></p>
<p>20 0.17706302 <a title="661-tfidf-20" href="../high_scalability-2010/high_scalability-2010-06-01-Web_Speed_Can_Push_You_Off_of_Google_Search_Rankings%21_What_Can_You_Do%3F.html">834 high scalability-2010-06-01-Web Speed Can Push You Off of Google Search Rankings! What Can You Do?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.351), (1, 0.189), (2, -0.007), (3, 0.012), (4, -0.074), (5, 0.013), (6, 0.079), (7, 0.156), (8, -0.161), (9, -0.024), (10, 0.003), (11, -0.035), (12, -0.02), (13, 0.02), (14, 0.01), (15, 0.024), (16, 0.039), (17, 0.029), (18, 0.015), (19, -0.049), (20, 0.046), (21, 0.042), (22, 0.056), (23, -0.015), (24, -0.012), (25, 0.042), (26, -0.038), (27, -0.032), (28, -0.011), (29, -0.035), (30, 0.076), (31, -0.024), (32, 0.034), (33, -0.03), (34, 0.05), (35, 0.052), (36, 0.023), (37, 0.034), (38, -0.079), (39, -0.033), (40, 0.05), (41, 0.035), (42, 0.026), (43, -0.013), (44, -0.0), (45, -0.089), (46, 0.049), (47, -0.057), (48, -0.029), (49, -0.01)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98484397 <a title="661-lsi-1" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>Introduction: Update 8 :  The Cost of Latency  by James Hamilton. James summarizing some latency info from      Steve Souder ,   Greg Linden , and   Marissa Mayer .      Speed [is] an undervalued and under-discussed asset on the web. 
 
 Update 7:   How do you know when you need more memcache servers? . Dathan Pattishall talks about using memcache not to scale, but to reduce latency and reduce I/O spikes, and how to use stats to know when more servers are needed.  Update 6:   Stock Traders Find Speed Pays, in Milliseconds . Goldman Sachs is making record profits off a  500 millisecond  trading advantage. Yes, latency matters. As an interesting aside, Libet found 500 msecs is about the time it takes the brain to weave together an experience of consciousness from all our sensor inputs.  Update 5:   Shopzilla's Site Redo - You Get What You Measure . At the  Velocity  conference Phil Dixon, from Shopzilla, presented data showing a 5 second speed up resulted in a 25% increase in page views, a 10% increas</p><p>2 0.93878084 <a title="661-lsi-2" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>Introduction: Likewise the current belief that, in the case of artificial machines the very large and the very small are equally feasible and lasting is a manifest error. Thus, for example, a small obelisk or column or other solid figure can certainly be laid down or set up without danger of breaking, while the large ones will go to pieces under the slightest provocation, and that purely on account of their own weight. -- Galileo  
Galileo observed how things broke if they were naively scaled up. Interestingly, Google noticed a similar pattern when building larger software systems using the same techniques used to build smaller systems. 
 
 Luiz André Barroso , Distinguished Engineer at Google, talks about this fundamental property of scaling systems in his fascinating talk,  Warehouse-Scale Computing: Entering the Teenage Decade . Google found the larger the scale the greater the impact of latency variability. When a request is implemented by work done in parallel, as is common with today's service</p><p>3 0.86554849 <a title="661-lsi-3" href="../high_scalability-2013/high_scalability-2013-12-04-How_Can_Batching_Requests_Actually_Reduce_Latency%3F.html">1558 high scalability-2013-12-04-How Can Batching Requests Actually Reduce Latency?</a></p>
<p>Introduction: Jeremy Edberg gave a talk on  Scaling Reddit from 1 Million to 1 Billion–Pitfalls and Lessons  and  one of the issues  they had was that they:
  

Did not account for increased latency after moving to EC2. In the datacenter they had submillisecond access between machines so it was possible to make a 1000 calls to memache for one page load. Not so on EC2. Memcache access times increased 10x to a millisecond which made their old approach unusable. Fix was to batch calls to memcache so a large number of gets are in one request.

  
Dave Pacheco had an  interesting question  about batching requests and its impact on latency:
  

 I was confused about the memcached problem after moving to the cloud.  I understand why network latency may have gone from submillisecond to milliseconds, but how could you improve latency by batching requests? Shouldn't that improve efficiency, not latency, at the possible expense of latency (since some requests will wait on the client as they get batched)?</p><p>4 0.8441962 <a title="661-lsi-4" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>Introduction: In   Taming The Long Latency Tail   we covered   Luiz Barroso  ’s exploration of the long tail latency (some operations are really slow) problems generated by large fanout architectures (a request is composed of potentially thousands of other requests). You may have noticed there weren’t a lot of solutions. That’s where a talk I attended,   Achieving Rapid Response Times in Large Online Services   (  slide deck  ), by  Jeff Dean , also of Google, comes in:
  
  In this talk, I’ll describe a collection of techniques and practices lowering response times in large distributed systems whose components run on shared clusters of machines, where pieces of these systems are subject to interference by other tasks, and where unpredictable latency hiccups are the norm, not the exception. 

  
 The goal is to use software techniques to reduce variability given the increasing variability in underlying hardware, the need to handle dynamic workloads on a shared infrastructure, and the need to use lar</p><p>5 0.83331788 <a title="661-lsi-5" href="../high_scalability-2010/high_scalability-2010-12-20-Netflix%3A_Use_Less_Chatty_Protocols_in_the_Cloud_-_Plus_26_Fixes.html">960 high scalability-2010-12-20-Netflix: Use Less Chatty Protocols in the Cloud - Plus 26 Fixes</a></p>
<p>Introduction: In  5 Lessons We’ve Learned Using AWS , Netflix's John Ciancutti says one of the big lessons they've learned is to create less  chatty protocols :
  
 In the Netflix data centers, we have a high capacity, super fast, highly reliable network. This has afforded us the luxury of designing around chatty APIs to remote systems. AWS networking has more variable latency. We’ve had to be much more structured about “over the wire” interactions, even as we’ve transitioned to a more highly distributed architecture. 
  
There's not a lot of advice out there on how to create protocols. Combine that with a rush to the cloud and you have a perfect storm for chatty applications crushing application performance. Netflix is far from the first to be surprised by the less than stellar networks inside AWS. 
 
A chatty protocol is one where a client makes a series of requests to a server and the client must wait on each reply before sending the next request. On a LAN this can work great. LAN's are typically</p><p>6 0.82816041 <a title="661-lsi-6" href="../high_scalability-2013/high_scalability-2013-01-15-More_Numbers_Every_Awesome_Programmer_Must_Know.html">1387 high scalability-2013-01-15-More Numbers Every Awesome Programmer Must Know</a></p>
<p>7 0.8213464 <a title="661-lsi-7" href="../high_scalability-2012/high_scalability-2012-05-02-12_Ways_to_Increase_Throughput_by_32X_and_Reduce_Latency_by__20X.html">1237 high scalability-2012-05-02-12 Ways to Increase Throughput by 32X and Reduce Latency by  20X</a></p>
<p>8 0.80381632 <a title="661-lsi-8" href="../high_scalability-2011/high_scalability-2011-05-27-Stuff_The_Internet_Says_On_Scalability_For_May_27%2C_2011.html">1048 high scalability-2011-05-27-Stuff The Internet Says On Scalability For May 27, 2011</a></p>
<p>9 0.79388982 <a title="661-lsi-9" href="../high_scalability-2012/high_scalability-2012-01-13-Stuff_The_Internet_Says_On_Scalability_For_January_13%2C_2012.html">1174 high scalability-2012-01-13-Stuff The Internet Says On Scalability For January 13, 2012</a></p>
<p>10 0.79213172 <a title="661-lsi-10" href="../high_scalability-2014/high_scalability-2014-01-31-Stuff_The_Internet_Says_On_Scalability_For_January_31st%2C_2014.html">1588 high scalability-2014-01-31-Stuff The Internet Says On Scalability For January 31st, 2014</a></p>
<p>11 0.78358072 <a title="661-lsi-11" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>12 0.77669191 <a title="661-lsi-12" href="../high_scalability-2012/high_scalability-2012-03-22-Paper%3A_Revisiting_Network_I-O_APIs%3A_The_netmap_Framework.html">1213 high scalability-2012-03-22-Paper: Revisiting Network I-O APIs: The netmap Framework</a></p>
<p>13 0.76622391 <a title="661-lsi-13" href="../high_scalability-2011/high_scalability-2011-09-15-Paper%3A_It%27s_Time_for_Low_Latency_-_Inventing_the_1_Microsecond_Datacenter.html">1116 high scalability-2011-09-15-Paper: It's Time for Low Latency - Inventing the 1 Microsecond Datacenter</a></p>
<p>14 0.76511759 <a title="661-lsi-14" href="../high_scalability-2012/high_scalability-2012-02-10-Stuff_The_Internet_Says_On_Scalability_For_February_10%2C_2012.html">1190 high scalability-2012-02-10-Stuff The Internet Says On Scalability For February 10, 2012</a></p>
<p>15 0.7638948 <a title="661-lsi-15" href="../high_scalability-2014/high_scalability-2014-01-03-Stuff_The_Internet_Says_On_Scalability_For_January_3rd%2C_2014.html">1572 high scalability-2014-01-03-Stuff The Internet Says On Scalability For January 3rd, 2014</a></p>
<p>16 0.75901252 <a title="661-lsi-16" href="../high_scalability-2011/high_scalability-2011-02-01-Google_Strategy%3A_Tree_Distribution_of_Requests_and_Responses.html">981 high scalability-2011-02-01-Google Strategy: Tree Distribution of Requests and Responses</a></p>
<p>17 0.75702655 <a title="661-lsi-17" href="../high_scalability-2011/high_scalability-2011-06-01-Why_is_your_network_so_slow%3F_Your_switch_should_tell_you..html">1051 high scalability-2011-06-01-Why is your network so slow? Your switch should tell you.</a></p>
<p>18 0.75664622 <a title="661-lsi-18" href="../high_scalability-2013/high_scalability-2013-05-17-Stuff_The_Internet_Says_On_Scalability_For_May_17%2C_2013.html">1460 high scalability-2013-05-17-Stuff The Internet Says On Scalability For May 17, 2013</a></p>
<p>19 0.7566421 <a title="661-lsi-19" href="../high_scalability-2013/high_scalability-2013-06-13-Busting_4_Modern_Hardware_Myths_-_Are_Memory%2C_HDDs%2C_and_SSDs_Really_Random_Access%3F.html">1475 high scalability-2013-06-13-Busting 4 Modern Hardware Myths - Are Memory, HDDs, and SSDs Really Random Access?</a></p>
<p>20 0.75577015 <a title="661-lsi-20" href="../high_scalability-2014/high_scalability-2014-03-14-Stuff_The_Internet_Says_On_Scalability_For_March_14th%2C_2014.html">1612 high scalability-2014-03-14-Stuff The Internet Says On Scalability For March 14th, 2014</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.096), (2, 0.239), (10, 0.059), (27, 0.014), (30, 0.027), (40, 0.018), (43, 0.012), (47, 0.032), (50, 0.073), (51, 0.013), (61, 0.088), (77, 0.016), (79, 0.118), (85, 0.033), (94, 0.052)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97709006 <a title="661-lda-1" href="../high_scalability-2013/high_scalability-2013-06-28-Stuff_The_Internet_Says_On_Scalability_For_June_28%2C_2013.html">1484 high scalability-2013-06-28-Stuff The Internet Says On Scalability For June 28, 2013</a></p>
<p>Introduction: Hey, it's HighScalability time:
     (Leandro Erlich's super cool scaling illusion )   
 Who am I? I have 50 petabytes of data stored in Hadoop and Teradata, 400 million items for sale, 250 million queries a day, 100,000 pages served per second, 112 million active users, $75 billions sold in 2012...If you  guessed eBay  then you've won the auction. 
 Quotable Quotes:                                          
 
   Controlled Experiments at Large Scale : Bing found that every 100ms faster they deliver search result pages yields 0.6% more in revenue  
  Luis Bettencourt : A city is first and foremost a social reactor. It works like a star, attracting people and accelerating social interaction and social outputs in a way that is analogous to how stars compress matter and burn brighter and faster the bigger they are. 
  @nntaleb : unless you understand that fat tails come from concentration of errors, you should not discuss probability & risk  
 
 
 Need to make Hadoop faster?  Hadoop + GPU</p><p>2 0.97419167 <a title="661-lda-2" href="../high_scalability-2009/high_scalability-2009-07-16-Scaling_Traffic%3A_People_Pod_Pool_of_On_Demand_Self_Driving_Robotic_Cars_who_Automatically_Refuel_from_Cheap_Solar.html">657 high scalability-2009-07-16-Scaling Traffic: People Pod Pool of On Demand Self Driving Robotic Cars who Automatically Refuel from Cheap Solar</a></p>
<p>Introduction: Update 17 :  Are Wireless Road Trains the Cure for Traffic Congestion?   BY   ADDY DUGDALE .  The concept of road trains--up to eight vehicles zooming down the road together--has long been considered a faster, safer, and greener way of traveling long distances by car 
 
 Update 16:  The first electric vehicle in the country  powered completely by ultracapacitors . The minibus can be fully recharged in fifteen minutes, unlike battery vehicles, which typically takes hours to recharge.
 
 Update 15:   How to Make UAVs Fully Autonomous . The Sense-and-Avoid system uses a four-megapixel camera on a pan tilt to detect obstacles from the ground. It puts red boxes around planes and birds, and blue boxes around movement that it determines is not an obstacle (e.g., dust on the lens).  Update 14:   ATNMBL is a concept vehicle  for 2040 that represents the end of driving and an alternative approach to car design. Upon entering ATNMBL, you are presented with a simple question: "Where can I take you</p><p>same-blog 3 0.96736723 <a title="661-lda-3" href="../high_scalability-2009/high_scalability-2009-07-25-Latency_is_Everywhere_and_it_Costs_You_Sales_-_How_to_Crush_it.html">661 high scalability-2009-07-25-Latency is Everywhere and it Costs You Sales - How to Crush it</a></p>
<p>Introduction: Update 8 :  The Cost of Latency  by James Hamilton. James summarizing some latency info from      Steve Souder ,   Greg Linden , and   Marissa Mayer .      Speed [is] an undervalued and under-discussed asset on the web. 
 
 Update 7:   How do you know when you need more memcache servers? . Dathan Pattishall talks about using memcache not to scale, but to reduce latency and reduce I/O spikes, and how to use stats to know when more servers are needed.  Update 6:   Stock Traders Find Speed Pays, in Milliseconds . Goldman Sachs is making record profits off a  500 millisecond  trading advantage. Yes, latency matters. As an interesting aside, Libet found 500 msecs is about the time it takes the brain to weave together an experience of consciousness from all our sensor inputs.  Update 5:   Shopzilla's Site Redo - You Get What You Measure . At the  Velocity  conference Phil Dixon, from Shopzilla, presented data showing a 5 second speed up resulted in a 25% increase in page views, a 10% increas</p><p>4 0.96662003 <a title="661-lda-4" href="../high_scalability-2012/high_scalability-2012-09-04-Changing_Architectures%3A_New_Datacenter_Networks_Will_Set_Your_Code_and_Data_Free___.html">1316 high scalability-2012-09-04-Changing Architectures: New Datacenter Networks Will Set Your Code and Data Free   </a></p>
<p>Introduction: One consequence of IT   standardization and commodification    has been Google’s    datacenter is the computer    view of the world. In that view all compute resources (memory, CPU, storage) are fungible. They are interchangeable and location independent, individual computers lose identity and become just a part of a service.     Thwarting that nirvana has been the abysmal performance of commodity datacenter networks which have caused the preference of architectures that favor the collocation of state and behaviour on the same box. MapReduce famously    ships code over to storage nodes    for just this reason.    Change the network and you change the fundamental assumption driving collocation based software architectures. You are then free to store data anywhere and move compute anywhere you wish. The datacenter becomes the computer.     On the host side with an x8 slot running at    PCI-Express 3.0    speeds able to push 8GB/sec (that’s bytes) of bandwidth in both directions, we have</p><p>5 0.96260971 <a title="661-lda-5" href="../high_scalability-2011/high_scalability-2011-09-07-What_Google_App_Engine_Price_Changes_Say_About_the_Future_of_Web_Architecture.html">1112 high scalability-2011-09-07-What Google App Engine Price Changes Say About the Future of Web Architecture</a></p>
<p>Introduction: When I was a child, I spake as a child, I understood as a child, I thought as a child: but when I became a man, I put away childish things . -- Corinthians
 
 With this new pricing, developments will be driven by the costs .  I like to optimize my apps to make them better or faster, but to optimize them just to make them cheaper is a waste of time.  -- Sylvain on  Google Groups 
 
The dream is dead. Google App Engine's bold  pay for what you use  dream dies as it leaves childish things behind and becomes a  real product .  Pricing will change . Architectures will change. Customers will change. Hearts and minds will change. But Google App Engine  will survive.   
 
Google is  shutting down  many of its  projects . GAE is not among them. Do we have GAE's pricing change to thank for it surving the  more wood behind  more deadly arrows push? Without a radical and quick shift towards profitably GAE would no doubt be a historical footnote in the long scroll of good ideas. The urgency involve</p><p>6 0.95849252 <a title="661-lda-6" href="../high_scalability-2013/high_scalability-2013-05-17-Stuff_The_Internet_Says_On_Scalability_For_May_17%2C_2013.html">1460 high scalability-2013-05-17-Stuff The Internet Says On Scalability For May 17, 2013</a></p>
<p>7 0.95836419 <a title="661-lda-7" href="../high_scalability-2011/high_scalability-2011-03-24-Strategy%3A_Disk_Backup_for_Speed%2C_Tape_Backup_to_Save_Your_Bacon%2C_Just_Ask_Google.html">1010 high scalability-2011-03-24-Strategy: Disk Backup for Speed, Tape Backup to Save Your Bacon, Just Ask Google</a></p>
<p>8 0.95793146 <a title="661-lda-8" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>9 0.95745635 <a title="661-lda-9" href="../high_scalability-2010/high_scalability-2010-06-28-VoltDB_Decapitates_Six_SQL_Urban_Myths_and_Delivers_Internet_Scale_OLTP_in_the_Process.html">849 high scalability-2010-06-28-VoltDB Decapitates Six SQL Urban Myths and Delivers Internet Scale OLTP in the Process</a></p>
<p>10 0.95606911 <a title="661-lda-10" href="../high_scalability-2013/high_scalability-2013-04-12-Stuff_The_Internet_Says_On_Scalability_For_April_12%2C_2013.html">1439 high scalability-2013-04-12-Stuff The Internet Says On Scalability For April 12, 2013</a></p>
<p>11 0.95559126 <a title="661-lda-11" href="../high_scalability-2011/high_scalability-2011-09-16-Stuff_The_Internet_Says_On_Scalability_For_September_16%2C_2011.html">1117 high scalability-2011-09-16-Stuff The Internet Says On Scalability For September 16, 2011</a></p>
<p>12 0.95540845 <a title="661-lda-12" href="../high_scalability-2013/high_scalability-2013-08-30-Stuff_The_Internet_Says_On_Scalability_For_August_30%2C_2013.html">1509 high scalability-2013-08-30-Stuff The Internet Says On Scalability For August 30, 2013</a></p>
<p>13 0.95436883 <a title="661-lda-13" href="../high_scalability-2013/high_scalability-2013-06-13-Busting_4_Modern_Hardware_Myths_-_Are_Memory%2C_HDDs%2C_and_SSDs_Really_Random_Access%3F.html">1475 high scalability-2013-06-13-Busting 4 Modern Hardware Myths - Are Memory, HDDs, and SSDs Really Random Access?</a></p>
<p>14 0.95424885 <a title="661-lda-14" href="../high_scalability-2007/high_scalability-2007-08-29-Skype_Failed_the_Boot_Scalability_Test%3A_Is_P2P_fundamentally_flawed%3F.html">76 high scalability-2007-08-29-Skype Failed the Boot Scalability Test: Is P2P fundamentally flawed?</a></p>
<p>15 0.95354033 <a title="661-lda-15" href="../high_scalability-2010/high_scalability-2010-05-10-Sify.com_Architecture_-_A_Portal_at_3900_Requests_Per_Second.html">825 high scalability-2010-05-10-Sify.com Architecture - A Portal at 3900 Requests Per Second</a></p>
<p>16 0.95309925 <a title="661-lda-16" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>17 0.9530766 <a title="661-lda-17" href="../high_scalability-2012/high_scalability-2012-04-25-The_Anatomy_of_Search_Technology%3A_blekko%E2%80%99s_NoSQL_database.html">1233 high scalability-2012-04-25-The Anatomy of Search Technology: blekko’s NoSQL database</a></p>
<p>18 0.9526909 <a title="661-lda-18" href="../high_scalability-2014/high_scalability-2014-01-03-Stuff_The_Internet_Says_On_Scalability_For_January_3rd%2C_2014.html">1572 high scalability-2014-01-03-Stuff The Internet Says On Scalability For January 3rd, 2014</a></p>
<p>19 0.95265657 <a title="661-lda-19" href="../high_scalability-2013/high_scalability-2013-12-13-Stuff_The_Internet_Says_On_Scalability_For_December_13th%2C_2013.html">1564 high scalability-2013-12-13-Stuff The Internet Says On Scalability For December 13th, 2013</a></p>
<p>20 0.9526096 <a title="661-lda-20" href="../high_scalability-2012/high_scalability-2012-07-09-Data_Replication_in_NoSQL_Databases.html">1279 high scalability-2012-07-09-Data Replication in NoSQL Databases</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
