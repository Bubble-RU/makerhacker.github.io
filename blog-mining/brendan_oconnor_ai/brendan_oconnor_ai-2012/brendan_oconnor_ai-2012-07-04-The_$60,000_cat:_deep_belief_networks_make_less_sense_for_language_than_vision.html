<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2012" href="../home/brendan_oconnor_ai-2012_home.html">brendan_oconnor_ai-2012</a> <a title="brendan_oconnor_ai-2012-184" href="#">brendan_oconnor_ai-2012-184</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2012-184-html" href="http://brenocon.com/blog/2012/07/the-60000-cat-deep-belief-networks-make-less-sense-for-language-than-vision/">html</a></p><p>Introduction: There was an  interesting ICML paper  this year about very large-scale training of deep belief networks (a.k.a. neural networks) for unsupervised concept extraction from images.  They ( Quoc V. Le  and colleagues at Google/Stanford) have a cute example of learning very high-level features that are evoked by images of cats (from YouTube still-image training data); one is shown below.
 
For those of us who work on machine learning and text, the question always comes up, why not DBN’s for language?  Many shallow latent-space text models have been quite successful (LSI, LDA, HMM, LPCFG…); there is hope that some sort of “deeper” concepts could be learned.  I think this is one of the most interesting areas for unsupervised language modeling right now.
 
But note it’s a bad idea to directly analogize results from image analysis to language analysis.  The problems have radically different levels of conceptual abstraction baked-in.  Consider the problem of detecting the concept of a cat; i.e.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 There was an  interesting ICML paper  this year about very large-scale training of deep belief networks (a. [sent-1, score-0.28]
</p><p>2 Le  and colleagues at Google/Stanford) have a cute example of learning very high-level features that are evoked by images of cats (from YouTube still-image training data); one is shown below. [sent-6, score-0.387]
</p><p>3 But note it’s a bad idea to directly analogize results from image analysis to language analysis. [sent-10, score-0.282]
</p><p>4 Consider the problem of detecting the concept of a cat; i. [sent-12, score-0.319]
</p><p>5 I hereby propose a system that can detect this concept in text, and compare it to the image analysis DBN as follows. [sent-15, score-0.502]
</p><p>6 Problem   Concept representation   Concept detector   Cost to create concept detector       Image analysis                1,152,000 CPU-hours to train neural network  $61,056 at current  GCE prices         Language analysis        cat     a. [sent-16, score-1.434]
</p><p>7 000078 at GCE prices        I mean: you can identify the concept “cat” by tokenizing a text, i. [sent-22, score-0.465]
</p><p>8 To identify the “cat” concept from a vector of pixel intensities, you have to run through a cascade of filters, edge detectors, shape detectors and more. [sent-25, score-0.593]
</p><p>9 This paper creates the image analyzer with tons of unsupervised learning; in other approaches you still have to train all the components in your cascade. [sent-26, score-0.293]
</p><p>10 ]    In text, the concept of “cat” is immediately available on the surface — there’s a whole word for it. [sent-28, score-0.42]
</p><p>11 In comparison, the point of language is communication, so it’s designed, at least a little bit, to be comprehensible — pixel intensity vectors do not seem to be have such a design goal. [sent-33, score-0.424]
</p><p>12 "]   The fact that it’s easy to write a rule-based word extractor with /[^a-zA-Z0-9]/ doesn’t mean bag-of-words or n-grams are “low-level”; it just means that concept extraction is easy with text. [sent-35, score-0.71]
</p><p>13 In particular, English has whitespace conventions and simple enough morphology that you can write a tokenizer by hand, and we’ve designed character encoding standards let computers unambiguously map between word forms and binary representations. [sent-36, score-0.429]
</p><p>14 Unsupervised cross-lingual phonetic and morphological learning is closer, cognitive-level-of-abstraction-wise, to what the deep belief networks people are trying to do with images. [sent-37, score-0.305]
</p><p>15 To make a fairer table above, you might want to compare to the training time of an unsupervised word segmenter / cross-lingual lexicon learner. [sent-38, score-0.345]
</p><p>16 Every time you run a topic model you're building off of your rule-based concept extractor -- your tokenizer -- which might very well be doing all the important work. [sent-40, score-0.465]
</p><p>17 Just within lexical semantics, it’s easy to come up with examples of concepts that “cat” might refer to, but you want other words as well. [sent-45, score-0.356]
</p><p>18 )   If you want to represent and differentiate between the concepts evoked by these wordsets, then yes, the bare symbol “cat” is too narrow (or too broad), and maybe we want something “deeper”. [sent-50, score-0.333]
</p><p>19 In the images case, “deep” seems to mean “recognizable concepts that look cool”. [sent-53, score-0.291]
</p><p>20 )  In the text case, if you let yourself use word-and-ngram extraction, then you’ve already started with recognizable concepts — where are you going next? [sent-55, score-0.392]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cat', 0.614), ('concept', 0.319), ('concepts', 0.149), ('deep', 0.13), ('unsupervised', 0.119), ('pixel', 0.118), ('reduction', 0.118), ('image', 0.116), ('text', 0.107), ('word', 0.101), ('language', 0.099), ('words', 0.099), ('learning', 0.097), ('dimension', 0.087), ('extraction', 0.087), ('mean', 0.08), ('cats', 0.078), ('dbn', 0.078), ('detectors', 0.078), ('evoked', 0.078), ('gce', 0.078), ('identify', 0.078), ('intensity', 0.078), ('pets', 0.078), ('recognizable', 0.078), ('regex', 0.078), ('tokenizer', 0.078), ('networks', 0.078), ('training', 0.072), ('designed', 0.069), ('prices', 0.068), ('extractor', 0.068), ('vectors', 0.068), ('morphology', 0.068), ('analysis', 0.067), ('deeper', 0.062), ('images', 0.062), ('neural', 0.062), ('detector', 0.062), ('design', 0.061), ('train', 0.058), ('costs', 0.058), ('broad', 0.058), ('let', 0.058), ('write', 0.055), ('network', 0.055), ('tasks', 0.055), ('lexical', 0.055), ('semantics', 0.055), ('want', 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999982 <a title="184-tfidf-1" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>Introduction: There was an  interesting ICML paper  this year about very large-scale training of deep belief networks (a.k.a. neural networks) for unsupervised concept extraction from images.  They ( Quoc V. Le  and colleagues at Google/Stanford) have a cute example of learning very high-level features that are evoked by images of cats (from YouTube still-image training data); one is shown below.
 
For those of us who work on machine learning and text, the question always comes up, why not DBN’s for language?  Many shallow latent-space text models have been quite successful (LSI, LDA, HMM, LPCFG…); there is hope that some sort of “deeper” concepts could be learned.  I think this is one of the most interesting areas for unsupervised language modeling right now.
 
But note it’s a bad idea to directly analogize results from image analysis to language analysis.  The problems have radically different levels of conceptual abstraction baked-in.  Consider the problem of detecting the concept of a cat; i.e.</p><p>2 0.10087277 <a title="184-tfidf-2" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>3 0.098950006 <a title="184-tfidf-3" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>Introduction: I haven’t done a paper review on this blog for a while, so here we go.
 
 Coreference  resolution is an interesting NLP problem.  ( Examples. )  It involves honest-to-goodness syntactic, semantic, and discourse phenomena, but still seems like a real cognitive task that humans have to solve when reading text [1].  I haven’t read the whole literature, but I’ve always been puzzled by the crop of papers on it I’ve seen in the last year or two.  There’s a big focus on fancy graph/probabilistic/constrained optimization algorithms, but often these papers gloss over the linguistic features — the core information they actually make their decisions with [2].  I never understood why the latter isn’t the most important issue.  Therefore, it was a joy to read
  
 Aria Haghighi and Dan Klein, EMNLP-2009.   “Simple Coreference Resolution with Rich Syntactic and Semantic Features.”  
  
They describe a simple, essentially non-statistical system that outperforms previous unsupervised systems, and compa</p><p>4 0.097823463 <a title="184-tfidf-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>Introduction: I’m a bit late blogging this, but here’s a messy, exciting — and statistically validated! — new online data source.
 
My friend  Roddy  at Facebook  wrote a post describing their sentiment analysis system , which can evaluate positive or negative sentiment toward a particular topic by looking at a large number of wall messages.  (I’d link to it, but I can’t find the URL anymore — here’s the  Lexicon , but that version only gets term frequencies but no sentiment.)
 
How they constructed their sentiment detector is interesting.  Starting with a list of positive and negative terms, they had a lexical acquisition step to gather many more candidate synonyms and misspellings — a necessity in this social media domain, where  WordNet  ain’t gonna come close!  After manually filtering these candidates, they assess the sentiment toward a mention of a topic by looking for instances of these positive and negative words nearby, along with “negation heuristics” and a few other features.
 
He describ</p><p>5 0.088246204 <a title="184-tfidf-5" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-02-23-Wasserman_on_Stats_vs_ML%2C_and_previous_comparisons.html">191 brendan oconnor ai-2013-02-23-Wasserman on Stats vs ML, and previous comparisons</a></p>
<p>Introduction: Larry Wasserman has a new position paper (forthcoming 2013) with a great comparison the Statistics and Machine Learning research cultures,  “Rise of the Machines” .  He has a very conciliatory view in terms of intellectual content, and a very pro-ML take on the research cultures.  Central to his argument is that ML has recently adopted rigorous statistical concepts, and the fast-moving conference culture (and heavy publishing by its grad students) have helped with this and other good innovations.  (I agree with a comment from Sinead that he’s going a little easy on ML, but it’s certainly worth a read.)
 
There’s now a little history of “Statistics vs Machine Learning” position papers that this can be compared to.  A classic is Leo Breiman (2001),  “Statistical Modeling: The Two Cultures” , which isn’t exactly about stats vs. ML, but is about the focus on modeling vs algorithms, and maybe about description vs. prediction.
 
It’s been a while since I’ve looked at it, but I’ve also enjoye</p><p>6 0.085067965 <a title="184-tfidf-6" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-19-End-to-end_NLP_packages.html">174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</a></p>
<p>7 0.082950339 <a title="184-tfidf-7" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>8 0.081787914 <a title="184-tfidf-8" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-08-01-Bayesian_analysis_of_intelligent_design_%28revised%21%29.html">23 brendan oconnor ai-2005-08-01-Bayesian analysis of intelligent design (revised!)</a></p>
<p>9 0.071855903 <a title="184-tfidf-9" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-27-China%3A_fines_for_bad_maps.html">71 brendan oconnor ai-2007-07-27-China: fines for bad maps</a></p>
<p>10 0.0680084 <a title="184-tfidf-10" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>11 0.067639723 <a title="184-tfidf-11" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-10-05-Be_careful_with_dictionary-based_text_analysis.html">176 brendan oconnor ai-2011-10-05-Be careful with dictionary-based text analysis</a></p>
<p>12 0.066658624 <a title="184-tfidf-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">153 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>13 0.065682538 <a title="184-tfidf-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-Netflix_Prize.html">125 brendan oconnor ai-2008-11-21-Netflix Prize</a></p>
<p>14 0.065312572 <a title="184-tfidf-14" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>15 0.064872012 <a title="184-tfidf-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-23-SF_conference_for_data_mining_mercenaries.html">133 brendan oconnor ai-2009-01-23-SF conference for data mining mercenaries</a></p>
<p>16 0.064277306 <a title="184-tfidf-16" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>17 0.062220573 <a title="184-tfidf-17" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-05-08-Movie_summary_corpus_and_learning_character_personas.html">196 brendan oconnor ai-2013-05-08-Movie summary corpus and learning character personas</a></p>
<p>18 0.062100332 <a title="184-tfidf-18" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-17-%22Time_will_tell%2C_epistemology_won%E2%80%99t%22.html">65 brendan oconnor ai-2007-06-17-"Time will tell, epistemology won’t"</a></p>
<p>19 0.061946958 <a title="184-tfidf-19" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>20 0.060905546 <a title="184-tfidf-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.257), (1, -0.049), (2, 0.099), (3, -0.048), (4, 0.052), (5, -0.03), (6, 0.013), (7, 0.022), (8, -0.026), (9, -0.022), (10, 0.043), (11, -0.0), (12, 0.055), (13, 0.07), (14, 0.045), (15, -0.027), (16, 0.033), (17, 0.004), (18, -0.113), (19, 0.028), (20, -0.006), (21, 0.008), (22, 0.065), (23, -0.088), (24, 0.044), (25, 0.013), (26, 0.017), (27, 0.052), (28, 0.011), (29, 0.041), (30, -0.037), (31, 0.022), (32, 0.016), (33, -0.001), (34, -0.017), (35, 0.017), (36, -0.066), (37, 0.025), (38, -0.04), (39, -0.067), (40, -0.023), (41, -0.012), (42, 0.044), (43, -0.025), (44, 0.012), (45, -0.048), (46, 0.112), (47, 0.038), (48, 0.117), (49, 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97617137 <a title="184-lsi-1" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>Introduction: There was an  interesting ICML paper  this year about very large-scale training of deep belief networks (a.k.a. neural networks) for unsupervised concept extraction from images.  They ( Quoc V. Le  and colleagues at Google/Stanford) have a cute example of learning very high-level features that are evoked by images of cats (from YouTube still-image training data); one is shown below.
 
For those of us who work on machine learning and text, the question always comes up, why not DBN’s for language?  Many shallow latent-space text models have been quite successful (LSI, LDA, HMM, LPCFG…); there is hope that some sort of “deeper” concepts could be learned.  I think this is one of the most interesting areas for unsupervised language modeling right now.
 
But note it’s a bad idea to directly analogize results from image analysis to language analysis.  The problems have radically different levels of conceptual abstraction baked-in.  Consider the problem of detecting the concept of a cat; i.e.</p><p>2 0.62855041 <a title="184-lsi-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>Introduction: I’m doing  word and bigram counts  on a corpus of tweets.  I want to store and rapidly retrieve them later for  language model  purposes.  So there’s a big table of counts that get incremented many times.  The easiest way to get something running is to use an open-source key/value store; but which?  There’s recently been some development in this area so I thought it would be good to revisit and evaluate some options.
 
Here are timings for a single counting process: iterate over 45,000 short text messages, tokenize them, then increment counters for their unigrams and bigrams.  (The speed of the data store is only one component of performance.)  There are about 17 increments per tweet: 400k unique terms and 750k total count.  This is substantially smaller than what I need, but it’s small enough to easily test.  I used several very different architectures and packages, explained below.
  
 
 architecture
  name
  speed
   
 in-memory, within-process
  python dictionary
   2700 tweets/sec</p><p>3 0.62343925 <a title="184-lsi-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>Introduction: I’m a bit late blogging this, but here’s a messy, exciting — and statistically validated! — new online data source.
 
My friend  Roddy  at Facebook  wrote a post describing their sentiment analysis system , which can evaluate positive or negative sentiment toward a particular topic by looking at a large number of wall messages.  (I’d link to it, but I can’t find the URL anymore — here’s the  Lexicon , but that version only gets term frequencies but no sentiment.)
 
How they constructed their sentiment detector is interesting.  Starting with a list of positive and negative terms, they had a lexical acquisition step to gather many more candidate synonyms and misspellings — a necessity in this social media domain, where  WordNet  ain’t gonna come close!  After manually filtering these candidates, they assess the sentiment toward a mention of a topic by looking for instances of these positive and negative words nearby, along with “negation heuristics” and a few other features.
 
He describ</p><p>4 0.6192081 <a title="184-lsi-4" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-10-05-Be_careful_with_dictionary-based_text_analysis.html">176 brendan oconnor ai-2011-10-05-Be careful with dictionary-based text analysis</a></p>
<p>Introduction: OK, everyone loves to run dictionary methods for sentiment and other text analysis — counting words from a predefined lexicon in a big corpus, in order to explore or test hypotheses about the corpus.  In particular, this is often done for sentiment analysis: count positive and negative words (according to a sentiment polarity lexicon, which was derived from human raters or previous researchers’ intuitions), and then proclaim the output yields sentiment levels of the documents.  More and more papers come out every day that do this.   I’ve done this myself.   It’s interesting and fun, but it’s easy to get a bunch of meaningless numbers if you don’t carefully validate what’s going on.  There are certainly good studies in this area that do further validation and analysis, but it’s hard to trust a study that just presents a graph with a few overly strong speculative claims as to its meaning.  This happens more than it ought to.
 
I was happy to see a similarly critical view in a nice workin</p><p>5 0.56366849 <a title="184-lsi-5" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>Introduction: I haven’t done a paper review on this blog for a while, so here we go.
 
 Coreference  resolution is an interesting NLP problem.  ( Examples. )  It involves honest-to-goodness syntactic, semantic, and discourse phenomena, but still seems like a real cognitive task that humans have to solve when reading text [1].  I haven’t read the whole literature, but I’ve always been puzzled by the crop of papers on it I’ve seen in the last year or two.  There’s a big focus on fancy graph/probabilistic/constrained optimization algorithms, but often these papers gloss over the linguistic features — the core information they actually make their decisions with [2].  I never understood why the latter isn’t the most important issue.  Therefore, it was a joy to read
  
 Aria Haghighi and Dan Klein, EMNLP-2009.   “Simple Coreference Resolution with Rich Syntactic and Semantic Features.”  
  
They describe a simple, essentially non-statistical system that outperforms previous unsupervised systems, and compa</p><p>6 0.5487681 <a title="184-lsi-6" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>7 0.51885146 <a title="184-lsi-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-Netflix_Prize.html">125 brendan oconnor ai-2008-11-21-Netflix Prize</a></p>
<p>8 0.49555165 <a title="184-lsi-8" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>9 0.49427477 <a title="184-lsi-9" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-26-Seeing_how_%E2%80%9Cart%E2%80%9D_and_%E2%80%9Cpharmaceuticals%E2%80%9D_are_linguistically_similar_in_web_text.html">156 brendan oconnor ai-2009-09-26-Seeing how “art” and “pharmaceuticals” are linguistically similar in web text</a></p>
<p>10 0.49251229 <a title="184-lsi-10" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-19-End-to-end_NLP_packages.html">174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</a></p>
<p>11 0.46956143 <a title="184-lsi-11" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-05-19-conplot_%E2%80%93_a_console_plotter.html">103 brendan oconnor ai-2008-05-19-conplot – a console plotter</a></p>
<p>12 0.46291244 <a title="184-lsi-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>13 0.45772901 <a title="184-lsi-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">153 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>14 0.43947524 <a title="184-lsi-14" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>15 0.43731394 <a title="184-lsi-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-23-SF_conference_for_data_mining_mercenaries.html">133 brendan oconnor ai-2009-01-23-SF conference for data mining mercenaries</a></p>
<p>16 0.43647006 <a title="184-lsi-16" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-funny_comic.html">48 brendan oconnor ai-2007-01-02-funny comic</a></p>
<p>17 0.43063349 <a title="184-lsi-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-17-%22Time_will_tell%2C_epistemology_won%E2%80%99t%22.html">65 brendan oconnor ai-2007-06-17-"Time will tell, epistemology won’t"</a></p>
<p>18 0.42443359 <a title="184-lsi-18" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-29-%22Stanford_Impostor%22.html">62 brendan oconnor ai-2007-05-29-"Stanford Impostor"</a></p>
<p>19 0.41638708 <a title="184-lsi-19" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-18-Scatterplot_of_KN-PYP_language_model_results.html">202 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</a></p>
<p>20 0.41638049 <a title="184-lsi-20" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(7, 0.014), (16, 0.018), (22, 0.044), (24, 0.016), (25, 0.288), (43, 0.041), (44, 0.169), (48, 0.031), (55, 0.019), (64, 0.023), (70, 0.044), (74, 0.118), (80, 0.036), (85, 0.012)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.90252358 <a title="184-lda-1" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>Introduction: There was an  interesting ICML paper  this year about very large-scale training of deep belief networks (a.k.a. neural networks) for unsupervised concept extraction from images.  They ( Quoc V. Le  and colleagues at Google/Stanford) have a cute example of learning very high-level features that are evoked by images of cats (from YouTube still-image training data); one is shown below.
 
For those of us who work on machine learning and text, the question always comes up, why not DBN’s for language?  Many shallow latent-space text models have been quite successful (LSI, LDA, HMM, LPCFG…); there is hope that some sort of “deeper” concepts could be learned.  I think this is one of the most interesting areas for unsupervised language modeling right now.
 
But note it’s a bad idea to directly analogize results from image analysis to language analysis.  The problems have radically different levels of conceptual abstraction baked-in.  Consider the problem of detecting the concept of a cat; i.e.</p><p>2 0.57887173 <a title="184-lda-2" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>3 0.55880773 <a title="184-lda-3" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>Introduction: Everyone recently seems to be talking about  this newish paper by Digrazia, McKelvey, Bollen, and Rojas  ( pdf here ) that examines the correlation of Congressional candidate name mentions on Twitter against whether the candidate won the race.  One of the coauthors also wrote a Washington Post  Op-Ed  about it.  I read the paper and I think it’s reasonable, but their op-ed overstates their results.  It claims:
  
“In the 2010 data, our Twitter data predicted the winner in 404 out of 435 competitive races”
  
But this analysis is nowhere in their paper.  Fabio Rojas has now  posted errata/rebuttals  about the op-ed and described this analysis they did here.  There are several major issues off the bat:
  
 They didn’t ever predict 404/435 races; they only analyzed 406 races they call “competitive,” getting 92.5% (in-sample) accuracy, then extrapolated to all races to get the 435 number. 
 They’re reporting about  in-sample  predictions, which is really misleading to a non-scientific audi</p><p>4 0.54479092 <a title="184-lda-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>Introduction: I’m a bit late blogging this, but here’s a messy, exciting — and statistically validated! — new online data source.
 
My friend  Roddy  at Facebook  wrote a post describing their sentiment analysis system , which can evaluate positive or negative sentiment toward a particular topic by looking at a large number of wall messages.  (I’d link to it, but I can’t find the URL anymore — here’s the  Lexicon , but that version only gets term frequencies but no sentiment.)
 
How they constructed their sentiment detector is interesting.  Starting with a list of positive and negative terms, they had a lexical acquisition step to gather many more candidate synonyms and misspellings — a necessity in this social media domain, where  WordNet  ain’t gonna come close!  After manually filtering these candidates, they assess the sentiment toward a mention of a topic by looking for instances of these positive and negative words nearby, along with “negation heuristics” and a few other features.
 
He describ</p><p>5 0.53376544 <a title="184-lda-5" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>Introduction: This is my idea based off of  Bernheim and Rangel’s  model of addict decision-making .  It’s a really neat model; it manages to relax rationality to allow someone to do something they don’t want to do because they’re addicted to it.  [Rationality assumes a nice well-ordered set of preferences; this model hypothesizes as distinction between emotional "liking" and cognitive, forward "wanting" that can conflict.]  The model is mathematically tractable, it can be used for public welfare analysis, and to top it off — it’s got neuroscientific grounding!
 
It appears to me there are two big criticisms of the economics discipline’s assumptions.  One of course is rationality.  The second has to do with the perfect structure of the market and environment that shapes both preferences and the ability to exercise them.  One critique is about social structure: consumers are not atomistic individual units, but rather exchange information and ideas along networks of patterned social relations.  (Socia</p><p>6 0.52666092 <a title="184-lda-6" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>7 0.51135391 <a title="184-lda-7" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-26-Seeing_how_%E2%80%9Cart%E2%80%9D_and_%E2%80%9Cpharmaceuticals%E2%80%9D_are_linguistically_similar_in_web_text.html">156 brendan oconnor ai-2009-09-26-Seeing how “art” and “pharmaceuticals” are linguistically similar in web text</a></p>
<p>8 0.511289 <a title="184-lda-8" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>9 0.49273944 <a title="184-lda-9" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>10 0.48521689 <a title="184-lda-10" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<p>11 0.48412368 <a title="184-lda-11" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>12 0.48132202 <a title="184-lda-12" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-09-I_don%E2%80%99t_get_this_web_parsing_shared_task.html">181 brendan oconnor ai-2012-03-09-I don’t get this web parsing shared task</a></p>
<p>13 0.47819248 <a title="184-lda-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>14 0.47604284 <a title="184-lda-14" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>15 0.47539583 <a title="184-lda-15" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>16 0.47101104 <a title="184-lda-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-08-Blog_move_has_landed.html">115 brendan oconnor ai-2008-10-08-Blog move has landed</a></p>
<p>17 0.47007492 <a title="184-lda-17" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-08-30-A_big%2C_fun_list_of_links_I%E2%80%99m_reading.html">44 brendan oconnor ai-2006-08-30-A big, fun list of links I’m reading</a></p>
<p>18 0.46515173 <a title="184-lda-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>19 0.46442717 <a title="184-lda-19" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>20 0.4602915 <a title="184-lda-20" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-03-18-Mark_Turner%3A_Toward_the_Founding_of_Cognitive_Social_Science.html">31 brendan oconnor ai-2006-03-18-Mark Turner: Toward the Founding of Cognitive Social Science</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
