<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2012" href="../home/brendan_oconnor_ai-2012_home.html">brendan_oconnor_ai-2012</a> <a title="brendan_oconnor_ai-2012-179" href="#">brendan_oconnor_ai-2012-179</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2012-179-html" href="http://brenocon.com/blog/2012/02/histograms-matplotlib-vs-r/">html</a></p><p>Introduction: When possible, I like to use R for its really, really good statistical visualization capabilities.  I’m doing a modeling project in Python right now (R is too slow, bad at large data, bad at structured data, etc.), and in comparison to base R, the matplotlib library is just painful.  I wrote a toy  Metropolis  sampler for a  triangle distribution  and all I want to see is whether it looks like it’s working.  For the same dataset, here are histograms with default settings.  (Python:  pylab.hist(d) , R:  hist(d) )
 
   
 
I want to know whether my Metropolis sampler is working; those two plots give a very different idea.  Of course, you could say this is an unfair comparison, since matplotlib is only using 10 bins, while R is using 18 here — and it’s always important to vary the bin size a few times when looking at histograms.  But R’s defaults really are better: it actually uses an adaptive bin size, and the heuristic worked, choosing a reasonable number for the data.  The  hist()  manu</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 When possible, I like to use R for its really, really good statistical visualization capabilities. [sent-1, score-0.3]
</p><p>2 I’m doing a modeling project in Python right now (R is too slow, bad at large data, bad at structured data, etc. [sent-2, score-0.234]
</p><p>3 ), and in comparison to base R, the matplotlib library is just painful. [sent-3, score-0.406]
</p><p>4 I wrote a toy  Metropolis  sampler for a  triangle distribution  and all I want to see is whether it looks like it’s working. [sent-4, score-0.291]
</p><p>5 For the same dataset, here are histograms with default settings. [sent-5, score-0.165]
</p><p>6 hist(d) , R:  hist(d) )         I want to know whether my Metropolis sampler is working; those two plots give a very different idea. [sent-7, score-0.338]
</p><p>7 Of course, you could say this is an unfair comparison, since matplotlib is only using 10 bins, while R is using 18 here — and it’s always important to vary the bin size a few times when looking at histograms. [sent-8, score-1.068]
</p><p>8 But R’s defaults really are better: it actually uses an adaptive bin size, and the heuristic worked, choosing a reasonable number for the data. [sent-9, score-0.527]
</p><p>9 It’s hard to find other computer software that cites 100 year old papers for its design decisions — and where it matters. [sent-11, score-0.174]
</p><p>10 (Old versions of R used to yell at you when you made a pie chart, citing perceptual studies that humans are really bad at interpreting them ( here ). [sent-12, score-0.552]
</p><p>11 In the following plots, I’ve manually set the  number of bins to 10, and then 30 for each. [sent-15, score-0.36]
</p><p>12 The second one is now OK for matplotlib — it’s good enough to figure out what’s going on — though still a little lame. [sent-16, score-0.391]
</p><p>13 The problem is that my data are discrete — they’re all integers from 1 through 19 — and I think matplotlib is naively carving up that range into bins, which sometimes lumps together two integers, and sometimes gets zero of them. [sent-18, score-0.898]
</p><p>14 For reference, here is the correct visualization of the data (R:  plot(table(d)) ). [sent-20, score-0.203]
</p><p>15 Note that R’s original Sturges breakpoints did make one error: the first two values got combined into one bin. [sent-21, score-0.234]
</p><p>16 Lessons: (1) always vary the bin sizes for histograms, especially if you’re using naive breakpoint selection, and (2) don’t ignore a century’s worth of statistical research on these issues. [sent-22, score-0.883]
</p><p>17 And since it’s hard to learn a century’s worth of statistics, just use R, where they’re compiled it in for you. [sent-23, score-0.172]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('matplotlib', 0.302), ('bins', 0.285), ('bin', 0.248), ('sturges', 0.19), ('integers', 0.165), ('hist', 0.165), ('histograms', 0.165), ('metropolis', 0.165), ('vary', 0.151), ('naive', 0.141), ('sampler', 0.133), ('century', 0.121), ('plots', 0.121), ('really', 0.121), ('bad', 0.117), ('python', 0.116), ('comparison', 0.104), ('data', 0.102), ('visualization', 0.101), ('size', 0.098), ('using', 0.093), ('old', 0.091), ('second', 0.089), ('worth', 0.089), ('sometimes', 0.085), ('two', 0.084), ('cites', 0.083), ('waste', 0.083), ('lessons', 0.083), ('histogram', 0.083), ('fault', 0.083), ('ignore', 0.083), ('pylab', 0.083), ('triangle', 0.083), ('choosing', 0.083), ('unfair', 0.083), ('originally', 0.083), ('compiled', 0.083), ('slow', 0.083), ('citing', 0.083), ('made', 0.081), ('statistical', 0.078), ('heuristic', 0.075), ('versions', 0.075), ('pie', 0.075), ('combined', 0.075), ('values', 0.075), ('toy', 0.075), ('zero', 0.075), ('manually', 0.075)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="179-tfidf-1" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>Introduction: When possible, I like to use R for its really, really good statistical visualization capabilities.  I’m doing a modeling project in Python right now (R is too slow, bad at large data, bad at structured data, etc.), and in comparison to base R, the matplotlib library is just painful.  I wrote a toy  Metropolis  sampler for a  triangle distribution  and all I want to see is whether it looks like it’s working.  For the same dataset, here are histograms with default settings.  (Python:  pylab.hist(d) , R:  hist(d) )
 
   
 
I want to know whether my Metropolis sampler is working; those two plots give a very different idea.  Of course, you could say this is an unfair comparison, since matplotlib is only using 10 bins, while R is using 18 here — and it’s always important to vary the bin size a few times when looking at histograms.  But R’s defaults really are better: it actually uses an adaptive bin size, and the heuristic worked, choosing a reasonable number for the data.  The  hist()  manu</p><p>2 0.12705019 <a title="179-tfidf-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>Introduction: Lukas  and I were trying to write a succinct comparison of the most popular packages that are typically used for data analysis.  I think most people choose one based on what people around them use or what they learn in school, so I’ve found it hard to find comparative information.  I’m posting the table here in hopes of useful comments.
  
 
 
  Name  
  Advantages  
  Disadvantages  
  Open source?  
  Typical   users  
 
 
 R 
 Library support; visualization 
 Steep learning curve 
 Yes 
 Finance; Statistics 
 
 
 Matlab 
 Elegant matrix support; visualization 
 Expensive; incomplete statistics support 
 No 
 Engineering 
 
 
 SciPy/NumPy/Matplotlib 
 Python (general-purpose programming language) 
 Immature 
 Yes 
 Engineering 
 
 
 Excel 
 Easy; visual; flexible 
 Large datasets 
 No 
 Business 
 
 
 SAS 
 Large datasets 
 Expensive; outdated programming language 
 No 
 Business; Government 
 
 
 Stata 
 Easy statistical analysis 
  
 No 
 Science 
 
 
 SPSS 
 Like Stata but more ex</p><p>3 0.10084507 <a title="179-tfidf-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-28-Calculating_running_variance_in_Python_and_C%2B%2B.html">128 brendan oconnor ai-2008-11-28-Calculating running variance in Python and C++</a></p>
<p>Introduction: It’s fairly obvious that an average can be calculated online, but interestingly, there’s also a way to calculate a running variance and standard deviation.  Read all about it  here .
 
I’m playing around with the  Netflix Prize  data of 100 million movie ratings, and a huge problem is figuring out how to load and calculate everything in memory.  I’m having success with  NumPy , the numeric library for Python, because it compactly stores arrays with C/Fortran binary layouts.  For example, 100 million 32-bit floats = 100M * 4 = 400MB of memory, which is manageable.  And it’s much easier to play around interactively in  ipython / matplotlib  rather than write C++ for everything.
 
Unfortunately, the simple ways to calculate variance on an array of that size create wasteful intermediate data structures as long as the original array.
  
>>> mean( (x-mean(x)) ** 2 )            # two intermediate structures
>>> tmp=x-mean(x); tmp**=2; mean(tmp)   # one intermediate structure
  
That’s an e</p><p>4 0.096444882 <a title="179-tfidf-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>5 0.093022905 <a title="179-tfidf-5" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-02-23-Wasserman_on_Stats_vs_ML%2C_and_previous_comparisons.html">191 brendan oconnor ai-2013-02-23-Wasserman on Stats vs ML, and previous comparisons</a></p>
<p>Introduction: Larry Wasserman has a new position paper (forthcoming 2013) with a great comparison the Statistics and Machine Learning research cultures,  “Rise of the Machines” .  He has a very conciliatory view in terms of intellectual content, and a very pro-ML take on the research cultures.  Central to his argument is that ML has recently adopted rigorous statistical concepts, and the fast-moving conference culture (and heavy publishing by its grad students) have helped with this and other good innovations.  (I agree with a comment from Sinead that he’s going a little easy on ML, but it’s certainly worth a read.)
 
There’s now a little history of “Statistics vs Machine Learning” position papers that this can be compared to.  A classic is Leo Breiman (2001),  “Statistical Modeling: The Two Cultures” , which isn’t exactly about stats vs. ML, but is about the focus on modeling vs algorithms, and maybe about description vs. prediction.
 
It’s been a while since I’ve looked at it, but I’ve also enjoye</p><p>6 0.088089094 <a title="179-tfidf-6" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>7 0.084408201 <a title="179-tfidf-7" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-idea%3A_Morals_are_heuristics_for_socially_optimal_behavior.html">6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</a></p>
<p>8 0.08309342 <a title="179-tfidf-8" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>9 0.082437649 <a title="179-tfidf-9" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-20-Log-normal_and_logistic-normal_terminology.html">169 brendan oconnor ai-2011-05-20-Log-normal and logistic-normal terminology</a></p>
<p>10 0.079723924 <a title="179-tfidf-10" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-09-I_don%E2%80%99t_get_this_web_parsing_shared_task.html">181 brendan oconnor ai-2012-03-09-I don’t get this web parsing shared task</a></p>
<p>11 0.076569967 <a title="179-tfidf-11" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>12 0.076189615 <a title="179-tfidf-12" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-11-Memorizing_small_tables.html">177 brendan oconnor ai-2011-11-11-Memorizing small tables</a></p>
<p>13 0.075991161 <a title="179-tfidf-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-05-Clinton-Obama_support_visualization.html">105 brendan oconnor ai-2008-06-05-Clinton-Obama support visualization</a></p>
<p>14 0.074920096 <a title="179-tfidf-14" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-08-Blog_move_has_landed.html">115 brendan oconnor ai-2008-10-08-Blog move has landed</a></p>
<p>15 0.074197002 <a title="179-tfidf-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>16 0.073781133 <a title="179-tfidf-16" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>17 0.071328506 <a title="179-tfidf-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-24-Python_bindings_to_Google%E2%80%99s_%E2%80%9CAJAX%E2%80%9D_Search_API.html">127 brendan oconnor ai-2008-11-24-Python bindings to Google’s “AJAX” Search API</a></p>
<p>18 0.070563622 <a title="179-tfidf-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>19 0.069853835 <a title="179-tfidf-19" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">153 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>20 0.068254136 <a title="179-tfidf-20" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-19-End-to-end_NLP_packages.html">174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.274), (1, -0.119), (2, 0.069), (3, -0.041), (4, -0.026), (5, 0.081), (6, -0.023), (7, -0.069), (8, 0.03), (9, -0.041), (10, 0.008), (11, -0.017), (12, -0.131), (13, -0.094), (14, 0.081), (15, 0.121), (16, 0.045), (17, 0.054), (18, -0.04), (19, 0.046), (20, 0.047), (21, 0.007), (22, -0.068), (23, -0.005), (24, -0.075), (25, -0.033), (26, 0.008), (27, -0.033), (28, -0.071), (29, -0.061), (30, 0.008), (31, 0.014), (32, 0.216), (33, 0.015), (34, -0.115), (35, -0.023), (36, 0.137), (37, 0.036), (38, 0.012), (39, -0.033), (40, -0.086), (41, -0.076), (42, 0.083), (43, -0.035), (44, -0.018), (45, -0.034), (46, -0.087), (47, 0.007), (48, -0.035), (49, -0.004)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9750644 <a title="179-lsi-1" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>Introduction: When possible, I like to use R for its really, really good statistical visualization capabilities.  I’m doing a modeling project in Python right now (R is too slow, bad at large data, bad at structured data, etc.), and in comparison to base R, the matplotlib library is just painful.  I wrote a toy  Metropolis  sampler for a  triangle distribution  and all I want to see is whether it looks like it’s working.  For the same dataset, here are histograms with default settings.  (Python:  pylab.hist(d) , R:  hist(d) )
 
   
 
I want to know whether my Metropolis sampler is working; those two plots give a very different idea.  Of course, you could say this is an unfair comparison, since matplotlib is only using 10 bins, while R is using 18 here — and it’s always important to vary the bin size a few times when looking at histograms.  But R’s defaults really are better: it actually uses an adaptive bin size, and the heuristic worked, choosing a reasonable number for the data.  The  hist()  manu</p><p>2 0.72086692 <a title="179-lsi-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>Introduction: Lukas  and I were trying to write a succinct comparison of the most popular packages that are typically used for data analysis.  I think most people choose one based on what people around them use or what they learn in school, so I’ve found it hard to find comparative information.  I’m posting the table here in hopes of useful comments.
  
 
 
  Name  
  Advantages  
  Disadvantages  
  Open source?  
  Typical   users  
 
 
 R 
 Library support; visualization 
 Steep learning curve 
 Yes 
 Finance; Statistics 
 
 
 Matlab 
 Elegant matrix support; visualization 
 Expensive; incomplete statistics support 
 No 
 Engineering 
 
 
 SciPy/NumPy/Matplotlib 
 Python (general-purpose programming language) 
 Immature 
 Yes 
 Engineering 
 
 
 Excel 
 Easy; visual; flexible 
 Large datasets 
 No 
 Business 
 
 
 SAS 
 Large datasets 
 Expensive; outdated programming language 
 No 
 Business; Government 
 
 
 Stata 
 Easy statistical analysis 
  
 No 
 Science 
 
 
 SPSS 
 Like Stata but more ex</p><p>3 0.60614115 <a title="179-lsi-3" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>Introduction: I’m doing  word and bigram counts  on a corpus of tweets.  I want to store and rapidly retrieve them later for  language model  purposes.  So there’s a big table of counts that get incremented many times.  The easiest way to get something running is to use an open-source key/value store; but which?  There’s recently been some development in this area so I thought it would be good to revisit and evaluate some options.
 
Here are timings for a single counting process: iterate over 45,000 short text messages, tokenize them, then increment counters for their unigrams and bigrams.  (The speed of the data store is only one component of performance.)  There are about 17 increments per tweet: 400k unique terms and 750k total count.  This is substantially smaller than what I need, but it’s small enough to easily test.  I used several very different architectures and packages, explained below.
  
 
 architecture
  name
  speed
   
 in-memory, within-process
  python dictionary
   2700 tweets/sec</p><p>4 0.60512871 <a title="179-lsi-4" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-11-Memorizing_small_tables.html">177 brendan oconnor ai-2011-11-11-Memorizing small tables</a></p>
<p>Introduction: Lately, I’ve been trying  to memorize very small tables, especially for better intuitions and rule-of-thumb calculations.  At the moment I have these above my desk:
 
   
 
The first one is a few entries in a natural logarithm table.  There are all these stories about how in the slide rule era, people would develop better intuitions about the scale of logarithms because they physically engaged with them all the time.  I spend lots of time looking at log-likelihoods, log-odds-ratios, and logistic regression coefficients, so I think it would be nice to have quick intuitions about what they are.  (Though the  Gelman and Hill  textbook has an interesting argument against odds scale interpretations of logistic regression coefficients.)
 
The second one are some zsh filename manipulation  shortcuts .  OK, this is more narrow than the others, but pretty useful for me at least.
 
The third one are rough unit equivalencies for data rates over time.  I find this very important for quickly determ</p><p>5 0.59294021 <a title="179-lsi-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-28-Calculating_running_variance_in_Python_and_C%2B%2B.html">128 brendan oconnor ai-2008-11-28-Calculating running variance in Python and C++</a></p>
<p>Introduction: It’s fairly obvious that an average can be calculated online, but interestingly, there’s also a way to calculate a running variance and standard deviation.  Read all about it  here .
 
I’m playing around with the  Netflix Prize  data of 100 million movie ratings, and a huge problem is figuring out how to load and calculate everything in memory.  I’m having success with  NumPy , the numeric library for Python, because it compactly stores arrays with C/Fortran binary layouts.  For example, 100 million 32-bit floats = 100M * 4 = 400MB of memory, which is manageable.  And it’s much easier to play around interactively in  ipython / matplotlib  rather than write C++ for everything.
 
Unfortunately, the simple ways to calculate variance on an array of that size create wasteful intermediate data structures as long as the original array.
  
>>> mean( (x-mean(x)) ** 2 )            # two intermediate structures
>>> tmp=x-mean(x); tmp**=2; mean(tmp)   # one intermediate structure
  
That’s an e</p><p>6 0.59102029 <a title="179-lsi-6" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>7 0.5608995 <a title="179-lsi-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-05-19-conplot_%E2%80%93_a_console_plotter.html">103 brendan oconnor ai-2008-05-19-conplot – a console plotter</a></p>
<p>8 0.55203623 <a title="179-lsi-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-04-13-Are_women_discriminated_against_in_graduate_admissions%3F_Simpson%E2%80%99s_paradox_via_R_in_three_easy_steps%21.html">101 brendan oconnor ai-2008-04-13-Are women discriminated against in graduate admissions? Simpson’s paradox via R in three easy steps!</a></p>
<p>9 0.47502646 <a title="179-lsi-9" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-04-26-Replot%3A_departure_delays_vs_flight_time_speed-up.html">204 brendan oconnor ai-2014-04-26-Replot: departure delays vs flight time speed-up</a></p>
<p>10 0.45955208 <a title="179-lsi-10" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-14-R_scan%28%29_for_quick-and-dirty_checks.html">192 brendan oconnor ai-2013-03-14-R scan() for quick-and-dirty checks</a></p>
<p>11 0.44494039 <a title="179-lsi-11" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-04-16-Rise_and_fall_of_Dirichlet_process_clusters.html">194 brendan oconnor ai-2013-04-16-Rise and fall of Dirichlet process clusters</a></p>
<p>12 0.4314872 <a title="179-lsi-12" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-31-war_death_statistics.html">22 brendan oconnor ai-2005-07-31-war death statistics</a></p>
<p>13 0.42964822 <a title="179-lsi-13" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-idea%3A_Morals_are_heuristics_for_socially_optimal_behavior.html">6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</a></p>
<p>14 0.41698119 <a title="179-lsi-14" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>15 0.41138235 <a title="179-lsi-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>16 0.40327632 <a title="179-lsi-16" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-03-Supreme_Court_justices%E2%80%99_agreement_levels.html">13 brendan oconnor ai-2005-07-03-Supreme Court justices’ agreement levels</a></p>
<p>17 0.39890909 <a title="179-lsi-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-08-Game_outcome_graphs_%E2%80%94_prisoner%E2%80%99s_dilemma_with_FUN_ARROWS%21%21%21.html">68 brendan oconnor ai-2007-07-08-Game outcome graphs — prisoner’s dilemma with FUN ARROWS!!!</a></p>
<p>18 0.39740801 <a title="179-lsi-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>19 0.39543605 <a title="179-lsi-19" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>20 0.38975587 <a title="179-lsi-20" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-09-Simpson%E2%80%99s_paradox_is_so_totally_solved.html">60 brendan oconnor ai-2007-05-09-Simpson’s paradox is so totally solved</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(4, 0.436), (24, 0.063), (43, 0.041), (44, 0.147), (55, 0.014), (74, 0.192), (80, 0.017)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.97008985 <a title="179-lda-1" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-24-Python_bindings_to_Google%E2%80%99s_%E2%80%9CAJAX%E2%80%9D_Search_API.html">127 brendan oconnor ai-2008-11-24-Python bindings to Google’s “AJAX” Search API</a></p>
<p>Introduction: I couldn’t find this anywhere on the web, so I threw together a quick Python binding for  Google’s “AJAX” Search API  (or rather, JSON-over-HTTP).Â  (There are bindings out there for the old SOAP interface; I heard that was discontinued though.)
 
Nothing fancy but it works for me.Â  At:  gist.github.com/28405</p><p>same-blog 2 0.8872661 <a title="179-lda-2" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>Introduction: When possible, I like to use R for its really, really good statistical visualization capabilities.  I’m doing a modeling project in Python right now (R is too slow, bad at large data, bad at structured data, etc.), and in comparison to base R, the matplotlib library is just painful.  I wrote a toy  Metropolis  sampler for a  triangle distribution  and all I want to see is whether it looks like it’s working.  For the same dataset, here are histograms with default settings.  (Python:  pylab.hist(d) , R:  hist(d) )
 
   
 
I want to know whether my Metropolis sampler is working; those two plots give a very different idea.  Of course, you could say this is an unfair comparison, since matplotlib is only using 10 bins, while R is using 18 here — and it’s always important to vary the bin size a few times when looking at histograms.  But R’s defaults really are better: it actually uses an adaptive bin size, and the heuristic worked, choosing a reasonable number for the data.  The  hist()  manu</p><p>3 0.46065897 <a title="179-lda-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>4 0.45142326 <a title="179-lda-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>Introduction: Lukas  and I were trying to write a succinct comparison of the most popular packages that are typically used for data analysis.  I think most people choose one based on what people around them use or what they learn in school, so I’ve found it hard to find comparative information.  I’m posting the table here in hopes of useful comments.
  
 
 
  Name  
  Advantages  
  Disadvantages  
  Open source?  
  Typical   users  
 
 
 R 
 Library support; visualization 
 Steep learning curve 
 Yes 
 Finance; Statistics 
 
 
 Matlab 
 Elegant matrix support; visualization 
 Expensive; incomplete statistics support 
 No 
 Engineering 
 
 
 SciPy/NumPy/Matplotlib 
 Python (general-purpose programming language) 
 Immature 
 Yes 
 Engineering 
 
 
 Excel 
 Easy; visual; flexible 
 Large datasets 
 No 
 Business 
 
 
 SAS 
 Large datasets 
 Expensive; outdated programming language 
 No 
 Business; Government 
 
 
 Stata 
 Easy statistical analysis 
  
 No 
 Science 
 
 
 SPSS 
 Like Stata but more ex</p><p>5 0.44839028 <a title="179-lda-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>Introduction: This is a good idea: in a search engine’s query logs, look for outbreaks of queries like [[flu symptoms]] in a given region.  I’ve heard (from  Roddy ) that this trick also works well on Facebook statuses (e.g. “Feeling crappy this morning, think I just got the flu”).
  
  Google Uses Web Searches to Track Flu’s Spread – NYTimes.com  
  Google Flu Trends – google.org  
  
For an example with a publicly available data feed, these queries works decently well on Twitter search:
 
 [[ flu -shot -google ]]  (high recall)
 
 [[ "muscle aches" flu -shot ]]  (high precision)
     
 
The “muscle aches” query is too sparse and the general query is too noisy, but you could imagine some more tricks to clean it up, then train a classifier, etc.  With a bit more work it looks like geolocation information can be had out of the  Twitter search API .</p><p>6 0.43751794 <a title="179-lda-6" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>7 0.43298811 <a title="179-lda-7" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>8 0.42437619 <a title="179-lda-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>9 0.42169231 <a title="179-lda-9" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>10 0.4181532 <a title="179-lda-10" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>11 0.41740888 <a title="179-lda-11" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>12 0.41486993 <a title="179-lda-12" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>13 0.41470093 <a title="179-lda-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-05-Clinton-Obama_support_visualization.html">105 brendan oconnor ai-2008-06-05-Clinton-Obama support visualization</a></p>
<p>14 0.41402677 <a title="179-lda-14" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>15 0.41184169 <a title="179-lda-15" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>16 0.41142941 <a title="179-lda-16" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>17 0.41119307 <a title="179-lda-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>18 0.40888596 <a title="179-lda-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>19 0.40885517 <a title="179-lda-19" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>20 0.40275922 <a title="179-lda-20" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
