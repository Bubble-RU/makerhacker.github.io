<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>193 brendan oconnor ai-2013-03-18-Correlation picture</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2013" href="../home/brendan_oconnor_ai-2013_home.html">brendan_oconnor_ai-2013</a> <a title="brendan_oconnor_ai-2013-193" href="#">brendan_oconnor_ai-2013-193</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>193 brendan oconnor ai-2013-03-18-Correlation picture</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2013-193-html" href="http://brenocon.com/blog/2013/03/correlation-picture/">html</a></p><p>Introduction: Paul Moore  posted a comment pointing out this great discussion of the correlation coefficient:
  
 Joseph Lee Rodgers and W. Alan Nicewander.  “Thirteen Ways to Look at the Correlation Coefficient.” The American Statistician, Vol. 42, No. 1. (Feb., 1988), pp. 59-66.   Link  
  
It’s related to the the post on  cosine similarity, correlation and OLS .  Anyway, I was just struck by the following diagram.  It almost has a pop-art feel.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Paul Moore  posted a comment pointing out this great discussion of the correlation coefficient:     Joseph Lee Rodgers and W. [sent-1, score-1.115]
</p><p>2 Link      It’s related to the the post on  cosine similarity, correlation and OLS . [sent-10, score-1.047]
</p><p>3 Anyway, I was just struck by the following diagram. [sent-11, score-0.367]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('correlation', 0.587), ('struck', 0.23), ('statistician', 0.23), ('cosine', 0.23), ('ols', 0.23), ('joseph', 0.23), ('paul', 0.21), ('alan', 0.196), ('coefficient', 0.175), ('comment', 0.175), ('similarity', 0.175), ('american', 0.161), ('anyway', 0.155), ('discussion', 0.155), ('almost', 0.145), ('feel', 0.145), ('following', 0.137), ('related', 0.133), ('posted', 0.127), ('ways', 0.121), ('link', 0.102), ('post', 0.097), ('look', 0.094), ('great', 0.071)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="193-tfidf-1" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-18-Correlation_picture.html">193 brendan oconnor ai-2013-03-18-Correlation picture</a></p>
<p>Introduction: Paul Moore  posted a comment pointing out this great discussion of the correlation coefficient:
  
 Joseph Lee Rodgers and W. Alan Nicewander.  “Thirteen Ways to Look at the Correlation Coefficient.” The American Statistician, Vol. 42, No. 1. (Feb., 1988), pp. 59-66.   Link  
  
It’s related to the the post on  cosine similarity, correlation and OLS .  Anyway, I was just struck by the following diagram.  It almost has a pop-art feel.</p><p>2 0.20803343 <a title="193-tfidf-2" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-13-Cosine_similarity%2C_Pearson_correlation%2C_and_OLS_coefficients.html">182 brendan oconnor ai-2012-03-13-Cosine similarity, Pearson correlation, and OLS coefficients</a></p>
<p>Introduction: Cosine similarity, Pearson correlations, and OLS coefficients can all be viewed as variants on the inner product — tweaked in different ways for centering and magnitude (i.e. location and scale, or something like that).
 
Details:
 
You have two vectors \(x\) and \(y\) and want to measure similarity between them.  A basic similarity function is the   inner product  
 
\[ Inner(x,y) = \sum_i x_i y_i = \langle x, y \rangle \]
 
If x tends to be high where y is also high, and low where y is low, the inner product will be high — the vectors are more similar.
 
The inner product is unbounded.  One way to make it bounded between -1 and 1 is to divide by the vectors’ L2 norms, giving the   cosine similarity  
 
\[ CosSim(x,y) = \frac{\sum_i x_i y_i}{ \sqrt{ \sum_i x_i^2} \sqrt{ \sum_i y_i^2 } } 
= \frac{ \langle x,y \rangle }{ ||x||\ ||y|| } 
\]
 
This is actually bounded between 0 and 1 if x and y are non-negative.  Cosine similarity has an interpretation as the cosine of the angle between t</p><p>3 0.1596598 <a title="193-tfidf-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-11-It_is_accurate_to_determine_a_blog%E2%80%99s_bias_by_what_it_links_to.html">117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</a></p>
<p>Introduction: Here’s a great project from Andy Baio and Joshua Schachter : they assessed the political biases of different blogs based on which articles they tend link to.  Using these political bias scores, they made a cool little Firefox extension that colors the names of different sources on the news aggregator site  Memeorandum , like so:
 
 
 
How they computed these biases is pretty neat.  Their data source was the Memeorandum site itself, which shows a particular news story, then a list of different news sites that have written articles about the topic.  Scraping out that data, Joshua constructed the adjacency matrix of sites vs. articles they linked to and ran good ol’  SVD  on it, an algorithm that can be used to summarize the very high-dimensional article linking information in just several numbers (“components” or “dimensions”) for each news site.  Basically, the algorithm groups together sites that tend to link to the same articles.  It’s not exactly clustering though; rather, it project</p><p>4 0.10200381 <a title="193-tfidf-4" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-08-30-A_big%2C_fun_list_of_links_I%E2%80%99m_reading.html">44 brendan oconnor ai-2006-08-30-A big, fun list of links I’m reading</a></p>
<p>Introduction: Since blogging is hard, but reading is easy, lately I’ve taken to bookmarking interesting articles I’m reading, with the plan of blogging about them later.  This follow-through has happened a few times, but not that often.  In an amazing moment of thesis procrastination, today I sat down and figured out how to turn my  del.icio.us bookmarks  into a nice blogpost, with the plan that every week a post will appear with links I’ve recently read, or maybe I’ll use the script to generate a draft for myself that I’ll revise, or something.
 
But for this first such link post, I put in a whole bunch of them beyond just the last week — why have just a few when you could have *all* of them?  Future link posts will be shorter, I promise.
 
  Ariel Rubinstein: Freak-Freakonomics    July 2006   posted 8/19 under  economics   sarcastic, critical review of levitt & dubner’s Freakonomics 
  New Yorker review of Philip Tetlock’s book on political expert judgment   posted 8/19 under  judgment ,  psycholo</p><p>5 0.074084163 <a title="193-tfidf-5" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-08-Gapminder.org_%E2%80%94_terrific_world_data_visualizations.html">57 brendan oconnor ai-2007-04-08-Gapminder.org — terrific world data visualizations</a></p>
<p>Introduction: This entry was posted in  Uncategorized . Bookmark the  permalink .</p><p>6 0.055419061 <a title="193-tfidf-6" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>7 0.042872097 <a title="193-tfidf-7" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-02-21-Libertarianism_and_evolution_don%E2%80%99t_mix.html">30 brendan oconnor ai-2006-02-21-Libertarianism and evolution don’t mix</a></p>
<p>8 0.037160434 <a title="193-tfidf-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-11-Richard_Rorty_has_died.html">64 brendan oconnor ai-2007-06-11-Richard Rorty has died</a></p>
<p>9 0.036705002 <a title="193-tfidf-9" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-26-Good_linguistic_semantics_textbook%3F.html">172 brendan oconnor ai-2011-06-26-Good linguistic semantics textbook?</a></p>
<p>10 0.033123195 <a title="193-tfidf-10" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>11 0.030077713 <a title="193-tfidf-11" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-11-guns%2C_germs%2C_%26_steel_pbs_show%3F%21.html">20 brendan oconnor ai-2005-07-11-guns, germs, & steel pbs show?!</a></p>
<p>12 0.028597167 <a title="193-tfidf-12" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-12-The_Universal_Declaration_of_Human_Rights_Animated.html">118 brendan oconnor ai-2008-10-12-The Universal Declaration of Human Rights Animated</a></p>
<p>13 0.027131487 <a title="193-tfidf-13" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-04-11-F-scores%2C_Dice%2C_and_Jaccard_set_similarity.html">183 brendan oconnor ai-2012-04-11-F-scores, Dice, and Jaccard set similarity</a></p>
<p>14 0.026869774 <a title="193-tfidf-14" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-14-How_much_text_versus_metadata_is_in_a_tweet%3F.html">171 brendan oconnor ai-2011-06-14-How much text versus metadata is in a tweet?</a></p>
<p>15 0.026801905 <a title="193-tfidf-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-08-Blog_move_has_landed.html">115 brendan oconnor ai-2008-10-08-Blog move has landed</a></p>
<p>16 0.025990609 <a title="193-tfidf-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-27-Graphics%21_Atari_Breakout_and_religious_text_NLP.html">91 brendan oconnor ai-2008-01-27-Graphics! Atari Breakout and religious text NLP</a></p>
<p>17 0.025972854 <a title="193-tfidf-17" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>18 0.025780445 <a title="193-tfidf-18" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-1st_International_Conference_on_Computational_Models_of_Argument_%28COMMA06%29.html">5 brendan oconnor ai-2005-06-25-1st International Conference on Computational Models of Argument (COMMA06)</a></p>
<p>19 0.025058594 <a title="193-tfidf-19" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-07-20-neuroscience_and_economics_both_ways.html">41 brendan oconnor ai-2006-07-20-neuroscience and economics both ways</a></p>
<p>20 0.02460484 <a title="193-tfidf-20" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-06-28-Social_network-ized_economic_markets.html">40 brendan oconnor ai-2006-06-28-Social network-ized economic markets</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.08), (1, 0.003), (2, -0.028), (3, 0.1), (4, -0.029), (5, 0.098), (6, -0.062), (7, -0.055), (8, -0.087), (9, -0.089), (10, -0.054), (11, -0.176), (12, 0.097), (13, 0.072), (14, -0.098), (15, 0.066), (16, -0.034), (17, -0.071), (18, -0.019), (19, -0.079), (20, -0.126), (21, 0.057), (22, 0.079), (23, 0.028), (24, 0.072), (25, -0.185), (26, -0.039), (27, 0.216), (28, 0.042), (29, -0.132), (30, -0.001), (31, -0.213), (32, -0.135), (33, -0.117), (34, 0.101), (35, -0.068), (36, 0.016), (37, 0.032), (38, 0.061), (39, -0.088), (40, -0.079), (41, 0.106), (42, 0.061), (43, 0.009), (44, 0.175), (45, -0.059), (46, -0.089), (47, -0.082), (48, -0.008), (49, 0.084)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99617124 <a title="193-lsi-1" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-18-Correlation_picture.html">193 brendan oconnor ai-2013-03-18-Correlation picture</a></p>
<p>Introduction: Paul Moore  posted a comment pointing out this great discussion of the correlation coefficient:
  
 Joseph Lee Rodgers and W. Alan Nicewander.  “Thirteen Ways to Look at the Correlation Coefficient.” The American Statistician, Vol. 42, No. 1. (Feb., 1988), pp. 59-66.   Link  
  
It’s related to the the post on  cosine similarity, correlation and OLS .  Anyway, I was just struck by the following diagram.  It almost has a pop-art feel.</p><p>2 0.78079444 <a title="193-lsi-2" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-13-Cosine_similarity%2C_Pearson_correlation%2C_and_OLS_coefficients.html">182 brendan oconnor ai-2012-03-13-Cosine similarity, Pearson correlation, and OLS coefficients</a></p>
<p>Introduction: Cosine similarity, Pearson correlations, and OLS coefficients can all be viewed as variants on the inner product — tweaked in different ways for centering and magnitude (i.e. location and scale, or something like that).
 
Details:
 
You have two vectors \(x\) and \(y\) and want to measure similarity between them.  A basic similarity function is the   inner product  
 
\[ Inner(x,y) = \sum_i x_i y_i = \langle x, y \rangle \]
 
If x tends to be high where y is also high, and low where y is low, the inner product will be high — the vectors are more similar.
 
The inner product is unbounded.  One way to make it bounded between -1 and 1 is to divide by the vectors’ L2 norms, giving the   cosine similarity  
 
\[ CosSim(x,y) = \frac{\sum_i x_i y_i}{ \sqrt{ \sum_i x_i^2} \sqrt{ \sum_i y_i^2 } } 
= \frac{ \langle x,y \rangle }{ ||x||\ ||y|| } 
\]
 
This is actually bounded between 0 and 1 if x and y are non-negative.  Cosine similarity has an interpretation as the cosine of the angle between t</p><p>3 0.60568261 <a title="193-lsi-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-11-It_is_accurate_to_determine_a_blog%E2%80%99s_bias_by_what_it_links_to.html">117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</a></p>
<p>Introduction: Here’s a great project from Andy Baio and Joshua Schachter : they assessed the political biases of different blogs based on which articles they tend link to.  Using these political bias scores, they made a cool little Firefox extension that colors the names of different sources on the news aggregator site  Memeorandum , like so:
 
 
 
How they computed these biases is pretty neat.  Their data source was the Memeorandum site itself, which shows a particular news story, then a list of different news sites that have written articles about the topic.  Scraping out that data, Joshua constructed the adjacency matrix of sites vs. articles they linked to and ran good ol’  SVD  on it, an algorithm that can be used to summarize the very high-dimensional article linking information in just several numbers (“components” or “dimensions”) for each news site.  Basically, the algorithm groups together sites that tend to link to the same articles.  It’s not exactly clustering though; rather, it project</p><p>4 0.43842748 <a title="193-lsi-4" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-04-11-F-scores%2C_Dice%2C_and_Jaccard_set_similarity.html">183 brendan oconnor ai-2012-04-11-F-scores, Dice, and Jaccard set similarity</a></p>
<p>Introduction: The  Dice similarity  is the same as  F1-score ; and they are monotonic in  Jaccard similarity .  I worked this out recently but couldn’t find anything about it online so here’s a writeup.
 
Let \(A\) be the set of found items, and \(B\) the set of wanted items.  \(Prec=|AB|/|A|\), \(Rec=|AB|/|B|\).  Their harmonic mean, the \(F1\)-measure, is the same as the Dice coefficient: 
\begin{align*} 
F1(A,B) 
&= \frac{2}{1/P+ 1/R} 
 = \frac{2}{|A|/|AB| + |B|/|AB|} \\ 
Dice(A,B) 
&= \frac{2|AB|}{ |A| + |B| } \\ 
&= \frac{2 |AB|}{ (|AB| + |A \setminus B|) + (|AB| + |B \setminus A|)} \\ 
&= \frac{|AB|}{|AB| + \frac{1}{2}|A \setminus B| + \frac{1}{2} |B \setminus A|} 
\end{align*}
 
It’s nice to characterize the set comparison into the three mutually exclusive partitions \(AB\), \(A \setminus B\), and \(B \setminus A\).  This illustrates Dice’s close relationship to the Jaccard metric, 
\begin{align*} 
Jacc(A,B) 
&= \frac{|AB|}{|A \cup B|} \\ 
&= \frac{|AB|}{|AB| + |A \setminus B| + |B \setminus</p><p>5 0.33813378 <a title="193-lsi-5" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-08-30-A_big%2C_fun_list_of_links_I%E2%80%99m_reading.html">44 brendan oconnor ai-2006-08-30-A big, fun list of links I’m reading</a></p>
<p>Introduction: Since blogging is hard, but reading is easy, lately I’ve taken to bookmarking interesting articles I’m reading, with the plan of blogging about them later.  This follow-through has happened a few times, but not that often.  In an amazing moment of thesis procrastination, today I sat down and figured out how to turn my  del.icio.us bookmarks  into a nice blogpost, with the plan that every week a post will appear with links I’ve recently read, or maybe I’ll use the script to generate a draft for myself that I’ll revise, or something.
 
But for this first such link post, I put in a whole bunch of them beyond just the last week — why have just a few when you could have *all* of them?  Future link posts will be shorter, I promise.
 
  Ariel Rubinstein: Freak-Freakonomics    July 2006   posted 8/19 under  economics   sarcastic, critical review of levitt & dubner’s Freakonomics 
  New Yorker review of Philip Tetlock’s book on political expert judgment   posted 8/19 under  judgment ,  psycholo</p><p>6 0.30110016 <a title="193-lsi-6" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-08-Gapminder.org_%E2%80%94_terrific_world_data_visualizations.html">57 brendan oconnor ai-2007-04-08-Gapminder.org — terrific world data visualizations</a></p>
<p>7 0.22100064 <a title="193-lsi-7" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-08-Washington_in_1774.html">69 brendan oconnor ai-2007-07-08-Washington in 1774</a></p>
<p>8 0.21216625 <a title="193-lsi-8" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-02-21-Libertarianism_and_evolution_don%E2%80%99t_mix.html">30 brendan oconnor ai-2006-02-21-Libertarianism and evolution don’t mix</a></p>
<p>9 0.21000779 <a title="193-lsi-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-12-The_Universal_Declaration_of_Human_Rights_Animated.html">118 brendan oconnor ai-2008-10-12-The Universal Declaration of Human Rights Animated</a></p>
<p>10 0.19655511 <a title="193-lsi-10" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-09-Race_and_IQ_debate_%E2%80%93_links.html">85 brendan oconnor ai-2007-12-09-Race and IQ debate – links</a></p>
<p>11 0.19268784 <a title="193-lsi-11" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>12 0.19132179 <a title="193-lsi-12" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-14-How_much_text_versus_metadata_is_in_a_tweet%3F.html">171 brendan oconnor ai-2011-06-14-How much text versus metadata is in a tweet?</a></p>
<p>13 0.1722593 <a title="193-lsi-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-11-Richard_Rorty_has_died.html">64 brendan oconnor ai-2007-06-11-Richard Rorty has died</a></p>
<p>14 0.16813043 <a title="193-lsi-14" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-11-guns%2C_germs%2C_%26_steel_pbs_show%3F%21.html">20 brendan oconnor ai-2005-07-11-guns, germs, & steel pbs show?!</a></p>
<p>15 0.15647341 <a title="193-lsi-15" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-13-Bayes_update_view_of_pointwise_mutual_information.html">178 brendan oconnor ai-2011-11-13-Bayes update view of pointwise mutual information</a></p>
<p>16 0.14294183 <a title="193-lsi-16" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-08-01-searchin%E2%80%99_for_our_friend%2C_homo_economicus.html">24 brendan oconnor ai-2005-08-01-searchin’ for our friend, homo economicus</a></p>
<p>17 0.14252914 <a title="193-lsi-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-09-18-%22Machine%22_translation-vision_%28Stanford_AI_courses_online%29.html">113 brendan oconnor ai-2008-09-18-"Machine" translation-vision (Stanford AI courses online)</a></p>
<p>18 0.12781514 <a title="193-lsi-18" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-09-Simpson%E2%80%99s_paradox_is_so_totally_solved.html">60 brendan oconnor ai-2007-05-09-Simpson’s paradox is so totally solved</a></p>
<p>19 0.12701097 <a title="193-lsi-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-04-02-Datawocky%3A_More_data_usually_beats_better_algorithms.html">99 brendan oconnor ai-2008-04-02-Datawocky: More data usually beats better algorithms</a></p>
<p>20 0.12290122 <a title="193-lsi-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-05-19-conplot_%E2%80%93_a_console_plotter.html">103 brendan oconnor ai-2008-05-19-conplot – a console plotter</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(3, 0.763), (44, 0.053)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96227294 <a title="193-lda-1" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-18-Correlation_picture.html">193 brendan oconnor ai-2013-03-18-Correlation picture</a></p>
<p>Introduction: Paul Moore  posted a comment pointing out this great discussion of the correlation coefficient:
  
 Joseph Lee Rodgers and W. Alan Nicewander.  “Thirteen Ways to Look at the Correlation Coefficient.” The American Statistician, Vol. 42, No. 1. (Feb., 1988), pp. 59-66.   Link  
  
It’s related to the the post on  cosine similarity, correlation and OLS .  Anyway, I was just struck by the following diagram.  It almost has a pop-art feel.</p><p>2 0.92037529 <a title="193-lda-2" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-04-28-Easterly_vs._Sachs_on_global_poverty.html">35 brendan oconnor ai-2006-04-28-Easterly vs. Sachs on global poverty</a></p>
<p>Introduction: I started reading Jeffrey Sachs’ new book  The End of Poverty .  The first 30 pages are excellent, but it starts getting arrogant and annoying quick.  Substantively, I’m uncertain whether a big new development aid push will solve things.
 
Since I enthusiastically bum around course websites I’m not taking (bad habit, will stop real soon now), I was fortunate to run across an excellent debate between Sachs and William Easterly:
 
 Easterly’s view on Africa: The West Can’t Take The Lead  which has some amazing anecdotes about African educators and entrepreneurs.  (Or, I think they’re amazing only because I’m a condescending Westerner?)
 
 Easterly reviews Sachs .  Choice quote: 
 “Success in ending the poverty trap,” Sachs writes, “will be much easier than it appears.” Really? If it’s so easy, why haven’t five decades of effort gotten the job done? Sachs should redirect some of his outrage at the question of why the previous $2.3 trillion didn’t reach the poor so that the next $2.3 trill</p><p>3 0.85611391 <a title="193-lda-3" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-04-City_crisis_simulation_%28e.g._terrorist_attack%29.html">14 brendan oconnor ai-2005-07-04-City crisis simulation (e.g. terrorist attack)</a></p>
<p>Introduction: WP:  Computers simulate terrorist extremes 
 
Los Alamos scientists are running terrorist attack/response simulations. Well, the article title is misleading, they’re not simulating terrorists (which would pose a whole set of interesting questions about scientific knowledge, social construction and security), but rather, the impact on telecomm, health, and infrastructure systems.  They’re using the standard justifications for systems simulation: these are big, highly complex, highly interdependent systems that are ill-understood and have had drastic domino-effect collapses before (like the northeast power blackout).
 
The article also talks about epidemiology simulations (smallpox in this case, following the terrorist scenario again) that take into account the interactions of individual people with each other — very much along the lines of agent-based simulations, and satisfying complexity theory’s arguments about tipping points and emergent effects.  [The article doesn't seem to say wh</p><p>4 0.098989502 <a title="193-lda-4" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-13-Cosine_similarity%2C_Pearson_correlation%2C_and_OLS_coefficients.html">182 brendan oconnor ai-2012-03-13-Cosine similarity, Pearson correlation, and OLS coefficients</a></p>
<p>Introduction: Cosine similarity, Pearson correlations, and OLS coefficients can all be viewed as variants on the inner product — tweaked in different ways for centering and magnitude (i.e. location and scale, or something like that).
 
Details:
 
You have two vectors \(x\) and \(y\) and want to measure similarity between them.  A basic similarity function is the   inner product  
 
\[ Inner(x,y) = \sum_i x_i y_i = \langle x, y \rangle \]
 
If x tends to be high where y is also high, and low where y is low, the inner product will be high — the vectors are more similar.
 
The inner product is unbounded.  One way to make it bounded between -1 and 1 is to divide by the vectors’ L2 norms, giving the   cosine similarity  
 
\[ CosSim(x,y) = \frac{\sum_i x_i y_i}{ \sqrt{ \sum_i x_i^2} \sqrt{ \sum_i y_i^2 } } 
= \frac{ \langle x,y \rangle }{ ||x||\ ||y|| } 
\]
 
This is actually bounded between 0 and 1 if x and y are non-negative.  Cosine similarity has an interpretation as the cosine of the angle between t</p><p>5 0.089224026 <a title="193-lda-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-11-It_is_accurate_to_determine_a_blog%E2%80%99s_bias_by_what_it_links_to.html">117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</a></p>
<p>Introduction: Here’s a great project from Andy Baio and Joshua Schachter : they assessed the political biases of different blogs based on which articles they tend link to.  Using these political bias scores, they made a cool little Firefox extension that colors the names of different sources on the news aggregator site  Memeorandum , like so:
 
 
 
How they computed these biases is pretty neat.  Their data source was the Memeorandum site itself, which shows a particular news story, then a list of different news sites that have written articles about the topic.  Scraping out that data, Joshua constructed the adjacency matrix of sites vs. articles they linked to and ran good ol’  SVD  on it, an algorithm that can be used to summarize the very high-dimensional article linking information in just several numbers (“components” or “dimensions”) for each news site.  Basically, the algorithm groups together sites that tend to link to the same articles.  It’s not exactly clustering though; rather, it project</p><p>6 0.068962581 <a title="193-lda-6" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-03-18-Mark_Turner%3A_Toward_the_Founding_of_Cognitive_Social_Science.html">31 brendan oconnor ai-2006-03-18-Mark Turner: Toward the Founding of Cognitive Social Science</a></p>
<p>7 0.068962581 <a title="193-lda-7" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-10-13-Verificationism_dinosaur_comics.html">79 brendan oconnor ai-2007-10-13-Verificationism dinosaur comics</a></p>
<p>8 0.068922207 <a title="193-lda-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-08-Blog_move_has_landed.html">115 brendan oconnor ai-2008-10-08-Blog move has landed</a></p>
<p>9 0.06879878 <a title="193-lda-9" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-09-I_don%E2%80%99t_get_this_web_parsing_shared_task.html">181 brendan oconnor ai-2012-03-09-I don’t get this web parsing shared task</a></p>
<p>10 0.06554608 <a title="193-lda-10" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>11 0.063940041 <a title="193-lda-11" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>12 0.061731726 <a title="193-lda-12" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-10-05-Be_careful_with_dictionary-based_text_analysis.html">176 brendan oconnor ai-2011-10-05-Be careful with dictionary-based text analysis</a></p>
<p>13 0.057353642 <a title="193-lda-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">153 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>14 0.053291038 <a title="193-lda-14" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-09-21-CMU_ARK_Twitter_Part-of-Speech_Tagger_%E2%80%93_v0.3_released.html">187 brendan oconnor ai-2012-09-21-CMU ARK Twitter Part-of-Speech Tagger – v0.3 released</a></p>
<p>15 0.048337534 <a title="193-lda-15" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-03-26-new_kind_of_science%2C_for_real.html">32 brendan oconnor ai-2006-03-26-new kind of science, for real</a></p>
<p>16 0.046117738 <a title="193-lda-16" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>17 0.046043154 <a title="193-lda-17" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>18 0.045946922 <a title="193-lda-18" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-18-Turker_classifiers_and_binary_classification_threshold_calibration.html">107 brendan oconnor ai-2008-06-18-Turker classifiers and binary classification threshold calibration</a></p>
<p>19 0.044346746 <a title="193-lda-19" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>20 0.043462276 <a title="193-lda-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
