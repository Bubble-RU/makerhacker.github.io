<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2009" href="../home/brendan_oconnor_ai-2009_home.html">brendan_oconnor_ai-2009</a> <a title="brendan_oconnor_ai-2009-140" href="#">brendan_oconnor_ai-2009-140</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2009-140-html" href="http://brenocon.com/blog/2009/05/announcing-tweetmotif-for-summarizing-twitter-topics-with-a-dash-of-nlp/">html</a></p><p>Introduction: Update  (3/14/2010): There is now a  TweetMotif paper . 
 
Last week, I, with my awesome friends  David Ahn and Mike Krieger , finished hacking together an experimental prototype,  TweetMotif , for exploratory search on Twitter.  If you want to know what people are thinking about something, the normal search interface  search.twitter.com  gives really cool information, but it’s hard to wade through hundreds or thousands of results.  We take tweets matching a query and group together similar messages, showing significant terms and phrases  that co-occur with the user query.  Try it out at  tweetmotif.com .  Here’s an example for a current hot topic,  #WolframAlpha :
 
    
   
 
It’s currently showing tweets that match both  #WolframAlpha  as well as two interesting bigrams: “queries failed” and “google killer”.  TweetMotif doesn’t attempt to derive the meaning or sentiment toward the phrases — NLP is hard, and doing this much is hard enough! — but it’s easy for you to look at the tweet</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Last week, I, with my awesome friends  David Ahn and Mike Krieger , finished hacking together an experimental prototype,  TweetMotif , for exploratory search on Twitter. [sent-2, score-0.39]
</p><p>2 If you want to know what people are thinking about something, the normal search interface  search. [sent-3, score-0.217]
</p><p>3 com  gives really cool information, but it’s hard to wade through hundreds or thousands of results. [sent-5, score-0.304]
</p><p>4 We take tweets matching a query and group together similar messages, showing significant terms and phrases  that co-occur with the user query. [sent-6, score-0.742]
</p><p>5 Here’s an example for a current hot topic,  #WolframAlpha :              It’s currently showing tweets that match both  #WolframAlpha  as well as two interesting bigrams: “queries failed” and “google killer”. [sent-9, score-0.767]
</p><p>6 TweetMotif doesn’t attempt to derive the meaning or sentiment toward the phrases — NLP is hard, and doing this much is hard enough! [sent-10, score-0.534]
</p><p>7 — but it’s easy for you to look at the tweets themselves and figure out what’s going on. [sent-11, score-0.208]
</p><p>8 Here’s another fun example right now, a query for  Dollhouse :              I love that the #wolframalpha topic has “infected” the dollhouse space. [sent-12, score-0.405]
</p><p>9 Someone pointed out a connection between them, but really they’re connected through bot spam. [sent-13, score-0.144]
</p><p>10 TweetMotif’s duplicate detection algorithm found 22 messages here where each is basically a list of all the trending topics. [sent-14, score-0.25]
</p><p>11 I learned a ton making this system, and I’ll try to write more about the technical details in a future post. [sent-16, score-0.236]
</p><p>12 It’s interesting to hear people speculate on how it works; everyone gives a different answer. [sent-17, score-0.273]
</p><p>13 There are lots of interesting TweetMotif examples. [sent-19, score-0.097]
</p><p>14 More prosaic, less news-y queries like  sandwich  yield cool things like major ingredients of sandwiches and types of sandwiches. [sent-20, score-0.394]
</p><p>15 (These are basically distributional similarity candidates for synonym and meronym acquisition, though a bit too noisy to use in its current form. [sent-21, score-0.217]
</p><p>16 )  And in a few cases, like for understanding currently unfolding events, TweetMotif might even be useful! [sent-22, score-0.131]
</p><p>17 It would be nice to expand the set of usefully served queries. [sent-23, score-0.232]
</p><p>18 We’re occasionally posting interesting queries at  twitter. [sent-24, score-0.403]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tweetmotif', 0.49), ('wolframalpha', 0.282), ('queries', 0.224), ('tweets', 0.208), ('dollhouse', 0.188), ('prototype', 0.188), ('phrases', 0.139), ('currently', 0.131), ('interface', 0.131), ('basically', 0.125), ('messages', 0.125), ('query', 0.125), ('hard', 0.109), ('gives', 0.107), ('together', 0.1), ('interesting', 0.097), ('try', 0.095), ('showing', 0.095), ('topic', 0.092), ('current', 0.092), ('cool', 0.088), ('search', 0.086), ('yield', 0.082), ('occasionally', 0.082), ('toward', 0.082), ('served', 0.082), ('connected', 0.075), ('hot', 0.075), ('expand', 0.075), ('beautiful', 0.075), ('usefully', 0.075), ('matching', 0.075), ('failed', 0.075), ('acquisition', 0.075), ('ton', 0.075), ('iphone', 0.075), ('meaning', 0.069), ('events', 0.069), ('finished', 0.069), ('connection', 0.069), ('match', 0.069), ('sentiment', 0.069), ('hear', 0.069), ('exploratory', 0.069), ('mike', 0.069), ('friends', 0.066), ('cases', 0.066), ('oh', 0.066), ('attempt', 0.066), ('technical', 0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="140-tfidf-1" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<p>Introduction: Update  (3/14/2010): There is now a  TweetMotif paper . 
 
Last week, I, with my awesome friends  David Ahn and Mike Krieger , finished hacking together an experimental prototype,  TweetMotif , for exploratory search on Twitter.  If you want to know what people are thinking about something, the normal search interface  search.twitter.com  gives really cool information, but it’s hard to wade through hundreds or thousands of results.  We take tweets matching a query and group together similar messages, showing significant terms and phrases  that co-occur with the user query.  Try it out at  tweetmotif.com .  Here’s an example for a current hot topic,  #WolframAlpha :
 
    
   
 
It’s currently showing tweets that match both  #WolframAlpha  as well as two interesting bigrams: “queries failed” and “google killer”.  TweetMotif doesn’t attempt to derive the meaning or sentiment toward the phrases — NLP is hard, and doing this much is hard enough! — but it’s easy for you to look at the tweet</p><p>2 0.14287996 <a title="140-tfidf-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-27-Where_tweets_get_sent_from.html">142 brendan oconnor ai-2009-05-27-Where tweets get sent from</a></p>
<p>Introduction: Playing around with  stream.twitter.com/spritzer ,  ggplot2  and  maps / mapdata :
 
   
 
I think I like the top better, without the map lines, like those  night satellite photos : pointwise ghosts of high-end human economic development.
 
This data is a fairly extreme sample of convenience: I’m only looking at tweets posted by certain types of iPhone clients, because they conveniently report exact gps-derived latitude/longitude numbers.  ( search.twitter.com  has geographic proximity operators — which are very cool! — but they seem to usually use zip codes or other user information that’s not available in the per-tweet API data.)  So there’s only 30,000 messages out of 1.2 million  spritzer  tweets over ~3 days (itself only a small single-digit percentage sample of twitter).</p><p>3 0.11762775 <a title="140-tfidf-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>Introduction: I’m a bit late blogging this, but here’s a messy, exciting — and statistically validated! — new online data source.
 
My friend  Roddy  at Facebook  wrote a post describing their sentiment analysis system , which can evaluate positive or negative sentiment toward a particular topic by looking at a large number of wall messages.  (I’d link to it, but I can’t find the URL anymore — here’s the  Lexicon , but that version only gets term frequencies but no sentiment.)
 
How they constructed their sentiment detector is interesting.  Starting with a list of positive and negative terms, they had a lexical acquisition step to gather many more candidate synonyms and misspellings — a necessity in this social media domain, where  WordNet  ain’t gonna come close!  After manually filtering these candidates, they assess the sentiment toward a mention of a topic by looking for instances of these positive and negative words nearby, along with “negation heuristics” and a few other features.
 
He describ</p><p>4 0.11667918 <a title="140-tfidf-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>Introduction: This is a good idea: in a search engine’s query logs, look for outbreaks of queries like [[flu symptoms]] in a given region.  I’ve heard (from  Roddy ) that this trick also works well on Facebook statuses (e.g. “Feeling crappy this morning, think I just got the flu”).
  
  Google Uses Web Searches to Track Flu’s Spread – NYTimes.com  
  Google Flu Trends – google.org  
  
For an example with a publicly available data feed, these queries works decently well on Twitter search:
 
 [[ flu -shot -google ]]  (high recall)
 
 [[ "muscle aches" flu -shot ]]  (high precision)
     
 
The “muscle aches” query is too sparse and the general query is too noisy, but you could imagine some more tricks to clean it up, then train a classifier, etc.  With a bit more work it looks like geolocation information can be had out of the  Twitter search API .</p><p>5 0.10166489 <a title="140-tfidf-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-09-30-PalinSpeak.com.html">114 brendan oconnor ai-2008-09-30-PalinSpeak.com</a></p>
<p>Introduction: With my friend  Doug , I just finished making a game —   PalinSpeak.com   —  where you can chat with a Sarah Palin simulator.  Check it out, it’s the best thing to hit the Internet since sliced bread.
 
   
 
I’ll post more the technical details (n-gram generation and query-answer matching, hurrah!) later…</p><p>6 0.088784844 <a title="140-tfidf-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-24-Python_bindings_to_Google%E2%80%99s_%E2%80%9CAJAX%E2%80%9D_Search_API.html">127 brendan oconnor ai-2008-11-24-Python bindings to Google’s “AJAX” Search API</a></p>
<p>7 0.083462171 <a title="140-tfidf-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>8 0.078577757 <a title="140-tfidf-8" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>9 0.072046548 <a title="140-tfidf-9" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-04-22-Updates%3A_CMU%2C_Facebook.html">160 brendan oconnor ai-2010-04-22-Updates: CMU, Facebook</a></p>
<p>10 0.068374939 <a title="140-tfidf-10" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-09-21-CMU_ARK_Twitter_Part-of-Speech_Tagger_%E2%80%93_v0.3_released.html">187 brendan oconnor ai-2012-09-21-CMU ARK Twitter Part-of-Speech Tagger – v0.3 released</a></p>
<p>11 0.068308279 <a title="140-tfidf-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>12 0.067472741 <a title="140-tfidf-12" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-08-Random_search_engine_searcher.html">59 brendan oconnor ai-2007-04-08-Random search engine searcher</a></p>
<p>13 0.067218937 <a title="140-tfidf-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>14 0.064033806 <a title="140-tfidf-14" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-08-27-CMU_Twitter_Part-of-Speech_tagger_0.2.html">173 brendan oconnor ai-2011-08-27-CMU Twitter Part-of-Speech tagger 0.2</a></p>
<p>15 0.063944243 <a title="140-tfidf-15" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>16 0.062727362 <a title="140-tfidf-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-Netflix_Prize.html">125 brendan oconnor ai-2008-11-21-Netflix Prize</a></p>
<p>17 0.062072888 <a title="140-tfidf-17" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-20-Log-normal_and_logistic-normal_terminology.html">169 brendan oconnor ai-2011-05-20-Log-normal and logistic-normal terminology</a></p>
<p>18 0.06201588 <a title="140-tfidf-18" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>19 0.058643423 <a title="140-tfidf-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-05-13-The_best_natural_language_search_commentary_on_the_internet.html">102 brendan oconnor ai-2008-05-13-The best natural language search commentary on the internet</a></p>
<p>20 0.058214061 <a title="140-tfidf-20" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-19-End-to-end_NLP_packages.html">174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.221), (1, -0.143), (2, -0.002), (3, 0.098), (4, -0.039), (5, -0.123), (6, 0.111), (7, 0.018), (8, -0.07), (9, 0.04), (10, -0.125), (11, 0.062), (12, 0.074), (13, -0.111), (14, -0.064), (15, 0.004), (16, 0.049), (17, -0.083), (18, -0.027), (19, 0.04), (20, -0.095), (21, 0.053), (22, -0.003), (23, 0.06), (24, -0.038), (25, -0.072), (26, 0.006), (27, -0.134), (28, 0.094), (29, 0.045), (30, 0.039), (31, 0.019), (32, 0.142), (33, -0.073), (34, 0.077), (35, -0.052), (36, -0.116), (37, -0.025), (38, 0.001), (39, -0.006), (40, -0.134), (41, 0.042), (42, -0.027), (43, -0.006), (44, -0.044), (45, 0.114), (46, -0.059), (47, -0.051), (48, -0.019), (49, -0.0)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98181963 <a title="140-lsi-1" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<p>Introduction: Update  (3/14/2010): There is now a  TweetMotif paper . 
 
Last week, I, with my awesome friends  David Ahn and Mike Krieger , finished hacking together an experimental prototype,  TweetMotif , for exploratory search on Twitter.  If you want to know what people are thinking about something, the normal search interface  search.twitter.com  gives really cool information, but it’s hard to wade through hundreds or thousands of results.  We take tweets matching a query and group together similar messages, showing significant terms and phrases  that co-occur with the user query.  Try it out at  tweetmotif.com .  Here’s an example for a current hot topic,  #WolframAlpha :
 
    
   
 
It’s currently showing tweets that match both  #WolframAlpha  as well as two interesting bigrams: “queries failed” and “google killer”.  TweetMotif doesn’t attempt to derive the meaning or sentiment toward the phrases — NLP is hard, and doing this much is hard enough! — but it’s easy for you to look at the tweet</p><p>2 0.68319935 <a title="140-lsi-2" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>Introduction: This is a good idea: in a search engine’s query logs, look for outbreaks of queries like [[flu symptoms]] in a given region.  I’ve heard (from  Roddy ) that this trick also works well on Facebook statuses (e.g. “Feeling crappy this morning, think I just got the flu”).
  
  Google Uses Web Searches to Track Flu’s Spread – NYTimes.com  
  Google Flu Trends – google.org  
  
For an example with a publicly available data feed, these queries works decently well on Twitter search:
 
 [[ flu -shot -google ]]  (high recall)
 
 [[ "muscle aches" flu -shot ]]  (high precision)
     
 
The “muscle aches” query is too sparse and the general query is too noisy, but you could imagine some more tricks to clean it up, then train a classifier, etc.  With a bit more work it looks like geolocation information can be had out of the  Twitter search API .</p><p>3 0.54685587 <a title="140-lsi-3" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-27-Where_tweets_get_sent_from.html">142 brendan oconnor ai-2009-05-27-Where tweets get sent from</a></p>
<p>Introduction: Playing around with  stream.twitter.com/spritzer ,  ggplot2  and  maps / mapdata :
 
   
 
I think I like the top better, without the map lines, like those  night satellite photos : pointwise ghosts of high-end human economic development.
 
This data is a fairly extreme sample of convenience: I’m only looking at tweets posted by certain types of iPhone clients, because they conveniently report exact gps-derived latitude/longitude numbers.  ( search.twitter.com  has geographic proximity operators — which are very cool! — but they seem to usually use zip codes or other user information that’s not available in the per-tweet API data.)  So there’s only 30,000 messages out of 1.2 million  spritzer  tweets over ~3 days (itself only a small single-digit percentage sample of twitter).</p><p>4 0.50443721 <a title="140-lsi-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-24-Python_bindings_to_Google%E2%80%99s_%E2%80%9CAJAX%E2%80%9D_Search_API.html">127 brendan oconnor ai-2008-11-24-Python bindings to Google’s “AJAX” Search API</a></p>
<p>Introduction: I couldn’t find this anywhere on the web, so I threw together a quick Python binding for  Google’s “AJAX” Search API  (or rather, JSON-over-HTTP).Â  (There are bindings out there for the old SOAP interface; I heard that was discontinued though.)
 
Nothing fancy but it works for me.Â  At:  gist.github.com/28405</p><p>5 0.48571828 <a title="140-lsi-5" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-08-Random_search_engine_searcher.html">59 brendan oconnor ai-2007-04-08-Random search engine searcher</a></p>
<p>Introduction: It’s sweeping the internet  — I wrote a little plugin for the firefox/internet explorer search box, so when you search it randomly picks one of several search engines.  You get to see what’s out there (you mean there’s something besides Google?) in your daily searching.
 
 Search a Random Search Engine</p><p>6 0.40159503 <a title="140-lsi-6" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-02-%24_echo_%7Bpolitical%2Csocial%2Ceconomic%7D%7Bcognition%2Cbehavior%2Csystems%7D.html">12 brendan oconnor ai-2005-07-02-$ echo {political,social,economic}{cognition,behavior,systems}</a></p>
<p>7 0.3835097 <a title="140-lsi-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>8 0.37618887 <a title="140-lsi-8" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-31-war_death_statistics.html">22 brendan oconnor ai-2005-07-31-war death statistics</a></p>
<p>9 0.37129679 <a title="140-lsi-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-27-Graphics%21_Atari_Breakout_and_religious_text_NLP.html">91 brendan oconnor ai-2008-01-27-Graphics! Atari Breakout and religious text NLP</a></p>
<p>10 0.36672333 <a title="140-lsi-10" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>11 0.362652 <a title="140-lsi-11" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-09-30-PalinSpeak.com.html">114 brendan oconnor ai-2008-09-30-PalinSpeak.com</a></p>
<p>12 0.36235788 <a title="140-lsi-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>13 0.33678675 <a title="140-lsi-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>14 0.32777995 <a title="140-lsi-14" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-15-Pirates_killed_by_President.html">137 brendan oconnor ai-2009-04-15-Pirates killed by President</a></p>
<p>15 0.32677636 <a title="140-lsi-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>16 0.31988883 <a title="140-lsi-16" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-22-FFT%3A_Friedman_%2B_Fortran_%2B_Tricks.html">147 brendan oconnor ai-2009-07-22-FFT: Friedman + Fortran + Tricks</a></p>
<p>17 0.31796619 <a title="140-lsi-17" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>18 0.31600118 <a title="140-lsi-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>19 0.31239623 <a title="140-lsi-19" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-03-31-How_Facebook_privacy_failed_me.html">158 brendan oconnor ai-2010-03-31-How Facebook privacy failed me</a></p>
<p>20 0.30791944 <a title="140-lsi-20" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-08-05-Are_ideas_interesting%2C_or_are_they_true%3F.html">73 brendan oconnor ai-2007-08-05-Are ideas interesting, or are they true?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.078), (22, 0.026), (24, 0.045), (44, 0.147), (55, 0.019), (70, 0.059), (74, 0.139), (89, 0.397)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96783221 <a title="140-lda-1" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-04-11-F-scores%2C_Dice%2C_and_Jaccard_set_similarity.html">183 brendan oconnor ai-2012-04-11-F-scores, Dice, and Jaccard set similarity</a></p>
<p>Introduction: The  Dice similarity  is the same as  F1-score ; and they are monotonic in  Jaccard similarity .  I worked this out recently but couldn’t find anything about it online so here’s a writeup.
 
Let \(A\) be the set of found items, and \(B\) the set of wanted items.  \(Prec=|AB|/|A|\), \(Rec=|AB|/|B|\).  Their harmonic mean, the \(F1\)-measure, is the same as the Dice coefficient: 
\begin{align*} 
F1(A,B) 
&= \frac{2}{1/P+ 1/R} 
 = \frac{2}{|A|/|AB| + |B|/|AB|} \\ 
Dice(A,B) 
&= \frac{2|AB|}{ |A| + |B| } \\ 
&= \frac{2 |AB|}{ (|AB| + |A \setminus B|) + (|AB| + |B \setminus A|)} \\ 
&= \frac{|AB|}{|AB| + \frac{1}{2}|A \setminus B| + \frac{1}{2} |B \setminus A|} 
\end{align*}
 
It’s nice to characterize the set comparison into the three mutually exclusive partitions \(AB\), \(A \setminus B\), and \(B \setminus A\).  This illustrates Dice’s close relationship to the Jaccard metric, 
\begin{align*} 
Jacc(A,B) 
&= \frac{|AB|}{|A \cup B|} \\ 
&= \frac{|AB|}{|AB| + |A \setminus B| + |B \setminus</p><p>same-blog 2 0.8830598 <a title="140-lda-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<p>Introduction: Update  (3/14/2010): There is now a  TweetMotif paper . 
 
Last week, I, with my awesome friends  David Ahn and Mike Krieger , finished hacking together an experimental prototype,  TweetMotif , for exploratory search on Twitter.  If you want to know what people are thinking about something, the normal search interface  search.twitter.com  gives really cool information, but it’s hard to wade through hundreds or thousands of results.  We take tweets matching a query and group together similar messages, showing significant terms and phrases  that co-occur with the user query.  Try it out at  tweetmotif.com .  Here’s an example for a current hot topic,  #WolframAlpha :
 
    
   
 
It’s currently showing tweets that match both  #WolframAlpha  as well as two interesting bigrams: “queries failed” and “google killer”.  TweetMotif doesn’t attempt to derive the meaning or sentiment toward the phrases — NLP is hard, and doing this much is hard enough! — but it’s easy for you to look at the tweet</p><p>3 0.88171387 <a title="140-lda-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-18-Turker_classifiers_and_binary_classification_threshold_calibration.html">107 brendan oconnor ai-2008-06-18-Turker classifiers and binary classification threshold calibration</a></p>
<p>Introduction: I wrote a big Dolores Labs blog post a few days ago.   Click here to read it .  I am most proud of the pictures I made for it:</p><p>4 0.45673758 <a title="140-lda-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>5 0.42355898 <a title="140-lda-5" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>Introduction: Everyone recently seems to be talking about  this newish paper by Digrazia, McKelvey, Bollen, and Rojas  ( pdf here ) that examines the correlation of Congressional candidate name mentions on Twitter against whether the candidate won the race.  One of the coauthors also wrote a Washington Post  Op-Ed  about it.  I read the paper and I think it’s reasonable, but their op-ed overstates their results.  It claims:
  
“In the 2010 data, our Twitter data predicted the winner in 404 out of 435 competitive races”
  
But this analysis is nowhere in their paper.  Fabio Rojas has now  posted errata/rebuttals  about the op-ed and described this analysis they did here.  There are several major issues off the bat:
  
 They didn’t ever predict 404/435 races; they only analyzed 406 races they call “competitive,” getting 92.5% (in-sample) accuracy, then extrapolated to all races to get the 435 number. 
 They’re reporting about  in-sample  predictions, which is really misleading to a non-scientific audi</p><p>6 0.41630369 <a title="140-lda-6" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>7 0.41271847 <a title="140-lda-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>8 0.40794009 <a title="140-lda-8" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>9 0.40502727 <a title="140-lda-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>10 0.40033138 <a title="140-lda-10" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>11 0.39902312 <a title="140-lda-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>12 0.39777225 <a title="140-lda-12" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-08-30-A_big%2C_fun_list_of_links_I%E2%80%99m_reading.html">44 brendan oconnor ai-2006-08-30-A big, fun list of links I’m reading</a></p>
<p>13 0.39242646 <a title="140-lda-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>14 0.39077282 <a title="140-lda-14" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>15 0.38672227 <a title="140-lda-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-03-24-Quick-R%2C_the_only_decent_R_documentation_on_the_internet.html">97 brendan oconnor ai-2008-03-24-Quick-R, the only decent R documentation on the internet</a></p>
<p>16 0.38544935 <a title="140-lda-16" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>17 0.3830924 <a title="140-lda-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>18 0.38291329 <a title="140-lda-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>19 0.38140872 <a title="140-lda-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>20 0.37886876 <a title="140-lda-20" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
