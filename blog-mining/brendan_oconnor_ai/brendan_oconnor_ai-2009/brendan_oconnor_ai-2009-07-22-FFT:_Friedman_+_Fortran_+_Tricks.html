<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>147 brendan oconnor ai-2009-07-22-FFT: Friedman + Fortran + Tricks</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2009" href="../home/brendan_oconnor_ai-2009_home.html">brendan_oconnor_ai-2009</a> <a title="brendan_oconnor_ai-2009-147" href="#">brendan_oconnor_ai-2009-147</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>147 brendan oconnor ai-2009-07-22-FFT: Friedman + Fortran + Tricks</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2009-147-html" href="http://brenocon.com/blog/2009/07/fft-friedman-fortran-tricks/">html</a></p><p>Introduction: …is a tongue-in-cheek phrase from Trevor Hastie’s  very fun to read useR-2009 presentation , from the merry trio of Hastie, Friedman, and Tibshirani, who brought us, among other things, the excellent  Elements of Statistical Learning textbook .  It’s a joy to read sophisticated but well-presented work like this.
 
This comes from a slide explaining the impressive speed results for their  glmnet  regression package.  Substantively, I’m interested in their observation that coordinate descent works well for sparse data — if you’re optimizing one feature at a time, and that feature is used in only a small percentage of instances, there are some neat optimizations!
 
But mostly, I had a fun time skimming the  glmnet code .  It’s written in 2008, but, yes,  the core algorithm is written entirely in Fortran , complete with punchcard-style, fixed-width formatting!  (This seems gratuitous to me — I thought the modern  Fortran-90  had done away with such things?)  I’ve felt clever enough making</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 …is a tongue-in-cheek phrase from Trevor Hastie’s  very fun to read useR-2009 presentation , from the merry trio of Hastie, Friedman, and Tibshirani, who brought us, among other things, the excellent  Elements of Statistical Learning textbook . [sent-1, score-0.595]
</p><p>2 It’s a joy to read sophisticated but well-presented work like this. [sent-2, score-0.373]
</p><p>3 This comes from a slide explaining the impressive speed results for their  glmnet  regression package. [sent-3, score-0.704]
</p><p>4 Substantively, I’m interested in their observation that coordinate descent works well for sparse data — if you’re optimizing one feature at a time, and that feature is used in only a small percentage of instances, there are some neat optimizations! [sent-4, score-1.123]
</p><p>5 But mostly, I had a fun time skimming the  glmnet code . [sent-5, score-0.497]
</p><p>6 It’s written in 2008, but, yes,  the core algorithm is written entirely in Fortran , complete with punchcard-style, fixed-width formatting! [sent-6, score-0.737]
</p><p>7 (This seems gratuitous to me — I thought the modern  Fortran-90  had done away with such things? [sent-7, score-0.211]
</p><p>8 )  I’ve felt clever enough making 10x-100x performance gains by switching from R or Python down to C++, but I’m told that this is nothing compared to Fortran with the proprietary  Intel compiler  — still the fastest language in the world for numeric computing. [sent-8, score-0.831]
</p><p>9 (Hat tip:  Revolution Computing  pointed out the useR-2009 presentations. [sent-9, score-0.097]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fortran', 0.277), ('glmnet', 0.277), ('hastie', 0.235), ('feature', 0.187), ('written', 0.17), ('observation', 0.138), ('elements', 0.138), ('tibshirani', 0.138), ('trevor', 0.138), ('clever', 0.138), ('brought', 0.138), ('descent', 0.138), ('gains', 0.138), ('hat', 0.138), ('joy', 0.138), ('proprietary', 0.138), ('fun', 0.133), ('sophisticated', 0.126), ('substantively', 0.126), ('phrase', 0.126), ('coordinate', 0.126), ('numeric', 0.126), ('optimizing', 0.118), ('modern', 0.118), ('slide', 0.118), ('sparse', 0.118), ('speed', 0.118), ('entirely', 0.118), ('revolution', 0.111), ('percentage', 0.111), ('computing', 0.111), ('read', 0.109), ('impressive', 0.106), ('instances', 0.106), ('friedman', 0.106), ('nothing', 0.101), ('textbook', 0.101), ('complete', 0.097), ('core', 0.097), ('presentation', 0.097), ('mostly', 0.097), ('told', 0.097), ('pointed', 0.097), ('python', 0.097), ('away', 0.093), ('performance', 0.093), ('things', 0.09), ('time', 0.087), ('comes', 0.085), ('algorithm', 0.085)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000004 <a title="147-tfidf-1" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-22-FFT%3A_Friedman_%2B_Fortran_%2B_Tricks.html">147 brendan oconnor ai-2009-07-22-FFT: Friedman + Fortran + Tricks</a></p>
<p>Introduction: …is a tongue-in-cheek phrase from Trevor Hastie’s  very fun to read useR-2009 presentation , from the merry trio of Hastie, Friedman, and Tibshirani, who brought us, among other things, the excellent  Elements of Statistical Learning textbook .  It’s a joy to read sophisticated but well-presented work like this.
 
This comes from a slide explaining the impressive speed results for their  glmnet  regression package.  Substantively, I’m interested in their observation that coordinate descent works well for sparse data — if you’re optimizing one feature at a time, and that feature is used in only a small percentage of instances, there are some neat optimizations!
 
But mostly, I had a fun time skimming the  glmnet code .  It’s written in 2008, but, yes,  the core algorithm is written entirely in Fortran , complete with punchcard-style, fixed-width formatting!  (This seems gratuitous to me — I thought the modern  Fortran-90  had done away with such things?)  I’ve felt clever enough making</p><p>2 0.083890833 <a title="147-tfidf-2" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>3 0.078893863 <a title="147-tfidf-3" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>Introduction: Lukas  and I were trying to write a succinct comparison of the most popular packages that are typically used for data analysis.  I think most people choose one based on what people around them use or what they learn in school, so I’ve found it hard to find comparative information.  I’m posting the table here in hopes of useful comments.
  
 
 
  Name  
  Advantages  
  Disadvantages  
  Open source?  
  Typical   users  
 
 
 R 
 Library support; visualization 
 Steep learning curve 
 Yes 
 Finance; Statistics 
 
 
 Matlab 
 Elegant matrix support; visualization 
 Expensive; incomplete statistics support 
 No 
 Engineering 
 
 
 SciPy/NumPy/Matplotlib 
 Python (general-purpose programming language) 
 Immature 
 Yes 
 Engineering 
 
 
 Excel 
 Easy; visual; flexible 
 Large datasets 
 No 
 Business 
 
 
 SAS 
 Large datasets 
 Expensive; outdated programming language 
 No 
 Business; Government 
 
 
 Stata 
 Easy statistical analysis 
  
 No 
 Science 
 
 
 SPSS 
 Like Stata but more ex</p><p>4 0.078404151 <a title="147-tfidf-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>Introduction: update 2012-10-25 : I’ve been informed there is a new maintainer for Mawk, who has probably fixed the bugs I’ve been seeing.
  

From: Gert Hulselmans   


[The bugs you have found are] indeed true with mawk v1.3.3 which comes standard with Debian/Ubuntu.  This version is almost not developed the last 10 years.


I now already use mawk v1.3.4 maintained by another developer (Thomas E. Dickey) 
for more than a year on huge datafiles (sometimes several GB).


The problems/wrong results I had with mawk v1.3.3 sometimes are gone. In his version, normally all open/known bugs are fixed.


This version can be downloaded from:  http://invisible-island.net/mawk/ 

     update 2010-04-30  : I have since found large datasets where mawk is buggy and gives the wrong result.  nawk seems safe.   When one of these newfangled   “Big Data”   sets comes your way, the very first thing you have to do is data munging: shuffling around file formats, renaming fields and the like.  Once you’re dealing with hun</p><p>5 0.073456913 <a title="147-tfidf-5" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-31-balkanized_USA.html">21 brendan oconnor ai-2005-07-31-balkanized USA</a></p>
<p>Introduction: From the same site,  this is fun.</p><p>6 0.069196396 <a title="147-tfidf-6" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>7 0.067119703 <a title="147-tfidf-7" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>8 0.06671124 <a title="147-tfidf-8" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>9 0.062349312 <a title="147-tfidf-9" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>10 0.060246367 <a title="147-tfidf-10" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>11 0.059692726 <a title="147-tfidf-11" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-24-Python_bindings_to_Google%E2%80%99s_%E2%80%9CAJAX%E2%80%9D_Search_API.html">127 brendan oconnor ai-2008-11-24-Python bindings to Google’s “AJAX” Search API</a></p>
<p>12 0.057628967 <a title="147-tfidf-12" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-06-03-Neuroeconomics_reviews.html">38 brendan oconnor ai-2006-06-03-Neuroeconomics reviews</a></p>
<p>13 0.052948691 <a title="147-tfidf-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<p>14 0.052424364 <a title="147-tfidf-14" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-07-Kurzweil_interview.html">27 brendan oconnor ai-2005-09-07-Kurzweil interview</a></p>
<p>15 0.050763786 <a title="147-tfidf-15" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-17-%22Time_will_tell%2C_epistemology_won%E2%80%99t%22.html">65 brendan oconnor ai-2007-06-17-"Time will tell, epistemology won’t"</a></p>
<p>16 0.049284369 <a title="147-tfidf-16" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-02-23-Wasserman_on_Stats_vs_ML%2C_and_previous_comparisons.html">191 brendan oconnor ai-2013-02-23-Wasserman on Stats vs ML, and previous comparisons</a></p>
<p>17 0.046235379 <a title="147-tfidf-17" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">153 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>18 0.046138532 <a title="147-tfidf-18" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-11-Memorizing_small_tables.html">177 brendan oconnor ai-2011-11-11-Memorizing small tables</a></p>
<p>19 0.044118341 <a title="147-tfidf-19" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-The_Jungle_Economy.html">47 brendan oconnor ai-2007-01-02-The Jungle Economy</a></p>
<p>20 0.043261759 <a title="147-tfidf-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-09-18-%22Machine%22_translation-vision_%28Stanford_AI_courses_online%29.html">113 brendan oconnor ai-2008-09-18-"Machine" translation-vision (Stanford AI courses online)</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.174), (1, -0.056), (2, -0.003), (3, -0.093), (4, -0.016), (5, 0.066), (6, 0.041), (7, 0.014), (8, 0.046), (9, -0.017), (10, 0.012), (11, -0.014), (12, -0.044), (13, -0.102), (14, 0.008), (15, -0.046), (16, 0.065), (17, 0.009), (18, -0.013), (19, 0.04), (20, -0.051), (21, -0.057), (22, -0.028), (23, -0.008), (24, -0.065), (25, 0.059), (26, -0.1), (27, 0.025), (28, 0.007), (29, -0.012), (30, 0.046), (31, -0.123), (32, 0.047), (33, -0.038), (34, 0.158), (35, -0.035), (36, -0.045), (37, -0.086), (38, 0.001), (39, -0.11), (40, -0.015), (41, 0.067), (42, -0.095), (43, 0.111), (44, 0.009), (45, 0.023), (46, 0.02), (47, -0.003), (48, 0.112), (49, -0.011)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98493719 <a title="147-lsi-1" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-22-FFT%3A_Friedman_%2B_Fortran_%2B_Tricks.html">147 brendan oconnor ai-2009-07-22-FFT: Friedman + Fortran + Tricks</a></p>
<p>Introduction: …is a tongue-in-cheek phrase from Trevor Hastie’s  very fun to read useR-2009 presentation , from the merry trio of Hastie, Friedman, and Tibshirani, who brought us, among other things, the excellent  Elements of Statistical Learning textbook .  It’s a joy to read sophisticated but well-presented work like this.
 
This comes from a slide explaining the impressive speed results for their  glmnet  regression package.  Substantively, I’m interested in their observation that coordinate descent works well for sparse data — if you’re optimizing one feature at a time, and that feature is used in only a small percentage of instances, there are some neat optimizations!
 
But mostly, I had a fun time skimming the  glmnet code .  It’s written in 2008, but, yes,  the core algorithm is written entirely in Fortran , complete with punchcard-style, fixed-width formatting!  (This seems gratuitous to me — I thought the modern  Fortran-90  had done away with such things?)  I’ve felt clever enough making</p><p>2 0.5129301 <a title="147-lsi-2" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-31-balkanized_USA.html">21 brendan oconnor ai-2005-07-31-balkanized USA</a></p>
<p>Introduction: From the same site,  this is fun.</p><p>3 0.49920577 <a title="147-lsi-3" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>Introduction: I’m doing  word and bigram counts  on a corpus of tweets.  I want to store and rapidly retrieve them later for  language model  purposes.  So there’s a big table of counts that get incremented many times.  The easiest way to get something running is to use an open-source key/value store; but which?  There’s recently been some development in this area so I thought it would be good to revisit and evaluate some options.
 
Here are timings for a single counting process: iterate over 45,000 short text messages, tokenize them, then increment counters for their unigrams and bigrams.  (The speed of the data store is only one component of performance.)  There are about 17 increments per tweet: 400k unique terms and 750k total count.  This is substantially smaller than what I need, but it’s small enough to easily test.  I used several very different architectures and packages, explained below.
  
 
 architecture
  name
  speed
   
 in-memory, within-process
  python dictionary
   2700 tweets/sec</p><p>4 0.47177508 <a title="147-lsi-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>Introduction: update 2012-10-25 : I’ve been informed there is a new maintainer for Mawk, who has probably fixed the bugs I’ve been seeing.
  

From: Gert Hulselmans   


[The bugs you have found are] indeed true with mawk v1.3.3 which comes standard with Debian/Ubuntu.  This version is almost not developed the last 10 years.


I now already use mawk v1.3.4 maintained by another developer (Thomas E. Dickey) 
for more than a year on huge datafiles (sometimes several GB).


The problems/wrong results I had with mawk v1.3.3 sometimes are gone. In his version, normally all open/known bugs are fixed.


This version can be downloaded from:  http://invisible-island.net/mawk/ 

     update 2010-04-30  : I have since found large datasets where mawk is buggy and gives the wrong result.  nawk seems safe.   When one of these newfangled   “Big Data”   sets comes your way, the very first thing you have to do is data munging: shuffling around file formats, renaming fields and the like.  Once you’re dealing with hun</p><p>5 0.44315836 <a title="147-lsi-5" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>Introduction: Lukas  and I were trying to write a succinct comparison of the most popular packages that are typically used for data analysis.  I think most people choose one based on what people around them use or what they learn in school, so I’ve found it hard to find comparative information.  I’m posting the table here in hopes of useful comments.
  
 
 
  Name  
  Advantages  
  Disadvantages  
  Open source?  
  Typical   users  
 
 
 R 
 Library support; visualization 
 Steep learning curve 
 Yes 
 Finance; Statistics 
 
 
 Matlab 
 Elegant matrix support; visualization 
 Expensive; incomplete statistics support 
 No 
 Engineering 
 
 
 SciPy/NumPy/Matplotlib 
 Python (general-purpose programming language) 
 Immature 
 Yes 
 Engineering 
 
 
 Excel 
 Easy; visual; flexible 
 Large datasets 
 No 
 Business 
 
 
 SAS 
 Large datasets 
 Expensive; outdated programming language 
 No 
 Business; Government 
 
 
 Stata 
 Easy statistical analysis 
  
 No 
 Science 
 
 
 SPSS 
 Like Stata but more ex</p><p>6 0.42414397 <a title="147-lsi-6" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>7 0.41970509 <a title="147-lsi-7" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>8 0.3958818 <a title="147-lsi-8" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">153 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>9 0.3897374 <a title="147-lsi-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<p>10 0.38384342 <a title="147-lsi-10" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-06-03-Neuroeconomics_reviews.html">38 brendan oconnor ai-2006-06-03-Neuroeconomics reviews</a></p>
<p>11 0.38237888 <a title="147-lsi-11" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-08-MyDebates.org%2C_online_polling%2C_and_potentially_the_coolest_question_corpus_ever.html">116 brendan oconnor ai-2008-10-08-MyDebates.org, online polling, and potentially the coolest question corpus ever</a></p>
<p>12 0.38100824 <a title="147-lsi-12" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-20-Log-normal_and_logistic-normal_terminology.html">169 brendan oconnor ai-2011-05-20-Log-normal and logistic-normal terminology</a></p>
<p>13 0.37269309 <a title="147-lsi-13" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>14 0.36034921 <a title="147-lsi-14" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-29-%22Stanford_Impostor%22.html">62 brendan oconnor ai-2007-05-29-"Stanford Impostor"</a></p>
<p>15 0.3518292 <a title="147-lsi-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<p>16 0.3511973 <a title="147-lsi-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-28-Calculating_running_variance_in_Python_and_C%2B%2B.html">128 brendan oconnor ai-2008-11-28-Calculating running variance in Python and C++</a></p>
<p>17 0.3390995 <a title="147-lsi-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-Anarchy_vs._social_order_in_Somalia.html">46 brendan oconnor ai-2007-01-02-Anarchy vs. social order in Somalia</a></p>
<p>18 0.33856744 <a title="147-lsi-18" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-03-02-Poor_man%E2%80%99s_linear_algebra_textbook.html">166 brendan oconnor ai-2011-03-02-Poor man’s linear algebra textbook</a></p>
<p>19 0.33414391 <a title="147-lsi-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>20 0.31948528 <a title="147-lsi-20" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(4, 0.023), (16, 0.063), (24, 0.041), (37, 0.494), (44, 0.041), (55, 0.033), (57, 0.035), (73, 0.038), (74, 0.132)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95028186 <a title="147-lda-1" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-22-FFT%3A_Friedman_%2B_Fortran_%2B_Tricks.html">147 brendan oconnor ai-2009-07-22-FFT: Friedman + Fortran + Tricks</a></p>
<p>Introduction: …is a tongue-in-cheek phrase from Trevor Hastie’s  very fun to read useR-2009 presentation , from the merry trio of Hastie, Friedman, and Tibshirani, who brought us, among other things, the excellent  Elements of Statistical Learning textbook .  It’s a joy to read sophisticated but well-presented work like this.
 
This comes from a slide explaining the impressive speed results for their  glmnet  regression package.  Substantively, I’m interested in their observation that coordinate descent works well for sparse data — if you’re optimizing one feature at a time, and that feature is used in only a small percentage of instances, there are some neat optimizations!
 
But mostly, I had a fun time skimming the  glmnet code .  It’s written in 2008, but, yes,  the core algorithm is written entirely in Fortran , complete with punchcard-style, fixed-width formatting!  (This seems gratuitous to me — I thought the modern  Fortran-90  had done away with such things?)  I’ve felt clever enough making</p><p>2 0.69708222 <a title="147-lda-2" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-03-26-new_kind_of_science%2C_for_real.html">32 brendan oconnor ai-2006-03-26-new kind of science, for real</a></p>
<p>Introduction: Great Microsoft Research report (from a workshop they held?):   2020 Science  where they argue that computer  science  will become part and parcel of science in general.  For example, computation theory will be important to understand biological organisms as information processing systems.  This is basically a much better version of Wolfram’s  New Kind of Science  argument — I believe this one.  The big shared insight is that computers aren’t just about data storage and number crunching.  Wolfram and the some of the Santa Fe complex systems people are really in to simulations, which is fine.  But there’s tremendous potential in computation  theory  — algorithms, formal representations, and more.  Empirical scientists are going to have to learn this stuff!</p><p>3 0.27104351 <a title="147-lda-3" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>Introduction: I’ve had several people ask me what the numbers in  ACL  reviews mean — and I can’t find anywhere online where they’re described.  (Can anyone point this out if it is somewhere?)
 
So here’s the review form, below.  They all go from 1 to 5, with 5 the best.  I think the review emails to authors only include a subset of the below — for example, “Overall Recommendation” is not included?
 
The CFP said that they have different types of review forms for different types of papers.  I think this one is for a standard full paper.  I guess what people  really  want to know is what scores tend to correspond to acceptances.  I really have no idea and I get the impression this can change year to year.  I have no involvement with the ACL conference besides being one of many, many reviewers.
 
  
  
APPROPRIATENESS (1-5)
Does the paper fit in ACL 2014? (Please answer this question in light of the desire to broaden the scope of the research areas represented at ACL.) 

5: Certainly. 
4: Probabl</p><p>4 0.267344 <a title="147-lda-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>Introduction: This is a good idea: in a search engine’s query logs, look for outbreaks of queries like [[flu symptoms]] in a given region.  I’ve heard (from  Roddy ) that this trick also works well on Facebook statuses (e.g. “Feeling crappy this morning, think I just got the flu”).
  
  Google Uses Web Searches to Track Flu’s Spread – NYTimes.com  
  Google Flu Trends – google.org  
  
For an example with a publicly available data feed, these queries works decently well on Twitter search:
 
 [[ flu -shot -google ]]  (high recall)
 
 [[ "muscle aches" flu -shot ]]  (high precision)
     
 
The “muscle aches” query is too sparse and the general query is too noisy, but you could imagine some more tricks to clean it up, then train a classifier, etc.  With a bit more work it looks like geolocation information can be had out of the  Twitter search API .</p><p>5 0.26702809 <a title="147-lda-5" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>Introduction: I don’t care how lame anyone thinks this is, but economic theorist  Ariel Rubinstein  is the shit.  He’s funny, self-deprecating, and brilliant.  I was just re-reading  his delightful, sarcastic review of Freakonomics .  (Overly dramatized visual depiction below; hey, conflict sells.)
 
    The review consists of excerpts from his own upcoming super-worldwide-bestseller, “Freak-Freakonomics”.  It is full of golden quotes such as: 
  Chapter 2: Why do economists earn more than mathematicians?  
 
…
 
The comparison between architects and prostitutes can be applied to mathematicians and economists: The former are more skilled, highly educated and intelligent.  
 
To elaborate: 
 Levitt has never encountered a girl who dreams of being a prostitute and I have never met a child who dreams of being an economist. Like prostitutes, the skill required of economists is “not necessarily ‘specialized’” (106). And, finally, here is a new explanation for the salary gap between mathematicians and eco</p><p>6 0.26683968 <a title="147-lda-6" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>7 0.2611697 <a title="147-lda-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-05-Clinton-Obama_support_visualization.html">105 brendan oconnor ai-2008-06-05-Clinton-Obama support visualization</a></p>
<p>8 0.2601504 <a title="147-lda-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>9 0.25840712 <a title="147-lda-9" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>10 0.25328553 <a title="147-lda-10" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Another_R_flashmob_today.html">152 brendan oconnor ai-2009-09-08-Another R flashmob today</a></p>
<p>11 0.25058451 <a title="147-lda-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>12 0.24994297 <a title="147-lda-12" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>13 0.24682465 <a title="147-lda-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>14 0.23769678 <a title="147-lda-14" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>15 0.23599252 <a title="147-lda-15" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>16 0.23337743 <a title="147-lda-16" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>17 0.23210756 <a title="147-lda-17" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>18 0.23081969 <a title="147-lda-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>19 0.22627851 <a title="147-lda-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-18-Information_cost_and_genocide.html">130 brendan oconnor ai-2008-12-18-Information cost and genocide</a></p>
<p>20 0.22380283 <a title="147-lda-20" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
