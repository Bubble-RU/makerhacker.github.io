<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>135 brendan oconnor ai-2009-02-14-La Jetee</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2009" href="../home/brendan_oconnor_ai-2009_home.html">brendan_oconnor_ai-2009</a> <a title="brendan_oconnor_ai-2009-135" href="#">brendan_oconnor_ai-2009-135</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>135 brendan oconnor ai-2009-02-14-La Jetee</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2009-135-html" href="http://brenocon.com/blog/2009/02/la-jetee/">html</a></p><p>Introduction: Fromhere.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sas', 0.391), ('stata', 0.329), ('matlab', 0.286), ('scipy', 0.219), ('spss', 0.164), ('matplotlib', 0.143), ('option', 0.13), ('statistical', 0.112), ('support', 0.104), ('scientists', 0.1), ('standard', 0.097), ('capabilities', 0.095), ('numpy', 0.095), ('traditional', 0.095), ('fortran', 0.095), ('people', 0.093), ('come', 0.093), ('popular', 0.093), ('seem', 0.09), ('used', 0.089), ('super', 0.087), ('memory', 0.087), ('solutions', 0.087), ('fit', 0.085), ('language', 0.083), ('significance', 0.081), ('hands', 0.081), ('impression', 0.081), ('packages', 0.081), ('libraries', 0.081), ('ones', 0.077), ('cluster', 0.076), ('data', 0.071), ('tests', 0.07), ('supposed', 0.07), ('package', 0.07), ('mostly', 0.067), ('went', 0.067), ('source', 0.067), ('datasets', 0.067), ('talking', 0.064), ('around', 0.063), ('user', 0.062), ('matrix', 0.062), ('programming', 0.062), ('computer', 0.06), ('visualization', 0.058), ('analysis', 0.057), ('either', 0.057), ('update', 0.057)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000005 <a title="135-tfidf-1" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-14-La_Jetee.html">135 brendan oconnor ai-2009-02-14-La Jetee</a></p>
<p>Introduction: Fromhere.</p><p>2 0.14340374 <a title="135-tfidf-2" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-13-Bayes_update_view_of_pointwise_mutual_information.html">179 brendan oconnor ai-2011-11-13-Bayes update view of pointwise mutual information</a></p>
<p>Introduction: This is fun. Pointwise Mutual Information (e.g.Church and Hanks 1990) between
two variable outcomes \\(x\\) and \\(y\\) is\\[ PMI(x,y) = \log
\frac{p(x,y)}{p(x)p(y)} \\]It's called "pointwise" becauseMutual Information,
between two (discrete) variables X and Y, is the expectation of PMI over
possible outcomes of X and Y: \\( MI(X,Y) = \sum_{x,y} p(x,y) PMI(x,y) \\).One
interpretation of PMI is it's measuring how much deviation from independence
there is -- since \\(p(x,y)=p(x)p(y)\\) if X and Y were independent, so the
ratio is how non-independent they (the outcomes) are.You can get another
interpretation of this quantity if you switch into conditional probabilities.
Looking just at the ratio, apply the definition of conditional probability:\\[
\frac{p(x,y)}{p(x)p(y)} = \frac{p(x|y)}{p(x)} \\]Think about doing a Bayes
update for your belief about \\(x\\). Start with the prior \\(p(x)\\), then
learn \\(y\\) and you update to the posterior belief \\(p(x|y)\\). How much
your belief change</p><p>3 0.1354457 <a title="135-tfidf-3" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>Introduction: Seeing a long, lavish article about R in the NEW YORK TIMES (!) really freaks
me out.replicate(100, c( "OMG OMG,Ris now famous?!", "People used to make fun
of me for learning R since Splus is SO OLD!", "I still hear stories that SAS
can do crazy tricks that make me jealous. But not enough to attempt learning
it." )[ floor(runif(1, min=1,max=4)) ] )This blog has been a long-time
supporter of this both brilliant and insanely quirky statistical programming
environment. Here are some graphs I've made in the last year or two that have
R code attached:Wisdom of small crowdsSimpson's paradox via mosaic
plotsDolores Labs color wheel!(code)Political bias SVD evaluationPresidential
poll aggregationOK, we didn't post the code, but check out ourN-body trolley
graph!Learning R is hard because there's a zillion packages, and the official
documentation is reference-oriented.  I've never looked at any of the books
much.  I think you can get very far with exactly two websites:Quick-R- the
best introduc</p><p>4 0.13366695 <a title="135-tfidf-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update-- well, it's been nearly a year, and I should say not
everything in this rant is totally true, and I certainly believe much less of
it now. Current take:Statistics, not machine learning, is the real deal, but
unfortunately suffers from bad marketing. On the other hand, to the extent
that bad marketing includes misguided undergraduate curriculums, there's
plenty of room to improve for everyone.So it's pretty clear by now that
statistics and machine learning aren't very different fields. I was recently
pointed toa very amusing comparisonby the excellent statistician -- and
machine learning expert --Robert Tibshiriani. Reproduced here:GlossaryMachine
learningStatisticsnetwork,
graphsmodelweightsparameterslearningfittinggeneralizationtest set
performancesupervised learningregression/classiﬁcationunsupervised
learningdensity estimation, clusteringlarge grant = $1,000,000large grant =
$50,000nice place to have a meeting:Snowbird, Utah, French Alpsnice place to
have a meeting:L</p><p>5 0.11154073 <a title="135-tfidf-5" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">154 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>Introduction: I've been reading several somewhat recent finance papers (Antweiler and Frank
2005,Das and Chen 2007) that useRainbow, the text classification software
originally written byAndrew McCallumback in 1996. The last version is from
2002 and the homepage announces he isn't really supporting it any
more.However, as far as I can tell, it might still be the easiest-to-use text
classifier package out there. You don't have to program -- just invoke
commandline arguments -- and it can accommodate reasonably sized datasets,
does tokenization, stopword filtering, etc. for you, and has some useful
feature selection and other options. Based on my limited usage, it seems well-
implemented. If anyone knows of a better one I'd love to hear it. I once
looked at, among other things,GATEandUIMA, and they seemed too hard to use if
you wanted to download something that did simple text classification; or else,
maybe they didn't have documentation on how to use them in that manner.Rainbow
does. If I had to reco</p><p>6 0.10929414 <a title="135-tfidf-6" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-11-20-science_writing_bad%21.html">28 brendan oconnor ai-2005-11-20-science writing bad!</a></p>
<p>7 0.10183834 <a title="135-tfidf-7" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-01-07-Perplexity_as_branching_factor%3B_as_Shannon_diversity_index.html">191 brendan oconnor ai-2013-01-07-Perplexity as branching factor; as Shannon diversity index</a></p>
<p>8 0.10158019 <a title="135-tfidf-8" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">139 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>9 0.098144233 <a title="135-tfidf-9" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-08-27-CMU_Twitter_Part-of-Speech_tagger_0.2.html">174 brendan oconnor ai-2011-08-27-CMU Twitter Part-of-Speech tagger 0.2</a></p>
<p>10 0.093735702 <a title="135-tfidf-10" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">185 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>11 0.092298321 <a title="135-tfidf-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-15-Beta_conjugate_explorer.html">147 brendan oconnor ai-2009-07-15-Beta conjugate explorer</a></p>
<p>12 0.09102539 <a title="135-tfidf-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Another_R_flashmob_today.html">153 brendan oconnor ai-2009-09-08-Another R flashmob today</a></p>
<p>13 0.088526301 <a title="135-tfidf-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-23-SF_conference_for_data_mining_mercenaries.html">133 brendan oconnor ai-2009-01-23-SF conference for data mining mercenaries</a></p>
<p>14 0.082501739 <a title="135-tfidf-14" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-26-Seeing_how_%E2%80%9Cart%E2%80%9D_and_%E2%80%9Cpharmaceuticals%E2%80%9D_are_linguistically_similar_in_web_text.html">157 brendan oconnor ai-2009-09-26-Seeing how “art” and “pharmaceuticals” are linguistically similar in web text</a></p>
<p>15 0.078957692 <a title="135-tfidf-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-09-18-%22Machine%22_translation-vision_%28Stanford_AI_courses_online%29.html">113 brendan oconnor ai-2008-09-18-"Machine" translation-vision (Stanford AI courses online)</a></p>
<p>16 0.07741677 <a title="135-tfidf-16" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-18-Scatterplot_of_KN-PYP_language_model_results.html">203 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</a></p>
<p>17 0.077373952 <a title="135-tfidf-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<p>18 0.070105322 <a title="135-tfidf-18" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-18-Correlation_picture.html">194 brendan oconnor ai-2013-03-18-Correlation picture</a></p>
<p>19 0.068902604 <a title="135-tfidf-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>20 0.068818897 <a title="135-tfidf-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-28-Calculating_running_variance_in_Python_and_C%2B%2B.html">128 brendan oconnor ai-2008-11-28-Calculating running variance in Python and C++</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.301), (1, -0.112), (2, -0.028), (3, -0.018), (4, -0.087), (5, -0.017), (6, 0.066), (7, -0.08), (8, -0.041), (9, -0.037), (10, 0.144), (11, -0.004), (12, 0.046), (13, -0.151), (14, 0.029), (15, 0.009), (16, 0.075), (17, 0.015), (18, -0.059), (19, -0.008), (20, -0.019), (21, -0.039), (22, 0.109), (23, 0.018), (24, 0.071), (25, -0.038), (26, -0.014), (27, 0.055), (28, 0.046), (29, 0.028), (30, -0.024), (31, 0.043), (32, -0.114), (33, 0.07), (34, 0.108), (35, -0.016), (36, -0.104), (37, 0.112), (38, 0.067), (39, 0.071), (40, -0.047), (41, 0.098), (42, 0.001), (43, -0.109), (44, 0.081), (45, 0.101), (46, 0.056), (47, 0.066), (48, 0.008), (49, 0.056)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97624999 <a title="135-lsi-1" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-14-La_Jetee.html">135 brendan oconnor ai-2009-02-14-La Jetee</a></p>
<p>Introduction: Fromhere.</p><p>2 0.67849612 <a title="135-lsi-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">139 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>Introduction: This is fun --Jamie Callan's group atCMU LTIjust finished a crawl of 1 billion
web pages. It's 5 terabytes compressed -- big enough so they have to send it
to you by mailing hard drives.Link: ClueWeb09One of their motivations was to
have a corpus large enough such that research results on it would be taken
seriously by search engine companies. To my mind, this begs the question
whether academics should try to innovate in web search, when it's a research
area incredibly dependent on really large, expensive-to-acquire datasets. And
what's the point? To slightly improve Google someday? Don't they do that
pretty well themselves?On the other hand, having a billion web pages around
sounds like a lot of fun. Someone should get Amazon to add this to theAWS
Public Datasets. Then, to process the data, instead of paying to get 5 TB of
data shipped to you, you instead pay Amazon to rent virtual computers that can
access the data. This costs less only to a certain point, of course.It always
seemed</p><p>3 0.66662115 <a title="135-lsi-3" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-13-Bayes_update_view_of_pointwise_mutual_information.html">179 brendan oconnor ai-2011-11-13-Bayes update view of pointwise mutual information</a></p>
<p>Introduction: This is fun. Pointwise Mutual Information (e.g.Church and Hanks 1990) between
two variable outcomes \\(x\\) and \\(y\\) is\\[ PMI(x,y) = \log
\frac{p(x,y)}{p(x)p(y)} \\]It's called "pointwise" becauseMutual Information,
between two (discrete) variables X and Y, is the expectation of PMI over
possible outcomes of X and Y: \\( MI(X,Y) = \sum_{x,y} p(x,y) PMI(x,y) \\).One
interpretation of PMI is it's measuring how much deviation from independence
there is -- since \\(p(x,y)=p(x)p(y)\\) if X and Y were independent, so the
ratio is how non-independent they (the outcomes) are.You can get another
interpretation of this quantity if you switch into conditional probabilities.
Looking just at the ratio, apply the definition of conditional probability:\\[
\frac{p(x,y)}{p(x)p(y)} = \frac{p(x|y)}{p(x)} \\]Think about doing a Bayes
update for your belief about \\(x\\). Start with the prior \\(p(x)\\), then
learn \\(y\\) and you update to the posterior belief \\(p(x|y)\\). How much
your belief change</p><p>4 0.64541799 <a title="135-lsi-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">154 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>Introduction: I've been reading several somewhat recent finance papers (Antweiler and Frank
2005,Das and Chen 2007) that useRainbow, the text classification software
originally written byAndrew McCallumback in 1996. The last version is from
2002 and the homepage announces he isn't really supporting it any
more.However, as far as I can tell, it might still be the easiest-to-use text
classifier package out there. You don't have to program -- just invoke
commandline arguments -- and it can accommodate reasonably sized datasets,
does tokenization, stopword filtering, etc. for you, and has some useful
feature selection and other options. Based on my limited usage, it seems well-
implemented. If anyone knows of a better one I'd love to hear it. I once
looked at, among other things,GATEandUIMA, and they seemed too hard to use if
you wanted to download something that did simple text classification; or else,
maybe they didn't have documentation on how to use them in that manner.Rainbow
does. If I had to reco</p><p>5 0.53834569 <a title="135-lsi-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update-- well, it's been nearly a year, and I should say not
everything in this rant is totally true, and I certainly believe much less of
it now. Current take:Statistics, not machine learning, is the real deal, but
unfortunately suffers from bad marketing. On the other hand, to the extent
that bad marketing includes misguided undergraduate curriculums, there's
plenty of room to improve for everyone.So it's pretty clear by now that
statistics and machine learning aren't very different fields. I was recently
pointed toa very amusing comparisonby the excellent statistician -- and
machine learning expert --Robert Tibshiriani. Reproduced here:GlossaryMachine
learningStatisticsnetwork,
graphsmodelweightsparameterslearningfittinggeneralizationtest set
performancesupervised learningregression/classiﬁcationunsupervised
learningdensity estimation, clusteringlarge grant = $1,000,000large grant =
$50,000nice place to have a meeting:Snowbird, Utah, French Alpsnice place to
have a meeting:L</p><p>6 0.52574909 <a title="135-lsi-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-04-13-Are_women_discriminated_against_in_graduate_admissions%3F_Simpson%E2%80%99s_paradox_via_R_in_three_easy_steps%21.html">101 brendan oconnor ai-2008-04-13-Are women discriminated against in graduate admissions? Simpson’s paradox via R in three easy steps!</a></p>
<p>7 0.51135147 <a title="135-lsi-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-28-Calculating_running_variance_in_Python_and_C%2B%2B.html">128 brendan oconnor ai-2008-11-28-Calculating running variance in Python and C++</a></p>
<p>8 0.51095223 <a title="135-lsi-8" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-11-20-science_writing_bad%21.html">28 brendan oconnor ai-2005-11-20-science writing bad!</a></p>
<p>9 0.50498784 <a title="135-lsi-9" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Another_R_flashmob_today.html">153 brendan oconnor ai-2009-09-08-Another R flashmob today</a></p>
<p>10 0.49663234 <a title="135-lsi-10" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>11 0.4892295 <a title="135-lsi-11" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-04-11-F-scores%2C_Dice%2C_and_Jaccard_set_similarity.html">184 brendan oconnor ai-2012-04-11-F-scores, Dice, and Jaccard set similarity</a></p>
<p>12 0.46103153 <a title="135-lsi-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">158 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>13 0.45738736 <a title="135-lsi-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-23-SF_conference_for_data_mining_mercenaries.html">133 brendan oconnor ai-2009-01-23-SF conference for data mining mercenaries</a></p>
<p>14 0.44198579 <a title="135-lsi-14" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-05-19-conplot_%E2%80%93_a_console_plotter.html">103 brendan oconnor ai-2008-05-19-conplot – a console plotter</a></p>
<p>15 0.43333128 <a title="135-lsi-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-26-Seeing_how_%E2%80%9Cart%E2%80%9D_and_%E2%80%9Cpharmaceuticals%E2%80%9D_are_linguistically_similar_in_web_text.html">157 brendan oconnor ai-2009-09-26-Seeing how “art” and “pharmaceuticals” are linguistically similar in web text</a></p>
<p>16 0.43283874 <a title="135-lsi-16" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-01-07-Perplexity_as_branching_factor%3B_as_Shannon_diversity_index.html">191 brendan oconnor ai-2013-01-07-Perplexity as branching factor; as Shannon diversity index</a></p>
<p>17 0.43152758 <a title="135-lsi-17" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">185 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>18 0.40762013 <a title="135-lsi-18" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<p>19 0.40099403 <a title="135-lsi-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-09-18-%22Machine%22_translation-vision_%28Stanford_AI_courses_online%29.html">113 brendan oconnor ai-2008-09-18-"Machine" translation-vision (Stanford AI courses online)</a></p>
<p>20 0.3994875 <a title="135-lsi-20" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-15-Beta_conjugate_explorer.html">147 brendan oconnor ai-2009-07-15-Beta conjugate explorer</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.024), (18, 0.517), (20, 0.015), (24, 0.013), (32, 0.065), (34, 0.025), (36, 0.03), (64, 0.02), (67, 0.023), (70, 0.053), (72, 0.037), (91, 0.08), (93, 0.015)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.995754 <a title="135-lda-1" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-14-La_Jetee.html">135 brendan oconnor ai-2009-02-14-La Jetee</a></p>
<p>Introduction: Fromhere.</p><p>2 0.98611224 <a title="135-lda-2" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">199 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>Introduction: Everyone recently seems to be talking aboutthis newish paper by Digrazia,
McKelvey, Bollen, and Rojas(pdf here) that examines the correlation of
Congressional candidate name mentions on Twitter against whether the candidate
won the race.  One of the coauthors also wrote a Washington PostOp-Edabout it.
I read the paper and I think it's reasonable, but their op-ed overstates their
results.  It claims:"In the 2010 data, our Twitter data predicted the winner
in 404 out of 435 competitive races"But this analysis is nowhere in their
paper.  Fabio Rojas has nowposted errata/rebuttalsabout the op-ed and
described this analysis they did here.  There are several major issues off the
bat:They didn't ever predict 404/435 races; they only analyzed 406 races they
call "competitive," getting 92.5% (in-sample) accuracy, then extrapolated to
all races to get the 435 number.They're reporting aboutin-samplepredictions,
which is really misleading to a non-scientific audience; more notes on this
further be</p><p>3 0.98540545 <a title="135-lda-3" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-04-11-F-scores%2C_Dice%2C_and_Jaccard_set_similarity.html">184 brendan oconnor ai-2012-04-11-F-scores, Dice, and Jaccard set similarity</a></p>
<p>Introduction: TheDice similarityis the same asF1-score; and they are monotonic inJaccard
similarity. I worked this out recently but couldn't find anything about it
online so here's a writeup.Let \\(A\\) be the set of found items, and \\(B\\)
the set of wanted items. \\(Prec=|AB|/|A|\\), \\(Rec=|AB|/|B|\\). Their
harmonic mean, the \\(F1\\)-measure, is the same as the Dice
coefficient:\begin{align*}F1(A,B)&= \frac{2}{1/P+ 1/R}= \frac{2}{|A|/|AB| +
|B|/|AB|} \\\Dice(A,B)&= \frac{2|AB|}{ |A| + |B| } \\\&= \frac{2 |AB|}{ (|AB|
+ |A \setminus B|) + (|AB| + |B \setminus A|)} \\\&= \frac{|AB|}{|AB| +
\frac{1}{2}|A \setminus B| + \frac{1}{2} |B \setminus A|}\end{align*}It's nice
to characterize the set comparison into the three mutually exclusive
partitions \\(AB\\), \\(A \setminus B\\), and \\(B \setminus A\\). This
illustrates Dice's close relationship to the Jaccard
metric,\begin{align*}Jacc(A,B)&= \frac{|AB|}{|A \cup B|} \\\&=
\frac{|AB|}{|AB| + |A \setminus B| + |B \setminus A|}\end{align*}And in fact</p><p>4 0.98520261 <a title="135-lda-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-20-Quiz%3A_%E2%80%9Cart%E2%80%9D_and_%E2%80%9Cpharmaceuticals%E2%80%9D.html">156 brendan oconnor ai-2009-09-20-Quiz: “art” and “pharmaceuticals”</a></p>
<p>Introduction: A lexical semantics question:How are "art" and "pharmaceuticals" similar?I
have a data-driven answer, but am curious how easy it is to guess it, and in
what sense it's valid. I'll post my answer and supporting evidence on Tuesday.</p><p>5 0.97397983 <a title="135-lda-5" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-07-Kurzweil_interview.html">27 brendan oconnor ai-2005-09-07-Kurzweil interview</a></p>
<p>Introduction: Ray Kurzweil interviewedon his new book,The Singularity Is Near. Good points
on neuroscience, artificial intelligence, nanotech and the like. But man, I
thoughtAge of Spiritual Machineswas a bit wacky… Complete model of the human
brain by 2030? Please. (Though the observation that brain scan resolutions are
doubling yearly is interesting.)I like the discussion about the relationship
of power and intelligence of orgnizations. Thinking about Kurzweil's bizarre-
sounding scenarios is good because in his world, humans and organizations
start becoming the same thing… which leads to insights on the intelligence of
normal organizations today.</p><p>6 0.96730292 <a title="135-lda-6" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-04-freakonomics_blog.html">15 brendan oconnor ai-2005-07-04-freakonomics blog</a></p>
<p>7 0.96730292 <a title="135-lda-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-17-Twitter_graphs_of_the_debate.html">121 brendan oconnor ai-2008-10-17-Twitter graphs of the debate</a></p>
<p>8 0.80818397 <a title="135-lda-8" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>9 0.78627372 <a title="135-lda-9" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-26-Seeing_how_%E2%80%9Cart%E2%80%9D_and_%E2%80%9Cpharmaceuticals%E2%80%9D_are_linguistically_similar_in_web_text.html">157 brendan oconnor ai-2009-09-26-Seeing how “art” and “pharmaceuticals” are linguistically similar in web text</a></p>
<p>10 0.73777801 <a title="135-lda-10" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-The_Jungle_Economy.html">47 brendan oconnor ai-2007-01-02-The Jungle Economy</a></p>
<p>11 0.72711563 <a title="135-lda-11" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>12 0.68602097 <a title="135-lda-12" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-25-Information_theory_stuff.html">176 brendan oconnor ai-2011-09-25-Information theory stuff</a></p>
<p>13 0.6639452 <a title="135-lda-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-04-Blogger_to_WordPress_migration_helper.html">150 brendan oconnor ai-2009-08-04-Blogger to WordPress migration helper</a></p>
<p>14 0.65778071 <a title="135-lda-14" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-08-27-CMU_Twitter_Part-of-Speech_tagger_0.2.html">174 brendan oconnor ai-2011-08-27-CMU Twitter Part-of-Speech tagger 0.2</a></p>
<p>15 0.65376318 <a title="135-lda-15" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-18-Scatterplot_of_KN-PYP_language_model_results.html">203 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</a></p>
<p>16 0.65259004 <a title="135-lda-16" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">139 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>17 0.64635557 <a title="135-lda-17" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">180 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>18 0.63684797 <a title="135-lda-18" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>19 0.63091934 <a title="135-lda-19" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-09-21-CMU_ARK_Twitter_Part-of-Speech_Tagger_%E2%80%93_v0.3_released.html">188 brendan oconnor ai-2012-09-21-CMU ARK Twitter Part-of-Speech Tagger – v0.3 released</a></p>
<p>20 0.62894446 <a title="135-lda-20" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">154 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
