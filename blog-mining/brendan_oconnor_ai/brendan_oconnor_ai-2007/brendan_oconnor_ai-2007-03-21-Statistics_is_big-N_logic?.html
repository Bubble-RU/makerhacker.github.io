<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>54 brendan oconnor ai-2007-03-21-Statistics is big-N logic?</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2007" href="../home/brendan_oconnor_ai-2007_home.html">brendan_oconnor_ai-2007</a> <a title="brendan_oconnor_ai-2007-54" href="#">brendan_oconnor_ai-2007-54</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>54 brendan oconnor ai-2007-03-21-Statistics is big-N logic?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2007-54-html" href="http://brenocon.com/blog/2007/03/statistics-is-big-n-logic/">html</a></p><p>Introduction: I think I believe one of these things, but I’m not quite sure. 
 Statistics is just like logic, except with uncertainty. 
 
This would be true if statistics is Bayesian statistics and you buy the Bayesian inductive logic story — add induction to propositional logic, via a conditional credibility operator, and the Cox axioms imply standard probability theory as a consequence.  (That is, probability theory is logic with uncertainty.  And then a good Bayesian thinks probability theory and statistics are the same.)  Links:  Jaynes’ explanation ;  SEP article ; also  Fitelson’s article .  (Though there are negative results; all I can think of right now is a  Halpern  article on Cox; and also interesting is  Halpern and Koller .)
 
Secondly, here is another statement.
  

Statistics is just like logic, except with a big N.

  
This is a more data-driven view — the world is full of things and they need to be described.  Logical rules can help you describe things, but you also have to deal wit</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Statistics is just like logic, except with uncertainty. [sent-2, score-0.11]
</p><p>2 This would be true if statistics is Bayesian statistics and you buy the Bayesian inductive logic story — add induction to propositional logic, via a conditional credibility operator, and the Cox axioms imply standard probability theory as a consequence. [sent-3, score-2.026]
</p><p>3 (That is, probability theory is logic with uncertainty. [sent-4, score-0.887]
</p><p>4 And then a good Bayesian thinks probability theory and statistics are the same. [sent-5, score-0.65]
</p><p>5 )  Links:  Jaynes’ explanation ;  SEP article ; also  Fitelson’s article . [sent-6, score-0.269]
</p><p>6 (Though there are negative results; all I can think of right now is a  Halpern  article on Cox; and also interesting is  Halpern and Koller . [sent-7, score-0.168]
</p><p>7 Statistics is just like logic, except with a big N. [sent-9, score-0.11]
</p><p>8 This is a more data-driven view — the world is full of things and they need to be described. [sent-10, score-0.178]
</p><p>9 Logical rules can help you describe things, but you also have to deal with averages, correlations, and other things based on counting. [sent-11, score-0.319]
</p><p>10 I don’t have any fancy cites or much thought yet in to this. [sent-12, score-0.161]
</p><p>11 Here are two other views I’ve seen…    Johan van Benthem: probability theory is “logic with numbers”. [sent-13, score-0.516]
</p><p>12 I only saw this mentioned in passing in a subtitle of some lecture notes; this is not his official position or anything. [sent-14, score-0.449]
</p><p>13 Multi-valued and fuzzy logics can fit this description too. [sent-15, score-0.381]
</p><p>14 I don’t know much about it, other than that the Bayesians claim a weakness of fuzzy logic is that it doesn’t naturally relate to statistics. [sent-17, score-1.074]
</p><p>15 )   Manning and Sch端tze: statistics has to do with counting. [sent-18, score-0.295]
</p><p>16 Not sure how all these different possibilities combine or interact. [sent-21, score-0.157]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('logic', 0.532), ('fuzzy', 0.301), ('statistics', 0.295), ('cox', 0.201), ('halpern', 0.201), ('probability', 0.197), ('bayesian', 0.183), ('theory', 0.158), ('things', 0.114), ('except', 0.11), ('article', 0.101), ('subtitle', 0.087), ('naturally', 0.087), ('sch', 0.087), ('jaynes', 0.087), ('inductive', 0.087), ('axioms', 0.087), ('cites', 0.087), ('combine', 0.087), ('credibility', 0.087), ('interact', 0.087), ('johan', 0.087), ('koller', 0.087), ('manning', 0.087), ('passing', 0.087), ('van', 0.087), ('imply', 0.08), ('sep', 0.08), ('induction', 0.08), ('correlations', 0.08), ('description', 0.08), ('intro', 0.08), ('weakness', 0.08), ('relate', 0.074), ('rules', 0.074), ('logical', 0.074), ('views', 0.074), ('averages', 0.074), ('fancy', 0.074), ('position', 0.074), ('possibilities', 0.07), ('lecture', 0.07), ('also', 0.067), ('official', 0.067), ('chapters', 0.067), ('buy', 0.064), ('conditional', 0.064), ('mentioned', 0.064), ('deal', 0.064), ('full', 0.064)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999976 <a title="54-tfidf-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-21-Statistics_is_big-N_logic%3F.html">54 brendan oconnor ai-2007-03-21-Statistics is big-N logic?</a></p>
<p>Introduction: I think I believe one of these things, but I’m not quite sure. 
 Statistics is just like logic, except with uncertainty. 
 
This would be true if statistics is Bayesian statistics and you buy the Bayesian inductive logic story — add induction to propositional logic, via a conditional credibility operator, and the Cox axioms imply standard probability theory as a consequence.  (That is, probability theory is logic with uncertainty.  And then a good Bayesian thinks probability theory and statistics are the same.)  Links:  Jaynes’ explanation ;  SEP article ; also  Fitelson’s article .  (Though there are negative results; all I can think of right now is a  Halpern  article on Cox; and also interesting is  Halpern and Koller .)
 
Secondly, here is another statement.
  

Statistics is just like logic, except with a big N.

  
This is a more data-driven view — the world is full of things and they need to be described.  Logical rules can help you describe things, but you also have to deal wit</p><p>2 0.20882925 <a title="54-tfidf-2" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-08-09-An_ML-AI_approach_to_P_%21%3D_NP.html">161 brendan oconnor ai-2010-08-09-An ML-AI approach to P != NP</a></p>
<p>Introduction: Like everyone, I’ve been just starting to look at the new, tentative,  proof that P != NP  from Vinay Deolalikar.  After reading the intro, what’s most striking is that probabilistic graphical models and mathematical logic are at the core of the proof.  This feels like a machine learning and artificial intelligence-centric approach to me — very different from what you usually see in mainstream CS theory.  (Maybe I should feel good that in my undergrad I basically stopped studying normal math and spent all my time with this weird stuff instead!)
 
He devotes several chapters to an introduction to graphical models — Ising models, conditional independence, MRF’s, Hammersley-Clifford, and all that other stuff you see in  Koller and Friedman  or something — and then logic and model theory!  I’m impressed.</p><p>3 0.18481296 <a title="54-tfidf-3" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-30-%E2%80%9CLogic_Bomb%E2%80%9D.html">134 brendan oconnor ai-2009-01-30-“Logic Bomb”</a></p>
<p>Introduction: Article:
 
 Fannie Mae Logic Bomb Would Have Caused Weeklong Shutdown | Threat Level from Wired.com .
 
I love the term “logic bomb”.  Can you pair it with a statistics bomb?  Data-driven bomb?  Or maybe the point is a connectionist bomb.</p><p>4 0.18307866 <a title="54-tfidf-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>5 0.14837247 <a title="54-tfidf-5" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-01-Modelling_environmentalism_thinking.html">11 brendan oconnor ai-2005-07-01-Modelling environmentalism thinking</a></p>
<p>Introduction: It’s a human political belief model — based on Cyc!  I’m not sure logic represents how people think all that well, but seeing the formalization of ideology is fascinating.  And besides, the methodology of cognitive modelling is awesome.   The link:  
 Modeling How People Think About Sustainability 
 
David C. James, M. P. Aff
 
LBJ School of Public Affairs The University of Texas at Austin May 2005
 
First Reader: Lodis Rhodes  Second Reader: Chandler Stolp
 
How effectively can a computer model represent the belief systems of different people? How would one go about representing a belief system using formal logic? How would that ideology react to different scenarios related to sustainable development? The author constructs the Cyc Agent-Scenario (CAS) model as a way to investigate these questions. The CAS model is built on top of ResearchCyc, a knowledge base (KB) and logical inference engine. The model consists of two agents (Libertarian and Green) and two scenarios. The model simula</p><p>6 0.12823939 <a title="54-tfidf-6" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>7 0.12278976 <a title="54-tfidf-7" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-02-19-Move_to_brenocon.com.html">165 brendan oconnor ai-2011-02-19-Move to brenocon.com</a></p>
<p>8 0.093522064 <a title="54-tfidf-8" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-02-23-Wasserman_on_Stats_vs_ML%2C_and_previous_comparisons.html">191 brendan oconnor ai-2013-02-23-Wasserman on Stats vs ML, and previous comparisons</a></p>
<p>9 0.080101863 <a title="54-tfidf-9" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>10 0.075480521 <a title="54-tfidf-10" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>11 0.071216449 <a title="54-tfidf-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-15-Beta_conjugate_explorer.html">146 brendan oconnor ai-2009-07-15-Beta conjugate explorer</a></p>
<p>12 0.064435609 <a title="54-tfidf-12" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-06-03-Neuroeconomics_reviews.html">38 brendan oconnor ai-2006-06-03-Neuroeconomics reviews</a></p>
<p>13 0.062491477 <a title="54-tfidf-13" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-25-Information_theory_stuff.html">175 brendan oconnor ai-2011-09-25-Information theory stuff</a></p>
<p>14 0.056493245 <a title="54-tfidf-14" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-Submit_your_poker_data%21.html">25 brendan oconnor ai-2005-09-02-Submit your poker data!</a></p>
<p>15 0.055770073 <a title="54-tfidf-15" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-11-20-science_writing_bad%21.html">28 brendan oconnor ai-2005-11-20-science writing bad!</a></p>
<p>16 0.053806387 <a title="54-tfidf-16" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>17 0.051670238 <a title="54-tfidf-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-funny_comic.html">48 brendan oconnor ai-2007-01-02-funny comic</a></p>
<p>18 0.048763711 <a title="54-tfidf-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>19 0.044901155 <a title="54-tfidf-19" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-20-Log-normal_and_logistic-normal_terminology.html">169 brendan oconnor ai-2011-05-20-Log-normal and logistic-normal terminology</a></p>
<p>20 0.043512352 <a title="54-tfidf-20" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.193), (1, 0.066), (2, 0.046), (3, -0.13), (4, 0.124), (5, 0.283), (6, -0.057), (7, 0.201), (8, -0.01), (9, 0.163), (10, -0.184), (11, 0.207), (12, -0.031), (13, -0.016), (14, -0.068), (15, -0.117), (16, 0.049), (17, -0.25), (18, 0.029), (19, 0.015), (20, 0.136), (21, 0.051), (22, -0.044), (23, -0.103), (24, -0.083), (25, 0.093), (26, -0.003), (27, -0.027), (28, 0.058), (29, -0.046), (30, 0.069), (31, 0.043), (32, -0.027), (33, -0.014), (34, 0.055), (35, 0.041), (36, 0.078), (37, 0.011), (38, 0.008), (39, 0.012), (40, 0.02), (41, 0.045), (42, 0.003), (43, -0.035), (44, -0.015), (45, 0.042), (46, -0.025), (47, -0.019), (48, -0.008), (49, 0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98899579 <a title="54-lsi-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-21-Statistics_is_big-N_logic%3F.html">54 brendan oconnor ai-2007-03-21-Statistics is big-N logic?</a></p>
<p>Introduction: I think I believe one of these things, but I’m not quite sure. 
 Statistics is just like logic, except with uncertainty. 
 
This would be true if statistics is Bayesian statistics and you buy the Bayesian inductive logic story — add induction to propositional logic, via a conditional credibility operator, and the Cox axioms imply standard probability theory as a consequence.  (That is, probability theory is logic with uncertainty.  And then a good Bayesian thinks probability theory and statistics are the same.)  Links:  Jaynes’ explanation ;  SEP article ; also  Fitelson’s article .  (Though there are negative results; all I can think of right now is a  Halpern  article on Cox; and also interesting is  Halpern and Koller .)
 
Secondly, here is another statement.
  

Statistics is just like logic, except with a big N.

  
This is a more data-driven view — the world is full of things and they need to be described.  Logical rules can help you describe things, but you also have to deal wit</p><p>2 0.73319888 <a title="54-lsi-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-30-%E2%80%9CLogic_Bomb%E2%80%9D.html">134 brendan oconnor ai-2009-01-30-“Logic Bomb”</a></p>
<p>Introduction: Article:
 
 Fannie Mae Logic Bomb Would Have Caused Weeklong Shutdown | Threat Level from Wired.com .
 
I love the term “logic bomb”.  Can you pair it with a statistics bomb?  Data-driven bomb?  Or maybe the point is a connectionist bomb.</p><p>3 0.73273456 <a title="54-lsi-3" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-08-09-An_ML-AI_approach_to_P_%21%3D_NP.html">161 brendan oconnor ai-2010-08-09-An ML-AI approach to P != NP</a></p>
<p>Introduction: Like everyone, I’ve been just starting to look at the new, tentative,  proof that P != NP  from Vinay Deolalikar.  After reading the intro, what’s most striking is that probabilistic graphical models and mathematical logic are at the core of the proof.  This feels like a machine learning and artificial intelligence-centric approach to me — very different from what you usually see in mainstream CS theory.  (Maybe I should feel good that in my undergrad I basically stopped studying normal math and spent all my time with this weird stuff instead!)
 
He devotes several chapters to an introduction to graphical models — Ising models, conditional independence, MRF’s, Hammersley-Clifford, and all that other stuff you see in  Koller and Friedman  or something — and then logic and model theory!  I’m impressed.</p><p>4 0.5718866 <a title="54-lsi-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>Introduction: There are an increasing number of systems that attempt to allow the user to specify a probabilistic model in a high-level language — for example, declare a (Bayesian) generative model as a hierarchy of various distributions — then automatically run training and inference algorithms on a data set.  Now, you could always learn a good math library, and implement every model from scratch, but the motivation for this approach is you’ll avoid doing lots of repetitive and error-prone programming.  I’m not yet convinced that any of them completely achieve this goal, but it would be great if they succeeded and we could use high-level frameworks for everything.
 
Everyone seems to know about only a few of them, so here’s a meager attempt to list together a bunch that can be freely downloaded.  There is one package that is far more mature and been around much longer than the rest, so let’s start with:
  
 

 BUGS  – Bayesian Inference under Gibbs Sampling.  Specify a generative model, then it doe</p><p>5 0.53531355 <a title="54-lsi-5" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-01-Modelling_environmentalism_thinking.html">11 brendan oconnor ai-2005-07-01-Modelling environmentalism thinking</a></p>
<p>Introduction: It’s a human political belief model — based on Cyc!  I’m not sure logic represents how people think all that well, but seeing the formalization of ideology is fascinating.  And besides, the methodology of cognitive modelling is awesome.   The link:  
 Modeling How People Think About Sustainability 
 
David C. James, M. P. Aff
 
LBJ School of Public Affairs The University of Texas at Austin May 2005
 
First Reader: Lodis Rhodes  Second Reader: Chandler Stolp
 
How effectively can a computer model represent the belief systems of different people? How would one go about representing a belief system using formal logic? How would that ideology react to different scenarios related to sustainable development? The author constructs the Cyc Agent-Scenario (CAS) model as a way to investigate these questions. The CAS model is built on top of ResearchCyc, a knowledge base (KB) and logical inference engine. The model consists of two agents (Libertarian and Green) and two scenarios. The model simula</p><p>6 0.50039452 <a title="54-lsi-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>7 0.47547132 <a title="54-lsi-7" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-02-19-Move_to_brenocon.com.html">165 brendan oconnor ai-2011-02-19-Move to brenocon.com</a></p>
<p>8 0.38193652 <a title="54-lsi-8" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-02-23-Wasserman_on_Stats_vs_ML%2C_and_previous_comparisons.html">191 brendan oconnor ai-2013-02-23-Wasserman on Stats vs ML, and previous comparisons</a></p>
<p>9 0.31191269 <a title="54-lsi-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-The_Wire%3A_Mr._Nugget.html">126 brendan oconnor ai-2008-11-21-The Wire: Mr. Nugget</a></p>
<p>10 0.25968975 <a title="54-lsi-10" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-15-Beta_conjugate_explorer.html">146 brendan oconnor ai-2009-07-15-Beta conjugate explorer</a></p>
<p>11 0.24783869 <a title="54-lsi-11" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-06-03-Neuroeconomics_reviews.html">38 brendan oconnor ai-2006-06-03-Neuroeconomics reviews</a></p>
<p>12 0.2450899 <a title="54-lsi-12" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-20-Log-normal_and_logistic-normal_terminology.html">169 brendan oconnor ai-2011-05-20-Log-normal and logistic-normal terminology</a></p>
<p>13 0.23588538 <a title="54-lsi-13" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>14 0.23029275 <a title="54-lsi-14" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-Submit_your_poker_data%21.html">25 brendan oconnor ai-2005-09-02-Submit your poker data!</a></p>
<p>15 0.2243005 <a title="54-lsi-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-22-FFT%3A_Friedman_%2B_Fortran_%2B_Tricks.html">147 brendan oconnor ai-2009-07-22-FFT: Friedman + Fortran + Tricks</a></p>
<p>16 0.21979749 <a title="54-lsi-16" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-13-Bayes_update_view_of_pointwise_mutual_information.html">178 brendan oconnor ai-2011-11-13-Bayes update view of pointwise mutual information</a></p>
<p>17 0.21957028 <a title="54-lsi-17" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-04-City_crisis_simulation_%28e.g._terrorist_attack%29.html">14 brendan oconnor ai-2005-07-04-City crisis simulation (e.g. terrorist attack)</a></p>
<p>18 0.21544115 <a title="54-lsi-18" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-11-20-science_writing_bad%21.html">28 brendan oconnor ai-2005-11-20-science writing bad!</a></p>
<p>19 0.21076457 <a title="54-lsi-19" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>20 0.20523235 <a title="54-lsi-20" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-04-21-What_inputs_do_Monte_Carlo_algorithms_need%3F.html">195 brendan oconnor ai-2013-04-21-What inputs do Monte Carlo algorithms need?</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.046), (28, 0.026), (43, 0.025), (44, 0.033), (48, 0.052), (50, 0.032), (74, 0.161), (80, 0.441), (85, 0.039), (91, 0.016), (96, 0.016)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96829498 <a title="54-lda-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-21-Statistics_is_big-N_logic%3F.html">54 brendan oconnor ai-2007-03-21-Statistics is big-N logic?</a></p>
<p>Introduction: I think I believe one of these things, but I’m not quite sure. 
 Statistics is just like logic, except with uncertainty. 
 
This would be true if statistics is Bayesian statistics and you buy the Bayesian inductive logic story — add induction to propositional logic, via a conditional credibility operator, and the Cox axioms imply standard probability theory as a consequence.  (That is, probability theory is logic with uncertainty.  And then a good Bayesian thinks probability theory and statistics are the same.)  Links:  Jaynes’ explanation ;  SEP article ; also  Fitelson’s article .  (Though there are negative results; all I can think of right now is a  Halpern  article on Cox; and also interesting is  Halpern and Koller .)
 
Secondly, here is another statement.
  

Statistics is just like logic, except with a big N.

  
This is a more data-driven view — the world is full of things and they need to be described.  Logical rules can help you describe things, but you also have to deal wit</p><p>2 0.96263206 <a title="54-lda-2" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-20-Log-normal_and_logistic-normal_terminology.html">169 brendan oconnor ai-2011-05-20-Log-normal and logistic-normal terminology</a></p>
<p>Introduction: I was cleaning my office and found a back-of-envelope diagram  Shay  drew me once, so I’m writing it up to not forget.  The definitions of the  logistic-normal  and  log-normal  distributions are a little confusing with regard to their relationship to the normal distribution.  If you draw samples from one, the arrows below show the transformation to make it such you have samples from another.
 
   
 
For example, if  x ~ Normal , then transforming as  y=exp(x)  implies  y ~ LogNormal .  The adjective terminology is inverted: the logistic function goes from normal to logistic-normal, but the log function goes from log-normal to normal (other way!).  The log of the log-normal is normal, but it’s the   logit   of the logistic normal that’s normal.
 
Here are densities of these different distributions via transformations from a standard normal.
 
   In R:   x=rnorm(1e6); hist(x); hist(exp(x)/(1+exp(x)); hist(exp(x)) 
 
Just to make things more confusing, note the logistic-normal distributi</p><p>3 0.93057489 <a title="54-lda-3" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-29-Evangelicals_vs._Aquarians.html">66 brendan oconnor ai-2007-06-29-Evangelicals vs. Aquarians</a></p>
<p>Introduction: Just read an interesting analysis on the the simultaneous rise of the cultural left and right (“hippies and evangelicals”) through the 50′s and 60′s.   Brink Lindsey argues here  that they were both reactions to post-war material prosperity:
  
On the left gathered those who were most alive to the new possibilities created by the unprecedented mass affluence of the postwar years but at the same time were hostile to the social institutions — namely, the market and the middle-class work ethic — that created those possibilities. On the right rallied those who staunchly supported the institutions that created prosperity but who shrank from the social dynamism they were unleashing. One side denounced capitalism but gobbled its fruits; the other cursed the fruits while defending the system that bore them. Both causes were quixotic, and consequently neither fully realized its ambitions.
  
I love  neat sweeping theories of history ; I can’t take it overly seriously but it is so fun.  Lindsey</p><p>4 0.91986859 <a title="54-lda-4" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-04-16-Rise_and_fall_of_Dirichlet_process_clusters.html">194 brendan oconnor ai-2013-04-16-Rise and fall of Dirichlet process clusters</a></p>
<p>Introduction: Here’s Gibbs sampling for a  Dirichlet process 1-d mixture of Gaussians .  On 1000 data points that look like this.
 
   
 
I gave it fixed variance and a concentration and over MCMC iterations, and it looks like this.
 
   
 
The top is the number of points in a cluster.  The bottom are the cluster means.  Every cluster has a unique color.  During MCMC, clusters are created and destroyed.  Every cluster has a unique color; when a cluster dies, its color is never reused.  
 
I’m showing clusters every 100 iterations.  If there is a single point, that cluster was at that iteration but not before or after.  If there is a line, the cluster lived for at least 100 iterations.  Some clusters live long, some live short, but all eventually die.
 
Usually the model likes to think there are about two clusters, occupying positions at the two modes in the data distribution.  It also entertains the existence of several much more minor ones.  Usually these are shortlived clusters that die away.  But</p><p>5 0.51421553 <a title="54-lda-5" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-30-%E2%80%9CLogic_Bomb%E2%80%9D.html">134 brendan oconnor ai-2009-01-30-“Logic Bomb”</a></p>
<p>Introduction: Article:
 
 Fannie Mae Logic Bomb Would Have Caused Weeklong Shutdown | Threat Level from Wired.com .
 
I love the term “logic bomb”.  Can you pair it with a statistics bomb?  Data-driven bomb?  Or maybe the point is a connectionist bomb.</p><p>6 0.45794073 <a title="54-lda-6" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-25-Information_theory_stuff.html">175 brendan oconnor ai-2011-09-25-Information theory stuff</a></p>
<p>7 0.43134898 <a title="54-lda-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>8 0.42024395 <a title="54-lda-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>9 0.41679576 <a title="54-lda-9" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-02-15-Pascal%E2%80%99s_Wager.html">50 brendan oconnor ai-2007-02-15-Pascal’s Wager</a></p>
<p>10 0.40549845 <a title="54-lda-10" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-11-26-How_did_Freud_become_a_respected_humanist%3F%21.html">84 brendan oconnor ai-2007-11-26-How did Freud become a respected humanist?!</a></p>
<p>11 0.4042567 <a title="54-lda-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-01-Binary_classification_evaluation_in_R_via_ROCR.html">136 brendan oconnor ai-2009-04-01-Binary classification evaluation in R via ROCR</a></p>
<p>12 0.38197711 <a title="54-lda-12" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>13 0.37794954 <a title="54-lda-13" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-31-Probabilistic_interpretation_of_the_B3_coreference_resolution_metric.html">199 brendan oconnor ai-2013-08-31-Probabilistic interpretation of the B3 coreference resolution metric</a></p>
<p>14 0.3753773 <a title="54-lda-14" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>15 0.3751936 <a title="54-lda-15" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-05-Evil.html">56 brendan oconnor ai-2007-04-05-Evil</a></p>
<p>16 0.36474758 <a title="54-lda-16" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>17 0.36207849 <a title="54-lda-17" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-04-21-What_inputs_do_Monte_Carlo_algorithms_need%3F.html">195 brendan oconnor ai-2013-04-21-What inputs do Monte Carlo algorithms need?</a></p>
<p>18 0.36014819 <a title="54-lda-18" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-18-Information_cost_and_genocide.html">130 brendan oconnor ai-2008-12-18-Information cost and genocide</a></p>
<p>19 0.35978144 <a title="54-lda-19" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>20 0.35733938 <a title="54-lda-20" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-15-Beta_conjugate_explorer.html">146 brendan oconnor ai-2009-07-15-Beta conjugate explorer</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
