<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>52 brendan oconnor ai-2007-03-15-Computability and induction and ideal rationality and the simpsons</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2007" href="../home/brendan_oconnor_ai-2007_home.html">brendan_oconnor_ai-2007</a> <a title="brendan_oconnor_ai-2007-52" href="#">brendan_oconnor_ai-2007-52</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>52 brendan oconnor ai-2007-03-15-Computability and induction and ideal rationality and the simpsons</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2007-52-html" href="http://brenocon.com/blog/2007/03/computability-and-induction-and-ideal-rationality-and-the-simpsons/">html</a></p><p>Introduction: Don’t have time to read much right now, but received word about a neat-looking paper:  Uncomputability: The Problem of Induction Internalized  by Kevin Kelly.
 
Kevin Kelly’s website has an awesome statement that mirrors thoughts I’ve been having for the last few years — the incredible importance of computational constraints applied to reasoning and rationality:
  
Kuhn teaches that a single, deep success suffices to keep a competing paradign on the table.  Not surprisingly, computational learning theory shows its superiority over ideal theories of rationality when we trade in our ideal agents for more realistic, computable agents.  The foundation of the deep success is a strong structural analogy between the halting problem and the problem of inductive generalization, allowing for a unified treatment of both, from the ground up.  One consequence of the approach is that one can often show that computable agents are forced to choose between ideal rationality and finding the right answer</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Don’t have time to read much right now, but received word about a neat-looking paper:  Uncomputability: The Problem of Induction Internalized  by Kevin Kelly. [sent-1, score-0.219]
</p><p>2 Not surprisingly, computational learning theory shows its superiority over ideal theories of rationality when we trade in our ideal agents for more realistic, computable agents. [sent-3, score-2.053]
</p><p>3 The foundation of the deep success is a strong structural analogy between the halting problem and the problem of inductive generalization, allowing for a unified treatment of both, from the ground up. [sent-4, score-1.52]
</p><p>4 One consequence of the approach is that one can often show that computable agents are forced to choose between ideal rationality and finding the right answer. [sent-5, score-1.681]
</p><p>5 I say “so much the worse for ideal rationality”. [sent-6, score-0.414]
</p><p>6 Another is that there are learning problems that cannot be solved by computational means unless the Humean barrier between theorem proving and the external, empirical data is torn down. [sent-7, score-0.753]
</p><p>7 To make this post worthwhile, here is an insightful Simpsons clip. [sent-9, score-0.114]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ideal', 0.414), ('rationality', 0.306), ('computable', 0.261), ('kevin', 0.193), ('computational', 0.187), ('success', 0.182), ('agents', 0.173), ('deep', 0.173), ('problem', 0.152), ('right', 0.122), ('trade', 0.114), ('realistic', 0.114), ('allowing', 0.114), ('consequence', 0.114), ('forced', 0.114), ('foundation', 0.114), ('inductive', 0.114), ('insightful', 0.114), ('kelly', 0.114), ('solved', 0.114), ('structural', 0.114), ('theorem', 0.114), ('treatment', 0.114), ('unified', 0.114), ('worthwhile', 0.114), ('generalization', 0.104), ('competing', 0.104), ('constraints', 0.104), ('induction', 0.104), ('surprisingly', 0.104), ('incredible', 0.097), ('statement', 0.097), ('ground', 0.097), ('choose', 0.097), ('external', 0.097), ('importance', 0.097), ('received', 0.097), ('unless', 0.097), ('learning', 0.093), ('theories', 0.091), ('thoughts', 0.091), ('thanks', 0.083), ('finding', 0.08), ('awesome', 0.08), ('strong', 0.08), ('keep', 0.077), ('empirical', 0.074), ('website', 0.074), ('problems', 0.074), ('reasoning', 0.072)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="52-tfidf-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Computability_and_induction_and_ideal_rationality_and_the_simpsons.html">52 brendan oconnor ai-2007-03-15-Computability and induction and ideal rationality and the simpsons</a></p>
<p>Introduction: Don’t have time to read much right now, but received word about a neat-looking paper:  Uncomputability: The Problem of Induction Internalized  by Kevin Kelly.
 
Kevin Kelly’s website has an awesome statement that mirrors thoughts I’ve been having for the last few years — the incredible importance of computational constraints applied to reasoning and rationality:
  
Kuhn teaches that a single, deep success suffices to keep a competing paradign on the table.  Not surprisingly, computational learning theory shows its superiority over ideal theories of rationality when we trade in our ideal agents for more realistic, computable agents.  The foundation of the deep success is a strong structural analogy between the halting problem and the problem of inductive generalization, allowing for a unified treatment of both, from the ground up.  One consequence of the approach is that one can often show that computable agents are forced to choose between ideal rationality and finding the right answer</p><p>2 0.14576903 <a title="52-tfidf-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>Introduction: I was planning to write some  WordNet  lookup code tonight.  But instead I’ve learned of too many intersecting things.
 
First, there are a zillion things to do this weekend ( hooray flavorpill ):
 
  Picasso and American Art  exhibit continuing at  SFMOMA .  I saw it very briefly last weekend but want some more.  And Doug claims there’s an interesting photography exhibit there too.
  Reading from  We Don’t Need Another Wave: Dispatches from the Next Generation of Feminists , a fascinating looking book I’ve seen many times in the bookstores around here.  By that I mean at least Modern Times (the neat Mission bookstore) and the Anarchist Collective Bookstore (out on the Haight).  And the reading is at Modern Times,  just down the street  from my house!  Amazing.  Tomorrow at 7:30.
  Since anarchists were just mentioned, fortuitously there also appears: the  Bay Area Anarchist Bookfair  this Saturday and Sunday!  Speakers and books down by Golden Gate Park, oh my.  

 
Can’t say I’m a ra</p><p>3 0.078403696 <a title="52-tfidf-3" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-17-%22Time_will_tell%2C_epistemology_won%E2%80%99t%22.html">65 brendan oconnor ai-2007-06-17-"Time will tell, epistemology won’t"</a></p>
<p>Introduction: Working on applied AI-related problems has really tempered my outlook away from theory.  Apologies for another Rorty-related post, but I loved this little bit I just came across, from  Stanley Fish (on slate.com) : 
 When Rorty concluded one of his dramatically undramatic performances, the hands shot up like quivering spears, and the questions were hurled in outraged tones that were almost comically in contrast to the low-key withdrawn words that had provoked them. 
 
Why outrage? Because more often than not a Rortyan sentence would, with irritatingly little fuss, take away everything his hearers believed in. Take, for example, this little Rortyan gem: “Time will tell; but epistemology won’t.” That is to sayâ€”and the fact that I have recourse to the ponderously academic circumlocution “that is to say” tells its own (for me) sad storyâ€”if you’re putting your faith in some grandly ambitious account of the way we know things and hoping that if you get the account right, you will be that</p><p>4 0.067605972 <a title="52-tfidf-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>5 0.067504942 <a title="52-tfidf-5" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>Introduction: Rational choice has been a huge imperialistic success, growing in popularity and being applied to more and more fields.  Why is this?  It’s not because the rational choice model of decision-making is particularly realistic.  Rather, it’s because rational choice is a  completely specified theory of human behavior , and therefore is great at generating hypotheses.  Given any situation involving people, rational choice can be used to generate a hypothesis about what to expect.  That is, you just ask, “What would a person do to maximize their own benefit?”
 
Similar things have been said about evolutionary psychology: you can always predict behavior by asking “what would hunter-gatherers do?”  Now, certainly both rational choice and evolutionary psychology don’t always generate  correct  hypotheses, but they’re incredibly useful because they at least give you a starting point.
 
Witness the theory of bounded rationality: just like rational choice, except amended to consider computational l</p><p>6 0.067376234 <a title="52-tfidf-6" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-09-01-Double_thesis_action.html">45 brendan oconnor ai-2006-09-01-Double thesis action</a></p>
<p>7 0.058185618 <a title="52-tfidf-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>8 0.057443235 <a title="52-tfidf-8" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>9 0.0553509 <a title="52-tfidf-9" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-1st_International_Conference_on_Computational_Models_of_Argument_%28COMMA06%29.html">5 brendan oconnor ai-2005-06-25-1st International Conference on Computational Models of Argument (COMMA06)</a></p>
<p>10 0.054731872 <a title="52-tfidf-10" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-15-Financial_market_theory_on_the_Daily_Show.html">119 brendan oconnor ai-2008-10-15-Financial market theory on the Daily Show</a></p>
<p>11 0.051157646 <a title="52-tfidf-11" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>12 0.05091089 <a title="52-tfidf-12" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-more_argumentation_%26_AI-formal_modelling_links.html">8 brendan oconnor ai-2005-06-25-more argumentation & AI-formal modelling links</a></p>
<p>13 0.050232731 <a title="52-tfidf-13" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-01-Modelling_environmentalism_thinking.html">11 brendan oconnor ai-2005-07-01-Modelling environmentalism thinking</a></p>
<p>14 0.0462652 <a title="52-tfidf-14" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-idea%3A_Morals_are_heuristics_for_socially_optimal_behavior.html">6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</a></p>
<p>15 0.045672812 <a title="52-tfidf-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>16 0.040872611 <a title="52-tfidf-16" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>17 0.040376179 <a title="52-tfidf-17" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-20-gintis%3A_theoretical_unity_in_the_social_sciences.html">1 brendan oconnor ai-2004-11-20-gintis: theoretical unity in the social sciences</a></p>
<p>18 0.039320055 <a title="52-tfidf-18" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-05-23-Sub-reddit_for_Systems_Science_and_OR.html">104 brendan oconnor ai-2008-05-23-Sub-reddit for Systems Science and OR</a></p>
<p>19 0.039138649 <a title="52-tfidf-19" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-11-20-science_writing_bad%21.html">28 brendan oconnor ai-2005-11-20-science writing bad!</a></p>
<p>20 0.038310301 <a title="52-tfidf-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-17-Pairwise_comparisons_for_relevance_evaluation.html">106 brendan oconnor ai-2008-06-17-Pairwise comparisons for relevance evaluation</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.147), (1, 0.056), (2, -0.02), (3, -0.082), (4, 0.103), (5, -0.056), (6, -0.033), (7, 0.067), (8, -0.029), (9, 0.001), (10, -0.066), (11, 0.034), (12, 0.01), (13, 0.112), (14, 0.031), (15, 0.014), (16, 0.067), (17, 0.046), (18, -0.043), (19, -0.006), (20, -0.078), (21, -0.051), (22, 0.042), (23, -0.072), (24, -0.092), (25, -0.061), (26, 0.017), (27, 0.051), (28, -0.133), (29, -0.052), (30, 0.019), (31, -0.032), (32, 0.027), (33, 0.039), (34, -0.044), (35, 0.1), (36, -0.031), (37, -0.051), (38, -0.11), (39, -0.048), (40, 0.172), (41, 0.007), (42, -0.043), (43, -0.079), (44, 0.05), (45, 0.068), (46, -0.08), (47, 0.078), (48, -0.004), (49, -0.158)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98790509 <a title="52-lsi-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Computability_and_induction_and_ideal_rationality_and_the_simpsons.html">52 brendan oconnor ai-2007-03-15-Computability and induction and ideal rationality and the simpsons</a></p>
<p>Introduction: Don’t have time to read much right now, but received word about a neat-looking paper:  Uncomputability: The Problem of Induction Internalized  by Kevin Kelly.
 
Kevin Kelly’s website has an awesome statement that mirrors thoughts I’ve been having for the last few years — the incredible importance of computational constraints applied to reasoning and rationality:
  
Kuhn teaches that a single, deep success suffices to keep a competing paradign on the table.  Not surprisingly, computational learning theory shows its superiority over ideal theories of rationality when we trade in our ideal agents for more realistic, computable agents.  The foundation of the deep success is a strong structural analogy between the halting problem and the problem of inductive generalization, allowing for a unified treatment of both, from the ground up.  One consequence of the approach is that one can often show that computable agents are forced to choose between ideal rationality and finding the right answer</p><p>2 0.666448 <a title="52-lsi-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>Introduction: I was planning to write some  WordNet  lookup code tonight.  But instead I’ve learned of too many intersecting things.
 
First, there are a zillion things to do this weekend ( hooray flavorpill ):
 
  Picasso and American Art  exhibit continuing at  SFMOMA .  I saw it very briefly last weekend but want some more.  And Doug claims there’s an interesting photography exhibit there too.
  Reading from  We Don’t Need Another Wave: Dispatches from the Next Generation of Feminists , a fascinating looking book I’ve seen many times in the bookstores around here.  By that I mean at least Modern Times (the neat Mission bookstore) and the Anarchist Collective Bookstore (out on the Haight).  And the reading is at Modern Times,  just down the street  from my house!  Amazing.  Tomorrow at 7:30.
  Since anarchists were just mentioned, fortuitously there also appears: the  Bay Area Anarchist Bookfair  this Saturday and Sunday!  Speakers and books down by Golden Gate Park, oh my.  

 
Can’t say I’m a ra</p><p>3 0.51309478 <a title="52-lsi-3" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-09-01-Double_thesis_action.html">45 brendan oconnor ai-2006-09-01-Double thesis action</a></p>
<p>Introduction: Earlier this year, it turned out that  humans socially evolved cooperation through group competition and conflict .  And now, it seems that  biased evidence assimilation can happen through bounded rationality .  Hooray.</p><p>4 0.5059343 <a title="52-lsi-4" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>Introduction: Rational choice has been a huge imperialistic success, growing in popularity and being applied to more and more fields.  Why is this?  It’s not because the rational choice model of decision-making is particularly realistic.  Rather, it’s because rational choice is a  completely specified theory of human behavior , and therefore is great at generating hypotheses.  Given any situation involving people, rational choice can be used to generate a hypothesis about what to expect.  That is, you just ask, “What would a person do to maximize their own benefit?”
 
Similar things have been said about evolutionary psychology: you can always predict behavior by asking “what would hunter-gatherers do?”  Now, certainly both rational choice and evolutionary psychology don’t always generate  correct  hypotheses, but they’re incredibly useful because they at least give you a starting point.
 
Witness the theory of bounded rationality: just like rational choice, except amended to consider computational l</p><p>5 0.48750633 <a title="52-lsi-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-15-Financial_market_theory_on_the_Daily_Show.html">119 brendan oconnor ai-2008-10-15-Financial market theory on the Daily Show</a></p>
<p>Introduction: Deep insight of the moment:
 
         

  
Volatility frequently occurs when everyone suddenly realizes the stock market is just a consensual mass delusion based on fictitious valuings of abstract assets.


It’s like finding out Santa Claus is real because you catch him robbing your house.
  
I wonder what a derivatives market is by that analogy.Â   $596 trillion  worth of hypothetical presents?</p><p>6 0.40738425 <a title="52-lsi-6" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-idea%3A_Morals_are_heuristics_for_socially_optimal_behavior.html">6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</a></p>
<p>7 0.38011265 <a title="52-lsi-7" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-17-%22Time_will_tell%2C_epistemology_won%E2%80%99t%22.html">65 brendan oconnor ai-2007-06-17-"Time will tell, epistemology won’t"</a></p>
<p>8 0.35549769 <a title="52-lsi-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-The_Jungle_Economy.html">47 brendan oconnor ai-2007-01-02-The Jungle Economy</a></p>
<p>9 0.33887029 <a title="52-lsi-9" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>10 0.31668341 <a title="52-lsi-10" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>11 0.31597129 <a title="52-lsi-11" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-04-28-Easterly_vs._Sachs_on_global_poverty.html">35 brendan oconnor ai-2006-04-28-Easterly vs. Sachs on global poverty</a></p>
<p>12 0.3144314 <a title="52-lsi-12" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-04-City_crisis_simulation_%28e.g._terrorist_attack%29.html">14 brendan oconnor ai-2005-07-04-City crisis simulation (e.g. terrorist attack)</a></p>
<p>13 0.29607612 <a title="52-lsi-13" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-1st_International_Conference_on_Computational_Models_of_Argument_%28COMMA06%29.html">5 brendan oconnor ai-2005-06-25-1st International Conference on Computational Models of Argument (COMMA06)</a></p>
<p>14 0.29183114 <a title="52-lsi-14" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>15 0.27677912 <a title="52-lsi-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>16 0.27069879 <a title="52-lsi-16" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-more_argumentation_%26_AI-formal_modelling_links.html">8 brendan oconnor ai-2005-06-25-more argumentation & AI-formal modelling links</a></p>
<p>17 0.27067006 <a title="52-lsi-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-28-Calculating_running_variance_in_Python_and_C%2B%2B.html">128 brendan oconnor ai-2008-11-28-Calculating running variance in Python and C++</a></p>
<p>18 0.2690509 <a title="52-lsi-18" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>19 0.26673692 <a title="52-lsi-19" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-08-Game_outcome_graphs_%E2%80%94_prisoner%E2%80%99s_dilemma_with_FUN_ARROWS%21%21%21.html">68 brendan oconnor ai-2007-07-08-Game outcome graphs — prisoner’s dilemma with FUN ARROWS!!!</a></p>
<p>20 0.26412895 <a title="52-lsi-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-17-Pairwise_comparisons_for_relevance_evaluation.html">106 brendan oconnor ai-2008-06-17-Pairwise comparisons for relevance evaluation</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(44, 0.077), (50, 0.7), (70, 0.022), (74, 0.08)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98712742 <a title="52-lda-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-08-Gapminder.org_%E2%80%94_terrific_world_data_visualizations.html">57 brendan oconnor ai-2007-04-08-Gapminder.org — terrific world data visualizations</a></p>
<p>Introduction: This entry was posted in  Uncategorized . Bookmark the  permalink .</p><p>same-blog 2 0.97683775 <a title="52-lda-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Computability_and_induction_and_ideal_rationality_and_the_simpsons.html">52 brendan oconnor ai-2007-03-15-Computability and induction and ideal rationality and the simpsons</a></p>
<p>Introduction: Don’t have time to read much right now, but received word about a neat-looking paper:  Uncomputability: The Problem of Induction Internalized  by Kevin Kelly.
 
Kevin Kelly’s website has an awesome statement that mirrors thoughts I’ve been having for the last few years — the incredible importance of computational constraints applied to reasoning and rationality:
  
Kuhn teaches that a single, deep success suffices to keep a competing paradign on the table.  Not surprisingly, computational learning theory shows its superiority over ideal theories of rationality when we trade in our ideal agents for more realistic, computable agents.  The foundation of the deep success is a strong structural analogy between the halting problem and the problem of inductive generalization, allowing for a unified treatment of both, from the ground up.  One consequence of the approach is that one can often show that computable agents are forced to choose between ideal rationality and finding the right answer</p><p>3 0.90471345 <a title="52-lda-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-05-23-Sub-reddit_for_Systems_Science_and_OR.html">104 brendan oconnor ai-2008-05-23-Sub-reddit for Systems Science and OR</a></p>
<p>Introduction: I’ve been a big fan of Reddit’s  Programing  subsite for a while.  Just this morning I found another sub-reddit:  SYSOR: Systems Science, Operations Research and Everything In Between , and I’m loving it.  Lots of links on data mining, graph software, image recognition, learning theory, etc etc.
 
Not sure if the Operations Research part in the title is so big now — there’s some sort of complicated reorganization of a number of fields including operations research, systems science, computational learning, and more general computer science areas.  I’m a fan of the great historical overview in the Introduction in  Rusell and Norvig’s AI book ; I’m sure it’s slanted in various ways, but what else are overarching narratives for?  :)</p><p>4 0.81491888 <a title="52-lda-4" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-05-Evil.html">56 brendan oconnor ai-2007-04-05-Evil</a></p>
<p>Introduction: I must be too cynical.  I thought I didn’t like  Philip Zimbardo ‘s theatrics, but regardless I really appreciated  this NYT interview  with him on the universal capacity for evil.     (S.P.E. is the  Stanford Prison Experiment , whose pictures here are from that lovely basement hallway, still there behind the 420-40 and 41 lecture rooms.)
 
In particular: 
 Q. What was your reaction when you first saw those photographs from Abu Ghraib? 
 
A. I was shocked. But not surprised. I immediately flashed on similar pictures from the S.P.E. What particularly bothered me was that the Pentagon blamed the whole thing on a “few bad apples.” I knew from our experiment, if you put good apples into a bad situation, you’ll get bad apples.
 
That was why I was willing to be an expert witness for Sgt. Chip Frederick, who was ultimately sentenced to eight years for his role at Abu Ghraib. Frederick was the Army reservist who was put in charge of the night shift at Tier 1A, where detainees were abused. Fr</p><p>5 0.19462639 <a title="52-lda-5" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-03-26-new_kind_of_science%2C_for_real.html">32 brendan oconnor ai-2006-03-26-new kind of science, for real</a></p>
<p>Introduction: Great Microsoft Research report (from a workshop they held?):   2020 Science  where they argue that computer  science  will become part and parcel of science in general.  For example, computation theory will be important to understand biological organisms as information processing systems.  This is basically a much better version of Wolfram’s  New Kind of Science  argument — I believe this one.  The big shared insight is that computers aren’t just about data storage and number crunching.  Wolfram and the some of the Santa Fe complex systems people are really in to simulations, which is fine.  But there’s tremendous potential in computation  theory  — algorithms, formal representations, and more.  Empirical scientists are going to have to learn this stuff!</p><p>6 0.19286293 <a title="52-lda-6" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-08-13-It%E2%80%99s_all_in_a_name%3A_%22Kingdom_of_Norway%22_vs._%22Democratic_People%E2%80%99s_Republic_of_Korea%22.html">75 brendan oconnor ai-2007-08-13-It’s all in a name: "Kingdom of Norway" vs. "Democratic People’s Republic of Korea"</a></p>
<p>7 0.19095859 <a title="52-lda-7" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>8 0.16863179 <a title="52-lda-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-Netflix_Prize.html">125 brendan oconnor ai-2008-11-21-Netflix Prize</a></p>
<p>9 0.16826886 <a title="52-lda-9" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>10 0.14434646 <a title="52-lda-10" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>11 0.14261147 <a title="52-lda-11" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>12 0.14168462 <a title="52-lda-12" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-17-%22Time_will_tell%2C_epistemology_won%E2%80%99t%22.html">65 brendan oconnor ai-2007-06-17-"Time will tell, epistemology won’t"</a></p>
<p>13 0.14022468 <a title="52-lda-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-27-Seth_Roberts_and_academic_blogging.html">55 brendan oconnor ai-2007-03-27-Seth Roberts and academic blogging</a></p>
<p>14 0.1395324 <a title="52-lda-14" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>15 0.13874009 <a title="52-lda-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>16 0.13806245 <a title="52-lda-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>17 0.13507479 <a title="52-lda-17" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>18 0.13475117 <a title="52-lda-18" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>19 0.13432771 <a title="52-lda-19" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>20 0.13431472 <a title="52-lda-20" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
