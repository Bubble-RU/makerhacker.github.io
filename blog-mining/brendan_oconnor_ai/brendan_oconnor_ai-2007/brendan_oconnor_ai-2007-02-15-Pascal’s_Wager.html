<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>50 brendan oconnor ai-2007-02-15-Pascal’s Wager</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2007" href="../home/brendan_oconnor_ai-2007_home.html">brendan_oconnor_ai-2007</a> <a title="brendan_oconnor_ai-2007-50" href="#">brendan_oconnor_ai-2007-50</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>50 brendan oconnor ai-2007-02-15-Pascal’s Wager</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2007-50-html" href="http://brenocon.com/blog/2007/02/pascals-wager/">html</a></p><p>Introduction: Either God is tricky, or maybe probability is.
 
Pascal’s Wager: Say there’s only a small chance God exists.  If you are an atheist but God does actually exist, He will send you to hell for eternity.  This is infinitely bad.  Therefore you should believe in God on the off-chance he does exist, since a small chance of something infinitely bad is worse than the alternative.
 
 Believe in Pascal’s Wager?  Have I got a deal for you!  says if you believe it, you should send Alex Tabarrok money because he will put in a good word to God for you.  Hey, there’s a small chance he has a direct line to God, which yields infinite utility (or avoids hell’s infinite disutility).
 
FWIW, I’m thinking the paradoxes in this sort of arithmetic always happen when you start doing addition/multiplication distribution across those darn infinities.  Like on the third page Tabarrok starts talking about p1*Inf – p2*Inf = (p1-p2)*Inf.  That’s shady shit.
 
 And more about the big PW .
 
I don’t like the  SEP ent</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Pascal’s Wager: Say there’s only a small chance God exists. [sent-2, score-0.379]
</p><p>2 If you are an atheist but God does actually exist, He will send you to hell for eternity. [sent-3, score-0.371]
</p><p>3 Therefore you should believe in God on the off-chance he does exist, since a small chance of something infinitely bad is worse than the alternative. [sent-5, score-1.013]
</p><p>4 says if you believe it, you should send Alex Tabarrok money because he will put in a good word to God for you. [sent-8, score-0.665]
</p><p>5 Hey, there’s a small chance he has a direct line to God, which yields infinite utility (or avoids hell’s infinite disutility). [sent-9, score-1.174]
</p><p>6 FWIW, I’m thinking the paradoxes in this sort of arithmetic always happen when you start doing addition/multiplication distribution across those darn infinities. [sent-10, score-0.385]
</p><p>7 Like on the third page Tabarrok starts talking about p1*Inf – p2*Inf = (p1-p2)*Inf. [sent-11, score-0.311]
</p><p>8 I don’t like the  SEP entry  on it, because there’s too much history and it talks too much about the boring stuff like the oddness of a decision to believe or disbelieve something. [sent-14, score-0.775]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('god', 0.507), ('inf', 0.242), ('infinite', 0.242), ('wager', 0.242), ('believe', 0.238), ('chance', 0.23), ('tabarrok', 0.211), ('infinitely', 0.211), ('pascal', 0.211), ('send', 0.192), ('hell', 0.179), ('exist', 0.169), ('small', 0.149), ('starts', 0.105), ('pw', 0.105), ('sep', 0.096), ('utility', 0.09), ('boring', 0.09), ('yields', 0.09), ('hey', 0.084), ('arithmetic', 0.084), ('tricky', 0.084), ('entry', 0.08), ('talks', 0.08), ('third', 0.08), ('deal', 0.077), ('direct', 0.074), ('talking', 0.071), ('happen', 0.071), ('something', 0.069), ('decision', 0.069), ('money', 0.066), ('worse', 0.066), ('says', 0.065), ('distribution', 0.061), ('history', 0.061), ('either', 0.061), ('therefore', 0.061), ('probability', 0.059), ('thinking', 0.057), ('line', 0.057), ('start', 0.057), ('across', 0.055), ('page', 0.055), ('stuff', 0.055), ('got', 0.052), ('put', 0.052), ('word', 0.052), ('much', 0.051), ('bad', 0.05)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="50-tfidf-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-02-15-Pascal%E2%80%99s_Wager.html">50 brendan oconnor ai-2007-02-15-Pascal’s Wager</a></p>
<p>Introduction: Either God is tricky, or maybe probability is.
 
Pascal’s Wager: Say there’s only a small chance God exists.  If you are an atheist but God does actually exist, He will send you to hell for eternity.  This is infinitely bad.  Therefore you should believe in God on the off-chance he does exist, since a small chance of something infinitely bad is worse than the alternative.
 
 Believe in Pascal’s Wager?  Have I got a deal for you!  says if you believe it, you should send Alex Tabarrok money because he will put in a good word to God for you.  Hey, there’s a small chance he has a direct line to God, which yields infinite utility (or avoids hell’s infinite disutility).
 
FWIW, I’m thinking the paradoxes in this sort of arithmetic always happen when you start doing addition/multiplication distribution across those darn infinities.  Like on the third page Tabarrok starts talking about p1*Inf – p2*Inf = (p1-p2)*Inf.  That’s shady shit.
 
 And more about the big PW .
 
I don’t like the  SEP ent</p><p>2 0.09697102 <a title="50-tfidf-2" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>Introduction: Since I posted the link to his blog, Baron just  wrote about   Cardinal Schönborn’s anti-evolution Op-Ed piece .  I agree absolutely that people should learn about the psychology of judgment and probability for these sorts of questions, where it’s really hard to understand that random processes can generate things that seem not so random.
 
I’m still thinking about how the psychology of judgment plays in to  the analysis below .  I have a feeling that people’s intuitions are usually too hospitable for explanations based on intention.  E.g.: People are poor, therefore someone is trying to make them poor.  Organizations (corportations, governments) do things, therefore someone (say, at the top) ordered them to do these things.  Natural disasters happen, therefore someone is wishing them upon us.  Etc., etc.  I’m still not sure how a bayesian dissection of whether “looks intentful” implies “is intentful” shows us whether such an “intent-seeking” bias (hey, I have to call it something) is</p><p>3 0.073108725 <a title="50-tfidf-3" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-08-01-Bayesian_analysis_of_intelligent_design_%28revised%21%29.html">23 brendan oconnor ai-2005-08-01-Bayesian analysis of intelligent design (revised!)</a></p>
<p>Introduction: This is a revision of  my earlier post .  In  Jaynes’ awesome statistical manifesto book  ( another link ), I just saw for the second time the odds ratio form of Bayes’ rule, which is a lot cleaner for this sort of static analysis.  So anyway…
   
Pick an organism.  Two propositions, H and E, each may be either true or false about it. 
 H : the organism was designed by an intelligent creator. 
 E : the organism looks like it was designed by an intelligent creator.
 
Most of what I know about Intelligent Design theory (ID) is from seeing a talk by Michael Behe (may 2005).  He had to major lines of argument:  (1) it is implausible that an evolutionary process could produce life that looks as if it was intelligently designed.  (2) Since it looks like it was intelligently designed, it was.  He really emphasized the E component of the argument.
 
Justifications for E: Lots of organisms look like they were intelligently designed.  They have complex and intricate mechanisms involving coordina</p><p>4 0.065101065 <a title="50-tfidf-4" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-08-Gapminder.org_%E2%80%94_terrific_world_data_visualizations.html">57 brendan oconnor ai-2007-04-08-Gapminder.org — terrific world data visualizations</a></p>
<p>Introduction: This entry was posted in  Uncategorized . Bookmark the  permalink .</p><p>5 0.062782504 <a title="50-tfidf-5" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-a_bayesian_analysis_of_intelligent_design.html">17 brendan oconnor ai-2005-07-09-a bayesian analysis of intelligent design</a></p>
<p>Introduction: UPDATE: just wrote  a revision of this .
   
Pick an organism.  Two propositions, H and E, each may be either true or false about it. 
 H : the organism was designed by an intelligent creator. 
 E : the organism looks like it was designed by an intelligent creator.
 
Most of what I know about ID is from seeing a talk by Michael Behe (may 2005).  He had to major lines of argument:  (1) it is implausible that an evolutionary process could produce life that looks as if it was intelligently designed.  (2) Since it looks like it was intelligently designed, it was.  He really emphasized the E component of the argument.
 
Justifications for E: Lots of organisms look like they were intelligently designed.  They have complex and intricate mechanisms involving coordination among many components.  Sometimes they look like things humans would design: for example, bacteria locomotion devices sometimes bear uncanny resemblance to human-designed motors or propellers.
 
Behe was really into showing al</p><p>6 0.061074402 <a title="50-tfidf-6" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-05-Evil.html">56 brendan oconnor ai-2007-04-05-Evil</a></p>
<p>7 0.055865042 <a title="50-tfidf-7" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>8 0.045380156 <a title="50-tfidf-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>9 0.041461799 <a title="50-tfidf-9" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-21-Statistics_is_big-N_logic%3F.html">54 brendan oconnor ai-2007-03-21-Statistics is big-N logic?</a></p>
<p>10 0.039805796 <a title="50-tfidf-10" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-19-End-to-end_NLP_packages.html">174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</a></p>
<p>11 0.039091025 <a title="50-tfidf-11" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-24-Rock_Paper_Scissors_psychology.html">61 brendan oconnor ai-2007-05-24-Rock Paper Scissors psychology</a></p>
<p>12 0.037401225 <a title="50-tfidf-12" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>13 0.037184145 <a title="50-tfidf-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>14 0.035515957 <a title="50-tfidf-14" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>15 0.035308547 <a title="50-tfidf-15" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-03-26-new_kind_of_science%2C_for_real.html">32 brendan oconnor ai-2006-03-26-new kind of science, for real</a></p>
<p>16 0.033140611 <a title="50-tfidf-16" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>17 0.031164221 <a title="50-tfidf-17" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-23-SF_conference_for_data_mining_mercenaries.html">133 brendan oconnor ai-2009-01-23-SF conference for data mining mercenaries</a></p>
<p>18 0.03100943 <a title="50-tfidf-18" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-25-Information_theory_stuff.html">175 brendan oconnor ai-2011-09-25-Information theory stuff</a></p>
<p>19 0.030652441 <a title="50-tfidf-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-08-Blog_move_has_landed.html">115 brendan oconnor ai-2008-10-08-Blog move has landed</a></p>
<p>20 0.029140927 <a title="50-tfidf-20" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-26-monkey_economics_%28and_brothels%29.html">10 brendan oconnor ai-2005-06-26-monkey economics (and brothels)</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.111), (1, 0.049), (2, 0.09), (3, 0.07), (4, -0.023), (5, 0.052), (6, -0.011), (7, 0.005), (8, 0.047), (9, -0.058), (10, -0.038), (11, -0.038), (12, -0.019), (13, -0.034), (14, 0.081), (15, -0.069), (16, -0.059), (17, -0.057), (18, -0.033), (19, -0.075), (20, 0.004), (21, 0.014), (22, 0.038), (23, 0.026), (24, -0.009), (25, 0.062), (26, -0.046), (27, -0.028), (28, -0.033), (29, 0.083), (30, 0.099), (31, 0.122), (32, -0.023), (33, 0.083), (34, 0.0), (35, 0.049), (36, -0.061), (37, -0.057), (38, -0.059), (39, -0.02), (40, 0.096), (41, -0.057), (42, -0.0), (43, -0.037), (44, 0.034), (45, 0.037), (46, 0.139), (47, 0.03), (48, -0.028), (49, -0.014)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98801029 <a title="50-lsi-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-02-15-Pascal%E2%80%99s_Wager.html">50 brendan oconnor ai-2007-02-15-Pascal’s Wager</a></p>
<p>Introduction: Either God is tricky, or maybe probability is.
 
Pascal’s Wager: Say there’s only a small chance God exists.  If you are an atheist but God does actually exist, He will send you to hell for eternity.  This is infinitely bad.  Therefore you should believe in God on the off-chance he does exist, since a small chance of something infinitely bad is worse than the alternative.
 
 Believe in Pascal’s Wager?  Have I got a deal for you!  says if you believe it, you should send Alex Tabarrok money because he will put in a good word to God for you.  Hey, there’s a small chance he has a direct line to God, which yields infinite utility (or avoids hell’s infinite disutility).
 
FWIW, I’m thinking the paradoxes in this sort of arithmetic always happen when you start doing addition/multiplication distribution across those darn infinities.  Like on the third page Tabarrok starts talking about p1*Inf – p2*Inf = (p1-p2)*Inf.  That’s shady shit.
 
 And more about the big PW .
 
I don’t like the  SEP ent</p><p>2 0.56827044 <a title="50-lsi-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-05-Evil.html">56 brendan oconnor ai-2007-04-05-Evil</a></p>
<p>Introduction: I must be too cynical.  I thought I didn’t like  Philip Zimbardo ‘s theatrics, but regardless I really appreciated  this NYT interview  with him on the universal capacity for evil.     (S.P.E. is the  Stanford Prison Experiment , whose pictures here are from that lovely basement hallway, still there behind the 420-40 and 41 lecture rooms.)
 
In particular: 
 Q. What was your reaction when you first saw those photographs from Abu Ghraib? 
 
A. I was shocked. But not surprised. I immediately flashed on similar pictures from the S.P.E. What particularly bothered me was that the Pentagon blamed the whole thing on a “few bad apples.” I knew from our experiment, if you put good apples into a bad situation, you’ll get bad apples.
 
That was why I was willing to be an expert witness for Sgt. Chip Frederick, who was ultimately sentenced to eight years for his role at Abu Ghraib. Frederick was the Army reservist who was put in charge of the night shift at Tier 1A, where detainees were abused. Fr</p><p>3 0.49999198 <a title="50-lsi-3" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>Introduction: I don’t care how lame anyone thinks this is, but economic theorist  Ariel Rubinstein  is the shit.  He’s funny, self-deprecating, and brilliant.  I was just re-reading  his delightful, sarcastic review of Freakonomics .  (Overly dramatized visual depiction below; hey, conflict sells.)
 
    The review consists of excerpts from his own upcoming super-worldwide-bestseller, “Freak-Freakonomics”.  It is full of golden quotes such as: 
  Chapter 2: Why do economists earn more than mathematicians?  
 
…
 
The comparison between architects and prostitutes can be applied to mathematicians and economists: The former are more skilled, highly educated and intelligent.  
 
To elaborate: 
 Levitt has never encountered a girl who dreams of being a prostitute and I have never met a child who dreams of being an economist. Like prostitutes, the skill required of economists is “not necessarily ‘specialized’” (106). And, finally, here is a new explanation for the salary gap between mathematicians and eco</p><p>4 0.49880618 <a title="50-lsi-4" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>Introduction: Since I posted the link to his blog, Baron just  wrote about   Cardinal Schönborn’s anti-evolution Op-Ed piece .  I agree absolutely that people should learn about the psychology of judgment and probability for these sorts of questions, where it’s really hard to understand that random processes can generate things that seem not so random.
 
I’m still thinking about how the psychology of judgment plays in to  the analysis below .  I have a feeling that people’s intuitions are usually too hospitable for explanations based on intention.  E.g.: People are poor, therefore someone is trying to make them poor.  Organizations (corportations, governments) do things, therefore someone (say, at the top) ordered them to do these things.  Natural disasters happen, therefore someone is wishing them upon us.  Etc., etc.  I’m still not sure how a bayesian dissection of whether “looks intentful” implies “is intentful” shows us whether such an “intent-seeking” bias (hey, I have to call it something) is</p><p>5 0.46164018 <a title="50-lsi-5" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>Introduction: Some ex-hedge fund analysts recently started a non-profit devoted to evaluating the effectiveness of hundreds of charities, and  apparently have been making waves (NYT) .  A few interesting reports have been posted on their website,  givewell.net  — they make recommendations for which charities where donors’ money is used most efficiently for saving lives or helping the disadvantaged.
 
(Does anyone else have interesting data on charity effectiveness?  I’ve heard that evaluations are the big thing in philanthropy world now, and certainly the Gates Foundation talks a lot about it.)
 
Obviously this sort of evaluation is tricky, but it  has  to be the right approach.  The NYT article makes them sound like they’re a bit arrogant, which is too bad; on the other hand, any one who makes claims to have better empirical information than the established wisdom will always end up in that dynamic.  (OK, so I love young smart people who come up with better results than a conservative, close-minded</p><p>6 0.37128335 <a title="50-lsi-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<p>7 0.35103586 <a title="50-lsi-7" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-08-01-Bayesian_analysis_of_intelligent_design_%28revised%21%29.html">23 brendan oconnor ai-2005-08-01-Bayesian analysis of intelligent design (revised!)</a></p>
<p>8 0.34294236 <a title="50-lsi-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-29-%22Stanford_Impostor%22.html">62 brendan oconnor ai-2007-05-29-"Stanford Impostor"</a></p>
<p>9 0.33817157 <a title="50-lsi-9" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-a_bayesian_analysis_of_intelligent_design.html">17 brendan oconnor ai-2005-07-09-a bayesian analysis of intelligent design</a></p>
<p>10 0.33488008 <a title="50-lsi-10" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-The_Wire%3A_Mr._Nugget.html">126 brendan oconnor ai-2008-11-21-The Wire: Mr. Nugget</a></p>
<p>11 0.33329019 <a title="50-lsi-11" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-03-31-How_Facebook_privacy_failed_me.html">158 brendan oconnor ai-2010-03-31-How Facebook privacy failed me</a></p>
<p>12 0.32736081 <a title="50-lsi-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-23-SF_conference_for_data_mining_mercenaries.html">133 brendan oconnor ai-2009-01-23-SF conference for data mining mercenaries</a></p>
<p>13 0.31675181 <a title="50-lsi-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-08-Game_outcome_graphs_%E2%80%94_prisoner%E2%80%99s_dilemma_with_FUN_ARROWS%21%21%21.html">68 brendan oconnor ai-2007-07-08-Game outcome graphs — prisoner’s dilemma with FUN ARROWS!!!</a></p>
<p>14 0.31640205 <a title="50-lsi-14" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-08-Gapminder.org_%E2%80%94_terrific_world_data_visualizations.html">57 brendan oconnor ai-2007-04-08-Gapminder.org — terrific world data visualizations</a></p>
<p>15 0.31065851 <a title="50-lsi-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-05-Obama_street_celebrations_in_San_Francisco.html">122 brendan oconnor ai-2008-11-05-Obama street celebrations in San Francisco</a></p>
<p>16 0.29083276 <a title="50-lsi-16" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-17-%22Time_will_tell%2C_epistemology_won%E2%80%99t%22.html">65 brendan oconnor ai-2007-06-17-"Time will tell, epistemology won’t"</a></p>
<p>17 0.29064479 <a title="50-lsi-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-Anarchy_vs._social_order_in_Somalia.html">46 brendan oconnor ai-2007-01-02-Anarchy vs. social order in Somalia</a></p>
<p>18 0.28729597 <a title="50-lsi-18" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-26-What_is_experimental_philosophy%3F.html">87 brendan oconnor ai-2007-12-26-What is experimental philosophy?</a></p>
<p>19 0.28615454 <a title="50-lsi-19" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>20 0.27890772 <a title="50-lsi-20" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-04-28-Easterly_vs._Sachs_on_global_poverty.html">35 brendan oconnor ai-2006-04-28-Easterly vs. Sachs on global poverty</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(44, 0.043), (50, 0.019), (74, 0.184), (80, 0.056), (85, 0.562)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94544607 <a title="50-lda-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-02-15-Pascal%E2%80%99s_Wager.html">50 brendan oconnor ai-2007-02-15-Pascal’s Wager</a></p>
<p>Introduction: Either God is tricky, or maybe probability is.
 
Pascal’s Wager: Say there’s only a small chance God exists.  If you are an atheist but God does actually exist, He will send you to hell for eternity.  This is infinitely bad.  Therefore you should believe in God on the off-chance he does exist, since a small chance of something infinitely bad is worse than the alternative.
 
 Believe in Pascal’s Wager?  Have I got a deal for you!  says if you believe it, you should send Alex Tabarrok money because he will put in a good word to God for you.  Hey, there’s a small chance he has a direct line to God, which yields infinite utility (or avoids hell’s infinite disutility).
 
FWIW, I’m thinking the paradoxes in this sort of arithmetic always happen when you start doing addition/multiplication distribution across those darn infinities.  Like on the third page Tabarrok starts talking about p1*Inf – p2*Inf = (p1-p2)*Inf.  That’s shady shit.
 
 And more about the big PW .
 
I don’t like the  SEP ent</p><p>2 0.90111417 <a title="50-lda-2" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-04-24-The_identity_politics_of_satananic_zombie_alien_man-beasts.html">33 brendan oconnor ai-2006-04-24-The identity politics of satananic zombie alien man-beasts</a></p>
<p>Introduction: I thought  Eurovision  was weird enough already.  But in addition to the usual fun mix of kitschy pop and Cold War legacy nationalism in its telephone voting politics, this year will see Finland’s satanic band Lordi: 
 HELSINKI, Finland â€” They have eight-foot retractable latex Satan wings, sing hits like “Chainsaw Buffet” and blow up slabs of smoking meat on stage. So members of the band Lordi expected a reaction when they beat a crooner of love ballads to represent Finland at the Eurovision song contest in Athens, the competition that was the springboard for Abba and Celine Dion. 
 
    
 “In Finland, we have no Eiffel Tower, few real famous artists, it is freezing cold and we suffer from low self-esteem,” said Mr. Putaansuu, who, as Lordi, has horns protruding from his forehead and sports long black fingernails. 
 
As he stuck out his tongue menacingly, his red demon eyes glaring, Lordi was surrounded by Kita, an alien-man-beast predator who plays flame-spitting drums inside a cage</p><p>3 0.86767972 <a title="50-lda-3" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-26-What_is_experimental_philosophy%3F.html">87 brendan oconnor ai-2007-12-26-What is experimental philosophy?</a></p>
<p>Introduction: Experimental philosophy:  
 Suppose the chairman of a company has to decide whether to adopt a new program. It would increase profits and help the environment too. “I don’t care at all about helping the environment,” the chairman says. “I just want to make as much profit as I can. Let’s start the new program.” Would you say that the chairman intended to help the environment? 
 
O.K., same circumstance. Except this time the program would harm the environment. The chairman, who still couldn’t care less about the environment, authorizes the program in order to get those profits. As expected, the bottom line goes up, the environment goes down. Would you say the chairman harmed the environment intentionally?
 
in one survey, only 23 percent of people said that the chairman in the first situation had intentionally helped the environment. When they had to think about the second situation, though, fully 82 percent thought that the chairman had intentionally harmed the environment. There’s plen</p><p>4 0.31660983 <a title="50-lda-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>Introduction: This is a good idea: in a search engine’s query logs, look for outbreaks of queries like [[flu symptoms]] in a given region.  I’ve heard (from  Roddy ) that this trick also works well on Facebook statuses (e.g. “Feeling crappy this morning, think I just got the flu”).
  
  Google Uses Web Searches to Track Flu’s Spread – NYTimes.com  
  Google Flu Trends – google.org  
  
For an example with a publicly available data feed, these queries works decently well on Twitter search:
 
 [[ flu -shot -google ]]  (high recall)
 
 [[ "muscle aches" flu -shot ]]  (high precision)
     
 
The “muscle aches” query is too sparse and the general query is too noisy, but you could imagine some more tricks to clean it up, then train a classifier, etc.  With a bit more work it looks like geolocation information can be had out of the  Twitter search API .</p><p>5 0.31658655 <a title="50-lda-5" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>Introduction: I’ve had several people ask me what the numbers in  ACL  reviews mean — and I can’t find anywhere online where they’re described.  (Can anyone point this out if it is somewhere?)
 
So here’s the review form, below.  They all go from 1 to 5, with 5 the best.  I think the review emails to authors only include a subset of the below — for example, “Overall Recommendation” is not included?
 
The CFP said that they have different types of review forms for different types of papers.  I think this one is for a standard full paper.  I guess what people  really  want to know is what scores tend to correspond to acceptances.  I really have no idea and I get the impression this can change year to year.  I have no involvement with the ACL conference besides being one of many, many reviewers.
 
  
  
APPROPRIATENESS (1-5)
Does the paper fit in ACL 2014? (Please answer this question in light of the desire to broaden the scope of the research areas represented at ACL.) 

5: Certainly. 
4: Probabl</p><p>6 0.31548092 <a title="50-lda-6" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>7 0.31547391 <a title="50-lda-7" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>8 0.31541559 <a title="50-lda-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-05-Clinton-Obama_support_visualization.html">105 brendan oconnor ai-2008-06-05-Clinton-Obama support visualization</a></p>
<p>9 0.3153891 <a title="50-lda-9" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>10 0.31465566 <a title="50-lda-10" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>11 0.30885667 <a title="50-lda-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Another_R_flashmob_today.html">152 brendan oconnor ai-2009-09-08-Another R flashmob today</a></p>
<p>12 0.29680729 <a title="50-lda-12" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-21-Statistics_is_big-N_logic%3F.html">54 brendan oconnor ai-2007-03-21-Statistics is big-N logic?</a></p>
<p>13 0.28948581 <a title="50-lda-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-05-Evil.html">56 brendan oconnor ai-2007-04-05-Evil</a></p>
<p>14 0.2645607 <a title="50-lda-14" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>15 0.26118585 <a title="50-lda-15" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>16 0.25994846 <a title="50-lda-16" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>17 0.25979877 <a title="50-lda-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>18 0.24721 <a title="50-lda-18" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>19 0.24647798 <a title="50-lda-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-18-Information_cost_and_genocide.html">130 brendan oconnor ai-2008-12-18-Information cost and genocide</a></p>
<p>20 0.2453756 <a title="50-lda-20" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-idea%3A_Morals_are_heuristics_for_socially_optimal_behavior.html">6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
