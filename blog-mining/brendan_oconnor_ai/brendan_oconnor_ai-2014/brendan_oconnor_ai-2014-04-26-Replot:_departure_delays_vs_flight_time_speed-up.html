<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>204 brendan oconnor ai-2014-04-26-Replot: departure delays vs flight time speed-up</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2014" href="../home/brendan_oconnor_ai-2014_home.html">brendan_oconnor_ai-2014</a> <a title="brendan_oconnor_ai-2014-204" href="#">brendan_oconnor_ai-2014-204</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>204 brendan oconnor ai-2014-04-26-Replot: departure delays vs flight time speed-up</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2014-204-html" href="http://brenocon.com/blog/2014/04/replot-departure-delays-vs-flight-time-speed-up/">html</a></p><p>Introduction: Here’s a re-plotting of a graph in  this 538 post .  It’s looking at whether pilots speed up the flight when there’s a delay, and find that it looks like that’s the case.  This is averaged data for flights on several major transcontinental routes.
 
I’ve replotted the main graph as follows.  The x-axis is departure delay.  The y-axis is the total trip time — number of minutes since the scheduled departure time.  For an on-time departure, the average flight is 5 hours, 44 minutes.  The blue line shows what the total trip time would be if the delayed flight took that long.  Gray lines are uncertainty (I think the CI due to averaging).
 
   
 
What’s going on is, the pilots seem to be targeting a total trip time of 370-380 minutes or so.  If the departure is only slightly delayed by 10 minutes, the flight time is still the same, but delays in the 30-50 minutes range see a faster flight time which makes up for some of the delay.
 
The original post plotted the y-axis as the delta against t</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Here’s a re-plotting of a graph in  this 538 post . [sent-1, score-0.196]
</p><p>2 It’s looking at whether pilots speed up the flight when there’s a delay, and find that it looks like that’s the case. [sent-2, score-0.8]
</p><p>3 This is averaged data for flights on several major transcontinental routes. [sent-3, score-0.054]
</p><p>4 The y-axis is the total trip time — number of minutes since the scheduled departure time. [sent-6, score-1.226]
</p><p>5 For an on-time departure, the average flight is 5 hours, 44 minutes. [sent-7, score-0.641]
</p><p>6 The blue line shows what the total trip time would be if the delayed flight took that long. [sent-8, score-1.503]
</p><p>7 Gray lines are uncertainty (I think the CI due to averaging). [sent-9, score-0.17]
</p><p>8 What’s going on is, the pilots seem to be targeting a total trip time of 370-380 minutes or so. [sent-10, score-1.043]
</p><p>9 If the departure is only slightly delayed by 10 minutes, the flight time is still the same, but delays in the 30-50 minutes range see a faster flight time which makes up for some of the delay. [sent-11, score-2.426]
</p><p>10 The original post plotted the y-axis as the delta against the expected travel time (delta against 5hr44min). [sent-12, score-0.882]
</p><p>11 It’s good at showing that the difference does really exist, but it’s harder to see the apparent “target travel time”. [sent-13, score-0.362]
</p><p>12 Also, I wonder if the grand averaging approach — which averages totally different routes — is necessarily the best. [sent-14, score-0.463]
</p><p>13 It seems like the analysis might be better by adjusting for different expected times for different routes. [sent-15, score-0.432]
</p><p>14 The original post is also interested in comparing average flight times by different airlines. [sent-16, score-1.067]
</p><p>15 You might have to go to linear regression to do all this at once. [sent-17, score-0.101]
</p><p>16 I got the data by pulling it out of 538′s plot using the new-to-me tool  WebPlotDigitizer . [sent-18, score-0.112]
</p><p>17 I put files and plotting code at  github/brendano/flight_delays . [sent-20, score-0.146]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('flight', 0.549), ('departure', 0.366), ('trip', 0.275), ('minutes', 0.255), ('delayed', 0.183), ('pilots', 0.183), ('travel', 0.183), ('time', 0.174), ('delta', 0.159), ('total', 0.156), ('averaging', 0.128), ('expected', 0.116), ('post', 0.101), ('graph', 0.095), ('average', 0.092), ('different', 0.091), ('original', 0.088), ('times', 0.082), ('handy', 0.08), ('ci', 0.08), ('files', 0.073), ('plotting', 0.073), ('target', 0.068), ('averages', 0.068), ('grand', 0.068), ('uncertainty', 0.068), ('speed', 0.068), ('apparent', 0.064), ('hours', 0.064), ('exist', 0.064), ('comparing', 0.064), ('range', 0.064), ('harder', 0.061), ('blue', 0.061), ('plotted', 0.061), ('took', 0.058), ('slightly', 0.058), ('main', 0.056), ('plot', 0.056), ('tool', 0.056), ('necessarily', 0.054), ('major', 0.054), ('difference', 0.054), ('totally', 0.054), ('faster', 0.054), ('might', 0.052), ('due', 0.052), ('lines', 0.05), ('regression', 0.049), ('shows', 0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="204-tfidf-1" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-04-26-Replot%3A_departure_delays_vs_flight_time_speed-up.html">204 brendan oconnor ai-2014-04-26-Replot: departure delays vs flight time speed-up</a></p>
<p>Introduction: Here’s a re-plotting of a graph in  this 538 post .  It’s looking at whether pilots speed up the flight when there’s a delay, and find that it looks like that’s the case.  This is averaged data for flights on several major transcontinental routes.
 
I’ve replotted the main graph as follows.  The x-axis is departure delay.  The y-axis is the total trip time — number of minutes since the scheduled departure time.  For an on-time departure, the average flight is 5 hours, 44 minutes.  The blue line shows what the total trip time would be if the delayed flight took that long.  Gray lines are uncertainty (I think the CI due to averaging).
 
   
 
What’s going on is, the pilots seem to be targeting a total trip time of 370-380 minutes or so.  If the departure is only slightly delayed by 10 minutes, the flight time is still the same, but delays in the 30-50 minutes range see a faster flight time which makes up for some of the delay.
 
The original post plotted the y-axis as the delta against t</p><p>2 0.082485288 <a title="204-tfidf-2" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>Introduction: Update Aug 10: THIS IS NOT A SUMMARY OF THE WHOLE PAPER!  it’s whining about one particular method of analysis before talking about other things further down
   
A quick note on  Berg-Kirkpatrick et al EMNLP-2012, “An Empirical Investigation of Statistical Signiﬁcance in NLP” .  They make lots of graphs of p-values against observed magnitudes and talk about “curves”, e.g.
 
 We see the same curve-shaped trend we saw for summarization and dependency parsing. Different group comparisons, same group comparisons, and system combination comparisons form distinct curves. 
 
For example, Figure 2.
 
   
 
I fear they made 10 graphs to rediscover a basic statistical fact: a p-value comes from a null hypothesis CDF.  That’s what these “curve-shaped trends” are in all their graphs.  They are CDFs.
 
To back up, the statistical significance testing question is whether, in their notation, the observed dataset performance difference \(\delta(x)\) is “real” or not: if you were to resample the data,</p><p>3 0.069721557 <a title="204-tfidf-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-08-16-A_better_Obama_vs_McCain_poll_aggregation.html">111 brendan oconnor ai-2008-08-16-A better Obama vs McCain poll aggregation</a></p>
<p>Introduction: Update:  Charles Franklin (of Pollster.com) kindly emailed me with many interesting points on this post.  One important note is that my technique isn’t really “no smoothing” — rather, there is now implicit smoothing within the polling houses, by assuming that responses are evenly distributed across the time interval of the poll.
   I was looking at Pollster.com’s page that aggregates many opinion polls on the Presidential race.    Here, they have a chart   that shows the many polls plus lowess fits: 
   
 
So there’s a trend of Obama recently declining.  But it wasn’t clear to me that the fitted curve was correct.  I downloaded the data and started playing around with it.
 
Here are several more graphs I made, with different smoothing parameters for the lowess fit.  Your interpretation completely changes depending which smoothing parameter you like best!
 
   
 
Well, maybe this is an argument to use rolling averages over a fixed number of days or something.  But it would be nice to di</p><p>4 0.066323966 <a title="204-tfidf-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-01-Bias_correction_sneak_peek%21.html">108 brendan oconnor ai-2008-07-01-Bias correction sneak peek!</a></p>
<p>Introduction: (Update 10/2008: actually this model doesn’t work in all cases.Â   In the final paper  we use an (even) simpler model.)
 
I really don’t have time to write up an explanation for what this is so I’ll just post the graph instead.  Each box is a scatterplot of an AMT worker’s responses versus a gold standard.  Drawn are attempts to fit linear models to each worker.  The idea is to correct for the biases of each worker.  With a linear model y ~ ax+b, the correction is correction(y) = (y-b)/a.  Arrows show such corrections.  Hilariously bad “corrections” happen.  *But*, there is also weighting: to get the “correct” answer (maximum likelihood) from several workers, you weight by a^2/stddev^2.  Despite the sometimes odd corrections, the cross-validated results from this model correlate better with the gold than the raw averaging of workers.  (Raw averaging is the maximum likelihood solution for a fixed noise model: a=1, b=0, and each worker’s variance is equal).
 
Much better explanation is c</p><p>5 0.05572943 <a title="204-tfidf-5" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-11-Memorizing_small_tables.html">177 brendan oconnor ai-2011-11-11-Memorizing small tables</a></p>
<p>Introduction: Lately, I’ve been trying  to memorize very small tables, especially for better intuitions and rule-of-thumb calculations.  At the moment I have these above my desk:
 
   
 
The first one is a few entries in a natural logarithm table.  There are all these stories about how in the slide rule era, people would develop better intuitions about the scale of logarithms because they physically engaged with them all the time.  I spend lots of time looking at log-likelihoods, log-odds-ratios, and logistic regression coefficients, so I think it would be nice to have quick intuitions about what they are.  (Though the  Gelman and Hill  textbook has an interesting argument against odds scale interpretations of logistic regression coefficients.)
 
The second one are some zsh filename manipulation  shortcuts .  OK, this is more narrow than the others, but pretty useful for me at least.
 
The third one are rough unit equivalencies for data rates over time.  I find this very important for quickly determ</p><p>6 0.05452263 <a title="204-tfidf-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-04-06-a_regression_slope_is_a_weighted_average_of_pairs%E2%80%99_slopes%21.html">100 brendan oconnor ai-2008-04-06-a regression slope is a weighted average of pairs’ slopes!</a></p>
<p>7 0.052133773 <a title="204-tfidf-7" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>8 0.049022548 <a title="204-tfidf-8" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>9 0.048057113 <a title="204-tfidf-9" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>10 0.047253527 <a title="204-tfidf-10" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-11-24-Graphs_for_SANCL-2012_web_parsing_results.html">189 brendan oconnor ai-2012-11-24-Graphs for SANCL-2012 web parsing results</a></p>
<p>11 0.04575469 <a title="204-tfidf-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>12 0.045276888 <a title="204-tfidf-12" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-04-16-Rise_and_fall_of_Dirichlet_process_clusters.html">194 brendan oconnor ai-2013-04-16-Rise and fall of Dirichlet process clusters</a></p>
<p>13 0.043734998 <a title="204-tfidf-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<p>14 0.042008534 <a title="204-tfidf-14" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-01-02-Interactive_visualization_of_Mixture_of_Gaussians%2C_the_Law_of_Total_Expectation_and_the_Law_of_Total_Variance.html">163 brendan oconnor ai-2011-01-02-Interactive visualization of Mixture of Gaussians, the Law of Total Expectation and the Law of Total Variance</a></p>
<p>15 0.041666944 <a title="204-tfidf-15" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-01-11-Please_report_your_SVM%E2%80%99s_kernel%21.html">164 brendan oconnor ai-2011-01-11-Please report your SVM’s kernel!</a></p>
<p>16 0.04062438 <a title="204-tfidf-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-16-Is_religion_the_opiate_of_the_elite%3F.html">120 brendan oconnor ai-2008-10-16-Is religion the opiate of the elite?</a></p>
<p>17 0.038873628 <a title="204-tfidf-17" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-22-FFT%3A_Friedman_%2B_Fortran_%2B_Tricks.html">147 brendan oconnor ai-2009-07-22-FFT: Friedman + Fortran + Tricks</a></p>
<p>18 0.038699392 <a title="204-tfidf-18" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>19 0.036896445 <a title="204-tfidf-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-05-Obama_street_celebrations_in_San_Francisco.html">122 brendan oconnor ai-2008-11-05-Obama street celebrations in San Francisco</a></p>
<p>20 0.036609616 <a title="204-tfidf-20" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-11-15-Actually_that_2008_elections_voter_fMRI_study_is_batshit_insane_%28and_sleazy_too%29.html">83 brendan oconnor ai-2007-11-15-Actually that 2008 elections voter fMRI study is batshit insane (and sleazy too)</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.143), (1, -0.077), (2, 0.054), (3, -0.02), (4, -0.04), (5, 0.015), (6, -0.052), (7, -0.069), (8, 0.028), (9, -0.021), (10, 0.007), (11, -0.037), (12, -0.04), (13, -0.038), (14, -0.105), (15, -0.008), (16, -0.101), (17, 0.058), (18, 0.02), (19, 0.012), (20, 0.04), (21, -0.006), (22, 0.017), (23, 0.002), (24, -0.019), (25, 0.026), (26, -0.071), (27, -0.026), (28, -0.066), (29, -0.052), (30, -0.004), (31, 0.042), (32, 0.059), (33, 0.092), (34, -0.061), (35, -0.057), (36, -0.013), (37, -0.089), (38, -0.006), (39, 0.117), (40, 0.02), (41, -0.047), (42, -0.059), (43, 0.05), (44, -0.099), (45, -0.074), (46, -0.016), (47, 0.005), (48, -0.087), (49, 0.032)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97010469 <a title="204-lsi-1" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-04-26-Replot%3A_departure_delays_vs_flight_time_speed-up.html">204 brendan oconnor ai-2014-04-26-Replot: departure delays vs flight time speed-up</a></p>
<p>Introduction: Here’s a re-plotting of a graph in  this 538 post .  It’s looking at whether pilots speed up the flight when there’s a delay, and find that it looks like that’s the case.  This is averaged data for flights on several major transcontinental routes.
 
I’ve replotted the main graph as follows.  The x-axis is departure delay.  The y-axis is the total trip time — number of minutes since the scheduled departure time.  For an on-time departure, the average flight is 5 hours, 44 minutes.  The blue line shows what the total trip time would be if the delayed flight took that long.  Gray lines are uncertainty (I think the CI due to averaging).
 
   
 
What’s going on is, the pilots seem to be targeting a total trip time of 370-380 minutes or so.  If the departure is only slightly delayed by 10 minutes, the flight time is still the same, but delays in the 30-50 minutes range see a faster flight time which makes up for some of the delay.
 
The original post plotted the y-axis as the delta against t</p><p>2 0.66823095 <a title="204-lsi-2" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-08-16-A_better_Obama_vs_McCain_poll_aggregation.html">111 brendan oconnor ai-2008-08-16-A better Obama vs McCain poll aggregation</a></p>
<p>Introduction: Update:  Charles Franklin (of Pollster.com) kindly emailed me with many interesting points on this post.  One important note is that my technique isn’t really “no smoothing” — rather, there is now implicit smoothing within the polling houses, by assuming that responses are evenly distributed across the time interval of the poll.
   I was looking at Pollster.com’s page that aggregates many opinion polls on the Presidential race.    Here, they have a chart   that shows the many polls plus lowess fits: 
   
 
So there’s a trend of Obama recently declining.  But it wasn’t clear to me that the fitted curve was correct.  I downloaded the data and started playing around with it.
 
Here are several more graphs I made, with different smoothing parameters for the lowess fit.  Your interpretation completely changes depending which smoothing parameter you like best!
 
   
 
Well, maybe this is an argument to use rolling averages over a fixed number of days or something.  But it would be nice to di</p><p>3 0.59892941 <a title="204-lsi-3" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-11-Memorizing_small_tables.html">177 brendan oconnor ai-2011-11-11-Memorizing small tables</a></p>
<p>Introduction: Lately, I’ve been trying  to memorize very small tables, especially for better intuitions and rule-of-thumb calculations.  At the moment I have these above my desk:
 
   
 
The first one is a few entries in a natural logarithm table.  There are all these stories about how in the slide rule era, people would develop better intuitions about the scale of logarithms because they physically engaged with them all the time.  I spend lots of time looking at log-likelihoods, log-odds-ratios, and logistic regression coefficients, so I think it would be nice to have quick intuitions about what they are.  (Though the  Gelman and Hill  textbook has an interesting argument against odds scale interpretations of logistic regression coefficients.)
 
The second one are some zsh filename manipulation  shortcuts .  OK, this is more narrow than the others, but pretty useful for me at least.
 
The third one are rough unit equivalencies for data rates over time.  I find this very important for quickly determ</p><p>4 0.4918054 <a title="204-lsi-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<p>Introduction: There’s a lot of exciting work in moral psychology right now.  I’ve been telling various poor fools who listen to me to read something from  Jonathan Haidt  or  Joshua Greene , but of course there’s a sea of too many articles and books of varying quality and intended audience.  But just last week Steven Pinker wrote a great NYT magazine article,  “The Moral Instinct,”  which summarizes current research and tries to spell out a few implications.  I recommend it highly, if just for presenting so many awesome examples.  (Yes, this blog has  poked fun  at Pinker before.  But in any case, he is a brilliant expository writer.   The Language Instinct  is still one of my favorite popular science books.)
 
For a while now I’ve been thinking that recruiting subjects online could lend itself to collecting some really interesting behavioral science data.  A few months ago I tried doing this with  Amazon Mechanical Turk , a horribly misnamed web service that actually lets you create web-based tasks</p><p>5 0.48097602 <a title="204-lsi-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-04-13-Are_women_discriminated_against_in_graduate_admissions%3F_Simpson%E2%80%99s_paradox_via_R_in_three_easy_steps%21.html">101 brendan oconnor ai-2008-04-13-Are women discriminated against in graduate admissions? Simpson’s paradox via R in three easy steps!</a></p>
<p>Introduction: R  has a fun built-in package,  datasets : a whole bunch of easy-to-use, interesting tables of data.  I found the famous UC Berkeley admissions data set, from a 1970′s study of whether sex discrimination existed in graduate admissions.  It’s famous for illustrating a particular statistical paradox.  Thanks to R’s awesome mosaic plots interface, we can see this really easily.
 
UCBAdmissions is a three-dimensional table (like a matrix): Admit Status x Gender x Dept, with counts for each category as the matrix’s values.  R’s default printing shows the basics just fine.  Here’s the data for just the first of six departments:
   >  UCBAdmissions 
, , Dept = A

          Gender
Admit      Male Female
  Admitted  512     89
  Rejected  313     19

...
 
  
Overall,  women have a lower admittance rate than men :
   >  apply(UCBAdmissions,c(1,2),sum) 

          Gender
Admit         M    F
  Admitted 1198  557
  Rejected 1493 1278
 
  
This is the phenomenon that prompted a laws</p><p>6 0.47022209 <a title="204-lsi-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-01-Bias_correction_sneak_peek%21.html">108 brendan oconnor ai-2008-07-01-Bias correction sneak peek!</a></p>
<p>7 0.46710604 <a title="204-lsi-7" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>8 0.4607338 <a title="204-lsi-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-04-06-a_regression_slope_is_a_weighted_average_of_pairs%E2%80%99_slopes%21.html">100 brendan oconnor ai-2008-04-06-a regression slope is a weighted average of pairs’ slopes!</a></p>
<p>9 0.45315233 <a title="204-lsi-9" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>10 0.43082726 <a title="204-lsi-10" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-04-16-Rise_and_fall_of_Dirichlet_process_clusters.html">194 brendan oconnor ai-2013-04-16-Rise and fall of Dirichlet process clusters</a></p>
<p>11 0.42505696 <a title="204-lsi-11" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-04-08-Rough_binomial_confidence_intervals.html">167 brendan oconnor ai-2011-04-08-Rough binomial confidence intervals</a></p>
<p>12 0.41217786 <a title="204-lsi-12" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-05-Obama_street_celebrations_in_San_Francisco.html">122 brendan oconnor ai-2008-11-05-Obama street celebrations in San Francisco</a></p>
<p>13 0.4000974 <a title="204-lsi-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-05-Indicators_of_a_crackpot_paper.html">88 brendan oconnor ai-2008-01-05-Indicators of a crackpot paper</a></p>
<p>14 0.38288763 <a title="204-lsi-14" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-04-28-Easterly_vs._Sachs_on_global_poverty.html">35 brendan oconnor ai-2006-04-28-Easterly vs. Sachs on global poverty</a></p>
<p>15 0.38277 <a title="204-lsi-15" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>16 0.37365252 <a title="204-lsi-16" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-14-R_scan%28%29_for_quick-and-dirty_checks.html">192 brendan oconnor ai-2013-03-14-R scan() for quick-and-dirty checks</a></p>
<p>17 0.36531946 <a title="204-lsi-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-05-Evil.html">56 brendan oconnor ai-2007-04-05-Evil</a></p>
<p>18 0.35591227 <a title="204-lsi-18" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-01-11-Please_report_your_SVM%E2%80%99s_kernel%21.html">164 brendan oconnor ai-2011-01-11-Please report your SVM’s kernel!</a></p>
<p>19 0.35382876 <a title="204-lsi-19" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>20 0.33551288 <a title="204-lsi-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-17-Pairwise_comparisons_for_relevance_evaluation.html">106 brendan oconnor ai-2008-06-17-Pairwise comparisons for relevance evaluation</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(44, 0.101), (55, 0.041), (57, 0.024), (63, 0.483), (70, 0.045), (74, 0.141), (94, 0.039)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.86903822 <a title="204-lda-1" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-04-26-Replot%3A_departure_delays_vs_flight_time_speed-up.html">204 brendan oconnor ai-2014-04-26-Replot: departure delays vs flight time speed-up</a></p>
<p>Introduction: Here’s a re-plotting of a graph in  this 538 post .  It’s looking at whether pilots speed up the flight when there’s a delay, and find that it looks like that’s the case.  This is averaged data for flights on several major transcontinental routes.
 
I’ve replotted the main graph as follows.  The x-axis is departure delay.  The y-axis is the total trip time — number of minutes since the scheduled departure time.  For an on-time departure, the average flight is 5 hours, 44 minutes.  The blue line shows what the total trip time would be if the delayed flight took that long.  Gray lines are uncertainty (I think the CI due to averaging).
 
   
 
What’s going on is, the pilots seem to be targeting a total trip time of 370-380 minutes or so.  If the departure is only slightly delayed by 10 minutes, the flight time is still the same, but delays in the 30-50 minutes range see a faster flight time which makes up for some of the delay.
 
The original post plotted the y-axis as the delta against t</p><p>2 0.31645358 <a title="204-lda-2" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>Introduction: I’ve had several people ask me what the numbers in  ACL  reviews mean — and I can’t find anywhere online where they’re described.  (Can anyone point this out if it is somewhere?)
 
So here’s the review form, below.  They all go from 1 to 5, with 5 the best.  I think the review emails to authors only include a subset of the below — for example, “Overall Recommendation” is not included?
 
The CFP said that they have different types of review forms for different types of papers.  I think this one is for a standard full paper.  I guess what people  really  want to know is what scores tend to correspond to acceptances.  I really have no idea and I get the impression this can change year to year.  I have no involvement with the ACL conference besides being one of many, many reviewers.
 
  
  
APPROPRIATENESS (1-5)
Does the paper fit in ACL 2014? (Please answer this question in light of the desire to broaden the scope of the research areas represented at ACL.) 

5: Certainly. 
4: Probabl</p><p>3 0.31519571 <a title="204-lda-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>Introduction: This is a good idea: in a search engine’s query logs, look for outbreaks of queries like [[flu symptoms]] in a given region.  I’ve heard (from  Roddy ) that this trick also works well on Facebook statuses (e.g. “Feeling crappy this morning, think I just got the flu”).
  
  Google Uses Web Searches to Track Flu’s Spread – NYTimes.com  
  Google Flu Trends – google.org  
  
For an example with a publicly available data feed, these queries works decently well on Twitter search:
 
 [[ flu -shot -google ]]  (high recall)
 
 [[ "muscle aches" flu -shot ]]  (high precision)
     
 
The “muscle aches” query is too sparse and the general query is too noisy, but you could imagine some more tricks to clean it up, then train a classifier, etc.  With a bit more work it looks like geolocation information can be had out of the  Twitter search API .</p><p>4 0.30452782 <a title="204-lda-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>Introduction: This is fun —  Jamie Callan ‘s group at  CMU LTI  just finished a crawl of 1 billion web pages.  It’s 5 terabytes compressed — big enough so they have to send it to you by mailing hard drives.
 
 Link: ClueWeb09 
 
One of their motivations was to have a corpus large enough such that research results on it would be taken seriously by search engine companies.  To my mind, this begs the question whether academics should try to innovate in web search, when it’s a research area incredibly dependent on really large, expensive-to-acquire datasets.  And what’s the point?  To slightly improve Google someday?  Don’t they do that pretty well themselves?
 
On the other hand, having a billion web pages around sounds like a lot of fun.  Someone should get Amazon to add this to the  AWS Public Datasets .  Then, to process the data, instead of paying to get 5 TB of data shipped to you, you instead pay Amazon to rent virtual computers that can access the data.  This costs less only to a certain point,</p><p>5 0.30428016 <a title="204-lda-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>6 0.29830998 <a title="204-lda-6" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>7 0.2981075 <a title="204-lda-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>8 0.29651299 <a title="204-lda-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>9 0.29411358 <a title="204-lda-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-05-Clinton-Obama_support_visualization.html">105 brendan oconnor ai-2008-06-05-Clinton-Obama support visualization</a></p>
<p>10 0.2919032 <a title="204-lda-10" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>11 0.2908479 <a title="204-lda-11" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>12 0.28734291 <a title="204-lda-12" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>13 0.28675684 <a title="204-lda-13" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>14 0.28657705 <a title="204-lda-14" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>15 0.28585541 <a title="204-lda-15" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>16 0.28548115 <a title="204-lda-16" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>17 0.28199568 <a title="204-lda-17" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>18 0.28117698 <a title="204-lda-18" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>19 0.28092653 <a title="204-lda-19" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-08-30-A_big%2C_fun_list_of_links_I%E2%80%99m_reading.html">44 brendan oconnor ai-2006-08-30-A big, fun list of links I’m reading</a></p>
<p>20 0.27846155 <a title="204-lda-20" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
