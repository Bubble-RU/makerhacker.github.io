<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>202 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2014" href="../home/brendan_oconnor_ai-2014_home.html">brendan_oconnor_ai-2014</a> <a title="brendan_oconnor_ai-2014-202" href="#">brendan_oconnor_ai-2014-202</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>202 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2014-202-html" href="http://brenocon.com/blog/2014/02/scatterplot-of-knpyp-language-model-results/">html</a></p><p>Introduction: I should make a blog where all I do is scatterplot results tables from papers.  I do this once in a while to make them eaiser to understand…
 
I think the following are results are from Yee Whye Teh’s paper on hierarchical Pitman-Yor language models, and in particular comparing them to Kneser-Ney and hierarchical Dirichlets.  They’re specifically from  these slides by Yee Whye Teh (page 25) , which shows model perplexities.  Every dot is for one experimental condition, which has four different results from each of the models.  So a pair of models can be compared in one scatterplot.
 
   
 
where
  
   ikn = interpolated kneser-ney
    mkn = modified kneser-ney
    hdlm = hierarchical dirichlet
    hpylm = hierarchical pitman-yor
   
My reading: the KN’s and HPYLM are incredibly similar (as Teh argues should be the case on theoretical grounds).  MKN and HPYLM edge out IKN.  HDLM is markedly worse (this is perplexity, so lower is better).  While HDLM is a lot worse, it does best, relativ</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I should make a blog where all I do is scatterplot results tables from papers. [sent-1, score-0.415]
</p><p>2 I do this once in a while to make them eaiser to understand…   I think the following are results are from Yee Whye Teh’s paper on hierarchical Pitman-Yor language models, and in particular comparing them to Kneser-Ney and hierarchical Dirichlets. [sent-2, score-1.178]
</p><p>3 They’re specifically from  these slides by Yee Whye Teh (page 25) , which shows model perplexities. [sent-3, score-0.295]
</p><p>4 Every dot is for one experimental condition, which has four different results from each of the models. [sent-4, score-0.506]
</p><p>5 So a pair of models can be compared in one scatterplot. [sent-5, score-0.319]
</p><p>6 where       ikn = interpolated kneser-ney     mkn = modified kneser-ney     hdlm = hierarchical dirichlet     hpylm = hierarchical pitman-yor     My reading: the KN’s and HPYLM are incredibly similar (as Teh argues should be the case on theoretical grounds). [sent-6, score-2.098]
</p><p>7 HDLM is markedly worse (this is perplexity, so lower is better). [sent-8, score-0.191]
</p><p>8 While HDLM is a lot worse, it does best, relatively speaking, on shorter contexts — that’s the green dot, the only bigram model that was tested, where there’s only one previous word of context. [sent-9, score-0.602]
</p><p>9 The other models have longer contexts, so I guess the hierarchical summing of pseudocounts screws up the Dirichlet more than the PYP, maybe. [sent-10, score-0.686]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hierarchical', 0.429), ('hdlm', 0.324), ('hpylm', 0.324), ('teh', 0.324), ('mkn', 0.216), ('whye', 0.216), ('yee', 0.216), ('dot', 0.188), ('dirichlet', 0.172), ('scatterplot', 0.151), ('contexts', 0.151), ('models', 0.139), ('results', 0.121), ('worse', 0.119), ('grounds', 0.094), ('condition', 0.094), ('bigram', 0.094), ('perplexity', 0.094), ('shorter', 0.086), ('speaking', 0.086), ('model', 0.084), ('meaning', 0.08), ('four', 0.08), ('slides', 0.08), ('tested', 0.075), ('specifically', 0.075), ('green', 0.075), ('edge', 0.075), ('tables', 0.075), ('comparing', 0.075), ('pair', 0.072), ('lower', 0.072), ('argues', 0.069), ('incredibly', 0.069), ('longer', 0.069), ('make', 0.068), ('theoretical', 0.066), ('experimental', 0.063), ('matrix', 0.061), ('previous', 0.058), ('following', 0.056), ('shows', 0.056), ('size', 0.056), ('understand', 0.054), ('compared', 0.054), ('one', 0.054), ('table', 0.052), ('page', 0.049), ('guess', 0.049), ('every', 0.047)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="202-tfidf-1" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-18-Scatterplot_of_KN-PYP_language_model_results.html">202 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</a></p>
<p>Introduction: I should make a blog where all I do is scatterplot results tables from papers.  I do this once in a while to make them eaiser to understand…
 
I think the following are results are from Yee Whye Teh’s paper on hierarchical Pitman-Yor language models, and in particular comparing them to Kneser-Ney and hierarchical Dirichlets.  They’re specifically from  these slides by Yee Whye Teh (page 25) , which shows model perplexities.  Every dot is for one experimental condition, which has four different results from each of the models.  So a pair of models can be compared in one scatterplot.
 
   
 
where
  
   ikn = interpolated kneser-ney
    mkn = modified kneser-ney
    hdlm = hierarchical dirichlet
    hpylm = hierarchical pitman-yor
   
My reading: the KN’s and HPYLM are incredibly similar (as Teh argues should be the case on theoretical grounds).  MKN and HPYLM edge out IKN.  HDLM is markedly worse (this is perplexity, so lower is better).  While HDLM is a lot worse, it does best, relativ</p><p>2 0.072580986 <a title="202-tfidf-2" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-11-24-Graphs_for_SANCL-2012_web_parsing_results.html">189 brendan oconnor ai-2012-11-24-Graphs for SANCL-2012 web parsing results</a></p>
<p>Introduction: I was just looking at some papers from the  SANCL-2012 workshop on web parsing  from June this year, which are very interesting to those of us who wish we had good parsers for non-newspaper text.  The shared task focus was on domain adaptation from a setting of lots of Wall Street Journal annotated data and very little in-domain training data.  (Previous discussion  here ; see Ryan McDonald’s detailed comment.)   Here are some graphs of the results ( last page in the Petrov & McDonald overview ).
 
I was most interested in whether parsing accuracy on the WSJ correlates to accuracy on web text.  Fortunately, it does.  They evaluated all systems on four evaluation sets: (1) Text from a question/answer site, (2) newsgroups, (3) reviews, and (4) Wall Street Journal PTB.  Here is a graph across system entries, with the x-axis being the labeled dependency parsing accuracy on WSJPTB, and the y-axis the average accuracy on the three web evaluation sets.  Note the axis scales are different: web</p><p>3 0.056064472 <a title="202-tfidf-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-01-Bias_correction_sneak_peek%21.html">108 brendan oconnor ai-2008-07-01-Bias correction sneak peek!</a></p>
<p>Introduction: (Update 10/2008: actually this model doesn’t work in all cases.Â   In the final paper  we use an (even) simpler model.)
 
I really don’t have time to write up an explanation for what this is so I’ll just post the graph instead.  Each box is a scatterplot of an AMT worker’s responses versus a gold standard.  Drawn are attempts to fit linear models to each worker.  The idea is to correct for the biases of each worker.  With a linear model y ~ ax+b, the correction is correction(y) = (y-b)/a.  Arrows show such corrections.  Hilariously bad “corrections” happen.  *But*, there is also weighting: to get the “correct” answer (maximum likelihood) from several workers, you weight by a^2/stddev^2.  Despite the sometimes odd corrections, the cross-validated results from this model correlate better with the gold than the raw averaging of workers.  (Raw averaging is the maximum likelihood solution for a fixed noise model: a=1, b=0, and each worker’s variance is equal).
 
Much better explanation is c</p><p>4 0.052811384 <a title="202-tfidf-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>Introduction: There are an increasing number of systems that attempt to allow the user to specify a probabilistic model in a high-level language — for example, declare a (Bayesian) generative model as a hierarchy of various distributions — then automatically run training and inference algorithms on a data set.  Now, you could always learn a good math library, and implement every model from scratch, but the motivation for this approach is you’ll avoid doing lots of repetitive and error-prone programming.  I’m not yet convinced that any of them completely achieve this goal, but it would be great if they succeeded and we could use high-level frameworks for everything.
 
Everyone seems to know about only a few of them, so here’s a meager attempt to list together a bunch that can be freely downloaded.  There is one package that is far more mature and been around much longer than the rest, so let’s start with:
  
 

 BUGS  – Bayesian Inference under Gibbs Sampling.  Specify a generative model, then it doe</p><p>5 0.050375011 <a title="202-tfidf-5" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-01-Modelling_environmentalism_thinking.html">11 brendan oconnor ai-2005-07-01-Modelling environmentalism thinking</a></p>
<p>Introduction: It’s a human political belief model — based on Cyc!  I’m not sure logic represents how people think all that well, but seeing the formalization of ideology is fascinating.  And besides, the methodology of cognitive modelling is awesome.   The link:  
 Modeling How People Think About Sustainability 
 
David C. James, M. P. Aff
 
LBJ School of Public Affairs The University of Texas at Austin May 2005
 
First Reader: Lodis Rhodes  Second Reader: Chandler Stolp
 
How effectively can a computer model represent the belief systems of different people? How would one go about representing a belief system using formal logic? How would that ideology react to different scenarios related to sustainable development? The author constructs the Cyc Agent-Scenario (CAS) model as a way to investigate these questions. The CAS model is built on top of ResearchCyc, a knowledge base (KB) and logical inference engine. The model consists of two agents (Libertarian and Green) and two scenarios. The model simula</p><p>6 0.050292142 <a title="202-tfidf-6" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-21-iPhone_autocorrection_error_analysis.html">170 brendan oconnor ai-2011-05-21-iPhone autocorrection error analysis</a></p>
<p>7 0.048009265 <a title="202-tfidf-7" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-08-09-An_ML-AI_approach_to_P_%21%3D_NP.html">161 brendan oconnor ai-2010-08-09-An ML-AI approach to P != NP</a></p>
<p>8 0.043149345 <a title="202-tfidf-8" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>9 0.042758431 <a title="202-tfidf-9" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-26-Seeing_how_%E2%80%9Cart%E2%80%9D_and_%E2%80%9Cpharmaceuticals%E2%80%9D_are_linguistically_similar_in_web_text.html">156 brendan oconnor ai-2009-09-26-Seeing how “art” and “pharmaceuticals” are linguistically similar in web text</a></p>
<p>10 0.040050492 <a title="202-tfidf-10" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-more_argumentation_%26_AI-formal_modelling_links.html">8 brendan oconnor ai-2005-06-25-more argumentation & AI-formal modelling links</a></p>
<p>11 0.03995112 <a title="202-tfidf-11" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>12 0.036820438 <a title="202-tfidf-12" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-The_Jungle_Economy.html">47 brendan oconnor ai-2007-01-02-The Jungle Economy</a></p>
<p>13 0.0362169 <a title="202-tfidf-13" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>14 0.035348143 <a title="202-tfidf-14" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-27-Graphics%21_Atari_Breakout_and_religious_text_NLP.html">91 brendan oconnor ai-2008-01-27-Graphics! Atari Breakout and religious text NLP</a></p>
<p>15 0.03449969 <a title="202-tfidf-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-04-06-a_regression_slope_is_a_weighted_average_of_pairs%E2%80%99_slopes%21.html">100 brendan oconnor ai-2008-04-06-a regression slope is a weighted average of pairs’ slopes!</a></p>
<p>16 0.033447221 <a title="202-tfidf-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-16-Is_religion_the_opiate_of_the_elite%3F.html">120 brendan oconnor ai-2008-10-16-Is religion the opiate of the elite?</a></p>
<p>17 0.033199836 <a title="202-tfidf-17" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-20-Log-normal_and_logistic-normal_terminology.html">169 brendan oconnor ai-2011-05-20-Log-normal and logistic-normal terminology</a></p>
<p>18 0.031596869 <a title="202-tfidf-18" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-01-07-Perplexity_as_branching_factor%3B_as_Shannon_diversity_index.html">190 brendan oconnor ai-2013-01-07-Perplexity as branching factor; as Shannon diversity index</a></p>
<p>19 0.030067993 <a title="202-tfidf-19" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-04-16-Rise_and_fall_of_Dirichlet_process_clusters.html">194 brendan oconnor ai-2013-04-16-Rise and fall of Dirichlet process clusters</a></p>
<p>20 0.029826455 <a title="202-tfidf-20" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-20-gintis%3A_theoretical_unity_in_the_social_sciences.html">1 brendan oconnor ai-2004-11-20-gintis: theoretical unity in the social sciences</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.107), (1, -0.04), (2, 0.034), (3, -0.036), (4, 0.04), (5, 0.049), (6, -0.02), (7, -0.024), (8, -0.058), (9, 0.033), (10, -0.024), (11, 0.023), (12, 0.064), (13, 0.039), (14, -0.092), (15, -0.046), (16, -0.065), (17, 0.107), (18, -0.05), (19, 0.013), (20, 0.076), (21, -0.077), (22, 0.056), (23, 0.029), (24, 0.058), (25, 0.018), (26, 0.044), (27, 0.101), (28, -0.03), (29, 0.057), (30, 0.019), (31, 0.035), (32, -0.013), (33, 0.083), (34, -0.01), (35, -0.054), (36, -0.055), (37, -0.006), (38, 0.086), (39, -0.016), (40, 0.051), (41, 0.037), (42, -0.075), (43, -0.054), (44, -0.008), (45, -0.059), (46, 0.048), (47, -0.094), (48, 0.121), (49, -0.131)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98418278 <a title="202-lsi-1" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-18-Scatterplot_of_KN-PYP_language_model_results.html">202 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</a></p>
<p>Introduction: I should make a blog where all I do is scatterplot results tables from papers.  I do this once in a while to make them eaiser to understand…
 
I think the following are results are from Yee Whye Teh’s paper on hierarchical Pitman-Yor language models, and in particular comparing them to Kneser-Ney and hierarchical Dirichlets.  They’re specifically from  these slides by Yee Whye Teh (page 25) , which shows model perplexities.  Every dot is for one experimental condition, which has four different results from each of the models.  So a pair of models can be compared in one scatterplot.
 
   
 
where
  
   ikn = interpolated kneser-ney
    mkn = modified kneser-ney
    hdlm = hierarchical dirichlet
    hpylm = hierarchical pitman-yor
   
My reading: the KN’s and HPYLM are incredibly similar (as Teh argues should be the case on theoretical grounds).  MKN and HPYLM edge out IKN.  HDLM is markedly worse (this is perplexity, so lower is better).  While HDLM is a lot worse, it does best, relativ</p><p>2 0.53105497 <a title="202-lsi-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>Introduction: There are an increasing number of systems that attempt to allow the user to specify a probabilistic model in a high-level language — for example, declare a (Bayesian) generative model as a hierarchy of various distributions — then automatically run training and inference algorithms on a data set.  Now, you could always learn a good math library, and implement every model from scratch, but the motivation for this approach is you’ll avoid doing lots of repetitive and error-prone programming.  I’m not yet convinced that any of them completely achieve this goal, but it would be great if they succeeded and we could use high-level frameworks for everything.
 
Everyone seems to know about only a few of them, so here’s a meager attempt to list together a bunch that can be freely downloaded.  There is one package that is far more mature and been around much longer than the rest, so let’s start with:
  
 

 BUGS  – Bayesian Inference under Gibbs Sampling.  Specify a generative model, then it doe</p><p>3 0.50103015 <a title="202-lsi-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-01-Bias_correction_sneak_peek%21.html">108 brendan oconnor ai-2008-07-01-Bias correction sneak peek!</a></p>
<p>Introduction: (Update 10/2008: actually this model doesn’t work in all cases.Â   In the final paper  we use an (even) simpler model.)
 
I really don’t have time to write up an explanation for what this is so I’ll just post the graph instead.  Each box is a scatterplot of an AMT worker’s responses versus a gold standard.  Drawn are attempts to fit linear models to each worker.  The idea is to correct for the biases of each worker.  With a linear model y ~ ax+b, the correction is correction(y) = (y-b)/a.  Arrows show such corrections.  Hilariously bad “corrections” happen.  *But*, there is also weighting: to get the “correct” answer (maximum likelihood) from several workers, you weight by a^2/stddev^2.  Despite the sometimes odd corrections, the cross-validated results from this model correlate better with the gold than the raw averaging of workers.  (Raw averaging is the maximum likelihood solution for a fixed noise model: a=1, b=0, and each worker’s variance is equal).
 
Much better explanation is c</p><p>4 0.44595623 <a title="202-lsi-4" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-21-iPhone_autocorrection_error_analysis.html">170 brendan oconnor ai-2011-05-21-iPhone autocorrection error analysis</a></p>
<p>Introduction: re  @andrewparker :
  
 My iPhone auto-corrected “Harvard” to “Garbage”. Well played Apple engineers. 
  
I was wondering how this would happen, and then noticed that each character pair has 0 to 2 distance on the QWERTY keyboard.  Perhaps their model is eager to allow QWERTY-local character substitutions.
  
 
>>> zip(‘harvard’,'garbage’) 
[('h', 'g'), ('a', 'a'), ('r', 'r'), ('v', 'b'), ('a', 'a'), ('r', 'g'), ('d', 'e')]
 
  
And then most any language model thinks p(“garbage”) > p(“harvard”), at the very least in a unigram model with a broad domain corpus.  So if it’s a noisy channel-style model, they’re underpenalizing the edit distance relative to the LM prior.  (Reference:  Norvig’s noisy channel spelling correction article .)
 
On the other hand, given how  insane iPhone autocorrections are , and from the number of times I’ve seen it delete a quite reasonable word I wrote, I’d bet “harvard” isn’t even in their LM.  (Where the LM is more like just a dictionary; call it quantizin</p><p>5 0.41969648 <a title="202-lsi-5" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-11-24-Graphs_for_SANCL-2012_web_parsing_results.html">189 brendan oconnor ai-2012-11-24-Graphs for SANCL-2012 web parsing results</a></p>
<p>Introduction: I was just looking at some papers from the  SANCL-2012 workshop on web parsing  from June this year, which are very interesting to those of us who wish we had good parsers for non-newspaper text.  The shared task focus was on domain adaptation from a setting of lots of Wall Street Journal annotated data and very little in-domain training data.  (Previous discussion  here ; see Ryan McDonald’s detailed comment.)   Here are some graphs of the results ( last page in the Petrov & McDonald overview ).
 
I was most interested in whether parsing accuracy on the WSJ correlates to accuracy on web text.  Fortunately, it does.  They evaluated all systems on four evaluation sets: (1) Text from a question/answer site, (2) newsgroups, (3) reviews, and (4) Wall Street Journal PTB.  Here is a graph across system entries, with the x-axis being the labeled dependency parsing accuracy on WSJPTB, and the y-axis the average accuracy on the three web evaluation sets.  Note the axis scales are different: web</p><p>6 0.38413757 <a title="202-lsi-6" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-01-Modelling_environmentalism_thinking.html">11 brendan oconnor ai-2005-07-01-Modelling environmentalism thinking</a></p>
<p>7 0.37254453 <a title="202-lsi-7" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-08-09-An_ML-AI_approach_to_P_%21%3D_NP.html">161 brendan oconnor ai-2010-08-09-An ML-AI approach to P != NP</a></p>
<p>8 0.35229856 <a title="202-lsi-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-08-Game_outcome_graphs_%E2%80%94_prisoner%E2%80%99s_dilemma_with_FUN_ARROWS%21%21%21.html">68 brendan oconnor ai-2007-07-08-Game outcome graphs — prisoner’s dilemma with FUN ARROWS!!!</a></p>
<p>9 0.34993467 <a title="202-lsi-9" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>10 0.34976757 <a title="202-lsi-10" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>11 0.3447811 <a title="202-lsi-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-01-Binary_classification_evaluation_in_R_via_ROCR.html">136 brendan oconnor ai-2009-04-01-Binary classification evaluation in R via ROCR</a></p>
<p>12 0.31457856 <a title="202-lsi-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-26-Seeing_how_%E2%80%9Cart%E2%80%9D_and_%E2%80%9Cpharmaceuticals%E2%80%9D_are_linguistically_similar_in_web_text.html">156 brendan oconnor ai-2009-09-26-Seeing how “art” and “pharmaceuticals” are linguistically similar in web text</a></p>
<p>13 0.30977878 <a title="202-lsi-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-12-Beautiful_Data_book_chapter.html">151 brendan oconnor ai-2009-08-12-Beautiful Data book chapter</a></p>
<p>14 0.3037335 <a title="202-lsi-14" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-04-06-a_regression_slope_is_a_weighted_average_of_pairs%E2%80%99_slopes%21.html">100 brendan oconnor ai-2008-04-06-a regression slope is a weighted average of pairs’ slopes!</a></p>
<p>15 0.29643595 <a title="202-lsi-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>16 0.29269338 <a title="202-lsi-16" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-more_argumentation_%26_AI-formal_modelling_links.html">8 brendan oconnor ai-2005-06-25-more argumentation & AI-formal modelling links</a></p>
<p>17 0.29207706 <a title="202-lsi-17" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-06-17-Confusion_matrix_diagrams.html">197 brendan oconnor ai-2013-06-17-Confusion matrix diagrams</a></p>
<p>18 0.28192991 <a title="202-lsi-18" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-20-Log-normal_and_logistic-normal_terminology.html">169 brendan oconnor ai-2011-05-20-Log-normal and logistic-normal terminology</a></p>
<p>19 0.27449608 <a title="202-lsi-19" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>20 0.26367939 <a title="202-lsi-20" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-04-26-Replot%3A_departure_delays_vs_flight_time_speed-up.html">204 brendan oconnor ai-2014-04-26-Replot: departure delays vs flight time speed-up</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(24, 0.028), (29, 0.611), (44, 0.067), (55, 0.026), (74, 0.096), (80, 0.036)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95311594 <a title="202-lda-1" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-18-Scatterplot_of_KN-PYP_language_model_results.html">202 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</a></p>
<p>Introduction: I should make a blog where all I do is scatterplot results tables from papers.  I do this once in a while to make them eaiser to understand…
 
I think the following are results are from Yee Whye Teh’s paper on hierarchical Pitman-Yor language models, and in particular comparing them to Kneser-Ney and hierarchical Dirichlets.  They’re specifically from  these slides by Yee Whye Teh (page 25) , which shows model perplexities.  Every dot is for one experimental condition, which has four different results from each of the models.  So a pair of models can be compared in one scatterplot.
 
   
 
where
  
   ikn = interpolated kneser-ney
    mkn = modified kneser-ney
    hdlm = hierarchical dirichlet
    hpylm = hierarchical pitman-yor
   
My reading: the KN’s and HPYLM are incredibly similar (as Teh argues should be the case on theoretical grounds).  MKN and HPYLM edge out IKN.  HDLM is markedly worse (this is perplexity, so lower is better).  While HDLM is a lot worse, it does best, relativ</p><p>2 0.94743311 <a title="202-lda-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-funny_comic.html">48 brendan oconnor ai-2007-01-02-funny comic</a></p>
<p>Introduction: [doesn't fit well; please click.]     Thx  Words and Other Things .</p><p>3 0.17952479 <a title="202-lda-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>4 0.17765489 <a title="202-lda-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>Introduction: This is a good idea: in a search engine’s query logs, look for outbreaks of queries like [[flu symptoms]] in a given region.  I’ve heard (from  Roddy ) that this trick also works well on Facebook statuses (e.g. “Feeling crappy this morning, think I just got the flu”).
  
  Google Uses Web Searches to Track Flu’s Spread – NYTimes.com  
  Google Flu Trends – google.org  
  
For an example with a publicly available data feed, these queries works decently well on Twitter search:
 
 [[ flu -shot -google ]]  (high recall)
 
 [[ "muscle aches" flu -shot ]]  (high precision)
     
 
The “muscle aches” query is too sparse and the general query is too noisy, but you could imagine some more tricks to clean it up, then train a classifier, etc.  With a bit more work it looks like geolocation information can be had out of the  Twitter search API .</p><p>5 0.17452994 <a title="202-lda-5" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>Introduction: I’ve had several people ask me what the numbers in  ACL  reviews mean — and I can’t find anywhere online where they’re described.  (Can anyone point this out if it is somewhere?)
 
So here’s the review form, below.  They all go from 1 to 5, with 5 the best.  I think the review emails to authors only include a subset of the below — for example, “Overall Recommendation” is not included?
 
The CFP said that they have different types of review forms for different types of papers.  I think this one is for a standard full paper.  I guess what people  really  want to know is what scores tend to correspond to acceptances.  I really have no idea and I get the impression this can change year to year.  I have no involvement with the ACL conference besides being one of many, many reviewers.
 
  
  
APPROPRIATENESS (1-5)
Does the paper fit in ACL 2014? (Please answer this question in light of the desire to broaden the scope of the research areas represented at ACL.) 

5: Certainly. 
4: Probabl</p><p>6 0.17257749 <a title="202-lda-6" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>7 0.16866249 <a title="202-lda-7" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>8 0.16748857 <a title="202-lda-8" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>9 0.16690448 <a title="202-lda-9" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>10 0.16559877 <a title="202-lda-10" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-05-Clinton-Obama_support_visualization.html">105 brendan oconnor ai-2008-06-05-Clinton-Obama support visualization</a></p>
<p>11 0.16536643 <a title="202-lda-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>12 0.16393474 <a title="202-lda-12" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>13 0.16380286 <a title="202-lda-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>14 0.16330701 <a title="202-lda-14" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>15 0.1622849 <a title="202-lda-15" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>16 0.16140081 <a title="202-lda-16" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>17 0.16063227 <a title="202-lda-17" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>18 0.16043778 <a title="202-lda-18" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>19 0.16028284 <a title="202-lda-19" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>20 0.15982902 <a title="202-lda-20" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
