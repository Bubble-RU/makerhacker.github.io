<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2005" href="../home/brendan_oconnor_ai-2005_home.html">brendan_oconnor_ai-2005</a> <a title="brendan_oconnor_ai-2005-6" href="#">brendan_oconnor_ai-2005-6</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2005-6-html" href="http://brenocon.com/blog/2005/06/idea-morals-are-heuristics-for-socially-optimal-behavior/">html</a></p><p>Introduction: A common cognitive science view (H. Simon): Heuristics/biases are useful rules-of-thumb to approximate optimizing behavior given computational constraints.
 
Consider the chess-playing heuristic “try not to lose your queen”.  Since you can’t analyze all possible chess moves, it’s nice to have such a rule-of-thumb to narrow down possible actions to consider.  You can reject out of hand an action that leads to losing your queen.  This heuristic helps to approximate optimal chess-playing behavior given your computational constraints.
 
Similarly, moral rules, tendencies, associations, and ontologies are heuristics to approximate socially optimal behavior. “Lying is bad” is a useful rule-of-thumb that usually gets good results for society. Codifying it as a norm — meaning, there’s 3rd party punishment and/or self-punishment (guilt) when it’s violated, thus the rule should get obeyed — is the implementation of a social-level heuristic that generally gives useful behavior.
 
Just like this S</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Simon): Heuristics/biases are useful rules-of-thumb to approximate optimizing behavior given computational constraints. [sent-2, score-0.917]
</p><p>2 Consider the chess-playing heuristic “try not to lose your queen”. [sent-3, score-0.387]
</p><p>3 Since you can’t analyze all possible chess moves, it’s nice to have such a rule-of-thumb to narrow down possible actions to consider. [sent-4, score-0.252]
</p><p>4 You can reject out of hand an action that leads to losing your queen. [sent-5, score-0.219]
</p><p>5 This heuristic helps to approximate optimal chess-playing behavior given your computational constraints. [sent-6, score-1.266]
</p><p>6 Similarly, moral rules, tendencies, associations, and ontologies are heuristics to approximate socially optimal behavior. [sent-7, score-0.807]
</p><p>7 “Lying is bad” is a useful rule-of-thumb that usually gets good results for society. [sent-8, score-0.347]
</p><p>8 Codifying it as a norm — meaning, there’s 3rd party punishment and/or self-punishment (guilt) when it’s violated, thus the rule should get obeyed — is the implementation of a social-level heuristic that generally gives useful behavior. [sent-9, score-1.102]
</p><p>9 Just like this Simonian definition of a heuristic, “Lying is bad” is necessary due to computational and informational limitations. [sent-10, score-0.265]
</p><p>10 You can’t foresee very well that lying could cause trouble down the road. [sent-11, score-0.497]
</p><p>11 In fact, you may be pretty sure it could give good results in the short-term. [sent-12, score-0.239]
</p><p>12 However, since it’s usually actually bad, a norm against it may be overall socially beneficial. [sent-13, score-0.77]
</p><p>13 Then for learning or group selection reasons (people imitate successful strategies, groups with the norm outcompete other groups), a socially beneficial norm may take root and spread. [sent-14, score-1.246]
</p><p>14 That does not mean “lying is bad” is some sort of universal truth, or even that it can be evaluated as a truth-functional statement (that is, must resolve to true/false in a certain world). [sent-15, score-0.227]
</p><p>15 That would imply there is are actually definite sets of good and bad things. [sent-16, score-0.284]
</p><p>16 Instead, it may be useful to think of a fictionalist explanation: this moral ontology of goodness/badness is a pragmatically useful fiction (useful because it helps bring about a just and orderly world. [sent-17, score-0.996]
</p><p>17 ) Specifically, it does this by functioning as a computational shortcut. [sent-18, score-0.278]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lying', 0.348), ('heuristic', 0.317), ('norm', 0.317), ('approximate', 0.261), ('socially', 0.209), ('bad', 0.205), ('useful', 0.192), ('computational', 0.191), ('may', 0.164), ('helps', 0.159), ('optimal', 0.139), ('moral', 0.132), ('behavior', 0.103), ('groups', 0.103), ('given', 0.096), ('possible', 0.091), ('functioning', 0.087), ('morality', 0.087), ('pragmatically', 0.087), ('resolve', 0.087), ('tendencies', 0.087), ('usually', 0.08), ('imply', 0.079), ('losing', 0.079), ('moves', 0.079), ('strategies', 0.079), ('trouble', 0.079), ('results', 0.075), ('leads', 0.074), ('meaning', 0.074), ('necessary', 0.074), ('optimizing', 0.074), ('party', 0.074), ('rules', 0.074), ('simon', 0.074), ('statement', 0.074), ('cause', 0.07), ('bring', 0.07), ('lose', 0.07), ('narrow', 0.07), ('rule', 0.07), ('selection', 0.07), ('specifically', 0.07), ('generally', 0.066), ('reasons', 0.066), ('action', 0.066), ('evaluated', 0.066), ('heuristics', 0.066), ('implementation', 0.066), ('truth', 0.066)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="6-tfidf-1" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-idea%3A_Morals_are_heuristics_for_socially_optimal_behavior.html">6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</a></p>
<p>Introduction: A common cognitive science view (H. Simon): Heuristics/biases are useful rules-of-thumb to approximate optimizing behavior given computational constraints.
 
Consider the chess-playing heuristic “try not to lose your queen”.  Since you can’t analyze all possible chess moves, it’s nice to have such a rule-of-thumb to narrow down possible actions to consider.  You can reject out of hand an action that leads to losing your queen.  This heuristic helps to approximate optimal chess-playing behavior given your computational constraints.
 
Similarly, moral rules, tendencies, associations, and ontologies are heuristics to approximate socially optimal behavior. “Lying is bad” is a useful rule-of-thumb that usually gets good results for society. Codifying it as a norm — meaning, there’s 3rd party punishment and/or self-punishment (guilt) when it’s violated, thus the rule should get obeyed — is the implementation of a social-level heuristic that generally gives useful behavior.
 
Just like this S</p><p>2 0.096008539 <a title="6-tfidf-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>Introduction: I was planning to write some  WordNet  lookup code tonight.  But instead I’ve learned of too many intersecting things.
 
First, there are a zillion things to do this weekend ( hooray flavorpill ):
 
  Picasso and American Art  exhibit continuing at  SFMOMA .  I saw it very briefly last weekend but want some more.  And Doug claims there’s an interesting photography exhibit there too.
  Reading from  We Don’t Need Another Wave: Dispatches from the Next Generation of Feminists , a fascinating looking book I’ve seen many times in the bookstores around here.  By that I mean at least Modern Times (the neat Mission bookstore) and the Anarchist Collective Bookstore (out on the Haight).  And the reading is at Modern Times,  just down the street  from my house!  Amazing.  Tomorrow at 7:30.
  Since anarchists were just mentioned, fortuitously there also appears: the  Bay Area Anarchist Bookfair  this Saturday and Sunday!  Speakers and books down by Golden Gate Park, oh my.  

 
Can’t say I’m a ra</p><p>3 0.084719121 <a title="6-tfidf-3" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-09-Simpson%E2%80%99s_paradox_is_so_totally_solved.html">60 brendan oconnor ai-2007-05-09-Simpson’s paradox is so totally solved</a></p>
<p>Introduction: My friend Lukas just wrote a great formulation of  Simpson’s Paradox as a puzzle :
  

Against left-handed pitchers, Player A has a higher batting average than Player B.  Player A does better against right-handed pitchers also.


Is it possible that B has a better average than A?

  
Here’s a beautiful ASCII art visualization that says Yes.
 
Each star represents a number of at-bats where the player hit; pluses represent misses.  If you put them in a horizontal line you can see the batting averages (proportions) pretty clearly.  The bar lenghts carry across rows — so a longer bar means more at-bats.
  
Against left-handed pitchers:
A hits |**--| A misses    --> 50% avg.
B hits |*---| B misses    --> 25% avg.

Against right-handed pitchers:
A hits |**|              A misses    --> 100% avg.
B hits |**************-| B misses    -->  93% avg.  (for many more at-bats!)

But, batting against *ALL* pitchers:
A hits  |****--| A misses                 --> 66% avg.
B hits  |*********</p><p>4 0.084578313 <a title="6-tfidf-4" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-02-23-Wasserman_on_Stats_vs_ML%2C_and_previous_comparisons.html">191 brendan oconnor ai-2013-02-23-Wasserman on Stats vs ML, and previous comparisons</a></p>
<p>Introduction: Larry Wasserman has a new position paper (forthcoming 2013) with a great comparison the Statistics and Machine Learning research cultures,  “Rise of the Machines” .  He has a very conciliatory view in terms of intellectual content, and a very pro-ML take on the research cultures.  Central to his argument is that ML has recently adopted rigorous statistical concepts, and the fast-moving conference culture (and heavy publishing by its grad students) have helped with this and other good innovations.  (I agree with a comment from Sinead that he’s going a little easy on ML, but it’s certainly worth a read.)
 
There’s now a little history of “Statistics vs Machine Learning” position papers that this can be compared to.  A classic is Leo Breiman (2001),  “Statistical Modeling: The Two Cultures” , which isn’t exactly about stats vs. ML, but is about the focus on modeling vs algorithms, and maybe about description vs. prediction.
 
It’s been a while since I’ve looked at it, but I’ve also enjoye</p><p>5 0.084408201 <a title="6-tfidf-5" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>Introduction: When possible, I like to use R for its really, really good statistical visualization capabilities.  I’m doing a modeling project in Python right now (R is too slow, bad at large data, bad at structured data, etc.), and in comparison to base R, the matplotlib library is just painful.  I wrote a toy  Metropolis  sampler for a  triangle distribution  and all I want to see is whether it looks like it’s working.  For the same dataset, here are histograms with default settings.  (Python:  pylab.hist(d) , R:  hist(d) )
 
   
 
I want to know whether my Metropolis sampler is working; those two plots give a very different idea.  Of course, you could say this is an unfair comparison, since matplotlib is only using 10 bins, while R is using 18 here — and it’s always important to vary the bin size a few times when looking at histograms.  But R’s defaults really are better: it actually uses an adaptive bin size, and the heuristic worked, choosing a reasonable number for the data.  The  hist()  manu</p><p>6 0.074654728 <a title="6-tfidf-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>7 0.069762662 <a title="6-tfidf-7" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-08-01-Bayesian_analysis_of_intelligent_design_%28revised%21%29.html">23 brendan oconnor ai-2005-08-01-Bayesian analysis of intelligent design (revised!)</a></p>
<p>8 0.068316169 <a title="6-tfidf-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-Netflix_Prize.html">125 brendan oconnor ai-2008-11-21-Netflix Prize</a></p>
<p>9 0.066955045 <a title="6-tfidf-9" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-09-01-Double_thesis_action.html">45 brendan oconnor ai-2006-09-01-Double thesis action</a></p>
<p>10 0.065188423 <a title="6-tfidf-10" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>11 0.064463861 <a title="6-tfidf-11" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-The_Jungle_Economy.html">47 brendan oconnor ai-2007-01-02-The Jungle Economy</a></p>
<p>12 0.064222902 <a title="6-tfidf-12" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>13 0.063112266 <a title="6-tfidf-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-03-06-data_data_data.html">93 brendan oconnor ai-2008-03-06-data data data</a></p>
<p>14 0.062119 <a title="6-tfidf-14" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-11-Memorizing_small_tables.html">177 brendan oconnor ai-2011-11-11-Memorizing small tables</a></p>
<p>15 0.060786631 <a title="6-tfidf-15" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-06-03-Rock%2C_Paper%2C_Scissors.html">39 brendan oconnor ai-2006-06-03-Rock, Paper, Scissors</a></p>
<p>16 0.058988731 <a title="6-tfidf-16" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-05-Evil.html">56 brendan oconnor ai-2007-04-05-Evil</a></p>
<p>17 0.057458449 <a title="6-tfidf-17" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-26-Good_linguistic_semantics_textbook%3F.html">172 brendan oconnor ai-2011-06-26-Good linguistic semantics textbook?</a></p>
<p>18 0.057291556 <a title="6-tfidf-18" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>19 0.057162102 <a title="6-tfidf-19" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-10-31-neo_institutional_economic_fun%21.html">80 brendan oconnor ai-2007-10-31-neo institutional economic fun!</a></p>
<p>20 0.056298241 <a title="6-tfidf-20" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-11-14-Pop_cog_neuro_is_so_sigh.html">82 brendan oconnor ai-2007-11-14-Pop cog neuro is so sigh</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.204), (1, 0.086), (2, 0.049), (3, -0.064), (4, 0.013), (5, -0.03), (6, -0.006), (7, -0.03), (8, 0.019), (9, -0.008), (10, -0.035), (11, 0.047), (12, 0.009), (13, 0.025), (14, 0.054), (15, 0.024), (16, 0.007), (17, 0.082), (18, -0.102), (19, -0.038), (20, -0.148), (21, 0.01), (22, 0.016), (23, 0.06), (24, -0.106), (25, -0.125), (26, 0.027), (27, 0.108), (28, -0.097), (29, -0.07), (30, 0.109), (31, 0.015), (32, 0.138), (33, 0.007), (34, -0.004), (35, 0.164), (36, 0.159), (37, 0.133), (38, -0.059), (39, -0.016), (40, 0.028), (41, 0.077), (42, 0.004), (43, -0.109), (44, -0.048), (45, 0.012), (46, 0.035), (47, -0.065), (48, -0.144), (49, 0.101)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98998928 <a title="6-lsi-1" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-idea%3A_Morals_are_heuristics_for_socially_optimal_behavior.html">6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</a></p>
<p>Introduction: A common cognitive science view (H. Simon): Heuristics/biases are useful rules-of-thumb to approximate optimizing behavior given computational constraints.
 
Consider the chess-playing heuristic “try not to lose your queen”.  Since you can’t analyze all possible chess moves, it’s nice to have such a rule-of-thumb to narrow down possible actions to consider.  You can reject out of hand an action that leads to losing your queen.  This heuristic helps to approximate optimal chess-playing behavior given your computational constraints.
 
Similarly, moral rules, tendencies, associations, and ontologies are heuristics to approximate socially optimal behavior. “Lying is bad” is a useful rule-of-thumb that usually gets good results for society. Codifying it as a norm — meaning, there’s 3rd party punishment and/or self-punishment (guilt) when it’s violated, thus the rule should get obeyed — is the implementation of a social-level heuristic that generally gives useful behavior.
 
Just like this S</p><p>2 0.64007992 <a title="6-lsi-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-09-Simpson%E2%80%99s_paradox_is_so_totally_solved.html">60 brendan oconnor ai-2007-05-09-Simpson’s paradox is so totally solved</a></p>
<p>Introduction: My friend Lukas just wrote a great formulation of  Simpson’s Paradox as a puzzle :
  

Against left-handed pitchers, Player A has a higher batting average than Player B.  Player A does better against right-handed pitchers also.


Is it possible that B has a better average than A?

  
Here’s a beautiful ASCII art visualization that says Yes.
 
Each star represents a number of at-bats where the player hit; pluses represent misses.  If you put them in a horizontal line you can see the batting averages (proportions) pretty clearly.  The bar lenghts carry across rows — so a longer bar means more at-bats.
  
Against left-handed pitchers:
A hits |**--| A misses    --> 50% avg.
B hits |*---| B misses    --> 25% avg.

Against right-handed pitchers:
A hits |**|              A misses    --> 100% avg.
B hits |**************-| B misses    -->  93% avg.  (for many more at-bats!)

But, batting against *ALL* pitchers:
A hits  |****--| A misses                 --> 66% avg.
B hits  |*********</p><p>3 0.50730705 <a title="6-lsi-3" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-08-Game_outcome_graphs_%E2%80%94_prisoner%E2%80%99s_dilemma_with_FUN_ARROWS%21%21%21.html">68 brendan oconnor ai-2007-07-08-Game outcome graphs — prisoner’s dilemma with FUN ARROWS!!!</a></p>
<p>Introduction: I think game theory could benefit immensely from better presentation.  Its default presentation is pretty mathematical.  This is good because it treats social interactions in an abstract way, highlighting their essential properties, but is bad because it’s hard to understand, especially at first.
 
However, I think I have a visualization that can sometimes capture the same abstract properties of the mathematics.  Here’s a stab at using it to explain everyone’s favorite game, the prisoner’s dilemma.
 
THE PD: Two players each choose whether to play nice, or be mean — Cooperate or Defect.  Then they simultaneously play their actions, and get payoffs depending on what both played.  If both cooperated, they help each other and do well; if both defect, they do quite poorly.  But if one tries to cooperate and the other defects, then the defector gets a big win, and the cooperator gets a crappy “sucker’s payoff”.
 
The formal PD definition looks like this:
 
   
 
where each of the four pairs</p><p>4 0.49523029 <a title="6-lsi-4" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-03-Supreme_Court_justices%E2%80%99_agreement_levels.html">13 brendan oconnor ai-2005-07-03-Supreme Court justices’ agreement levels</a></p>
<p>Introduction: Cool visualization of agreement levels among Supreme Court justices .  I like how they’re ordered so that the smallest amount of agreement ends up in the lower-left.  Hopefully it’s not deceptive for certain cases: I imagine that summarizing their tendencies to vote certain ways into a one dimensional spectrum would lose important information of other dimensions of agreement or coalitions.</p><p>5 0.48413035 <a title="6-lsi-5" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>Introduction: I got nervous and panicky just reading about this game.  I wonder if I could con some people into playing it.
  
Economics professors have a standard game they use to demonstrate how apparently rational decisions can create a disastrous result. They call it a “dollar auction.” The rules are simple. The professor offers a dollar for sale to the highest bidder, with only one wrinkle: the second-highest bidder has to pay up on their losing bid as well. Several students almost always get sucked in. The first bids a penny, looking to make 99 cents. The second bids 2 cents, the third 3 cents, and so on, each feeling they have a chance at something good on the cheap. The early stages are fun, and the bidders wonder what possessed the professor to be willing to lose some money.


The problem surfaces when the bidders get up close to a dollar. After 99 cents the last vestige of profitability disappears, but the bidding continues between the two highest players. They now realize that they stand</p><p>6 0.45553121 <a title="6-lsi-6" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-09-01-Double_thesis_action.html">45 brendan oconnor ai-2006-09-01-Double thesis action</a></p>
<p>7 0.44996896 <a title="6-lsi-7" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>8 0.44054416 <a title="6-lsi-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-Netflix_Prize.html">125 brendan oconnor ai-2008-11-21-Netflix Prize</a></p>
<p>9 0.43454483 <a title="6-lsi-9" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>10 0.42239469 <a title="6-lsi-10" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Computability_and_induction_and_ideal_rationality_and_the_simpsons.html">52 brendan oconnor ai-2007-03-15-Computability and induction and ideal rationality and the simpsons</a></p>
<p>11 0.4024477 <a title="6-lsi-11" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>12 0.38688645 <a title="6-lsi-12" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-11-Memorizing_small_tables.html">177 brendan oconnor ai-2011-11-11-Memorizing small tables</a></p>
<p>13 0.37759358 <a title="6-lsi-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>14 0.33432722 <a title="6-lsi-14" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-04-05-Evil.html">56 brendan oconnor ai-2007-04-05-Evil</a></p>
<p>15 0.32545748 <a title="6-lsi-15" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-02-%24_echo_%7Bpolitical%2Csocial%2Ceconomic%7D%7Bcognition%2Cbehavior%2Csystems%7D.html">12 brendan oconnor ai-2005-07-02-$ echo {political,social,economic}{cognition,behavior,systems}</a></p>
<p>16 0.32199812 <a title="6-lsi-16" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-26-Good_linguistic_semantics_textbook%3F.html">172 brendan oconnor ai-2011-06-26-Good linguistic semantics textbook?</a></p>
<p>17 0.31038374 <a title="6-lsi-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-29-%22Stanford_Impostor%22.html">62 brendan oconnor ai-2007-05-29-"Stanford Impostor"</a></p>
<p>18 0.30075324 <a title="6-lsi-18" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-02-23-Wasserman_on_Stats_vs_ML%2C_and_previous_comparisons.html">191 brendan oconnor ai-2013-02-23-Wasserman on Stats vs ML, and previous comparisons</a></p>
<p>19 0.29245415 <a title="6-lsi-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-18-Information_cost_and_genocide.html">130 brendan oconnor ai-2008-12-18-Information cost and genocide</a></p>
<p>20 0.29062331 <a title="6-lsi-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(24, 0.031), (28, 0.021), (44, 0.123), (64, 0.464), (70, 0.056), (74, 0.205)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.99215293 <a title="6-lda-1" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-a_bayesian_analysis_of_intelligent_design.html">17 brendan oconnor ai-2005-07-09-a bayesian analysis of intelligent design</a></p>
<p>Introduction: UPDATE: just wrote  a revision of this .
   
Pick an organism.  Two propositions, H and E, each may be either true or false about it. 
 H : the organism was designed by an intelligent creator. 
 E : the organism looks like it was designed by an intelligent creator.
 
Most of what I know about ID is from seeing a talk by Michael Behe (may 2005).  He had to major lines of argument:  (1) it is implausible that an evolutionary process could produce life that looks as if it was intelligently designed.  (2) Since it looks like it was intelligently designed, it was.  He really emphasized the E component of the argument.
 
Justifications for E: Lots of organisms look like they were intelligently designed.  They have complex and intricate mechanisms involving coordination among many components.  Sometimes they look like things humans would design: for example, bacteria locomotion devices sometimes bear uncanny resemblance to human-designed motors or propellers.
 
Behe was really into showing al</p><p>2 0.98249424 <a title="6-lda-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-07-Happiness_incarnate_on_the_Colbert_Report.html">67 brendan oconnor ai-2007-07-07-Happiness incarnate on the Colbert Report</a></p>
<p>Introduction: A bit ago I finished Daniel Gilbert’s “Stumbling on Happiness,” which despite its name, is not about how to be happy.  It’s about why people are bad at predicting (and remembering) their happiness levels.  (Pop science psychology, not pop psychology… something like that.)  I liked a bit of it mainly because it has an entertaining overview of some cognitive psychology.  A few very interesting happiness experiments get presented, but if your friend tells you about them before you read the book, it’s all over.
 
Perhaps more amusing is stumbling on Gilbert’s quite entertaining appearance on the Colbert Report last week:</p><p>3 0.98017603 <a title="6-lda-3" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-08-01-Bayesian_analysis_of_intelligent_design_%28revised%21%29.html">23 brendan oconnor ai-2005-08-01-Bayesian analysis of intelligent design (revised!)</a></p>
<p>Introduction: This is a revision of  my earlier post .  In  Jaynes’ awesome statistical manifesto book  ( another link ), I just saw for the second time the odds ratio form of Bayes’ rule, which is a lot cleaner for this sort of static analysis.  So anyway…
   
Pick an organism.  Two propositions, H and E, each may be either true or false about it. 
 H : the organism was designed by an intelligent creator. 
 E : the organism looks like it was designed by an intelligent creator.
 
Most of what I know about Intelligent Design theory (ID) is from seeing a talk by Michael Behe (may 2005).  He had to major lines of argument:  (1) it is implausible that an evolutionary process could produce life that looks as if it was intelligently designed.  (2) Since it looks like it was intelligently designed, it was.  He really emphasized the E component of the argument.
 
Justifications for E: Lots of organisms look like they were intelligently designed.  They have complex and intricate mechanisms involving coordina</p><p>same-blog 4 0.90065628 <a title="6-lda-4" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-06-25-idea%3A_Morals_are_heuristics_for_socially_optimal_behavior.html">6 brendan oconnor ai-2005-06-25-idea: Morals are heuristics for socially optimal behavior</a></p>
<p>Introduction: A common cognitive science view (H. Simon): Heuristics/biases are useful rules-of-thumb to approximate optimizing behavior given computational constraints.
 
Consider the chess-playing heuristic “try not to lose your queen”.  Since you can’t analyze all possible chess moves, it’s nice to have such a rule-of-thumb to narrow down possible actions to consider.  You can reject out of hand an action that leads to losing your queen.  This heuristic helps to approximate optimal chess-playing behavior given your computational constraints.
 
Similarly, moral rules, tendencies, associations, and ontologies are heuristics to approximate socially optimal behavior. “Lying is bad” is a useful rule-of-thumb that usually gets good results for society. Codifying it as a norm — meaning, there’s 3rd party punishment and/or self-punishment (guilt) when it’s violated, thus the rule should get obeyed — is the implementation of a social-level heuristic that generally gives useful behavior.
 
Just like this S</p><p>5 0.44034323 <a title="6-lda-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>Introduction: This is a good idea: in a search engine’s query logs, look for outbreaks of queries like [[flu symptoms]] in a given region.  I’ve heard (from  Roddy ) that this trick also works well on Facebook statuses (e.g. “Feeling crappy this morning, think I just got the flu”).
  
  Google Uses Web Searches to Track Flu’s Spread – NYTimes.com  
  Google Flu Trends – google.org  
  
For an example with a publicly available data feed, these queries works decently well on Twitter search:
 
 [[ flu -shot -google ]]  (high recall)
 
 [[ "muscle aches" flu -shot ]]  (high precision)
     
 
The “muscle aches” query is too sparse and the general query is too noisy, but you could imagine some more tricks to clean it up, then train a classifier, etc.  With a bit more work it looks like geolocation information can be had out of the  Twitter search API .</p><p>6 0.43579468 <a title="6-lda-6" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>7 0.43083671 <a title="6-lda-7" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>8 0.42460763 <a title="6-lda-8" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>9 0.42120558 <a title="6-lda-9" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>10 0.42002687 <a title="6-lda-10" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>11 0.41510192 <a title="6-lda-11" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-05-Clinton-Obama_support_visualization.html">105 brendan oconnor ai-2008-06-05-Clinton-Obama support visualization</a></p>
<p>12 0.41132516 <a title="6-lda-12" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<p>13 0.40911621 <a title="6-lda-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>14 0.4066067 <a title="6-lda-14" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-the_psychology_of_design_as_explanation.html">19 brendan oconnor ai-2005-07-09-the psychology of design as explanation</a></p>
<p>15 0.40651795 <a title="6-lda-15" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>16 0.40514988 <a title="6-lda-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>17 0.4001587 <a title="6-lda-17" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>18 0.39439559 <a title="6-lda-18" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>19 0.39314669 <a title="6-lda-19" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-10-31-neo_institutional_economic_fun%21.html">80 brendan oconnor ai-2007-10-31-neo institutional economic fun!</a></p>
<p>20 0.39023638 <a title="6-lda-20" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
