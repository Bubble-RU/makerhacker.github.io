<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2008" href="../home/brendan_oconnor_ai-2008_home.html">brendan_oconnor_ai-2008</a> <a title="brendan_oconnor_ai-2008-117" href="#">brendan_oconnor_ai-2008-117</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2008-117-html" href="http://brenocon.com/blog/2008/10/it-is-accurate-to-determine-a-blogs-bias-by-what-it-links-to/">html</a></p><p>Introduction: Here’s a great project from Andy Baio and Joshua Schachter : they assessed the political biases of different blogs based on which articles they tend link to.  Using these political bias scores, they made a cool little Firefox extension that colors the names of different sources on the news aggregator site  Memeorandum , like so:
 
 
 
How they computed these biases is pretty neat.  Their data source was the Memeorandum site itself, which shows a particular news story, then a list of different news sites that have written articles about the topic.  Scraping out that data, Joshua constructed the adjacency matrix of sites vs. articles they linked to and ran good ol’  SVD  on it, an algorithm that can be used to summarize the very high-dimensional article linking information in just several numbers (“components” or “dimensions”) for each news site.  Basically, the algorithm groups together sites that tend to link to the same articles.  It’s not exactly clustering though; rather, it project</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Here’s a great project from Andy Baio and Joshua Schachter : they assessed the political biases of different blogs based on which articles they tend link to. [sent-1, score-0.715]
</p><p>2 Using these political bias scores, they made a cool little Firefox extension that colors the names of different sources on the news aggregator site  Memeorandum , like so:       How they computed these biases is pretty neat. [sent-2, score-0.723]
</p><p>3 Their data source was the Memeorandum site itself, which shows a particular news story, then a list of different news sites that have written articles about the topic. [sent-3, score-0.889]
</p><p>4 Scraping out that data, Joshua constructed the adjacency matrix of sites vs. [sent-4, score-0.238]
</p><p>5 articles they linked to and ran good ol’  SVD  on it, an algorithm that can be used to summarize the very high-dimensional article linking information in just several numbers (“components” or “dimensions”) for each news site. [sent-5, score-0.586]
</p><p>6 Basically, the algorithm groups together sites that tend to link to the same articles. [sent-6, score-0.546]
</p><p>7 It’s not exactly clustering though; rather, it projects them into a space where sites close to each other had similar linking patterns. [sent-7, score-0.358]
</p><p>8 People have used this technique analogously to construct a political spectrum for Congress, by analyzing which legislators tend to vote together. [sent-8, score-0.367]
</p><p>9 So here they found that the second dimension of the SVD’s projected outputs seemed to strongly correlate with their own intuitions of sites’ political biases. [sent-9, score-0.492]
</p><p>10 This score is used for their coloring visualization, and I personally found the examples pretty accurate. [sent-11, score-0.336]
</p><p>11 I’ve found before that you can  assess media bias on AMT  pretty well; but for this, I simply went to a pre-existing site called  Skewz , which  collects people’s ratings  of the bias of individual articles from news sites. [sent-21, score-0.898]
</p><p>12 Within that set, it turns out that the SVD’s second component  significantly correlates  with Skewz users’ judgments of political bias! [sent-23, score-0.467]
</p><p>13 Higher numbers are conservative, lower are liberal:         So SVD tends to give most sites a neutral score, but when it assigns a strong score, it’s often right — or at least, correlates with Skewz users. [sent-25, score-0.415]
</p><p>14 (But don’t take any particular data point too seriously — the Skewz data is probably fairly noisy, and the bridging between the datasets introduces more noise too, since Memeorandum and Skewz are based on different sets of articles and such. [sent-28, score-0.433]
</p><p>15 There’s some more successful correlation in there:         Here are the actual correlation coefficients with the different SVD outputs. [sent-30, score-0.662]
</p><p>16 It turns out the first dimension slightly correlates to political bias as well. [sent-31, score-0.675]
</p><p>17 )  But the third through fifth dimensions, which they say were very hard for them to interpret, don’t correlate at all to these political bias ratings. [sent-34, score-0.437]
</p><p>18 A completely unsupervised algorithm, based purely on similarity of linking patterns, gets you a systematic correlation with independent judges’ assessments of bias. [sent-41, score-0.418]
</p><p>19 Final note: The correlation coefficients above are via  Kendall-Tau , which is invariant to rescalings of the data. [sent-53, score-0.306]
</p><p>20 This data has all sorts of odd spikes and such, and Joshua and Andy themselves rescaled the data for the coloring plugin, so this seemed safest. [sent-54, score-0.382]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('skewz', 0.506), ('svd', 0.328), ('sites', 0.238), ('correlation', 0.238), ('bias', 0.183), ('tend', 0.182), ('joshua', 0.16), ('articles', 0.146), ('political', 0.141), ('memeorandum', 0.138), ('dimension', 0.136), ('news', 0.135), ('linking', 0.12), ('score', 0.109), ('correlates', 0.109), ('andy', 0.092), ('coloring', 0.092), ('pca', 0.092), ('site', 0.087), ('rescaled', 0.08), ('data', 0.079), ('algorithm', 0.073), ('ratings', 0.073), ('correlate', 0.073), ('different', 0.069), ('judgments', 0.068), ('interpret', 0.068), ('coefficients', 0.068), ('numbers', 0.068), ('biases', 0.064), ('scatterplot', 0.064), ('liberal', 0.064), ('factor', 0.064), ('dimensions', 0.061), ('based', 0.06), ('overall', 0.058), ('component', 0.058), ('slightly', 0.058), ('scores', 0.056), ('thinks', 0.054), ('link', 0.053), ('seemed', 0.052), ('actual', 0.049), ('output', 0.049), ('turns', 0.048), ('found', 0.047), ('used', 0.044), ('pretty', 0.044), ('second', 0.043), ('fifth', 0.04)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="117-tfidf-1" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-11-It_is_accurate_to_determine_a_blog%E2%80%99s_bias_by_what_it_links_to.html">117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</a></p>
<p>Introduction: Here’s a great project from Andy Baio and Joshua Schachter : they assessed the political biases of different blogs based on which articles they tend link to.  Using these political bias scores, they made a cool little Firefox extension that colors the names of different sources on the news aggregator site  Memeorandum , like so:
 
 
 
How they computed these biases is pretty neat.  Their data source was the Memeorandum site itself, which shows a particular news story, then a list of different news sites that have written articles about the topic.  Scraping out that data, Joshua constructed the adjacency matrix of sites vs. articles they linked to and ran good ol’  SVD  on it, an algorithm that can be used to summarize the very high-dimensional article linking information in just several numbers (“components” or “dimensions”) for each news site.  Basically, the algorithm groups together sites that tend to link to the same articles.  It’s not exactly clustering though; rather, it project</p><p>2 0.1596598 <a title="117-tfidf-2" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-18-Correlation_picture.html">193 brendan oconnor ai-2013-03-18-Correlation picture</a></p>
<p>Introduction: Paul Moore  posted a comment pointing out this great discussion of the correlation coefficient:
  
 Joseph Lee Rodgers and W. Alan Nicewander.  “Thirteen Ways to Look at the Correlation Coefficient.” The American Statistician, Vol. 42, No. 1. (Feb., 1988), pp. 59-66.   Link  
  
It’s related to the the post on  cosine similarity, correlation and OLS .  Anyway, I was just struck by the following diagram.  It almost has a pop-art feel.</p><p>3 0.099390529 <a title="117-tfidf-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>Introduction: I’m a bit late blogging this, but here’s a messy, exciting — and statistically validated! — new online data source.
 
My friend  Roddy  at Facebook  wrote a post describing their sentiment analysis system , which can evaluate positive or negative sentiment toward a particular topic by looking at a large number of wall messages.  (I’d link to it, but I can’t find the URL anymore — here’s the  Lexicon , but that version only gets term frequencies but no sentiment.)
 
How they constructed their sentiment detector is interesting.  Starting with a list of positive and negative terms, they had a lexical acquisition step to gather many more candidate synonyms and misspellings — a necessity in this social media domain, where  WordNet  ain’t gonna come close!  After manually filtering these candidates, they assess the sentiment toward a mention of a topic by looking for instances of these positive and negative words nearby, along with “negation heuristics” and a few other features.
 
He describ</p><p>4 0.080877088 <a title="117-tfidf-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>Introduction: Seeing a long, lavish article about R in the NEW YORK TIMES (!) really freaks me out. 
  replicate(100,  c(
  "OMG OMG,  R  is now famous?!",
  "People used to make fun of me for learning R since Splus is SO OLD!",
  "I still hear stories that SAS can do crazy tricks that make me jealous.
  But not enough to attempt learning it."
)[ floor(runif(1, min=1,max=4)) ] )  
This blog has been a long-time supporter of this both brilliant and insanely quirky statistical programming environment.  Here are some graphs I’ve made in the last year or two that have R code attached:
  
  Wisdom of small crowds  
  Simpson’s paradox via mosaic plots  
  Dolores Labs color wheel!  ( code ) 
  Political bias SVD evaluation  
  Presidential poll aggregation  
 OK, we didn’t post the code, but check out our  N-body trolley graph ! 
  
Learning R is hard because there’s a zillion packages, and the official documentation is reference-oriented.  I’ve never looked at any of the books much.  I think you ca</p><p>5 0.072993703 <a title="117-tfidf-5" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-31-balkanized_USA.html">21 brendan oconnor ai-2005-07-31-balkanized USA</a></p>
<p>Introduction: From the same site,  this is fun.</p><p>6 0.068143785 <a title="117-tfidf-6" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-09-Race_and_IQ_debate_%E2%80%93_links.html">85 brendan oconnor ai-2007-12-09-Race and IQ debate – links</a></p>
<p>7 0.065647669 <a title="117-tfidf-7" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>8 0.061823744 <a title="117-tfidf-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-03-06-data_data_data.html">93 brendan oconnor ai-2008-03-06-data data data</a></p>
<p>9 0.055229928 <a title="117-tfidf-9" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-08-13-It%E2%80%99s_all_in_a_name%3A_%22Kingdom_of_Norway%22_vs._%22Democratic_People%E2%80%99s_Republic_of_Korea%22.html">75 brendan oconnor ai-2007-08-13-It’s all in a name: "Kingdom of Norway" vs. "Democratic People’s Republic of Korea"</a></p>
<p>10 0.055099458 <a title="117-tfidf-10" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-11-Memorizing_small_tables.html">177 brendan oconnor ai-2011-11-11-Memorizing small tables</a></p>
<p>11 0.055048358 <a title="117-tfidf-11" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-11-24-Graphs_for_SANCL-2012_web_parsing_results.html">189 brendan oconnor ai-2012-11-24-Graphs for SANCL-2012 web parsing results</a></p>
<p>12 0.054530889 <a title="117-tfidf-12" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-01-Bias_correction_sneak_peek%21.html">108 brendan oconnor ai-2008-07-01-Bias correction sneak peek!</a></p>
<p>13 0.053947493 <a title="117-tfidf-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>14 0.053812325 <a title="117-tfidf-14" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-27-Seth_Roberts_and_academic_blogging.html">55 brendan oconnor ai-2007-03-27-Seth Roberts and academic blogging</a></p>
<p>15 0.052409057 <a title="117-tfidf-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-17-Pairwise_comparisons_for_relevance_evaluation.html">106 brendan oconnor ai-2008-06-17-Pairwise comparisons for relevance evaluation</a></p>
<p>16 0.051114116 <a title="117-tfidf-16" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>17 0.050751593 <a title="117-tfidf-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-08-MyDebates.org%2C_online_polling%2C_and_potentially_the_coolest_question_corpus_ever.html">116 brendan oconnor ai-2008-10-08-MyDebates.org, online polling, and potentially the coolest question corpus ever</a></p>
<p>18 0.050526626 <a title="117-tfidf-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-12-Beautiful_Data_book_chapter.html">151 brendan oconnor ai-2009-08-12-Beautiful Data book chapter</a></p>
<p>19 0.05038479 <a title="117-tfidf-19" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-06-26-Michael_Jackson_in_Persepolis.html">145 brendan oconnor ai-2009-06-26-Michael Jackson in Persepolis</a></p>
<p>20 0.050357658 <a title="117-tfidf-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-08-16-A_better_Obama_vs_McCain_poll_aggregation.html">111 brendan oconnor ai-2008-08-16-A better Obama vs McCain poll aggregation</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.203), (1, -0.071), (2, -0.008), (3, 0.014), (4, -0.077), (5, 0.038), (6, -0.087), (7, -0.062), (8, -0.05), (9, -0.026), (10, -0.012), (11, -0.14), (12, 0.086), (13, -0.009), (14, -0.104), (15, 0.03), (16, -0.033), (17, -0.007), (18, -0.058), (19, 0.02), (20, -0.068), (21, -0.018), (22, 0.06), (23, -0.006), (24, -0.036), (25, -0.115), (26, -0.042), (27, 0.099), (28, 0.079), (29, -0.093), (30, -0.016), (31, -0.252), (32, -0.139), (33, -0.02), (34, -0.039), (35, -0.051), (36, 0.039), (37, -0.089), (38, 0.04), (39, 0.036), (40, -0.105), (41, 0.106), (42, 0.145), (43, -0.187), (44, 0.077), (45, -0.018), (46, -0.028), (47, 0.019), (48, 0.091), (49, -0.032)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97646946 <a title="117-lsi-1" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-11-It_is_accurate_to_determine_a_blog%E2%80%99s_bias_by_what_it_links_to.html">117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</a></p>
<p>Introduction: Here’s a great project from Andy Baio and Joshua Schachter : they assessed the political biases of different blogs based on which articles they tend link to.  Using these political bias scores, they made a cool little Firefox extension that colors the names of different sources on the news aggregator site  Memeorandum , like so:
 
 
 
How they computed these biases is pretty neat.  Their data source was the Memeorandum site itself, which shows a particular news story, then a list of different news sites that have written articles about the topic.  Scraping out that data, Joshua constructed the adjacency matrix of sites vs. articles they linked to and ran good ol’  SVD  on it, an algorithm that can be used to summarize the very high-dimensional article linking information in just several numbers (“components” or “dimensions”) for each news site.  Basically, the algorithm groups together sites that tend to link to the same articles.  It’s not exactly clustering though; rather, it project</p><p>2 0.66855866 <a title="117-lsi-2" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-18-Correlation_picture.html">193 brendan oconnor ai-2013-03-18-Correlation picture</a></p>
<p>Introduction: Paul Moore  posted a comment pointing out this great discussion of the correlation coefficient:
  
 Joseph Lee Rodgers and W. Alan Nicewander.  “Thirteen Ways to Look at the Correlation Coefficient.” The American Statistician, Vol. 42, No. 1. (Feb., 1988), pp. 59-66.   Link  
  
It’s related to the the post on  cosine similarity, correlation and OLS .  Anyway, I was just struck by the following diagram.  It almost has a pop-art feel.</p><p>3 0.42683694 <a title="117-lsi-3" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-08-13-It%E2%80%99s_all_in_a_name%3A_%22Kingdom_of_Norway%22_vs._%22Democratic_People%E2%80%99s_Republic_of_Korea%22.html">75 brendan oconnor ai-2007-08-13-It’s all in a name: "Kingdom of Norway" vs. "Democratic People’s Republic of Korea"</a></p>
<p>Introduction: Sometimes it seems bad countries come with long names.  North Korea is “People’s Democratic Republic of Korea”, Libya is “Great Socialist People’s Libyan Arab Jamahiriya”, and the like.  But on the other hand, there’s plenty of counter-examples — it’s the “United Kingdom of Great Britain and Northern Ireland” and “Republic of Cuba”, after all.  Do long names with good-sounding adjectives correspond with non-democratic governments?
 
Fortunately, this can be tested.  First, what words are out there?  From the  CIA Factbook’s  data on long form names, here are some of the most popular words used by today’s countries, listed with the number of occurrences across all 194 names.  I limited to tokens that appear >= 3 times.  A majority of countries are Republics, while there are some Kingdoms, and even a few Democracies.
  
(146 of) (127 Republic) (17 Kingdom) (8 the) (8 Democratic) (6 State) (6 People’s) (5 United) (4 and) (4 Islamic) (4 Arab) (3 States) (3 Socialist) (3 Principality) (3 Is</p><p>4 0.41822889 <a title="117-lsi-4" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-13-Cosine_similarity%2C_Pearson_correlation%2C_and_OLS_coefficients.html">182 brendan oconnor ai-2012-03-13-Cosine similarity, Pearson correlation, and OLS coefficients</a></p>
<p>Introduction: Cosine similarity, Pearson correlations, and OLS coefficients can all be viewed as variants on the inner product — tweaked in different ways for centering and magnitude (i.e. location and scale, or something like that).
 
Details:
 
You have two vectors \(x\) and \(y\) and want to measure similarity between them.  A basic similarity function is the   inner product  
 
\[ Inner(x,y) = \sum_i x_i y_i = \langle x, y \rangle \]
 
If x tends to be high where y is also high, and low where y is low, the inner product will be high — the vectors are more similar.
 
The inner product is unbounded.  One way to make it bounded between -1 and 1 is to divide by the vectors’ L2 norms, giving the   cosine similarity  
 
\[ CosSim(x,y) = \frac{\sum_i x_i y_i}{ \sqrt{ \sum_i x_i^2} \sqrt{ \sum_i y_i^2 } } 
= \frac{ \langle x,y \rangle }{ ||x||\ ||y|| } 
\]
 
This is actually bounded between 0 and 1 if x and y are non-negative.  Cosine similarity has an interpretation as the cosine of the angle between t</p><p>5 0.41542551 <a title="117-lsi-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>Introduction: I’m a bit late blogging this, but here’s a messy, exciting — and statistically validated! — new online data source.
 
My friend  Roddy  at Facebook  wrote a post describing their sentiment analysis system , which can evaluate positive or negative sentiment toward a particular topic by looking at a large number of wall messages.  (I’d link to it, but I can’t find the URL anymore — here’s the  Lexicon , but that version only gets term frequencies but no sentiment.)
 
How they constructed their sentiment detector is interesting.  Starting with a list of positive and negative terms, they had a lexical acquisition step to gather many more candidate synonyms and misspellings — a necessity in this social media domain, where  WordNet  ain’t gonna come close!  After manually filtering these candidates, they assess the sentiment toward a mention of a topic by looking for instances of these positive and negative words nearby, along with “negation heuristics” and a few other features.
 
He describ</p><p>6 0.4103297 <a title="117-lsi-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-04-13-Are_women_discriminated_against_in_graduate_admissions%3F_Simpson%E2%80%99s_paradox_via_R_in_three_easy_steps%21.html">101 brendan oconnor ai-2008-04-13-Are women discriminated against in graduate admissions? Simpson’s paradox via R in three easy steps!</a></p>
<p>7 0.39430764 <a title="117-lsi-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-08-16-A_better_Obama_vs_McCain_poll_aggregation.html">111 brendan oconnor ai-2008-08-16-A better Obama vs McCain poll aggregation</a></p>
<p>8 0.3923209 <a title="117-lsi-8" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-10-05-Be_careful_with_dictionary-based_text_analysis.html">176 brendan oconnor ai-2011-10-05-Be careful with dictionary-based text analysis</a></p>
<p>9 0.36660495 <a title="117-lsi-9" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-31-balkanized_USA.html">21 brendan oconnor ai-2005-07-31-balkanized USA</a></p>
<p>10 0.3612687 <a title="117-lsi-10" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>11 0.34491467 <a title="117-lsi-11" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-12-02-go_science.html">3 brendan oconnor ai-2004-12-02-go science</a></p>
<p>12 0.32778174 <a title="117-lsi-12" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>13 0.32428074 <a title="117-lsi-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-03-06-data_data_data.html">93 brendan oconnor ai-2008-03-06-data data data</a></p>
<p>14 0.3186661 <a title="117-lsi-14" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-12-Beautiful_Data_book_chapter.html">151 brendan oconnor ai-2009-08-12-Beautiful Data book chapter</a></p>
<p>15 0.30623043 <a title="117-lsi-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-08-MyDebates.org%2C_online_polling%2C_and_potentially_the_coolest_question_corpus_ever.html">116 brendan oconnor ai-2008-10-08-MyDebates.org, online polling, and potentially the coolest question corpus ever</a></p>
<p>16 0.30009848 <a title="117-lsi-16" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-14-How_much_text_versus_metadata_is_in_a_tweet%3F.html">171 brendan oconnor ai-2011-06-14-How much text versus metadata is in a tweet?</a></p>
<p>17 0.29748556 <a title="117-lsi-17" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-06-04-June_4.html">143 brendan oconnor ai-2009-06-04-June 4</a></p>
<p>18 0.29210946 <a title="117-lsi-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>19 0.29167131 <a title="117-lsi-19" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>20 0.28653398 <a title="117-lsi-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-28-Calculating_running_variance_in_Python_and_C%2B%2B.html">128 brendan oconnor ai-2008-11-28-Calculating running variance in Python and C++</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(14, 0.022), (16, 0.021), (24, 0.038), (36, 0.018), (44, 0.095), (48, 0.039), (55, 0.027), (59, 0.014), (70, 0.07), (74, 0.121), (75, 0.027), (79, 0.339), (80, 0.05)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9569183 <a title="117-lda-1" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-07-30-4-move_rock%2C_paper%2C_scissors%21.html">43 brendan oconnor ai-2006-07-30-4-move rock, paper, scissors!</a></p>
<p>Introduction: Contrary to  baseless speculation , it turns out it  is  possible to have a four-player, non-degenerate RPS game.  The game below is assymetrical: B does better than others, but you don’t want to play it all the time because that makes you vulnerable to A.  By contrast, D ain’t so hot.  But if you never play D, then your opponent can get away with A.  It’s uneven, but the optimal mixed strategy plays everything with non-zero probability.
 
     
 
Notation: the arrow from A to B means that A beats B.  Everyone ties themself.  No arrow indicates a tie.  There is a tie between A and C.  The  previous analysis  indicated there is no non-degenerate 4-RPS with no ties.  This has only 1 tie, so it seems to be the best possible.
 
(This game is just the  previous one  with the link from A to C removed.  This makes it so B no longer dominates C, since C is now invulnerable from A, unlike B.)</p><p>same-blog 2 0.92761159 <a title="117-lda-2" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-11-It_is_accurate_to_determine_a_blog%E2%80%99s_bias_by_what_it_links_to.html">117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</a></p>
<p>Introduction: Here’s a great project from Andy Baio and Joshua Schachter : they assessed the political biases of different blogs based on which articles they tend link to.  Using these political bias scores, they made a cool little Firefox extension that colors the names of different sources on the news aggregator site  Memeorandum , like so:
 
 
 
How they computed these biases is pretty neat.  Their data source was the Memeorandum site itself, which shows a particular news story, then a list of different news sites that have written articles about the topic.  Scraping out that data, Joshua constructed the adjacency matrix of sites vs. articles they linked to and ran good ol’  SVD  on it, an algorithm that can be used to summarize the very high-dimensional article linking information in just several numbers (“components” or “dimensions”) for each news site.  Basically, the algorithm groups together sites that tend to link to the same articles.  It’s not exactly clustering though; rather, it project</p><p>3 0.4243952 <a title="117-lda-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>4 0.40674621 <a title="117-lda-4" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-08-30-A_big%2C_fun_list_of_links_I%E2%80%99m_reading.html">44 brendan oconnor ai-2006-08-30-A big, fun list of links I’m reading</a></p>
<p>Introduction: Since blogging is hard, but reading is easy, lately I’ve taken to bookmarking interesting articles I’m reading, with the plan of blogging about them later.  This follow-through has happened a few times, but not that often.  In an amazing moment of thesis procrastination, today I sat down and figured out how to turn my  del.icio.us bookmarks  into a nice blogpost, with the plan that every week a post will appear with links I’ve recently read, or maybe I’ll use the script to generate a draft for myself that I’ll revise, or something.
 
But for this first such link post, I put in a whole bunch of them beyond just the last week — why have just a few when you could have *all* of them?  Future link posts will be shorter, I promise.
 
  Ariel Rubinstein: Freak-Freakonomics    July 2006   posted 8/19 under  economics   sarcastic, critical review of levitt & dubner’s Freakonomics 
  New Yorker review of Philip Tetlock’s book on political expert judgment   posted 8/19 under  judgment ,  psycholo</p><p>5 0.40492651 <a title="117-lda-5" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>Introduction: There’s a lot to say about  Powerset , the short-lived natural language search company (2005-2008) where I worked after college.  AI overhype, flying too close to the sun, the psychology of tech journalism and venture capitalism, etc.  A year or two ago I wrote the following bit about Powerset’s technology in response to a question  on Quora .  I’m posting a revised version here.
 
 Question:  What was Powerset’s core innovation in search?  As far as I can tell, they licensed an NLP engine. They did not have a question answering system or any system for information extraction. How was Powerset’s search engine different than Google’s?
 
 My answer:  Powerset built a system vaguely like a question-answering system on top of Xerox PARC’s NLP engine.  The output is better described as query-focused summarization rather than question answering; primarily, it matched semantic fragments of the user query against indexed semantic relations, with lots of keyword/ngram-matching fallback for when</p><p>6 0.39913774 <a title="117-lda-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-08-16-A_better_Obama_vs_McCain_poll_aggregation.html">111 brendan oconnor ai-2008-08-16-A better Obama vs McCain poll aggregation</a></p>
<p>7 0.393336 <a title="117-lda-7" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>8 0.38410836 <a title="117-lda-8" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>9 0.38073966 <a title="117-lda-9" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>10 0.37953281 <a title="117-lda-10" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-03-31-How_Facebook_privacy_failed_me.html">158 brendan oconnor ai-2010-03-31-How Facebook privacy failed me</a></p>
<p>11 0.3758246 <a title="117-lda-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<p>12 0.37521547 <a title="117-lda-12" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>13 0.37439549 <a title="117-lda-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>14 0.37338284 <a title="117-lda-14" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>15 0.37062708 <a title="117-lda-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>16 0.37035632 <a title="117-lda-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>17 0.36953825 <a title="117-lda-17" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>18 0.36476627 <a title="117-lda-18" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>19 0.36374399 <a title="117-lda-19" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>20 0.36241955 <a title="117-lda-20" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
