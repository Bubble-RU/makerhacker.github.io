<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>170 brendan oconnor ai-2011-05-21-iPhone autocorrection error analysis</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2011" href="../home/brendan_oconnor_ai-2011_home.html">brendan_oconnor_ai-2011</a> <a title="brendan_oconnor_ai-2011-170" href="#">brendan_oconnor_ai-2011-170</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>170 brendan oconnor ai-2011-05-21-iPhone autocorrection error analysis</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2011-170-html" href="http://brenocon.com/blog/2011/05/iphone-autocorrection-error-analysis/">html</a></p><p>Introduction: re  @andrewparker :
  
 My iPhone auto-corrected “Harvard” to “Garbage”. Well played Apple engineers. 
  
I was wondering how this would happen, and then noticed that each character pair has 0 to 2 distance on the QWERTY keyboard.  Perhaps their model is eager to allow QWERTY-local character substitutions.
  
 
>>> zip(‘harvard’,'garbage’) 
[('h', 'g'), ('a', 'a'), ('r', 'r'), ('v', 'b'), ('a', 'a'), ('r', 'g'), ('d', 'e')]
 
  
And then most any language model thinks p(“garbage”) > p(“harvard”), at the very least in a unigram model with a broad domain corpus.  So if it’s a noisy channel-style model, they’re underpenalizing the edit distance relative to the LM prior.  (Reference:  Norvig’s noisy channel spelling correction article .)
 
On the other hand, given how  insane iPhone autocorrections are , and from the number of times I’ve seen it delete a quite reasonable word I wrote, I’d bet “harvard” isn’t even in their LM.  (Where the LM is more like just a dictionary; call it quantizin</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 re  @andrewparker :     My iPhone auto-corrected “Harvard” to “Garbage”. [sent-1, score-0.067]
</p><p>2 I was wondering how this would happen, and then noticed that each character pair has 0 to 2 distance on the QWERTY keyboard. [sent-3, score-0.781]
</p><p>3 Perhaps their model is eager to allow QWERTY-local character substitutions. [sent-4, score-0.527]
</p><p>4 >>> zip(‘harvard’,'garbage’)  [('h', 'g'), ('a', 'a'), ('r', 'r'), ('v', 'b'), ('a', 'a'), ('r', 'g'), ('d', 'e')]      And then most any language model thinks p(“garbage”) > p(“harvard”), at the very least in a unigram model with a broad domain corpus. [sent-5, score-0.893]
</p><p>5 So if it’s a noisy channel-style model, they’re underpenalizing the edit distance relative to the LM prior. [sent-6, score-0.468]
</p><p>6 (Reference:  Norvig’s noisy channel spelling correction article . [sent-7, score-0.273]
</p><p>7 )   On the other hand, given how  insane iPhone autocorrections are , and from the number of times I’ve seen it delete a quite reasonable word I wrote, I’d bet “harvard” isn’t even in their LM. [sent-8, score-0.509]
</p><p>8 (Where the LM is more like just a dictionary; call it quantizing probabilities to 1 bit if you like. [sent-9, score-0.169]
</p><p>9 )  I think  Hal  mentioned once he would gladly give up GB’s of storage for a better language model to make iPhone autocorrect not suck. [sent-10, score-0.728]
</p><p>10 Language models with high coverage are important. [sent-12, score-0.206]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('harvard', 0.41), ('iphone', 0.307), ('apple', 0.258), ('garbage', 0.258), ('lm', 0.258), ('model', 0.25), ('distance', 0.224), ('character', 0.191), ('noisy', 0.171), ('language', 0.14), ('played', 0.112), ('delete', 0.112), ('noticed', 0.112), ('zip', 0.112), ('hal', 0.112), ('illustrated', 0.112), ('insane', 0.112), ('storage', 0.102), ('norvig', 0.102), ('correction', 0.102), ('gb', 0.102), ('probabilities', 0.102), ('dictionary', 0.102), ('would', 0.095), ('coverage', 0.095), ('broad', 0.095), ('allow', 0.086), ('reference', 0.086), ('wish', 0.086), ('bet', 0.086), ('pair', 0.086), ('mentioned', 0.082), ('domain', 0.082), ('reasonable', 0.079), ('thinks', 0.076), ('happen', 0.076), ('wondering', 0.073), ('sounds', 0.073), ('google', 0.073), ('relative', 0.073), ('re', 0.067), ('call', 0.067), ('figure', 0.067), ('hand', 0.065), ('papers', 0.062), ('given', 0.062), ('give', 0.059), ('times', 0.058), ('high', 0.056), ('models', 0.055)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="170-tfidf-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-21-iPhone_autocorrection_error_analysis.html">170 brendan oconnor ai-2011-05-21-iPhone autocorrection error analysis</a></p>
<p>Introduction: re  @andrewparker :
  
 My iPhone auto-corrected “Harvard” to “Garbage”. Well played Apple engineers. 
  
I was wondering how this would happen, and then noticed that each character pair has 0 to 2 distance on the QWERTY keyboard.  Perhaps their model is eager to allow QWERTY-local character substitutions.
  
 
>>> zip(‘harvard’,'garbage’) 
[('h', 'g'), ('a', 'a'), ('r', 'r'), ('v', 'b'), ('a', 'a'), ('r', 'g'), ('d', 'e')]
 
  
And then most any language model thinks p(“garbage”) > p(“harvard”), at the very least in a unigram model with a broad domain corpus.  So if it’s a noisy channel-style model, they’re underpenalizing the edit distance relative to the LM prior.  (Reference:  Norvig’s noisy channel spelling correction article .)
 
On the other hand, given how  insane iPhone autocorrections are , and from the number of times I’ve seen it delete a quite reasonable word I wrote, I’d bet “harvard” isn’t even in their LM.  (Where the LM is more like just a dictionary; call it quantizin</p><p>2 0.17065217 <a title="170-tfidf-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-31-Cooperation_dynamics_%E2%80%93_Martin_Nowak.html">72 brendan oconnor ai-2007-07-31-Cooperation dynamics – Martin Nowak</a></p>
<p>Introduction: Nice little NYT article on  Martin Nowak, of evolution-of-cooperation fame .  He’s the directory of Harvard’s  Program for Evolutionary Dynamics  which looks neat.  I love the  the Price Equation .  Sweet.</p><p>3 0.10592571 <a title="170-tfidf-3" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-01-Modelling_environmentalism_thinking.html">11 brendan oconnor ai-2005-07-01-Modelling environmentalism thinking</a></p>
<p>Introduction: It’s a human political belief model — based on Cyc!  I’m not sure logic represents how people think all that well, but seeing the formalization of ideology is fascinating.  And besides, the methodology of cognitive modelling is awesome.   The link:  
 Modeling How People Think About Sustainability 
 
David C. James, M. P. Aff
 
LBJ School of Public Affairs The University of Texas at Austin May 2005
 
First Reader: Lodis Rhodes  Second Reader: Chandler Stolp
 
How effectively can a computer model represent the belief systems of different people? How would one go about representing a belief system using formal logic? How would that ideology react to different scenarios related to sustainable development? The author constructs the Cyc Agent-Scenario (CAS) model as a way to investigate these questions. The CAS model is built on top of ResearchCyc, a knowledge base (KB) and logical inference engine. The model consists of two agents (Libertarian and Green) and two scenarios. The model simula</p><p>4 0.092430398 <a title="170-tfidf-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-01-Bias_correction_sneak_peek%21.html">108 brendan oconnor ai-2008-07-01-Bias correction sneak peek!</a></p>
<p>Introduction: (Update 10/2008: actually this model doesn’t work in all cases.Â   In the final paper  we use an (even) simpler model.)
 
I really don’t have time to write up an explanation for what this is so I’ll just post the graph instead.  Each box is a scatterplot of an AMT worker’s responses versus a gold standard.  Drawn are attempts to fit linear models to each worker.  The idea is to correct for the biases of each worker.  With a linear model y ~ ax+b, the correction is correction(y) = (y-b)/a.  Arrows show such corrections.  Hilariously bad “corrections” happen.  *But*, there is also weighting: to get the “correct” answer (maximum likelihood) from several workers, you weight by a^2/stddev^2.  Despite the sometimes odd corrections, the cross-validated results from this model correlate better with the gold than the raw averaging of workers.  (Raw averaging is the maximum likelihood solution for a fixed noise model: a=1, b=0, and each worker’s variance is equal).
 
Much better explanation is c</p><p>5 0.086884156 <a title="170-tfidf-5" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-27-Where_tweets_get_sent_from.html">142 brendan oconnor ai-2009-05-27-Where tweets get sent from</a></p>
<p>Introduction: Playing around with  stream.twitter.com/spritzer ,  ggplot2  and  maps / mapdata :
 
   
 
I think I like the top better, without the map lines, like those  night satellite photos : pointwise ghosts of high-end human economic development.
 
This data is a fairly extreme sample of convenience: I’m only looking at tweets posted by certain types of iPhone clients, because they conveniently report exact gps-derived latitude/longitude numbers.  ( search.twitter.com  has geographic proximity operators — which are very cool! — but they seem to usually use zip codes or other user information that’s not available in the per-tweet API data.)  So there’s only 30,000 messages out of 1.2 million  spritzer  tweets over ~3 days (itself only a small single-digit percentage sample of twitter).</p><p>6 0.069635987 <a title="170-tfidf-6" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>7 0.069312133 <a title="170-tfidf-7" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-05-08-Movie_summary_corpus_and_learning_character_personas.html">196 brendan oconnor ai-2013-05-08-Movie summary corpus and learning character personas</a></p>
<p>8 0.067355886 <a title="170-tfidf-8" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-12-Beautiful_Data_book_chapter.html">151 brendan oconnor ai-2009-08-12-Beautiful Data book chapter</a></p>
<p>9 0.067330427 <a title="170-tfidf-9" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>10 0.058030274 <a title="170-tfidf-10" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>11 0.057340082 <a title="170-tfidf-11" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-08-21-ConnectU.com_SQL_injection_vulnerability%3A_a_story_of_pathetic_hubris_%28and_fun_with_the_password_%E2%80%98password%E2%80%99%29.html">76 brendan oconnor ai-2007-08-21-ConnectU.com SQL injection vulnerability: a story of pathetic hubris (and fun with the password ‘password’)</a></p>
<p>12 0.055122368 <a title="170-tfidf-12" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>13 0.053917691 <a title="170-tfidf-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<p>14 0.050714828 <a title="170-tfidf-14" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-The_Jungle_Economy.html">47 brendan oconnor ai-2007-01-02-The Jungle Economy</a></p>
<p>15 0.050292142 <a title="170-tfidf-15" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-18-Scatterplot_of_KN-PYP_language_model_results.html">202 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</a></p>
<p>16 0.048364867 <a title="170-tfidf-16" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-25-Cerealitivity.html">70 brendan oconnor ai-2007-07-25-Cerealitivity</a></p>
<p>17 0.048113286 <a title="170-tfidf-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>18 0.046713151 <a title="170-tfidf-18" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-27-Graphics%21_Atari_Breakout_and_religious_text_NLP.html">91 brendan oconnor ai-2008-01-27-Graphics! Atari Breakout and religious text NLP</a></p>
<p>19 0.043949749 <a title="170-tfidf-19" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-09-18-%22Machine%22_translation-vision_%28Stanford_AI_courses_online%29.html">113 brendan oconnor ai-2008-09-18-"Machine" translation-vision (Stanford AI courses online)</a></p>
<p>20 0.043419603 <a title="170-tfidf-20" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-10-05-Be_careful_with_dictionary-based_text_analysis.html">176 brendan oconnor ai-2011-10-05-Be careful with dictionary-based text analysis</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.157), (1, -0.044), (2, 0.033), (3, 0.014), (4, -0.005), (5, 0.022), (6, 0.043), (7, 0.077), (8, -0.064), (9, 0.171), (10, -0.064), (11, -0.02), (12, 0.07), (13, 0.002), (14, -0.078), (15, -0.036), (16, 0.069), (17, 0.056), (18, -0.086), (19, -0.027), (20, 0.178), (21, -0.04), (22, 0.157), (23, 0.115), (24, 0.124), (25, -0.07), (26, 0.171), (27, 0.062), (28, 0.022), (29, 0.155), (30, -0.101), (31, -0.002), (32, 0.089), (33, -0.045), (34, -0.059), (35, 0.048), (36, -0.007), (37, -0.173), (38, 0.204), (39, 0.032), (40, -0.12), (41, 0.06), (42, -0.12), (43, -0.014), (44, 0.068), (45, -0.042), (46, 0.12), (47, 0.111), (48, -0.052), (49, 0.031)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98644418 <a title="170-lsi-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-21-iPhone_autocorrection_error_analysis.html">170 brendan oconnor ai-2011-05-21-iPhone autocorrection error analysis</a></p>
<p>Introduction: re  @andrewparker :
  
 My iPhone auto-corrected “Harvard” to “Garbage”. Well played Apple engineers. 
  
I was wondering how this would happen, and then noticed that each character pair has 0 to 2 distance on the QWERTY keyboard.  Perhaps their model is eager to allow QWERTY-local character substitutions.
  
 
>>> zip(‘harvard’,'garbage’) 
[('h', 'g'), ('a', 'a'), ('r', 'r'), ('v', 'b'), ('a', 'a'), ('r', 'g'), ('d', 'e')]
 
  
And then most any language model thinks p(“garbage”) > p(“harvard”), at the very least in a unigram model with a broad domain corpus.  So if it’s a noisy channel-style model, they’re underpenalizing the edit distance relative to the LM prior.  (Reference:  Norvig’s noisy channel spelling correction article .)
 
On the other hand, given how  insane iPhone autocorrections are , and from the number of times I’ve seen it delete a quite reasonable word I wrote, I’d bet “harvard” isn’t even in their LM.  (Where the LM is more like just a dictionary; call it quantizin</p><p>2 0.67122209 <a title="170-lsi-2" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-31-Cooperation_dynamics_%E2%80%93_Martin_Nowak.html">72 brendan oconnor ai-2007-07-31-Cooperation dynamics – Martin Nowak</a></p>
<p>Introduction: Nice little NYT article on  Martin Nowak, of evolution-of-cooperation fame .  He’s the directory of Harvard’s  Program for Evolutionary Dynamics  which looks neat.  I love the  the Price Equation .  Sweet.</p><p>3 0.48260415 <a title="170-lsi-3" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-01-Modelling_environmentalism_thinking.html">11 brendan oconnor ai-2005-07-01-Modelling environmentalism thinking</a></p>
<p>Introduction: It’s a human political belief model — based on Cyc!  I’m not sure logic represents how people think all that well, but seeing the formalization of ideology is fascinating.  And besides, the methodology of cognitive modelling is awesome.   The link:  
 Modeling How People Think About Sustainability 
 
David C. James, M. P. Aff
 
LBJ School of Public Affairs The University of Texas at Austin May 2005
 
First Reader: Lodis Rhodes  Second Reader: Chandler Stolp
 
How effectively can a computer model represent the belief systems of different people? How would one go about representing a belief system using formal logic? How would that ideology react to different scenarios related to sustainable development? The author constructs the Cyc Agent-Scenario (CAS) model as a way to investigate these questions. The CAS model is built on top of ResearchCyc, a knowledge base (KB) and logical inference engine. The model consists of two agents (Libertarian and Green) and two scenarios. The model simula</p><p>4 0.46647227 <a title="170-lsi-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-Netflix_Prize.html">125 brendan oconnor ai-2008-11-21-Netflix Prize</a></p>
<p>Introduction: Here’s  a fascinating NYT article on the Netflix Prize  for a better movie recommendation system.  Tons of great stuff there; here’s a few highlights …
 
First, a good unsupervised learning story:
  
There’s a sort of unsettling, alien quality to their computers’ results. When the teams examine the ways that singular value decomposition is slotting movies into categories, sometimes it makes sense to them — as when the computer highlights what appears to be some essence of nerdiness in a bunch of sci-fi movies. But many categorizations are now so obscure that they cannot see the reasoning behind them. Possibly the algorithms are finding connections so deep and subconscious that customers themselves wouldn’t even recognize them. At one point, Chabbert showed me a list of movies that his algorithm had discovered share some ineffable similarity; it includes a historical movie, “Joan of Arc,” a wrestling video, “W.W.E.: SummerSlam 2004,” the comedy “It Had to Be You” and a version of Charle</p><p>5 0.43768859 <a title="170-lsi-5" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-18-Scatterplot_of_KN-PYP_language_model_results.html">202 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</a></p>
<p>Introduction: I should make a blog where all I do is scatterplot results tables from papers.  I do this once in a while to make them eaiser to understand…
 
I think the following are results are from Yee Whye Teh’s paper on hierarchical Pitman-Yor language models, and in particular comparing them to Kneser-Ney and hierarchical Dirichlets.  They’re specifically from  these slides by Yee Whye Teh (page 25) , which shows model perplexities.  Every dot is for one experimental condition, which has four different results from each of the models.  So a pair of models can be compared in one scatterplot.
 
   
 
where
  
   ikn = interpolated kneser-ney
    mkn = modified kneser-ney
    hdlm = hierarchical dirichlet
    hpylm = hierarchical pitman-yor
   
My reading: the KN’s and HPYLM are incredibly similar (as Teh argues should be the case on theoretical grounds).  MKN and HPYLM edge out IKN.  HDLM is markedly worse (this is perplexity, so lower is better).  While HDLM is a lot worse, it does best, relativ</p><p>6 0.39633188 <a title="170-lsi-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-01-Bias_correction_sneak_peek%21.html">108 brendan oconnor ai-2008-07-01-Bias correction sneak peek!</a></p>
<p>7 0.35336855 <a title="170-lsi-7" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-27-Where_tweets_get_sent_from.html">142 brendan oconnor ai-2009-05-27-Where tweets get sent from</a></p>
<p>8 0.326444 <a title="170-lsi-8" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>9 0.32192993 <a title="170-lsi-9" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-05-08-Movie_summary_corpus_and_learning_character_personas.html">196 brendan oconnor ai-2013-05-08-Movie summary corpus and learning character personas</a></p>
<p>10 0.31494647 <a title="170-lsi-10" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-04-City_crisis_simulation_%28e.g._terrorist_attack%29.html">14 brendan oconnor ai-2005-07-04-City crisis simulation (e.g. terrorist attack)</a></p>
<p>11 0.30750307 <a title="170-lsi-11" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>12 0.29889745 <a title="170-lsi-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-12-Beautiful_Data_book_chapter.html">151 brendan oconnor ai-2009-08-12-Beautiful Data book chapter</a></p>
<p>13 0.29320818 <a title="170-lsi-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>14 0.28004935 <a title="170-lsi-14" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-11-guns%2C_germs%2C_%26_steel_pbs_show%3F%21.html">20 brendan oconnor ai-2005-07-11-guns, germs, & steel pbs show?!</a></p>
<p>15 0.28003553 <a title="170-lsi-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>16 0.27303666 <a title="170-lsi-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-27-Graphics%21_Atari_Breakout_and_religious_text_NLP.html">91 brendan oconnor ai-2008-01-27-Graphics! Atari Breakout and religious text NLP</a></p>
<p>17 0.25944683 <a title="170-lsi-17" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-08-09-An_ML-AI_approach_to_P_%21%3D_NP.html">161 brendan oconnor ai-2010-08-09-An ML-AI approach to P != NP</a></p>
<p>18 0.25002426 <a title="170-lsi-18" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-01-02-The_Jungle_Economy.html">47 brendan oconnor ai-2007-01-02-The Jungle Economy</a></p>
<p>19 0.2410772 <a title="170-lsi-19" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-04-16-Rise_and_fall_of_Dirichlet_process_clusters.html">194 brendan oconnor ai-2013-04-16-Rise and fall of Dirichlet process clusters</a></p>
<p>20 0.22870708 <a title="170-lsi-20" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(44, 0.144), (55, 0.031), (74, 0.147), (76, 0.542)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.96584564 <a title="170-lda-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-31-Cooperation_dynamics_%E2%80%93_Martin_Nowak.html">72 brendan oconnor ai-2007-07-31-Cooperation dynamics – Martin Nowak</a></p>
<p>Introduction: Nice little NYT article on  Martin Nowak, of evolution-of-cooperation fame .  He’s the directory of Harvard’s  Program for Evolutionary Dynamics  which looks neat.  I love the  the Price Equation .  Sweet.</p><p>same-blog 2 0.92360306 <a title="170-lda-2" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-21-iPhone_autocorrection_error_analysis.html">170 brendan oconnor ai-2011-05-21-iPhone autocorrection error analysis</a></p>
<p>Introduction: re  @andrewparker :
  
 My iPhone auto-corrected “Harvard” to “Garbage”. Well played Apple engineers. 
  
I was wondering how this would happen, and then noticed that each character pair has 0 to 2 distance on the QWERTY keyboard.  Perhaps their model is eager to allow QWERTY-local character substitutions.
  
 
>>> zip(‘harvard’,'garbage’) 
[('h', 'g'), ('a', 'a'), ('r', 'r'), ('v', 'b'), ('a', 'a'), ('r', 'g'), ('d', 'e')]
 
  
And then most any language model thinks p(“garbage”) > p(“harvard”), at the very least in a unigram model with a broad domain corpus.  So if it’s a noisy channel-style model, they’re underpenalizing the edit distance relative to the LM prior.  (Reference:  Norvig’s noisy channel spelling correction article .)
 
On the other hand, given how  insane iPhone autocorrections are , and from the number of times I’ve seen it delete a quite reasonable word I wrote, I’d bet “harvard” isn’t even in their LM.  (Where the LM is more like just a dictionary; call it quantizin</p><p>3 0.70348656 <a title="170-lda-3" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>Introduction: This is my idea based off of  Bernheim and Rangel’s  model of addict decision-making .  It’s a really neat model; it manages to relax rationality to allow someone to do something they don’t want to do because they’re addicted to it.  [Rationality assumes a nice well-ordered set of preferences; this model hypothesizes as distinction between emotional "liking" and cognitive, forward "wanting" that can conflict.]  The model is mathematically tractable, it can be used for public welfare analysis, and to top it off — it’s got neuroscientific grounding!
 
It appears to me there are two big criticisms of the economics discipline’s assumptions.  One of course is rationality.  The second has to do with the perfect structure of the market and environment that shapes both preferences and the ability to exercise them.  One critique is about social structure: consumers are not atomistic individual units, but rather exchange information and ideas along networks of patterned social relations.  (Socia</p><p>4 0.32348448 <a title="170-lda-4" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>Introduction: Everyone recently seems to be talking about  this newish paper by Digrazia, McKelvey, Bollen, and Rojas  ( pdf here ) that examines the correlation of Congressional candidate name mentions on Twitter against whether the candidate won the race.  One of the coauthors also wrote a Washington Post  Op-Ed  about it.  I read the paper and I think it’s reasonable, but their op-ed overstates their results.  It claims:
  
“In the 2010 data, our Twitter data predicted the winner in 404 out of 435 competitive races”
  
But this analysis is nowhere in their paper.  Fabio Rojas has now  posted errata/rebuttals  about the op-ed and described this analysis they did here.  There are several major issues off the bat:
  
 They didn’t ever predict 404/435 races; they only analyzed 406 races they call “competitive,” getting 92.5% (in-sample) accuracy, then extrapolated to all races to get the 435 number. 
 They’re reporting about  in-sample  predictions, which is really misleading to a non-scientific audi</p><p>5 0.31369293 <a title="170-lda-5" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>6 0.31350014 <a title="170-lda-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>7 0.30950078 <a title="170-lda-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>8 0.30382651 <a title="170-lda-8" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>9 0.30203778 <a title="170-lda-9" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>10 0.3010397 <a title="170-lda-10" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>11 0.29721448 <a title="170-lda-11" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-09-02-cognitive_modelling_is_rational_choice%2B%2B.html">26 brendan oconnor ai-2005-09-02-cognitive modelling is rational choice++</a></p>
<p>12 0.2971155 <a title="170-lda-12" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>13 0.29129624 <a title="170-lda-13" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>14 0.29036647 <a title="170-lda-14" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>15 0.28529784 <a title="170-lda-15" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-06-10-Freak-Freakonomics_%28Ariel_Rubinstein_is_the_shit%21%29.html">63 brendan oconnor ai-2007-06-10-Freak-Freakonomics (Ariel Rubinstein is the shit!)</a></p>
<p>16 0.28222463 <a title="170-lda-16" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<p>17 0.28186977 <a title="170-lda-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-05-Clinton-Obama_support_visualization.html">105 brendan oconnor ai-2008-06-05-Clinton-Obama support visualization</a></p>
<p>18 0.27766699 <a title="170-lda-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>19 0.27754444 <a title="170-lda-19" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>20 0.27750611 <a title="170-lda-20" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-09-15-Dollar_auction.html">77 brendan oconnor ai-2007-09-15-Dollar auction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
