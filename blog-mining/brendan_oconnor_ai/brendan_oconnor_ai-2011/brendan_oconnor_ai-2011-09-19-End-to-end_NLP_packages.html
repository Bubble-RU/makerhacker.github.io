<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2011" href="../home/brendan_oconnor_ai-2011_home.html">brendan_oconnor_ai-2011</a> <a title="brendan_oconnor_ai-2011-174" href="#">brendan_oconnor_ai-2011-174</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2011-174-html" href="http://brenocon.com/blog/2011/09/end-to-end-nlp-packages/">html</a></p><p>Introduction: What freely available end-to-end natural language processing (NLP) systems are out there, that start with raw text, and output parses and semantic structures?  Lots of NLP research focuses on single tasks at a time, and thus produces software that does a single task at a time.  But for various applications, it is nicer to have a full end-to-end system that just runs on whatever text you give it.
 
If you believe this is a worthwhile goal (see caveat at bottom), I will postulate there aren’t a ton of such end-to-end, multilevel systems.  Here are ones I can think of.  Corrections and clarifications welcome.
  
  Stanford CoreNLP .  Raw text to  rich syntactic dependencies  ( LFG -inspired).  Also POS, NER, coreference. 
  C&C; tools .  From (sentence-segmented, tokenized?) text to rich syntactic dependencies ( CCG -based) and also a semantic representation.  POS and chunks on the way.  Does anyone use this much?  It seems underappreciated relative to its richness. 
  Senna .  Sentence-se</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 What freely available end-to-end natural language processing (NLP) systems are out there, that start with raw text, and output parses and semantic structures? [sent-1, score-0.32]
</p><p>2 Lots of NLP research focuses on single tasks at a time, and thus produces software that does a single task at a time. [sent-2, score-0.438]
</p><p>3 But for various applications, it is nicer to have a full end-to-end system that just runs on whatever text you give it. [sent-3, score-0.414]
</p><p>4 Raw text to  rich syntactic dependencies  ( LFG -inspired). [sent-8, score-0.707]
</p><p>5 ) text to rich syntactic dependencies ( CCG -based) and also a semantic representation. [sent-12, score-1.002]
</p><p>6 Sentence-segmented text -> parse trees, plus POS, NER, chunks, and semantic role labeling. [sent-17, score-0.571]
</p><p>7 It doesn’t give syntactic dependencies, though for some applications semantic role labeling is similar or better (or worse? [sent-19, score-0.75]
</p><p>8 I’m a little concerned that its documentation seems overly focused on competing in evaluation datasets, as opposed to trying to ensure they’ve made something more broadly useful. [sent-21, score-0.389]
</p><p>9 (To be fair, they’re focused on developing algorithms that could be broadly applicable to different NLP tasks; that’s a whole other discussion. [sent-22, score-0.372]
</p><p>10 )     If you want to quickly get some sort of shallow semantic relations, a. [sent-23, score-0.327]
</p><p>11 high-level syntactic relations, one of the above packages might be your best bet. [sent-26, score-0.393]
</p><p>12 One example: if you have constituent parse trees and want dependencies, you could swap in the  Stanford Dependency  extractor (or another one like  pennconverter ? [sent-29, score-0.453]
</p><p>13 Or you could swap in the  Charniak-Johnson  or  Berkeley  parser into the middle of the Stanford CoreNLP stack. [sent-31, score-0.297]
</p><p>14 Or you could use a direct dependency parser (I think  Malt  is the most popular? [sent-32, score-0.433]
</p><p>15 I believe that, unlike the above, they don’t focus on out-of-the-box end-to-end NLP analysis (though you can certainly use them to perform various parts of an NLP pipeline). [sent-36, score-0.245]
</p><p>16 Mallet  — focuses on information extraction and topic modeling, so slightly different than the other packages listed here. [sent-43, score-0.262]
</p><p>17 It seems to do various tagging and chunking tasks. [sent-45, score-0.57]
</p><p>18 zip archive all the time though (I can’t find a direct download link unfortunately), for its stopword lists and small toy corpora. [sent-47, score-0.254]
</p><p>19 I guess it now counts as a toy corpus since you can grep it in less than a second. [sent-49, score-0.19]
</p><p>20 )     These packages are nice in terms of documentation and software engineering, but they don’t do any syntactic parsing or other shallow relational extraction. [sent-50, score-0.761]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('syntactic', 0.24), ('nlp', 0.227), ('dependencies', 0.219), ('semantic', 0.218), ('tagging', 0.207), ('chunking', 0.18), ('text', 0.157), ('packages', 0.153), ('pos', 0.153), ('chunks', 0.138), ('corenlp', 0.138), ('nltk', 0.138), ('trees', 0.138), ('broadly', 0.12), ('swap', 0.12), ('stanford', 0.114), ('toy', 0.109), ('ner', 0.109), ('focuses', 0.109), ('parse', 0.109), ('shallow', 0.109), ('various', 0.107), ('focused', 0.102), ('raw', 0.102), ('libraries', 0.102), ('dependency', 0.102), ('relations', 0.096), ('tasks', 0.096), ('tools', 0.096), ('rich', 0.091), ('parser', 0.091), ('documentation', 0.091), ('role', 0.087), ('full', 0.087), ('software', 0.087), ('could', 0.086), ('direct', 0.084), ('applications', 0.081), ('corpus', 0.081), ('parsing', 0.081), ('also', 0.077), ('seems', 0.076), ('single', 0.073), ('use', 0.07), ('believe', 0.068), ('lots', 0.065), ('algorithms', 0.064), ('give', 0.063), ('though', 0.061), ('aims', 0.06)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="174-tfidf-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-19-End-to-end_NLP_packages.html">174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</a></p>
<p>Introduction: What freely available end-to-end natural language processing (NLP) systems are out there, that start with raw text, and output parses and semantic structures?  Lots of NLP research focuses on single tasks at a time, and thus produces software that does a single task at a time.  But for various applications, it is nicer to have a full end-to-end system that just runs on whatever text you give it.
 
If you believe this is a worthwhile goal (see caveat at bottom), I will postulate there aren’t a ton of such end-to-end, multilevel systems.  Here are ones I can think of.  Corrections and clarifications welcome.
  
  Stanford CoreNLP .  Raw text to  rich syntactic dependencies  ( LFG -inspired).  Also POS, NER, coreference. 
  C&C; tools .  From (sentence-segmented, tokenized?) text to rich syntactic dependencies ( CCG -based) and also a semantic representation.  POS and chunks on the way.  Does anyone use this much?  It seems underappreciated relative to its richness. 
  Senna .  Sentence-se</p><p>2 0.25618389 <a title="174-tfidf-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>Introduction: I haven’t done a paper review on this blog for a while, so here we go.
 
 Coreference  resolution is an interesting NLP problem.  ( Examples. )  It involves honest-to-goodness syntactic, semantic, and discourse phenomena, but still seems like a real cognitive task that humans have to solve when reading text [1].  I haven’t read the whole literature, but I’ve always been puzzled by the crop of papers on it I’ve seen in the last year or two.  There’s a big focus on fancy graph/probabilistic/constrained optimization algorithms, but often these papers gloss over the linguistic features — the core information they actually make their decisions with [2].  I never understood why the latter isn’t the most important issue.  Therefore, it was a joy to read
  
 Aria Haghighi and Dan Klein, EMNLP-2009.   “Simple Coreference Resolution with Rich Syntactic and Semantic Features.”  
  
They describe a simple, essentially non-statistical system that outperforms previous unsupervised systems, and compa</p><p>3 0.19402589 <a title="174-tfidf-3" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-04-14-quick_note%3A_cer_et_al_2010.html">159 brendan oconnor ai-2010-04-14-quick note: cer et al 2010</a></p>
<p>Introduction: Quick note, reading this  paper  from  their tweet .
 
 update  this reaction might be totally wrong; in particular, the conll dependencies for at least some languages were done completely by hand.
   
Malt and MSTParser were designed for the Yamada and Matsumodo dependencies formalism (the one used for the CoNLL dependency parsing shared task, from the   penn2malt   tool).  Their feature sets and probably many other design decisions were created to support that.  If you compare their outputs side-by-side, you will see that the Stanford Dependencies are a substantially different formalism; for example, compound verbs are handled very differently (the paper talks about copula example). 
I think the following conclusion is premature:
  
Notwithstanding the very large amount of research that has gone into dependency 
parsing algorithms in the last ďŹ ve years, our central conclusion is that the quality of the Charniak, Charniak-Johnson reranking, and Berkeley parsers is so high that in th</p><p>4 0.16472897 <a title="174-tfidf-4" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>Introduction: There’s a lot to say about  Powerset , the short-lived natural language search company (2005-2008) where I worked after college.  AI overhype, flying too close to the sun, the psychology of tech journalism and venture capitalism, etc.  A year or two ago I wrote the following bit about Powerset’s technology in response to a question  on Quora .  I’m posting a revised version here.
 
 Question:  What was Powerset’s core innovation in search?  As far as I can tell, they licensed an NLP engine. They did not have a question answering system or any system for information extraction. How was Powerset’s search engine different than Google’s?
 
 My answer:  Powerset built a system vaguely like a question-answering system on top of Xerox PARC’s NLP engine.  The output is better described as query-focused summarization rather than question answering; primarily, it matched semantic fragments of the user query against indexed semantic relations, with lots of keyword/ngram-matching fallback for when</p><p>5 0.14462319 <a title="174-tfidf-5" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">153 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>Introduction: I’ve been reading several somewhat recent finance papers ( Antweiler and Frank 2005 ,  Das and Chen 2007 ) that use  Rainbow , the text classification software originally written by  Andrew McCallum  back in 1996.  The last version is from 2002 and the homepage announces he isn’t really supporting it any more.
 
However, as far as I can tell, it might still be the easiest-to-use text classifier package out there.  You don’t have to program — just invoke commandline arguments — and it can accommodate reasonably sized datasets, does tokenization, stopword filtering, etc. for you, and has some useful feature selection and other options.  Based on my limited usage, it seems well-implemented.  If anyone knows of a better one I’d love to hear it.  I once looked at, among other things,  GATE  and  UIMA , and they seemed too hard to use if you wanted to download something that did simple text classification; or else, maybe they didn’t have documentation on how to use them in that manner.     R</p><p>6 0.1333086 <a title="174-tfidf-6" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-11-24-Graphs_for_SANCL-2012_web_parsing_results.html">189 brendan oconnor ai-2012-11-24-Graphs for SANCL-2012 web parsing results</a></p>
<p>7 0.1277729 <a title="174-tfidf-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-09-I_don%E2%80%99t_get_this_web_parsing_shared_task.html">181 brendan oconnor ai-2012-03-09-I don’t get this web parsing shared task</a></p>
<p>8 0.11305219 <a title="174-tfidf-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-09-18-%22Machine%22_translation-vision_%28Stanford_AI_courses_online%29.html">113 brendan oconnor ai-2008-09-18-"Machine" translation-vision (Stanford AI courses online)</a></p>
<p>9 0.095476553 <a title="174-tfidf-9" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>10 0.090222627 <a title="174-tfidf-10" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>11 0.088965535 <a title="174-tfidf-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>12 0.085067965 <a title="174-tfidf-12" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>13 0.081563398 <a title="174-tfidf-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>14 0.078931779 <a title="174-tfidf-14" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>15 0.076046616 <a title="174-tfidf-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>16 0.075225309 <a title="174-tfidf-16" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-26-Good_linguistic_semantics_textbook%3F.html">172 brendan oconnor ai-2011-06-26-Good linguistic semantics textbook?</a></p>
<p>17 0.071938679 <a title="174-tfidf-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-03-24-Quick-R%2C_the_only_decent_R_documentation_on_the_internet.html">97 brendan oconnor ai-2008-03-24-Quick-R, the only decent R documentation on the internet</a></p>
<p>18 0.07166329 <a title="174-tfidf-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-07-Love_it_and_hate_it%2C_R_has_come_of_age.html">132 brendan oconnor ai-2009-01-07-Love it and hate it, R has come of age</a></p>
<p>19 0.071639277 <a title="174-tfidf-19" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-29-%22Stanford_Impostor%22.html">62 brendan oconnor ai-2007-05-29-"Stanford Impostor"</a></p>
<p>20 0.070829242 <a title="174-tfidf-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.273), (1, -0.218), (2, 0.091), (3, -0.081), (4, 0.1), (5, -0.14), (6, 0.019), (7, 0.002), (8, 0.011), (9, -0.188), (10, 0.092), (11, 0.002), (12, 0.072), (13, 0.115), (14, 0.208), (15, -0.106), (16, -0.01), (17, 0.012), (18, 0.131), (19, -0.067), (20, 0.212), (21, -0.049), (22, -0.086), (23, -0.0), (24, 0.078), (25, 0.028), (26, 0.066), (27, 0.072), (28, -0.012), (29, 0.048), (30, 0.075), (31, 0.019), (32, -0.1), (33, -0.146), (34, 0.02), (35, 0.087), (36, -0.03), (37, 0.011), (38, -0.111), (39, 0.063), (40, -0.127), (41, 0.02), (42, -0.015), (43, -0.007), (44, 0.031), (45, 0.01), (46, -0.048), (47, 0.012), (48, -0.024), (49, 0.035)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98299181 <a title="174-lsi-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-19-End-to-end_NLP_packages.html">174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</a></p>
<p>Introduction: What freely available end-to-end natural language processing (NLP) systems are out there, that start with raw text, and output parses and semantic structures?  Lots of NLP research focuses on single tasks at a time, and thus produces software that does a single task at a time.  But for various applications, it is nicer to have a full end-to-end system that just runs on whatever text you give it.
 
If you believe this is a worthwhile goal (see caveat at bottom), I will postulate there aren’t a ton of such end-to-end, multilevel systems.  Here are ones I can think of.  Corrections and clarifications welcome.
  
  Stanford CoreNLP .  Raw text to  rich syntactic dependencies  ( LFG -inspired).  Also POS, NER, coreference. 
  C&C; tools .  From (sentence-segmented, tokenized?) text to rich syntactic dependencies ( CCG -based) and also a semantic representation.  POS and chunks on the way.  Does anyone use this much?  It seems underappreciated relative to its richness. 
  Senna .  Sentence-se</p><p>2 0.80539489 <a title="174-lsi-2" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>Introduction: I haven’t done a paper review on this blog for a while, so here we go.
 
 Coreference  resolution is an interesting NLP problem.  ( Examples. )  It involves honest-to-goodness syntactic, semantic, and discourse phenomena, but still seems like a real cognitive task that humans have to solve when reading text [1].  I haven’t read the whole literature, but I’ve always been puzzled by the crop of papers on it I’ve seen in the last year or two.  There’s a big focus on fancy graph/probabilistic/constrained optimization algorithms, but often these papers gloss over the linguistic features — the core information they actually make their decisions with [2].  I never understood why the latter isn’t the most important issue.  Therefore, it was a joy to read
  
 Aria Haghighi and Dan Klein, EMNLP-2009.   “Simple Coreference Resolution with Rich Syntactic and Semantic Features.”  
  
They describe a simple, essentially non-statistical system that outperforms previous unsupervised systems, and compa</p><p>3 0.72538114 <a title="174-lsi-3" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-04-14-quick_note%3A_cer_et_al_2010.html">159 brendan oconnor ai-2010-04-14-quick note: cer et al 2010</a></p>
<p>Introduction: Quick note, reading this  paper  from  their tweet .
 
 update  this reaction might be totally wrong; in particular, the conll dependencies for at least some languages were done completely by hand.
   
Malt and MSTParser were designed for the Yamada and Matsumodo dependencies formalism (the one used for the CoNLL dependency parsing shared task, from the   penn2malt   tool).  Their feature sets and probably many other design decisions were created to support that.  If you compare their outputs side-by-side, you will see that the Stanford Dependencies are a substantially different formalism; for example, compound verbs are handled very differently (the paper talks about copula example). 
I think the following conclusion is premature:
  
Notwithstanding the very large amount of research that has gone into dependency 
parsing algorithms in the last ďŹ ve years, our central conclusion is that the quality of the Charniak, Charniak-Johnson reranking, and Berkeley parsers is so high that in th</p><p>4 0.58031815 <a title="174-lsi-4" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-08-Patches_to_Rainbow%2C_the_old_text_classifier_that_won%E2%80%99t_go_away.html">153 brendan oconnor ai-2009-09-08-Patches to Rainbow, the old text classifier that won’t go away</a></p>
<p>Introduction: I’ve been reading several somewhat recent finance papers ( Antweiler and Frank 2005 ,  Das and Chen 2007 ) that use  Rainbow , the text classification software originally written by  Andrew McCallum  back in 1996.  The last version is from 2002 and the homepage announces he isn’t really supporting it any more.
 
However, as far as I can tell, it might still be the easiest-to-use text classifier package out there.  You don’t have to program — just invoke commandline arguments — and it can accommodate reasonably sized datasets, does tokenization, stopword filtering, etc. for you, and has some useful feature selection and other options.  Based on my limited usage, it seems well-implemented.  If anyone knows of a better one I’d love to hear it.  I once looked at, among other things,  GATE  and  UIMA , and they seemed too hard to use if you wanted to download something that did simple text classification; or else, maybe they didn’t have documentation on how to use them in that manner.     R</p><p>5 0.54856038 <a title="174-lsi-5" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>Introduction: There’s a lot to say about  Powerset , the short-lived natural language search company (2005-2008) where I worked after college.  AI overhype, flying too close to the sun, the psychology of tech journalism and venture capitalism, etc.  A year or two ago I wrote the following bit about Powerset’s technology in response to a question  on Quora .  I’m posting a revised version here.
 
 Question:  What was Powerset’s core innovation in search?  As far as I can tell, they licensed an NLP engine. They did not have a question answering system or any system for information extraction. How was Powerset’s search engine different than Google’s?
 
 My answer:  Powerset built a system vaguely like a question-answering system on top of Xerox PARC’s NLP engine.  The output is better described as query-focused summarization rather than question answering; primarily, it matched semantic fragments of the user query against indexed semantic relations, with lots of keyword/ngram-matching fallback for when</p><p>6 0.49070239 <a title="174-lsi-6" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-11-24-Graphs_for_SANCL-2012_web_parsing_results.html">189 brendan oconnor ai-2012-11-24-Graphs for SANCL-2012 web parsing results</a></p>
<p>7 0.47297964 <a title="174-lsi-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-09-I_don%E2%80%99t_get_this_web_parsing_shared_task.html">181 brendan oconnor ai-2012-03-09-I don’t get this web parsing shared task</a></p>
<p>8 0.46111348 <a title="174-lsi-8" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>9 0.43665007 <a title="174-lsi-9" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>10 0.40929842 <a title="174-lsi-10" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>11 0.40924028 <a title="174-lsi-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>12 0.39215705 <a title="174-lsi-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-22-Performance_comparison%3A_key-value_stores_for_language_model_counts.html">139 brendan oconnor ai-2009-04-22-Performance comparison: key-value stores for language model counts</a></p>
<p>13 0.3892276 <a title="174-lsi-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-09-18-%22Machine%22_translation-vision_%28Stanford_AI_courses_online%29.html">113 brendan oconnor ai-2008-09-18-"Machine" translation-vision (Stanford AI courses online)</a></p>
<p>14 0.38302556 <a title="174-lsi-14" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-26-Good_linguistic_semantics_textbook%3F.html">172 brendan oconnor ai-2011-06-26-Good linguistic semantics textbook?</a></p>
<p>15 0.3674247 <a title="174-lsi-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-03-24-Quick-R%2C_the_only_decent_R_documentation_on_the_internet.html">97 brendan oconnor ai-2008-03-24-Quick-R, the only decent R documentation on the internet</a></p>
<p>16 0.34892321 <a title="174-lsi-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-17-Pairwise_comparisons_for_relevance_evaluation.html">106 brendan oconnor ai-2008-06-17-Pairwise comparisons for relevance evaluation</a></p>
<p>17 0.33828178 <a title="174-lsi-17" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-05-29-%22Stanford_Impostor%22.html">62 brendan oconnor ai-2007-05-29-"Stanford Impostor"</a></p>
<p>18 0.31729898 <a title="174-lsi-18" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-01-11-Please_report_your_SVM%E2%80%99s_kernel%21.html">164 brendan oconnor ai-2011-01-11-Please report your SVM’s kernel!</a></p>
<p>19 0.31048873 <a title="174-lsi-19" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>20 0.3058109 <a title="174-lsi-20" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-31-Probabilistic_interpretation_of_the_B3_coreference_resolution_metric.html">199 brendan oconnor ai-2013-08-31-Probabilistic interpretation of the B3 coreference resolution metric</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.029), (24, 0.065), (41, 0.024), (44, 0.143), (48, 0.444), (59, 0.038), (61, 0.026), (70, 0.021), (74, 0.123)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.9754023 <a title="174-lda-1" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-11-14-Pop_cog_neuro_is_so_sigh.html">82 brendan oconnor ai-2007-11-14-Pop cog neuro is so sigh</a></p>
<p>Introduction: A good anti-pop-cognitive-neuroscience rant  on Language Log: 
 In closing, there is a larger issue here, beyond the validity of a specific study of voter psychology. A number of different commercial ventures, from neuromarketing to brain-based lie detection, are banking on the scientific aura of brain imaging to bring them customers, in addition to whatever real information the imaging conveys. The fact that the UCLA study involved brain imaging will garner it more attention, and possibly more credibility among the general public, than if it had used only behavioral measures like questionnaires or people’s facial expressions as they watched the candidates. Because brain imaging is a more high tech approach, it also seems more “scientific” and perhaps even more ‘objective.” Of course, these last two terms do not necessarily apply. Depending on the way the output of UCLA’s multimillion dollar 3-Tesla scanner is interpreted, the result may be objective and scientific, or of no more value</p><p>2 0.96715379 <a title="174-lda-2" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-17-Pairwise_comparisons_for_relevance_evaluation.html">106 brendan oconnor ai-2008-06-17-Pairwise comparisons for relevance evaluation</a></p>
<p>Introduction: Not much on this blog lately, so I’ll repost a comment I just wrote on whether to use pairwise vs. absolute judgments for relevance quality evaluation.  (A fun one I know!)
 
From  this post on the Dolores Labs blog .
 
The paper being talked about is  Here or There: Preference Judgments for Relevance  by Carterette et al.
  
I skimmed through the Carterette paper and it’s interesting. My concern with pairwise setup is, in order to get comparability among query-result pairs, you need to get annotators to do an O(N^2) amount of work. (Unless you do something horribly complicated with partial orders.) The absolute judgment task scales linearly, of course. Given the AMT environment and a fixed budget, if I stay in the smaller-volume task, instead of spending a lot on a quadratic taskload, I can simply get a higher number of workers per result and boil out more noise. Of course, if it’s true the pairwise judgment task is easier — as the paper claims — that might make my spending more effic</p><p>same-blog 3 0.94900596 <a title="174-lda-3" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-19-End-to-end_NLP_packages.html">174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</a></p>
<p>Introduction: What freely available end-to-end natural language processing (NLP) systems are out there, that start with raw text, and output parses and semantic structures?  Lots of NLP research focuses on single tasks at a time, and thus produces software that does a single task at a time.  But for various applications, it is nicer to have a full end-to-end system that just runs on whatever text you give it.
 
If you believe this is a worthwhile goal (see caveat at bottom), I will postulate there aren’t a ton of such end-to-end, multilevel systems.  Here are ones I can think of.  Corrections and clarifications welcome.
  
  Stanford CoreNLP .  Raw text to  rich syntactic dependencies  ( LFG -inspired).  Also POS, NER, coreference. 
  C&C; tools .  From (sentence-segmented, tokenized?) text to rich syntactic dependencies ( CCG -based) and also a semantic representation.  POS and chunks on the way.  Does anyone use this much?  It seems underappreciated relative to its richness. 
  Senna .  Sentence-se</p><p>4 0.93091136 <a title="174-lda-4" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-17-Twitter_graphs_of_the_debate.html">121 brendan oconnor ai-2008-10-17-Twitter graphs of the debate</a></p>
<p>Introduction: Fascinating, from the  Twitter blog :</p><p>5 0.53035277 <a title="174-lda-5" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>Introduction: There’s a lot to say about  Powerset , the short-lived natural language search company (2005-2008) where I worked after college.  AI overhype, flying too close to the sun, the psychology of tech journalism and venture capitalism, etc.  A year or two ago I wrote the following bit about Powerset’s technology in response to a question  on Quora .  I’m posting a revised version here.
 
 Question:  What was Powerset’s core innovation in search?  As far as I can tell, they licensed an NLP engine. They did not have a question answering system or any system for information extraction. How was Powerset’s search engine different than Google’s?
 
 My answer:  Powerset built a system vaguely like a question-answering system on top of Xerox PARC’s NLP engine.  The output is better described as query-focused summarization rather than question answering; primarily, it matched semantic fragments of the user query against indexed semantic relations, with lots of keyword/ngram-matching fallback for when</p><p>6 0.52237779 <a title="174-lda-6" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>7 0.44571632 <a title="174-lda-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>8 0.43183982 <a title="174-lda-8" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-11-24-Graphs_for_SANCL-2012_web_parsing_results.html">189 brendan oconnor ai-2012-11-24-Graphs for SANCL-2012 web parsing results</a></p>
<p>9 0.41738439 <a title="174-lda-9" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>10 0.41192073 <a title="174-lda-10" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>11 0.41019636 <a title="174-lda-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>12 0.4056882 <a title="174-lda-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-02-23-Comparison_of_data_analysis_packages%3A_R%2C_Matlab%2C_SciPy%2C_Excel%2C_SAS%2C_SPSS%2C_Stata.html">135 brendan oconnor ai-2009-02-23-Comparison of data analysis packages: R, Matlab, SciPy, Excel, SAS, SPSS, Stata</a></p>
<p>13 0.40096787 <a title="174-lda-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>14 0.39870661 <a title="174-lda-14" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-11-It_is_accurate_to_determine_a_blog%E2%80%99s_bias_by_what_it_links_to.html">117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</a></p>
<p>15 0.39735433 <a title="174-lda-15" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-09-13-Response_on_our_movie_personas_paper.html">200 brendan oconnor ai-2013-09-13-Response on our movie personas paper</a></p>
<p>16 0.39713788 <a title="174-lda-16" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>17 0.39687771 <a title="174-lda-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-21-Netflix_Prize.html">125 brendan oconnor ai-2008-11-21-Netflix Prize</a></p>
<p>18 0.3796916 <a title="174-lda-18" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-08-Game_outcome_graphs_%E2%80%94_prisoner%E2%80%99s_dilemma_with_FUN_ARROWS%21%21%21.html">68 brendan oconnor ai-2007-07-08-Game outcome graphs — prisoner’s dilemma with FUN ARROWS!!!</a></p>
<p>19 0.37801841 <a title="174-lda-19" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-12-31-List_of_probabilistic_model_mini-language_toolkits.html">157 brendan oconnor ai-2009-12-31-List of probabilistic model mini-language toolkits</a></p>
<p>20 0.3778595 <a title="174-lda-20" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
