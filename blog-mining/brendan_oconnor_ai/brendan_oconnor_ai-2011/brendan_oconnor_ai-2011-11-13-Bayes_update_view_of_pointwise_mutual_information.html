<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>178 brendan oconnor ai-2011-11-13-Bayes update view of pointwise mutual information</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2011" href="../home/brendan_oconnor_ai-2011_home.html">brendan_oconnor_ai-2011</a> <a title="brendan_oconnor_ai-2011-178" href="#">brendan_oconnor_ai-2011-178</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>178 brendan oconnor ai-2011-11-13-Bayes update view of pointwise mutual information</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2011-178-html" href="http://brenocon.com/blog/2011/11/bayes-update-view-of-pointwise-mutual-information/">html</a></p><p>Introduction: This is fun.  Pointwise Mutual Information (e.g.  Church and Hanks 1990 ) between two variable outcomes \(x\) and \(y\) is
 
\[ PMI(x,y) = \log \frac{p(x,y)}{p(x)p(y)} \]
 
It’s called “pointwise” because  Mutual Information , between two (discrete) variables X and Y, is the expectation of PMI over possible outcomes of X and Y: \( MI(X,Y) = \sum_{x,y} p(x,y) PMI(x,y) \).
 
One interpretation of PMI is it’s measuring how much deviation from independence there is — since \(p(x,y)=p(x)p(y)\) if X and Y were independent, so the ratio is how non-independent they (the outcomes) are.
 
You can get another interpretation of this quantity if you switch into conditional probabilities.  Looking just at the ratio, apply the definition of conditional probability:
 
\[ \frac{p(x,y)}{p(x)p(y)} = \frac{p(x|y)}{p(x)} \]
 
Think about doing a Bayes update for your belief about \(x\).  Start with the prior \(p(x)\), then learn \(y\) and you update to the posterior belief \(p(x|y)\).  How much your belief</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 One interpretation of PMI is it’s measuring how much deviation from independence there is — since \(p(x,y)=p(x)p(y)\) if X and Y were independent, so the ratio is how non-independent they (the outcomes) are. [sent-5, score-0.551]
</p><p>2 You can get another interpretation of this quantity if you switch into conditional probabilities. [sent-6, score-0.379]
</p><p>3 Looking just at the ratio, apply the definition of conditional probability:   \[ \frac{p(x,y)}{p(x)p(y)} = \frac{p(x|y)}{p(x)} \]   Think about doing a Bayes update for your belief about \(x\). [sent-7, score-0.573]
</p><p>4 Start with the prior \(p(x)\), then learn \(y\) and you update to the posterior belief \(p(x|y)\). [sent-8, score-0.471]
</p><p>5 How much your belief changes is measured by that ratio; the log-scaled ratio is PMI. [sent-9, score-0.53]
</p><p>6 (Positive PMI = increase belief, negative PMI = decrease belief. [sent-10, score-0.145]
</p><p>7 This is closer to the information gain view of mutual information, when you decompose it into relative and conditional entropies; the current Wikipedia page has some of the derivations back and forth for them. [sent-14, score-0.683]
</p><p>8 And early chapters of the (free)  MacKay 2003 textbook . [sent-16, score-0.052]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pmi', 0.631), ('ratio', 0.275), ('frac', 0.24), ('mutual', 0.206), ('belief', 0.2), ('mi', 0.158), ('conditional', 0.15), ('outcomes', 0.144), ('learn', 0.141), ('information', 0.137), ('pointwise', 0.137), ('association', 0.125), ('interpretation', 0.105), ('definition', 0.096), ('positive', 0.093), ('negative', 0.093), ('wikipedia', 0.09), ('amount', 0.087), ('update', 0.072), ('quantity', 0.069), ('estimation', 0.069), ('divergence', 0.069), ('kl', 0.069), ('measurement', 0.069), ('decompose', 0.069), ('mle', 0.069), ('circumstances', 0.063), ('bayes', 0.063), ('closer', 0.063), ('church', 0.063), ('expectation', 0.063), ('entropies', 0.063), ('variables', 0.058), ('gain', 0.058), ('symmetric', 0.058), ('independence', 0.058), ('pairwise', 0.058), ('posterior', 0.058), ('deviation', 0.058), ('variable', 0.058), ('mackay', 0.055), ('discrete', 0.055), ('switch', 0.055), ('measuring', 0.055), ('measured', 0.055), ('apply', 0.055), ('interestingly', 0.052), ('requires', 0.052), ('increase', 0.052), ('chapters', 0.052)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000002 <a title="178-tfidf-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-13-Bayes_update_view_of_pointwise_mutual_information.html">178 brendan oconnor ai-2011-11-13-Bayes update view of pointwise mutual information</a></p>
<p>Introduction: This is fun.  Pointwise Mutual Information (e.g.  Church and Hanks 1990 ) between two variable outcomes \(x\) and \(y\) is
 
\[ PMI(x,y) = \log \frac{p(x,y)}{p(x)p(y)} \]
 
It’s called “pointwise” because  Mutual Information , between two (discrete) variables X and Y, is the expectation of PMI over possible outcomes of X and Y: \( MI(X,Y) = \sum_{x,y} p(x,y) PMI(x,y) \).
 
One interpretation of PMI is it’s measuring how much deviation from independence there is — since \(p(x,y)=p(x)p(y)\) if X and Y were independent, so the ratio is how non-independent they (the outcomes) are.
 
You can get another interpretation of this quantity if you switch into conditional probabilities.  Looking just at the ratio, apply the definition of conditional probability:
 
\[ \frac{p(x,y)}{p(x)p(y)} = \frac{p(x|y)}{p(x)} \]
 
Think about doing a Bayes update for your belief about \(x\).  Start with the prior \(p(x)\), then learn \(y\) and you update to the posterior belief \(p(x|y)\).  How much your belief</p><p>2 0.12008872 <a title="178-tfidf-2" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-25-Information_theory_stuff.html">175 brendan oconnor ai-2011-09-25-Information theory stuff</a></p>
<p>Introduction: Actually this post is mainly to test the  MathJax  installation I put into WordPress via  this plugin .  But  information theory  is great, why not?
 
The probability of a symbol is \(p\).
 
It takes \(\log \frac{1}{p} = -\log p\) bits to encode one symbol — sometimes called its “surprisal”.  Surprisal is 0 for a 100% probable symbol, and ranges up to \(\infty\) for extremely low probability symbols.  This is because you use a coding scheme that encodes common symbols as very short strings, and less common symbols as longer ones.  (e.g.  Huffman  or  arithmetic  coding.)  We should say logarithms are base-2 so information is measured in bits.\(^*\)
 
If you have a stream of such symbols and a probability distribution \(\vec{p}\) for them, where a symbol \(i\) comes at probability \(p_i\), then the average message size is the expected surprisal:
 
\[ H(\vec{p}) = \sum_i p_i \log \frac{1}{p_i} \]
 
this is the Shannon  entropy  of the probability distribution \( \vec{p} \), which is a me</p><p>3 0.075757369 <a title="178-tfidf-3" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-08-Game_outcome_graphs_%E2%80%94_prisoner%E2%80%99s_dilemma_with_FUN_ARROWS%21%21%21.html">68 brendan oconnor ai-2007-07-08-Game outcome graphs — prisoner’s dilemma with FUN ARROWS!!!</a></p>
<p>Introduction: I think game theory could benefit immensely from better presentation.  Its default presentation is pretty mathematical.  This is good because it treats social interactions in an abstract way, highlighting their essential properties, but is bad because it’s hard to understand, especially at first.
 
However, I think I have a visualization that can sometimes capture the same abstract properties of the mathematics.  Here’s a stab at using it to explain everyone’s favorite game, the prisoner’s dilemma.
 
THE PD: Two players each choose whether to play nice, or be mean — Cooperate or Defect.  Then they simultaneously play their actions, and get payoffs depending on what both played.  If both cooperated, they help each other and do well; if both defect, they do quite poorly.  But if one tries to cooperate and the other defects, then the defector gets a big win, and the cooperator gets a crappy “sucker’s payoff”.
 
The formal PD definition looks like this:
 
   
 
where each of the four pairs</p><p>4 0.07329125 <a title="178-tfidf-4" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-31-Probabilistic_interpretation_of_the_B3_coreference_resolution_metric.html">199 brendan oconnor ai-2013-08-31-Probabilistic interpretation of the B3 coreference resolution metric</a></p>
<p>Introduction: Here is an intuitive justification for the  B3  evaluation metric often used in coreference resolution, based on whether mention pairs are coreferent. If a mention from the document is chosen at random,
  
 B3-Recall is the (expected) proportion of its actual coreferents that the system thinks are coreferent with it. 
 B3-Precision is the (expected) proportion of its system-hypothesized coreferents that are actually coreferent with it. 
  
Does this look correct to people? Details below:  
 
In B3′s basic form, it’s a clustering evaluation metric, to evaluate a gold-standard clustering of mentions against a system-produced clustering of mentions.
 
Let \(G\) mean a gold-standard entity and \(S\) mean a system-predicted entity, where an entity is a set of mentions. \(i\)Â refers to a mention; there are \(n\) mentions in the document. \(G_i\) means the gold entity that contains mention \(i\); and \(S_i\) means the system entity that has \(i\).
 
The B3 precision and recall for a document</p><p>5 0.070168301 <a title="178-tfidf-5" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-04-11-F-scores%2C_Dice%2C_and_Jaccard_set_similarity.html">183 brendan oconnor ai-2012-04-11-F-scores, Dice, and Jaccard set similarity</a></p>
<p>Introduction: The  Dice similarity  is the same as  F1-score ; and they are monotonic in  Jaccard similarity .  I worked this out recently but couldn’t find anything about it online so here’s a writeup.
 
Let \(A\) be the set of found items, and \(B\) the set of wanted items.  \(Prec=|AB|/|A|\), \(Rec=|AB|/|B|\).  Their harmonic mean, the \(F1\)-measure, is the same as the Dice coefficient: 
\begin{align*} 
F1(A,B) 
&= \frac{2}{1/P+ 1/R} 
 = \frac{2}{|A|/|AB| + |B|/|AB|} \\ 
Dice(A,B) 
&= \frac{2|AB|}{ |A| + |B| } \\ 
&= \frac{2 |AB|}{ (|AB| + |A \setminus B|) + (|AB| + |B \setminus A|)} \\ 
&= \frac{|AB|}{|AB| + \frac{1}{2}|A \setminus B| + \frac{1}{2} |B \setminus A|} 
\end{align*}
 
It’s nice to characterize the set comparison into the three mutually exclusive partitions \(AB\), \(A \setminus B\), and \(B \setminus A\).  This illustrates Dice’s close relationship to the Jaccard metric, 
\begin{align*} 
Jacc(A,B) 
&= \frac{|AB|}{|A \cup B|} \\ 
&= \frac{|AB|}{|AB| + |A \setminus B| + |B \setminus</p><p>6 0.068388432 <a title="178-tfidf-6" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-08-01-Bayesian_analysis_of_intelligent_design_%28revised%21%29.html">23 brendan oconnor ai-2005-08-01-Bayesian analysis of intelligent design (revised!)</a></p>
<p>7 0.06528604 <a title="178-tfidf-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-13-Cosine_similarity%2C_Pearson_correlation%2C_and_OLS_coefficients.html">182 brendan oconnor ai-2012-03-13-Cosine similarity, Pearson correlation, and OLS coefficients</a></p>
<p>8 0.064922266 <a title="178-tfidf-8" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-01-07-Perplexity_as_branching_factor%3B_as_Shannon_diversity_index.html">190 brendan oconnor ai-2013-01-07-Perplexity as branching factor; as Shannon diversity index</a></p>
<p>9 0.061489325 <a title="178-tfidf-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>10 0.053267375 <a title="178-tfidf-10" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-01-Modelling_environmentalism_thinking.html">11 brendan oconnor ai-2005-07-01-Modelling environmentalism thinking</a></p>
<p>11 0.048175424 <a title="178-tfidf-11" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-14-R_scan%28%29_for_quick-and-dirty_checks.html">192 brendan oconnor ai-2013-03-14-R scan() for quick-and-dirty checks</a></p>
<p>12 0.045911059 <a title="178-tfidf-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-27-Where_tweets_get_sent_from.html">142 brendan oconnor ai-2009-05-27-Where tweets get sent from</a></p>
<p>13 0.045845844 <a title="178-tfidf-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-17-Pairwise_comparisons_for_relevance_evaluation.html">106 brendan oconnor ai-2008-06-17-Pairwise comparisons for relevance evaluation</a></p>
<p>14 0.04567305 <a title="178-tfidf-14" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-09-a_bayesian_analysis_of_intelligent_design.html">17 brendan oconnor ai-2005-07-09-a bayesian analysis of intelligent design</a></p>
<p>15 0.04439925 <a title="178-tfidf-15" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-10-31-tanh_is_a_rescaled_logistic_sigmoid_function.html">201 brendan oconnor ai-2013-10-31-tanh is a rescaled logistic sigmoid function</a></p>
<p>16 0.043706417 <a title="178-tfidf-16" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-08-09-An_ML-AI_approach_to_P_%21%3D_NP.html">161 brendan oconnor ai-2010-08-09-An ML-AI approach to P != NP</a></p>
<p>17 0.04350742 <a title="178-tfidf-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>18 0.040953353 <a title="178-tfidf-18" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-03-31-How_Facebook_privacy_failed_me.html">158 brendan oconnor ai-2010-03-31-How Facebook privacy failed me</a></p>
<p>19 0.038876407 <a title="178-tfidf-19" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>20 0.038828727 <a title="178-tfidf-20" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-21-Statistics_is_big-N_logic%3F.html">54 brendan oconnor ai-2007-03-21-Statistics is big-N logic?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.135), (1, -0.026), (2, 0.12), (3, -0.021), (4, -0.037), (5, 0.155), (6, 0.048), (7, -0.101), (8, -0.12), (9, 0.059), (10, -0.029), (11, -0.026), (12, 0.003), (13, 0.095), (14, 0.0), (15, 0.004), (16, -0.076), (17, -0.078), (18, -0.011), (19, -0.023), (20, -0.134), (21, 0.01), (22, 0.002), (23, -0.035), (24, -0.131), (25, -0.087), (26, -0.025), (27, -0.04), (28, -0.011), (29, 0.082), (30, 0.009), (31, 0.045), (32, -0.049), (33, -0.068), (34, -0.003), (35, 0.028), (36, 0.04), (37, 0.045), (38, 0.03), (39, -0.034), (40, -0.0), (41, -0.147), (42, -0.036), (43, 0.114), (44, 0.014), (45, 0.02), (46, 0.014), (47, 0.005), (48, -0.037), (49, 0.027)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98623294 <a title="178-lsi-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-13-Bayes_update_view_of_pointwise_mutual_information.html">178 brendan oconnor ai-2011-11-13-Bayes update view of pointwise mutual information</a></p>
<p>Introduction: This is fun.  Pointwise Mutual Information (e.g.  Church and Hanks 1990 ) between two variable outcomes \(x\) and \(y\) is
 
\[ PMI(x,y) = \log \frac{p(x,y)}{p(x)p(y)} \]
 
It’s called “pointwise” because  Mutual Information , between two (discrete) variables X and Y, is the expectation of PMI over possible outcomes of X and Y: \( MI(X,Y) = \sum_{x,y} p(x,y) PMI(x,y) \).
 
One interpretation of PMI is it’s measuring how much deviation from independence there is — since \(p(x,y)=p(x)p(y)\) if X and Y were independent, so the ratio is how non-independent they (the outcomes) are.
 
You can get another interpretation of this quantity if you switch into conditional probabilities.  Looking just at the ratio, apply the definition of conditional probability:
 
\[ \frac{p(x,y)}{p(x)p(y)} = \frac{p(x|y)}{p(x)} \]
 
Think about doing a Bayes update for your belief about \(x\).  Start with the prior \(p(x)\), then learn \(y\) and you update to the posterior belief \(p(x|y)\).  How much your belief</p><p>2 0.78155273 <a title="178-lsi-2" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-04-11-F-scores%2C_Dice%2C_and_Jaccard_set_similarity.html">183 brendan oconnor ai-2012-04-11-F-scores, Dice, and Jaccard set similarity</a></p>
<p>Introduction: The  Dice similarity  is the same as  F1-score ; and they are monotonic in  Jaccard similarity .  I worked this out recently but couldn’t find anything about it online so here’s a writeup.
 
Let \(A\) be the set of found items, and \(B\) the set of wanted items.  \(Prec=|AB|/|A|\), \(Rec=|AB|/|B|\).  Their harmonic mean, the \(F1\)-measure, is the same as the Dice coefficient: 
\begin{align*} 
F1(A,B) 
&= \frac{2}{1/P+ 1/R} 
 = \frac{2}{|A|/|AB| + |B|/|AB|} \\ 
Dice(A,B) 
&= \frac{2|AB|}{ |A| + |B| } \\ 
&= \frac{2 |AB|}{ (|AB| + |A \setminus B|) + (|AB| + |B \setminus A|)} \\ 
&= \frac{|AB|}{|AB| + \frac{1}{2}|A \setminus B| + \frac{1}{2} |B \setminus A|} 
\end{align*}
 
It’s nice to characterize the set comparison into the three mutually exclusive partitions \(AB\), \(A \setminus B\), and \(B \setminus A\).  This illustrates Dice’s close relationship to the Jaccard metric, 
\begin{align*} 
Jacc(A,B) 
&= \frac{|AB|}{|A \cup B|} \\ 
&= \frac{|AB|}{|AB| + |A \setminus B| + |B \setminus</p><p>3 0.72307837 <a title="178-lsi-3" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-25-Information_theory_stuff.html">175 brendan oconnor ai-2011-09-25-Information theory stuff</a></p>
<p>Introduction: Actually this post is mainly to test the  MathJax  installation I put into WordPress via  this plugin .  But  information theory  is great, why not?
 
The probability of a symbol is \(p\).
 
It takes \(\log \frac{1}{p} = -\log p\) bits to encode one symbol — sometimes called its “surprisal”.  Surprisal is 0 for a 100% probable symbol, and ranges up to \(\infty\) for extremely low probability symbols.  This is because you use a coding scheme that encodes common symbols as very short strings, and less common symbols as longer ones.  (e.g.  Huffman  or  arithmetic  coding.)  We should say logarithms are base-2 so information is measured in bits.\(^*\)
 
If you have a stream of such symbols and a probability distribution \(\vec{p}\) for them, where a symbol \(i\) comes at probability \(p_i\), then the average message size is the expected surprisal:
 
\[ H(\vec{p}) = \sum_i p_i \log \frac{1}{p_i} \]
 
this is the Shannon  entropy  of the probability distribution \( \vec{p} \), which is a me</p><p>4 0.59122926 <a title="178-lsi-4" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-13-Cosine_similarity%2C_Pearson_correlation%2C_and_OLS_coefficients.html">182 brendan oconnor ai-2012-03-13-Cosine similarity, Pearson correlation, and OLS coefficients</a></p>
<p>Introduction: Cosine similarity, Pearson correlations, and OLS coefficients can all be viewed as variants on the inner product — tweaked in different ways for centering and magnitude (i.e. location and scale, or something like that).
 
Details:
 
You have two vectors \(x\) and \(y\) and want to measure similarity between them.  A basic similarity function is the   inner product  
 
\[ Inner(x,y) = \sum_i x_i y_i = \langle x, y \rangle \]
 
If x tends to be high where y is also high, and low where y is low, the inner product will be high — the vectors are more similar.
 
The inner product is unbounded.  One way to make it bounded between -1 and 1 is to divide by the vectors’ L2 norms, giving the   cosine similarity  
 
\[ CosSim(x,y) = \frac{\sum_i x_i y_i}{ \sqrt{ \sum_i x_i^2} \sqrt{ \sum_i y_i^2 } } 
= \frac{ \langle x,y \rangle }{ ||x||\ ||y|| } 
\]
 
This is actually bounded between 0 and 1 if x and y are non-negative.  Cosine similarity has an interpretation as the cosine of the angle between t</p><p>5 0.57996625 <a title="178-lsi-5" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-31-Probabilistic_interpretation_of_the_B3_coreference_resolution_metric.html">199 brendan oconnor ai-2013-08-31-Probabilistic interpretation of the B3 coreference resolution metric</a></p>
<p>Introduction: Here is an intuitive justification for the  B3  evaluation metric often used in coreference resolution, based on whether mention pairs are coreferent. If a mention from the document is chosen at random,
  
 B3-Recall is the (expected) proportion of its actual coreferents that the system thinks are coreferent with it. 
 B3-Precision is the (expected) proportion of its system-hypothesized coreferents that are actually coreferent with it. 
  
Does this look correct to people? Details below:  
 
In B3′s basic form, it’s a clustering evaluation metric, to evaluate a gold-standard clustering of mentions against a system-produced clustering of mentions.
 
Let \(G\) mean a gold-standard entity and \(S\) mean a system-predicted entity, where an entity is a set of mentions. \(i\)Â refers to a mention; there are \(n\) mentions in the document. \(G_i\) means the gold entity that contains mention \(i\); and \(S_i\) means the system entity that has \(i\).
 
The B3 precision and recall for a document</p><p>6 0.5428195 <a title="178-lsi-6" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-01-07-Perplexity_as_branching_factor%3B_as_Shannon_diversity_index.html">190 brendan oconnor ai-2013-01-07-Perplexity as branching factor; as Shannon diversity index</a></p>
<p>7 0.4977825 <a title="178-lsi-7" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-04-21-What_inputs_do_Monte_Carlo_algorithms_need%3F.html">195 brendan oconnor ai-2013-04-21-What inputs do Monte Carlo algorithms need?</a></p>
<p>8 0.40064639 <a title="178-lsi-8" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-03-31-How_Facebook_privacy_failed_me.html">158 brendan oconnor ai-2010-03-31-How Facebook privacy failed me</a></p>
<p>9 0.35287052 <a title="178-lsi-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-17-Pairwise_comparisons_for_relevance_evaluation.html">106 brendan oconnor ai-2008-06-17-Pairwise comparisons for relevance evaluation</a></p>
<p>10 0.33633628 <a title="178-lsi-10" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-05-20-Log-normal_and_logistic-normal_terminology.html">169 brendan oconnor ai-2011-05-20-Log-normal and logistic-normal terminology</a></p>
<p>11 0.33320084 <a title="178-lsi-11" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-18-Information_cost_and_genocide.html">130 brendan oconnor ai-2008-12-18-Information cost and genocide</a></p>
<p>12 0.32849607 <a title="178-lsi-12" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-10-31-tanh_is_a_rescaled_logistic_sigmoid_function.html">201 brendan oconnor ai-2013-10-31-tanh is a rescaled logistic sigmoid function</a></p>
<p>13 0.32369947 <a title="178-lsi-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-01-20-Moral_psychology_on_Amazon_Mechanical_Turk.html">90 brendan oconnor ai-2008-01-20-Moral psychology on Amazon Mechanical Turk</a></p>
<p>14 0.30833203 <a title="178-lsi-14" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-07-08-Game_outcome_graphs_%E2%80%94_prisoner%E2%80%99s_dilemma_with_FUN_ARROWS%21%21%21.html">68 brendan oconnor ai-2007-07-08-Game outcome graphs — prisoner’s dilemma with FUN ARROWS!!!</a></p>
<p>15 0.2803047 <a title="178-lsi-15" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-14-R_scan%28%29_for_quick-and-dirty_checks.html">192 brendan oconnor ai-2013-03-14-R scan() for quick-and-dirty checks</a></p>
<p>16 0.27380818 <a title="178-lsi-16" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-10-05-Be_careful_with_dictionary-based_text_analysis.html">176 brendan oconnor ai-2011-10-05-Be careful with dictionary-based text analysis</a></p>
<p>17 0.27043951 <a title="178-lsi-17" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>18 0.25936285 <a title="178-lsi-18" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-07-03-Supreme_Court_justices%E2%80%99_agreement_levels.html">13 brendan oconnor ai-2005-07-03-Supreme Court justices’ agreement levels</a></p>
<p>19 0.25837228 <a title="178-lsi-19" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-02-15-Pascal%E2%80%99s_Wager.html">50 brendan oconnor ai-2007-02-15-Pascal’s Wager</a></p>
<p>20 0.25010788 <a title="178-lsi-20" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(16, 0.031), (24, 0.019), (32, 0.521), (43, 0.012), (44, 0.101), (48, 0.031), (51, 0.013), (72, 0.031), (74, 0.1), (80, 0.026)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.98270077 <a title="178-lda-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-02-19-Move_to_brenocon.com.html">165 brendan oconnor ai-2011-02-19-Move to brenocon.com</a></p>
<p>Introduction: I’ve changed my website and blog URL from  anyall.org  to  brenocon.com .  The former was supposed to be a reference to first-order logic: the existential and universal quantifiers are fundamental to relational reasoning, and as testament to that, they are enshrined as “any()” and “all()” in wise programming languages like Python and R.  Or something like that.  It turns out this was obvious only to me :)
 
I tried to set up everything to automatically redirect, so no links should be broken.  Hopefully.</p><p>same-blog 2 0.96038532 <a title="178-lda-2" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-11-13-Bayes_update_view_of_pointwise_mutual_information.html">178 brendan oconnor ai-2011-11-13-Bayes update view of pointwise mutual information</a></p>
<p>Introduction: This is fun.  Pointwise Mutual Information (e.g.  Church and Hanks 1990 ) between two variable outcomes \(x\) and \(y\) is
 
\[ PMI(x,y) = \log \frac{p(x,y)}{p(x)p(y)} \]
 
It’s called “pointwise” because  Mutual Information , between two (discrete) variables X and Y, is the expectation of PMI over possible outcomes of X and Y: \( MI(X,Y) = \sum_{x,y} p(x,y) PMI(x,y) \).
 
One interpretation of PMI is it’s measuring how much deviation from independence there is — since \(p(x,y)=p(x)p(y)\) if X and Y were independent, so the ratio is how non-independent they (the outcomes) are.
 
You can get another interpretation of this quantity if you switch into conditional probabilities.  Looking just at the ratio, apply the definition of conditional probability:
 
\[ \frac{p(x,y)}{p(x)p(y)} = \frac{p(x|y)}{p(x)} \]
 
Think about doing a Bayes update for your belief about \(x\).  Start with the prior \(p(x)\), then learn \(y\) and you update to the posterior belief \(p(x|y)\).  How much your belief</p><p>3 0.26349658 <a title="178-lda-3" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>Introduction: 10/1/09 update  — well, it’s been nearly a year, and I should say not everything in this rant is totally true, and I certainly believe much less of it now.  Current take:  Statistics , not machine learning, is the real deal, but unfortunately suffers from bad marketing.  On the other hand, to the extent that bad marketing includes misguided undergraduate curriculums, there’s plenty of room to improve for everyone.
   
So it’s pretty clear by now that statistics and machine learning aren’t very different fields. I was recently pointed to   a very amusing comparison   by the excellent statistician — and machine learning expert —   Robert Tibshiriani  .  Reproduced here:  
 
  Glossary 
   
 Machine learning
  Statistics 
   
 network, graphs
  model 
   
 weights
  parameters 
   
 learning
  fitting 
   
 generalization
  test set performance 
   
 supervised learning
  regression/classiﬁcation 
   
 unsupervised learning
  density estimation, clustering 
   
 large grant = $1,000,000</p><p>4 0.24521385 <a title="178-lda-4" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>Introduction: Everyone recently seems to be talking about  this newish paper by Digrazia, McKelvey, Bollen, and Rojas  ( pdf here ) that examines the correlation of Congressional candidate name mentions on Twitter against whether the candidate won the race.  One of the coauthors also wrote a Washington Post  Op-Ed  about it.  I read the paper and I think it’s reasonable, but their op-ed overstates their results.  It claims:
  
“In the 2010 data, our Twitter data predicted the winner in 404 out of 435 competitive races”
  
But this analysis is nowhere in their paper.  Fabio Rojas has now  posted errata/rebuttals  about the op-ed and described this analysis they did here.  There are several major issues off the bat:
  
 They didn’t ever predict 404/435 races; they only analyzed 406 races they call “competitive,” getting 92.5% (in-sample) accuracy, then extrapolated to all races to get the 435 number. 
 They’re reporting about  in-sample  predictions, which is really misleading to a non-scientific audi</p><p>5 0.24333562 <a title="178-lda-5" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>Introduction: I haven’t done a paper review on this blog for a while, so here we go.
 
 Coreference  resolution is an interesting NLP problem.  ( Examples. )  It involves honest-to-goodness syntactic, semantic, and discourse phenomena, but still seems like a real cognitive task that humans have to solve when reading text [1].  I haven’t read the whole literature, but I’ve always been puzzled by the crop of papers on it I’ve seen in the last year or two.  There’s a big focus on fancy graph/probabilistic/constrained optimization algorithms, but often these papers gloss over the linguistic features — the core information they actually make their decisions with [2].  I never understood why the latter isn’t the most important issue.  Therefore, it was a joy to read
  
 Aria Haghighi and Dan Klein, EMNLP-2009.   “Simple Coreference Resolution with Rich Syntactic and Semantic Features.”  
  
They describe a simple, essentially non-statistical system that outperforms previous unsupervised systems, and compa</p><p>6 0.23841733 <a title="178-lda-6" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>7 0.23813592 <a title="178-lda-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>8 0.23728178 <a title="178-lda-8" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-10-02-Powerset%E2%80%99s_natural_language_search_system.html">188 brendan oconnor ai-2012-10-02-Powerset’s natural language search system</a></p>
<p>9 0.23672435 <a title="178-lda-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>10 0.23571795 <a title="178-lda-10" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-25-Information_theory_stuff.html">175 brendan oconnor ai-2011-09-25-Information theory stuff</a></p>
<p>11 0.22859356 <a title="178-lda-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-04-17-1_billion_web_page_dataset_from_CMU.html">138 brendan oconnor ai-2009-04-17-1 billion web page dataset from CMU</a></p>
<p>12 0.22768669 <a title="178-lda-12" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>13 0.2258645 <a title="178-lda-13" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-15-Feminists%2C_anarchists%2C_computational_complexity%2C_bounded_rationality%2C_nethack%2C_and_other_things_to_do.html">53 brendan oconnor ai-2007-03-15-Feminists, anarchists, computational complexity, bounded rationality, nethack, and other things to do</a></p>
<p>14 0.22370389 <a title="178-lda-14" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>15 0.22291327 <a title="178-lda-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-18-Announcing_TweetMotif_for_summarizing_twitter_topics.html">140 brendan oconnor ai-2009-05-18-Announcing TweetMotif for summarizing twitter topics</a></p>
<p>16 0.22241352 <a title="178-lda-16" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>17 0.22006795 <a title="178-lda-17" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-09-19-End-to-end_NLP_packages.html">174 brendan oconnor ai-2011-09-19-End-to-end NLP packages</a></p>
<p>18 0.2200121 <a title="178-lda-18" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-19-What_the_ACL-2014_review_scores_mean.html">203 brendan oconnor ai-2014-02-19-What the ACL-2014 review scores mean</a></p>
<p>19 0.21876414 <a title="178-lda-19" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>20 0.21653645 <a title="178-lda-20" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-20-Data-driven_charity.html">86 brendan oconnor ai-2007-12-20-Data-driven charity</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
