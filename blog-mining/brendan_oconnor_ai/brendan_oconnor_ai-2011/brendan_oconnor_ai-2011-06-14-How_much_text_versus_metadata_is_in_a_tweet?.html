<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>171 brendan oconnor ai-2011-06-14-How much text versus metadata is in a tweet?</title>
</head>

<body>
<p><a title="brendan_oconnor_ai" href="../brendan_oconnor_ai_home.html">brendan_oconnor_ai</a> <a title="brendan_oconnor_ai-2011" href="../home/brendan_oconnor_ai-2011_home.html">brendan_oconnor_ai-2011</a> <a title="brendan_oconnor_ai-2011-171" href="#">brendan_oconnor_ai-2011-171</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>171 brendan oconnor ai-2011-06-14-How much text versus metadata is in a tweet?</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="brendan_oconnor_ai-2011-171-html" href="http://brenocon.com/blog/2011/06/how-much-text-versus-metadata-is-in-a-tweet/">html</a></p><p>Introduction: This should have been a blog post, but I got lazy and wrote a plaintext document instead.
  
  Link  
  
For twitter, context matters: 90% of a tweet is metadata and 10% is text. Â That’s measured by (an approximation of) information content; by raw data size, it’s 95/5.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This should have been a blog post, but I got lazy and wrote a plaintext document instead. [sent-1, score-1.252]
</p><p>2 Link      For twitter, context matters: 90% of a tweet is metadata and 10% is text. [sent-2, score-0.796]
</p><p>3 Â That’s measured by (an approximation of) information content; by raw data size, it’s 95/5. [sent-3, score-1.024]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lazy', 0.31), ('approximation', 0.31), ('metadata', 0.31), ('plaintext', 0.283), ('matters', 0.264), ('raw', 0.264), ('document', 0.264), ('measured', 0.249), ('tweet', 0.249), ('context', 0.237), ('content', 0.237), ('twitter', 0.202), ('size', 0.185), ('got', 0.153), ('link', 0.138), ('post', 0.131), ('information', 0.124), ('blog', 0.122), ('wrote', 0.12), ('data', 0.077)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="171-tfidf-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-14-How_much_text_versus_metadata_is_in_a_tweet%3F.html">171 brendan oconnor ai-2011-06-14-How much text versus metadata is in a tweet?</a></p>
<p>Introduction: This should have been a blog post, but I got lazy and wrote a plaintext document instead.
  
  Link  
  
For twitter, context matters: 90% of a tweet is metadata and 10% is text. Â That’s measured by (an approximation of) information content; by raw data size, it’s 95/5.</p><p>2 0.17085306 <a title="171-tfidf-2" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-17-Twitter_graphs_of_the_debate.html">121 brendan oconnor ai-2008-10-17-Twitter graphs of the debate</a></p>
<p>Introduction: Fascinating, from the  Twitter blog :</p><p>3 0.13210846 <a title="171-tfidf-3" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>Introduction: Everyone recently seems to be talking about  this newish paper by Digrazia, McKelvey, Bollen, and Rojas  ( pdf here ) that examines the correlation of Congressional candidate name mentions on Twitter against whether the candidate won the race.  One of the coauthors also wrote a Washington Post  Op-Ed  about it.  I read the paper and I think it’s reasonable, but their op-ed overstates their results.  It claims:
  
“In the 2010 data, our Twitter data predicted the winner in 404 out of 435 competitive races”
  
But this analysis is nowhere in their paper.  Fabio Rojas has now  posted errata/rebuttals  about the op-ed and described this analysis they did here.  There are several major issues off the bat:
  
 They didn’t ever predict 404/435 races; they only analyzed 406 races they call “competitive,” getting 92.5% (in-sample) accuracy, then extrapolated to all races to get the 435 number. 
 They’re reporting about  in-sample  predictions, which is really misleading to a non-scientific audi</p><p>4 0.11165982 <a title="171-tfidf-4" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-09-21-CMU_ARK_Twitter_Part-of-Speech_Tagger_%E2%80%93_v0.3_released.html">187 brendan oconnor ai-2012-09-21-CMU ARK Twitter Part-of-Speech Tagger – v0.3 released</a></p>
<p>Introduction: We’re pleased to announce a new release of the CMU ARK Twitter Part-of-Speech 
Tagger, version 0.3.
  
 The new version is much faster (40x) and more accurate (89.2 -> 92.8) than 
  before.
  We also have released new POS-annotated data, including a dataset of one 
  tweet for each of 547 days.
  We have made available large-scale word clusters from unlabeled Twitter data 
  (217k words, 56m tweets, 847m tokens).
   
Tools, data, and a new technical report describing the release are available at: 
 www.ark.cs.cmu.edu/TweetNLP .
 
 0100100  a  1111100101110   111100000011 , Brendan</p><p>5 0.077266596 <a title="171-tfidf-5" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-08-27-CMU_Twitter_Part-of-Speech_tagger_0.2.html">173 brendan oconnor ai-2011-08-27-CMU Twitter Part-of-Speech tagger 0.2</a></p>
<p>Introduction: Announcement: We recently released a new version (0.2) of our  part-of-speech tagger for English Twitter messages , along with annotations and interface.  See the link for more details.</p><p>6 0.074236214 <a title="171-tfidf-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-01-Bias_correction_sneak_peek%21.html">108 brendan oconnor ai-2008-07-01-Bias correction sneak peek!</a></p>
<p>7 0.073860817 <a title="171-tfidf-7" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-18-Turker_classifiers_and_binary_classification_threshold_calibration.html">107 brendan oconnor ai-2008-06-18-Turker classifiers and binary classification threshold calibration</a></p>
<p>8 0.052571315 <a title="171-tfidf-8" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-05-08-Movie_summary_corpus_and_learning_character_personas.html">196 brendan oconnor ai-2013-05-08-Movie summary corpus and learning character personas</a></p>
<p>9 0.048892442 <a title="171-tfidf-9" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-31-Probabilistic_interpretation_of_the_B3_coreference_resolution_metric.html">199 brendan oconnor ai-2013-08-31-Probabilistic interpretation of the B3 coreference resolution metric</a></p>
<p>10 0.046129934 <a title="171-tfidf-10" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-05-16-Online_Deliberation_2005_conference_blog_%26_more_is_up%21.html">4 brendan oconnor ai-2005-05-16-Online Deliberation 2005 conference blog & more is up!</a></p>
<p>11 0.04576166 <a title="171-tfidf-11" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-01-23-SF_conference_for_data_mining_mercenaries.html">133 brendan oconnor ai-2009-01-23-SF conference for data mining mercenaries</a></p>
<p>12 0.041421235 <a title="171-tfidf-12" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-27-Where_tweets_get_sent_from.html">142 brendan oconnor ai-2009-05-27-Where tweets get sent from</a></p>
<p>13 0.041400757 <a title="171-tfidf-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>14 0.040334582 <a title="171-tfidf-14" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-01-02-Interactive_visualization_of_Mixture_of_Gaussians%2C_the_Law_of_Total_Expectation_and_the_Law_of_Total_Variance.html">163 brendan oconnor ai-2011-01-02-Interactive visualization of Mixture of Gaussians, the Law of Total Expectation and the Law of Total Variance</a></p>
<p>15 0.039056592 <a title="171-tfidf-15" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-27-Seth_Roberts_and_academic_blogging.html">55 brendan oconnor ai-2007-03-27-Seth Roberts and academic blogging</a></p>
<p>16 0.038876418 <a title="171-tfidf-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-03-06-data_data_data.html">93 brendan oconnor ai-2008-03-06-data data data</a></p>
<p>17 0.038637303 <a title="171-tfidf-17" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-01-07-Perplexity_as_branching_factor%3B_as_Shannon_diversity_index.html">190 brendan oconnor ai-2013-01-07-Perplexity as branching factor; as Shannon diversity index</a></p>
<p>18 0.038608301 <a title="171-tfidf-18" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-12-The_Universal_Declaration_of_Human_Rights_Animated.html">118 brendan oconnor ai-2008-10-12-The Universal Declaration of Human Rights Animated</a></p>
<p>19 0.036124986 <a title="171-tfidf-19" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-07-23-R_questions_on_StackOverflow.html">148 brendan oconnor ai-2009-07-23-R questions on StackOverflow</a></p>
<p>20 0.036113769 <a title="171-tfidf-20" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/brendan_oconnor_ai_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, -0.101), (1, -0.141), (2, -0.057), (3, 0.269), (4, -0.033), (5, 0.018), (6, -0.129), (7, -0.04), (8, -0.053), (9, 0.099), (10, -0.008), (11, 0.061), (12, -0.035), (13, 0.068), (14, -0.091), (15, -0.071), (16, -0.062), (17, -0.051), (18, 0.084), (19, 0.033), (20, -0.093), (21, -0.047), (22, -0.028), (23, 0.043), (24, 0.021), (25, 0.025), (26, -0.045), (27, 0.042), (28, -0.135), (29, 0.008), (30, -0.054), (31, -0.023), (32, -0.062), (33, -0.015), (34, -0.057), (35, 0.039), (36, 0.043), (37, -0.008), (38, 0.043), (39, 0.012), (40, 0.024), (41, -0.103), (42, -0.003), (43, -0.099), (44, 0.084), (45, -0.1), (46, -0.051), (47, -0.025), (48, 0.051), (49, -0.097)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98816991 <a title="171-lsi-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-14-How_much_text_versus_metadata_is_in_a_tweet%3F.html">171 brendan oconnor ai-2011-06-14-How much text versus metadata is in a tweet?</a></p>
<p>Introduction: This should have been a blog post, but I got lazy and wrote a plaintext document instead.
  
  Link  
  
For twitter, context matters: 90% of a tweet is metadata and 10% is text. Â That’s measured by (an approximation of) information content; by raw data size, it’s 95/5.</p><p>2 0.7725274 <a title="171-lsi-2" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-17-Twitter_graphs_of_the_debate.html">121 brendan oconnor ai-2008-10-17-Twitter graphs of the debate</a></p>
<p>Introduction: Fascinating, from the  Twitter blog :</p><p>3 0.56147188 <a title="171-lsi-3" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>Introduction: Everyone recently seems to be talking about  this newish paper by Digrazia, McKelvey, Bollen, and Rojas  ( pdf here ) that examines the correlation of Congressional candidate name mentions on Twitter against whether the candidate won the race.  One of the coauthors also wrote a Washington Post  Op-Ed  about it.  I read the paper and I think it’s reasonable, but their op-ed overstates their results.  It claims:
  
“In the 2010 data, our Twitter data predicted the winner in 404 out of 435 competitive races”
  
But this analysis is nowhere in their paper.  Fabio Rojas has now  posted errata/rebuttals  about the op-ed and described this analysis they did here.  There are several major issues off the bat:
  
 They didn’t ever predict 404/435 races; they only analyzed 406 races they call “competitive,” getting 92.5% (in-sample) accuracy, then extrapolated to all races to get the 435 number. 
 They’re reporting about  in-sample  predictions, which is really misleading to a non-scientific audi</p><p>4 0.51551729 <a title="171-lsi-4" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-08-27-CMU_Twitter_Part-of-Speech_tagger_0.2.html">173 brendan oconnor ai-2011-08-27-CMU Twitter Part-of-Speech tagger 0.2</a></p>
<p>Introduction: Announcement: We recently released a new version (0.2) of our  part-of-speech tagger for English Twitter messages , along with annotations and interface.  See the link for more details.</p><p>5 0.47492561 <a title="171-lsi-5" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-09-21-CMU_ARK_Twitter_Part-of-Speech_Tagger_%E2%80%93_v0.3_released.html">187 brendan oconnor ai-2012-09-21-CMU ARK Twitter Part-of-Speech Tagger – v0.3 released</a></p>
<p>Introduction: We’re pleased to announce a new release of the CMU ARK Twitter Part-of-Speech 
Tagger, version 0.3.
  
 The new version is much faster (40x) and more accurate (89.2 -> 92.8) than 
  before.
  We also have released new POS-annotated data, including a dataset of one 
  tweet for each of 547 days.
  We have made available large-scale word clusters from unlabeled Twitter data 
  (217k words, 56m tweets, 847m tokens).
   
Tools, data, and a new technical report describing the release are available at: 
 www.ark.cs.cmu.edu/TweetNLP .
 
 0100100  a  1111100101110   111100000011 , Brendan</p><p>6 0.3764976 <a title="171-lsi-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-18-Turker_classifiers_and_binary_classification_threshold_calibration.html">107 brendan oconnor ai-2008-06-18-Turker classifiers and binary classification threshold calibration</a></p>
<p>7 0.33816382 <a title="171-lsi-7" href="../brendan_oconnor_ai-2005/brendan_oconnor_ai-2005-05-16-Online_Deliberation_2005_conference_blog_%26_more_is_up%21.html">4 brendan oconnor ai-2005-05-16-Online Deliberation 2005 conference blog & more is up!</a></p>
<p>8 0.32707128 <a title="171-lsi-8" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-03-27-Seth_Roberts_and_academic_blogging.html">55 brendan oconnor ai-2007-03-27-Seth Roberts and academic blogging</a></p>
<p>9 0.31593829 <a title="171-lsi-9" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-06-17-Pairwise_comparisons_for_relevance_evaluation.html">106 brendan oconnor ai-2008-06-17-Pairwise comparisons for relevance evaluation</a></p>
<p>10 0.30056834 <a title="171-lsi-10" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-01-Bias_correction_sneak_peek%21.html">108 brendan oconnor ai-2008-07-01-Bias correction sneak peek!</a></p>
<p>11 0.29114634 <a title="171-lsi-11" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-09-I_don%E2%80%99t_get_this_web_parsing_shared_task.html">181 brendan oconnor ai-2012-03-09-I don’t get this web parsing shared task</a></p>
<p>12 0.27760544 <a title="171-lsi-12" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-11-It_is_accurate_to_determine_a_blog%E2%80%99s_bias_by_what_it_links_to.html">117 brendan oconnor ai-2008-10-11-It is accurate to determine a blog’s bias by what it links to</a></p>
<p>13 0.25370803 <a title="171-lsi-13" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-07-04-Link%3A_Today%E2%80%99s_international_organizations.html">109 brendan oconnor ai-2008-07-04-Link: Today’s international organizations</a></p>
<p>14 0.25367558 <a title="171-lsi-14" href="../brendan_oconnor_ai-2014/brendan_oconnor_ai-2014-02-18-Scatterplot_of_KN-PYP_language_model_results.html">202 brendan oconnor ai-2014-02-18-Scatterplot of KN-PYP language model results</a></p>
<p>15 0.24107519 <a title="171-lsi-15" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-11-12-Disease_tracking_with_web_queries_and_social_messaging_%28Google%2C_Twitter%2C_Facebook%E2%80%A6%29.html">123 brendan oconnor ai-2008-11-12-Disease tracking with web queries and social messaging (Google, Twitter, Facebook…)</a></p>
<p>16 0.23402718 <a title="171-lsi-16" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-03-20-Spending_money_on_others_makes_you_happy.html">96 brendan oconnor ai-2008-03-20-Spending money on others makes you happy</a></p>
<p>17 0.22253287 <a title="171-lsi-17" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-12-The_Universal_Declaration_of_Human_Rights_Animated.html">118 brendan oconnor ai-2008-10-12-The Universal Declaration of Human Rights Animated</a></p>
<p>18 0.21756627 <a title="171-lsi-18" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-05-27-Where_tweets_get_sent_from.html">142 brendan oconnor ai-2009-05-27-Where tweets get sent from</a></p>
<p>19 0.21370837 <a title="171-lsi-19" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-12-09-Race_and_IQ_debate_%E2%80%93_links.html">85 brendan oconnor ai-2007-12-09-Race and IQ debate – links</a></p>
<p>20 0.20648554 <a title="171-lsi-20" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-03-18-Correlation_picture.html">193 brendan oconnor ai-2013-03-18-Correlation picture</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/brendan_oconnor_ai_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(44, 0.174), (74, 0.081), (86, 0.559)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97656798 <a title="171-lda-1" href="../brendan_oconnor_ai-2011/brendan_oconnor_ai-2011-06-14-How_much_text_versus_metadata_is_in_a_tweet%3F.html">171 brendan oconnor ai-2011-06-14-How much text versus metadata is in a tweet?</a></p>
<p>Introduction: This should have been a blog post, but I got lazy and wrote a plaintext document instead.
  
  Link  
  
For twitter, context matters: 90% of a tweet is metadata and 10% is text. Â That’s measured by (an approximation of) information content; by raw data size, it’s 95/5.</p><p>2 0.97488552 <a title="171-lda-2" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-13-Cosine_similarity%2C_Pearson_correlation%2C_and_OLS_coefficients.html">182 brendan oconnor ai-2012-03-13-Cosine similarity, Pearson correlation, and OLS coefficients</a></p>
<p>Introduction: Cosine similarity, Pearson correlations, and OLS coefficients can all be viewed as variants on the inner product — tweaked in different ways for centering and magnitude (i.e. location and scale, or something like that).
 
Details:
 
You have two vectors \(x\) and \(y\) and want to measure similarity between them.  A basic similarity function is the   inner product  
 
\[ Inner(x,y) = \sum_i x_i y_i = \langle x, y \rangle \]
 
If x tends to be high where y is also high, and low where y is low, the inner product will be high — the vectors are more similar.
 
The inner product is unbounded.  One way to make it bounded between -1 and 1 is to divide by the vectors’ L2 norms, giving the   cosine similarity  
 
\[ CosSim(x,y) = \frac{\sum_i x_i y_i}{ \sqrt{ \sum_i x_i^2} \sqrt{ \sum_i y_i^2 } } 
= \frac{ \langle x,y \rangle }{ ||x||\ ||y|| } 
\]
 
This is actually bounded between 0 and 1 if x and y are non-negative.  Cosine similarity has an interpretation as the cosine of the angle between t</p><p>3 0.86992323 <a title="171-lda-3" href="../brendan_oconnor_ai-2010/brendan_oconnor_ai-2010-04-22-Updates%3A_CMU%2C_Facebook.html">160 brendan oconnor ai-2010-04-22-Updates: CMU, Facebook</a></p>
<p>Introduction: It’s been a good year.  Last fall I started a master’s program in the Language Technologies department at  CMU SCS , taking some great classes, hanging out with a  cool lab , and writing two new papers (for  ICWSM , involving Twitter:  polls  and  tweetmotif ; also did some  coref  work, financial text regression stuff, and looked at  social lexicography .)  I also applied to CS and stats PhD programs at several universities.  Next year I’ll be starting the PhD program in the  Machine Learning Department  here at CMU.
 
I’m excited!  Just the other day I was looking at videos on my old hard drive and found a presentation by  Tom Mitchell  on “the Discipline of Machine Learning” that I downloaded back in 2007 or so.  (Can’t find it online right now, but  this is similar .)  That might be where I heard of the department first.  Maybe some day I will be smarter than the guy who wrote  this rant  (though I am much more pro-stats and anti-ML these days…).
 
Also, I was recently named a fina</p><p>4 0.33138698 <a title="171-lda-4" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-08-21-ConnectU.com_SQL_injection_vulnerability%3A_a_story_of_pathetic_hubris_%28and_fun_with_the_password_%E2%80%98password%E2%80%99%29.html">76 brendan oconnor ai-2007-08-21-ConnectU.com SQL injection vulnerability: a story of pathetic hubris (and fun with the password ‘password’)</a></p>
<p>Introduction: This is off-topic for this blog but here goes.   ConnectU , a small college social networking site, has been in the news due to their  apparently weak lawsuit against Facebook , in which they claim  Mark Zuckerberg  stole their business plan and computer code back when they all were Harvard undergraduates.  (Judges involved have noted the case’s flimsy evidence; some technology commentators — as well as everyone I know — have noted that the business idea wasn’t all that brilliant or original in the first place.)  Zuckerberg, of course, went on to found Facebook and bring it to incredible success.
 
I tried to use the ConnectU site recently, but got an error when searching for a funny name with an apostrophe,  o’connor .  It turns out this was symptomatic of a very grave security flaw in their code, an  SQL injection vulnerability .  While Facebook recently had  a minor security-related glitch , ConnectU’s flaw is far more serious.  A malicious attacker could use this to easily break in</p><p>5 0.32272893 <a title="171-lda-5" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-08-20-Some_analysis_of_tweet_shares_and_%E2%80%9Cpredicting%E2%80%9D_election_outcomes.html">198 brendan oconnor ai-2013-08-20-Some analysis of tweet shares and “predicting” election outcomes</a></p>
<p>Introduction: Everyone recently seems to be talking about  this newish paper by Digrazia, McKelvey, Bollen, and Rojas  ( pdf here ) that examines the correlation of Congressional candidate name mentions on Twitter against whether the candidate won the race.  One of the coauthors also wrote a Washington Post  Op-Ed  about it.  I read the paper and I think it’s reasonable, but their op-ed overstates their results.  It claims:
  
“In the 2010 data, our Twitter data predicted the winner in 404 out of 435 competitive races”
  
But this analysis is nowhere in their paper.  Fabio Rojas has now  posted errata/rebuttals  about the op-ed and described this analysis they did here.  There are several major issues off the bat:
  
 They didn’t ever predict 404/435 races; they only analyzed 406 races they call “competitive,” getting 92.5% (in-sample) accuracy, then extrapolated to all races to get the 435 number. 
 They’re reporting about  in-sample  predictions, which is really misleading to a non-scientific audi</p><p>6 0.32152352 <a title="171-lda-6" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-27-Facebook_sentiment_mining_predicts_presidential_polls.html">131 brendan oconnor ai-2008-12-27-Facebook sentiment mining predicts presidential polls</a></p>
<p>7 0.30351809 <a title="171-lda-7" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-03-09-I_don%E2%80%99t_get_this_web_parsing_shared_task.html">181 brendan oconnor ai-2012-03-09-I don’t get this web parsing shared task</a></p>
<p>8 0.29927483 <a title="171-lda-8" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-10-08-Blog_move_has_landed.html">115 brendan oconnor ai-2008-10-08-Blog move has landed</a></p>
<p>9 0.29473907 <a title="171-lda-9" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-03-18-Mark_Turner%3A_Toward_the_Founding_of_Cognitive_Social_Science.html">31 brendan oconnor ai-2006-03-18-Mark Turner: Toward the Founding of Cognitive Social Science</a></p>
<p>10 0.29473907 <a title="171-lda-10" href="../brendan_oconnor_ai-2007/brendan_oconnor_ai-2007-10-13-Verificationism_dinosaur_comics.html">79 brendan oconnor ai-2007-10-13-Verificationism dinosaur comics</a></p>
<p>11 0.26852283 <a title="171-lda-11" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-04-The_%2460%2C000_cat%3A_deep_belief_networks_make_less_sense_for_language_than_vision.html">184 brendan oconnor ai-2012-07-04-The $60,000 cat: deep belief networks make less sense for language than vision</a></p>
<p>12 0.26785505 <a title="171-lda-12" href="../brendan_oconnor_ai-2008/brendan_oconnor_ai-2008-12-03-Statistics_vs._Machine_Learning%2C_fight%21.html">129 brendan oconnor ai-2008-12-03-Statistics vs. Machine Learning, fight!</a></p>
<p>13 0.26498175 <a title="171-lda-13" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-08-08-Haghighi_and_Klein_%282009%29%3A_Simple_Coreference_Resolution_with_Rich_Syntactic_and_Semantic_Features.html">150 brendan oconnor ai-2009-08-08-Haghighi and Klein (2009): Simple Coreference Resolution with Rich Syntactic and Semantic Features</a></p>
<p>14 0.26133886 <a title="171-lda-14" href="../brendan_oconnor_ai-2004/brendan_oconnor_ai-2004-11-24-addiction_%26_2_problems_of_economics.html">2 brendan oconnor ai-2004-11-24-addiction & 2 problems of economics</a></p>
<p>15 0.25529075 <a title="171-lda-15" href="../brendan_oconnor_ai-2009/brendan_oconnor_ai-2009-09-10-Don%E2%80%99t_MAWK_AWK_%E2%80%93_the_fastest_and_most_elegant_big_data_munging_language%21.html">154 brendan oconnor ai-2009-09-10-Don’t MAWK AWK – the fastest and most elegant big data munging language!</a></p>
<p>16 0.2494927 <a title="171-lda-16" href="../brendan_oconnor_ai-2006/brendan_oconnor_ai-2006-03-26-new_kind_of_science%2C_for_real.html">32 brendan oconnor ai-2006-03-26-new kind of science, for real</a></p>
<p>17 0.24775696 <a title="171-lda-17" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-09-21-CMU_ARK_Twitter_Part-of-Speech_Tagger_%E2%80%93_v0.3_released.html">187 brendan oconnor ai-2012-09-21-CMU ARK Twitter Part-of-Speech Tagger – v0.3 released</a></p>
<p>18 0.24311993 <a title="171-lda-18" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-02-02-Histograms_%E2%80%94_matplotlib_vs._R.html">179 brendan oconnor ai-2012-02-02-Histograms — matplotlib vs. R</a></p>
<p>19 0.23706752 <a title="171-lda-19" href="../brendan_oconnor_ai-2012/brendan_oconnor_ai-2012-07-17-p-values%2C_CDF%E2%80%99s%2C_NLP_etc..html">185 brendan oconnor ai-2012-07-17-p-values, CDF’s, NLP etc.</a></p>
<p>20 0.23613001 <a title="171-lda-20" href="../brendan_oconnor_ai-2013/brendan_oconnor_ai-2013-01-07-Perplexity_as_branching_factor%3B_as_Shannon_diversity_index.html">190 brendan oconnor ai-2013-01-07-Perplexity as branching factor; as Shannon diversity index</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
