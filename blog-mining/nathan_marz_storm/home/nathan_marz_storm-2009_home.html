<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>nathan_marz_storm 2009 knowledge graph</title>
</head>

<body>
<p><a title="nathan_marz_storm" href="../nathan_marz_storm_home.html">nathan_marz_storm</a> <a title="nathan_marz_storm-2009" href="#">nathan_marz_storm-2009</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>nathan_marz_storm 2009 knowledge graph</h1>
<br/><h3>similar blogs computed by tfidf model</h3><br/><h3>similar blogs computed by <a title="lsi-model" href="./nathan_marz_storm_lsi.html">lsi model</a></h3><br/><h3>similar blogs computed by <a title="lda-model" href="./nathan_marz_storm_lda.html">lda model</a></h3><br/><h2>blogs list:</h2><p>1 <a title="nathan_marz_storm-2009-1" href="../nathan_marz_storm-2009/nathan_marz_storm-2009-12-28-The_mathematics_behind_Hadoop-based_systems.html">nathan marz storm-2009-12-28-The mathematics behind Hadoop-based systems</a></p>
<p>Introduction: I wish I had known this a year ago. Now, with some simple mathematics I can finally answer:
  
 Why doesn't the speed of my workflow double when I double the amount of processing power? 
 Why does a 10% failure rate cause my runtime to go up by 300%? 
 How does optimizing out 30% of my workflow runtime cause the runtime to decrease by 80%? 
 How many machines should I have in my cluster to be adequately performant and fault-tolerant? 
  
All of these questions are neatly answered by one simple equation:
 
Runtime = Overhead / (1 - {Time to process one hour of data})
 
We will derive this equation in a moment. First, let's briefly discuss what I mean by "Hadoop-based system."  1   A common use-case of Hadoop is running a workflow that processes a continuous stream of incoming data. The workflow runs in a "while(true)" loop, and each iteration of the workflow processes the data that accumulated since last iteration.
 
The inspiration for the following analysis can be summarized in a simp</p><br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
