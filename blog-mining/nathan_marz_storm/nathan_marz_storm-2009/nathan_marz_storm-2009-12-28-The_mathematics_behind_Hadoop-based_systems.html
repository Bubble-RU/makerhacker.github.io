<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1 nathan marz storm-2009-12-28-The mathematics behind Hadoop-based systems</title>
</head>

<body>
<p><a title="nathan_marz_storm" href="../nathan_marz_storm_home.html">nathan_marz_storm</a> <a title="nathan_marz_storm-2009" href="../home/nathan_marz_storm-2009_home.html">nathan_marz_storm-2009</a> <a title="nathan_marz_storm-2009-1" href="#">nathan_marz_storm-2009-1</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1 nathan marz storm-2009-12-28-The mathematics behind Hadoop-based systems</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="nathan_marz_storm-2009-1-html" href="http://nathanmarz.com//blog/the-mathematics-behind-hadoop-based-systems.html">html</a></p><p>Introduction: I wish I had known this a year ago. Now, with some simple mathematics I can
finally answer:Why doesn't the speed of my workflow double when I double the
amount of processing power?Why does a 10% failure rate cause my runtime to go
up by 300%?How does optimizing out 30% of my workflow runtime cause the
runtime to decrease by 80%?How many machines should I have in my cluster to be
adequately performant and fault-tolerant?All of these questions are neatly
answered by one simple equation:Runtime = Overhead / (1 - {Time to process one
hour of data})We will derive this equation in a moment. First, let's briefly
discuss what I mean by "Hadoop-based system."1A common use-case of Hadoop is
running a workflow that processes a continuous stream of incoming data. The
workflow runs in a "while(true)" loop, and each iteration of the workflow
processes the data that accumulated since last iteration.The inspiration for
the following analysis can be summarized in a simple example. Let's say you
have a</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('runtime', 0.671), ('workflow', 0.392), ('overhead', 0.183), ('hour', 0.172), ('cluster', 0.142), ('doubling', 0.125), ('tasks', 0.123), ('machines', 0.122), ('data', 0.122), ('equation', 0.11), ('hours', 0.105), ('decrease', 0.102), ('processing', 0.095), ('rate', 0.091), ('failure', 0.088), ('size', 0.088), ('iteration', 0.085), ('double', 0.081), ('failures', 0.081), ('processes', 0.081)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1-tfidf-1" href="../nathan_marz_storm-2009/nathan_marz_storm-2009-12-28-The_mathematics_behind_Hadoop-based_systems.html">1 nathan marz storm-2009-12-28-The mathematics behind Hadoop-based systems</a></p>
<p>Introduction: I wish I had known this a year ago. Now, with some simple mathematics I can
finally answer:Why doesn't the speed of my workflow double when I double the
amount of processing power?Why does a 10% failure rate cause my runtime to go
up by 300%?How does optimizing out 30% of my workflow runtime cause the
runtime to decrease by 80%?How many machines should I have in my cluster to be
adequately performant and fault-tolerant?All of these questions are neatly
answered by one simple equation:Runtime = Overhead / (1 - {Time to process one
hour of data})We will derive this equation in a moment. First, let's briefly
discuss what I mean by "Hadoop-based system."1A common use-case of Hadoop is
running a workflow that processes a continuous stream of incoming data. The
workflow runs in a "while(true)" loop, and each iteration of the workflow
processes the data that accumulated since last iteration.The inspiration for
the following analysis can be summarized in a simple example. Let's say you
have a</p><p>2 0.61693031 <a title="1-tfidf-2" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-08-Follow-up_to_%22The_mathematics_behind_Hadoop-based_systems%22.html">8 nathan marz storm-2010-03-08-Follow-up to "The mathematics behind Hadoop-based systems"</a></p>
<p>Introduction: In aprevious post, I developed an equation modeling the stable runtime of an
iterative, batch-oriented workflow. We saw how the equation explained a number
of counter-intuitive behaviors of batch-oriented systems. In this post, we
will learn how to measure the amount of overhead versus dynamic time in a
workflow, which is the first step in applying the theory to optimize a
workflow.Recall that we started with the equation for the runtime of a single
iteration of a workflow:Runtime = Overhead + {Time to process one hour of
data} * {Hours of Data}T = O + P * HWe ended with the equation for the stable
runtime of a workflow that runs repeatedly:{Stable Runtime} = Overhead / (1 -
{Time to process one hour of data}T = O / (1 - P)Measuring O and PThe first
step towards utilizing this theory for optimizing your workflow will be to
measure the values of O and P for your workflow. This can be difficult if the
cluster is shared with lots of other jobs, as the P for each run will vary.
Let's start</p><p>3 0.098905072 <a title="1-tfidf-3" href="../nathan_marz_storm-2011/nathan_marz_storm-2011-10-13-How_to_beat_the_CAP_theorem.html">31 nathan marz storm-2011-10-13-How to beat the CAP theorem</a></p>
<p>Introduction: The CAP theorem states a database cannot guarantee consistency, availability,
and partition-tolerance at the same time. But you can't sacrifice partition-
tolerance (seehereandhere), so you must make a tradeoff between availability
and consistency. Managing this tradeoff is a central focus of the NoSQL
movement.Consistency means that after you do a successful write, future reads
will always take that write into account. Availability means that you can
always read and write to the system. During a partition, you can only have one
of these properties.Systems that choose consistency over availability have to
deal with some awkward issues. What do you do when the database isn't
available? You can try buffering writes for later, but you risk losing those
writes if you lose the machine with the buffer. Also, buffering writes can be
a form of inconsistency because a client thinks a write has succeeded but the
write isn't in the database yet. Alternatively, you can return errors back to
the cl</p><p>4 0.070376314 <a title="1-tfidf-4" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-07-12-My_experience_as_the_first_employee_of_a_Y_Combinator_startup.html">19 nathan marz storm-2010-07-12-My experience as the first employee of a Y Combinator startup</a></p>
<p>Introduction: I'm the first employee ofBackType, a Summer '08 YC company. My joining the
company increased the company size by 50%. The experience has been awesome,
but I will say up front that being the first employee of a startup is not for
everyone.The best part of being the first employee of a startup is the total
exposure to all parts of the company. I've learned a ton about product
development, customer development, recruiting, and entrepreneurship.
Additionally, I've met and connected with lots of other awesome people through
the YC network. I've gotten all these benefits at relatively low risk for
myself, as I still have a salary and a solid chunk of equity.No RulesThere are
a lot of rules working at most companies. You don't even realize that some of
the rulesarerules until you work at a company with no rules. I'm talking about
the most basic things like what hours you work, what days of the week you
work, what tools you use, and whether you come into the office or not.Because
there are no</p><p>5 0.060158972 <a title="1-tfidf-5" href="../nathan_marz_storm-2013/nathan_marz_storm-2013-04-02-Principles_of_Software_Engineering%2C_Part_1.html">37 nathan marz storm-2013-04-02-Principles of Software Engineering, Part 1</a></p>
<p>Introduction: This is the first in a series of posts on the principles of software
engineering. There's far more to software engineering than just "making
computers do stuff" – while that phrase is accurate, it does not come close to
describing what's involved in making robust, reliable software. I will use my
experience building large scale systems to inform a first principles approach
to defining what it is we do – or should be doing – as software engineers. I'm
not interested in tired debates like dynamic vs. static languages – instead, I
intend to explore the really core aspects of software engineering.The first
order of business is to define what software engineering even is in the first
place. Software engineering is the construction of software that produces some
desired output for some range of inputs. The inputs to software are more than
just method parameters: they include the hardware on which it's running, the
rate at which it receives data, and anything else that influences the
operatio</p><p>6 0.054661017 <a title="1-tfidf-6" href="../nathan_marz_storm-2014/nathan_marz_storm-2014-02-12-Interview_with_%22Programmer_Magazine%22.html">39 nathan marz storm-2014-02-12-Interview with "Programmer Magazine"</a></p>
<p>7 0.050343044 <a title="1-tfidf-7" href="../nathan_marz_storm-2012/nathan_marz_storm-2012-02-06-Suffering-oriented_programming.html">33 nathan marz storm-2012-02-06-Suffering-oriented programming</a></p>
<p>8 0.045480113 <a title="1-tfidf-8" href="../nathan_marz_storm-2011/nathan_marz_storm-2011-01-07-Analysis_of_the_%23LessAmbitiousMovies_Twitter_Meme.html">27 nathan marz storm-2011-01-07-Analysis of the #LessAmbitiousMovies Twitter Meme</a></p>
<p>9 0.039740596 <a title="1-tfidf-9" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-10-Thrift_%2B_Graphs_%3D_Strong%2C_flexible_schemas_on_Hadoop.html">9 nathan marz storm-2010-03-10-Thrift + Graphs = Strong, flexible schemas on Hadoop</a></p>
<p>10 0.037710574 <a title="1-tfidf-10" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-01-03-Tips_for_Optimizing_Cascading_Flows.html">2 nathan marz storm-2010-01-03-Tips for Optimizing Cascading Flows</a></p>
<p>11 0.037577432 <a title="1-tfidf-11" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-05-08-News_Feed_in_38_lines_of_code_using_Cascalog.html">16 nathan marz storm-2010-05-08-News Feed in 38 lines of code using Cascalog</a></p>
<p>12 0.035541352 <a title="1-tfidf-12" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-10-27-Fastest_Viable_Product%3A_Investing_in_Speed_at_a_Startup.html">23 nathan marz storm-2010-10-27-Fastest Viable Product: Investing in Speed at a Startup</a></p>
<p>13 0.034768272 <a title="1-tfidf-13" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-04-14-Introducing_Cascalog%3A_a_Clojure-based_query_language_for_Hadoop.html">13 nathan marz storm-2010-04-14-Introducing Cascalog: a Clojure-based query language for Hadoop</a></p>
<p>14 0.033790745 <a title="1-tfidf-14" href="../nathan_marz_storm-2013/nathan_marz_storm-2013-04-12-Break_into_Silicon_Valley_with_a_blog.html">38 nathan marz storm-2013-04-12-Break into Silicon Valley with a blog</a></p>
<p>15 0.031599011 <a title="1-tfidf-15" href="../nathan_marz_storm-2014/nathan_marz_storm-2014-02-24-The_inexplicable_rise_of_open_floor_plans_in_tech_companies.html">40 nathan marz storm-2014-02-24-The inexplicable rise of open floor plans in tech companies</a></p>
<p>16 0.028690713 <a title="1-tfidf-16" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-01-26-My_conversation_with_the_great_John_McCarthy.html">4 nathan marz storm-2010-01-26-My conversation with the great John McCarthy</a></p>
<p>17 0.027820073 <a title="1-tfidf-17" href="../nathan_marz_storm-2012/nathan_marz_storm-2012-09-19-Storm%27s_1st_birthday.html">34 nathan marz storm-2012-09-19-Storm's 1st birthday</a></p>
<p>18 0.026913418 <a title="1-tfidf-18" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-04-27-New_Cascalog_features%3A_outer_joins%2C_combiners%2C_sorting%2C_and_more.html">14 nathan marz storm-2010-04-27-New Cascalog features: outer joins, combiners, sorting, and more</a></p>
<p>19 0.024288958 <a title="1-tfidf-19" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-10-05-How_to_get_a_job_at_a_kick-ass_startup_%28for_programmers%29.html">22 nathan marz storm-2010-10-05-How to get a job at a kick-ass startup (for programmers)</a></p>
<p>20 0.023091076 <a title="1-tfidf-20" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-17-Proof_that_1_%3D_0_using_a_common_logical_fallacy.html">10 nathan marz storm-2010-03-17-Proof that 1 = 0 using a common logical fallacy</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/nathan_marz_storm_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.25), (1, -0.064), (2, 0.847), (3, -0.087), (4, 0.011), (5, -0.067), (6, 0.058), (7, -0.054), (8, 0.036), (9, 0.005), (10, -0.009), (11, -0.017), (12, -0.017), (13, -0.008), (14, 0.025), (15, 0.027), (16, 0.015), (17, 0.002), (18, 0.024), (19, -0.023), (20, -0.009), (21, -0.007), (22, -0.009), (23, -0.006), (24, -0.0), (25, 0.009), (26, 0.005), (27, 0.019), (28, -0.001), (29, -0.004), (30, -0.011), (31, -0.002), (32, -0.008), (33, 0.014), (34, 0.023), (35, -0.01), (36, 0.023), (37, -0.003), (38, 0.02), (39, -0.436), (40, 0.019)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9871611 <a title="1-lsi-1" href="../nathan_marz_storm-2009/nathan_marz_storm-2009-12-28-The_mathematics_behind_Hadoop-based_systems.html">1 nathan marz storm-2009-12-28-The mathematics behind Hadoop-based systems</a></p>
<p>Introduction: I wish I had known this a year ago. Now, with some simple mathematics I can
finally answer:Why doesn't the speed of my workflow double when I double the
amount of processing power?Why does a 10% failure rate cause my runtime to go
up by 300%?How does optimizing out 30% of my workflow runtime cause the
runtime to decrease by 80%?How many machines should I have in my cluster to be
adequately performant and fault-tolerant?All of these questions are neatly
answered by one simple equation:Runtime = Overhead / (1 - {Time to process one
hour of data})We will derive this equation in a moment. First, let's briefly
discuss what I mean by "Hadoop-based system."1A common use-case of Hadoop is
running a workflow that processes a continuous stream of incoming data. The
workflow runs in a "while(true)" loop, and each iteration of the workflow
processes the data that accumulated since last iteration.The inspiration for
the following analysis can be summarized in a simple example. Let's say you
have a</p><p>2 0.6122877 <a title="1-lsi-2" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-08-Follow-up_to_%22The_mathematics_behind_Hadoop-based_systems%22.html">8 nathan marz storm-2010-03-08-Follow-up to "The mathematics behind Hadoop-based systems"</a></p>
<p>Introduction: In aprevious post, I developed an equation modeling the stable runtime of an
iterative, batch-oriented workflow. We saw how the equation explained a number
of counter-intuitive behaviors of batch-oriented systems. In this post, we
will learn how to measure the amount of overhead versus dynamic time in a
workflow, which is the first step in applying the theory to optimize a
workflow.Recall that we started with the equation for the runtime of a single
iteration of a workflow:Runtime = Overhead + {Time to process one hour of
data} * {Hours of Data}T = O + P * HWe ended with the equation for the stable
runtime of a workflow that runs repeatedly:{Stable Runtime} = Overhead / (1 -
{Time to process one hour of data}T = O / (1 - P)Measuring O and PThe first
step towards utilizing this theory for optimizing your workflow will be to
measure the values of O and P for your workflow. This can be difficult if the
cluster is shared with lots of other jobs, as the P for each run will vary.
Let's start</p><p>3 0.19209899 <a title="1-lsi-3" href="../nathan_marz_storm-2011/nathan_marz_storm-2011-10-13-How_to_beat_the_CAP_theorem.html">31 nathan marz storm-2011-10-13-How to beat the CAP theorem</a></p>
<p>Introduction: The CAP theorem states a database cannot guarantee consistency, availability,
and partition-tolerance at the same time. But you can't sacrifice partition-
tolerance (seehereandhere), so you must make a tradeoff between availability
and consistency. Managing this tradeoff is a central focus of the NoSQL
movement.Consistency means that after you do a successful write, future reads
will always take that write into account. Availability means that you can
always read and write to the system. During a partition, you can only have one
of these properties.Systems that choose consistency over availability have to
deal with some awkward issues. What do you do when the database isn't
available? You can try buffering writes for later, but you risk losing those
writes if you lose the machine with the buffer. Also, buffering writes can be
a form of inconsistency because a client thinks a write has succeeded but the
write isn't in the database yet. Alternatively, you can return errors back to
the cl</p><p>4 0.10791018 <a title="1-lsi-4" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-07-12-My_experience_as_the_first_employee_of_a_Y_Combinator_startup.html">19 nathan marz storm-2010-07-12-My experience as the first employee of a Y Combinator startup</a></p>
<p>Introduction: I'm the first employee ofBackType, a Summer '08 YC company. My joining the
company increased the company size by 50%. The experience has been awesome,
but I will say up front that being the first employee of a startup is not for
everyone.The best part of being the first employee of a startup is the total
exposure to all parts of the company. I've learned a ton about product
development, customer development, recruiting, and entrepreneurship.
Additionally, I've met and connected with lots of other awesome people through
the YC network. I've gotten all these benefits at relatively low risk for
myself, as I still have a salary and a solid chunk of equity.No RulesThere are
a lot of rules working at most companies. You don't even realize that some of
the rulesarerules until you work at a company with no rules. I'm talking about
the most basic things like what hours you work, what days of the week you
work, what tools you use, and whether you come into the office or not.Because
there are no</p><p>5 0.10652664 <a title="1-lsi-5" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-10-Thrift_%2B_Graphs_%3D_Strong%2C_flexible_schemas_on_Hadoop.html">9 nathan marz storm-2010-03-10-Thrift + Graphs = Strong, flexible schemas on Hadoop</a></p>
<p>Introduction: There are a lot of misconceptions about what Hadoop is useful for and what
kind of data you can put in it. A lot of people think that Hadoop is meant for
unstructured data like log files. While Hadoop is great for log files, it's
alsofantasticfor strongly typed, structured data.In this post I'll discuss how
you can use a tool likeThriftto store strongly typed data in Hadoop while
retaining the flexibility to evolve your schema. We'll look at graph-based
schemas and see why they are an ideal fit for many Hadoop-based
applications.OK, so what kind of "structured" data can you put in
Hadoop?Anything! AtBackTypewe put data about news, conversations, and people
into Hadoop as structured objects. You can easily push structured information
about social graphs, financial information, or anything you want into Hadoop.
That sounds all well and good, but why not just use JSON as the data
format?JSON doesn't give you a real schema and doesn't protect against data
inconsistency. For example, if you</p><p>6 0.095782287 <a title="1-lsi-6" href="../nathan_marz_storm-2011/nathan_marz_storm-2011-01-07-Analysis_of_the_%23LessAmbitiousMovies_Twitter_Meme.html">27 nathan marz storm-2011-01-07-Analysis of the #LessAmbitiousMovies Twitter Meme</a></p>
<p>7 0.088976644 <a title="1-lsi-7" href="../nathan_marz_storm-2014/nathan_marz_storm-2014-02-12-Interview_with_%22Programmer_Magazine%22.html">39 nathan marz storm-2014-02-12-Interview with "Programmer Magazine"</a></p>
<p>8 0.086007975 <a title="1-lsi-8" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-05-08-News_Feed_in_38_lines_of_code_using_Cascalog.html">16 nathan marz storm-2010-05-08-News Feed in 38 lines of code using Cascalog</a></p>
<p>9 0.083489954 <a title="1-lsi-9" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-01-03-Tips_for_Optimizing_Cascading_Flows.html">2 nathan marz storm-2010-01-03-Tips for Optimizing Cascading Flows</a></p>
<p>10 0.083483018 <a title="1-lsi-10" href="../nathan_marz_storm-2013/nathan_marz_storm-2013-04-02-Principles_of_Software_Engineering%2C_Part_1.html">37 nathan marz storm-2013-04-02-Principles of Software Engineering, Part 1</a></p>
<p>11 0.071469322 <a title="1-lsi-11" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-10-27-Fastest_Viable_Product%3A_Investing_in_Speed_at_a_Startup.html">23 nathan marz storm-2010-10-27-Fastest Viable Product: Investing in Speed at a Startup</a></p>
<p>12 0.070387878 <a title="1-lsi-12" href="../nathan_marz_storm-2012/nathan_marz_storm-2012-01-09-Early_access_edition_of_my_book_is_available.html">32 nathan marz storm-2012-01-09-Early access edition of my book is available</a></p>
<p>13 0.069565475 <a title="1-lsi-13" href="../nathan_marz_storm-2012/nathan_marz_storm-2012-02-06-Suffering-oriented_programming.html">33 nathan marz storm-2012-02-06-Suffering-oriented programming</a></p>
<p>14 0.056038994 <a title="1-lsi-14" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-04-14-Introducing_Cascalog%3A_a_Clojure-based_query_language_for_Hadoop.html">13 nathan marz storm-2010-04-14-Introducing Cascalog: a Clojure-based query language for Hadoop</a></p>
<p>15 0.054187901 <a title="1-lsi-15" href="../nathan_marz_storm-2011/nathan_marz_storm-2011-03-29-My_talks_at_POSSCON.html">30 nathan marz storm-2011-03-29-My talks at POSSCON</a></p>
<p>16 0.053058337 <a title="1-lsi-16" href="../nathan_marz_storm-2014/nathan_marz_storm-2014-02-24-The_inexplicable_rise_of_open_floor_plans_in_tech_companies.html">40 nathan marz storm-2014-02-24-The inexplicable rise of open floor plans in tech companies</a></p>
<p>17 0.052698463 <a title="1-lsi-17" href="../nathan_marz_storm-2013/nathan_marz_storm-2013-04-12-Break_into_Silicon_Valley_with_a_blog.html">38 nathan marz storm-2013-04-12-Break into Silicon Valley with a blog</a></p>
<p>18 0.050599419 <a title="1-lsi-18" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-01-13-Mimi_Silbert%3A_the_greatest_hacker_in_the_world.html">3 nathan marz storm-2010-01-13-Mimi Silbert: the greatest hacker in the world</a></p>
<p>19 0.047299106 <a title="1-lsi-19" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-17-Proof_that_1_%3D_0_using_a_common_logical_fallacy.html">10 nathan marz storm-2010-03-17-Proof that 1 = 0 using a common logical fallacy</a></p>
<p>20 0.045451391 <a title="1-lsi-20" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-23-Migrating_data_from_a_SQL_database_to_Hadoop.html">11 nathan marz storm-2010-03-23-Migrating data from a SQL database to Hadoop</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/nathan_marz_storm_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.014), (5, 0.024), (10, 0.043), (28, 0.537), (33, 0.012), (41, 0.034), (48, 0.018), (59, 0.076), (68, 0.056), (78, 0.011), (82, 0.014), (88, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95019996 <a title="1-lda-1" href="../nathan_marz_storm-2009/nathan_marz_storm-2009-12-28-The_mathematics_behind_Hadoop-based_systems.html">1 nathan marz storm-2009-12-28-The mathematics behind Hadoop-based systems</a></p>
<p>Introduction: I wish I had known this a year ago. Now, with some simple mathematics I can
finally answer:Why doesn't the speed of my workflow double when I double the
amount of processing power?Why does a 10% failure rate cause my runtime to go
up by 300%?How does optimizing out 30% of my workflow runtime cause the
runtime to decrease by 80%?How many machines should I have in my cluster to be
adequately performant and fault-tolerant?All of these questions are neatly
answered by one simple equation:Runtime = Overhead / (1 - {Time to process one
hour of data})We will derive this equation in a moment. First, let's briefly
discuss what I mean by "Hadoop-based system."1A common use-case of Hadoop is
running a workflow that processes a continuous stream of incoming data. The
workflow runs in a "while(true)" loop, and each iteration of the workflow
processes the data that accumulated since last iteration.The inspiration for
the following analysis can be summarized in a simple example. Let's say you
have a</p><p>2 0.72914273 <a title="1-lda-2" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-08-Follow-up_to_%22The_mathematics_behind_Hadoop-based_systems%22.html">8 nathan marz storm-2010-03-08-Follow-up to "The mathematics behind Hadoop-based systems"</a></p>
<p>Introduction: In aprevious post, I developed an equation modeling the stable runtime of an
iterative, batch-oriented workflow. We saw how the equation explained a number
of counter-intuitive behaviors of batch-oriented systems. In this post, we
will learn how to measure the amount of overhead versus dynamic time in a
workflow, which is the first step in applying the theory to optimize a
workflow.Recall that we started with the equation for the runtime of a single
iteration of a workflow:Runtime = Overhead + {Time to process one hour of
data} * {Hours of Data}T = O + P * HWe ended with the equation for the stable
runtime of a workflow that runs repeatedly:{Stable Runtime} = Overhead / (1 -
{Time to process one hour of data}T = O / (1 - P)Measuring O and PThe first
step towards utilizing this theory for optimizing your workflow will be to
measure the values of O and P for your workflow. This can be difficult if the
cluster is shared with lots of other jobs, as the P for each run will vary.
Let's start</p><p>3 0.16456485 <a title="1-lda-3" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-07-12-My_experience_as_the_first_employee_of_a_Y_Combinator_startup.html">19 nathan marz storm-2010-07-12-My experience as the first employee of a Y Combinator startup</a></p>
<p>Introduction: I'm the first employee ofBackType, a Summer '08 YC company. My joining the
company increased the company size by 50%. The experience has been awesome,
but I will say up front that being the first employee of a startup is not for
everyone.The best part of being the first employee of a startup is the total
exposure to all parts of the company. I've learned a ton about product
development, customer development, recruiting, and entrepreneurship.
Additionally, I've met and connected with lots of other awesome people through
the YC network. I've gotten all these benefits at relatively low risk for
myself, as I still have a salary and a solid chunk of equity.No RulesThere are
a lot of rules working at most companies. You don't even realize that some of
the rulesarerules until you work at a company with no rules. I'm talking about
the most basic things like what hours you work, what days of the week you
work, what tools you use, and whether you come into the office or not.Because
there are no</p><p>4 0.1463014 <a title="1-lda-4" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-04-10-Fun_with_equality_in_Clojure.html">12 nathan marz storm-2010-04-10-Fun with equality in Clojure</a></p>
<p>Introduction: I ran into some very non-intuitive behavior from Clojure recently. See if you
can guess what "foo" is in the following examples:Example 1:user=> foo1user=>
(= foo 1)trueuser=> (= [foo 2] [1 2])trueuser=> (= {foo 2} {1 2})falseExample
2:user=> foofalseuser=> (= foo false)trueuser=> (when foo (println "shouldn't
print?"))shouldn't print?nilYikes, huh? Here are the answers:Example 1: (def
foo (Long. "1"))Example 2: (def foo (Boolean. false))For example 1, the map
equality breaks down because Long and Integer have different hashcodes for the
same numeric value. In example 2, Clojure considers anything besides false or
nil to be true in a conditional, so that means a false Boolean object will be
true in a conditional even though it's equal to "false".I would definitely
consider #1 a bug, as part of the contract of equality is that two equal
objects have the same hashcode. #2 is more debatable, but it seems more
intuitive that the Boolean object false be considered false in conditionals as
w</p><p>5 0.14499606 <a title="1-lda-5" href="../nathan_marz_storm-2012/nathan_marz_storm-2012-02-06-Suffering-oriented_programming.html">33 nathan marz storm-2012-02-06-Suffering-oriented programming</a></p>
<p>Introduction: Someone asked me an interesting question the other day: "How did you justify
taking such a huge risk on buildingStormwhile working on astartup?" (Storm is
a realtime computation system). I can see how from an outsider's perspective
investing in such a massive project seems extremely risky for a startup. From
my perspective, though, building Storm wasn't risky at all. It was
challenging, but not risky.I follow a style of development that greatly
reduces the risk of big projects like Storm. I call this style "suffering-
oriented programming." Suffering-oriented programming can be summarized like
so: don't build technology unless you feel the pain of not having it. It
applies to the big, architectural decisions as well as the smaller everyday
programming decisions. Suffering-oriented programming greatly reduces risk by
ensuring that you're always working on something important, and it ensures
that you are well-versed in a problem space before attempting a large
investment.I have a mantra</p><p>6 0.14074548 <a title="1-lda-6" href="../nathan_marz_storm-2011/nathan_marz_storm-2011-10-13-How_to_beat_the_CAP_theorem.html">31 nathan marz storm-2011-10-13-How to beat the CAP theorem</a></p>
<p>7 0.12710923 <a title="1-lda-7" href="../nathan_marz_storm-2014/nathan_marz_storm-2014-02-12-Interview_with_%22Programmer_Magazine%22.html">39 nathan marz storm-2014-02-12-Interview with "Programmer Magazine"</a></p>
<p>8 0.11763605 <a title="1-lda-8" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-10-Thrift_%2B_Graphs_%3D_Strong%2C_flexible_schemas_on_Hadoop.html">9 nathan marz storm-2010-03-10-Thrift + Graphs = Strong, flexible schemas on Hadoop</a></p>
<p>9 0.10336707 <a title="1-lda-9" href="../nathan_marz_storm-2013/nathan_marz_storm-2013-04-02-Principles_of_Software_Engineering%2C_Part_1.html">37 nathan marz storm-2013-04-02-Principles of Software Engineering, Part 1</a></p>
<p>10 0.097107589 <a title="1-lda-10" href="../nathan_marz_storm-2012/nathan_marz_storm-2012-09-19-Storm%27s_1st_birthday.html">34 nathan marz storm-2012-09-19-Storm's 1st birthday</a></p>
<p>11 0.094555996 <a title="1-lda-11" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-06-16-Your_company_has_a_knowledge_debt_problem.html">18 nathan marz storm-2010-06-16-Your company has a knowledge debt problem</a></p>
<p>12 0.092174992 <a title="1-lda-12" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-04-14-Introducing_Cascalog%3A_a_Clojure-based_query_language_for_Hadoop.html">13 nathan marz storm-2010-04-14-Introducing Cascalog: a Clojure-based query language for Hadoop</a></p>
<p>13 0.089900099 <a title="1-lda-13" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-10-27-Fastest_Viable_Product%3A_Investing_in_Speed_at_a_Startup.html">23 nathan marz storm-2010-10-27-Fastest Viable Product: Investing in Speed at a Startup</a></p>
<p>14 0.089699954 <a title="1-lda-14" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-10-05-How_to_get_a_job_at_a_kick-ass_startup_%28for_programmers%29.html">22 nathan marz storm-2010-10-05-How to get a job at a kick-ass startup (for programmers)</a></p>
<p>15 0.089694053 <a title="1-lda-15" href="../nathan_marz_storm-2014/nathan_marz_storm-2014-02-24-The_inexplicable_rise_of_open_floor_plans_in_tech_companies.html">40 nathan marz storm-2014-02-24-The inexplicable rise of open floor plans in tech companies</a></p>
<p>16 0.088835649 <a title="1-lda-16" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-03-04-Introducing_%22Nanny%22_-_a_really_simple_dependency_management_tool.html">7 nathan marz storm-2010-03-04-Introducing "Nanny" - a really simple dependency management tool</a></p>
<p>17 0.088161312 <a title="1-lda-17" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-01-03-Tips_for_Optimizing_Cascading_Flows.html">2 nathan marz storm-2010-01-03-Tips for Optimizing Cascading Flows</a></p>
<p>18 0.088013552 <a title="1-lda-18" href="../nathan_marz_storm-2011/nathan_marz_storm-2011-01-11-Cascalog_workshop.html">28 nathan marz storm-2011-01-11-Cascalog workshop</a></p>
<p>19 0.087008111 <a title="1-lda-19" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-05-08-News_Feed_in_38_lines_of_code_using_Cascalog.html">16 nathan marz storm-2010-05-08-News Feed in 38 lines of code using Cascalog</a></p>
<p>20 0.086693957 <a title="1-lda-20" href="../nathan_marz_storm-2010/nathan_marz_storm-2010-12-06-You_Are_a_Product.html">25 nathan marz storm-2010-12-06-You Are a Product</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
