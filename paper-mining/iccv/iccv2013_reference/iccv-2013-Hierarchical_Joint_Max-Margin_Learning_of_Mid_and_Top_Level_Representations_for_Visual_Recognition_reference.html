<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-197" href="../iccv2013/iccv-2013-Hierarchical_Joint_Max-Margin_Learning_of_Mid_and_Top_Level_Representations_for_Visual_Recognition.html">iccv2013-197</a> <a title="iccv-2013-197-reference" href="#">iccv2013-197-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>197 iccv-2013-Hierarchical Joint Max-Margin Learning of Mid and Top Level Representations for Visual Recognition</h1>
<br/><p>Source: <a title="iccv-2013-197-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Lobel_Hierarchical_Joint_Max-Margin_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Hans Lobel, René Vidal, Alvaro Soto</p><p>Abstract: Currently, Bag-of-Visual-Words (BoVW) and part-based methods are the most popular approaches for visual recognition. In both cases, a mid-level representation is built on top of low-level image descriptors and top-level classifiers use this mid-level representation to achieve visual recognition. While in current part-based approaches, mid- and top-level representations are usually jointly trained, this is not the usual case for BoVW schemes. A main reason for this is the complex data association problem related to the usual large dictionary size needed by BoVW approaches. As a further observation, typical solutions based on BoVW and part-based representations are usually limited to extensions of binary classification schemes, a strategy that ignores relevant correlations among classes. In this work we propose a novel hierarchical approach to visual recognition based on a BoVW scheme that jointly learns suitable midand top-level representations. Furthermore, using a maxmargin learning framework, the proposed approach directly handles the multiclass case at both levels of abstraction. We test our proposed method using several popular bench- mark datasets. As our main result, we demonstrate that, by coupling learning of mid- and top-level representations, the proposed approach fosters sharing of discriminative visual words among target classes, being able to achieve state-ofthe-art recognition performance using far less visual words than previous approaches.</p><br/>
<h2>reference text</h2><p>[1] H. Bay, T. Tuytelaars, and L. V. Gool. Surf: Speeded up robust features. In ECCV, 2006. 3</p>
<p>[2] I. Biederman. Recognition-by-components: A theory of human image understanding. Psychological Review, 94: 115– 147, 1987. 2</p>
<p>[3] L. Bourdev, S. Maji, T. Brox, and J. Malik. Detecting people using mutually consistent poselet activations. In European Conference on Computer Vision (ECCV), 2010. 1 11770022  the other two sets we use 300 words.</p>
<p>[4] Y. Boureau, F. Bach, Y. LeCun, and J. Ponce. Learning midlevel features for recognition. In CVPR, 2010. 1, 2</p>
<p>[5] G. Csurka, C. R. Dance, L. Fan, J. Willamowski, and</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]  C. Bray. Visual categorization with bags of keypoints. In In Workshop on Statistical Learning in Computer Vision, ECCV, 2004. 1 N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2005 (CVPR 2005)., volume 1, pages 886–893, 2005. 1 P. Felzenszwalb and D. Huttenlocher. Pictorial structures for object recognition. International Journal of Computer Vision, 61(1):55–79, 2005. 1 P. Felzenszwalb, D. Mcallester, and D. Ramanan. A discriminatively trained, multiscale, deformable part model. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2008. 1, 2 G. E. Hinton and S. Osindero. A fast learning algorithm for deep belief nets. Neural Computation, 18:2006, 2006. 2 A. Jain, L. Zappella, P. McClure, and R. Vidal. Visual dictionary learning for joint object categorization and segmentation. In ECCV, 2012. 3 Y. Jia, C. Huang, and T. Darrell. Beyond spatial pyramids: Receptive field learning for pooled image features. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3370–3377, 2012. 6 F. Jurie and B. Triggs. Creating efficient codebooks for visual recognition. In ICCV, 2005. 1 A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012. 2 S. Lazebnik and M. Raginsky. Supervised learning of quantizer codebooks by information loss minimization. PAMI, 31(7):1294–1309, 2009. 1</p>
<p>[15] S. Lazebnik, C. Schmid, and J. Ponce. Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2169–2178, 2006. 1, 7</p>
<p>[16] E. P. X. Li-Jia Li, Hao Su and L. Fei-Fei. Object bank: A high-level image representation for scene classification & semantic feature sparsification. In Neural Information Processing Systems (NIPS), Vancouver, Canada, December 2010. 7</p>
<p>[17] X.-C. Lian, Z. Li, B.-L. Lu, and L. Zhang. Max-margin dictionary learning for multiclass image categorization. In European Conference on Computer Vision (ECCV), ECCV’ 10, pages 157–170, 2010. 7</p>
<p>[18] D. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2):91–1 10, 2004. 3</p>
<p>[19] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Supervised dictionary learning. In Advances in Neural Information Processing Systems 21, pages 1033–1040. 2008. 1</p>
<p>[20] F. Moosmann, B. Triggs, and F. Jurie. Fast discriminative visual codebooks using randomized clustering forests. In Neural Information Processing Systems (NIPS), 2007. 1</p>
<p>[21] S. Parizi, J. Oberlin, and P. Felzenszwalb. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2775–2782, 2012. 7</p>
<p>[22] A. Shabou and H. Le-Borgne. Locality-constrained and spatially regularized coding for scene categorization. In CVPR, 2012. 7</p>
<p>[23] S. Singh, A. Gupta, and A. Efros. Unsupervised discovery of mid-level discriminative patches. In ECCV, 2012. 7</p>
<p>[24] J. Sivic and A. Zisserman. Video google: A text retrieval</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]</p>
<p>[29]  approach to object matching in videos. In ICCV, 2003. 1, 2 P. Tseng. Convergence of a block coordinate descent method for nondifferentiable minimization. Journal of Optimization Theory and Applications, 109(3):475–494, June 2001. 5 I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Support vector machine learning for interdependent and structured output spaces. In ICML, 2004. 4 P. Viola and M. Jones. Robust real-time face detection. International Journal of Computer Vision, 57(2):137–154, 2004. 1 J. Wang, J. Yang, K. Yu, F. Lv, T. Huang, and Y. Gong. Locality-constrained linear coding for image classification. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010. 7 Y. Wang and G. Mori. Hidden part models for human action recognition: Probabilistic versus max margin. PAMI, 33(7): 1310–1323, 2011. 2 11770033</p>
<p>[30] J. Winn, A. Criminisi, and T. Minka. Object categorization by learned universal visual dictionary. In ICCV, pages 1800– 1807, 2005. 1 [3 1] J. Yang, K. Yu, Y. Gong, and T. Huang. Linear spatial pyramid matching using sparse coding for image classification. In CVPR, 2009. 1, 2, 3, 7</p>
<p>[32] C. J. Yu and T. Joachims. Learning structural svms with latent variables. In Proceedings of the 26th Annual International Conference on Machine Learning (ICML), 2009. 4</p>
<p>[33] A. L. Yuille and A. Rangarajan. The concave-convex procedure. Neural Computation, 15(4):915–936, Apr. 2003. 4 11770044</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
