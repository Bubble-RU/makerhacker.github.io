<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>109 iccv-2013-Detecting Avocados to Zucchinis: What Have We Done, and Where Are We Going?</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-109" href="../iccv2013/iccv-2013-Detecting_Avocados_to_Zucchinis%3A_What_Have_We_Done%2C_and_Where_Are_We_Going%3F.html">iccv2013-109</a> <a title="iccv-2013-109-reference" href="#">iccv2013-109-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>109 iccv-2013-Detecting Avocados to Zucchinis: What Have We Done, and Where Are We Going?</h1>
<br/><p>Source: <a title="iccv-2013-109-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Russakovsky_Detecting_Avocados_to_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Olga Russakovsky, Jia Deng, Zhiheng Huang, Alexander C. Berg, Li Fei-Fei</p><p>Abstract: The growth of detection datasets and the multiple directions of object detection research provide both an unprecedented need and a great opportunity for a thorough evaluation of the current state of the field of categorical object detection. In this paper we strive to answer two key questions. First, where are we currently as a field: what have we done right, what still needs to be improved? Second, where should we be going in designing the next generation of object detectors? Inspired by the recent work of Hoiem et al. [10] on the standard PASCAL VOC detection dataset, we perform a large-scale study on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) data. First, we quantitatively demonstrate that this dataset provides many of the same detection challenges as the PASCAL VOC. Due to its scale of 1000 object categories, ILSVRC also provides an excellent testbed for understanding the performance of detectors as a function of several key properties of the object classes. We conduct a series of analyses looking at how different detection methods perform on a number of imagelevel and object-class-levelproperties such as texture, color, deformation, and clutter. We learn important lessons of the current object detection methods and propose a number of insights for designing the next generation object detectors.</p><br/>
<h2>reference text</h2><p>[1] B. Alexe, T. Deselares, and V. Ferrari. Measuring the objectness of image windows. In PAMI, 2012. 4, 5, 8</p>
<p>[2] R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, 2012. 4</p>
<p>[3] J. Deng, A. Berg, S. Satheesh, H. Su, A. Khosla, and L. Fei-Fei. Large Scale Visual Recognition Challenge. http://www.image-net.org/challenges/LSVRC/2012/, 2012. 1, 2</p>
<p>[4] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. FeiFei. ImageNet: a large-scale hierarchical image database. In CVPR, 2009. 1, 3, 5</p>
<p>[5] S. Divvala, D. Hoiem, J. Hays, A. Efros, and M. Hebert. An empirical study of context in object detection. In CVPR, 2009. 2</p>
<p>[6] P. Dollar, C. Wojek, B. Schiele, and P. Perona. Pedestrian detection: A benchmark. In CVPR, 2009. 2, 3</p>
<p>[7] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The Pascal Visual Object Classes (VOC) challenge. IJCV, 88(2):303–338, June 2010. 1, 2, 3</p>
<p>[8] L. Fei-Fei, R. Fergus, and P. Perona. Learning generative visual models from few examples: an incremental bayesian approach tested on 101 object categories. In CVPR, 2004. 1</p>
<p>[9] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. PAMI, 32, 2010. 1, 2, 4, 7</p>
<p>[10] D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error in object detectors. In ECCV, 2012. 1, 2, 3, 8</p>
<p>[11] D. Hoiem, C. Rother, and J. Winn. 3D layout CRF for multiview object class recognition and segmentation. In CVPR, 2007. 2</p>
<p>[12] A. Krizhevsky, I. Sutskever, and G. Hinton. ImageNet classification with deep convolutional neural networks. In NIPS, 2012. 1, 2, 4</p>
<p>[13] D. G. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2):91–1 10, 2004. 4</p>
<p>[14] N. Pinto, D. Cox, and J. DiCarlo. Why is real-world visual object recognition hard? PLoS Comp Biology, 4, 2008. 2</p>
<p>[15] B. Russell, A. Torralba, K. Murphy, and W. T. Freeman. LabelMe: a database and web-based tool for image annotation. IJCV, 2007. 1</p>
<p>[16] J. Sanchez and F. Perronnin. High-dim. signature compression for large-scale image classification. In CVPR, 2011. 4</p>
<p>[17] J. Sanchez, F. Perronnin, and T. de Campos. Modeling spatial layout of images beyond spatial pyramids. In PRL, 2012. 4</p>
<p>[18] A. Torralba and A. Efros. An unbiased look at dataset bias. In CVPR, 2011. 1, 2</p>
<p>[19] A. Torralba, R. Fergus, and W. Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition. In PAMI, 2008. 1</p>
<p>[20] K. E. A. van de Sande, J. R. R. Uijlings, T. Gevers, and A. W. M. Smeulders. Segmentation as selective search for object recognition. In ICCV, 2011. 1</p>
<p>[21] A. Vedaldi, V. Gulshan, M. Varma, and A. Zisserman. Multiple kernels for object detection. In ICCV, 2009. 1</p>
<p>[22] X. Wang, T. Han, and S. Yan. An HOG-LBP human detector with partial occlusion handling. In ICCV, 2009. 2</p>
<p>[23] B. Wu and R. Nevatia. Detection of multiple, partially occluded humans in a single image by bayesian combination of edgelet part detectors. In ICCV, 2005. 2</p>
<p>[24] J. Xiao, J. Hays, K. Ehinger, A. Oliva, and A. Torralba. SUN database: Large-scale scene recognition from Abbey to Zoo. CVPR, 2010. 1</p>
<p>[25] X. Zhu, C. Vondrick, D. Ramanan, and C. C. Fowlkes. Do we need more training data or better models for object detection.  In BMVC, 2012. 2 2071</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
