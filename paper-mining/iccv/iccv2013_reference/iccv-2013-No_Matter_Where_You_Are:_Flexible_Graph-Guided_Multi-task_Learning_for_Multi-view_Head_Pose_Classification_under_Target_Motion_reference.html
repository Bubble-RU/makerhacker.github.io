<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>291 iccv-2013-No Matter Where You Are: Flexible Graph-Guided Multi-task Learning for Multi-view Head Pose Classification under Target Motion</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-291" href="../iccv2013/iccv-2013-No_Matter_Where_You_Are%3A_Flexible_Graph-Guided_Multi-task_Learning_for_Multi-view_Head_Pose_Classification_under_Target_Motion.html">iccv2013-291</a> <a title="iccv-2013-291-reference" href="#">iccv2013-291-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>291 iccv-2013-No Matter Where You Are: Flexible Graph-Guided Multi-task Learning for Multi-view Head Pose Classification under Target Motion</h1>
<br/><p>Source: <a title="iccv-2013-291-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Yan_No_Matter_Where_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yan Yan, Elisa Ricci, Ramanathan Subramanian, Oswald Lanz, Nicu Sebe</p><p>Abstract: We propose a novel Multi-Task Learning framework (FEGA-MTL) for classifying the head pose of a person who moves freely in an environment monitored by multiple, large field-of-view surveillance cameras. As the target (person) moves, distortions in facial appearance owing to camera perspective and scale severely impede performance of traditional head pose classification methods. FEGA-MTL operates on a dense uniform spatial grid and learns appearance relationships across partitions as well as partition-specific appearance variations for a given head pose to build region-specific classifiers. Guided by two graphs which a-priori model appearance similarity among (i) grid partitions based on camera geometry and (ii) head pose classes, the learner efficiently clusters appearancewise related grid partitions to derive the optimal partitioning. For pose classification, upon determining the target’s position using a person tracker, the appropriate regionspecific classifier is invoked. Experiments confirm that FEGA-MTL achieves state-of-the-art classification with few training data.</p><br/>
<h2>reference text</h2><p>[1] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task feature learning. In NIPS, 2007. 2, 6, 7</p>
<p>[2] A. Beck and M. Teboulle. A fast iterative shrinkagethresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2(1): 183–202, 2009. 5</p>
<p>[3] B. Benfold and I. Reid. Unsupervised learning of a scenespecific coarse gaze estimator. In ICCV, 2011. 2, 4</p>
<p>[4] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Distributed optimization and statistical learning via the alternating direction method of multipliers. Found. Trends Mach. Learn., 3(1): 1–122, 2011. 5</p>
<p>[5] C. Chen and J.-M. Odobez. We are not contortionists: coupled adaptive learning for head and body orientation estimation in surveillance video. In CVPR, 2012. 1, 2, 4</p>
<p>[6] X. Chen, Q. Lin, S. Kim, J. Carbonell, and E. Xing. Smoothing proximal gradient method for general structured sparse learning. In UAI, 2011. 3, 7</p>
<p>[7] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR, 2005. 2</p>
<p>[8] T. Evgeniou and M. Pontil. Regularized multi-task learning. In SIGKDD, 2004. 2</p>
<p>[9] P. Gong, J. Ye, and C. Zhang. Robust multi-task feature learning. In SIGKDD, 2012. 3, 7</p>
<p>[10] A. Jalali, P. Ravikumar, S. Sanghavi, and C. Ruan. A dirty model for multi-task learning. In NIPS, 2010. 3, 7</p>
<p>[11] Z. Kang, K. Grauman, and F. Sha. Learning with whom to share in multi-task feature learning. In ICML, 2011. 3</p>
<p>[12] O. Lanz. Approximate bayesian multibody tracking. IEEE Trans. on PAMI, 28:1436–1449, 2006. 3, 6, 7</p>
<p>[13] B. Lepri, R. Subramanian, K. Kalimeri, J. Staiano, F. Pianesi,</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]  and N. Sebe. Connecting meeting behavior with extraversion: A systematic study. IEEE Trans. on Affective Computing, 3:443–455, 2012. 1 R. Mu˜ noz-Salinas, E. Yeguas-Bolivar, A. Saffiotti, and R. M. Carnicer. Multi-camera head pose estimation. Mach. Vis. Appl., 23(3):479–490, 2012. 1, 2, 6, 7 E. Murphy-Chutorian and M. M. Trivedi. Head pose estimation in computer vision: A survey. IEEE Trans. on PAMI, 31:607–626, 2009. 1 J. Orozco, S. Gong, and T. Xiang. Head pose classification in crowded scenes. In BMVC, 2009. 1, 2 A. Rajagopal, R. Subramanian, R. Vieriu, E. Ricci, O. Lanz, N. Sebe, and K. Ramakrishnan. An adaptation framework for head pose estimation in dynamic multi-view scenarios. In ACCV, 2012. 1, 2, 6, 7 R. Stiefelhagen, R. Bowers, and J. G. Fiscus. Multimodal technologies for perception of humans, CLEAR. 2007. 6 D. Tosato, M. Farenzena, M. Cristani, M. Spera, and V. Murino. Multi-class classification on riemannian manifolds for video surveillance. In ECCV, 2010. 1, 2, 6, 7 M. Voit and R. Stiefelhagen. A system for probabilistic joint 3d head tracking and pose estimation in low-resolution, multi-view environments. In Computer Vision Systems, pages 415–424, 2009. 1, 2 Y. Yan, G. Liu, E. Ricci, and N. Sebe. Multi-task linear discriminant analysis for multi-view action recognition. In ICIP, 2013. 2 Y. Yan, R. Subramanian, O. Lanz, and N. Sebe. Active transfer learning for multi-view head-pose classification. In ICPR, 2012. 1 X. Zabulis, T. Sarmis, and A. Argyros. 3d headpose esti-  mation from multiple distant views. In BMVC, 2009. 1, 2, 6</p>
<p>[24] L. W. Zhong and J. T. Kwok. Convex multitask learning with flexible task clusters. In ICML, 2012. 3, 6, 7</p>
<p>[25] J. Zhou, J. Chen, and J. Ye. Clustered multi-task learning via alternating structure optimization. In NIPS, 2011. 3, 6, 7</p>
<p>[26] J. Zhou, J. Chen, and J. Ye. MALSAR: Multi-tAsk Learning via StructurAl Regularization. Arizona State University, 2011. 7 11 118844</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
