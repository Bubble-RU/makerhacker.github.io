<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>287 iccv-2013-Neighbor-to-Neighbor Search for Fast Coding of Feature Vectors</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-287" href="../iccv2013/iccv-2013-Neighbor-to-Neighbor_Search_for_Fast_Coding_of_Feature_Vectors.html">iccv2013-287</a> <a title="iccv-2013-287-reference" href="#">iccv2013-287-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>287 iccv-2013-Neighbor-to-Neighbor Search for Fast Coding of Feature Vectors</h1>
<br/><p>Source: <a title="iccv-2013-287-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Inoue_Neighbor-to-Neighbor_Search_for_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Nakamasa Inoue, Koichi Shinoda</p><p>Abstract: Assigning a visual code to a low-level image descriptor, which we call code assignment, is the most computationally expensive part of image classification algorithms based on the bag of visual word (BoW) framework. This paper proposes a fast computation method, Neighbor-toNeighbor (NTN) search, for this code assignment. Based on the fact that image features from an adjacent region are usually similar to each other, this algorithm effectively reduces the cost of calculating the distance between a codeword and a feature vector. This method can be applied not only to a hard codebook constructed by vector quantization (NTN-VQ), but also to a soft codebook, a Gaussian mixture model (NTN-GMM). We evaluated this method on the PASCAL VOC 2007 classification challenge task. NTN-VQ reduced the assignment cost by 77.4% in super-vector coding, and NTN-GMM reduced it by 89.3% in Fisher-vector coding, without any significant degradation in classification performance.</p><br/>
<h2>reference text</h2><p>[1] G. Csurka, C. Dance, L. Fan, J. Willamowski, and C. Bray. Visual categorization with bags of keypoints. Proc. ECCV SLCV workshop, pages 59–74, 2004. 1, 2</p>
<p>[2] D. G. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2):91–1 10, 2004. 1, 2</p>
<p>[3] M. Ovsjanikov, W. Li, L. Guibas, and N. J. Mitra. Exploration of continuous variability in collections of 3d shapes. ACM Trans. Graph., 30(4): 1–10, July 2011. 1</p>
<p>[4] iJPm.rao St.ce. B C ne ViasPrR eans,td p-na Degi.ge Gshb 1.o0 Lu0or0w– se 1.a0r0c 6Sh, i1an9p h9ei7g in.hd 1-edximinegns uisoin agl a sp parcoexs-.</p>
<p>[5] C. Silpa-anan and R. Hartley. Optimised kd-trees for fast image descriptor matching. Proc. CVPR, pages 1–8, 2008. 1, 2</p>
<p>[6]p Mbao.rge Mss wu 3ijta3h1 a– anu3dt4o 0mD,.a 2t G0ic.09 L al.ogw 1o,eri 2.t,h F 5ma,s 6 c,ton 7 apfipgruorxaitmioant.e P nreoacr.e VstIS nAeiPghP-,</p>
<p>[7] N. Inoue and K. Shinoda. A fast map adaptation technique for gmm-supervector-based video semantic indexing systems. Proc. ACM Multimedia, pages 1357–1360, 2011. 1, 2, 5, 6</p>
<p>[8] X. Zhou, K. Yu, T. Zhang, and T. S. Huang. Image classification using super-vector coding of local image descriptors. Proc. ECCV, pages 141–154, 2010. 1, 2, 5</p>
<p>[9] F. Perronnin, S. Jorge, and T. Mensink. Improving the fisher kernel for large-scale image classification. Proc. ECCV, pages 143–156, 2010. 1, 2, 5</p>
<p>[10] D. Nister and H. Stewenius. Scalable recognition with a vocabulary tree. Proc. CVPR, pages 2161–2168, 2006. 2</p>
<p>[11] H. J ´egou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE Trans. on Pattern Analysis and Machine Intelligence, 33(1): 117–128, 2011. 2, 8</p>
<p>[12] F. Perronnin, C. Dance, G. Csurka, and M. Bressan. Adapted vocabularies for generic visual categorization. Proc. ECCV, pages 464–475, 2006. 2  Figure 11. Relative computational cost. Computational cost for each step of super-vector (SV) coding and Fisher-vector (FV) coding is reported. The codebook size is 512. Feature extraction: SIFT descriptors are extracted from every 4 pixels at 5 scales, Coding: each descriptor is assigned to codeword(s), Pooling: an SV or FV image representation is generated. 85.3%, 56.6%, 88.4%, 65.4% and 64.2% of computational time is occupied from coding by VQ, NTN-VQ, GMM, NTN-GMM, and NTN-LM-GMM, respectively. Total computational cost is reduced by 66.0%, 66.5% and 85.3% by NTN-VQ, NTN-GMM, and NTN-LM-GMM, respectively.</p>
<p>[13]i2 Tn0.g0 H9 fuo.ar n2 igm.a Lgience laras s piafitcia lti pony.ra Pmroidc. m CaVtcPhRin,g pa ugsiensg 1 s7p9a4r–se1 c8o0d1,[14] J. Wang, J. Yang, K. Yu, F. Lv, T. Huang, and Y. Gong.  Locality-constrained linear coding for image classification. Proc. CVPR, pages 3360–3367, 2010. 2</p>
<p>[15] K. Chatfield, V. Lempitsky, A. Vedaldi, and A. Zisserman. The devil is in the details: an evaluation of recent feature encoding methods. Proc. BMVC, pages 1–12, 2011. 2, 5</p>
<p>[16] M. Everingham, A. Zisserman, C. Williams, and L. V. Gool. The pascal visual obiect classes challenge 2007 (voc2007) results. http://www.pascal-network.org/challenges/VOC/voc 2007/workshop/index.html, 2007. 5 Appendix The upper bound pjk of the probability (Eq. (13)) is delivered as follows. The law of cosines gives ∃δ∗ ∈ [−1, 1] s.t. ?xj − μk ? 2Σk−1 (19) = ?xi − μk?2Σk−1 + ?xi  − xj  ?2Σk−1 − 2δ∗?xi  − xj  ?Σk−1 ?xi − μk?Σk−1 .  For δ ≥ max(δ∗ , 0), it implies ?xj − μk?2Σk−1 ≥ ?xi − μk?2Σk−1 − 2Skδ?xi − xj? ?xi − μk?Σk−1 ≥ ?xi − μk?2Σk−1 − 2SkδΔij?xi − μk?Σk−1,  (20)  Σk−1  where Sk is the square root ofthe spectral radius of and Δij is the accumulated distance given by Eq. (6). Thus, we have  pjk=Zwkkexp?−21?xj− μk?2Σk−1? ≤ wZkkexp ?−12?xi − μk?2Σk−1 + SkδΔij?xi − μk?Σk−1? ?SkδΔij?xi − μk?Σk−1? = pikexp  = pik exp (δikΔij) = pjk, where Zk = (2π)  2d |Σk | 21 and δik 1240  is given in Eq.(14).  (21) (22) (23) (24)</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
