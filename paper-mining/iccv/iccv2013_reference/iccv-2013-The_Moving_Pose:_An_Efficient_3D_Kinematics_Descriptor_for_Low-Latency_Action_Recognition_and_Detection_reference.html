<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-417" href="../iccv2013/iccv-2013-The_Moving_Pose%3A_An_Efficient_3D_Kinematics_Descriptor_for_Low-Latency_Action_Recognition_and_Detection.html">iccv2013-417</a> <a title="iccv-2013-417-reference" href="#">iccv2013-417-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>417 iccv-2013-The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection</h1>
<br/><p>Source: <a title="iccv-2013-417-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zanfir_The_Moving_Pose_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Mihai Zanfir, Marius Leordeanu, Cristian Sminchisescu</p><p>Abstract: Human action recognition under low observational latency is receiving a growing interest in computer vision due to rapidly developing technologies in human-robot interaction, computer gaming and surveillance. In this paper we propose a fast, simple, yet powerful non-parametric Moving Pose (MP)frameworkfor low-latency human action and activity recognition. Central to our methodology is a moving pose descriptor that considers both pose information as well as differential quantities (speed and acceleration) of the human body joints within a short time window around the current frame. The proposed descriptor is used in conjunction with a modified kNN classifier that considers both the temporal location of a particular frame within the action sequence as well as the discrimination power of its moving pose descriptor compared to other frames in the training set. The resulting method is non-parametric and enables low-latency recognition, one-shot learning, and action detection in difficult unsegmented sequences. Moreover, the framework is real-time, scalable, and outperforms more sophisticated approaches on challenging benchmarks like MSR-Action3D or MSR-DailyActivities3D.</p><br/>
<h2>reference text</h2><p>[1] S. Ali and M. Shah. Human action recognition in videos using kinematic features and multiple instance learning. PAMI, 32, 2010.</p>
<p>[2] L. Cao, Z. Liu, and T. Huang. Cross-dataset action detection. In CVPR, 2010.</p>
<p>[3] S. Carlsson and J. Sullivan. Action recognition by shape matching to key frames. In WMECV, 2001.</p>
<p>[4] S. Cheema, A. Eweiwi, C. Thurau, and C. Bauckhage. Action recognition by learning discriminative key poses. In ICCV Workshop, 2011.</p>
<p>[5] N. Cuntoor and R. Chellappa. Key frame-based activity representation using antieigenvalues. In ACCV, 2006.</p>
<p>[6] O. Duchenne, I. Laptev, J. Sivic, F. Bach, and J. Ponce. Automatic annotation of human actions in video. In ICCV, 2009.</p>
<p>[7] C. Ellis, S. Masood, M. Tappen, J. L. Jr., and R. Sukthankar. Exploring the trade-off between accuracy and observational latency in action recognition. IJCV, August 2012.</p>
<p>[8] M. Everingham, L. J. V. Gool, C. K. I. Williams, J. M. Winn, and A. Zisserman. The pascal visual object classes (voc) challenge. IJCV, 88(2):303–338, 2010.</p>
<p>[9] M. Hoai and F. de la Torre. Max-margin early event detectors. In CVPR, 2012.</p>
<p>[10] W. Li, Z. Zhang, and Z. Liu. Action recognition based on a bag of 3d points. In WCBA-CVPR, 2010.</p>
<p>[11] F. Lv and F. Nevaita. Single view human action recognition using key pose matching and viterbi path searching. In CVPR, 2007.</p>
<p>[12] F. Lv and R. Nevatia. Recognition and segmentation of 3d human action using hmm and multi-class adaboost. In ECCV, 2006.</p>
<p>[13] J. Martens and I. Sutskever. Learning recurrent neural networks with hessian-free optimization. In ICML, 2011.</p>
<p>[14] L.-P. Morency, A. Quattoni, and T. Darrell. Latent-dynamic discriminative models for continuous gesture recognition. In CVPR. IEEE Computer Society, 2007.</p>
<p>[15] M. M ¨uller and T. R ¨oder. Motion templates for automatic classification and retrieval of motion capture data. In SCA, 2006.</p>
<p>[16] M. Narasimhan, P. Viola, and M. Shilman. Online decoding of markov models under latency constraints. In ICML, 2006.</p>
<p>[17] M. Raptis, D. Kirovski, and H. Hoppes. Real-time classification of dance gestures from skeleton animation. In Symp. on Comp. Anim., 2011.</p>
<p>[18] K. Schindler and L. van Gool. Action snippets: How many frames does human action recognition require ? In CVPR, 2012.</p>
<p>[19] L. Shao and L. Ji. Motion histogram analysis based key frame extraction for human action/activity representation. In CRV, 2009.</p>
<p>[20] Y. Shen and H. Foroosh. View-invariant action recognition from point triplets. PAMI, 3 1, 2009.</p>
<p>[21] J. Shotton, A. Fitzgibbon, M. Cook, T. Sharp, M. Finocchio, R. Moore, A. Kipman, and A. Blake. Real-time human pose recognition in parts from a single depth image. In CVPR, 2011.</p>
<p>[22] C. Sminchisescu, A. Kanaujia, and D. Metaxas. Conditional models for contextual human motion recognition. In CVIU, 2006.</p>
<p>[23] A. Vahdat, B. Gao, M. Ranjbar, and G. Mori. A discriminative key pose sequence model for recognizing human interactions. In IWVS, 2008.</p>
<p>[24] J. Wang, Z. Liu, Y. Wu, and J. Yuan. Mining actionlet ensemble for action recognition with depth cameras. In CVPR, 2012.</p>
<p>[25] X. Yang and Y. Tian. Eigenjoints-based action recognition using na¨ ıve-bayes-nearest-neighbor. In CVPR Workshops, pages 14–19, 2012.</p>
<p>[26] J. Yuan, Z. Liu, and Y. Wu. Discriminative subvolume search for efficient action detection. In CVPR, 2009.</p>
<p>[27] Z. Zhao and A. Elgammal. Information theoretic key frame selection for action recognition. In BMVC, 2008. 2759</p>
<br/>
<br/><br/><br/></body>
</html>
