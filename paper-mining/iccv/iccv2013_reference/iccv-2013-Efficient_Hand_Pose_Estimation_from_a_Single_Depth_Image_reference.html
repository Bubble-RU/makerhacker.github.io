<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>133 iccv-2013-Efficient Hand Pose Estimation from a Single Depth Image</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-133" href="../iccv2013/iccv-2013-Efficient_Hand_Pose_Estimation_from_a_Single_Depth_Image.html">iccv2013-133</a> <a title="iccv-2013-133-reference" href="#">iccv2013-133-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>133 iccv-2013-Efficient Hand Pose Estimation from a Single Depth Image</h1>
<br/><p>Source: <a title="iccv-2013-133-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Xu_Efficient_Hand_Pose_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Chi Xu, Li Cheng</p><p>Abstract: We tackle the practical problem of hand pose estimation from a single noisy depth image. A dedicated three-step pipeline is proposed: Initial estimation step provides an initial estimation of the hand in-plane orientation and 3D location; Candidate generation step produces a set of 3D pose candidate from the Hough voting space with the help of the rotational invariant depth features; Verification step delivers the final 3D hand pose as the solution to an optimization problem. We analyze the depth noises, and suggest tips to minimize their negative impacts on the overall performance. Our approach is able to work with Kinecttype noisy depth images, and reliably produces pose estimations of general motions efficiently (12 frames per second). Extensive experiments are conducted to qualitatively and quantitatively evaluate the performance with respect to the state-of-the-art methods that have access to additional RGB images. Our approach is shown to deliver on par or even better results.</p><br/>
<h2>reference text</h2><p>[1]</p>
<p>[2]</p>
<p>[3]</p>
<p>[4]</p>
<p>[5]</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]  Kinect. http://www.xbox.com/en-US/kinect/, 2011. 3gear. http://www.threegear.com/, 2012. Leapmotion. http://www.leapmotion.com/, 2013. L. Ballan, A. Taneja, J. Gall, L. Gool, and M. Pollefeys. Motion capture of hands in action using discriminative salient points. In ECCV, 2012. L. Breiman. Random forests. Machine Learning, 45(1):5–32, 2001. E. Chao, K. An, W. Cooney, and R. Linscheid. Biomechanics of the Hand: A Basic Research Study. World Scientific, 1989. D. Comaniciu and P. Meer. Mean shift: A robust approach toward feature space analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24:603–619, 2002. T. de Campos and D. Murray. Regression-based hand pose estimation from multiple cameras. In CVPR, 2006. M. de La Gorce, D. Fleet, and N. Paragios. Model-based 3d hand pose estimation from monocular video. IEEE Trans. Pattern Anal. Mach, 33(9): 1793–1805, 2011. A. Erol, G. Bebis, M. Nicolescu, R. Boyle, and X. Twombly. Visionbased hand pose estimation: A review. Comput. Vis. Image Underst., 108(1-2):52–73, 2007. R. Girshick, J. Shotton, P. Kohli, A. Criminisi, and A. Fitzgibbon. Efficient regression of general-activity human poses from depth images. In ICCV, 2011. U. Grenander. Pattern Theory: From Representation to Inference. Oxford University Press, 2007. A. Gustus, G. Stillfried, J. Visser, H. Jorntell, and P. van der Smagt. Human hand modelling: kinematics, dynamics, applications. Biological Cybernetics, 106(1 1-12):741–755, 2012. P. Huber. Robust Statistics. Wiley Press, 1981. C. Keskin, F. Kirac, Y. Kara, and L. Akarun. Hand pose estimation and hand shape classification using multi-layered randomized decision forests. In ECCV, 2012. N. Oikonomidis and A. Argyros. Efficient model-based 3d tracking of hand articulations using kinect. In BMVC, 2011. V. Pavlovic, R. Sharma, and T. Huang. Visual interpretation of hand gestures for human-computer interaction: A review. IEEE Trans. Pattern Anal. Mach. Intell., 19(7):677–695, 1997. J. Rehg and T. Knade. Visual tracking of high dof articulated structures: an application to human hand tracking. In European Conference on Computer Vision, pages 35–46, 1994. J. Shotton, A. Fitzgibbon, M. Cook, T. Sharp, M. Finocchio, R. Moore, A. Kipman, and A. Blake. Real-time human pose recognition in parts from single depth images. In CVPR, 2011. B. Siciliano and the DEXMART team. Kinematic modelling of the human hand. Technical report, University of Naples, 2009. http://www.dexmart.eu/index.php?id=13735. B. Stenger, P. Mendonca, and R. Cipolla. Model-based 3d tracking of an articulated hand. In CVPR, 2001. S. Sueda, A. Kaufman, and D. Pai. Musculotendon simulation for hand animation. In SIGGRAPH, pages 83: 1–83:8, 2008. M. ˇSari ´c. Libhand: A library for hand articulation, 2011. Version 0.9. R. Wang and J. Popovi´ c. Real-time hand-tracking with a color glove. In SIGGRAPH, pages 63: 1–63:8, 2009. W. Zhao, J. Chai, and Y. Xu. Combining marker-based mocap and rgb-d camera for acquiring high-fidelity hand motion data. In Eurographics Symposium on Computer Animation, 2012. 33445625</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
