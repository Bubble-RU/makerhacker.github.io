<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-366" href="../iccv2013/iccv-2013-STAR3D%3A_Simultaneous_Tracking_and_Reconstruction_of_3D_Objects_Using_RGB-D_Data.html">iccv2013-366</a> <a title="iccv-2013-366-reference" href="#">iccv2013-366-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>366 iccv-2013-STAR3D: Simultaneous Tracking and Reconstruction of 3D Objects Using RGB-D Data</h1>
<br/><p>Source: <a title="iccv-2013-366-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Ren_STAR3D_Simultaneous_Tracking_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Carl Yuheng Ren, Victor Prisacariu, David Murray, Ian Reid</p><p>Abstract: We introduce a probabilistic framework for simultaneous tracking and reconstruction of 3D rigid objects using an RGB-D camera. The tracking problem is handled using a bag-of-pixels representation and a back-projection scheme. Surface and background appearance models are learned online, leading to robust tracking in the presence of heavy occlusion and outliers. In both our tracking and reconstruction modules, the 3D object is implicitly embedded using a 3D level-set function. The framework is initialized with a simple shape primitive model (e.g. a sphere or a cube), and the real 3D object shape is tracked and reconstructed online. Unlike existing depth-based 3D reconstruction works, which either rely on calibrated/fixed camera set up or use the observed world map to track the depth camera, our framework can simultaneously track and reconstruct small moving objects. We use both qualitative and quantitative results to demonstrate the superior performance of both tracking and reconstruction of our method.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
