<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-78" href="../iccv2013/iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">iccv2013-78</a> <a title="iccv-2013-78-reference" href="#">iccv2013-78-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</h1>
<br/><p>Source: <a title="iccv-2013-78-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Narayana_Coherent_Motion_Segmentation_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Manjunath Narayana, Allen Hanson, Erik Learned-Miller</p><p>Abstract: In moving camera videos, motion segmentation is commonly performed using the image plane motion of pixels, or optical flow. However, objects that are at different depths from the camera can exhibit different optical flows even if they share the same real-world motion. This can cause a depth-dependent segmentation of the scene. Our goal is to develop a segmentation algorithm that clusters pixels that have similar real-world motion irrespective of their depth in the scene. Our solution uses optical flow orientations instead of the complete vectors and exploits the well-known property that under camera translation, optical flow orientations are independent of object depth. We introduce a probabilistic model that automatically estimates the number of observed independent motions and results in a labeling that is consistent with real-world motion in the scene. The result of our system is that static objects are correctly identified as one segment, even if they are at different depths. Color features and information from previous frames in the video sequence are used to correct occasional errors due to the orientation-based segmentation. We present results on more than thirty videos from different benchmarks. The system is particularly robust on complex background scenes containing objects at significantly different depths.</p><br/>
<h2>reference text</h2><p>[1] T. Brox and J. Malik. Object segmentation by long term analysis of point trajectories. In ECCV, 2010. 1, 2, 3, 4, 6, 7 11558833  Figure 5. Sample results from four videos. The columns are the original image, the observed FOF, FOF segmentation results, and results from combining FOF with color and prior models, respectively. FOF is very accurate when the foreground objects’ FOFs are easily distinguishable from the camera motion’s FOF. When the observed FOF cannot distinguish between the foreground and the background, FOF segmentation is not accurate. Color and prior information can help in these cases (row 2 in (a)). If the foreground object is not obvious from the FOF for a long duration, the color and prior too are unable to help recover them after some time (row 3 in (b) and (d)). In the new videos(c and d), camera rotation is a challenge (row 3 in (c) and row 2 in (d)). Occasionally, the largest detected segment is the foreground object, which gets labeled as background (row 3 in (c)). Using a prior helps reduce this error as well as errors due to rotation.</p>
<p>[2] D. J. Butler, J. Wulff, G. B. Stanley, and M. J. Black. naturalistic In ECCV,  A  open source movie for optical flow evaluation.  2012.  1,  3</p>
<p>[3] P. Chockalingam, S. N. Pradeep, and S. Birchfield. Adaptive fragments-based sets. In ICCV,  of non-rigid  objects  using level  2009. 3</p>
<p>[4] A. M. Elgammal, parametric  tracking  D. Harwood,  and L. S. Davis.  model for background  subtraction.  Non-  In ECCV,  2000. 1</p>
<p>[5] A. Elqursh and A. M. Elgammal. background subtraction.  Online moving camera  In ECCV, 2012. 1, 2, 4, 7</p>
<p>[6] E. Hayman and J.-O. Eklundh.  Statistical background  sub-  traction for a mobile observer. In ICCV, 2003. 1, 2</p>
<p>[7] M. Irani, B. Rousso, and S. Peleg. Computing occluding and transparent motions. IJCV, 12:5–16,  1994. 1, 2</p>
<p>[8] M. Irani, B. Rousso, and S. Peleg. Recovery of ego-motion</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]  using image stabilization. In CVPR, 1994. 3 S. Kwak, T. Lim, W. Nam, B. Han, and J. H. Han. Generalized background subtraction based on hybrid inference by belief propagation and Bayesian filtering. In ICCV, 2011. 1, 2, 7 Y. J. Lee, J. Kim, and K. Grauman. Key-segments for video object segmentation. In ICCV, 2011. 3 M. Narayana, A. Hanson, and E. Learned-Miller. Improvements in joint domain-range modeling for background subtraction. In BMVC, 2012. 1, 5 R. M. Neal. Markov chain sampling methods for Dirichlet process mixture models. Journal of Computational and Graphical Statistics, 9(2):249–265, 2000. 4 P. Ochs and T. Brox. Higher order motion models and spectral clustering. In CVPR, 2012. 1, 2, 4, 5, 6, 7 Y. Ren, C.-S. Chua, and Y.-K. Ho. Statistical background modeling for non-stationary camera. Pattern Recognition Letters, 24(1-3): 183–196, Jan. 2003. 1, 2 Y. Sheikh, O. Javed, and T. Kanade. Background subtraction for freely moving cameras. In ICCV, 2009. 1, 2, 5 Y. Sheikh and M. Shah. Bayesian modeling of dynamic scenes for object detection. PAMI, 27, 2005. 1, 5 J. Shi and J. Malik. Motion segmentation and tracking using normalized cuts. In ICCV, 1998. 1 C. Stauffer and W. E. L. Grimson. Adaptive background mixture models for real-time tracking. In CVPR, 1999. 1 D. Sun, S. Roth, and M. J. Black. Secrets of optical flow estimation and their principles. In CVPR, 2010. 1, 3 R. Tron and R. Vidal. A benchmark for the comparison of 3-d motion segmentation algorithms. In CVPR, 2007. 6, 7 D. Tsai, M. Flagg, and J. M. Rehg. Motion coherent tracking  with multi-label MRF optimization. BMVC, 2010. 3, 6 11558844</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
