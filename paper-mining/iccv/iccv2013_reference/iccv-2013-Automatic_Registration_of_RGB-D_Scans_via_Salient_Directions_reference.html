<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>56 iccv-2013-Automatic Registration of RGB-D Scans via Salient Directions</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-56" href="../iccv2013/iccv-2013-Automatic_Registration_of_RGB-D_Scans_via_Salient_Directions.html">iccv2013-56</a> <a title="iccv-2013-56-reference" href="#">iccv2013-56-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>56 iccv-2013-Automatic Registration of RGB-D Scans via Salient Directions</h1>
<br/><p>Source: <a title="iccv-2013-56-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zeisl_Automatic_Registration_of_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Bernhard Zeisl, Kevin Köser, Marc Pollefeys</p><p>Abstract: We address the problem of wide-baseline registration of RGB-D data, such as photo-textured laser scans without any artificial targets or prediction on the relative motion. Our approach allows to fully automatically register scans taken in GPS-denied environments such as urban canyon, industrial facilities or even indoors. We build upon image features which are plenty, localized well and much more discriminative than geometry features; however, they suffer from viewpoint distortions and request for normalization. We utilize the principle of salient directions present in the geometry and propose to extract (several) directions from the distribution of surface normals or other cues such as observable symmetries. Compared to previous work we pose no requirements on the scanned scene (like containing large textured planes) and can handle arbitrary surface shapes. Rendering the whole scene from these repeatable directions using an orthographic camera generates textures which are identical up to 2D similarity transformations. This ambiguity is naturally handled by 2D features and allows to find stable correspondences among scans. For geometric pose estimation from tentative matches we propose a fast and robust 2 point sample consensus scheme integrating an early rejection phase. We evaluate our approach on different challenging real world scenes.</p><br/>
<h2>reference text</h2><p>[1] G. Baatz, K. K ¨oser, D. Chen, R. Grzeszczuk, and M. Pollefeys. Leveraging 3d city models for rotation invariant placeof-interest recognition. IJCV, 2012. 2, 4</p>
<p>[2] P. Besl and N. McKay. A method for registration of 3-d shapes. IEEE TPAMI, 1992. 1, 2</p>
<p>[3] Y. Cao and J. McDonald. Improved Feature Extraction and Matching in Urban Environments based on 3D Viewpoint Normalization. Comp. Vision a. Image Underst., 2012. 2</p>
<p>[4] Y. Cao, M. Yang, and J. McDonald. Robust Alignment of Wide Baseline Terrestrial Laser Scans via 3D Viewpoint Normalization. In Workshop on App. of Comp. Vision. IEEE, 2011. 2, 6, 7, 8</p>
<p>[5] D. Comaniciu and P. Meer. Mean Shift: A Robust Approach Toward Feature Space Analysis. IEEE TPAMI, 2002. 4</p>
<p>[6] D. Eggert, A. Lorusso, and R. Fisher. Estimating 3-D Rigid Body Transformations: A Comparison of Four Major Algorithms. Machine Vision and Appl., 1997. 6</p>
<p>[7] C. Harris and M. Stephens. A combined corner and edge detector. In 4th Alvey Vision Conf., Manchester, 1988. 5</p>
<p>[8] S. Holzer, J. Shotton, and P. Kohli. Learning to Efficiently Detect Repeatable Interest Points in Depth Data. In Proc. ECCV, 2012. 2</p>
<p>[9] A. Johnson and M. Hebert. Using spin images for efficient object recognition in cluttered 3d scenes. IEEE TPAMI, 1999. 2, 6</p>
<p>[10] B. King, T. Malisiewicz, C. Stewart, and R. Radke. Registration of multiple range scans as a location recognition problem: hypothesis generation, refinement and verification. In Int. Conf. on 3-D Digital Imaging and Modeling, 2005. 2</p>
<p>[11] K. K o¨ser and R. Koch. Perspectively Invariant Normal Features. In ICCV, Works. on 3D Repr. and Rec., 2007. 2</p>
<p>[12] K. K ¨oser, C. Zach, and M. Pollefeys. Dense 3d reconstruction of symmetric scenes from a single image. In Pattern Recognition. 2011. 4</p>
<p>[13] R. K ¨ummerle, G. Grisetti, H. Strasdat, K. Konolige, and W. Burgard. g2o: A general framework for graph optimization. In Proc. ICRA, 2011. 7</p>
<p>[14] J.-F. Lalonde, S. G. Narasimhan, and A. A. Efros. What do the sun and the sky tell us about the camera? IJCV, 2010. 4</p>
<p>[15] D. G. Lowe. Distinctive Image Features from Scale-Invariant Keypoints. IJCV, 2004. 2, 5</p>
<p>[16] K. Mikolajczyk, T. Tuytelaars, C. Schmid, A. Zisserman, J. Matas, F. Schaffalitzky, T. Kadir, and L. Van Gool. A Comparison of Affine Region Detectors. IJCV, 2005. 2 2814  A  A  B  C  D  E  4212 8 / 52641 310271 / 416309 21— / 68 15— / 39  B  214312 / 316212  5/5  C 4/5  2/3 1/ 2  1/1 1/ 2  5538 / 7 955  1859 / 1 20235 15294 / 3 1 290  4/5  D E  19— / 54  5/7 2/2  — 0/ 0  (a) CASTLE Table 1: Registration evaluation for CASTLE and CHURCH.  A  A B 6/7 C  6  /  7  B  C  D  E  13 6 5 / 420169 75— / 146 8625 / 1 7454 2146 / 2 63 405— / 480 134149 / 414325 6494 / 1 6408 7  /  121 / 168  9  D  7/7  8/8  5/6  5/8  5/7  12773 / /7 1 966  6/8  E  63 / 118  6/ 8  (b) CHURCH (Upper right parts) Relation between correct and tentative matches, for our approach (in bold) and planar rectification [22, 4]. The results indicate our superior performance. (Lower left parts) Repeatability scores for salient directions, i.e. the ration of found and present salient directions in the scan overlap.  horizontal cube faces. The numbers in the table are organized in the same way as in Table 1.</p>
<p>[17] G. Pandey, J. McBride, S. Savarese, and R. Eustice. Automatic Targetless Extrinsic Calibration of a 3D Lidar and Camera by Maximizing Mutual Information. In AAAI Conf. on Artificial Intelligence, 2012. 2</p>
<p>[18] D. Robertson and R. Cipolla. An Image-Based System for Urban Navigation. In Proc. BMVC, 2004. 2</p>
<p>[19] R. B. Rusu, N. Blodow, and M. Beetz. Fast point feature histograms (fpfh) for 3d registration. In Proc. ICRA, 2009. 2</p>
<p>[20] A. Telea. An Image Inpainting Technique Based on the Fast Marching Method. J. of Graphic Tools, 2004. 5</p>
<p>[21] R. Unnikrishnan and M. Hebert. Fast extrinsic calibration of a laser rangefinder to a camera. Technical Report CMU-RITR-05-09, 2005. 2</p>
<p>[22] C. Wu, B. Clipp, X. Li, J.-M. Frahm, and M. Pollefeys. 3D Model Matching with Viewpoint-Invariant Patches (VIP). In Proc. CVPR, 2008. 2, 5, 6, 7, 8</p>
<p>[23] J. V. Wyngaerd and L. V. Gool. Automatic crude patch registration: toward automatic 3d model building. Comput. Vis.  Image Underst., 2002. 2</p>
<p>[24] S. Yamany and A. Farag. Surface Signatures: An orientation independent free-form surface representation scheme for the purpose of objects registration and matching. IEEE TPAMI, 2002. 2</p>
<p>[25] B. Zeisl, K. K ¨oser, and M. Pollefeys. Viewpoint Invariant Matching via Developable Surfaces. In ECCV, Workshop on Consumer Depth Cameras, 2012. 2 28 15</p>
<br/>
<br/><br/><br/></body>
</html>
