<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-12" href="../iccv2013/iccv-2013-A_General_Dense_Image_Matching_Framework_Combining_Direct_and_Feature-Based_Costs.html">iccv2013-12</a> <a title="iccv-2013-12-reference" href="#">iccv2013-12-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>12 iccv-2013-A General Dense Image Matching Framework Combining Direct and Feature-Based Costs</h1>
<br/><p>Source: <a title="iccv-2013-12-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Braux-Zin_A_General_Dense_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Jim Braux-Zin, Romain Dupont, Adrien Bartoli</p><p>Abstract: Dense motion field estimation (typically Romain Dupont1 romain . dupont @ cea . fr Adrien Bartoli2 adrien . bart o l @ gmai l com i . 2 ISIT, Universit e´ d’Auvergne/CNRS, France sions are explicitly modeled [32, 13]. Coarse-to-fine warping improves global convergence by making the assumption that optical flow, the motion of smaller structures is similar to the motion of stereo disparity and surface registration) is a key computer vision problem. Many solutions have been proposed to compute small or large displacements, narrow or wide baseline stereo disparity, but a unified methodology is still lacking. We here introduce a general framework that robustly combines direct and feature-based matching. The feature-based cost is built around a novel robust distance function that handles keypoints and “weak” features such as segments. It allows us to use putative feature matches which may contain mismatches to guide dense motion estimation out of local minima. Our framework uses a robust direct data term (AD-Census). It is implemented with a powerful second order Total Generalized Variation regularization with external and self-occlusion reasoning. Our framework achieves state of the art performance in several cases (standard optical flow benchmarks, wide-baseline stereo and non-rigid surface registration). Our framework has a modular design that customizes to specific application needs.</p><br/>
<h2>reference text</h2><p>[1] Special session on robust optical flow, 2013. German Conference on Pattern Recognition.</p>
<p>[2] S. Baker, D. Scharstein, J. Lewis, S. Roth, M. Black, and R. Szeliski. A database and evaluation methodology for optical flow. IJCV, 2011.</p>
<p>[3] H. Bay, T. Tuytelaars, and L. Van Gool. SURF: Speeded up robust features. ECCV, 2006.</p>
<p>[4] A. C. Berg and J. Malik. Geometric blur for template matching. In CVPR, 2001.</p>
<p>[5] Y. Boykov, O. Veksler, and R. Zabih. Fast approximate energy minimization via graph cuts. PAMI, 2001 .</p>
<p>[6] G. Bradski. The OpenCV library. Dr. Dobb’s Journal of Software Tools, 2000.</p>
<p>[7] K. Bredies. Recovering piecewise smooth multichannel images by minimization of convex functionals with total generalized variation penalty. SFB Report, 6, 2012.</p>
<p>[8] K. Bredies, K. Kunisch, and T. Pock. Total generalized variation. SIAM Journal on Imaging Sciences, 2010.</p>
<p>[9] T. Brox and J. Malik. Large displacement optical flow: descriptor matching in variational motion estimation. PAMI, 2011.</p>
<p>[10] A. Chambolle and T. Pock. A first-order primal-dual algorithm for convex problems with applications to imaging. Journal of Mathematical Imaging and Vision, 2011.</p>
<p>[11] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR, 2005.</p>
<p>[12] R. Garg, A. Roussos, and L. Agapito. A variational approach to video registration with subspace constraints. IJCV, 2013.</p>
<p>[13] V. Gay-Bellile, A. Bartoli, and P. Sayd. Direct estimation of nonrigid registrations with image-based self-occlusion reasoning. PAMI, 2010.</p>
<p>[14] A. Geiger, P. Lenz, and R. Urtasun. Are we ready for autonomous driving? The KITTI vision benchmark suite. In CVPR, 2012.</p>
<p>[15] C. Harris and M. Stephens. A combined corner and edge detector. In Alvey vision conference, 1988.</p>
<p>[16] B. K. P. Horn and B. G. Schunck. Determining optical flow. Artificial Intelligence, 1981 .</p>
<p>[17] C. Liu, J. Yuen, and A. Torralba. SIFT flow: Dense correspondence across scenes and its applications. PAMI, 2011.</p>
<p>[18] D. G. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 2004.</p>
<p>[19] B. D. Lucas and T. Kanade. An iterative image registration technique with an application to stereo vision. In DARPA Image Understanding Workshop, 1981 .</p>
<p>[20] X. Mei, X. Sun, M. Zhou, S. Jiao, H. Wang, and X. Zhang. On building an accurate stereo matching system on graphics hardware. In Third Workshop on GPUs for Computer Vision, 2011.</p>
<p>[21] E. Mouragnon, M. Lhuillier, M. Dhome, F. Dekeyser, and P. Sayd. Real time localization and 3D reconstruction. In CVPR, 2006.</p>
<p>[22] M. Perriollat and A. Bartoli. A computational model of bounded developable surfaces with application to imagebased three-dimensional reconstruction. Computer Animation and Virtual Worlds, 2012.</p>
<p>[23] J. Pilet, V. Lepetit, and P. Fua. Fast non-rigid surface detection, registration and realistic augmentation. IJCV, 2008.</p>
<p>[24] D. Pizarro and A. Bartoli. Feature-based deformable surface</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]</p>
<p>[29]</p>
<p>[30] [3 1]</p>
<p>[32]</p>
<p>[33]</p>
<p>[34]</p>
<p>[35]</p>
<p>[36]  detection with self-occlusion reasoning. IJCV, 2012. R. Ranftl, S. Gehrig, T. Pock, and H. Bischof. Pushing the limits of stereo using variational stereo estimation. In Intelligent Vehicles Symposium (IV), 2012. E. Rosten, R. Porter, and T. Drummond. Faster and better: A machine learning approach to corner detection. PAMI, 2010. E. Tola, V. Lepetit, and P. Fua. Daisy: An efficient dense descriptor applied to wide-baseline stereo. PAMI, 2010. L. Wang, U. Neumann, and S. You. Wide-baseline image matching using line signatures. In ICCV, 2009. Z. Wang, F. Wu, and Z. Hu. MSLD: A robust descriptor for line matching. Pattern Recognition, 2009. M. Werlberger, W. Trobin, T. Pock, A. Wedel, D. Cremers, and H. Bischof. Anisotropic Huber-L1 optical flow. In BMVC, 2009. J. Wills, S. Agarwal, and S. Belongie. A feature-based approach for dense segmentation and estimation of large disparity motion. IJCV, 2006. L. Xu, J. Jia, and Y. Matsushita. Motion detail preserving optical flow estimation. In CVPR, 2010. K. Yamaguchi, D. McAllester, and R. Urtasun. Robust monocular epipolar flow estimation. In CVPR, 2013. G. Yu and J.-M. Morel. ASIFT: An Algorithm for Fully Affine Invariant Comparison. Image Processing On Line, 2011. R. Zabih and J. Woodfill. Non-parametric local transforms for computing visual correspondence. In ECCV, 1994. H. Zimmer, A. Bruhn, and J. Weickert. Optic flow in harmony. IJCV, 2011. 192</p>
<br/>
<br/><br/><br/></body>
</html>
