<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>369 iccv-2013-Saliency Detection: A Boolean Map Approach</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-369" href="../iccv2013/iccv-2013-Saliency_Detection%3A_A_Boolean_Map_Approach.html">iccv2013-369</a> <a title="iccv-2013-369-reference" href="#">iccv2013-369-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>369 iccv-2013-Saliency Detection: A Boolean Map Approach</h1>
<br/><p>Source: <a title="iccv-2013-369-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zhang_Saliency_Detection_A_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Jianming Zhang, Stan Sclaroff</p><p>Abstract: A novel Boolean Map based Saliency (BMS) model is proposed. An image is characterized by a set of binary images, which are generated by randomly thresholding the image ’s color channels. Based on a Gestalt principle of figure-ground segregation, BMS computes saliency maps by analyzing the topological structure of Boolean maps. BMS is simple to implement and efficient to run. Despite its simplicity, BMS consistently achieves state-of-the-art performance compared with ten leading methods on five eye tracking datasets. Furthermore, BMS is also shown to be advantageous in salient object detection.</p><br/>
<h2>reference text</h2><p>[1] R. Achanta, S. Hemami, F. Estrada, and S. Susstrunk. Frequency-tuned salient region detection. In CVPR, 2009.</p>
<p>[2] G. C. Baylis, J. Driver, et al. Shape-coding in it cells generalizes over contrast and mirror reversal, but not figure-  ground reversal. Nature Neuroscience, 4:937–942, 2001.  Figure 8: Saliency maps on the ASD dataset.</p>
<p>[3] A. Borji and L. Itti. Exploiting local and global patch rarities for saliency detection. In CVPR, 2012.</p>
<p>[4] A. Borji and L. Itti. State-of-the-art in visual attention modeling. PAMI, 2012.</p>
<p>[5] A. Borji, D. N. Sihite, and L. Itti. Salient object detection: A benchmark. In ECCV, 2012.</p>
<p>[6] N. Bruce and J. Tsotsos. Saliency, attention, and visual search: An information theoretic approach. Journal of Vision, 9(3), 2009.</p>
<p>[7] M. Cerf, J. Harel, W. Einh a¨user, and C. Koch. Predicting human gaze using low-level saliency combined with face detection. In NIPS, 2008.</p>
<p>[8] L. Chen. Topological structure in visual perception. Science, 1982.</p>
<p>[9] M. Cheng, G. Zhang, N. Mitra, X. Huang, and S. Hu. Global  contrast based salient region detection. In CVPR, 2011. 159  Figure9:SaliencymapsontheImgSaldat set.Wecan otshow  saliency maps of GSSP [36] because its code is not publicly  available.</p>
<p>[10] A. Garcia-Diaz, X. Vidal, X. Pardo, and R. Dosil. Saliency from hierarchical adaptation through decorrelation and variance normalization. IVC, 2011.</p>
<p>[11] S. Goferman, L. Zelnik-Manor, and A. Tal. Context-aware saliency detection. PAMI, 34(10), 2012.</p>
<p>[12] J. Han, K. Ngan, M. Li, and H. Zhang. Unsupervised extraction of visual attention objects in color images. Trans. Circuits and Systems for Video Technology, 16(1), 2006.</p>
<p>[13] J. Harel, C. Koch, and P. Perona. Graph-based visual saliency. In NIPS, 2007.</p>
<p>[14] X. Hou, J. Harel, and C. Koch. Image signature: Highlighting sparse salient regions. PAMI, 34(1), 2012.</p>
<p>[15] X. Hou and L. Zhang. Saliency detection: A spectral residual approach. In CVPR, 2007.</p>
<p>[16] Y. Hu, X. Xie, W.-Y. Ma, L.-T. Chia, and D. Rajan. Salient region detection using weighted feature maps based on the human visual attention model. In Pacific Rim Conference on Advances in Multimedia Information Processing, 2004.</p>
<p>[17] L. Huang and H. Pashler. A boolean map theory of visual attention. Psychological review, 114(3):599, 2007.</p>
<p>[18] L. Itti and P. Baldi. Bayesian surprise attracts human</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]</p>
<p>[29]</p>
<p>[30]  attention. In NIPS, 2006. L. Itti, C. Koch, and E. Niebur. A model of saliencybased visual attention for rapid scene analysis. PAMI, 20(1 1): 1254–1259, 1998. T. Judd, K. Ehinger, F. Durand, and A. Torralba. Learning to predict where humans look. In CVPR, 2009. W. Kienzle, F. Wichmann, B. Sch o¨lkopf, and M. Franz. A nonparametric approach to bottom-up visual saliency. In NIPS, 2007. R. Kimchi and M. A. Peterson. Figure-ground segmentation can occur without attention. Psychological Science, 19(7):660–668, 2008. K. Koffka. Principles of Gestalt psychology. 1935. G. Kootstra, A. Nederveen, and B. De Boer. Paying attention to symmetry. In BMCV, 2008. G. Kootstra and L. Schomaker. Prediction of human eye fixations using symmetry. In Proc. of the 31st Annual Conf. of the Cognitive Science Society (CogSci09), 2009. Z. Kourtzi and N. Kanwisher. Representation of perceived object shape by the human lateral occipital complex. Science, 293(5534):1506–1509, 2001. J. Li, M. D. Levine, X. An, X. Xu, and H. He. Visual saliency based on scale-space analysis in the frequency domain. PAMI, 35(4), 2013. V. Mahadevan and N. Vasconcelos. Saliency-based discriminant tracking. In CVPR, 2009. V. Mazza, M. Turatto, and C. Umilta. Foreground– background segmentation and attention: A change blindness study. Psychological Research, 69(3):201–210, 2005. S. E. Palmer. Vision science: Photons to phenomenology. The MIT press, 1999.  [3 1] E. Rubin. Figure and ground. Readings in Perception, pages 194–203, 1958.</p>
<p>[32] U. Rutishauser, D. Walther, C. Koch, and P. Perona. Is bottom-up attention useful for object recognition? In CVPR, 2004.</p>
<p>[33] B. Schauerte and R. Stiefelhagen. Quaternion-based spectral saliency detection for eye fixation prediction. In ECCV, 2012.</p>
<p>[34] B. Tatler, R. Baddeley, I. Gilchrist, et al. Visual correlates of fixation selection: Effects of scale and time. Vision Research, 45(5):643–659, 2005.</p>
<p>[35] L. Vincent. Morphological grayscale reconstruction in image analysis: Applications and efficient algorithms. TIP, 2(2), 1993.</p>
<p>[36] Y. Wei, F. Wen, W. Zhu, and J. Sun. Geodesic saliency using background priors. In ECCV, 2012.</p>
<p>[37] J. Wolfe and T. Horowitz. What attributes guide the deployment ofvisual attention and how do they do it? Nature Reviews Neuroscience, 5(6):495–501, 2004.</p>
<p>[38] Q. Yan, L. Xu, J. Shi, and J. Jia. Hierarchical saliency detection. In CVPR, 2013.</p>
<p>[39] L. Zhang, M. Tong, T. Marks, H. Shan, and G. Cottrell. Sun: A bayesian framework for saliency using natural statistics. Journal of Vision, 8(7), 2008. 160</p>
<br/>
<br/><br/><br/></body>
</html>
