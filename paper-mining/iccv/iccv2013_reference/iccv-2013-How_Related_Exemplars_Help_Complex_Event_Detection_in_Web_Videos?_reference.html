<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>203 iccv-2013-How Related Exemplars Help Complex Event Detection in Web Videos?</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-203" href="../iccv2013/iccv-2013-How_Related_Exemplars_Help_Complex_Event_Detection_in_Web_Videos%3F.html">iccv2013-203</a> <a title="iccv-2013-203-reference" href="#">iccv2013-203-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>203 iccv-2013-How Related Exemplars Help Complex Event Detection in Web Videos?</h1>
<br/><p>Source: <a title="iccv-2013-203-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Yang_How_Related_Exemplars_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yi Yang, Zhigang Ma, Zhongwen Xu, Shuicheng Yan, Alexander G. Hauptmann</p><p>Abstract: Compared to visual concepts such as actions, scenes and objects, complex event is a higher level abstraction of longer video sequences. For example, a “marriage proposal” event is described by multiple objects (e.g., ring, faces), scenes (e.g., in a restaurant, outdoor) and actions (e.g., kneeling down). The positive exemplars which exactly convey the precise semantic of an event are hard to obtain. It would be beneficial to utilize the related exemplars for complex event detection. However, the semantic correlations between related exemplars and the target event vary substantially as relatedness assessment is subjective. Two related exemplars can be about completely different events, e.g., in the TRECVID MED dataset, both bicycle riding and equestrianism are labeled as related to “attempting a bike trick” event. To tackle the subjectiveness of human assessment, our algorithm automatically evaluates how positive the related exemplars are for the detection of an event and uses them on an exemplar-specific basis. Experiments demonstrate that our algorithm is able to utilize related exemplars adaptively, and the algorithm gains good perform- z. ance for complex event detection.</p><br/>
<h2>reference text</h2><p>[1] Z. Akata, F. Perronnin, Z. Harchaoui, C. Schmid, et al. Label-embedding for attribute-based classification. In CVPR, 2013.</p>
<p>[2] C. Cabrera, R. Sastre, J. Rodr, and S. Bas. Surfing the point clouds: Selective 3D spatial pyramids for category-level object recognition. ICCV, 2011.</p>
<p>[3] M. Chen and A. Hauptmann. Mosift: Reocgnizing human actions in surveillance videos. Technical Report: CMU-CS-</p>
<p>[4]</p>
<p>[5]</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]  09-161, 2009. L. Fei-Fei, R. Fergus, and P. Perona. One-shot learning of object categories. TPAMI, 28(4):594–61 1, 2006. G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. Labeled faces in the wild: A database for studying face recognition in unconstrained environments. Technical Report 07-49, University of Massachusetts, October 2007. H. Izadinia and M. Shah. Recognizing complex events using large margin joint low-level event model. ECCV, 2012. Z. Kang, K. Grauman, and F. Sha. Learning with whom to share in multi-task feature learning. In ICML, 2011. I. Laptev, M. Marszalek, C. Schmid, and B. Rozenfeld. Learning realistic human actions from movies. In CVPR, 2008. Z. Ma, Y. Yang, Y. Cai, N. Sebe, and A. Hauptmann. Knowledge adaptation for ad hoc multimedia event detection with few examplars. ACM Multimedia, 2012. Z. Ma, Y. Yang, Z. Xu, S. Yan, N. Sebe, and A. Hauptmann. Complex event detection via multi-source video attributes. CVPR, 2013. P. Natarajan, P. Natarajan, A. Vazquez-Reina, S. Vitaladevuni, C. Andersen, R. Prasad, S.-F. Chang, I. Saleemi, M. Shah, Y. Ng, B. White, L. Davis, A. Gupta, and I. Haritaoglu. BBN VISER TRECVID 2012 Multimedia Event Detection and Multimedia Event Recounting Systems. In TRECVID Workshop, 2012. P. Natarajan, S. Wu, S. Vitaladevuni, U. Park, R. Prasad, and P. Natarajan. Multimodal feature fusion for robust event detection in web videos. CVPR, 2012. K. Sande, T. Gevers, and C. Snoek. Evaluating color descriptors for object and scene recognition. TPAMI,</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]  32(9):1582–1596, 2010. A. Tamrakar, S. Ali, Q. Yu, J. Liu, O. Javed, A. Divakaran, H. Cheng, and H. Sawhney. Evaluation of low-level features and their combinations for complex event detection in open source video. CVPR, 2012. H. Wang, A. Klaser, C. Schmid, and C. Liu. Action recognition by dense trajectories. In CVPR, 2011. H. Wang, M. Ullah, A. Klaser, I. Laptev, C. Schmid, et al. Evaluation of local spatio-temporal features for action recognition. In BMVC, 2009. S. Wang, Y. Yang, Z. Ma, X. Li, C. Pang, and A. Hauptmann. Action recognition by exploring data distribution and feature correlation. CVPR, 2012. Z. Xu, Y. Yang, I. Tsang, N. Sebe, and A. Hauptmann. Feature weighting via optimal thresholding for video analysis. In ICCV, 2013. Y. Yang, Z. Ma, A. Hauptmann, and N. Sebe. Feature selection for multimedia analysis by sharing information among multiple tasks. TMM, 3(15):661–669, 2013. S. Yu, Z. Xu, D. Ding, et al. Informedia e-lamp @ TRECVID 2012, multimedia event detection and recounting. TRECVID Workshop, 2012. 2111</p>
<br/>
<br/><br/><br/></body>
</html>
