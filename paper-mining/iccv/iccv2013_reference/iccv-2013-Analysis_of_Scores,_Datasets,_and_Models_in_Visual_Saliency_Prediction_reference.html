<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>50 iccv-2013-Analysis of Scores, Datasets, and Models in Visual Saliency Prediction</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-50" href="../iccv2013/iccv-2013-Analysis_of_Scores%2C_Datasets%2C_and_Models_in_Visual_Saliency_Prediction.html">iccv2013-50</a> <a title="iccv-2013-50-reference" href="#">iccv2013-50-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>50 iccv-2013-Analysis of Scores, Datasets, and Models in Visual Saliency Prediction</h1>
<br/><p>Source: <a title="iccv-2013-50-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Borji_Analysis_of_Scores_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Ali Borji, Hamed R. Tavakoli, Dicky N. Sihite, Laurent Itti</p><p>Abstract: Significant recent progress has been made in developing high-quality saliency models. However, less effort has been undertaken on fair assessment of these models, over large standardized datasets and correctly addressing confounding factors. In this study, we pursue a critical and quantitative look at challenges (e.g., center-bias, map smoothing) in saliency modeling and the way they affect model accuracy. We quantitatively compare 32 state-of-the-art models (using the shuffled AUC score to discount center-bias) on 4 benchmark eye movement datasets, for prediction of human fixation locations and scanpath sequence. We also account for the role of map smoothing. We find that, although model rankings vary, some (e.g., AWS, LG, AIM, and HouNIPS) consistently outperform other models over all datasets. Some models work well for prediction of both fixation locations and scanpath sequence (e.g., Judd, GBVS). Our results show low prediction accuracy for models over emotional stimuli from the NUSEF dataset. Our last benchmark, for the first time, gauges the ability of models to decode the stimulus category from statistics of fixations, saccades, and model saliency values at fixated locations. In this test, ITTI and AIM models win over other models. Our benchmark provides a comprehensive high-level picture of the strengths and weaknesses of many popular models, and suggests future research directions in saliency modeling.</p><br/>
<h2>reference text</h2><p>[1] A. Borji and L. Itti. State-of-the-art in Visual Attention Modeling. PAMI, 2013.</p>
<p>[2] T. Judd, K. Ehinger, F. Durand and, A. Torralba. Learning to predict where humans look. ICCV, 2009.</p>
<p>[3] L. Itti, C. Koch, and E. Niebur. A model of saliency-based visual attention for rapid scene analysis. IEEE Trans. PAMI, 20(1 1): 1254-1259, 1998.</p>
<p>[4] R. Subramanian, H. Katti, N. Sebe, M. Kankanhalli, and T.S. Chua. An eye fixation database for saliency detection in images. ECCV, 2010.</p>
<p>[5] C. Koch and S. Ullman. Shifts in selective visual attention: Towards the underlying neural circuitry. Human Neurobiology, 1985.</p>
<p>[6] S. Frintrop. VOCUS: A visual attention system for object detection and goaldirected search. PhD Thesis. Springer 2006.</p>
<p>[7] J. Harel, C. Koch, and P. Perona. Graph-based visual saliency. NIPS, 2006.</p>
<p>[8] G. Kootstra, A. Nederveen, and B. de Boer. Paying attention to symmetry. British Machine Vision Conference, 2008.</p>
<p>[9] L. Itti and P. Baldi. Bayesian surprise attracts human attention. NIPS, 2005.</p>
<p>[10] N.D.B. Bruce and J.K. Tsotsos. Saliency based on information maximization. Advances in Neural Information Processing Systems (NIPS), 2005.</p>
<p>[11] X. Hou and L. Zhang. Saliency detection: A spectral residual approach. Computer Vision and Pattern Recognition (CVPR), 2007.</p>
<p>[12] X. Hou and L. Zhang. Dynamic visual attention: Searching for coding length increments. NIPS, 2008.</p>
<p>[13] M. Mancas. Computational attention: Modelisation and application to audio and image processing. PhD. thesis, 2007.</p>
<p>[14] T. Avraham, M. Lindenbaum. Esaliency (Extended Saliency): Meaningful</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]</p>
<p>[29]</p>
<p>[30]  [3 1]</p>
<p>[32]  attention using stochastic image modeling. PAMI, 2010. C. Guo and L. Zhang. A novel multiresolution spatiotemporal saliency detection model and Its applications in image and video compression. IEEE Trans. on Image Processing, 2010. P. Bian and L. Zhang. Biological plausibility of spectral domain approach for spatiotemporal visual saliency. LNCS, 2009. A. Garcia-Diaz, X. R. Fdez-Vidal, X. M. Pardo, and R. Dosil. Decorrelation and distinctiveness provide with human-like saliency. ACIVS, 5807, 2009. Y. Li, Y. Zhou, J. Yan, and J. Yang. Visual saliency based on conditional entropy. ACCV, 2009. J. Yan, J. Liu, Y. Li, and Y. Liu. Visual saliency via sparsity rank decomposition. ICIP, 2010. A. Torralba. Modeling global scene factors in attention. Journal of Optical Society of America, 20(7), 2003. O. Le Meur, P. Le Callet, and D. Barba. Predicting visual fixations on video based on low-level visual features. Vision Research, 47(19), 2007. H.J. Seo and P. Milanfar. Static and space-time visual saliency detection by self-resemblance. Journal of Vision, 9: 1-27, 2009. S. Marat, T. Ho-Phuoc, L. Granjon, N. Guyader, D. Pellerin, and A. Gu´ erinDugu e´. Modeling saliency to predict gaze direction for short videos. IJCV, 2009. D. Walther and C. Koch. Modeling attention to salient proto-objects. Neural Networks, 19(9): 1395-1407, 2006.  992288 L. Zhang, M. H. Tong, T. K. Marks, H. Shan, and G. W. Cottrell, SUN: A Bayesian framework for saliency using natural statistics. JOV, 2008. J. Li, Y. Tian, T. Huang, and W. Gao. Probabilistic multi-task learning for visual saliency estimation in video. IJCV, 90(2): 150-165, 2010. A.M. Treisman and G. Gelade. A feature integration theory of attention. Cognitive Psych., 12:97-136, 1980. B.W. Tatler. The central fixation bias in scene viewing: selecting an optimal viewing position independently of motor bases and image feature distributions. J. Vision, 14(7): 2007. O. Le Meur and T. Baccino. Methods for comparing scanpaths and saliency maps: strengths and weaknesses. Behavioral Research, 2012. A. Borji, D. N. Sihite, and L. Itti. Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study. IEEE Transactions on Image Processing, 2012. D. Noton and L. Stark. Scanpaths in Saccadic Eye Movements While Viewing and Recognizing Patterns. Vision Research, 11, 929-942, 1971 C.M. Privitera and L. Stark. Algorithms for defining visual regions-of-interest: comparison with eye fixations. PAMI, 2000.</p>
<p>[33] L. Itti, L. and C. Koch. A saliency-based search mechanism for overt and covert shifts of visual attention. Vision research, 40, 2000.</p>
<p>[34] H.R. Tavakoli, E. Rahtu, and J. Heikkil a¨. Fast and efficient saliency detection using sparse sampling and kernel density estimation. SCIA, 2011.</p>
<p>[35] M. Cerf, J. Harel, W. Einh a¨user, and C. Koch. Predicting human gaze using low-level saliency combined with face detection. NIPS, 2007.</p>
<p>[36] Q. Zhao and C. Koch. Learning a saliency map using fixated locations in natural scenes. Journal of Vision, 11(3), 201 1.</p>
<p>[37] D. Gao, S. Han, and N. Vasconcelos. Discriminant saliency, the detection of suspicious coincidences and applications to visual recognition. PAMI, 2009.</p>
<p>[38] A. Borji and L. Itti. Exploiting Local and Global Patch Rarities for Saliency Detection. CVPR, 2012.</p>
<p>[39] A. Borji, Boosting Bottom-up and Top-down Visual Features for Saliency Estimation, CVPR, 2012.</p>
<p>[40] J. B. Huang and N. Ahuja, Saliency Detection via Divergence Analysis: A Unified Perspective, ICPR, 2012.</p>
<p>[41] T. Judd, F. Durand, and A. Torralba. A Benchmark of Computational Models of Saliency to Predict Human Fixations. MIT technical report, 2012.</p>
<p>[42] T. Ho-Phuoc, L. Alacoque, A. Dupret, A. Guerin-Dugue, and A. Verdant. A unified method for comparison of algorithms of saliency extraction, SPIE, 2012.</p>
<p>[43] X. Hou, J. Harel, and C. Koch. Image Signature: Highlighting Sparse Salient Regions. PAMI, 2012.</p>
<p>[44] L. Elazary and L. Itti, Interesting objects are visually salient, J. Vision, 2008.</p>
<p>[45] K. Humphrey, G. Underwood, and T. Lambert. Salience of the lambs: A test of the saliency map hypothesis with pictures of emotive objects, J. of vision, 2012.</p>
<p>[46] P. Lang, , M. Bradley, and B. Cuthbert. (iaps): Affective ratings of pictures and instruction manual. Technical report, University of Florida, 2008.</p>
<p>[47] N. Murray, M. Vanrell, X. Otazu, and C. A. Parraga. Saliency Estimation Using a Non-Parametric Low-Level Vision Model. CVPR, 2011.</p>
<p>[48] M. Spain and P. Perona. Measuring and predicting object importance. International Journal of Computer Vision, 2010.</p>
<p>[49] A. Khosla, J. Xiao, A. Torralba, and A. Oliva. Memorability of Image Regions. NIPS, 2012.</p>
<p>[50] W. Einh a¨user, M. Spain, and P. Perona. Objects Predict Fixations Better Than Early Saliency. Journal of Vision, 2008. [5 1] R.J. Peters, A. Iyer, L. Itti, C. Koch. Components of bottom-up gaze allocation in natural images. Vision Research, 2005.</p>
<p>[52] M.S. Gide and L.J. Karam. Comparative evaluation of visual saliency models for quality assessment task, 6th Int. Workshop on Video Processing, 2012.</p>
<p>[53] S.B. Needleman, C.D. Wunsch. A general method applicable to the search for similarities in the amino acid sequence oftwo proteins. MolecularBiology, 1970.</p>
<p>[54] A. Borji, D. N. Sihite, and L. Itti. Probabilistic Learning of Task-Specific</p>
<p>[55]</p>
<p>[56]</p>
<p>[57]</p>
<p>[58]</p>
<p>[59]</p>
<p>[60]</p>
<p>[61]</p>
<p>[62]</p>
<p>[63]  Visual Attention, CVPR, 2012. S. Winkler and R. Subramanian, Overview of Eye tracking Datasets, Quality of Multimedia Experience (QoMEX, 2013. U. Engelke, H. Liu, J. Wang, P. Le Callet, I. Heynderickx, H.J Zepernick, and A. Maeder, A Comparative Study of Fixation Density Maps, IEEE T. IP, 2013. M.R. Greene, T. Liu, J.M. Wolfe, Reconsidering Yarbus: A failure to predict observers’ task from eye movement patterns, Vision Research, 2012. J.B Huang and N. Ahuja, Saliency Detection via Divergence Analysis: A Unified Perspective, International Conference on Pattern Recognition, 2012. B. Schauerte and R. Stiefelhagen, Quaternion-based spectral saliency detection for eye fixation prediction, ECCV, 2012. E. Erdem and A. Erdem, Visual saliency estimation by nonlinearly integrating features using region covariances, Journal of Vision, 13:4, 1-20, 2013. A. Nuthmann and J. M. Henderson, Object-based attentional selection in scene viewing. Journal of Vision, 10(8):20, 1-19, 2010. A. Borji, D. N. Sihite, and L. Itti. Objects do not predict fixations better than early saliency: A re-analysis of Einh a¨user et al.’s data, Journal of Vision, 2013. A., Yarbus, Eye movements and vision.. New York: Plenum, 1967.</p>
<br/>
<br/><br/><br/></body>
</html>
