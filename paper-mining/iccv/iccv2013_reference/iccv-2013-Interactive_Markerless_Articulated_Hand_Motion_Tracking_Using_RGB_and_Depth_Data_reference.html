<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>218 iccv-2013-Interactive Markerless Articulated Hand Motion Tracking Using RGB and Depth Data</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-218" href="../iccv2013/iccv-2013-Interactive_Markerless_Articulated_Hand_Motion_Tracking_Using_RGB_and_Depth_Data.html">iccv2013-218</a> <a title="iccv-2013-218-reference" href="#">iccv2013-218-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>218 iccv-2013-Interactive Markerless Articulated Hand Motion Tracking Using RGB and Depth Data</h1>
<br/><p>Source: <a title="iccv-2013-218-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Sridhar_Interactive_Markerless_Articulated_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Srinath Sridhar, Antti Oulasvirta, Christian Theobalt</p><p>Abstract: Tracking the articulated 3D motion of the hand has important applications, for example, in human–computer interaction and teleoperation. We present a novel method that can capture a broad range of articulated hand motions at interactive rates. Our hybrid approach combines, in a voting scheme, a discriminative, part-based pose retrieval method with a generative pose estimation method based on local optimization. Color information from a multiview RGB camera setup along with a person-specific hand model are used by the generative method to find the pose that best explains the observed images. In parallel, our discriminative pose estimation method uses fingertips detected on depth data to estimate a complete or partial pose of the hand by adopting a part-based pose retrieval strategy. This part-based strategy helps reduce the search space drastically in comparison to a global pose retrieval strategy. Quantitative results show that our method achieves state-of-the-art accuracy on challenging sequences and a near-realtime performance of 10 fps on a desktop computer.</p><br/>
<h2>reference text</h2><p>[1] V. Athitsos and S. Sclaroff. Estimating 3D hand pose from a cluttered image. In Proc. CVPR, volume 2, pages II 432–9 vol.2, June 2003. 2 –</p>
<p>[2] A. Baak, M. Muller, G. Bharaj, H.-P. Seidel, and C. Theobalt. A data-driven approach for real-time full body pose reconstruction from a depth camera. In Proc. ICCV, pages 1092 –1099, Nov. 2011. 1, 3, 5</p>
<p>[3] L. Ballan, A. Taneja, J. Gall, L. Van Gool, and M. Pollefeys. Motion capture of hands in action using discriminative salient points. In Proc. ECCV, volume 7577, pages 640–653. Springer Berlin / Heidelberg, 2012. 2, 6</p>
<p>[4] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In Proc. CVPR, volume 1, pages 886–893. IEEE, 2005. 5</p>
<p>[5] A. Erol, G. Bebis, M. Nicolescu, R. D. Boyle, and X. Twombly. Vision-based hand pose estimation: A review. CVIU, 108(12):52–73, Oct. 2007. 2</p>
<p>[6] V. Ganapathi, C. Plagemann, D. Koller, and S. Thrun. Realtime human pose tracking from range data. In Proc. ECCV, volume 7577, pages 738–751. Berlin, Heidelberg, 2012. 3</p>
<p>[7] H. Hamer, J. Gall, T. Weise, and L. Van Gool. An objectdependent hand pose prior from sparse training data. In Proc. CVPR, pages 671–678, 2010. 2</p>
<p>[8] H. Hamer, K. Schindler, E. Koller-Meier, and L. Van Gool. Tracking a hand manipulating an object. In Proc. ICCV, pages 1475–1482, 2009. 2</p>
<p>[9] L. A. Jones and S. J. Lederman. Human Hand Function. Oxford University Press, USA, 1 edition, Apr. 2006. 1 1http : / /handtracker .mpi-inf .mpg .de 22446622  Figure 7. Qualitative results of our method as seen from two camera views. Results in (a), (b) show general slow motion. Results in (c) show successful tracking even in the presence of fast motion. Result (d) shows a failure case due to fast motion.</p>
<p>[10] C. Keskin, F. Kra ¸c, Y. E. Kara, and L. Akarun. Hand pose estimation and hand shape classification using multi-layered randomized decision forests. In Proc. ECCV, pages 852– 863. Springer Berlin Heidelberg, 2012. 2</p>
<p>[11] J. Lin, Y. Wu, and T. Huang. Modeling the constraints of human hand motion. In Proc. HUMO, pages 121–126, 2000. 2</p>
<p>[12] J. MacCormick and M. Isard. Partitioned sampling, articulated objects, and interface-quality hand tracking. In Proc. ECCV, number 1843, pages 3–19. Jan. 2000. 2</p>
<p>[13] T. B. Moeslund, A. Hilton, and V. Krger. A survey of advances in vision-based human motion capture and analysis. CVIU, 104(23):90–126, Nov. 2006. 3</p>
<p>[14] I. Oikonomidis, N. Kyriazis, and A. Argyros. Efficient model-based 3D tracking of hand articulations using kinect. In Proc. BMVC, pages 101.1–101. 11, 2011. 2, 6</p>
<p>[15] I. Oikonomidis, N. Kyriazis, and A. Argyros. Full DOF tracking of a hand interacting with an object by modeling occlusions and physical constraints. In Proc. ICCV, pages</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]  2088–2095, 2011. 2, 6 C. Plagemann, V. Ganapathi, D. Koller, and S. Thrun. Realtime identification and localization of body parts from depth images. In Proc. ICRA, pages 3 108–3 113, May. 5 R. Poppe. Vision-based human motion analysis: An overview. CVIU, 108(12):4–18, Oct. 2007. 3 J. Rehg and T. Kanade. Visual tracking of high DOF articulated structures: An application to human hand tracking. In Proc. ECCV, volume 801, pages 35–46. Springer Berlin / Heidelberg, 1994. 2 J. Romero, H. Kjellstrom, and D. Kragic. Hands in action: real-time 3D reconstruction of hands in interaction with objects. In Proc. ICRA, pages 458–463, 2010. 2 J. Shotton, A. Fitzgibbon, M. Cook, T. Sharp, M. Finocchio, R. Moore, A. Kipman, and A. Blake. Real-time human pose recognition in parts from single depth images. In Proc. CVPR, pages 1297 –1304, June 2011. 3 E. Simo Serra. Kinematic Model of the Hand using Computer Vision. PhD thesis, Institut de Rob o`tica iInform` atica Industrial, 2011. 3 B. Stenger, A. Thayananthan, P. H. S. Torr, and R. Cipolla. Model-based hand tracking using a hierarchical bayesian filter. 28(9): 1372–1384, 2006. 2 C. Stoll, N. Hasler, J. Gall, H. Seidel, and C. Theobalt. Fast articulated motion tracking using a sums of gaussians body model. In Proc. ICCV, pages 951 –958, Nov. 2011. 2, 3, 4 R. Wang, S. Paris, and J. Popovi´ c. 6D hands: markerless hand-tracking for computer aided design. In Proc. ACM UIST, pages 549–558. ACM, 2011. 2 R. Y. Wang and J. Popovi´ c. Real-time hand-tracking with a color glove. ACM TOG (Proc. SIGGRAPH), (3):63: 163:8,</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]</p>
<p>[29]  July 2009. 1, 2, 5 X. Wei, P. Zhang, and J. Chai. Accurate realtime full-body motion capture using a single depth camera. ACM TOG (Proc. SIGGRAPH Asia), 31(6), Nov. 2012. 1, 3 H. Wendland. Piecewise polynomial, positive definite and compactly supported radial functions ofminimal degree. Adv Comput Math, 4(1):389–396, Dec. 1995. 4 Y. Wu, J. Lin, and T. Huang. Capturing natural hand articulation. In Proc. ICCV, pages 426 –432 vol.2, 2001 . 2 M. Ye, X. Wang, R. Yang, L. Ren, and M. Pollefeys. Accurate 3D pose estimation from a single depth image. In Proc. ICCV, pages 731–738, 2011. 1, 3 22446633</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
