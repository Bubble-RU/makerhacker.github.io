<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-450" href="../iccv2013/iccv-2013-What_is_the_Most_EfficientWay_to_Select_Nearest_Neighbor_Candidates_for_Fast_Approximate_Nearest_Neighbor_Search%3F.html">iccv2013-450</a> <a title="iccv-2013-450-reference" href="#">iccv2013-450-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>450 iccv-2013-What is the Most EfficientWay to Select Nearest Neighbor Candidates for Fast Approximate Nearest Neighbor Search?</h1>
<br/><p>Source: <a title="iccv-2013-450-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Iwamura_What_is_the_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Masakazu Iwamura, Tomokazu Sato, Koichi Kise</p><p>Abstract: Approximate nearest neighbor search (ANNS) is a basic and important technique used in many tasks such as object recognition. It involves two processes: selecting nearest neighbor candidates and performing a brute-force search of these candidates. Only the former though has scope for improvement. In most existing methods, it approximates the space by quantization. It then calculates all the distances between the query and all the quantized values (e.g., clusters or bit sequences), and selects a fixed number of candidates close to the query. The performance of the method is evaluated based on accuracy as a function of the number of candidates. This evaluation seems rational but poses a serious problem; it ignores the computational cost of the process of selection. In this paper, we propose a new ANNS method that takes into account costs in the selection process. Whereas existing methods employ computationally expensive techniques such as comparative sort and heap, the proposed method does not. This realizes a significantly more efficient search. We have succeeded in reducing computation times by one-third compared with the state-of-the- art on an experiment using 100 million SIFT features.</p><br/>
<h2>reference text</h2><p>[1] A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In Proc.</p>
<p>[2]</p>
<p>[3]</p>
<p>[4]</p>
<p>[5]</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]  FOCS, 2006. 2 A. Babenko and V. Lempitsky. The inverted multi-index. In Proc. CVPR, 2012. 1, 2, 3, 6 J. Brandt. Transform coding for fast approximate nearest neighbor search in high dimensions. In Proc. CVPR, 2010. 2, 6 M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based on 푝-stable distributions. In Proc. 20th annual symposium on Computational geometry, 2004. 2, 6 A. Gersho and R. Gray. Vector Quantization and Signal Compression. Kluwer Acadmic Publishers, 1992. 3 Y. Gong and S. Lazebnik. Iterative quantization: A procrustean approach to learning binary codes. In Proc. CVPR, 2011. 2 Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. IEEE Trans. PAMI, 2012. 2 P. Indyk and R. Motwani. Approximate nearest neighbor: towards removing the curse of dimensionality. In Proc. 30th Symposium on Theory of Computing, 1998. 2 M. Iwamura, T. Kobayashi, and K. Kise. Recognition of multiple characters in a scene image using arrangement of local features. In Proc. ICDAR, 2011. 1 M. Iwamura, T. Tsuji, and K. Kise. Memory-based recognition of camera-captured characters. In Proc. DAS, 2010. 33553414  aRe][cl%1 28701536940 0 1IVFBAD1M0HCI1 0 1 0 0[laceR]%1 09876543210 0 1IVFAB0DMCHI10 10 0 1e+6 Rle]ac%[1 28709564310 0 1IVFBAD1M0HCI1 0 1 0 0[laceR]%1 09876543210 0 1IVFABD0MCHI10 10 0 1e+6 Number of candidates [%] (a) SIFT 1M  Number of candidates [%] (b) SIFT 10M  Number of candidates [%] (d) GIST 100K  Number of candidates [%] (e) GIST 1M  [al%Rce]1 2346871509 0 1IVFBAD0MHCI10 10 01e+6 Number of candidates [%] (c) SIFT 100M  [al%Rce]1 2346871509 0 01IVFBA1ID0MHCI10 10 0 1e+06 Number of candidates [%]  (f) GIST 10M Figure 6: Experiment 2: Recall vs Number of candidates.</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]  1 H. J ´egou, M. Douze, and C. Schmid. Packing bag-offeatures. In Proc. ICCV, 2009. 1 H. J ´egou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE Trans. PAMI, 33(1): 117 –128, 2011. 1, 2, 6 Y. Ke, R. Sukthankar, and L. Huston. Efficient near-duplicate detection and sub-image retrieval. In Proc. ACMMultimedia, 2004. 1 K. Kise, K. Noguchi, and M. Iwamura. Robust and efficient recognition of low-quality images by cascaded recognizers</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]  with massive local features. In Proc. WS-LAVD, 2009. 1 W. Kong and W.-J. Li. Isotropic hashing. In Proc. NIPS, 2012. 2 B. Kulis and T. Darrell. Learning to hash with binary reconstructive embeddings. In Proc. NIPS, 2009. 2 R.-S. Lin, D. A. Ross, and J. Yagnik. SPEC hashing: Similarity preserving algorithm for entropy-based coding. In Proc. CVPR, 2010. 2 D. G. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2), 2004. 6 Q. Lv, W. Josephson, Z. Wang, M. Charikar, and K. Li. Multi-probe LSH: efficient indexing for high-dimensional similarity search. In Proc. VLDB, 2007. 2 M. Muja and D. G. Lowe. Fast approximate nearest neighbors with automatic algorithm configuration. In Proc. VISSAPP. INSTICC Press, 2009. 1, 2, 6 D. Nist e´r and H. Stew e´nius. Scalable recognition with a vocabulary tree. In Proc. CVPR, 2006. 1, 2, 6 M. Norouzi and D. J. Fleet. Minimal loss hashing for compact binary codes. In Proc. ICML, 2011. 2 A. Oliva and A. Torralba. Modeling the shape of the scene: A holistic representation of the spatial envelope. IJCV, 42, 2001. 6 C. Silpa-Anan and R. Hartley. Optimised kd-trees for fast image descriptor matching. In Proc. CVPR, 2008. 2, 6 K. Takeda, K. Kise, and M. Iwamura. Memory reduction for real-time document image retrieval with a 20 million pages database. In Proc. CBDAR, 2011. 1 A. Torralba, R. Fergus, and W. T. Freeman. 80 million tiny images: a large dataset for non-parametric object and scene</p>
<p>[27]</p>
<p>[28]</p>
<p>[29]</p>
<p>[30]  [3 1]  recognition. IEEE Trans. PAMI, 30(1 1): 1958–1970, 2008. 1 E. Tuncel, H. Ferhatosmanoglu, and K. Rose. VQ-index: an index structure for similarity searching in multimedia databases. In Proc. ACM Multimedia, 2002. 2 Y. Weiss, R. Fergus, and A. Torralba. Multidimensional spectral hashing. In Proc. ECCV, Part V (LNCS 7576), 2012. 2 Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In Proc. NIPS, 2008. 2, 6 H. Xu, J. Wang, Z. Li, G. Zeng, S. Li, and N. Yu. Complementary hashing for approximate nearest neighbor search. In Proc. ICCV, 2011. 2 L. Zhang, Y. Zhang, J. Tang, K. Lu, and Q. Tian. Binary code ranking with weighted hamming distance. In Proc. CVPR, 2013. 2 33553425</p>
<br/>
<br/><br/><br/></body>
</html>
