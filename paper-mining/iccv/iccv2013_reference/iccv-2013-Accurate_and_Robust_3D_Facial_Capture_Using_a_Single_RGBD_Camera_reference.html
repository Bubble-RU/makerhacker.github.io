<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-36" href="../iccv2013/iccv-2013-Accurate_and_Robust_3D_Facial_Capture_Using_a_Single_RGBD_Camera.html">iccv2013-36</a> <a title="iccv-2013-36-reference" href="#">iccv2013-36-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>36 iccv-2013-Accurate and Robust 3D Facial Capture Using a Single RGBD Camera</h1>
<br/><p>Source: <a title="iccv-2013-36-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Chen_Accurate_and_Robust_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Yen-Lin Chen, Hsiang-Tao Wu, Fuhao Shi, Xin Tong, Jinxiang Chai</p><p>Abstract: This paper presents an automatic and robust approach that accurately captures high-quality 3D facial performances using a single RGBD camera. The key of our approach is to combine the power of automatic facial feature detection and image-based 3D nonrigid registration techniques for 3D facial reconstruction. In particular, we develop a robust and accurate image-based nonrigid registration algorithm that incrementally deforms a 3D template mesh model to best match observed depth image data and important facial features detected from single RGBD images. The whole process is fully automatic and robust because it is based on single frame facial registration framework. The system is flexible because it does not require any strong 3D facial priors such as blendshape models. We demonstrate the power of our approach by capturing a wide range of 3D facial expressions using a single RGBD camera and achieve state-of-the-art accuracy by comparing against alternative methods.</p><br/>
<h2>reference text</h2><p>[1] S. Baker and I. Matthews. Lucas-kanade 20 years on: A unifying framework. International Journal of Computer Vision, 2004. 56(3):221–255. 1, 4, 5, 6</p>
<p>[2] B. Bickel, M. Botsch, R. Angst, W. Matusik, M. Otaduy, H. Pfister, and M. Gross. Multi-scale capture of facial geometry and motion. ACM Trans. Graph., 26(3):33: 1–33: 10, 2007. 2</p>
<p>[3] V. Blanz, C. Basso, T. Poggio, and T. Vetter. Reanimating faces in images and video. In Computer Graphics Forum, 2003. 22(3):641–650. 2</p>
<p>[4] M. Breidt, H. Biilthoff, and C. Curio. Robust semantic analysis by synthesis of 3d facial motion. In Automatic Face & Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on, pages 713–719. IEEE, 2011. 2</p>
<p>[5] Q. Cai, D. Gallup, C. Zhang, and Z. Zhang. 3d deformable face tracking with a commodity depth camera. pages 229– 242, 2010. 2, 7</p>
<p>[6] D. DeCarlo and D. Metaxas. Optical flow constraints on deformable models with applications to face tracking. International Journal of Computer Vision, 2000. 38(2):99-127. 2</p>
<p>[7] I. Essa, S. Basu, T. Darrell, and A. Pentland. Modeling, tracking and interactive animation of faces and heads using input from video. In Proceedings of Computer Animation Conference. 1996. 68-79. 2</p>
<p>[8] faceshift. http://www.faceshift.com/, 2013. 7</p>
<p>[9] B. Guenter, C. Grimm, D. Wood, H. Malvar, and F. Pighin. Making Faces. In Proceedings of ACM SIGGRAPH 1998, pages 55–66, 1998. 2</p>
<p>[10] H. Huang, J. Chai, X. Tong, and H.-T. Wu. Leveraging motion capture and 3d scanning for high-fidelity facial performance acquisition. ACM Trans. Graph. , 30(4):74: 1–74: 10, 2011. 2, 6, 7</p>
<p>[11] Kinect for Windows SDK. http://msdn.microsoft.com/enus/library/jj130970.aspx/, 2013. 1, 7</p>
<p>[12] H. Li, B. Adams, L. J. Guibas, and M. Pauly. Robust singleview geometry and motion reconstruction. ACM Trans. Graph., 28(5):175: 1–175: 10, 2009. 2, 7</p>
<p>[13] W.-C. Ma, A. Jones, J.-Y. Chiang, T. Hawkins, S. Frederiksen, P. Peers, M. Vukovic, M. Ouhyoung, and P. Debevec. Facial performance synthesis using deformationdriven polynomial displacement maps. ACM Trans. Graph., 27(5): 121: 1–121 :10, 2008. 2</p>
<p>[14] F. Pighin, R. Szeliski, and D. Salesin. Resynthesizing facial animation through 3D model-based tracking. In Inter-</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]  national Conference on Computer Vision. 1999. 143–150. 2 F. Shi and J. Chai. Fast and accurate facial alignment from a single rgbd image. In Computer Science and Engineering Technical Reports 2013, Texas A&M; University. 2013. 3 R. W. Sumner, J. Schmid, and M. Pauly. Embedded deformation for shape manipulation. ACM Trans. Graph., 26(3):80:1–80:7, 2007. 1, 3, 4 R. W. Sumner, M. Zwicker, C. Gotsman, and J. Popovi´ c. Mesh-based inverse kinematics. ACM Trans. Graph., 24(3):488–495, July 2005. 5 Vicon Systems. http://www.vicon.com, 2013. 1, 6 D. Vlasic, M. Brand, H. Pfister, and J. Popovi´ c. Face transfer with multilinear models. ACM Transactions on Graphics, 24(3):426–433, 2005. 2 T. Weise, S. Bouaziz, H. Li, and M. Pauly. Realtime performance-based facial animation. ACM Trans. Graph., 30(4):77: 1–77: 10, 2011. 1, 2, 7, 8 T. Weise, H. Li, L. Van Gool, and M. Pauly. Face/off: live facial puppetry. In Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA ’09, pages 7–16, New York, NY, USA, 2009. ACM. 2 L. Zhang, N. Snavely, B. Curless, and S. Seitz. Spacetime faces: high resolution capture for modeling and animation. ACM Transactions on Graphics, 23(3):548–558, 2004. 2 33661225</p>
<br/>
<br/><br/><br/></body>
</html>
