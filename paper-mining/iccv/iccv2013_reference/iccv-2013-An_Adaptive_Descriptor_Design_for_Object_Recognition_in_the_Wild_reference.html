<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-48" href="../iccv2013/iccv-2013-An_Adaptive_Descriptor_Design_for_Object_Recognition_in_the_Wild.html">iccv2013-48</a> <a title="iccv-2013-48-reference" href="#">iccv2013-48-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>48 iccv-2013-An Adaptive Descriptor Design for Object Recognition in the Wild</h1>
<br/><p>Source: <a title="iccv-2013-48-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Guo_An_Adaptive_Descriptor_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Zhenyu Guo, Z. Jane Wang</p><p>Abstract: Digital images nowadays show large appearance variabilities on picture styles, in terms of color tone, contrast, vignetting, and etc. These ‘picture styles’ are directly related to the scene radiance, image pipeline of the camera, and post processing functions (e.g., photography effect filters). Due to the complexity and nonlinearity of these factors, popular gradient-based image descriptors generally are not invariant to different picture styles, which could degrade the performance for object recognition. Given that images shared online or created by individual users are taken with a wide range of devices and may be processed by various post processing functions, to find a robust object recognition system is useful and challenging. In this paper, we investigate the influence of picture styles on object recognition by making a connection between image descriptors and a pixel mapping function g, and accordingly propose an adaptive approach based on a g-incorporated kernel descriptor and multiple kernel learning, without estimating or specifying the image styles used in training and testing. We conduct experiments on the Domain Adaptation data set, the Oxford Flower data set, and several variants of the Flower data set by introducing popular photography effects through post-processing. The results demonstrate that theproposedmethod consistently yields recognition improvements over standard descriptors in all studied cases.</p><br/>
<h2>reference text</h2><p>[1] H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. Speeded-up robust features (surf). Computer vision and image understanding, 110(3):346–359, 2008.</p>
<p>[2] L. Bo, X. Ren, and D. Fox. Kernel descriptors for visual recognition. Advances in Neural Information Processing Systems (NIPS), 7, 2010.</p>
<p>[3] L. Bo and C. Sminchisescu. Efficient match kernel between sets of features for visual recognition. Advances in neural information processing systems (NIPS), 2(3), 2009.</p>
<p>[4] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In IEEE Conference onComputer Vision and Pattern Recognition (CVPR), volume 1, pages 886–893. IEEE, 2005.</p>
<p>[5] L. Fei-Fei, R. Fergus, and P. Perona. One-shot learning of object categories. IEEE Transactions on Pattern Analysis and Machine Intelligence, 28(4):594–61 1, 2006.</p>
<p>[6] P. Gehler and S. Nowozin. On feature combination for multiclass object classification. In IEEE International Conference on Computer Vision (ICCV), pages 221–228. IEEE, 2009.</p>
<p>[7] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic flow kernel for unsupervised domain adaptation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]  pages 2066–2073. IEEE, 2012. R. Gopalan, R. Li, and R. Chellappa. Domain adaptation for object recognition: An unsupervised approach. In IEEE International Conference on Computer Vision (ICCV), pages 999–1006. IEEE, 2011. M. D. Grossberg and S. K. Nayar. Modeling the space of camera response functions. IEEE Transactions on Pattern Analysis and Machine Intelligence, 26(10): 1272–1282, 2004. Z. Guo and Z. Wang. Cross-domain object recognition via input-output kernel analysis. IEEE transactions on image processing, 22(8):3108–31 19, 2013. I.-H. Jhuo, D. Liu, D. Lee, and S.-F. Chang. Robust visual domain adaptation with low-rank reconstruction. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2168–2175. IEEE, 2012. S. Kim, H. Lin, Z. Lu, S. Susstrunk, S. Lin, and M. Brown. A new in-camera imaging model for color computer vision and its application. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012. B. Kulis, K. Saenko, and T. Darrell. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1785–1792. IEEE, 2011. S. Lazebnik, C. Schmid, and J. Ponce. Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 2, pages 2169– 2178. IEEE, 2006. H. Ling and D. W. Jacobs. Deformation invariant image matching. In IEEE International Conference on Computer</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]  Vision (ICCV), volume 2, pages 1466–1473. IEEE, 2005. D. G. Lowe. Distinctive image features from scaleinvariant keypoints. International journal of computer vision, 60(2):91–1 10, 2004. F. Moreno-Noguer. Deformation and illumination invariant feature point descriptor. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1593–1600. IEEE, 2011. M.-E. Nilsback and A. Zisserman. A visual vocabulary for flower classification. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 2, pages 1447–1454. IEEE, 2006. K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In European Conference on Computer Vision (ECCV), pages 213–226. Springer, 2010. K. Simonyan, A. Vedaldi, and A. Zisserman. Descriptor learning using convex optimisation. In European Conference on Computer Vision ECCV, pages 243–256. Springer, 2012. E. Tola, V. Lepetit, and P. Fua. Daisy: An efficient dense descriptor applied to wide-baseline stereo. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(5):815– 830, 2010. M. Varma and B. R. Babu. More generality in efficient multiple kernel learning. In International Conference on Machine Learning (ICML), pages 1065–1072. ACM, 2009. C. Wah, S. Branson, P. Perona, and S. Belongie. Multiclass recognition and part localization with humans in the loop. In IEEE International Conference on Computer Vision (ICCV), pages 2524–2531. IEEE, 2011. S. Winder, G. Hua, and M. Brown. Picking the best daisy. In  IEEE Conference onComputer Vision and Pattern Recognition (CVPR), pages 178–185. IEEE, 2009.</p>
<p>[25] S. A. Winder and M. Brown. Learning local image descriptors. In Computer Vision and Pattern Recognition, 2007. CVPR’07. IEEE Conference on, pages 1–8. IEEE, 2007.</p>
<p>[26] Y. Xiong, K. Saenko, T. Darrell, and T. Zickler. From pixels to physics: Probabilistic color de-rendering. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 358–365. IEEE, 2012. 22557755</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
