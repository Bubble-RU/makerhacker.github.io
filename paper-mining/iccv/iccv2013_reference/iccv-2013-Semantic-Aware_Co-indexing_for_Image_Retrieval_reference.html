<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>378 iccv-2013-Semantic-Aware Co-indexing for Image Retrieval</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-378" href="../iccv2013/iccv-2013-Semantic-Aware_Co-indexing_for_Image_Retrieval.html">iccv2013-378</a> <a title="iccv-2013-378-reference" href="#">iccv2013-378-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>378 iccv-2013-Semantic-Aware Co-indexing for Image Retrieval</h1>
<br/><p>Source: <a title="iccv-2013-378-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zhang_Semantic-Aware_Co-indexing_for_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Shiliang Zhang, Ming Yang, Xiaoyu Wang, Yuanqing Lin, Qi Tian</p><p>Abstract: Inverted indexes in image retrieval not only allow fast access to database images but also summarize all knowledge about the database, so that their discriminative capacity largely determines the retrieval performance. In this paper, for vocabulary tree based image retrieval, we propose a semantic-aware co-indexing algorithm to jointly San Antonio, TX 78249 . j dl@gmai l com qit ian@cs .ut sa . edu . The query embed two strong cues into the inverted indexes: 1) local invariant features that are robust to delineate low-level image contents, and 2) semantic attributes from large-scale object recognition that may reveal image semantic meanings. For an initial set of inverted indexes of local features, we utilize 1000 semantic attributes to filter out isolated images and insert semantically similar images to the initial set. Encoding these two distinct cues together effectively enhances the discriminative capability of inverted indexes. Such co-indexing operations are totally off-line and introduce small computation overhead to online query cause only local features but no semantic attributes are used for query. Experiments and comparisons with recent retrieval methods on 3 datasets, i.e., UKbench, Holidays, Oxford5K, and 1.3 million images from Flickr as distractors, manifest the competitive performance of our method 1.</p><br/>
<h2>reference text</h2><p>[1] Large scale visual recognition challenge. http://www.imagenet.org/challenges/LSVRC/2010, 2010. 2, 3</p>
<p>[2] J. Deng, A. C. Berg, and L. Fei-Fei. Hierarchical semantic indexing for large scale image retrieval. In CVPR, 2011. 1, 2, 3, 4</p>
<p>[3] M. Douze, A. Ramisa, and C. Schmid. Combinging attributes and fisher vectors for efficient image retrieval. In CVPR, 2011. 7</p>
<p>[4] R. Fagin, R. Kumar, and D. Sivakumar. Efficient similarity search and classification via rank aggregation. In ACM SIGMOD, 2003. 1, 2</p>
<p>[5] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describing objects by their attributes. In CVPR, 2009. 1, 2</p>
<p>[6] V. Ferrari and A. Zisserman. Learning visual attributes. In NIPS, 2007. 2</p>
<p>[7] P. Gehler and S. Nowozin. On feature combination for multiclass object classification. In ICCV, 2009. 2</p>
<p>[8] A. G. Hauptmann, M. G. Christel, and R. Yan. Video retrieval based on semantic concepts. Proc. IEEE, 96(4):602– 622, 2008. 2</p>
<p>[9] H. J ´egou, M. Douze, and C. Schmid. Improving bag-offeature for large scale image search. IJCV, 87(3):316–336, 2010. 2, 5, 7</p>
<p>[10] A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012. 2</p>
<p>[11] N. Kumar, A. C. Berg, P. N. Belhumeur, and S. K. Nayar.</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]  Attribute and simile classifiers for face verification. In ICCV, 2009. 2 Y. Lin, F. Lv, S. Zhu, M. Yang, T. Cour, K. Yu, L. Cao, and T. Huang. Large-scale image classification: fast feature extraction and svm training. In CVPR, 2011. 2, 3 D. G. Lowe. Distinctive image features from scale invariant keypoints. IJCV, 60(2):91–1 10, 2004. 1, 2 D. Nist e´r and H. Stew e´nius. Scalable recognition with a vocabulary tree. In CVPR, 2006. 1, 2, 3, 5, 6 A. Oliva and A. Torralba. Modeling the shape of the scene: A holistic representation of the spatial envelope. IJCV, 42(3): 145–175, 2001. 1, 6 F. Perronnin, J. S ´anchez, and T. Mensink. Improving the fisher kernel for large-scale image classification. In ECCV, 2010. 2 J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman. Object retrieval with large vocabularies and fast spatial matching. In CVPR, 2007. 2, 5, 7 X. Shen, Z. Lin, J. Brandt, S. Avidan, and Y. Wu. Object retrieval and localization with spatially-constrained similarity measure and k-NN reranking. In CVPR, 2012. 2, 7 J. Sivic and A. Zisserman. Video google: A text retrieval approach to object matching in videos. In ICCV, 2003. 1, 2 A. Torralba, R. Fergus, and W. T. Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition. PAMI, 30(1 1): 1985–1970, Nov. 2008. 1, 2 A. Torralba, R. Fergus, and Y. Weiss. Small codes and large image databases for recognition. In CVPR, 2008. 1 L. Torresni, M. Szummer, and A. Fitzgibbon. Efficient object category recognition using classemes. In ECCV, 2010. 1, 2 P. Turcot and D. G. Lowe. Better matching with fewer</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]  features: the selection of useful features in large database recognition problems. In ICCV Workshop, 2009. 4 X. Wang, M. Yang, T. Cour, S. Zhu, K. Yu, and T. X. Han. Contextual weighting for vocabulary tree based image retrieval. In ICCV, 2011. 2, 5, 6, 7 F. Yu, R. Ji, M. Tsai, G. Ye, and S.-F. Chang. Weak attributes for large-scale image retrieval. In CVPR, 2012. 1, 2 S. Zhang, Q. Huang, G. Hua, S. Jiang, W. Gao, and Q. Tian. Building contextual visual vocabulary for large-scale image applications. In ACM Multimedia, 2010. 2 Y. Zhang, Z. Jia, and T. Chen. Image retrieval with geometrypreserving visual phrases. In CVPR, 2011. 2, 5, 7 W. Zhou, Y. Lu, H. Li, Y. Song, and Q. Tian. Spatial coding for large scale partial-duplicate web image search. In ACM Multimedia, 2010. 2, 5 11668800</p>
<br/>
<br/><br/><br/></body>
</html>
