<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-60" href="../iccv2013/iccv-2013-Bayesian_Robust_Matrix_Factorization_for_Image_and_Video_Processing.html">iccv2013-60</a> <a title="iccv-2013-60-reference" href="#">iccv2013-60-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>60 iccv-2013-Bayesian Robust Matrix Factorization for Image and Video Processing</h1>
<br/><p>Source: <a title="iccv-2013-60-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Wang_Bayesian_Robust_Matrix_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Naiyan Wang, Dit-Yan Yeung</p><p>Abstract: Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. For Bayesian inference, we devise an efficient sampling algorithm by exploiting a hierarchical view of the Laplace distribution. Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. The proposed methods give competitive experimental results when compared with several state-of-the-art methods on some benchmark image and video processing tasks.</p><br/>
<h2>reference text</h2><p>[1] S. Babacan, M. Luessi, R. Molina, and A. Katsaggelos. Sparse Bayesian methods for low-rank matrix estimation. IEEE Transactions on Signal Processing, 60(8):3964–3977, 2012. 2, 5</p>
<p>[2] S. Brutzer, B. Hoferlin, and G. Heidemann. Evaluation of background subtraction techniques for video surveillance. In CVPR, pages 1937–1944, 2011. 6 11779911  Figure 6. Results of real background modeling.  (a) Noisy(b) PCP(c) BRPCA(d) DECOLOR(e) PRMF(f) VBLR(g) MBRMF Figure 7. Robustness of different methods to additive Gaussian noise.</p>
<p>[3] A. M. Buchanan and A. W. Fitzgibbon. Damped Newton algorithms for matrix factorization with missing data. In CVPR, pages 316–322, 2005. 1</p>
<p>[4] E. Candes, X. Li, Y. Ma, and J. Wright. Robust principal component analysis? Journal of the Association for Computing Machinery, 58(3), 2011. 2, 4, 5</p>
<p>[5] L. Carin, X. Ding, and L. He. Bayesian robust principal component analysis. IEEE Transactions on Image Processing, 20(12):3419– 3430, 2011. 2, 5</p>
<p>[6] C. Croux and P. Filzmoser. Robust factorization of a data matrix. In COMPSTAT, pages 245–249, 1998. 2</p>
<p>[7] A. Eriksson and A. Van Den Hengel. Efficient computation of robust low-rank matrix approximations in the presence of missing data using the l1 norm. In CVPR, pages 771–778, 2010. 2</p>
<p>[8] Z. Gao, L.-F. Cheong, and M. Shan. Block-sparse RPCA for consistent foreground detection. In ECCV, pages 690–703, 2012. 2, 6</p>
<p>[9] J. He, L. Balzano, and A. Szlam. Incremental gradient on the Grassmannian for online foreground and background separation in subsampled video. In CVPR, pages 1568–1575, 2012. 2</p>
<p>[10] B. Jørgensen. Statistical Properties of the Generalized Inverse Gaussian Distribution, volume 21. Springer, New York, 1982. 4</p>
<p>[11] Q. Ke and T. Kanade. Robust l1 norm factorization in the presence of outliers and missing data by alternative convex programming. In CVPR, pages 739–746, 2005. 2</p>
<p>[12] B. Lakshminarayanan, G. Bouchard, and C. Archambeau. Robust Bayesian matrix factorisation. In AISTATS, 2011. 2</p>
<p>[13] Z. Lin, M. Chen, and Y. Ma. The augmented Lagrange multiplier method for exact recovery of corrupted low-rank matrices. Arxiv preprint arXiv:1009.5055, 2010. 2</p>
<p>[14] Y. Peng, A. Ganesh, J. Wright, W. Xu, and Y. Ma. RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images. In CVPR, pages 763–770, 2010. 1</p>
<p>[15] R. Salakhutdinov and A. Mnih. Bayesian probabilistic matrix factorization using Markov chain Monte Carlo. In ICML, pages 880–887, 2008. 1, 2</p>
<p>[16] R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. NIPS, 20: 1257–1264, 2008. 2</p>
<p>[17] Y. She and A. Owen. Outlier detection using nonconvex penalized regression. Journal of the American Statistical Association, 106(494):626–639, 2011. 5</p>
<p>[18] N. Wang, T. Yao, J. Wang, and D.-Y. Yeung. A probabilistic approach to robust matrix factorization. In ECCV, pages 126–139, 2012. 1, 2, 3, 5</p>
<p>[19] Z. Zhang, A. Ganesh, X. Liang, and Y. Ma. TILT: Transform invariant low-rank textures. International Journal of Computer Vision, 99(1): 1–24, 2012. 1, 5</p>
<p>[20] Z. Zhang, S. Wang, D. Liu, and M. Jordan. EP-GIG priors and applications in Bayesian sparse learning. Journal of Machine Learning Research, 13:2031–2061, 2012. 3, 4</p>
<p>[21] Y. Zheng, G. Liu, S. Sugimoto, S. Yan, and M. Okutomi. Practical low-rank matrix approximation under robust l1 norm. In CVPR, pages 771–778, 2012. 2</p>
<p>[22] X. Zhou, C. Yang, and W. Yu. Moving object detection by detecting contiguous outliers in the low-rank representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(3):597–610, 2013. 1, 2, 4, 5</p>
<p>[23] Z. Zhou, X. Li, J. Wright, E. Candes, and Y. Ma. Stable principal component pursuit. In International Symposium on Information Theory, pages 15 18–1522, 2010. 2, 4 11779922</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
