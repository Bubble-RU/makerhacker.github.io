<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>242 iccv-2013-Learning People Detectors for Tracking in Crowded Scenes</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-242" href="../iccv2013/iccv-2013-Learning_People_Detectors_for_Tracking_in_Crowded_Scenes.html">iccv2013-242</a> <a title="iccv-2013-242-reference" href="#">iccv2013-242-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>242 iccv-2013-Learning People Detectors for Tracking in Crowded Scenes</h1>
<br/><p>Source: <a title="iccv-2013-242-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Tang_Learning_People_Detectors_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Siyu Tang, Mykhaylo Andriluka, Anton Milan, Konrad Schindler, Stefan Roth, Bernt Schiele</p><p>Abstract: People tracking in crowded real-world scenes is challenging due to frequent and long-term occlusions. Recent tracking methods obtain the image evidence from object (people) detectors, but typically use off-the-shelf detectors and treat them as black box components. In this paper we argue that for best performance one should explicitly train people detectors on failure cases of the overall tracker instead. To that end, we first propose a novel joint people detector that combines a state-of-the-art single person detector with a detector for pairs of people, which explicitly exploits common patterns of person-person occlusions across multiple viewpoints that are a frequent failure case for tracking in crowded scenes. To explicitly address remaining failure modes of the tracker we explore two methods. First, we analyze typical failures of trackers and train a detector explicitly on these cases. And second, we train the detector with the people tracker in the loop, focusing on the most common tracker failures. We show that our joint multi-person detector significantly improves both de- tection accuracy as well as tracker performance, improving the state-of-the-art on standard benchmarks.</p><br/>
<h2>reference text</h2><p>[1] M. Andriluka, S. Roth, and B. Schiele. People-tracking-bydetection and people-detection-by-tracking. CVPR 2008. 3www . d2 . mpi -inf . mpg . de /t ang_i ccv1 3</p>
<p>[2] A. Andriyenko and K. Schindler. Multi-target tracking by continuous energy minimization. CVPR 2011.</p>
<p>[3] A. Andriyenko, K. Schindler, and S. Roth. Discrete-continuous optimization for multi-target tracking. CVPR 2012.</p>
<p>[4] O. Barinova, V. Lempitsky, and P. Kohli. On detection of multiple object instances using hough transform. CVPR 2010.</p>
<p>[5] K. Bernardin and R. Stiefelhagen. Evaluating multiple object tracking performance: The CLEAR MOT metrics. Image and Video Processing, 2008(1): 1–10, 2008.</p>
<p>[6] M. Breitenstein, F. Reichlin, B. Leibe, E. Koller-Meier, and L. Van Gool. Online multiperson tracking-by-detection from a single uncalibrated camera. PAMI, 33(9): 1820–1833, 2011.</p>
<p>[7] C. Desai and D. Ramanan. Detecting actions, poses, and objects with relational phraselets. ECCV 2012.</p>
<p>[8] P. Doll a´r, C. Wojek, B. Schiele, and P. Perona. Pedestrian detection: An evaluation of the state of the art. PAMI, 34(4):743–761, 2012.</p>
<p>[9] M. Enzweiler, A. Eigenstetter, B. Schiele, and D. M. Gavrila. Multi-cue pedestrian classification with partial occlusion handling. CVPR 2010.</p>
<p>[10] A. Farhadi and M. Sadeghi. Recognition using visual phrases. CVPR 2011.</p>
<p>[11] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained partbased models. PAMI, 32(9): 1627–1645, 2010.</p>
<p>[12] J. M. Ferryman and A. Shahrokni. PETS2009: Dataset and challenge. Winter-PETS, 2009.</p>
<p>[13] B. Leibe, K. Schindler, and L. Van Gool. Coupled detection and trajectory estimation for multi-object tracking. ICCV 2007.</p>
<p>[14] B. Leibe, E. Seemann, and B. Schiele. Pedestrian detection in crowded scenes. CVPR 2005.</p>
<p>[15] B. Pepik, M. Stark, P. Gehler, and B. Schiele. Teaching 3d geometry to deformable part models. CVPR 2012.</p>
<p>[16] G. Shu, A. Dehghan, O. Oreifej, E. Hand, and M. Shah. Partbased multiple-person tracking with partial occlusion handling. CVPR 2012.</p>
<p>[17] S. Tang, M. Andriluka, and B. Schiele. Detection and tracking of occluded people. BMVC 2012.</p>
<p>[18] X. Wang, T. Han, and S. Yan. An HOG-LBP human detector with partial occlusion handling. ICCV 2009.</p>
<p>[19] C. Wojek, S. Walk, S. Roth, and B. Schiele. Monocular 3D scene understanding with explicit occlusion reasoning. CVPR 2011.</p>
<p>[20] B. Wu and R. Nevatia. Tracking of multiple, partially occluded humans based on static body part detection. CVPR 2006.</p>
<p>[21] Z. Wu, A. Thangali, S. Sclaroff, and M. Betke. Coupling detection and data association for multiple object tracking. CVPR 2012.</p>
<p>[22] B. Yang and R. Nevatia. Online learned discriminative partbased appearance models for multi-human tracking. ECCV 2012.</p>
<p>[23] A. R. Zamir, A. Dehghan, and M. Shah. GMCP-Tracker: Global multi-object tracking using generalized minimum clique graphs. ECCV 2012. 11005566</p>
<br/>
<br/><br/><br/></body>
</html>
