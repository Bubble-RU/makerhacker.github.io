<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>189 iccv-2013-HOGgles: Visualizing Object Detection Features</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-189" href="../iccv2013/iccv-2013-HOGgles%3A_Visualizing_Object_Detection_Features.html">iccv2013-189</a> <a title="iccv-2013-189-reference" href="#">iccv2013-189-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>189 iccv-2013-HOGgles: Visualizing Object Detection Features</h1>
<br/><p>Source: <a title="iccv-2013-189-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Vondrick_HOGgles_Visualizing_Object_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Carl Vondrick, Aditya Khosla, Tomasz Malisiewicz, Antonio Torralba</p><p>Abstract: We introduce algorithms to visualize feature spaces used by object detectors. The tools in this paper allow a human to put on ‘HOG goggles ’ and perceive the visual world as a HOG based object detector sees it. We found that these visualizations allow us to analyze object detection systems in new ways and gain new insight into the detector’s failures. For example, when we visualize the features for high scoring false alarms, we discovered that, although they are clearly wrong in image space, they do look deceptively similar to true positives in feature space. This result suggests that many of these false alarms are caused by our choice of feature space, and indicates that creating a better learning algorithm or building bigger datasets is unlikely to correct these errors. By visualizing feature spaces, we can gain a more intuitive understanding of our detection systems.</p><br/>
<h2>reference text</h2><p>[1] A. Alahi, R. Ortiz, and P. Vandergheynst. Freak: In CVPR, 2012. 2</p>
<p>[2] M. Calonder, V. Lepetit, C. Strecha, and P. Fua. independent elementary features. ECCV, 2010.</p>
<p>[3] N. Dalal and B. Triggs. Histograms of oriented detection. In CVPR, 2005. 6  Fast retina keypoint. Brief: Binary robust 2 gradients for human</p>
<p>[4] E. d’Angelo, A. Alahi, and P. Vandergheynst. Beyond bits: Reconstructing images from local binary descriptors. ICPR, 2012. 2</p>
<p>[5] S. Divvala, A. Efros, and M. Hebert. How important are deformable parts in the deformable parts model? Technical Report, 2012. 2</p>
<p>[6] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The pascal visual object classes challenge. IJCV, 2010. 4</p>
<p>[7] P. Felzenszwalb, R. Girshick, and D. McAllester. Cascade object detection with deformable part models. In CVPR, 2010. 6</p>
<p>[8] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part-based models. PAMI, 2010. 1, 2, 6, 7, 8</p>
<p>[9] B. Hariharan, J. Malik, and D. Ramanan. Discriminative decorrelation for clustering and classification. ECCV, 2012. 3</p>
<p>[10] D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error in object detectors. ECCV, 2012. 2</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]  8 H. Lee, A. Battle, R. Raina, and A. Ng. Efficient sparse coding algorithms. NIPS, 2007. 4 L. Liu and L. Wang. What has my classifier learned? visualizing the classification rules of bag-of-feature model by support region detection. In CVPR, 2012. 2 D. Lowe. Object recognition from local scale-invariant features. In ICCV, 1999. 2 J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary learning for sparse coding. In ICML, 2009. 4 T. Malisiewicz, A. Gupta, and A. Efros. Ensemble of exemplar-svms for object detection and beyond. In ICCV, 2011. 3 S. Nishimoto, A. Vu, T. Naselaris, Y. Benjamini, B. Yu, and J. Gallant. Reconstructing visual experiences from brain activity evoked by natural movies. Current Biology, 2011. 3 A. Oliva and A. Torralba. Modeling the shape of the scene: A holistic representation of the spatial envelope. IJCV, 2001 . 2 D. Parikh and C. Zitnick. Human-debugging of machines. In NIPS WCSSWC, 2011. 2, 7 D. Parikh and C. L. Zitnick. The role of features, algorithms and data</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]  in visual recognition. In CVPR, 2010. 2, 7 A. Tatu, F. Lauze, M. Nielsen, and B. Kimia. Exploring the representation capabilities of hog descriptors. In ICCV WIT, 2011. 2 S. Wang, L. Zhang, Y. Liang, and Q. Pan. Semi-coupled dictionary learning with applications to image super-resolution and photosketch synthesis. In CVPR, 2012. 4 P. Weinzaepfel, H. J ´egou, and P. P ´erez. Reconstructing an image from its local descriptors. In CVPR, 2011. 2 J. Yang, J. Wright, T. Huang, and Y. Ma. Image super-resolution via sparse representation. Transactions on Image Processing, 2010. 4 X. Zhu, C. Vondrick, D. Ramanan, and C. Fowlkes. Do we need more training data or better models for object detection? BMVC, 2012. 2</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
