<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>316 iccv-2013-Pictorial Human Spaces: How Well Do Humans Perceive a 3D Articulated Pose?</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-316" href="../iccv2013/iccv-2013-Pictorial_Human_Spaces%3A_How_Well_Do_Humans_Perceive_a_3D_Articulated_Pose%3F.html">iccv2013-316</a> <a title="iccv-2013-316-reference" href="#">iccv2013-316-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>316 iccv-2013-Pictorial Human Spaces: How Well Do Humans Perceive a 3D Articulated Pose?</h1>
<br/><p>Source: <a title="iccv-2013-316-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Marinoiu_Pictorial_Human_Spaces_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Elisabeta Marinoiu, Dragos Papava, Cristian Sminchisescu</p><p>Abstract: Human motion analysis in images and video is a central computer vision problem. Yet, there are no studies that reveal how humans perceive other people in images and how accurate they are. In this paper we aim to unveil some of the processing–as well as the levels of accuracy–involved in the 3D perception of people from images by assessing the human performance. Our contributions are: (1) the construction of an experimental apparatus that relates perception and measurement, in particular the visual and kinematic performance with respect to 3D ground truth when the human subject is presented an image of a person in a given pose; (2) the creation of a dataset containing images, articulated 2D and 3D pose ground truth, as well as synchronized eye movement recordings of human subjects, shown a variety of human body configurations, both easy and difficult, as well as their ‘re-enacted’ 3D poses; (3) quantitative analysis revealing the human performance in 3D pose reenactment tasks, the degree of stability in the visual fixation patterns of human subjects, and the way it correlates with different poses. We also discuss the implications of our find- ings for the construction of visual human sensing systems.</p><br/>
<h2>reference text</h2><p>[1] A. Agarwal and B. Triggs. Recovering 3D human pose from monocular images. PAMI, 2006.</p>
<p>[2] M. Andriluka, S. Roth, and B. Schiele. Monocular 3D pose estimation and tracking by detection. In CVPR, 2010.</p>
<p>[3] L. Bo and C. Sminchisescu. Twin gaussian processes for structured prediction. IJCV, 2010.</p>
<p>[4] L. Bourdev, S. Maji, T. Brox, and J. Malik. Detecting people using mutually consistent poselet activations. In (ECCV), 2010.</p>
<p>[5] J. Deutscher, A. Blake, and I. Reid. Articulated body motion capture by annealed particle filtering. In CVPR, 2000.</p>
<p>[6] K. A. Ehinger, B. Hidalgo-Sotelo, A. Torralba, and A. Oliva. Modelling search for people in 900 scenes: A combined source model of eye guidance. Visual Cognition, 2009.</p>
<p>[7] V. Ferrari, M. Marin, and A. Zisserman. Pose Search: retrieving people using their pose. In CVPR, 2009.</p>
<p>[8] J. Gall, B. Rosenhahn, T. Brox, and H. Seidel. Optimization and filtering for human motion capture: A multi-layer framework. IJCV, 2010.</p>
<p>[9] C. Ionescu, D. Papava, V. Olaru, and C. Sminchisescu. Human3.6M: Large scale datasets and predictive methods for 3D human sensing in natural environments. PAMI, 2014.</p>
<p>[10] G. Johannson. Visual perception of biological motion and a model for its analysis. In Perception and Psychophysics, 1973.</p>
<p>[11] J. Koenderink. Pictorial relief. In Phil. Trans. R. Soc. London. A, volume 356, 1998.</p>
<p>[12] H. J. Lee and Z. Chen. Determination of 3D human body postures from a single view. CVGIP, 30, 1985.</p>
<p>[13] E. Marinoiu, D. Papava, and C. Sminchisescu. Pictorial human spaces: A study on the human perception of 3D articulated poses . Technical report, IMAR and Lund University, 2013.</p>
<p>[14] S. Mathe and C. Sminchisescu. Action from still image dataset and inverse optimal control to learn task specific visual scanpaths. In NIPS, 2013.</p>
<p>[15] B. Sapp, A. Toshev, and B. Taskar. Cascaded models for articulated pose estimation. In ECCV, 2010.</p>
<p>[16] A. Sekunova, M. Black, L. Parkinson, and J. Barton. Viewpoint and pose in body-form adaptation. Perception, 2013.</p>
<p>[17] L. Sigal, A. Balan, and M. J. Black. Combined discriminative and generative articulated pose and non-rigid shape estimation. In NIPS, 2007.</p>
<p>[18] L. Sigal, D. J. Fleet, N. F. Troje, and M. Livne. Human attributes from 3D pose tracking. In ECCV, 2010.</p>
<p>[19] C. Sminchisescu and A. Jepson. Variational mixture smoothing for non-linear dynamical systems. In CVPR, volume 2,</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]  pages 608–615, Washington D.C., 2004. C. Sminchisescu, A. Kanaujia, and D. Metaxas. Learning joint top-down and bottom-up processes for 3D Visual inference. In CVPR, 2006. C. Sminchisescu and B. Triggs. Kinematic jump processes for monocular 3D human tracking. In CVPR, 2003. C. Sminchisescu and B. Triggs. Mapping minima and transitions in visual models. IJCV, 61(1), 2005. M. Sun, P. Kohli, and J. Shotton. Conditional regression forests for human pose estimation. In CVPR, 2012. R. Urtasun, D. Fleet, A. Hertzmann, and P. Fua. Priors for people tracking in small training sets. In ICCV, 2005. D. M. Wolpert, J. Diedrichsen, and J. R. Flanagan. Principles of sensorimotor learning. Nat. Rev. Neuroscience, 2011. Y. Yang and D. Ramanan. Articulated pose estimation using flexible mixture of parts. In CVPR, 2011. 1296</p>
<br/>
<br/><br/><br/></body>
</html>
