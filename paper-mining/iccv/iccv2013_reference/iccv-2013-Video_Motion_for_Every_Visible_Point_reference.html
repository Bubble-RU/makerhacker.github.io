<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>441 iccv-2013-Video Motion for Every Visible Point</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-441" href="../iccv2013/iccv-2013-Video_Motion_for_Every_Visible_Point.html">iccv2013-441</a> <a title="iccv-2013-441-reference" href="#">iccv2013-441-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>441 iccv-2013-Video Motion for Every Visible Point</h1>
<br/><p>Source: <a title="iccv-2013-441-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Ricco_Video_Motion_for_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Susanna Ricco, Carlo Tomasi</p><p>Abstract: Dense motion of image points over many video frames can provide important information about the world. However, occlusions and drift make it impossible to compute long motionpaths by merely concatenating opticalflow vectors between consecutive frames. Instead, we solve for entire paths directly, and flag the frames in which each is visible. As in previous work, we anchor each path to a unique pixel which guarantees an even spatial distribution of paths. Unlike earlier methods, we allow paths to be anchored in any frame. By explicitly requiring that at least one visible path passes within a small neighborhood of every pixel, we guarantee complete coverage of all visible points in all frames. We achieve state-of-the-art results on real sequences including both rigid and non-rigid motions with significant occlusions.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
