<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-211" href="../iccv2013/iccv-2013-Image_Segmentation_with_Cascaded_Hierarchical_Models_and_Logistic_Disjunctive_Normal_Networks.html">iccv2013-211</a> <a title="iccv-2013-211-reference" href="#">iccv2013-211-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>211 iccv-2013-Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks</h1>
<br/><p>Source: <a title="iccv-2013-211-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Seyedhosseini_Image_Segmentation_with_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Mojtaba Seyedhosseini, Mehdi Sajjadi, Tolga Tasdizen</p><p>Abstract: Contextual information plays an important role in solving vision problems such as image segmentation. However, extracting contextual information and using it in an effective way remains a difficult problem. To address this challenge, we propose a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation. At each level of the hierarchy, a classifier is trained based on downsampled input images and outputs of previous levels. Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. We repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy. Multiple classifiers are learned in the CHM; therefore, a fast and accurate classifier is required to make the training tractable. The classifier also needs to be robust against overfitting due to the large number of parameters learned during training. We introduce a novel classification scheme, called logistic dis- junctive normal networks (LDNN), which consists of one adaptive layer of feature detectors implemented by logistic sigmoid functions followed by two fixed layers of logical units that compute conjunctions and disjunctions, respectively. We demonstrate that LDNN outperforms state-of-theart classifiers and can be used in the CHM to improve object segmentation performance.</p><br/>
<h2>reference text</h2><p>[1] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. From contours to regions: An empirical evaluation. CVPR, 2009. 7, 8</p>
<p>[2] I. Arganda-Carreras, S. Seung, A. Cardona, and J. Schindelin. ISBI2012 segmentation of neuronal structures in em stacks. http : / /braini ac2 .mit . edu / i sbi_ chal l enge / , 2012. 7 2174  (a)(b)(c)(d)(e)(f)(g)  Figure 4. Test results ofthe mouse neuropil dataset (first row) and the Drosophila VNC dataset (second row). (a) Input image, (b) gPb-OWTUCM [1], (c) BEL [9], (d) MSANN [24], (e) CHM-RF, (f) CHM-LDNN, (g) ground truth images. The CHM-LDNN is more successful in removing undesired parts and closing small gaps. Some of the improvements are marked with red rectangles. For gPb-OWT-UCM method, the best threshold was picked and the edges were dilated to the true membrane thickness.</p>
<p>[3] L. Bertelli, T. Yu, D. Vu, and B. Gokturk. Kernelized structural svm learning for supervised object segmentation. In CVPR, 2011. 6</p>
<p>[4] E. Borenstein, E. Sharon, and S. Ullman. Combining topdown and bottom-up segmentation. Proc. of CVPRW, pages 46 –46, 2004. 5</p>
<p>[5] C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27: 1–27:27, 2011. Software available at http : / /www . c s i . ntu . edu .tw/ e ˜c j l in/ l ibsvm. 5</p>
<p>[6] M. J. Choi, A. Torralba, and A. S. Willsky. A tree-based context model for object recognition. IEEE Trans. on PAMI, 34(2):240–252, 2012. 1</p>
<p>[7] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. CVPR, 2005. 5</p>
<p>[8] C. Desai, D. Ramanan, and C. Fowlkes. Discriminative mod-</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]  els for multi-class object layout. ICCV, 2009. 1 P. Dollar, Z. Tu, and S. Belongie. Supervised learning of edges and object boundaries. CVPR, 2006. 7, 8 S. E. Fahlman and C. Lebiere. The cascade-correlation learning architecture. NIPS, 1990. 2 A. Frank and A. Asuncion. UCI machine learning repository. http : / / archive . i s .uc i edu /ml, 2010. 5 c . M. Hazewinkel. Encyclopaedia of Mathematics, Supplement III, volume 13. Springer, 2001 . 4 X. He, R. Zemel, and M. Carreira-Perpinan. Multiscale conditional random fields for image labeling. Proc. of CVPR, 2:695–702, 2004. 1, 5, 7 G. Heitz, S. Gould, A. Saxena, and D. Koller. Cascaded classification models: Combining models for holistic scene understanding. Proc. of NIPS, pages 641–648, 2008. 1 G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580, 2012. 5 E. Jurrus, A. R. C. Paiva, S. Watanabe, J. R. Anderson, B. W. Jones, R. T. Whitaker, E. M. Jorgensen, R. E. Marc, and T. Tasdizen. Detection of neuron membranes in electron microscopy images using a serial neural network architecture. Medical Image Analysis, 14(6):770–783, 2010. 5 D. Kuettel and V. Ferrari. Figure-ground segmentation by transferring window masks. In CVPR, 2012. 6 R. Kumar, A. Va andzquez Reina, and H. Pfister. Radon-like features and their application to connectomics. In CVPRW, pages 186 –193, june 2010. 6 Y. LeCun and C. Cortes. The MNIST database. http : / / yann . le cun . com/ exdb /mni st / . 5</p>
<p>[20] H.-M. Lee, K.-H. Chen, and I. Jiang. A neural network classifier with disjunctive fuzzy information. Neural Networks, 11(6):1 113–1 125, 1998. 5</p>
<p>[21] A. Levin and Y. Weiss. Learning to combine bottom-up and top-down segmentation. In ECCV. 2006. 6</p>
<p>[22] C. Li, A. Kowdle, A. Saxena, and T. Chen. Toward holistic scene understanding: Feedback enabled cascaded classification models. TPAMI, 34(7): 1394–1408, 2012. 1</p>
<p>[23] C. Liu, J. Yuen, and A. Torralba. Sift flow: Dense correspondence across scenes and its applications. TPAMI, 33(5):978– 994, 2011. 5</p>
<p>[24] M. Seyedhosseini, R. Kumar, E. Jurrus, R. Guily, M. Ellisman, H. Pfister, and T. Tasdizen. Detection of neuron membranes in electron microscopy images using multi-scale context and radon-like features. In MICCAI, 2011. 3, 6, 7, 8</p>
<p>[25] J. Shotton, J. Winn, C. Rother, and A. Criminisi. Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture, layout, and context. IJCV, 2009. 7</p>
<p>[26] P. K. Simpson. Fuzzy min-max neural networks. i. classification. NeuralNetworks, IEEE Transactions on, 3(5):776–786, 1992. 4</p>
<p>[27] A. Torralba, K. P. Murphy, and W. T. Freeman. Contextual models for object detection using boosted random fields. NIPS, 2004. 1</p>
<p>[28] Z. Tu and X. Bai. Auto-context and its application to highlevel vision tasks and 3d brain image segmentation. IEEE Trans. on PAMI, 32(10): 1744–1757, 2010. 1, 5, 6</p>
<p>[29] P. Viola and M. J. Jones. Robust real-time face detection. IJCV, 57(2): 137–154, 2004. 5 2175</p>
<br/>
<br/><br/><br/></body>
</html>
