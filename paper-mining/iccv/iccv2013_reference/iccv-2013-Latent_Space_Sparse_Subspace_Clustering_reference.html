<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>232 iccv-2013-Latent Space Sparse Subspace Clustering</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-232" href="../iccv2013/iccv-2013-Latent_Space_Sparse_Subspace_Clustering.html">iccv2013-232</a> <a title="iccv-2013-232-reference" href="#">iccv2013-232-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>232 iccv-2013-Latent Space Sparse Subspace Clustering</h1>
<br/><p>Source: <a title="iccv-2013-232-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Patel_Latent_Space_Sparse_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Vishal M. Patel, Hien Van Nguyen, René Vidal</p><p>Abstract: We propose a novel algorithm called Latent Space Sparse Subspace Clustering for simultaneous dimensionality reduction and clustering of data lying in a union of subspaces. Specifically, we describe a method that learns the projection of data and finds the sparse coefficients in the low-dimensional latent space. Cluster labels are then assigned by applying spectral clustering to a similarity matrix built from these sparse coefficients. An efficient optimization method is proposed and its non-linear extensions based on the kernel methods are presented. One of the main advantages of our method is that it is computationally efficient as the sparse coefficients are found in the low-dimensional latent space. Various experiments show that the proposed method performs better than the competitive state-of-theart subspace clustering methods.</p><br/>
<h2>reference text</h2><p>[1] R. Baraniuk, M. Davenport, R. DeVore, and M. Wakin. A simple proof of the restricted isometry property for random matrices. Constructive Approximation, 28(3):253–263, 2008.</p>
<p>[2] R. Basri and D. W. Jacobs. Lambertian reflectance and linear subspaces. IEEE Trans. Pattern Anal. Mach. Intell., 25(2):218–233, 2003.</p>
<p>[3] G. Chen and G. Lerman. Spectral curvature clustering (SCC). International Journal of Computer Vision, 81(3):317–330, 2009.</p>
<p>[4] J. P. Costeira and T. Kanade. A multibody factorization method for independently moving objects. International Journal of Computer Vision, 29(3): 159–179, 1998.</p>
<p>[5] E. Elhamifar and R. Vidal. Sparse subspace clustering. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2790–2797, 2009.</p>
<p>[6] E. Elhamifar and R. Vidal. Sparse subspace clustering: Algorithm, theory, and applications. IEEE Trans. Pattern Anal. Mach. Intell., 2013.</p>
<p>[7] P. Favaro, R. Vidal, and A. Ravichandran. A closed form solution to robust subspace estimation and clustering. In IEEE Conference on Computer Vision and Pattern Recognition, 2011.</p>
<p>[8] M. A. Fischler and R. C. Bolles. RANSAC random sample consensus: A paradigm for model fitting with applications to  image analysis and automated cartography. Communications of the ACM, 26:381–395, 1981.</p>
<p>[9] A. Goh and R. Vidal. Segmenting motions of different types by unsupervised manifold clustering. In IEEE Conference on Computer Vision and Pattern Recognition, 2007.</p>
<p>[10] T. Hastie and P. Y. Simard. Metrics and models for handwritten character recognition. Statistical Science, 13(1):54–65.</p>
<p>[11] J. Ho, M. H. Yang, J. Lim, K. Lee, and D. Kriegman. Clustering appearances of objects under varying illumination conditions. In IEEE Conference on Computer Vision and Pattern Recognition, 2003.</p>
<p>[12] K. Kanatani. Motion segmentation by subspace separation and model selection. In IEEE Conference on Computer Vision and Pattern Recognition, volume 2, pages 586–591, 2001.</p>
<p>[13] H. Larochelle, D. Erhan, A. Courville, J. Bergstra, and Y. Bengio. An empirical evaluation of deep architectures on problems with many factors of variation. In International Conference on Machine Learning, pages 473–480. ACM, 2007.</p>
<p>[14] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradientbased learning applied to document recognition. Proceedings of the IEEE, 86(1 1):2278–2324, 1998.</p>
<p>[15] G. Liu, Z. Lin, and Y. Yu. Robust subspace segmentation by low-rank representation. In International Conference on Machine Learning, 2010.</p>
<p>[16] G. Liu and S. Yan. Latent low-rank representation for subspace segmentation and feature extraction. In IEEE International Conference on Computer Vision, pages 1615–1622, 2011.</p>
<p>[17] J. Mairal, F. Bach, and J. Ponce. Task-driven dictionary learning. IEEE Transactions on Pattern Analysis and Ma-</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]</p>
<p>[23]</p>
<p>[24]</p>
<p>[25]</p>
<p>[26]</p>
<p>[27]</p>
<p>[28]  chine Intelligence, 34(4):791–804, 2012. A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm. In Neural Information Processing Systems, volume 2, pages 849–856, 2002. H. V. Nguyen, V. M. Patel, N. M. Nasrabadi, and R. Chellappa. Sparse embedding: A framework for sparsity promoting dimensionality reduction. In European Conference on Computer Vision, pages 414–427, Oct. 2012. Q. Qiu and G. Sapiro. Learning transformations for clustering and classification. Preprint, 2013. R. Rubinstein, M. Zibulevsky, and M. Elad. Double sparsity: Learning sparse dictionaries for sparse signal approximation. IEEE Transactions on Signal Processing, 58(3): 1553–1564, 2010. A. H. Sameh and J. A. Wisniewski. A trace minimization algorithm for the generalized eigenvalue problem. SIAM J. Numer. Anal., 19(6): 1243–1259, 1982. M. Soltanolkotabi and E. J. Candes. A geometric analysis of subspace clustering with outliers. Annals of Statistics, 40(4):2195–2238, 2011. R. Tron, R. Vidal, and A. Ravichandran. A benchmark for the comparison of 3-d motion segmentation algorithms. In IEEE Conference on Computer Vision and Pattern Recognition, pages 1–8, 2007. R. Vidal. Subspace clustering. IEEE Signal Processing Magazine, 28(2):52–68, 2011. R. Vidal and P. Favaro. Low rank subspace clustering (LRSC). Pattern Recognition Letters, 2013. R. Vidal, Y. Ma, and S. Sastry. Generalized principal component analysis (GPCA). IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(12): 1–15, 2005. J. Wright, A. Yang, A. Ganesh, S. Sastry, and Y. Ma. Robust face recognition via sparse representation. IEEE  Transactions on Pattern Analysis and Machine Intelligence, 31(2):210–227, 2009.</p>
<p>[29] J. Yan and M. Pollefeys. A general framework for motion segmentation: Independent, articulated, rigid, non-rigid, degenerate and non-degenerate. In European Conf. on Computer Vision, page 94106, 2006.</p>
<p>[30] D. Zhang, M. Yang, Z. Feng, and D. Zhang. On the dimensionality reduction for sparse representation based face recognition. In International Conference on Pattern Recognition, pages 1237–1240, 2010.</p>
<p>[31] T. Zhang, A. Szlam, and G. Lerman. Median k-flats for hybrid linear modeling with many outliers. In Workshop on Subspace Methods, 2009. 232</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
