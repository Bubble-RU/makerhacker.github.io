<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1 iccv-2013-3DNN: Viewpoint Invariant 3D Geometry Matching for Scene Understanding</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-1" href="../iccv2013/iccv-2013-3DNN%3A_Viewpoint_Invariant_3D_Geometry_Matching_for_Scene_Understanding.html">iccv2013-1</a> <a title="iccv-2013-1-reference" href="#">iccv2013-1-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1 iccv-2013-3DNN: Viewpoint Invariant 3D Geometry Matching for Scene Understanding</h1>
<br/><p>Source: <a title="iccv-2013-1-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Satkin_3DNN_Viewpoint_Invariant_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Scott Satkin, Martial Hebert</p><p>Abstract: We present a new algorithm 3DNN (3D NearestNeighbor), which is capable of matching an image with 3D data, independently of the viewpoint from which the image was captured. By leveraging rich annotations associated with each image, our algorithm can automatically produce precise and detailed 3D models of a scene from a single image. Moreover, we can transfer information across images to accurately label and segment objects in a scene. The true benefit of 3DNN compared to a traditional 2D nearest-neighbor approach is that by generalizing across viewpoints, we free ourselves from the need to have training examples captured from all possible viewpoints. Thus, we are able to achieve comparable results using orders of magnitude less data, and recognize objects from never-beforeseen viewpoints. In this work, we describe the 3DNN algorithm and rigorously evaluate its performance for the tasks of geometry estimation and object detection/segmentation. By decoupling the viewpoint and the geometry of an image, we develop a scene matching approach which is truly 100% viewpoint invariant, yielding state-of-the-art performance on challenging data.</p><br/>
<h2>reference text</h2><p>[1] CMU 3D-Annotated Scene Database. http : / / cmu . s at kin . com/bmvc2 0 1 / . 3, 4 2</p>
<p>[2] Microsoft Corp. Redmond WA. Kinect for Xbox 360. 2</p>
<p>[3] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Contour detection and hierarchical image segmentation. PAMI, 33(5):898–916, May 2011. 3</p>
<p>[4] W. Choi, C. Pantofaru, and S. Savarese. Understanding indoor scenes using 3d geometric phrases. In CVPR, 2013. 2</p>
<p>[5] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In ICCV, 2005. 5, 6, 7</p>
<p>[6] M. Douze, H. J´ egou, H. Sandhawalia, L. Amsaleg, and C. Schmid. Evaluation of gist descriptors for web-scale image search. In CIVR, 2009. 3</p>
<p>[7] D. F. Fouhey, V. Delaitre, A. Gupta, A. A. Efros, I. Laptev, and J. Sivic. People watching: Human actions as a cue for single-view geometry. In ECCV, 2012. 2, 3</p>
<p>[8] A. Gupta, S. Satkin, A. A. Efros, and M. Hebert. From 3d scene geometry to human workspace. In CVPR, 2011. 2, 3</p>
<p>[9] J. Hays and A. A. Efros. Scene completion using millions of photographs. In SIGGRAPH, 2007. 1, 7</p>
<p>[10] J. Hays and A. A. Efros. im2gps: estimating geographic information from a single image. In CVPR, 2008. 1</p>
<p>[11] V. Hedau, D. Hoiem, and D. Forsyth. Recovering the spatial layout of cluttered rooms. In ICCV, 2009. 3, 4</p>
<p>[12] V. Hedau, D. Hoiem, and D. Forsyth. Thinking inside the box: Using appearance models and context based on room geometry. In ECCV, 2010. 3</p>
<p>[13] V. Hedau, D. Hoiem, and D. Forsyth. Recovering free space ofindoor scenes from a single image. In CVPR, 2012. 2, 5</p>
<p>[14] R. Herbrich, T. Graepel, and K. Obermayer. Support vector learning for ordinal regression. In ANN, volume 1, pages 97 –102, 1999. 3</p>
<p>[15] D. Hoiem, A. A. Efros, and M. Hebert. Recovering surface layout from an image. In IJCV, 2007. 3</p>
<p>[16] K. Karsch, V. Hedau, D. Forsyth, and D. Hoiem. Rendering synthetic objects into legacy photographs. In SIGGRAPH Asia, 2011. 2</p>
<p>[17] K. Karsch, C. Liu, and S. B. Kang. Depth extraction from video using non-parametric sampling. In ECCV, 2012. 2</p>
<p>[18] D. Lee, A. Gupta, M. Hebert, and T. Kanade. Estimating spatial layout of rooms using volumetric reasoning about objects and surfaces. In NIPS, 2010. 2, 3</p>
<p>[19] D. Lee, M. Hebert, and T. Kanade. Geometric reasoning for single image structure recovery. In CVPR, 2009. 3</p>
<p>[20] C. Liu, J. Yuen, A. Torralba, J. Sivic, and W. T. Freeman. SIFT Flow: dense correspondence across different scenes. In ECCV, 2008. 1, 4, 6</p>
<p>[21] D. Lowe. Three-dimensional object recognition from single twodimensional images. In Artificial Intelligence, volume 3 1, 1987. 3</p>
<p>[22] K. Mikolajczyk and C. Schmid. A performance evaluation of local descriptors. PAMI, 27(10): 1615–1630, 2005. 3</p>
<p>[23] D. Munoz, J. A. Bagnell, and M. Hebert. Stacked hierarchical labeling. In ECCV, 2010. 3</p>
<p>[24] A. Oliva and A. Torralba. Building the gist of a scene: the role of global image features in recognition. In Progress in Brain Research, 2006. 1, 3, 5, 6, 7</p>
<p>[25] L. D. Pero, J. Bowdish, D. Fried, B. Kermgard, E. Hartley, and K. Barnard. Bayesian geometric modeling of indoor scenes. In CVPR, 2012. 2, 3</p>
<p>[26] L. D. Pero, J. Bowdish, E. Hartley, B. Kermgard, and K. Barnard. Understanding bayesian rooms using composite 3d object models. In CVPR, 2013. 2</p>
<p>[27] L. D. Pero, J. Guan, E. Brau, J. Schlecht, and K. Barnard. Sampling bedrooms. In CVPR, 2011. 3</p>
<p>[28] S. Satkin, J. Lin, and M. Hebert. Data-driven scene understanding from 3D models. In BMVC, 2012. 1, 2, 3, 5, 6</p>
<p>[29] A. Saxena, M. Sun, and A. Y. Ng. Make3D: Learning 3D scene structure from a single still image. PAMI, 2009. 2</p>
<p>[30] A. G. Schwing and R. Urtasun. Efficient Exact Inference for 3D Indoor Scene Understanding. In ECCV, 2012. 2, 3</p>
<p>[31] T. Shao, W. Xu, K. Zhou, J. Wang, D. Li, and B. Guo. An interactive approach to semantic modeling of indoor scenes with an rgbd camera. ACM Trans. Graph. , Nov. 2012. 2</p>
<p>[32] J. Tighe and S. Lazebnik. Superparsing: scalable nonparametric image parsing with superpixels. In ECCV, 2010. 1</p>
<p>[33] A. Torralba, R. Fergus, and W. T. Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition. PAMI, Nov. 2008. 1, 7</p>
<p>[34] A. Torralba, B. C. Russell, and J. Yuen. Labelme: Online image annotation and applications. Proceedings of the IEEE, 98(8): 1467– 1484, 2010. 3</p>
<p>[35] C. Vondrick, A. Khosla, T. Malisiewicz, and A. Torralba. Inverting and visualizing features for object detection. In MIT Technical Report, 2013. 6</p>
<p>[36] H. Wang, S. Gould, and D. Koller. Discriminative learning with latent variables for cluttered indoor scene understanding. In ECCV, 2010. 2</p>
<p>[37] J. Xiao, J. Hays, K. Ehinger, A. Oliva, and A. Torralba. Sun database: Large-scale scene recognition from abbey to zoo. In CVPR, 2010. 3</p>
<p>[38] S. Yu, H. Zhang, and J. Malik. Inferring spatial layout from a single image via depth-ordered grouping. In CVPR Workshop, 2008. 2</p>
<p>[39] Y. Zheng, X. Chen, M.-M. Cheng, K. Zhou, S.-M. Hu, and N. J. Mitra. Interactive images: Cuboid proxies for smart image manipulation. ACM Transactions on Graphics, 3 1(4), 2012. 2 11888800</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
