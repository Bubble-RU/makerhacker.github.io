<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-334" href="../iccv2013/iccv-2013-Query-Adaptive_Asymmetrical_Dissimilarities_for_Visual_Object_Retrieval.html">iccv2013-334</a> <a title="iccv-2013-334-reference" href="#">iccv2013-334-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>334 iccv-2013-Query-Adaptive Asymmetrical Dissimilarities for Visual Object Retrieval</h1>
<br/><p>Source: <a title="iccv-2013-334-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zhu_Query-Adaptive_Asymmetrical_Dissimilarities_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Cai-Zhi Zhu, Hervé Jégou, Shin'Ichi Satoh</p><p>Abstract: Visual object retrieval aims at retrieving, from a collection of images, all those in which a given query object appears. It is inherently asymmetric: the query object is mostly included in the database image, while the converse is not necessarily true. However, existing approaches mostly compare the images with symmetrical measures, without considering the different roles of query and database. This paper first measure the extent of asymmetry on large-scale public datasets reflecting this task. Considering the standard bag-of-words representation, we then propose new asymmetrical dissimilarities accounting for the different inlier ratios associated with query and database images. These asymmetrical measures depend on the query, yet they are compatible with an inverted file structure, without noticeably impacting search efficiency. Our experiments show the benefit of our approach, and show that the visual object retrieval task is better treated asymmetrically, in the spirit of state-of-the-art text retrieval.</p><br/>
<h2>reference text</h2><p>[1] R. Arandjelovi c´ and A. Zisserman. Multiple queries for large scale specific object retrieval. In BMVC, 2012. 4, 7</p>
<p>[2] R. Arandjelovi c´ and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, 2012. 1, 2, 7</p>
<p>[3] O. Chum, J. Philbin, J. Sivic, M. Isard, and A. Zisserman. Total recall: Automatic query expansion with a generative feature model for object retrieval. In ICCV, 2007. 1, 6</p>
<p>[4] S. C. Hoi, R. Jin, J. Zhu, and M. R. Lyu. Semi-supervised SVM batch mode active learning for image retrieval. In CVPR, 2008. 1</p>
<p>[5] H. J ´egou, M. Douze, and C. Schmid. Hamming embedding and weak geometric consistency for large scale image search. In ECCV, 2008. 1, 3</p>
<p>[6] H. J ´egou, M. Douze, and C. Schmid. On the burstiness of visual elements. In CVPR, 2009. 2</p>
<p>[7] H. J ´egou, H. Harzallah, and C. Schmid. A contextual dissimilarity measure for accurate and efficient image search. In CVPR, 2007. 1, 6</p>
<p>[8] B. Kulis, K. Saenko, and T. Darrell. What you saw is not</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]  what you get: Domain adaptation using asymmetric kernel transforms. In CVPR, 2011. 1 S. Kullback and R. A. Leibler. On information and sufficiency. Ann. Math. Statist., 22(1):79–86, 195 1. 1 D. Lowe. Distinctive image features from scale-invariant key points. IJCV, 60:91–1 10, 2004. 2 C. D. Manning, P. Raghavan, and H. Sch u¨tze. An Introduction to Information Retrieval. Cambridge University Press, 2009. 1 K. Mikolajczyk and C. Schmid. Scale & affine invariant interest point detectors. IJCV, 1:63–86, 2004. 2 D. Nist e´r and H. Stew e´nius. Scalable recognition with a vocabulary tree. In CVPR, 2006. 1, 6 O. Paul, G. Awad, J. Fiscus, G. Sanders, and B. Shaw. Trecvid 2012 - an introduction of the goals, tasks, data, evaluation mechanisms and metrics. In TRECVID, 2012. 1, 2, 7</p>
<p>[15] M. Perdˇoch, O. Chum, and J. Matas. Efficient representation of local geometry for large scale object retrieval. In CVPR, 2009. 2, 7</p>
<p>[16] J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman. Object retrieval with large vocabularies and fast spatial matching. In CVPR, 2007. 1, 2, 3, 7</p>
<p>[17] J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman. Lost in quantization: Improving particular object retrieval in large scale image databases. In CVPR, 2008. 1, 2, 6, 7</p>
<p>[18] S. E. Robertson and K. S. arck Jones. Relevance weighting of search terms. Journal of the American Society for Information Science, 27(3), 1976. 1</p>
<p>[19] S. E. Robertson, S. Walker, S. Jones, M. Hancock-Beaulieu, and M. Gatford. Okapi at TREC-3. In TREC, 1994. 1</p>
<p>[20] G. Salton and M. J. McGill. Introduction to modern information retrieval. McGraw-Hill, 1983. 1</p>
<p>[21] J. Sivic and A. Zisserman. Video google: A text retrieval approach to object matching in videos. In ICCV, 2003. 1, 3, 6</p>
<p>[22] P. Tirilly and V. Claveau. Distances and weighting schemes for bag of visual words image retrieval. In ICMR, 2010. 6</p>
<p>[23] W. Zhou, Y. Lu, H. Li, Y. Song, and Q. Tian. Spatial coding for large scale partial-duplicate web image search. In ACM Multimedia, 2010. 1</p>
<p>[24] C.-Z. Zhu and S. Satoh. Large vocabulary quantization for searching instances from videos. In ICMR, 2012. 1, 4, 7 11771122</p>
<br/>
<br/><br/><br/></body>
</html>
