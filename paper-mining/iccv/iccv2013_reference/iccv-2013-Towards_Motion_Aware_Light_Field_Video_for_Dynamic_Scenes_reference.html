<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-423" href="../iccv2013/iccv-2013-Towards_Motion_Aware_Light_Field_Video_for_Dynamic_Scenes.html">iccv2013-423</a> <a title="iccv-2013-423-reference" href="#">iccv2013-423-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>423 iccv-2013-Towards Motion Aware Light Field Video for Dynamic Scenes</h1>
<br/><p>Source: <a title="iccv-2013-423-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Tambe_Towards_Motion_Aware_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Salil Tambe, Ashok Veeraraghavan, Amit Agrawal</p><p>Abstract: Current Light Field (LF) cameras offer fixed resolution in space, time and angle which is decided a-priori and is independent of the scene. These cameras either trade-off spatial resolution to capture single-shot LF [20, 27, 12] or tradeoff temporal resolution by assuming a static scene to capture high spatial resolution LF [18, 3]. Thus, capturing high spatial resolution LF video for dynamic scenes remains an open and challenging problem. We present the concept, design and implementation of a LF video camera that allows capturing high resolution LF video. The spatial, angular and temporal resolution are not fixed a-priori and we exploit the scene-specific redundancy in space, time and angle. Our reconstruction is motion-aware and offers a continuum of resolution tradeoff with increasing motion in the scene. The key idea is (a) to design efficient multiplexing matrices that allow resolution tradeoffs, (b) use dictionary learning and sparse repre- sentations for robust reconstruction, and (c) perform local motion-aware adaptive reconstruction. We perform extensive analysis and characterize the performance of our motion-aware reconstruction algorithm. We show realistic simulations using a graphics simulator as well as real results using a LCoS based programmable camera. We demonstrate novel results such as high resolution digital refocusing for dynamic moving objects.</p><br/>
<h2>reference text</h2><p>[1] A. Agrawal, A. Veeraraghavan, and R. Raskar. Reinterpretable imager: Towards variable post-capture space, angle and time resolution in photography. Computer Graphics Forum, 29:763–773, May 2010. 3</p>
<p>[2] M. Aharon, M. Elad, and A. Bruckstein. K-svd: Design of dictionaries for sparse representation. Proc. SPARS, 5:9–12, 2005. 4</p>
<p>[3] D. Babacan, R. Ansorge, M. Luessi, P. Ruiz, R. Molina, and A. Katsaggelos. Compressive light field sensing. IEEE Trans. Image Processing, 21:4746–4757, 2012. 1, 2, 3</p>
<p>[4] T. E. Bishop, S. Zanetti, and P. Favaro. Light field superresolution. In Proc. Int’l Conf. Computational Photography, pages 1–9, 2009. 1, 3</p>
<p>[5] E. J. Cand e`s. The restricted isometry property and its implications for compressed sensing. Comptes Rendus Mathematique, 346(9):589–592, 2008. 5</p>
<p>[6] E. J. Candes, J. K. Romberg, and T. Tao. Stable signal recovery from incomplete and inaccurate measurements. Communications on pure and applied mathematics, 59(8): 1207– 1223, 2006. 3</p>
<p>[7] W. Dong, L. Zhang, G. Shi, and X. Wu. Image deblurring and super-resolution by adaptive sparse domain selec-  tion and adaptive regularization. IEEE Trans. Image Processing, 20(7): 1838–1857, 2011. 4</p>
<p>[8] D. L. Donoho. Compressed sensing. IEEE Trans. Information Theory, 52(4): 1289–1306, 2006. 3</p>
<p>[9] J. M. Duarte-Carvajalino and G. Sapiro. Learning to sense sparse signals: Simultaneous sensing matrix and sparsify11001155  ? ? ?%? &’? ? ? ? ? ? ? ? ? ? ? ? ?! ? </p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]  et  al. [18] completely fails  on  moving objects while  our  motion-aware approach enables high-quality refocusing.  ing dictionary optimization. IEEE Trans. Image Processing, 18(7):1395–1408, 2009. 5 M. Elad. Optimized projections for compressed sensing. IEEE Trans. Signal Processing, 55(12):5695–5702, 2007. 5 M. Elad and M. Aharon. Image denoising via sparse and redundant representations over learned dictionaries. IEEE Trans. Image Processing, 15(12):3736–3745, 2006. 4 T. Georgiev and A. Lumsdaine. Superresolution with plenoptic camera 2.0. Adobe Systems Inc., Tech. Rep, 2009. 1, 2, 3 T. Georgiev, C. Zheng, S. Nayar, B. Curless, D. Salasin, and C. Intwala. Spatio-angular resolution trade-offs in integral photography. In EGSR, pages 263–272, 2006. 2</p>
<p>[14] Y. Hitomi, J. Gu, M. Gupta, T. Mitsunaga, and S. K. Nayar. Video from a single coded exposure photograph using a learned over-complete dictionary. In ICCV, pages 287–294, Nov. 2011. 4</p>
<p>[15] A. Levin, R. Fergus, F. Durand, and W. T. Freeman. Image and depth from a conventional camera with a coded aperture. ACM Trans. Graph., 26(3):70, 2007. 3</p>
<p>[16] M. Levoy, B. Chen, V. Vaish, M. Horowitz, I. McDowall, and M. Bolas. Synthetic aperture confocal imaging. ACM Trans. Graph., 23(3):825–834, 2004. 2</p>
<p>[17] M. Levoy and P. Hanrahan. Light field rendering. In SIGGRAPH, pages 31–42, 1996. 2</p>
<p>[18] C.-K. Liang, T.-H. Lin, B.-Y. Wong, C. Liu, and H. Chen. Programmable aperture photography: Multiplexed light field acquisition. ACM Trans. Graphics, 27(3):55: 1–55: 10, 2008. 1, 2, 3, 4, 6, 8</p>
<p>[19] C. Liu. Beyond Pixels: Exploring New Representations and Applications for Motion Analysis. PhD thesis, MIT, 2009. 5</p>
<p>[20] Lytro. The lytro camera. https://www.lytro.com/. 1, 2</p>
<p>[21] R. F. Marcia, Z. T. Harmany, and R. M. Willett. Compressive coded aperture imaging. In Proc. SPIE, 2009. 3</p>
<p>[22] K. Marwah, G. Wetzstein, Y. Bando, and R. Raskar. Compressive Light Field Photography using Overcomplete Dictionaries and Optimized Projections. ACM Trans. Graph. (Proc. SIGGRAPH), 32(4): 1–1 1, 2013. 2, 3</p>
<p>[23] H. Nagahara, C. Zhou, T. Watanabe, H. Ishiguro, and S. K. Nayar. Programmable aperture camera using lcos. In ECCV, pages 337–350, 2010. 2, 6</p>
<p>[24] R. Ng, M. Levoy, M. Bredif, G. Duval, M. Horowitz, and P. Hanrahan. Light field photography with handheld plenoptic camera. Technical report, Stanford U, 2005. 2, 3</p>
<p>[25] P. Peers, D. K. Mahajan, B. Lamond, A. Ghosh, W. Matusik, R. Ramamoorthi, and P. Debevec. Compressive light transport sensing. ACM Trans. Graphics, 28(1):3, 2009. 3</p>
<p>[26] Pointgrey. Profusion 25 camera. 1</p>
<p>[27] Raytrix. 3d light field camera technology. http://www.raytrix.de/. 1, 2, 3</p>
<p>[28] G. K. Skinner. X-Ray Imaging with Coded Masks. Scientific American, 259:84, Aug. 1988. 3</p>
<p>[29] J. A. Tropp and A. C. Gilbert. Signal recovery from random measurements via orthogonal matching pursuit. IEEE Trans. Information Theory, 53(12):4655–4666, 2007. 4</p>
<p>[30] A. Veeraraghavan, R. Raskar, A. Agrawal, A. Mohan, and J. Tumblin. Dappled photography: Mask enhanced cameras for heterodyned light fields and coded aperture refocusing. ACM Trans. Graph., 26(3):69: 1–69: 12, 2007. 2, 3</p>
<p>[31] B. Wilburn, N. Joshi, V. Vaish, E.-V. Talvala, E. Antunez, A. Barth, A. Adams, M. Horowitz, and M. Levoy. High performance imaging using large camera arrays. ACM Trans. Graph., 24(3):765–776, 2005. 2</p>
<p>[32] X. Yuan, J. Yang, P. Llull, X. Liao, G. Sapiro, D. J. Brady, and L. Carin. Adaptive temporal compressive sensing for video. arXiv preprint arXiv:1302.3446, 2013. 3</p>
<p>[33] Q. Zhang and B. Li. Discriminative k-svd for dictionary learning in face recognition. In CVPR, pages 2691–2698, 2010. 4 11001166</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
