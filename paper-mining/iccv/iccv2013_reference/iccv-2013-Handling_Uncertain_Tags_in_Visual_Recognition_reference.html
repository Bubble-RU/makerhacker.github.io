<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>191 iccv-2013-Handling Uncertain Tags in Visual Recognition</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-191" href="../iccv2013/iccv-2013-Handling_Uncertain_Tags_in_Visual_Recognition.html">iccv2013-191</a> <a title="iccv-2013-191-reference" href="#">iccv2013-191-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>191 iccv-2013-Handling Uncertain Tags in Visual Recognition</h1>
<br/><p>Source: <a title="iccv-2013-191-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Vahdat_Handling_Uncertain_Tags_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Arash Vahdat, Greg Mori</p><p>Abstract: Gathering accurate training data for recognizing a set of attributes or tags on images or videos is a challenge. Obtaining labels via manual effort or from weakly-supervised data typically results in noisy training labels. We develop the FlipSVM, a novel algorithm for handling these noisy, structured labels. The FlipSVM models label noise by “flipping ” labels on training examples. We show empirically that the FlipSVM is effective on images-and-attributes and video tagging datasets.</p><br/>
<h2>reference text</h2><p>[1] T. L. Berg, A. C. Berg, and J. Shih. Automatic attribute discovery and characterization from noisy web data. In ECCV, 2010. 2</p>
<p>[2] O. Chapelle, C. B. Do, Q. V. Le, A. J. Smola, and C. H. Teo. Tighter bounds for structured estimation. In NIPS, 2008. 2</p>
<p>[3] R. Collobert, F. H. Sinz, J. Weston, and L. Bottou. Trading convexity for scalability. In ICML, 2006. 2</p>
<p>[4] T. M. T. Do and T. Arti e`res. Large margin training for hidden markov models with partially observed states. In ICML, 2009. 4</p>
<p>[5] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describing objects by their attributes. In CVPR, 2009. 1, 2, 5 774433 Rank  Wedding Ceremony  Rank  Landing Fish  21 Tags: house, day, child, shot, performance, ceremony, building, indoors, birthday, wedding  Tags: lake, river, landing fish, water, fish, vehicles, lady, clip, amateur footage , drive  33 Tags: house, child, day, ceremony, shot, indoors, performance, montage, wedding ceremony, park  Tags: lake, river, water, drive, landing fish, lady, fish, fishing feed, men  910 Tags: shot, child, children, ceremony, wedding, lady, dancing, birthday, indoors, building  Tags: lake, river, drive, landing fish, water, amateur footage, fishing, boat, fish, lady  RankRepairing Appliance  2 Tags: repairing appliance, machine, demonstration/tutorial, work, person  5 Tags: repairing appliance, demonstration/tutorial, machine, talk, man, piece  15 Tags: repairing appliance, amateur footage, demonstration/tutorial man, home video, talk, machine, person, clip Figure 3: Qualitative visualization of TRECVID MED results. Each column shows three videos that are retrieved for a particular event category from the test dataset. The rank of each video is reported next to it, where its color indicates the ground truth event label, i.e. red/green indicate the negative/positive classes respectively. Tags are shown below each video sorted by decreasing confidence score. Here at most 10 tags that have score greater than a threshold are reported. Our algorithm not only learns the tags that are associated with each category, but also it discriminates some less common ones such as “park” and “dancing” in wedding ceremony, “feed” in landing fish, or “talk” in repairing appliance. Note how the detection of “river”, “lake” and “water” misleads our algorithm to classify two background videos as landing fish category.</p>
<p>[6] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. PAMI, 32(9): 1627–1645, 2010. 2, 3</p>
<p>[7] V. Ferrari and A. Zisserman. Learning visual attributes. In NIPS, 2007. 2</p>
<p>[8] H. Izadinia and M. Shah. Recognizing complex events using large margin joint low-level event model. In ECCV, 2012. 2, 4, 7</p>
<p>[9] L. S. Kennedy, S.-F. Chang, and I. Kozintsev. To search or to label?: predicting the performance of search-based automatic image classifiers. In ACM Multimedia Information Retrieval, 2006. 6</p>
<p>[10] G. Kulkarni, V. Premraj, S. Dhar, S. Li, Y. Choi, A. C. Berg, and T. L. Berg. Baby talk: Understanding and generating simple image descriptions. In CVPR, 2011. 1</p>
<p>[11] N. Kumar, A. C. Berg, P. N. Belhumeur, and S. K. Nayar. Attribute and simile classifiers for face verification. In ICCV, 2009. 1, 2</p>
<p>[12] T. Leung, Y. Song, and J. Zhang. Handling label noise in video classification via multiple instance learning. In ICCV, 2011. 2, 5</p>
<p>[13] D. A. McAllester and J. Keshet. Generalization bounds and consistency for latent structural probit and ramp loss. In NIPS, 2011. 2</p>
<p>[14] P. Over, G. Awad, M. Michel, J. Fiscus, W. Kraaij, A. F. Smeaton, and G. Quenot. Trecvid 2011 an overview of the goals, tasks, data, evaluation mechansims and metrics. In Proceedings of TRECVID 2011, 2011. 5, 6</p>
<p>[15] D. Parikh and K. Grauman. Interactively building a discriminative vocabulary of nameable attributes. In CVPR, 2011. 2 —  774444</p>
<p>[16] D. Parikh and K. Grauman. Relative attributes. In ICCV, 2011. 2</p>
<p>[17] G.-J. Qi, X.-S. Hua, Y. Rui, J. Tang, T. Mei, and H.-J. Zhang. Correlative multi-label video annotation. In ACM Multimedia, 2007. 2, 4, 5</p>
<p>[18] S. Richter, R. Ferriday, and the Zope Community. Topia, content term extraction using POS tagging, https://pypi.python.org/pypi/topia.termextract, Jan. 2013. 7</p>
<p>[19] O. Russakovsky and F.-F. Li. Attribute learning in large-scale datasets. In ECCV Worksh. on Parts and Attributes, 2010. 2</p>
<p>[20] B. Siddiquie, R. Feris, and L. Davis. Image ranking and retrieval based on multi-attribute queries. In CVPR, 2011. 1, 2</p>
<p>[21] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Support vector machine learning for interdependent and structured output spaces. In ICML, 2004. 2, 3, 4</p>
<p>[22] A. Vedaldi, V. Gulshan, M. Varma, and A. Zisserman. Multiple kernels for object detection. In ICCV, 2009. 6</p>
<p>[23] P. A. Viola, J. C. Platt, and C. Zhang. Multiple instance boosting for object detection. In NIPS, 2005. 2</p>
<p>[24] Y. Wang and G. Mori. Max-margin hidden conditional random fields for human action recognition. In CVPR, 2009. 3</p>
<p>[25] Y. Wang and G. Mori. A discriminative latent model of object classes and attributes. In ECCV, 2010. 2, 4, 6</p>
<p>[26] W. Yang and G. Toderici. Discriminative tag learning on youtube videos with latent sub-tags. In CVPR, 2011. 1, 2</p>
<p>[27] C.-N. J. Yu and T. Joachims. Learning structural SVMs with latent variables. In ICML, 2009. 4</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
