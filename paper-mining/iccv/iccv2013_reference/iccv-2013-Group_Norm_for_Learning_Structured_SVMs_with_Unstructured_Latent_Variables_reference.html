<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-187" href="../iccv2013/iccv-2013-Group_Norm_for_Learning_Structured_SVMs_with_Unstructured_Latent_Variables.html">iccv2013-187</a> <a title="iccv-2013-187-reference" href="#">iccv2013-187-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>187 iccv-2013-Group Norm for Learning Structured SVMs with Unstructured Latent Variables</h1>
<br/><p>Source: <a title="iccv-2013-187-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Chen_Group_Norm_for_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Daozheng Chen, Dhruv Batra, William T. Freeman</p><p>Abstract: Latent variables models have been applied to a number of computer vision problems. However, the complexity of the latent space is typically left as a free design choice. A larger latent space results in a more expressive model, but such models are prone to overfitting and are slower to perform inference with. The goal of this paper is to regularize the complexity of the latent space and learn which hidden states are really relevant for prediction. Specifically, we propose using group-sparsity-inducing regularizers such as ?1-?2 to estimate the parameters of Structured SVMs with unstructured latent variables. Our experiments on digit recognition and object detection show that our approach is indeed able to control the complexity of latent space without any significant loss in accuracy of the learnt model.</p><br/>
<h2>reference text</h2><p>[1] F. Bach, R. Jenatton, J. Mairal, and G. Obozinski. Structured sparsity through convex optimization. Statistical Science, 2012.</p>
<p>[2] S. Bakin. Adaptive Regression and Model Selection in Data Mining Problems. Australian National University, 1999.</p>
<p>[3] S. Bengio, F. Pereira, Y. Singer, and D. Strelow. Group sparse coding. In NIPS, 2009.</p>
<p>[4] Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Curriculum learning. In ICML, 2009.</p>
<p>[5] V. Chandrasekaran, P. A. Parrilo, and A. S. Willsky. Latent variable graphical model selection via convex optimization. Annals of Statis-</p>
<p>[6]</p>
<p>[7]</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]  tics, 2012. S. S. Chen, D. L. Donoho, and M. A. Saunders. Atomic decomposition by basis pursuit. SIAM Review, 2001. N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR, 2005. A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, 1977. S. K. Divvala, A. A. Efros, and M. Hebert. How important are deformable parts in the deformable parts model? CoRR, abs/1206.3714, 2012. D. L. Donoho. Compressed sensing. Info. Theory, 2006. B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani. Least angle regression. The Annals of Statistics, 2004. M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results. http://www.pascalnetwork.org/challenges/VOC/voc2007/workshop/index.html.  The last row in the root+part table shows the number of non-sparse</p>
<p>[13] P. F. Felzenszwalb, R. B. Girshick, and D. McAllester. Discriminatively trained deformable part models, release 4. http://www.cs.brown.edu/∼pff/latent-release4/.</p>
<p>[14] hP.t tpF.: F//ewlzwewn.sczsw.barolbw, Rn.e. dBu. /G∼irpsfhf/licatke, nDt-. MelecaAslel4e/s.ter, and D. Ramanan. Object detection with discriminatively trained part-based models. PAMI, 2010.</p>
<p>[15] K. Jia, T.-H. Chan, and Y. Ma. Robust and practical face recognition via structured sparsity. In ECCV, 2012.</p>
<p>[16] Y. Jia, M. Salzmann, and T. Darrell. Factorized latent spaces with structured sparsity. In NIPS, 2010.</p>
<p>[17] T. Koo, A. M. Rush, M. Collins, T. Jaakkola, and D. Sontag. Dual decomposition for parsing with non-projective head automata. In EMNLP, 2010.</p>
<p>[18] P. Kumar, B. Packer, and D. Koller. Self-paced learning for latent variable models. In NIPS, 2010.</p>
<p>[19] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 1998.</p>
<p>[20] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary learning for sparse coding. In ICML, 2009.</p>
<p>[21] P. Ott and M. Everingham. Shared parts for deformable part-based models. In CVPR, 201 1.</p>
<p>[22] H. Pirsiavash and D. Ramanan. Steerable part models. In CVPR, 2012.</p>
<p>[23] A. Quattoni, M. Collins, and T. Darrell. Conditional random fields for object recognition. In NIPS, 2004.</p>
<p>[24] L. Rabiner. A tutorial on hidden markov models and selected applications in speech recognition. Proceedings of the IEEE, 1989.</p>
<p>[25] H. O. Song, S. Zickler, T. Althoff, R. Girshick, M. Fritz, C. Geyer, P. Felzenszwalb, and T. Darrell. Sparselet models for efficient multiclass object detection. In ECCV, 2012.</p>
<p>[26] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society, 1996.</p>
<p>[27] C. J. Yu and T. Joachims. Learning structural svms with latent variables. In ICML, 2009.</p>
<p>[28] M. Yuan, M. Yuan, Y. Lin, and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of the Royal Statistical Society, Series B, 2006.</p>
<p>[29] A. L. Yuille and A. Rangarajan. The concave-convex procedure. Neural Computation, 2003.</p>
<p>[30] H. Zou and T. Hastie. Regularization and variable selection via the elastic net. Journal Of The Royal Statistical Society Series B, 2005. 416</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
