<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>20 iccv-2013-A Max-Margin Perspective on Sparse Representation-Based Classification</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-20" href="../iccv2013/iccv-2013-A_Max-Margin_Perspective_on_Sparse_Representation-Based_Classification.html">iccv2013-20</a> <a title="iccv-2013-20-reference" href="#">iccv2013-20-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>20 iccv-2013-A Max-Margin Perspective on Sparse Representation-Based Classification</h1>
<br/><p>Source: <a title="iccv-2013-20-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Wang_A_Max-Margin_Perspective_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Zhaowen Wang, Jianchao Yang, Nasser Nasrabadi, Thomas Huang</p><p>Abstract: Sparse Representation-based Classification (SRC) is a powerful tool in distinguishing signal categories which lie on different subspaces. Despite its wide application to visual recognition tasks, current understanding of SRC is solely based on a reconstructive perspective, which neither offers any guarantee on its classification performance nor provides any insight on how to design a discriminative dictionary for SRC. In this paper, we present a novel perspective towards SRC and interpret it as a margin classifier. The decision boundary and margin of SRC are analyzed in local regions where the support of sparse code is stable. Based on the derived margin, we propose a hinge loss function as the gauge for the classification performance of SRC. A stochastic gradient descent algorithm is implemented to maximize the margin of SRC and obtain more discriminative dictionaries. Experiments validate the effectiveness of the proposed approach in predicting classification performance and improving dictionary quality over reconstructive ones. Classification results competitive with other state-ofthe-art sparse coding methods are reported on several data sets.</p><br/>
<h2>reference text</h2><p>[1] M. Aharon, M. Elad, and A. Bruckstein. K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation. IEEE Trans. Sig. Proc., 54(11):43 11–4322, 2006.</p>
<p>[2] B. E. Boser, I. M. Guyon, and V. N. Vapnik. A training algorithm for optimal margin classifiers. In the 5th Annual Workshop on Computational Learning Theory, pages 144– 152, 1992.</p>
<p>[3] L. Bottou. Stochastic learning. In O. Bousquet and U. von Luxburg, editors, Advanced Lectures on Machine Learning, Lecture Notes in Artificial Intelligence, LNAI 3 176, pages 146–168. Springer Verlag, 2004.</p>
<p>[4] D. M. Bradley and J. A. Bagnell. Differential sparse coding. In Adv. NIPS, pages 113–120, 2008.</p>
<p>[5] C.-K. Chiang, C.-H. Duan, S.-H. Lai, and S.-F. Chang. Learning component-level sparse representation using histogram information for image classification. In Proc. ICCV, pages 1519–1526, 2011.</p>
<p>[6] S. F. Cotter. Sparse representation for accurate classification of corrupted and occluded facial expressions. In Proc. ICASSP, pages 838–841, 2010.</p>
<p>[7] C. Domeniconi, J. Peng, and D. Gunopulos. Locally adaptive metric nearest-neighbor classification. IEEE Trans. PAMI, 24(9): 1281–1285, 2002.</p>
<p>[8] K. Engan, S. O. Aase, and J. Hakon Husoy. Method of optimal directions for frame design. In Proc. ICASSP, pages 2443–2446, 1999.</p>
<p>[9] A. Georghiades, P. Belhumeur, and D. Kriegman. From few to many: illumination cone models for face recognition under variable lighting and pose. IEEE Trans. PAMI, 23(6):643–660, 2001.</p>
<p>[10] Z. Jiang, Z. Lin, and L. S. Davis. Learning a discriminative dictionary for sparse coding via label consistent K-SVD. In Proc. CVPR, pages 1697–1704, 2011.</p>
<p>[11] T. Kohonen. Improved versions of learning vector quanti-</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]</p>
<p>[16]</p>
<p>[17]</p>
<p>[18]</p>
<p>[19]</p>
<p>[20]</p>
<p>[21]</p>
<p>[22]  zation. In IJCNN International Joint Conference on Neural Networks, volume 1, pages 545–550, 1990. Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradientbased learning applied to document recognition. Proceedings of the IEEE, 86(1 1):2278–2324, 1998. H. Lee, A. Battle, R. Raina, and A. Y. Ng. Efficient sparse coding algorithms. In Adv. NIPS, pages 801–808, 2007. J. Mairal, F. Bach, and J. Ponce. Task-driven dictionary learning. IEEE Trans. PAMI, 32(4), 2012. J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary learning for sparse coding. In Proc. ICML, pages 689–696, 2009. J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Discriminative learned dictionaries for local image analysis. In Proc. CVPR, pages 1–8, 2008. A. Martinez and R. Benavente. The AR face database. CVC Technical Report 24, 1998. N. Mehta and A. Gray. Sparsity-based generalization bounds for predictive sparse coding. In Proc. ICML, 2013. accepted. Q. Qiu, Z. Jiang, and R. Chellappa. Sparse dictionary-based representation and recognition of action attributes. In Proc. ICCV, pages 707–714, 2011. I. Ramirez, P. Sprechmann, and G. Sapiro. Classification and clustering via dictionary learning with structured incoherence and shared features. In Proc. CVPR, pages 3501– 3508, 2010. M. Soltanolkotabi and E. J. Candes. A geometric analysis of subspace clustering with outliers. arXiv preprint arXiv:1112.4258, 2011. V. Vapnik. The nature of statistical learning theory. springer, 1999.</p>
<p>[23] K. Q. Weinberger, J. Blitzer, and L. K. Saul. Distance metric learning for large margin nearest neighbor classification. In Adv. NIPS, pages 1473–1480, 2006.</p>
<p>[24] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma. Robust face recognition via sparse representation. IEEE Trans. PAMI, 31(2):210–227, 2009.</p>
<p>[25] J. Yang, J. Wang, and T. S. Huang. Learning the sparse representation for classification. In Proc. ICME, pages 1–6, 2011.</p>
<p>[26] J. Yang, Z. Wang, Z. Lin, X. Shu, and T. Huang. Bilevel sparse coding for coupled feature spaces. In Proc. CVPR, 2012.</p>
<p>[27] M. Yang, L. Zhang, X. Feng, and D. Zhang. Fisher discrimination dictionary learning for sparse representation. In Proc. ICCV, pages 543–550, 2011.</p>
<p>[28] L. Zhang, M. Yang, and X. Feng. Sparse representation or collaborative representation: Which helps face recognition? In Proc. ICCV, pages 471–478, 2011.</p>
<p>[29] H. Zou, T. Hastie, and R. Tibshirani. On the “degrees of freedom” of the LASSO. The Annals of Statistics, 35(5):2173– 2192, 2007. 1224</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
