<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</title>
</head>

<body>
<p><a title="iccv" href="../iccv_home.html">iccv</a> <a title="iccv-2013" href="../home/iccv2013_home.html">iccv2013</a> <a title="iccv-2013-63" href="#">iccv2013-63</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</h1>
<br/><p>Source: <a title="iccv-2013-63-pdf" href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Nosrati_Bounded_Labeling_Function_2013_ICCV_paper.pdf">pdf</a></p><p>Author: Masoud S. Nosrati, Shawn Andrews, Ghassan Hamarneh</p><p>Abstract: The inclusion of shape and appearance priors have proven useful for obtaining more accurate and plausible segmentations, especially for complex objects with multiple parts. In this paper, we augment the popular MumfordShah model to incorporate two important geometrical constraints, termed containment and detachment, between different regions with a specified minimum distance between their boundaries. Our method is able to handle multiple instances of multi-part objects defined by these geometrical hamarneh} @ s fu . ca (a)Standar laΩb ehlingΩfuhnctionseting(Ωb)hΩOuirseΩtijng Figure 1: The inside vs. outside ambiguity in (a) is resolved by our containment constraint in (b). constraints using a single labeling function while maintaining global optimality. We demonstrate the utility and advantages of these two constraints and show that the proposed convex continuous method is superior to other state-of-theart methods, including its discrete counterpart, in terms of memory usage, and metrication errors.</p><p>Reference: <a title="iccv-2013-63-reference" href="../iccv2013_reference/iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper, we augment the popular MumfordShah model to incorporate two important geometrical constraints, termed containment and detachment, between different regions with a specified minimum distance between their boundaries. [sent-3, score-0.957]
</p><p>2 Our method is able to handle multiple instances of multi-part objects defined by these geometrical hamarneh} @ s fu . [sent-4, score-0.171]
</p><p>3 outside ambiguity in (a) is resolved by  our containment constraint in (b). [sent-6, score-0.822]
</p><p>4 constraints using a single labeling function while maintaining global optimality. [sent-7, score-0.256]
</p><p>5 We demonstrate the utility and advantages of these two constraints and show that the proposed convex continuous method is superior to other state-of-theart methods, including its discrete counterpart, in terms of memory usage, and metrication errors. [sent-8, score-0.415]
</p><p>6 Introduction The piecewise constant Mumford-Shah (MS) model [18] is one of the most popular models in image segmentation. [sent-10, score-0.037]
</p><p>7 In recent years, many efforts have been made to improve this model in terms of optimizability, by simplifying the objective function and formulating it as a convex energy functional [2, 7, 20], and fidelity, by making the objective function more faithful to the underlying segmentation tasks. [sent-11, score-0.339]
</p><p>8 In image segmentation literature, improving objective function fidelity has taken several forms: (i) adding new energy terms, e. [sent-12, score-0.261]
</p><p>9 edge, region, and, shape prior terms [1]; (ii) extending binary segmentation methods to multi-label segmentation [8, 26]; and (iii) incorporating spatial relationships between labels, objects, or object parts [14]. [sent-14, score-0.487]
</p><p>10 In many image labeling tasks, some geometric relationships are known beforehand, and incorporating this information into a segmentation algorithm improves results. [sent-15, score-0.422]
</p><p>11 In this paper, we focus on segmentation tasks where two regions must be separated by a third. [sent-16, score-0.192]
</p><p>12 Specifically, we focus primarily on the geometric constraint containment,  where one region separates a second region from the background (cf. [sent-17, score-0.364]
</p><p>13 Other geometric constraints can also be enforced using the same framework, such as detachment, where the background separates two regions. [sent-20, score-0.244]
</p><p>14 This paper addresses the problem of multi-region segmentation with these two important geometrical constraints, containment and detachment with a minimum distance (or thickness) between regions’ boundaries, in a continuous framework while maintaining global optimality. [sent-21, score-1.512]
</p><p>15 We choose these two geometrical constraints due to their intuitive definitions, descriptive power, and ability to help properly segment regions with weak intensity/color appearance models. [sent-22, score-0.263]
</p><p>16 Using a continuous framework provides several advantages over discrete methods: 1) no metrication error; 2) less memory usage; 3) efficient parallelizability, and 4) allowance for sub-pixel resolution. [sent-23, score-0.341]
</p><p>17 Previous works Improving segmentation via encoding spatial relations between multiple target objects is not new. [sent-26, score-0.238]
</p><p>18 For example, some methods encode spatial relationships via relative interobject distances [17] while other works have incorporated fuzzy spatial relationships [9], but those methods do not handle stricter geometric constraints such as containment. [sent-27, score-0.598]
</p><p>19 Another popular approach is to perform atlas-based segmentation, which has been particularly useful in medical image analysis applications since an atlas encodes the spatial relationships between multiple anatomical structures, or  2032  Ω hi(wa)Ωj Ω hi(b)Ωj Ω hi(c)Ω j Figure 2: Containment vs. [sent-28, score-0.273]
</p><p>20 According to (3), “object icontains object j” in (a) with Th(Ωh , Ωi , Ωj ) ≥ w, but the relationship between iand j in (b) and (c) is not co)nt ≥ain wm,e bnut. [sent-30, score-0.067]
</p><p>21 However, those methods have been designed to encode constraints on a single instance of an object in an image, not multiple instances, spatially-recurring throughout the image. [sent-32, score-0.194]
</p><p>22 A few recent works have focused on tiered segmentation to encode adjacency relationships [12, 21]. [sent-33, score-0.373]
</p><p>23 [21] proposed a generalized label ordering constraint which can enforce many complex geometric constraints while maintaining convexity. [sent-35, score-0.282]
</p><p>24 This method requires that the constraint term obey the triangle inequality, a requirement that was later relaxed by introducing a convex relaxation method for non-metric priors [22]. [sent-36, score-0.153]
</p><p>25 Both [21] and [22] are designed to penalize transitions between adjacent labels, but for meaningful containment and detachment con-  straints, a minimum spatial distance between non-adjacent labels is required. [sent-37, score-1.119]
</p><p>26 Other recent works have focused on incorporating topological constraints into a segmentation objective function. [sent-38, score-0.359]
</p><p>27 In the continuous domain, some methods incorporate the containment constraint into their segmentation framework by simultaneously evolving a coupled surfaces [19, 23, 25, 28]. [sent-39, score-1.063]
</p><p>28 However, these works are limited to objects with two surfaces and also are limited to segmenting a single instance of each object in an image. [sent-40, score-0.122]
</p><p>29 [16] proposed a method to segment nested objects, but their method is limited to star-shaped objects. [sent-42, score-0.068]
</p><p>30 [24] proposed segmentation methods that encode geometric constraints (including containment) between distinct regions into a graph cut framework. [sent-44, score-0.415]
</p><p>31 Our work can be viewed as a continuous analogue to these works, providing several advantages, as noted earlier and as will demonstrated in Section 4. [sent-45, score-0.126]
</p><p>32 We represent our segmentation using a single continuous labeling function, assigning each region to an interval of label values. [sent-46, score-0.435]
</p><p>33 We perform segmentation via energy minimization, and we ensure a globally optimal solution using a “functional lifting” technique, similar to what is used by Pock et al. [sent-47, score-0.211]
</p><p>34 [20], to convexify our data energy term by reformulating the problem in a higher dimensional space. [sent-48, score-0.142]
</p><p>35 This approach exhibits several important qualities, such as the ability to deal with topological changes (e. [sent-49, score-0.052]
</p><p>36 spatially recurring instances of an object), and extendibility to higher dimensional images. [sent-51, score-0.078]
</p><p>37 We introduce the containment and detachment con-  straints in Section 2. [sent-52, score-1.136]
</p><p>38 We show how to encode these two constraints in a continuous segmentation framework and show how our formulation can be convexified by functional lifting in Section 2. [sent-53, score-0.533]
</p><p>39 Different examples as well as comparisons with other popular state-of-the-art methods are given in Section 4, followed by our conclusions in Section 5. [sent-56, score-0.037]
</p><p>40 Methodology In this section we explicitly define containment and detachment and show how we encode them in a MS based model while maintaining global optimality. [sent-58, score-1.21]
</p><p>41 We first consider a containment constraint in a 3 region segmentation. [sent-59, score-0.869]
</p><p>42 1g(eb )d)o: mthaei no,u Ωtsi⊂d e or background region Ωh, the outer region Ωi, and the contained region Ωj, where Ω = Ωh ∪ Ωi ∪ Ωj . [sent-61, score-0.352]
</p><p>43 In many binary segmentation applications that∪ use r∪el Ωaxed labeling functions, label values below 1/2 correspond to background and values above 1/2 correspond to foreground. [sent-62, score-0.275]
</p><p>44 Given a label set Γ = [0, 1], we define our labeling function u : Ω → Γ, such that 0 ≤ u(x) < 1/3 ⇐⇒ x ∈ Ωh 1/3 ≤ u(x) < 2/3 ⇐⇒ x ∈ Ωi 2/3 ≤ u(x) < 1 ⇐⇒ x ∈ Ωj . [sent-64, score-0.085]
</p><p>45 (1)  To precisely define containment, we introduce a function that measures the thickness of the outer region Ωi:  Th(Ωh,Ωi,Ωj) = x m1∈inΩj x2m∈iΩnh ? [sent-65, score-0.296]
</p><p>46 (2) We define containment for 3 regions as: Definition 1 (Containment). [sent-68, score-0.781]
</p><p>47 We say object i contains object j with thickness w if and only if Th(Ωh, Ωi, Ωj) ≥ w . [sent-69, score-0.232]
</p><p>48 2(a) where the light gray object, i, contains the dark gray object, j, with a minimum thickness of w. [sent-72, score-0.313]
</p><p>49 The related configurations between iand j seen in Fig. [sent-73, score-0.068]
</p><p>50 2(b) and (c) are not containment based on our definition in (3). [sent-74, score-0.775]
</p><p>51 However, (b) can be seen as containment in a 4 region segmentation: i contains the interior white region, and the interior white region contains j. [sent-75, score-1.109]
</p><p>52 Given an input image1 I: Ω ⊂ R2 → R, for objects i and j and the background h:, Ω Ωlet ⊂ μi, μj an Rd, μh b oeb constant approximations of the regional intensities and define 1Our method can be extended to vector valued images, e. [sent-76, score-0.17]
</p><p>53 To segment I such tha(tx xi) c =on |tIa(inxs) j we soflvore kth =e following energy emnint Iim siuzcahtion problem: gk  −  arug∈mDinE(u,g)  = arug∈mDin? [sent-79, score-0.124]
</p><p>54 y directions, g = (gHhe, gi, gj ), and ρ(x, u(x) , g) : Ω → R+ is a non-negative data term t)h,a atn encourages u gto) satisfy (R1), e. [sent-85, score-0.061]
</p><p>55 Constraining u to D, E(u, g) ensures that object j and object h have no shared boundaries, resulting in j being contained in i. [sent-89, score-0.092]
</p><p>56 In other words, the segmentation corresponding to u cannot abruptly change from object j to object h, and thus the value of u cannot change from u ≥ 2/3 tjeoc u h≤, a1n/d3 hinu a dthiseta vnalcuee el oefss u uth caann w. [sent-90, score-0.367]
</p><p>57 uT ≤his 1 l3e iands a us ctoe tshse t afnac wt that the constraint Th(Ωh, Ωi, Ωj) ≥ w can be replaced by the more convenient constra≥int |∇xu| ≤ 31w, which limits the rate tchoantv u can change spatially. [sent-91, score-0.089]
</p><p>58 Here, a black and white image is segmented into three regions, with μh corresponding to black pixels, μi corresponding to (nonexistent) gray pixels, and μj corresponding to white pixels. [sent-101, score-0.165]
</p><p>59 3(b) illustrates the labeling function u corresponding to the segmentation in Fig. [sent-103, score-0.235]
</p><p>60 Here, u becomes discontinuous (unbounded |∇xu|) in ordHeerr eto, uav boeidco assigning any pixels ntob otuhen eexdte |∇rior object ri. [sent-105, score-0.147]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('containment', 0.739), ('detachment', 0.312), ('thickness', 0.172), ('segmentation', 0.15), ('arug', 0.104), ('metrication', 0.104), ('geometrical', 0.1), ('hamarneh', 0.092), ('continuous', 0.089), ('relationships', 0.088), ('constraints', 0.088), ('straints', 0.085), ('labeling', 0.085), ('maintaining', 0.083), ('region', 0.078), ('encode', 0.076), ('lifting', 0.071), ('xu', 0.065), ('energy', 0.061), ('geometric', 0.059), ('functional', 0.059), ('white', 0.057), ('separates', 0.057), ('hi', 0.057), ('topological', 0.052), ('constraint', 0.052), ('gray', 0.051), ('interior', 0.05), ('fidelity', 0.05), ('otuhen', 0.046), ('rior', 0.046), ('allowance', 0.046), ('convexify', 0.046), ('hinu', 0.046), ('interobject', 0.046), ('nonexistent', 0.046), ('tia', 0.046), ('unbounded', 0.046), ('outer', 0.046), ('medical', 0.044), ('abruptly', 0.043), ('strekalovskiy', 0.043), ('usage', 0.043), ('regions', 0.042), ('instances', 0.041), ('incorporating', 0.04), ('obey', 0.04), ('anatomical', 0.04), ('delong', 0.04), ('fraser', 0.04), ('organs', 0.04), ('background', 0.04), ('minimum', 0.039), ('andrews', 0.038), ('discontinuous', 0.038), ('iand', 0.037), ('advantages', 0.037), ('mdin', 0.037), ('faithful', 0.037), ('analogue', 0.037), ('uth', 0.037), ('ctoe', 0.037), ('gto', 0.037), ('recurring', 0.037), ('popular', 0.037), ('ms', 0.036), ('definition', 0.036), ('atlas', 0.035), ('regional', 0.035), ('reformulating', 0.035), ('nested', 0.035), ('oeb', 0.035), ('stricter', 0.034), ('sho', 0.034), ('discrete', 0.034), ('segment', 0.033), ('atn', 0.033), ('assigning', 0.033), ('surfaces', 0.033), ('qualities', 0.032), ('fuzzy', 0.032), ('convex', 0.032), ('contained', 0.032), ('configurations', 0.031), ('el', 0.031), ('canada', 0.031), ('resolved', 0.031), ('memory', 0.031), ('objects', 0.03), ('adjacency', 0.03), ('lets', 0.03), ('beforehand', 0.03), ('gk', 0.03), ('object', 0.03), ('valued', 0.03), ('works', 0.029), ('bc', 0.029), ('priors', 0.029), ('spatial', 0.029), ('gj', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="63-tfidf-1" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>Author: Masoud S. Nosrati, Shawn Andrews, Ghassan Hamarneh</p><p>Abstract: The inclusion of shape and appearance priors have proven useful for obtaining more accurate and plausible segmentations, especially for complex objects with multiple parts. In this paper, we augment the popular MumfordShah model to incorporate two important geometrical constraints, termed containment and detachment, between different regions with a specified minimum distance between their boundaries. Our method is able to handle multiple instances of multi-part objects defined by these geometrical hamarneh} @ s fu . ca (a)Standar laΩb ehlingΩfuhnctionseting(Ωb)hΩOuirseΩtijng Figure 1: The inside vs. outside ambiguity in (a) is resolved by our containment constraint in (b). constraints using a single labeling function while maintaining global optimality. We demonstrate the utility and advantages of these two constraints and show that the proposed convex continuous method is superior to other state-of-theart methods, including its discrete counterpart, in terms of memory usage, and metrication errors.</p><p>2 0.096612029 <a title="63-tfidf-2" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>Author: Fan Wang, Qixing Huang, Leonidas J. Guibas</p><p>Abstract: Joint segmentation of image sets has great importance for object recognition, image classification, and image retrieval. In this paper, we aim to jointly segment a set of images starting from a small number of labeled images or none at all. To allow the images to share segmentation information with each other, we build a network that contains segmented as well as unsegmented images, and extract functional maps between connected image pairs based on image appearance features. These functional maps act as general property transporters between the images and, in particular, are used to transfer segmentations. We define and operate in a reduced functional space optimized so that the functional maps approximately satisfy cycle-consistency under composition in the network. A joint optimization framework is proposed to simultaneously generate all segmentation functions over the images so that they both align with local segmentation cues in each particular image, and agree with each other under network transportation. This formulation allows us to extract segmentations even with no training data, but can also exploit such data when available. The collective effect of the joint processing using functional maps leads to accurate information sharing among images and yields superior segmentation results, as shown on the iCoseg, MSRC, and PASCAL data sets.</p><p>3 0.080290608 <a title="63-tfidf-3" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>Author: Claudia Nieuwenhuis, Evgeny Strekalovskiy, Daniel Cremers</p><p>Abstract: We propose a convex multilabel framework for image sequence segmentation which allows to impose proportion priors on object parts in order to preserve their size ratios across multiple images. The key idea is that for strongly deformable objects such as a gymnast the size ratio of respective regions (head versus torso, legs versus full body, etc.) is typically preserved. We propose different ways to impose such priors in a Bayesian framework for image segmentation. We show that near-optimal solutions can be computed using convex relaxation techniques. Extensive qualitative and quantitative evaluations demonstrate that the proportion priors allow for highly accurate segmentations, avoiding seeping-out of regions and preserving semantically relevant small-scale structures such as hands or feet. They naturally apply to multiple object instances such as players in sports scenes, and they can relate different objects instead of object parts, e.g. organs in medical imaging. The algorithm is efficient and easily parallelized leading to proportion-consistent segmentations at runtimes around one second.</p><p>4 0.075290956 <a title="63-tfidf-4" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>Author: Abdelaziz Djelouah, Jean-Sébastien Franco, Edmond Boyer, François Le_Clerc, Patrick Pérez</p><p>Abstract: In this paper, we address the problem of object segmentation in multiple views or videos when two or more viewpoints of the same scene are available. We propose a new approach that propagates segmentation coherence information in both space and time, hence allowing evidences in one image to be shared over the complete set. To this aim the segmentation is cast as a single efficient labeling problem over space and time with graph cuts. In contrast to most existing multi-view segmentation methods that rely on some form of dense reconstruction, ours only requires a sparse 3D sampling to propagate information between viewpoints. The approach is thoroughly evaluated on standard multiview datasets, as well as on videos. With static views, results compete with state of the art methods but they are achieved with significantly fewer viewpoints. With multiple videos, we report results that demonstrate the benefit of segmentation propagation through temporal cues.</p><p>5 0.072739288 <a title="63-tfidf-5" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>Author: Jan Stühmer, Peter Schröder, Daniel Cremers</p><p>Abstract: We propose a novel method to include a connectivity prior into image segmentation that is based on a binary labeling of a directed graph, in this case a geodesic shortest path tree. Specifically we make two contributions: First, we construct a geodesic shortest path tree with a distance measure that is related to the image data and the bending energy of each path in the tree. Second, we include a connectivity prior in our segmentation model, that allows to segment not only a single elongated structure, but instead a whole connected branching tree. Because both our segmentation model and the connectivity constraint are convex, a global optimal solution can be found. To this end, we generalize a recent primal-dual algorithm for continuous convex optimization to an arbitrary graph structure. To validate our method we present results on data from medical imaging in angiography and retinal blood vessel segmentation.</p><p>6 0.07217855 <a title="63-tfidf-6" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>7 0.072003677 <a title="63-tfidf-7" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>8 0.070552625 <a title="63-tfidf-8" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>9 0.063329287 <a title="63-tfidf-9" href="./iccv-2013-A_Unified_Video_Segmentation_Benchmark%3A_Annotation%2C_Metrics_and_Analysis.html">33 iccv-2013-A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis</a></p>
<p>10 0.061986644 <a title="63-tfidf-10" href="./iccv-2013-Joint_Segmentation_and_Pose_Tracking_of_Human_in_Natural_Videos.html">225 iccv-2013-Joint Segmentation and Pose Tracking of Human in Natural Videos</a></p>
<p>11 0.057466466 <a title="63-tfidf-11" href="./iccv-2013-NEIL%3A_Extracting_Visual_Knowledge_from_Web_Data.html">285 iccv-2013-NEIL: Extracting Visual Knowledge from Web Data</a></p>
<p>12 0.056901015 <a title="63-tfidf-12" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>13 0.055365305 <a title="63-tfidf-13" href="./iccv-2013-Fast_Object_Segmentation_in_Unconstrained_Video.html">160 iccv-2013-Fast Object Segmentation in Unconstrained Video</a></p>
<p>14 0.055067535 <a title="63-tfidf-14" href="./iccv-2013-Learning_a_Dictionary_of_Shape_Epitomes_with_Applications_to_Image_Labeling.html">245 iccv-2013-Learning a Dictionary of Shape Epitomes with Applications to Image Labeling</a></p>
<p>15 0.053632118 <a title="63-tfidf-15" href="./iccv-2013-Holistic_Scene_Understanding_for_3D_Object_Detection_with_RGBD_Cameras.html">201 iccv-2013-Holistic Scene Understanding for 3D Object Detection with RGBD Cameras</a></p>
<p>16 0.053361729 <a title="63-tfidf-16" href="./iccv-2013-Online_Motion_Segmentation_Using_Dynamic_Label_Propagation.html">297 iccv-2013-Online Motion Segmentation Using Dynamic Label Propagation</a></p>
<p>17 0.053332217 <a title="63-tfidf-17" href="./iccv-2013-Video_Segmentation_by_Tracking_Many_Figure-Ground_Segments.html">442 iccv-2013-Video Segmentation by Tracking Many Figure-Ground Segments</a></p>
<p>18 0.051862303 <a title="63-tfidf-18" href="./iccv-2013-PixelTrack%3A_A_Fast_Adaptive_Algorithm_for_Tracking_Non-rigid_Objects.html">318 iccv-2013-PixelTrack: A Fast Adaptive Algorithm for Tracking Non-rigid Objects</a></p>
<p>19 0.051740587 <a title="63-tfidf-19" href="./iccv-2013-Coherent_Motion_Segmentation_in_Moving_Camera_Videos_Using_Optical_Flow_Orientations.html">78 iccv-2013-Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations</a></p>
<p>20 0.051310793 <a title="63-tfidf-20" href="./iccv-2013-Weakly_Supervised_Learning_of_Image_Partitioning_Using_Decision_Trees_with_Structured_Split_Criteria.html">448 iccv-2013-Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/iccv2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.117), (1, -0.028), (2, 0.013), (3, 0.002), (4, 0.032), (5, 0.03), (6, -0.062), (7, 0.049), (8, 0.027), (9, -0.081), (10, 0.007), (11, 0.052), (12, -0.006), (13, 0.007), (14, -0.006), (15, 0.01), (16, -0.012), (17, -0.008), (18, -0.052), (19, -0.045), (20, 0.035), (21, -0.025), (22, 0.006), (23, -0.011), (24, -0.012), (25, 0.017), (26, 0.041), (27, -0.012), (28, 0.033), (29, 0.026), (30, 0.001), (31, 0.021), (32, 0.02), (33, 0.023), (34, -0.033), (35, 0.029), (36, -0.063), (37, 0.062), (38, 0.016), (39, 0.056), (40, 0.022), (41, 0.032), (42, -0.001), (43, 0.052), (44, 0.018), (45, 0.026), (46, -0.008), (47, -0.006), (48, -0.014), (49, -0.103)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94033086 <a title="63-lsi-1" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>Author: Masoud S. Nosrati, Shawn Andrews, Ghassan Hamarneh</p><p>Abstract: The inclusion of shape and appearance priors have proven useful for obtaining more accurate and plausible segmentations, especially for complex objects with multiple parts. In this paper, we augment the popular MumfordShah model to incorporate two important geometrical constraints, termed containment and detachment, between different regions with a specified minimum distance between their boundaries. Our method is able to handle multiple instances of multi-part objects defined by these geometrical hamarneh} @ s fu . ca (a)Standar laΩb ehlingΩfuhnctionseting(Ωb)hΩOuirseΩtijng Figure 1: The inside vs. outside ambiguity in (a) is resolved by our containment constraint in (b). constraints using a single labeling function while maintaining global optimality. We demonstrate the utility and advantages of these two constraints and show that the proposed convex continuous method is superior to other state-of-theart methods, including its discrete counterpart, in terms of memory usage, and metrication errors.</p><p>2 0.79530251 <a title="63-lsi-2" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>Author: Fan Wang, Qixing Huang, Leonidas J. Guibas</p><p>Abstract: Joint segmentation of image sets has great importance for object recognition, image classification, and image retrieval. In this paper, we aim to jointly segment a set of images starting from a small number of labeled images or none at all. To allow the images to share segmentation information with each other, we build a network that contains segmented as well as unsegmented images, and extract functional maps between connected image pairs based on image appearance features. These functional maps act as general property transporters between the images and, in particular, are used to transfer segmentations. We define and operate in a reduced functional space optimized so that the functional maps approximately satisfy cycle-consistency under composition in the network. A joint optimization framework is proposed to simultaneously generate all segmentation functions over the images so that they both align with local segmentation cues in each particular image, and agree with each other under network transportation. This formulation allows us to extract segmentations even with no training data, but can also exploit such data when available. The collective effect of the joint processing using functional maps leads to accurate information sharing among images and yields superior segmentation results, as shown on the iCoseg, MSRC, and PASCAL data sets.</p><p>3 0.7902469 <a title="63-lsi-3" href="./iccv-2013-GrabCut_in_One_Cut.html">186 iccv-2013-GrabCut in One Cut</a></p>
<p>Author: Meng Tang, Lena Gorelick, Olga Veksler, Yuri Boykov</p><p>Abstract: Among image segmentation algorithms there are two major groups: (a) methods assuming known appearance models and (b) methods estimating appearance models jointly with segmentation. Typically, the first group optimizes appearance log-likelihoods in combination with some spacial regularization. This problem is relatively simple and many methods guarantee globally optimal results. The second group treats model parameters as additional variables transforming simple segmentation energies into highorder NP-hard functionals (Zhu-Yuille, Chan-Vese, GrabCut, etc). It is known that such methods indirectly minimize the appearance overlap between the segments. We propose a new energy term explicitly measuring L1 distance between the object and background appearance models that can be globally maximized in one graph cut. We show that in many applications our simple term makes NP-hard segmentation functionals unnecessary. Our one cut algorithm effectively replaces approximate iterative optimization techniques based on block coordinate descent.</p><p>4 0.75793505 <a title="63-lsi-4" href="./iccv-2013-Proportion_Priors_for_Image_Sequence_Segmentation.html">330 iccv-2013-Proportion Priors for Image Sequence Segmentation</a></p>
<p>Author: Claudia Nieuwenhuis, Evgeny Strekalovskiy, Daniel Cremers</p><p>Abstract: We propose a convex multilabel framework for image sequence segmentation which allows to impose proportion priors on object parts in order to preserve their size ratios across multiple images. The key idea is that for strongly deformable objects such as a gymnast the size ratio of respective regions (head versus torso, legs versus full body, etc.) is typically preserved. We propose different ways to impose such priors in a Bayesian framework for image segmentation. We show that near-optimal solutions can be computed using convex relaxation techniques. Extensive qualitative and quantitative evaluations demonstrate that the proportion priors allow for highly accurate segmentations, avoiding seeping-out of regions and preserving semantically relevant small-scale structures such as hands or feet. They naturally apply to multiple object instances such as players in sports scenes, and they can relate different objects instead of object parts, e.g. organs in medical imaging. The algorithm is efficient and easily parallelized leading to proportion-consistent segmentations at runtimes around one second.</p><p>5 0.7260142 <a title="63-lsi-5" href="./iccv-2013-Uncertainty-Driven_Efficiently-Sampled_Sparse_Graphical_Models_for_Concurrent_Tumor_Segmentation_and_Atlas_Registration.html">432 iccv-2013-Uncertainty-Driven Efficiently-Sampled Sparse Graphical Models for Concurrent Tumor Segmentation and Atlas Registration</a></p>
<p>Author: Sarah Parisot, William Wells_III, Stéphane Chemouny, Hugues Duffau, Nikos Paragios</p><p>Abstract: Graph-based methods have become popular in recent years and have successfully addressed tasks like segmentation and deformable registration. Their main strength is optimality of the obtained solution while their main limitation is the lack of precision due to the grid-like representations and the discrete nature of the quantized search space. In this paper we introduce a novel approach for combined segmentation/registration of brain tumors that adapts graph and sampling resolution according to the image content. To this end we estimate the segmentation and registration marginals towards adaptive graph resolution and intelligent definition of the search space. This information is considered in a hierarchical framework where uncertainties are propagated in a natural manner. State of the art results in the joint segmentation/registration of brain images with low-grade gliomas demonstrate the potential of our approach.</p><p>6 0.71795225 <a title="63-lsi-6" href="./iccv-2013-Exemplar_Cut.html">150 iccv-2013-Exemplar Cut</a></p>
<p>7 0.698434 <a title="63-lsi-7" href="./iccv-2013-Tree_Shape_Priors_with_Connectivity_Constraints_Using_Convex_Relaxation_on_General_Graphs.html">429 iccv-2013-Tree Shape Priors with Connectivity Constraints Using Convex Relaxation on General Graphs</a></p>
<p>8 0.69404316 <a title="63-lsi-8" href="./iccv-2013-Active_MAP_Inference_in_CRFs_for_Efficient_Semantic_Segmentation.html">42 iccv-2013-Active MAP Inference in CRFs for Efficient Semantic Segmentation</a></p>
<p>9 0.65829462 <a title="63-lsi-9" href="./iccv-2013-Progressive_Multigrid_Eigensolvers_for_Multiscale_Spectral_Segmentation.html">329 iccv-2013-Progressive Multigrid Eigensolvers for Multiscale Spectral Segmentation</a></p>
<p>10 0.65719557 <a title="63-lsi-10" href="./iccv-2013-Semantic_Segmentation_without_Annotating_Segments.html">379 iccv-2013-Semantic Segmentation without Annotating Segments</a></p>
<p>11 0.6416527 <a title="63-lsi-11" href="./iccv-2013-Multi-view_Object_Segmentation_in_Space_and_Time.html">282 iccv-2013-Multi-view Object Segmentation in Space and Time</a></p>
<p>12 0.63535941 <a title="63-lsi-12" href="./iccv-2013-Predicting_Sufficient_Annotation_Strength_for_Interactive_Foreground_Segmentation.html">326 iccv-2013-Predicting Sufficient Annotation Strength for Interactive Foreground Segmentation</a></p>
<p>13 0.62024575 <a title="63-lsi-13" href="./iccv-2013-Fix_Structured_Learning_of_2013_ICCV_paper_k2opt.pdf.html">171 iccv-2013-Fix Structured Learning of 2013 ICCV paper k2opt.pdf</a></p>
<p>14 0.61077601 <a title="63-lsi-14" href="./iccv-2013-A_Unified_Video_Segmentation_Benchmark%3A_Annotation%2C_Metrics_and_Analysis.html">33 iccv-2013-A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis</a></p>
<p>15 0.59514958 <a title="63-lsi-15" href="./iccv-2013-Sequential_Bayesian_Model_Update_under_Structured_Scene_Prior_for_Semantic_Road_Scenes_Labeling.html">386 iccv-2013-Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling</a></p>
<p>16 0.58369195 <a title="63-lsi-16" href="./iccv-2013-Learning_CRFs_for_Image_Parsing_with_Adaptive_Subgradient_Descent.html">234 iccv-2013-Learning CRFs for Image Parsing with Adaptive Subgradient Descent</a></p>
<p>17 0.5766632 <a title="63-lsi-17" href="./iccv-2013-Learning_a_Dictionary_of_Shape_Epitomes_with_Applications_to_Image_Labeling.html">245 iccv-2013-Learning a Dictionary of Shape Epitomes with Applications to Image Labeling</a></p>
<p>18 0.57371575 <a title="63-lsi-18" href="./iccv-2013-Characterizing_Layouts_of_Outdoor_Scenes_Using_Spatial_Topic_Processes.html">72 iccv-2013-Characterizing Layouts of Outdoor Scenes Using Spatial Topic Processes</a></p>
<p>19 0.55931216 <a title="63-lsi-19" href="./iccv-2013-Decomposing_Bag_of_Words_Histograms.html">104 iccv-2013-Decomposing Bag of Words Histograms</a></p>
<p>20 0.5584501 <a title="63-lsi-20" href="./iccv-2013-A_Deformable_Mixture_Parsing_Model_with_Parselets.html">8 iccv-2013-A Deformable Mixture Parsing Model with Parselets</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/iccv2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.068), (26, 0.088), (31, 0.034), (42, 0.098), (48, 0.384), (64, 0.046), (73, 0.028), (89, 0.132), (98, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83441949 <a title="63-lda-1" href="./iccv-2013-Pyramid_Coding_for_Functional_Scene_Element_Recognition_in_Video_Scenes.html">331 iccv-2013-Pyramid Coding for Functional Scene Element Recognition in Video Scenes</a></p>
<p>Author: Eran Swears, Anthony Hoogs, Kim Boyer</p><p>Abstract: Recognizing functional scene elemeents in video scenes based on the behaviors of moving objects that interact with them is an emerging problem ooff interest. Existing approaches have a limited ability to chharacterize elements such as cross-walks, intersections, andd buildings that have low activity, are multi-modal, or havee indirect evidence. Our approach recognizes the low activvity and multi-model elements (crosswalks/intersections) by introducing a hierarchy of descriptive clusters to fform a pyramid of codebooks that is sparse in the numbber of clusters and dense in content. The incorporation oof local behavioral context such as person-enter-building aand vehicle-parking nearby enables the detection of elemennts that do not have direct motion-based evidence, e.g. buuildings. These two contributions significantly improvee scene element recognition when compared against thhree state-of-the-art approaches. Results are shown on tyypical ground level surveillance video and for the first time on the more complex Wide Area Motion Imagery.</p><p>2 0.79780108 <a title="63-lda-2" href="./iccv-2013-Pedestrian_Parsing_via_Deep_Decompositional_Network.html">311 iccv-2013-Pedestrian Parsing via Deep Decompositional Network</a></p>
<p>Author: Ping Luo, Xiaogang Wang, Xiaoou Tang</p><p>Abstract: We propose a new Deep Decompositional Network (DDN) for parsing pedestrian images into semantic regions, such as hair, head, body, arms, and legs, where the pedestrians can be heavily occluded. Unlike existing methods based on template matching or Bayesian inference, our approach directly maps low-level visual features to the label maps of body parts with DDN, which is able to accurately estimate complex pose variations with good robustness to occlusions and background clutters. DDN jointly estimates occluded regions and segments body parts by stacking three types of hidden layers: occlusion estimation layers, completion layers, and decomposition layers. The occlusion estimation layers estimate a binary mask, indicating which part of a pedestrian is invisible. The completion layers synthesize low-level features of the invisible part from the original features and the occlusion mask. The decomposition layers directly transform the synthesized visual features to label maps. We devise a new strategy to pre-train these hidden layers, and then fine-tune the entire network using the stochastic gradient descent. Experimental results show that our approach achieves better segmentation accuracy than the state-of-the-art methods on pedestrian images with or without occlusions. Another important contribution of this paper is that it provides a large scale benchmark human parsing dataset1 that includes 3, 673 annotated samples collected from 171 surveillance videos. It is 20 times larger than existing public datasets.</p><p>same-paper 3 0.76734585 <a title="63-lda-3" href="./iccv-2013-Bounded_Labeling_Function_for_Global_Segmentation_of_Multi-part_Objects_with_Geometric_Constraints.html">63 iccv-2013-Bounded Labeling Function for Global Segmentation of Multi-part Objects with Geometric Constraints</a></p>
<p>Author: Masoud S. Nosrati, Shawn Andrews, Ghassan Hamarneh</p><p>Abstract: The inclusion of shape and appearance priors have proven useful for obtaining more accurate and plausible segmentations, especially for complex objects with multiple parts. In this paper, we augment the popular MumfordShah model to incorporate two important geometrical constraints, termed containment and detachment, between different regions with a specified minimum distance between their boundaries. Our method is able to handle multiple instances of multi-part objects defined by these geometrical hamarneh} @ s fu . ca (a)Standar laΩb ehlingΩfuhnctionseting(Ωb)hΩOuirseΩtijng Figure 1: The inside vs. outside ambiguity in (a) is resolved by our containment constraint in (b). constraints using a single labeling function while maintaining global optimality. We demonstrate the utility and advantages of these two constraints and show that the proposed convex continuous method is superior to other state-of-theart methods, including its discrete counterpart, in terms of memory usage, and metrication errors.</p><p>4 0.69487154 <a title="63-lda-4" href="./iccv-2013-Pose-Configurable_Generic_Tracking_of_Elongated_Objects.html">320 iccv-2013-Pose-Configurable Generic Tracking of Elongated Objects</a></p>
<p>Author: Daniel Wesierski, Patrick Horain</p><p>Abstract: Elongated objects have various shapes and can shift, rotate, change scale, and be rigid or deform by flexing, articulating, and vibrating, with examples as varied as a glass bottle, a robotic arm, a surgical suture, a finger pair, a tram, and a guitar string. This generally makes tracking of poses of elongated objects very challenging. We describe a unified, configurable framework for tracking the pose of elongated objects, which move in the image plane and extend over the image region. Our method strives for simplicity, versatility, and efficiency. The object is decomposed into a chained assembly of segments of multiple parts that are arranged under a hierarchy of tailored spatio-temporal constraints. In this hierarchy, segments can rescale independently while their elasticity is controlled with global orientations and local distances. While the trend in tracking is to design complex, structure-free algorithms that update object appearance on- line, we show that our tracker, with the novel but remarkably simple, structured organization of parts with constant appearance, reaches or improves state-of-the-art performance. Most importantly, our model can be easily configured to track exact pose of arbitrary, elongated objects in the image plane. The tracker can run up to 100 fps on a desktop PC, yet the computation time scales linearly with the number of object parts. To our knowledge, this is the first approach to generic tracking of elongated objects.</p><p>5 0.68301833 <a title="63-lda-5" href="./iccv-2013-Robust_Dictionary_Learning_by_Error_Source_Decomposition.html">354 iccv-2013-Robust Dictionary Learning by Error Source Decomposition</a></p>
<p>Author: Zhuoyuan Chen, Ying Wu</p><p>Abstract: Sparsity models have recently shown great promise in many vision tasks. Using a learned dictionary in sparsity models can in general outperform predefined bases in clean data. In practice, both training and testing data may be corrupted and contain noises and outliers. Although recent studies attempted to cope with corrupted data and achieved encouraging results in testing phase, how to handle corruption in training phase still remains a very difficult problem. In contrast to most existing methods that learn the dictionaryfrom clean data, this paper is targeted at handling corruptions and outliers in training data for dictionary learning. We propose a general method to decompose the reconstructive residual into two components: a non-sparse component for small universal noises and a sparse component for large outliers, respectively. In addition, , further analysis reveals the connection between our approach and the “partial” dictionary learning approach, updating only part of the prototypes (or informative codewords) with remaining (or noisy codewords) fixed. Experiments on synthetic data as well as real applications have shown satisfactory per- formance of this new robust dictionary learning approach.</p><p>6 0.65798807 <a title="63-lda-6" href="./iccv-2013-Illuminant_Chromaticity_from_Image_Sequences.html">207 iccv-2013-Illuminant Chromaticity from Image Sequences</a></p>
<p>7 0.56568331 <a title="63-lda-7" href="./iccv-2013-Joint_Deep_Learning_for_Pedestrian_Detection.html">220 iccv-2013-Joint Deep Learning for Pedestrian Detection</a></p>
<p>8 0.55066514 <a title="63-lda-8" href="./iccv-2013-Multi-stage_Contextual_Deep_Learning_for_Pedestrian_Detection.html">279 iccv-2013-Multi-stage Contextual Deep Learning for Pedestrian Detection</a></p>
<p>9 0.54006553 <a title="63-lda-9" href="./iccv-2013-A_Deep_Sum-Product_Architecture_for_Robust_Facial_Attributes_Analysis.html">7 iccv-2013-A Deep Sum-Product Architecture for Robust Facial Attributes Analysis</a></p>
<p>10 0.53666615 <a title="63-lda-10" href="./iccv-2013-Hybrid_Deep_Learning_for_Face_Verification.html">206 iccv-2013-Hybrid Deep Learning for Face Verification</a></p>
<p>11 0.52763009 <a title="63-lda-11" href="./iccv-2013-Deep_Learning_Identity-Preserving_Face_Space.html">106 iccv-2013-Deep Learning Identity-Preserving Face Space</a></p>
<p>12 0.51369131 <a title="63-lda-12" href="./iccv-2013-Image_Co-segmentation_via_Consistent_Functional_Maps.html">208 iccv-2013-Image Co-segmentation via Consistent Functional Maps</a></p>
<p>13 0.50525439 <a title="63-lda-13" href="./iccv-2013-A_Color_Constancy_Model_with_Double-Opponency_Mechanisms.html">5 iccv-2013-A Color Constancy Model with Double-Opponency Mechanisms</a></p>
<p>14 0.50366008 <a title="63-lda-14" href="./iccv-2013-Beyond_Hard_Negative_Mining%3A_Efficient_Detector_Learning_via_Block-Circulant_Decomposition.html">61 iccv-2013-Beyond Hard Negative Mining: Efficient Detector Learning via Block-Circulant Decomposition</a></p>
<p>15 0.50269032 <a title="63-lda-15" href="./iccv-2013-Person_Re-identification_by_Salience_Matching.html">313 iccv-2013-Person Re-identification by Salience Matching</a></p>
<p>16 0.50240755 <a title="63-lda-16" href="./iccv-2013-Perceptual_Fidelity_Aware_Mean_Squared_Error.html">312 iccv-2013-Perceptual Fidelity Aware Mean Squared Error</a></p>
<p>17 0.50027782 <a title="63-lda-17" href="./iccv-2013-Restoring_an_Image_Taken_through_a_Window_Covered_with_Dirt_or_Rain.html">351 iccv-2013-Restoring an Image Taken through a Window Covered with Dirt or Rain</a></p>
<p>18 0.49492124 <a title="63-lda-18" href="./iccv-2013-Cosegmentation_and_Cosketch_by_Unsupervised_Learning.html">95 iccv-2013-Cosegmentation and Cosketch by Unsupervised Learning</a></p>
<p>19 0.49394917 <a title="63-lda-19" href="./iccv-2013-Exploiting_Reflection_Change_for_Automatic_Reflection_Removal.html">151 iccv-2013-Exploiting Reflection Change for Automatic Reflection Removal</a></p>
<p>20 0.49098724 <a title="63-lda-20" href="./iccv-2013-A_Max-Margin_Perspective_on_Sparse_Representation-Based_Classification.html">20 iccv-2013-A Max-Margin Perspective on Sparse Representation-Based Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
